[
    {
        "title": "Transforming Information Systems Management: A Reference Model for\n  Digital Engineering Integration",
        "link": "http://arxiv.org/abs/2405.19576v1",
        "abstract": "Digital engineering practices offer significant yet underutilized potential\nfor improving information assurance and system lifecycle management. This paper\nexamines how capabilities like model-based engineering, digital threads, and\nintegrated product lifecycles can address gaps in prevailing frameworks. A\nreference model demonstrates applying digital engineering techniques to a\nreference information system, exhibiting enhanced traceability, risk\nvisibility, accuracy, and integration. The model links strategic needs to\nrequirements and architecture while reusing authoritative elements across\nviews. Analysis of the model shows digital engineering closes gaps in\ncompliance, monitoring, change management, and risk assessment. Findings\nindicate purposeful digital engineering adoption could transform cybersecurity,\noperations, service delivery, and system governance through comprehensive\ndigital system representations. This research provides a foundation for\nmaturing application of digital engineering for information systems as\norganizations modernize infrastructure and pursue digital transformation.",
        "subjects": [
            "cs.CR",
            "cs.SE"
        ],
        "authors": [
            "John Bonar",
            "John Hastings"
        ],
        "published": "2024-05-29T23:49:47Z"
    },
    {
        "title": "A Deep Convolutional Neural Network-based Model for Aspect and Polarity\n  Classification in Hausa Movie Reviews",
        "link": "http://arxiv.org/abs/2405.19575v1",
        "abstract": "Aspect-based Sentiment Analysis (ABSA) is crucial for understanding sentiment\nnuances in text, especially across diverse languages and cultures. This paper\nintroduces a novel Deep Convolutional Neural Network (CNN)-based model tailored\nfor aspect and polarity classification in Hausa movie reviews, an\nunderrepresented language in sentiment analysis research. A comprehensive Hausa\nABSA dataset is created, filling a significant gap in resource availability.\nThe dataset, preprocessed using sci-kit-learn for TF-IDF transformation,\nincludes manually annotated aspect-level feature ontology words and sentiment\npolarity assignments. The proposed model combines CNNs with attention\nmechanisms for aspect-word prediction, leveraging contextual information and\nsentiment polarities. With 91% accuracy on aspect term extraction and 92% on\nsentiment polarity classification, the model outperforms traditional machine\nmodels, offering insights into specific aspects and sentiments. This study\nadvances ABSA research, particularly in underrepresented languages, with\nimplications for cross-cultural linguistic research.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Umar Ibrahim",
            "Abubakar Yakubu Zandam",
            "Fatima Muhammad Adam",
            "Aminu Musa"
        ],
        "published": "2024-05-29T23:45:42Z"
    },
    {
        "title": "Blind Image Restoration via Fast Diffusion Inversion",
        "link": "http://arxiv.org/abs/2405.19572v1",
        "abstract": "Recently, various methods have been proposed to solve Image Restoration (IR)\ntasks using a pre-trained diffusion model leading to state-of-the-art\nperformance. However, most of these methods assume that the degradation\noperator in the IR task is completely known. Furthermore, a common\ncharacteristic among these approaches is that they alter the diffusion sampling\nprocess in order to satisfy the consistency with the degraded input image. This\nchoice has recently been shown to be sub-optimal and to cause the restored\nimage to deviate from the data manifold. To address these issues, we propose\nBlind Image Restoration via fast Diffusion inversion (BIRD) a blind IR method\nthat jointly optimizes for the degradation model parameters and the restored\nimage. To ensure that the restored images lie onto the data manifold, we\npropose a novel sampling technique on a pre-trained diffusion model. A key idea\nin our method is not to modify the reverse sampling, i.e., not to alter all the\nintermediate latents, once an initial noise is sampled. This is ultimately\nequivalent to casting the IR task as an optimization problem in the space of\nthe input noise. Moreover, to mitigate the computational cost associated with\ninverting a fully unrolled diffusion model, we leverage the inherent capability\nof these models to skip ahead in the forward diffusion process using large time\nsteps. We experimentally validate BIRD on several image restoration tasks and\nshow that it achieves state of the art performance on all of them. Our code is\navailable at https://github.com/hamadichihaoui/BIRD.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hamadi Chihaoui",
            "Abdelhak Lemkhenter",
            "Paolo Favaro"
        ],
        "published": "2024-05-29T23:38:12Z"
    },
    {
        "title": "Distributed Online Planning for Min-Max Problems in Networked Markov\n  Games",
        "link": "http://arxiv.org/abs/2405.19570v1",
        "abstract": "Min-max problems are important in multi-agent sequential decision-making\nbecause they improve the performance of the worst-performing agent in the\nnetwork. However, solving the multi-agent min-max problem is challenging. We\npropose a modular, distributed, online planning-based algorithm that is able to\napproximate the solution of the min-max objective in networked Markov games,\nassuming that the agents communicate within a network topology and the\ntransition and reward functions are neighborhood-dependent. This set-up is\nencountered in the multi-robot setting. Our method consists of two phases at\nevery planning step. In the first phase, each agent obtains sample returns\nbased on its local reward function, by performing online planning. Using the\nsamples from online planning, each agent constructs a concave approximation of\nits underlying local return as a function of only the action of its\nneighborhood at the next planning step. In the second phase, the agents deploy\na distributed optimization framework that converges to the optimal immediate\nnext action for each agent, based on the function approximations of the first\nphase. We demonstrate our algorithm's performance through formation control\nsimulations.",
        "subjects": [
            "cs.MA",
            "cs.RO"
        ],
        "authors": [
            "Alexandros E. Tzikas",
            "Jinkyoo Park",
            "Mykel J. Kochenderfer",
            "Ross E. Allen"
        ],
        "published": "2024-05-29T23:26:30Z"
    },
    {
        "title": "Improved Convex Decomposition with Ensembling and Boolean Primitives",
        "link": "http://arxiv.org/abs/2405.19569v1",
        "abstract": "Describing a scene in terms of primitives -- geometrically simple shapes that\noffer a parsimonious but accurate abstraction of structure -- is an established\nvision problem. This is a good model of a difficult fitting problem: different\nscenes require different numbers of primitives and primitives interact\nstrongly, but any proposed solution can be evaluated at inference time. The\nstate of the art method involves a learned regression procedure to predict a\nstart point consisting of a fixed number of primitives, followed by a descent\nmethod to refine the geometry and remove redundant primitives. Methods are\nevaluated by accuracy in depth and normal prediction and in scene segmentation.\nThis paper shows that very significant improvements in accuracy can be obtained\nby (a) incorporating a small number of negative primitives and (b) ensembling\nover a number of different regression procedures. Ensembling is by refining\neach predicted start point, then choosing the best by fitting loss. Extensive\nexperiments on a standard dataset confirm that negative primitives are useful\nin a large fraction of images, and that our refine-then-choose strategy\noutperforms choose-then-refine, confirming that the fitting problem is very\ndifficult.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Vaibhav Vavilala",
            "Florian Kluger",
            "Seemandhar Jain",
            "Bodo Rosenhahn",
            "David Forsyth"
        ],
        "published": "2024-05-29T23:24:48Z"
    },
    {
        "title": "Organizing Background to Explore Latent Classes for Incremental Few-shot\n  Semantic Segmentation",
        "link": "http://arxiv.org/abs/2405.19568v1",
        "abstract": "The goal of incremental Few-shot Semantic Segmentation (iFSS) is to extend\npre-trained segmentation models to new classes via few annotated images without\naccess to old training data. During incrementally learning novel classes, the\ndata distribution of old classes will be destroyed, leading to catastrophic\nforgetting. Meanwhile, the novel classes have only few samples, making models\nimpossible to learn the satisfying representations of novel classes. For the\niFSS problem, we propose a network called OINet, i.e., the background embedding\nspace \\textbf{O}rganization and prototype \\textbf{I}nherit Network.\nSpecifically, when training base classes, OINet uses multiple classification\nheads for the background and sets multiple sub-class prototypes to reserve\nembedding space for the latent novel classes. During incrementally learning\nnovel classes, we propose a strategy to select the sub-class prototypes that\nbest match the current learning novel classes and make the novel classes\ninherit the selected prototypes' embedding space. This operation allows the\nnovel classes to be registered in the embedding space using few samples without\naffecting the distribution of the base classes. Results on Pascal-VOC and COCO\nshow that OINet achieves a new state of the art.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Lianlei Shan",
            "Wenzhang Zhou",
            "Wei Li",
            "Xingyu Ding"
        ],
        "published": "2024-05-29T23:22:12Z"
    },
    {
        "title": "Dr-LLaVA: Visual Instruction Tuning with Symbolic Clinical Grounding",
        "link": "http://arxiv.org/abs/2405.19567v1",
        "abstract": "Vision-Language Models (VLM) can support clinicians by analyzing medical\nimages and engaging in natural language interactions to assist in diagnostic\nand treatment tasks. However, VLMs often exhibit \"hallucinogenic\" behavior,\ngenerating textual outputs not grounded in contextual multimodal information.\nThis challenge is particularly pronounced in the medical domain, where we do\nnot only require VLM outputs to be accurate in single interactions but also to\nbe consistent with clinical reasoning and diagnostic pathways throughout\nmulti-turn conversations. For this purpose, we propose a new alignment\nalgorithm that uses symbolic representations of clinical reasoning to ground\nVLMs in medical knowledge. These representations are utilized to (i) generate\nGPT-4-guided visual instruction tuning data at scale, simulating clinician-VLM\nconversations with demonstrations of clinical reasoning, and (ii) create an\nautomatic reward function that evaluates the clinical validity of VLM\ngenerations throughout clinician-VLM interactions. Our algorithm eliminates the\nneed for human involvement in training data generation or reward model\nconstruction, reducing costs compared to standard reinforcement learning with\nhuman feedback (RLHF). We apply our alignment algorithm to develop Dr-LLaVA, a\nconversational VLM finetuned for analyzing bone marrow pathology slides,\ndemonstrating strong performance in multi-turn medical conversations.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Shenghuan Sun",
            "Gregory M. Goldgof",
            "Alexander Schubert",
            "Zhiqing Sun",
            "Thomas Hartvigsen",
            "Atul J. Butte",
            "Ahmed Alaa"
        ],
        "published": "2024-05-29T23:19:28Z"
    },
    {
        "title": "Unbending strategies shepherd cooperation and suppress extortion in\n  spatial populations",
        "link": "http://arxiv.org/abs/2405.19565v1",
        "abstract": "Evolutionary game dynamics on networks typically consider the competition\namong simple strategies such as cooperation and defection in the Prisoner's\nDilemma and summarize the effect of population structure as network\nreciprocity. However, it remains largely unknown regarding the evolutionary\ndynamics involving multiple powerful strategies typically considered in\nrepeated games, such as the zero-determinant (ZD) strategies that are able to\nenforce a linear payoff relationship between them and their co-players. Here,\nwe consider the evolutionary dynamics of always cooperate (AllC), extortionate\nZD (extortioners), and unbending players in lattice populations based on the\ncommonly used death-birth updating. Out of the class of unbending strategies,\nwe consider a particular candidate, PSO Gambler, a machine-learning-optimized\nmemory-one strategy, which can foster reciprocal cooperation and fairness among\nextortionate players. We derive analytical results under weak selection and\nrare mutations, including pairwise fixation probabilities and long-term\nfrequencies of strategies. In the absence of the third unbending type,\nextortioners can achieve a half-half split in equilibrium with unconditional\ncooperators for sufficiently large extortion factors. However, the presence of\nunbending players fundamentally changes the dynamics and tilts the system to\nfavor unbending cooperation. Most surprisingly, extortioners cannot dominate at\nall regardless of how large their extortion factor is, and the long-term\nfrequency of unbending players is maintained almost as a constant. Our\nanalytical method is applicable to studying the evolutionary dynamics of\nmultiple strategies in structured populations. Our work provides insights into\nthe interplay between network reciprocity and direct reciprocity, revealing the\nrole of unbending strategies in enforcing fairness and suppressing extortion.",
        "subjects": [
            "physics.soc-ph",
            "cs.GT",
            "q-bio.PE"
        ],
        "authors": [
            "Zijie Chen",
            "Yuxin Geng",
            "Xingru Chen",
            "Feng Fu"
        ],
        "published": "2024-05-29T23:14:10Z"
    },
    {
        "title": "Unlearning Climate Misinformation in Large Language Models",
        "link": "http://arxiv.org/abs/2405.19563v1",
        "abstract": "Misinformation regarding climate change is a key roadblock in addressing one\nof the most serious threats to humanity. This paper investigates factual\naccuracy in large language models (LLMs) regarding climate information. Using\ntrue/false labeled Q&A data for fine-tuning and evaluating LLMs on\nclimate-related claims, we compare open-source models, assessing their ability\nto generate truthful responses to climate change questions. We investigate the\ndetectability of models intentionally poisoned with false climate information,\nfinding that such poisoning may not affect the accuracy of a model's responses\nin other domains. Furthermore, we compare the effectiveness of unlearning\nalgorithms, fine-tuning, and Retrieval-Augmented Generation (RAG) for factually\ngrounding LLMs on climate change topics. Our evaluation reveals that unlearning\nalgorithms can be effective for nuanced conceptual claims, despite previous\nfindings suggesting their inefficacy in privacy contexts. These insights aim to\nguide the development of more factually reliable LLMs and highlight the need\nfor additional work to secure LLMs against misinformation attacks.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Michael Fore",
            "Simranjit Singh",
            "Chaehong Lee",
            "Amritanshu Pandey",
            "Antonios Anastasopoulos",
            "Dimitrios Stamoulis"
        ],
        "published": "2024-05-29T23:11:53Z"
    },
    {
        "title": "Selective Explanations",
        "link": "http://arxiv.org/abs/2405.19562v1",
        "abstract": "Feature attribution methods explain black-box machine learning (ML) models by\nassigning importance scores to input features. These methods can be\ncomputationally expensive for large ML models. To address this challenge, there\nhas been increasing efforts to develop amortized explainers, where a machine\nlearning model is trained to predict feature attribution scores with only one\ninference. Despite their efficiency, amortized explainers can produce\ninaccurate predictions and misleading explanations. In this paper, we propose\nselective explanations, a novel feature attribution method that (i) detects\nwhen amortized explainers generate low-quality explanations and (ii) improves\nthese explanations using a technique called explanations with initial guess.\nOur selective explanation method allows practitioners to specify the fraction\nof samples that receive explanations with initial guess, offering a principled\nway to bridge the gap between amortized explainers and their high-quality\ncounterparts.",
        "subjects": [
            "cs.CY",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Lucas Monteiro Paes",
            "Dennis Wei",
            "Flavio P. Calmon"
        ],
        "published": "2024-05-29T23:08:31Z"
    },
    {
        "title": "Quo Vadis ChatGPT? From Large Language Models to Large Knowledge Models",
        "link": "http://arxiv.org/abs/2405.19561v1",
        "abstract": "The startling success of ChatGPT and other large language models (LLMs) using\ntransformer-based generative neural network architecture in applications such\nas natural language processing and image synthesis has many researchers excited\nabout potential opportunities in process systems engineering (PSE). The almost\nhuman-like performance of LLMs in these areas is indeed very impressive,\nsurprising, and a major breakthrough. Their capabilities are very useful in\ncertain tasks, such as writing first drafts of documents, code writing\nassistance, text summarization, etc. However, their success is limited in\nhighly scientific domains as they cannot yet reason, plan, or explain due to\ntheir lack of in-depth domain knowledge. This is a problem in domains such as\nchemical engineering as they are governed by fundamental laws of physics and\nchemistry (and biology), constitutive relations, and highly technical knowledge\nabout materials, processes, and systems. Although purely data-driven machine\nlearning has its immediate uses, the long-term success of AI in scientific and\nengineering domains would depend on developing hybrid AI systems that use first\nprinciples and technical knowledge effectively. We call these hybrid AI systems\nLarge Knowledge Models (LKMs), as they will not be limited to only NLP-based\ntechniques or NLP-like applications. In this paper, we discuss the challenges\nand opportunities in developing such systems in chemical engineering.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "I.2.0; I.2.7"
        ],
        "authors": [
            "Venkat Venkatasubramanian",
            "Arijit Chakraborty"
        ],
        "published": "2024-05-29T23:06:54Z"
    },
    {
        "title": "Clustering Mixtures of Discrete Distributions: A Note on Mitra's\n  Algorithm",
        "link": "http://arxiv.org/abs/2405.19559v1",
        "abstract": "In this note, we provide a refined analysis of Mitra's algorithm\n\\cite{mitra2008clustering} for classifying general discrete mixture\ndistribution models. Built upon spectral clustering\n\\cite{mcsherry2001spectral}, this algorithm offers compelling conditions for\nprobability distributions. We enhance this analysis by tailoring the model to\nbipartite stochastic block models, resulting in more refined conditions.\nCompared to those derived in \\cite{mitra2008clustering}, our improved\nseparation conditions are obtained.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Mohamed Seif",
            "Yanxi Chen"
        ],
        "published": "2024-05-29T22:55:45Z"
    },
    {
        "title": "Numerical analysis of a 1/2-equation model of turbulence",
        "link": "http://arxiv.org/abs/2405.19554v1",
        "abstract": "The recent 1/2-equation model of turbulence is a simplification of the\nstandard Kolmogorov-Prandtl 1-equation URANS model. Surprisingly, initial\nnumerical tests indicated that the 1/2-equation model produces comparable\nvelocity statistics at reduced cost. It is also a test problem and first step\nfor developing numerical analysis to address a full 1-equation model. This\nreport begins the numerical analysis of the 1/2 equation model. Stability,\nconvergence and error estimates are proven for a semi-discrete and fully\ndiscrete approximation. Finally, numerical tests are conducted to validate our\nconvergence theory.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Wei-Wei Han",
            "Rui Fang",
            "William Layton"
        ],
        "published": "2024-05-29T22:44:00Z"
    },
    {
        "title": "Convergence Bounds for Sequential Monte Carlo on Multimodal\n  Distributions using Soft Decomposition",
        "link": "http://arxiv.org/abs/2405.19553v1",
        "abstract": "We prove bounds on the variance of a function $f$ under the empirical measure\nof the samples obtained by the Sequential Monte Carlo (SMC) algorithm, with\ntime complexity depending on local rather than global Markov chain mixing\ndynamics. SMC is a Markov Chain Monte Carlo (MCMC) method, which starts by\ndrawing $N$ particles from a known distribution, and then, through a sequence\nof distributions, re-weights and re-samples the particles, at each instance\napplying a Markov chain for smoothing. In principle, SMC tries to alleviate\nproblems from multi-modality. However, most theoretical guarantees for SMC are\nobtained by assuming global mixing time bounds, which are only efficient in the\nuni-modal setting. We show that bounds can be obtained in the truly multi-modal\nsetting, with mixing times that depend only on local MCMC dynamics.",
        "subjects": [
            "math.ST",
            "cs.LG",
            "math.PR",
            "stat.ML",
            "stat.TH"
        ],
        "authors": [
            "Holden Lee",
            "Matheau Santana-Gijzen"
        ],
        "published": "2024-05-29T22:43:45Z"
    },
    {
        "title": "Point process analysis of geographical diffusion of news in Argentina",
        "link": "http://arxiv.org/abs/2405.19552v1",
        "abstract": "The diffusion of information plays a crucial role in a society,\ncharacterizing the diffusion process is challenging because it is highly\nnon-stationary and varies with the media type. To understand the spreading of\nnewspaper news in Argentina, we collected data from more than 27000 articles\npublished in six main provinces during four months. We classified the articles\ninto 20 thematic axes and obtained a set of 120 time series that capture daily\nnewspaper attention on different topics in different provinces. To analyze the\ndata we use a point process approach. For each topic, $n$, and for all pairs of\nprovinces, $i$ and $j$, we use two measures to quantify the synchronicity of\nthe events, $Q_s(i,j)$, which quantifies the number of events that occur almost\nsimultaneously in $i$ and $j$, and $Q_a(i,j)$, which quantifies the direction\nof news spreading. We also analyze the dataset using well-known measures to\ndetect correlations and dependencies, computed from the raw time series:\nundirected measures (linear cross-correlation, $CC$, and nonlinear mutual\ninformation, $MI$) and directed measures (linear Granger causality, $GC$, and\nnonlinear Transfer entropy, $TE$). Our analysis unveils how fast the\ninformation diffusion process is, as high values of $Q_{s}$, $CC$, and $MI$\nreveal pairs of provinces with very similar and almost simultaneous temporal\nvariations of media attention. On the other hand, $GC$ and $TE$ do not perform\nwell in this context because they often return opposite directions of\ninformation transfer. We interpret this as due to three main factors: the\ncharacteristics of the data, which is highly non-stationary, the\ncharacteristics of the information diffusion process, which is very fast and\nprobably acts at a sub-resolution time scale, and the action of large media\ncompanies that act as global, external drivers of information dissemination.",
        "subjects": [
            "physics.soc-ph",
            "cs.SI"
        ],
        "authors": [
            "Lucio L. Garcia",
            "Giulio Tirabassi",
            "Cristina Masoller",
            "Pablo Balenzuela"
        ],
        "published": "2024-05-29T22:29:37Z"
    },
    {
        "title": "Stress-Testing Capability Elicitation With Password-Locked Models",
        "link": "http://arxiv.org/abs/2405.19550v1",
        "abstract": "To determine the safety of large language models (LLMs), AI developers must\nbe able to assess their dangerous capabilities. But simple prompting strategies\noften fail to elicit an LLM's full capabilities. One way to elicit capabilities\nmore robustly is to fine-tune the LLM to complete the task. In this paper, we\ninvestigate the conditions under which fine-tuning-based elicitation suffices\nto elicit capabilities. To do this, we introduce password-locked models, LLMs\nfine-tuned such that some of their capabilities are deliberately hidden.\nSpecifically, these LLMs are trained to exhibit these capabilities only when a\npassword is present in the prompt, and to imitate a much weaker LLM otherwise.\nPassword-locked models enable a novel method of evaluating capabilities\nelicitation methods, by testing whether these password-locked capabilities can\nbe elicited without using the password. We find that a few high-quality\ndemonstrations are often sufficient to fully elicit password-locked\ncapabilities. More surprisingly, fine-tuning can elicit other capabilities that\nhave been locked using the same password, or even different passwords.\nFurthermore, when only evaluations, and not demonstrations, are available,\napproaches like reinforcement learning are still often able to elicit\ncapabilities. Overall, our findings suggest that fine-tuning is an effective\nmethod of eliciting hidden capabilities of current models, but may be\nunreliable when high-quality demonstrations are not available, e.g. as may be\nthe case when models' (hidden) capabilities exceed those of human\ndemonstrators.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "authors": [
            "Ryan Greenblatt",
            "Fabien Roger",
            "Dmitrii Krasheninnikov",
            "David Krueger"
        ],
        "published": "2024-05-29T22:26:26Z"
    },
    {
        "title": "RLeXplore: Accelerating Research in Intrinsically-Motivated\n  Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.19548v1",
        "abstract": "Extrinsic rewards can effectively guide reinforcement learning (RL) agents in\nspecific tasks. However, extrinsic rewards frequently fall short in complex\nenvironments due to the significant human effort needed for their design and\nannotation. This limitation underscores the necessity for intrinsic rewards,\nwhich offer auxiliary and dense signals and can enable agents to learn in an\nunsupervised manner. Although various intrinsic reward formulations have been\nproposed, their implementation and optimization details are insufficiently\nexplored and lack standardization, thereby hindering research progress. To\naddress this gap, we introduce RLeXplore, a unified, highly modularized, and\nplug-and-play framework offering reliable implementations of eight\nstate-of-the-art intrinsic reward algorithms. Furthermore, we conduct an\nin-depth study that identifies critical implementation details and establishes\nwell-justified standard practices in intrinsically-motivated RL. The source\ncode for RLeXplore is available at https://github.com/RLE-Foundation/RLeXplore.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Mingqi Yuan",
            "Roger Creus Castanyer",
            "Bo Li",
            "Xin Jin",
            "Glen Berseth",
            "Wenjun Zeng"
        ],
        "published": "2024-05-29T22:23:20Z"
    },
    {
        "title": "CLIPLoss and Norm-Based Data Selection Methods for Multimodal\n  Contrastive Learning",
        "link": "http://arxiv.org/abs/2405.19547v1",
        "abstract": "Data selection has emerged as a core issue for large-scale visual-language\nmodel pretaining (e.g., CLIP), particularly with noisy web-curated datasets.\nThree main data selection approaches are: (1) leveraging external non-CLIP\nmodels to aid data selection, (2) training new CLIP-style embedding models that\nare more effective at selecting high-quality data than the original OpenAI CLIP\nmodel, and (3) designing better metrics or strategies universally applicable to\nany CLIP embedding without requiring specific model properties (e.g., CLIPScore\nis one popular metric). While the first two approaches have been extensively\nstudied, the third remains under-explored. In this paper, we advance the third\napproach by proposing two new methods. Firstly, instead of classical CLIP\nscores that only consider the alignment between two modalities from a single\nsample, we introduce negCLIPLoss, a CLIP loss-inspired method that adds the\nalignment between one sample and its contrastive pairs as an extra\nnormalization term for better quality measurement. Secondly, when downstream\ntasks are known, we propose a new norm-based metric, NormSim, to measure the\nsimilarity between pretraining data and target data. We test our methods on the\ndata selection benchmark, DataComp~\\cite{gadre2023datacomp}. Compared to the\nbest baseline using only OpenAI's CLIP-L/14, our methods achieve a 5.3\\%\nimprovement on ImageNet-1k and a 2.8\\% improvement on 38 downstream evaluation\ntasks. Moreover, both negCLIPLoss and NormSim are compatible with existing\ntechniques. By combining our methods with the current best methods\nDFN~\\cite{fang2023data} and HYPE~\\cite{kim2024hype}, we can boost average\nperformance on downstream tasks by 0.9\\%, achieving a new state-of-the-art.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Yiping Wang",
            "Yifang Chen",
            "Wendan Yan",
            "Alex Fang",
            "Wenjing Zhou",
            "Kevin Jamieson",
            "Simon Shaolei Du"
        ],
        "published": "2024-05-29T22:19:57Z"
    },
    {
        "title": "Convex Optimization of Initial Perturbations toward Quantitative Weather\n  Control",
        "link": "http://arxiv.org/abs/2405.19546v1",
        "abstract": "We propose a convex optimization approach to determine perturbations in the\ninitial conditions of a weather phenomenon as control inputs for quantitative\nweather control. We first construct a sensitivity matrix of outputs, such as\naccumulated precipitation, to the initial conditions, such as temperature and\nhumidity, through sensitivity analysis of a numerical weather prediction model.\nWe then solve a convex optimization problem to find optimal perturbations in\nthe initial conditions to realize the desired spatial distribution of the\ntargeting outputs. We implement the proposed method in a benchmark of a warm\nbubble experiment and show that it realizes desired spatial distributions of\naccumulated precipitation, such as a reference distribution and the reduced\nmaximum value.",
        "subjects": [
            "physics.ao-ph",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ],
        "authors": [
            "Toshiyuki Ohtsuka",
            "Atsushi Okazaki",
            "Masaki Ogura",
            "Shunji Kotsuki"
        ],
        "published": "2024-05-29T22:19:39Z"
    },
    {
        "title": "One-Shot Safety Alignment for Large Language Models via Optimal\n  Dualization",
        "link": "http://arxiv.org/abs/2405.19544v1",
        "abstract": "The growing safety concerns surrounding Large Language Models (LLMs) raise an\nurgent need to align them with diverse human preferences to simultaneously\nenhance their helpfulness and safety. A promising approach is to enforce safety\nconstraints through Reinforcement Learning from Human Feedback (RLHF). For such\nconstrained RLHF, common Lagrangian-based primal-dual policy optimization\nmethods are computationally expensive and often unstable. This paper presents a\ndualization perspective that reduces constrained alignment to an equivalent\nunconstrained alignment problem. We do so by pre-optimizing a smooth and convex\ndual function that has a closed form. This shortcut eliminates the need for\ncumbersome primal-dual policy iterations, thus greatly reducing the\ncomputational burden and improving training stability. Our strategy leads to\ntwo practical algorithms in model-based and preference-based scenarios (MoCAN\nand PeCAN, respectively). A broad range of experiments demonstrate the\neffectiveness of our methods.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "math.OC",
            "stat.ML"
        ],
        "authors": [
            "Xinmeng Huang",
            "Shuo Li",
            "Edgar Dobriban",
            "Osbert Bastani",
            "Hamed Hassani",
            "Dongsheng Ding"
        ],
        "published": "2024-05-29T22:12:52Z"
    },
    {
        "title": "Anatomical Region Recognition and Real-time Bone Tracking Methods by\n  Dynamically Decoding A-Mode Ultrasound Signals",
        "link": "http://arxiv.org/abs/2405.19542v1",
        "abstract": "Accurate bone tracking is crucial for kinematic analysis in orthopedic\nsurgery and prosthetic robotics. Traditional methods (e.g., skin markers) are\nsubject to soft tissue artifacts, and the bone pins used in surgery introduce\nthe risk of additional trauma and infection. For electromyography (EMG), its\ninability to directly measure joint angles requires complex algorithms for\nkinematic estimation. To address these issues, A-mode ultrasound-based tracking\nhas been proposed as a non-invasive and safe alternative. However, this\napproach suffers from limited accuracy in peak detection when processing\nreceived ultrasound signals. To build a precise and real-time bone tracking\napproach, this paper introduces a deep learning-based method for anatomical\nregion recognition and bone tracking using A-mode ultrasound signals,\nspecifically focused on the knee joint. The algorithm is capable of\nsimultaneously performing bone tracking and identifying the anatomical region\nwhere the A-mode ultrasound transducer is placed. It contains the fully\nconnection between all encoding and decoding layers of the cascaded U-Nets to\nfocus only on the signal region that is most likely to have the bone peak, thus\npinpointing the exact location of the peak and classifying the anatomical\nregion of the signal. The experiment showed a 97% accuracy in the\nclassification of the anatomical regions and a precision of around 0.5$\\pm$1mm\nunder dynamic tracking conditions for various anatomical areas surrounding the\nknee joint. In general, this approach shows great potential beyond the\ntraditional method, in terms of the accuracy achieved and the recognition of\nthe anatomical region where the ultrasound has been attached as an additional\nfunctionality.",
        "subjects": [
            "eess.SP",
            "cs.LG",
            "cs.RO"
        ],
        "authors": [
            "Bangyu Lan",
            "Stefano Stramigioli",
            "Kenan Niu"
        ],
        "published": "2024-05-29T22:04:40Z"
    },
    {
        "title": "Computing Low-Entropy Couplings for Large-Support Distributions",
        "link": "http://arxiv.org/abs/2405.19540v1",
        "abstract": "Minimum-entropy coupling (MEC) -- the process of finding a joint distribution\nwith minimum entropy for given marginals -- has applications in areas such as\ncausality and steganography. However, existing algorithms are either\ncomputationally intractable for large-support distributions or limited to\nspecific distribution types and sensitive to hyperparameter choices. This work\naddresses these limitations by unifying a prior family of iterative MEC (IMEC)\napproaches into a generalized partition-based formalism. From this framework,\nwe derive a novel IMEC algorithm called ARIMEC, capable of handling arbitrary\ndiscrete distributions, and introduce a method to make IMEC robust to\nsuboptimal hyperparameter settings. These innovations facilitate the\napplication of IMEC to high-throughput steganography with language models,\namong other settings. Our codebase is available at\nhttps://github.com/ssokota/mec .",
        "subjects": [
            "cs.IT",
            "cs.CR",
            "math.IT"
        ],
        "authors": [
            "Samuel Sokota",
            "Dylan Sam",
            "Christian Schroeder de Witt",
            "Spencer Compton",
            "Jakob Foerster",
            "J. Zico Kolter"
        ],
        "published": "2024-05-29T21:54:51Z"
    },
    {
        "title": "CheXpert Plus: Hundreds of Thousands of Aligned Radiology Texts, Images\n  and Patients",
        "link": "http://arxiv.org/abs/2405.19538v1",
        "abstract": "Since the release of the original CheXpert paper five years ago, CheXpert has\nbecome one of the most widely used and cited clinical AI datasets. The\nemergence of vision language models has sparked an increase in demands for\nsharing reports linked to CheXpert images, along with a growing interest among\nAI fairness researchers in obtaining demographic data. To address this,\nCheXpert Plus serves as a new collection of radiology data sources, made\npublicly available to enhance the scaling, performance, robustness, and\nfairness of models for all subsequent machine learning tasks in the field of\nradiology. CheXpert Plus is the largest text dataset publicly released in\nradiology, with a total of 36 million text tokens, including 13 million\nimpression tokens. To the best of our knowledge, it represents the largest text\nde-identification effort in radiology, with almost 1 million PHI spans\nanonymized. It is only the second time that a large-scale English paired\ndataset has been released in radiology, thereby enabling, for the first time,\ncross-institution training at scale. All reports are paired with high-quality\nimages in DICOM format, along with numerous image and patient metadata covering\nvarious clinical and socio-economic groups, as well as many pathology labels\nand RadGraph annotations. We hope this dataset will boost research for AI\nmodels that can further assist radiologists and help improve medical care. Data\nis available at the following URL:\nhttps://stanfordaimi.azurewebsites.net/datasets/5158c524-d3ab-4e02-96e9-6ee9efc110a1\nModels are available at the following URL:\nhttps://github.com/Stanford-AIMI/chexpert-plus",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Pierre Chambon",
            "Jean-Benoit Delbrouck",
            "Thomas Sounack",
            "Shih-Cheng Huang",
            "Zhihong Chen",
            "Maya Varma",
            "Steven QH Truong",
            "Chu The Chuong",
            "Curtis P. Langlotz"
        ],
        "published": "2024-05-29T21:48:56Z"
    },
    {
        "title": "Preference Learning Algorithms Do Not Learn Preference Rankings",
        "link": "http://arxiv.org/abs/2405.19534v1",
        "abstract": "Preference learning algorithms (e.g., RLHF and DPO) are frequently used to\nsteer LLMs to produce generations that are more preferred by humans, but our\nunderstanding of their inner workings is still limited. In this work, we study\nthe conventional wisdom that preference learning trains models to assign higher\nlikelihoods to more preferred outputs than less preferred outputs, measured via\n$\\textit{ranking accuracy}$. Surprisingly, we find that most state-of-the-art\npreference-tuned models achieve a ranking accuracy of less than 60% on common\npreference datasets. We furthermore derive the $\\textit{idealized ranking\naccuracy}$ that a preference-tuned LLM would achieve if it optimized the DPO or\nRLHF objective perfectly. We demonstrate that existing models exhibit a\nsignificant $\\textit{alignment gap}$ -- $\\textit{i.e.}$, a gap between the\nobserved and idealized ranking accuracies. We attribute this discrepancy to the\nDPO objective, which is empirically and theoretically ill-suited to fix even\nmild ranking errors in the reference model, and derive a simple and efficient\nformula for quantifying the difficulty of learning a given preference\ndatapoint. Finally, we demonstrate that ranking accuracy strongly correlates\nwith the empirically popular win rate metric when the model is close to the\nreference model used in the objective, shedding further light on the\ndifferences between on-policy (e.g., RLHF) and off-policy (e.g., DPO)\npreference learning algorithms.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Angelica Chen",
            "Sadhika Malladi",
            "Lily H. Zhang",
            "Xinyi Chen",
            "Qiuyi Zhang",
            "Rajesh Ranganath",
            "Kyunghyun Cho"
        ],
        "published": "2024-05-29T21:29:44Z"
    },
    {
        "title": "Contrasting Multiple Representations with the Multi-Marginal Matching\n  Gap",
        "link": "http://arxiv.org/abs/2405.19532v1",
        "abstract": "Learning meaningful representations of complex objects that can be seen\nthrough multiple ($k\\geq 3$) views or modalities is a core task in machine\nlearning. Existing methods use losses originally intended for paired views, and\nextend them to $k$ views, either by instantiating $\\tfrac12k(k-1)$ loss-pairs,\nor by using reduced embeddings, following a \\textit{one vs. average-of-rest}\nstrategy. We propose the multi-marginal matching gap (M3G), a loss that borrows\ntools from multi-marginal optimal transport (MM-OT) theory to simultaneously\nincorporate all $k$ views. Given a batch of $n$ points, each seen as a\n$k$-tuple of views subsequently transformed into $k$ embeddings, our loss\ncontrasts the cost of matching these $n$ ground-truth $k$-tuples with the MM-OT\npolymatching cost, which seeks $n$ optimally arranged $k$-tuples chosen within\nthese $n\\times k$ vectors. While the exponential complexity $O(n^k$) of the\nMM-OT problem may seem daunting, we show in experiments that a suitable\ngeneralization of the Sinkhorn algorithm for that problem can scale to, e.g.,\n$k=3\\sim 6$ views using mini-batches of size $64~\\sim128$. Our experiments\ndemonstrate improved performance over multiview extensions of pairwise losses,\nfor both self-supervised and multimodal tasks.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Zoe Piran",
            "Michal Klein",
            "James Thornton",
            "Marco Cuturi"
        ],
        "published": "2024-05-29T21:24:44Z"
    },
    {
        "title": "Real-Time Dynamic Robot-Assisted Hand-Object Interaction via Motion\n  Primitives",
        "link": "http://arxiv.org/abs/2405.19531v1",
        "abstract": "Advances in artificial intelligence (AI) have been propelling the evolution\nof human-robot interaction (HRI) technologies. However, significant challenges\nremain in achieving seamless interactions, particularly in tasks requiring\nphysical contact with humans. These challenges arise from the need for accurate\nreal-time perception of human actions, adaptive control algorithms for robots,\nand the effective coordination between human and robotic movements. In this\npaper, we propose an approach to enhancing physical HRI with a focus on dynamic\nrobot-assisted hand-object interaction (HOI). Our methodology integrates hand\npose estimation, adaptive robot control, and motion primitives to facilitate\nhuman-robot collaboration. Specifically, we employ a transformer-based\nalgorithm to perform real-time 3D modeling of human hands from single RGB\nimages, based on which a motion primitives model (MPM) is designed to translate\nhuman hand motions into robotic actions. The robot's action implementation is\ndynamically fine-tuned using the continuously updated 3D hand models.\nExperimental validations, including a ring-wearing task, demonstrate the\nsystem's effectiveness in adapting to real-time movements and assisting in\nprecise task executions.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "authors": [
            "Mingqi Yuan",
            "Huijiang Wang",
            "Kai-Fung Chu",
            "Fumiya Iida",
            "Bo Li",
            "Wenjun Zeng"
        ],
        "published": "2024-05-29T21:20:16Z"
    },
    {
        "title": "Predicting Long-Term Human Behaviors in Discrete Representations via\n  Physics-Guided Diffusion",
        "link": "http://arxiv.org/abs/2405.19528v1",
        "abstract": "Long-term human trajectory prediction is a challenging yet critical task in\nrobotics and autonomous systems. Prior work that studied how to predict\naccurate short-term human trajectories with only unimodal features often failed\nin long-term prediction. Reinforcement learning provides a good solution for\nlearning human long-term behaviors but can suffer from challenges in data\nefficiency and optimization. In this work, we propose a long-term human\ntrajectory forecasting framework that leverages a guided diffusion model to\ngenerate diverse long-term human behaviors in a high-level latent action space,\nobtained via a hierarchical action quantization scheme using a VQ-VAE to\ndiscretize continuous trajectories and the available context. The latent\nactions are predicted by our guided diffusion model, which uses\nphysics-inspired guidance at test time to constrain generated multimodal action\ndistributions. Specifically, we use reachability analysis during the reverse\ndenoising process to guide the diffusion steps toward physically feasible\nlatent actions. We evaluate our framework on two publicly available human\ntrajectory forecasting datasets: SFU-Store-Nav and JRDB, and extensive\nexperimental results show that our framework achieves superior performance in\nlong-term human trajectory forecasting.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Zhitian Zhang",
            "Anjian Li",
            "Angelica Lim",
            "Mo Chen"
        ],
        "published": "2024-05-29T21:13:07Z"
    },
    {
        "title": "Flexible Agent-based Modeling Framework to Evaluate Integrated\n  Microtransit and Fixed-route Transit Designs: Mode Choice, Supernetworks, and\n  Fleet Simulation",
        "link": "http://arxiv.org/abs/2405.19527v1",
        "abstract": "The integration of traditional fixed-route transit (FRT) and more flexible\nmicrotransit has been touted as a means of improving mobility and access to\nopportunity, increasing transit ridership, and promoting environmental\nsustainability. To help evaluate integrated FRT and microtransit public transit\n(PT) system (henceforth ``integrated fixed-flex PT system'') designs, we\npropose a high-fidelity modeling framework that provides reliable estimates for\na wide range of (i) performance metrics and (ii) integrated fixed-flex PT\nsystem designs. We formulate the mode choice equilibrium problem as a\nfixed-point problem wherein microtransit demand is a function of microtransit\nperformance, and microtransit performance depends on microtransit demand. We\npropose a detailed agent-based simulation modeling framework that includes (i)\na binary logit mode choice model (private auto vs. transit), (ii) a\nsupernetwork-based model and pathfinding algorithm for multi-modal transit path\nchoice where the supernetwork includes pedestrian, FRT, and microtransit\nlayers, (iii) a detailed mobility-on-demand fleet simulator called FleetPy to\nmodel the supply-demand dynamics of the microtransit service. In this paper, we\nillustrate the capabilities of the modeling framework by analyzing integrated\nfixed-flex PT system designs that vary the following design parameters: FRT\nfrequencies and microtransit fleet size, service region structure, virtual stop\ncoverage, and operating hours. We include case studies in downtown San Diego\nand Lemon Grove, California. The computational results show that the proposed\nmodeling framework converges to a mode choice equilibrium. Moreover, the\nscenario results imply that introducing a new microtransit service decreases\nFRT ridership and requires additional subsidies, but it significantly increases\njob accessibility and slightly reduces total VMT.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Siwei Hu",
            "Michael F. Hyland",
            "Ritun Saha",
            "Jacob J. Berkel",
            "Geoffrey Vander Veen"
        ],
        "published": "2024-05-29T21:10:51Z"
    },
    {
        "title": "Lifelong Learning Using a Dynamically Growing Tree of Sub-networks for\n  Domain Generalization in Video Object Segmentation",
        "link": "http://arxiv.org/abs/2405.19525v1",
        "abstract": "Current state-of-the-art video object segmentation models have achieved great\nsuccess using supervised learning with massive labeled training datasets.\nHowever, these models are trained using a single source domain and evaluated\nusing videos sampled from the same source domain. When these models are\nevaluated using videos sampled from a different target domain, their\nperformance degrades significantly due to poor domain generalization, i.e.,\ntheir inability to learn from multi-domain sources simultaneously using\ntraditional supervised learning. In this paper, We propose a dynamically\ngrowing tree of sub-networks (DGT) to learn effectively from multi-domain\nsources. DGT uses a novel lifelong learning technique that allows the model to\ncontinuously and effectively learn from new domains without forgetting the\npreviously learned domains. Hence, the model can generalize to out-of-domain\nvideos. The proposed work is evaluated using single-source in-domain\n(traditional video object segmentation), multi-source in-domain, and\nmulti-source out-of-domain video object segmentation. The results of DGT show a\nsingle source in-domain performance gain of 0.2% and 3.5% on the DAVIS16 and\nDAVIS17 datasets, respectively. However, when DGT is evaluated using in-domain\nmulti-sources, the results show superior performance compared to\nstate-of-the-art video object segmentation and other lifelong learning\ntechniques with an average performance increase in the F-score of 6.9% with\nminimal catastrophic forgetting. Finally, in the out-of-domain experiment, the\nperformance of DGT is 2.7% and 4% better than state-of-the-art in 1 and\n5-shots, respectively.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Islam Osman",
            "Mohamed S. Shehata"
        ],
        "published": "2024-05-29T21:01:27Z"
    },
    {
        "title": "AI Risk Management Should Incorporate Both Safety and Security",
        "link": "http://arxiv.org/abs/2405.19524v1",
        "abstract": "The exposure of security vulnerabilities in safety-aligned language models,\ne.g., susceptibility to adversarial attacks, has shed light on the intricate\ninterplay between AI safety and AI security. Although the two disciplines now\ncome together under the overarching goal of AI risk management, they have\nhistorically evolved separately, giving rise to differing perspectives.\nTherefore, in this paper, we advocate that stakeholders in AI risk management\nshould be aware of the nuances, synergies, and interplay between safety and\nsecurity, and unambiguously take into account the perspectives of both\ndisciplines in order to devise mostly effective and holistic risk mitigation\napproaches. Unfortunately, this vision is often obfuscated, as the definitions\nof the basic concepts of \"safety\" and \"security\" themselves are often\ninconsistent and lack consensus across communities. With AI risk management\nbeing increasingly cross-disciplinary, this issue is particularly salient. In\nlight of this conceptual challenge, we introduce a unified reference framework\nto clarify the differences and interplay between AI safety and AI security,\naiming to facilitate a shared understanding and effective collaboration across\ncommunities.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "authors": [
            "Xiangyu Qi",
            "Yangsibo Huang",
            "Yi Zeng",
            "Edoardo Debenedetti",
            "Jonas Geiping",
            "Luxi He",
            "Kaixuan Huang",
            "Udari Madhushani",
            "Vikash Sehwag",
            "Weijia Shi",
            "Boyi Wei",
            "Tinghao Xie",
            "Danqi Chen",
            "Pin-Yu Chen",
            "Jeffrey Ding",
            "Ruoxi Jia",
            "Jiaqi Ma",
            "Arvind Narayanan",
            "Weijie J Su",
            "Mengdi Wang",
            "Chaowei Xiao",
            "Bo Li",
            "Dawn Song",
            "Peter Henderson",
            "Prateek Mittal"
        ],
        "published": "2024-05-29T21:00:47Z"
    },
    {
        "title": "Artificial Intelligence Index Report 2024",
        "link": "http://arxiv.org/abs/2405.19522v1",
        "abstract": "The 2024 Index is our most comprehensive to date and arrives at an important\nmoment when AI's influence on society has never been more pronounced. This\nyear, we have broadened our scope to more extensively cover essential trends\nsuch as technical advancements in AI, public perceptions of the technology, and\nthe geopolitical dynamics surrounding its development. Featuring more original\ndata than ever before, this edition introduces new estimates on AI training\ncosts, detailed analyses of the responsible AI landscape, and an entirely new\nchapter dedicated to AI's impact on science and medicine. The AI Index report\ntracks, collates, distills, and visualizes data related to artificial\nintelligence (AI). Our mission is to provide unbiased, rigorously vetted,\nbroadly sourced data in order for policymakers, researchers, executives,\njournalists, and the general public to develop a more thorough and nuanced\nunderstanding of the complex field of AI. The AI Index is recognized globally\nas one of the most credible and authoritative sources for data and insights on\nartificial intelligence. Previous editions have been cited in major newspapers,\nincluding the The New York Times, Bloomberg, and The Guardian, have amassed\nhundreds of academic citations, and been referenced by high-level policymakers\nin the United States, the United Kingdom, and the European Union, among other\nplaces. This year's edition surpasses all previous ones in size, scale, and\nscope, reflecting the growing significance that AI is coming to hold in all of\nour lives.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Nestor Maslej",
            "Loredana Fattorini",
            "Raymond Perrault",
            "Vanessa Parli",
            "Anka Reuel",
            "Erik Brynjolfsson",
            "John Etchemendy",
            "Katrina Ligett",
            "Terah Lyons",
            "James Manyika",
            "Juan Carlos Niebles",
            "Yoav Shoham",
            "Russell Wald",
            "Jack Clark"
        ],
        "published": "2024-05-29T20:59:57Z"
    },
    {
        "title": "Crowdsourcing with Difficulty: A Bayesian Rating Model for Heterogeneous\n  Items",
        "link": "http://arxiv.org/abs/2405.19521v1",
        "abstract": "In applied statistics and machine learning, the \"gold standards\" used for\ntraining are often biased and almost always noisy. Dawid and Skene's\njustifiably popular crowdsourcing model adjusts for rater (coder, annotator)\nsensitivity and specificity, but fails to capture distributional properties of\nrating data gathered for training, which in turn biases training. In this\nstudy, we introduce a general purpose measurement-error model with which we can\ninfer consensus categories by adding item-level effects for difficulty,\ndiscriminativeness, and guessability. We further show how to constrain the\nbimodal posterior of these models to avoid (or if necessary, allow) adversarial\nraters. We validate our model's goodness of fit with posterior predictive\nchecks, the Bayesian analogue of $\\chi^2$ tests. Dawid and Skene's model is\nrejected by goodness of fit tests, whereas our new model, which adjusts for\nitem heterogeneity, is not rejected. We illustrate our new model with two\nwell-studied data sets, binary rating data for caries in dental X-rays and\nimplication in natural language.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Seong Woo Han",
            "Ozan Adgzel",
            "Bob Carpenter"
        ],
        "published": "2024-05-29T20:59:28Z"
    },
    {
        "title": "Two-layer retrieval augmented generation framework for low-resource\n  medical question-answering: proof of concept using Reddit data",
        "link": "http://arxiv.org/abs/2405.19519v1",
        "abstract": "Retrieval augmented generation (RAG) provides the capability to constrain\ngenerative model outputs, and mitigate the possibility of hallucination, by\nproviding relevant in-context text. The number of tokens a generative large\nlanguage model (LLM) can incorporate as context is finite, thus limiting the\nvolume of knowledge from which to generate an answer. We propose a two-layer\nRAG framework for query-focused answer generation and evaluate a\nproof-of-concept for this framework in the context of query-focused summary\ngeneration from social media forums, focusing on emerging drug-related\ninformation. The evaluations demonstrate the effectiveness of the two-layer\nframework in resource constrained settings to enable researchers in obtaining\nnear real-time data from users.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Sudeshna Das",
            "Yao Ge",
            "Yuting Guo",
            "Swati Rajwal",
            "JaMor Hairston",
            "Jeanne Powell",
            "Drew Walker",
            "Snigdha Peddireddy",
            "Sahithi Lakamana",
            "Selen Bozkurt",
            "Matthew Reyna",
            "Reza Sameni",
            "Yunyu Xiao",
            "Sangmi Kim",
            "Rasheeta Chandler",
            "Natalie Hernandez",
            "Danielle Mowery",
            "Rachel Wightman",
            "Jennifer Love",
            "Anthony Spadaro",
            "Jeanmarie Perrone",
            "Abeed Sarker"
        ],
        "published": "2024-05-29T20:56:52Z"
    },
    {
        "title": "Exploring the Potential of Hybrid Machine-Learning/Physics-Based\n  Modeling for Atmospheric/Oceanic Prediction Beyond the Medium Range",
        "link": "http://arxiv.org/abs/2405.19518v1",
        "abstract": "This paper explores the potential of a hybrid modeling approach that combines\nmachine learning (ML) with conventional physics-based modeling for weather\nprediction beyond the medium range. It extends the work of Arcomano et al.\n(2022), which tested the approach for short- and medium-range weather\nprediction, and the work of Arcomano et al. (2023), which investigated its\npotential for climate modeling. The hybrid model used for the forecast\nexperiments of the paper is based on the low-resolution, simplified\nparameterization atmospheric general circulation model (AGCM) SPEEDY. In\naddition to the hybridized prognostic variables of SPEEDY, the current version\nof the model has three purely ML-based prognostic variables. One of these is\n6~h cumulative precipitation, another is the sea surface temperature, while the\nthird is the heat content of the top 300 m deep layer of the ocean. The model\nhas skill in predicting the El Ni\\~no cycle and its global teleconnections with\nprecipitation for 3-7 months depending on the season. The model captures\nequatorial variability of the precipitation associated with Kelvin and Rossby\nwaves and MJO. Predictions of the precipitation in the equatorial region have\nskill for 15 days in the East Pacific and 11.5 days in the West Pacific. Though\nthe model has low spatial resolution, for these tasks it has prediction skill\ncomparable to what has been published for high-resolution, purely\nphysics-based, conventional operational forecast models.",
        "subjects": [
            "physics.ao-ph",
            "cs.LG",
            "nlin.CD"
        ],
        "authors": [
            "Dhruvit Patel",
            "Troy Arcomano",
            "Brian Hunt",
            "Istvan Szunyogh",
            "Edward Ott"
        ],
        "published": "2024-05-29T20:56:44Z"
    },
    {
        "title": "Enabling Visual Recognition at Radio Frequency",
        "link": "http://arxiv.org/abs/2405.19516v1",
        "abstract": "This paper introduces PanoRadar, a novel RF imaging system that brings RF\nresolution close to that of LiDAR, while providing resilience against\nconditions challenging for optical signals. Our LiDAR-comparable 3D imaging\nresults enable, for the first time, a variety of visual recognition tasks at\nradio frequency, including surface normal estimation, semantic segmentation,\nand object detection. PanoRadar utilizes a rotating single-chip mmWave radar,\nalong with a combination of novel signal processing and machine learning\nalgorithms, to create high-resolution 3D images of the surroundings. Our system\naccurately estimates robot motion, allowing for coherent imaging through a\ndense grid of synthetic antennas. It also exploits the high azimuth resolution\nto enhance elevation resolution using learning-based methods. Furthermore,\nPanoRadar tackles 3D learning via 2D convolutions and addresses challenges due\nto the unique characteristics of RF signals. Our results demonstrate\nPanoRadar's robust performance across 12 buildings.",
        "subjects": [
            "eess.SP",
            "cs.CV",
            "cs.LG",
            "cs.RO"
        ],
        "authors": [
            "Haowen Lai",
            "Gaoxiang Luo",
            "Yifei Liu",
            "Mingmin Zhao"
        ],
        "published": "2024-05-29T20:52:59Z"
    },
    {
        "title": "Wavefront Threading Enables Effective High-Level Synthesis",
        "link": "http://dx.doi.org/10.1145/3656420",
        "abstract": "Digital systems are growing in importance and computing hardware is growing\nmore heterogeneous. Hardware design, however, remains laborious and expensive,\nin part due to the limitations of conventional hardware description languages\n(HDLs) like VHDL and Verilog. A longstanding research goal has been programming\nhardware like software, with high-level languages that can generate efficient\nhardware designs. This paper describes Kanagawa, a language that takes a new\napproach to combine the programmer productivity benefits of traditional\nHigh-Level Synthesis (HLS) approaches with the expressibility and hardware\nefficiency of Register-Transfer Level (RTL) design. The language's concise\nsyntax, matched with a hardware design-friendly execution model, permits a\nrelatively simple toolchain to map high-level code into efficient hardware\nimplementations.",
        "subjects": [
            "cs.PL"
        ],
        "authors": [
            "Blake Pelton",
            "Adam Sapek",
            "Ken Eguro",
            "Daniel Lo",
            "Alessandro Forin",
            "Matt Humphrey",
            "Jinwen Xi",
            "David Cox",
            "Rajas Karandikar",
            "Johannes de Fine Licht",
            "Evgeny Babin",
            "Adrian Caulfield",
            "Doug Burger"
        ],
        "published": "2024-05-29T20:52:38Z"
    },
    {
        "title": "Decentralized Optimization in Time-Varying Networks with Arbitrary\n  Delays",
        "link": "http://arxiv.org/abs/2405.19513v1",
        "abstract": "We consider a decentralized optimization problem for networks affected by\ncommunication delays. Examples of such networks include collaborative machine\nlearning, sensor networks, and multi-agent systems. To mimic communication\ndelays, we add virtual non-computing nodes to the network, resulting in\ndirected graphs. This motivates investigating decentralized optimization\nsolutions on directed graphs. Existing solutions assume nodes know their\nout-degrees, resulting in limited applicability. To overcome this limitation,\nwe introduce a novel gossip-based algorithm, called DT-GO, that does not need\nto know the out-degrees. The algorithm is applicable in general directed\nnetworks, for example networks with delays or limited acknowledgment\ncapabilities. We derive convergence rates for both convex and non-convex\nobjectives, showing that our algorithm achieves the same complexity order as\ncentralized Stochastic Gradient Descent. In other words, the effects of the\ngraph topology and delays are confined to higher-order terms. Additionally, we\nextend our analysis to accommodate time-varying network topologies. Numerical\nsimulations are provided to support our theoretical findings.",
        "subjects": [
            "cs.LG",
            "cs.DC",
            "cs.SY",
            "eess.SY",
            "math.OC",
            "stat.ML",
            "68W10, 68W15, 68W40, 90C06, 90C35, 90C25",
            "G.1.6; F.2.1; E.4"
        ],
        "authors": [
            "Tomas Ortega",
            "Hamid Jafarkhani"
        ],
        "published": "2024-05-29T20:51:38Z"
    },
    {
        "title": "Leveraging partial stragglers within gradient coding",
        "link": "http://arxiv.org/abs/2405.19509v1",
        "abstract": "Within distributed learning, workers typically compute gradients on their\nassigned dataset chunks and send them to the parameter server (PS), which\naggregates them to compute either an exact or approximate version of $\\nabla L$\n(gradient of the loss function $L$). However, in large-scale clusters, many\nworkers are slower than their promised speed or even failure-prone. A gradient\ncoding solution introduces redundancy within the assignment of chunks to the\nworkers and uses coding theoretic ideas to allow the PS to recover $\\nabla L$\n(exactly or approximately), even in the presence of stragglers. Unfortunately,\nmost existing gradient coding protocols are inefficient from a computation\nperspective as they coarsely classify workers as operational or failed; the\npotentially valuable work performed by slow workers (partial stragglers) is\nignored. In this work, we present novel gradient coding protocols that\njudiciously leverage the work performed by partial stragglers. Our protocols\nare efficient from a computation and communication perspective and numerically\nstable. For an important class of chunk assignments, we present efficient\nalgorithms for optimizing the relative ordering of chunks within the workers;\nthis ordering affects the overall execution time. For exact gradient\nreconstruction, our protocol is around $2\\times$ faster than the original class\nof protocols and for approximate gradient reconstruction, the\nmean-squared-error of our reconstructed gradient is several orders of magnitude\nbetter.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Aditya Ramamoorthy",
            "Ruoyu Meng",
            "Vrinda S. Girimaji"
        ],
        "published": "2024-05-29T20:45:57Z"
    },
    {
        "title": "Data-Efficient Discovery of Hyperelastic TPMS Metamaterials with Extreme\n  Energy Dissipation",
        "link": "http://arxiv.org/abs/2405.19507v1",
        "abstract": "Triply periodic minimal surfaces (TPMS) are a class of metamaterials with a\nvariety of applications and well-known primitives. We present a new method for\ndiscovering novel microscale TPMS structures with exceptional\nenergy-dissipation capabilities, achieving double the energy absorption of the\nbest existing TPMS primitive structure. Our approach employs a parametric\nrepresentation, allowing seamless interpolation between structures and\nrepresenting a rich TPMS design space. We show that simulations are intractable\nfor optimizing microscale hyperelastic structures, and instead propose a\nsample-efficient computational strategy for rapidly discovering structures with\nextreme energy dissipation using limited amounts of empirical data from\n3D-printed and tested microscale metamaterials. This strategy ensures\nhigh-fidelity results but involves time-consuming 3D printing and testing. To\naddress this, we leverage an uncertainty-aware Deep Ensembles model to predict\nmicrostructure behaviors and identify which structures to 3D-print and test\nnext. We iteratively refine our model through batch Bayesian optimization,\nselecting structures for fabrication that maximize exploration of the\nperformance space and exploitation of our energy-dissipation objective. Using\nour method, we produce the first open-source dataset of hyperelastic microscale\nTPMS structures, including a set of novel structures that demonstrate extreme\nenergy dissipation capabilities. We show several potential applications of\nthese structures in protective equipment and bone implants.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Maxine Perroni-Scharf",
            "Zachary Ferguson",
            "Thomas Butrille",
            "Carlos Portela",
            "Mina Konakovi Lukovi"
        ],
        "published": "2024-05-29T20:43:25Z"
    },
    {
        "title": "MUVERA: Multi-Vector Retrieval via Fixed Dimensional Encodings",
        "link": "http://arxiv.org/abs/2405.19504v1",
        "abstract": "Neural embedding models have become a fundamental component of modern\ninformation retrieval (IR) pipelines. These models produce a single embedding\n$x \\in \\mathbb{R}^d$ per data-point, allowing for fast retrieval via highly\noptimized maximum inner product search (MIPS) algorithms. Recently, beginning\nwith the landmark ColBERT paper, multi-vector models, which produce a set of\nembedding per data point, have achieved markedly superior performance for IR\ntasks. Unfortunately, using these models for IR is computationally expensive\ndue to the increased complexity of multi-vector retrieval and scoring.\n  In this paper, we introduce MUVERA (MUlti-VEctor Retrieval Algorithm), a\nretrieval mechanism which reduces multi-vector similarity search to\nsingle-vector similarity search. This enables the usage of off-the-shelf MIPS\nsolvers for multi-vector retrieval. MUVERA asymmetrically generates Fixed\nDimensional Encodings (FDEs) of queries and documents, which are vectors whose\ninner product approximates multi-vector similarity. We prove that FDEs give\nhigh-quality $\\epsilon$-approximations, thus providing the first single-vector\nproxy for multi-vector similarity with theoretical guarantees. Empirically, we\nfind that FDEs achieve the same recall as prior state-of-the-art heuristics\nwhile retrieving 2-5$\\times$ fewer candidates. Compared to prior state of the\nart implementations, MUVERA achieves consistently good end-to-end recall and\nlatency across a diverse set of the BEIR retrieval datasets, achieving an\naverage of 10$\\%$ improved recall with $90\\%$ lower latency.",
        "subjects": [
            "cs.DS",
            "cs.DB",
            "cs.IR"
        ],
        "authors": [
            "Laxman Dhulipala",
            "Majid Hadian",
            "Rajesh Jayaram",
            "Jason Lee",
            "Vahab Mirrokni"
        ],
        "published": "2024-05-29T20:40:20Z"
    },
    {
        "title": "MDS-ViTNet: Improving saliency prediction for Eye-Tracking with Vision\n  Transformer",
        "link": "http://arxiv.org/abs/2405.19501v1",
        "abstract": "In this paper, we present a novel methodology we call MDS-ViTNet (Multi\nDecoder Saliency by Vision Transformer Network) for enhancing visual saliency\nprediction or eye-tracking. This approach holds significant potential for\ndiverse fields, including marketing, medicine, robotics, and retail. We propose\na network architecture that leverages the Vision Transformer, moving beyond the\nconventional ImageNet backbone. The framework adopts an encoder-decoder\nstructure, with the encoder utilizing a Swin transformer to efficiently embed\nmost important features. This process involves a Transfer Learning method,\nwherein layers from the Vision Transformer are converted by the Encoder\nTransformer and seamlessly integrated into a CNN Decoder. This methodology\nensures minimal information loss from the original input image. The decoder\nemploys a multi-decoding technique, utilizing dual decoders to generate two\ndistinct attention maps. These maps are subsequently combined into a singular\noutput via an additional CNN model. Our trained model MDS-ViTNet achieves\nstate-of-the-art results across several benchmarks. Committed to fostering\nfurther collaboration, we intend to make our code, models, and datasets\naccessible to the public.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Polezhaev Ignat",
            "Goncharenko Igor",
            "Iurina Natalya"
        ],
        "published": "2024-05-29T20:28:04Z"
    },
    {
        "title": "The Numerical Solution of the External Dirichlet Generalized Harmonic\n  Problem for a Sphere by the Method of Probabilistic Solution",
        "link": "http://dx.doi.org/10.3390/math11030539",
        "abstract": "In the present paper, an algorithm for the numerical solution of the external\nDirichlet generalized harmonic problem for a sphere by the method of\nprobabilistic solution (MPS) is given, where generalized indicates that a\nboundary function has a finite number of first kind discontinuity curves. The\nalgorithm consists of the following main stages: (1) the transition from an\ninfinite domain to a finite domain by an inversion; (2) the consideration of a\nnew Dirichlet generalized harmonic problem on the basis of Kelvin theorem for\nthe obtained finite domain; (3) the numerical solution of the new problem for\nthe finite domain by the MPS, which in turn is based on a computer simulation\nof the Weiner process; (4) finding the probabilistic solution of the posed\ngeneralized problem at any fixed points of the infinite domain by the solution\nof the new problem. For illustration, numerical examples are considered and\nresults are presented.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "35J05, 35J25, 65C30, 65N75"
        ],
        "authors": [
            "Mamuli Zakradze",
            "Zaza Tabagari",
            "Nana Koblishvili",
            "Tinatin Davitashvili",
            "Jose Maria Sanchez",
            "Francisco Criado-Aldeanueva"
        ],
        "published": "2024-05-29T20:27:42Z"
    },
    {
        "title": "Momentum for the Win: Collaborative Federated Reinforcement Learning\n  across Heterogeneous Environments",
        "link": "http://arxiv.org/abs/2405.19499v1",
        "abstract": "We explore a Federated Reinforcement Learning (FRL) problem where $N$ agents\ncollaboratively learn a common policy without sharing their trajectory data. To\ndate, existing FRL work has primarily focused on agents operating in the same\nor ``similar\" environments. In contrast, our problem setup allows for\narbitrarily large levels of environment heterogeneity. To obtain the optimal\npolicy which maximizes the average performance across all potentially\ncompletely different environments, we propose two algorithms: FedSVRPG-M and\nFedHAPG-M. In contrast to existing results, we demonstrate that both FedSVRPG-M\nand FedHAPG-M, both of which leverage momentum mechanisms, can exactly converge\nto a stationary point of the average performance function, regardless of the\nmagnitude of environment heterogeneity. Furthermore, by incorporating the\nbenefits of variance-reduction techniques or Hessian approximation, both\nalgorithms achieve state-of-the-art convergence results, characterized by a\nsample complexity of $\\mathcal{O}\\left(\\epsilon^{-\\frac{3}{2}}/N\\right)$.\nNotably, our algorithms enjoy linear convergence speedups with respect to the\nnumber of agents, highlighting the benefit of collaboration among agents in\nfinding a common policy.",
        "subjects": [
            "cs.LG",
            "cs.MA"
        ],
        "authors": [
            "Han Wang",
            "Sihong He",
            "Zhili Zhang",
            "Fei Miao",
            "James Anderson"
        ],
        "published": "2024-05-29T20:24:42Z"
    },
    {
        "title": "Machine Psychology: Integrating Operant Conditioning with the\n  Non-Axiomatic Reasoning System for Advancing Artificial General Intelligence\n  Research",
        "link": "http://arxiv.org/abs/2405.19498v1",
        "abstract": "This paper introduces an interdisciplinary framework called Machine\nPsychology, which merges principles from operant learning psychology with a\nspecific Artificial Intelligence model, the Non-Axiomatic Reasoning System\n(NARS), to enhance Artificial General Intelligence (AGI) research. The core\npremise of this framework is that adaptation is crucial to both biological and\nartificial intelligence and can be understood through operant conditioning\nprinciples. The study assesses this approach via three operant learning tasks\nusing OpenNARS for Applications (ONA): simple discrimination, changing\ncontingencies, and conditional discrimination tasks.\n  In the simple discrimination task, NARS demonstrated rapid learning,\nachieving perfect accuracy during both training and testing phases. The\nchanging contingencies task showcased NARS's adaptability, as it successfully\nadjusted its behavior when task conditions were reversed. In the conditional\ndiscrimination task, NARS handled complex learning scenarios effectively,\nachieving high accuracy by forming and utilizing intricate hypotheses based on\nconditional cues.\n  These findings support the application of operant conditioning as a framework\nfor creating adaptive AGI systems. NARS's ability to operate under conditions\nof insufficient knowledge and resources, coupled with its sensorimotor\nreasoning capabilities, establishes it as a robust model for AGI. The Machine\nPsychology framework, by incorporating elements of natural intelligence such as\ncontinuous learning and goal-driven behavior, offers a scalable and flexible\napproach for real-world applications. Future research should investigate using\nenhanced NARS systems, more advanced tasks, and applying this framework to\ndiverse, complex challenges to further progress the development of human-level\nAI.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Robert Johansson"
        ],
        "published": "2024-05-29T20:23:57Z"
    },
    {
        "title": "Gaussian Flow Bridges for Audio Domain Transfer with Unpaired Data",
        "link": "http://arxiv.org/abs/2405.19497v1",
        "abstract": "Audio domain transfer is the process of modifying audio signals to match\ncharacteristics of a different domain, while retaining the original content.\nThis paper investigates the potential of Gaussian Flow Bridges, an emerging\napproach in generative modeling, for this problem. The presented framework\naddresses the transport problem across different distributions of audio signals\nthrough the implementation of a series of two deterministic probability flows.\nThe proposed framework facilitates manipulation of the target distribution\nproperties through a continuous control variable, which defines a certain\naspect of the target domain. Notably, this approach does not rely on paired\nexamples for training. To address identified challenges on maintaining the\nspeech content consistent, we recommend a training strategy that incorporates\nchunk-based minibatch Optimal Transport couplings of data samples and noise.\nComparing our unsupervised method with established baselines, we find\ncompetitive performance in tasks of reverberation and distortion manipulation.\nDespite encoutering limitations, the intriguing results obtained in this study\nunderscore potential for further exploration.",
        "subjects": [
            "eess.AS",
            "cs.LG",
            "cs.SD"
        ],
        "authors": [
            "Eloi Moliner",
            "Sebastian Braun",
            "Hannes Gamper"
        ],
        "published": "2024-05-29T20:23:01Z"
    },
    {
        "title": "Qiskit Code Assistant: Training LLMs for generating Quantum Computing\n  Code",
        "link": "http://arxiv.org/abs/2405.19495v1",
        "abstract": "Code Large Language Models (Code LLMs) have emerged as powerful tools,\nrevolutionizing the software development landscape by automating the coding\nprocess and reducing time and effort required to build applications. This paper\nfocuses on training Code LLMs to specialize in the field of quantum computing.\nWe begin by discussing the unique needs of quantum computing programming, which\ndiffer significantly from classical programming approaches or languages. A Code\nLLM specializing in quantum computing requires a foundational understanding of\nquantum computing and quantum information theory. However, the scarcity of\navailable quantum code examples and the rapidly evolving field, which\nnecessitates continuous dataset updates, present significant challenges.\nMoreover, we discuss our work on training Code LLMs to produce high-quality\nquantum code using the Qiskit library. This work includes an examination of the\nvarious aspects of the LLMs used for training and the specific training\nconditions, as well as the results obtained with our current models. To\nevaluate our models, we have developed a custom benchmark, similar to\nHumanEval, which includes a set of tests specifically designed for the field of\nquantum computing programming using Qiskit. Our findings indicate that our\nmodel outperforms existing state-of-the-art models in quantum computing tasks.\nWe also provide examples of code suggestions, comparing our model to other\nrelevant code LLMs. Finally, we introduce a discussion on the potential\nbenefits of Code LLMs for quantum computing computational scientists,\nresearchers, and practitioners. We also explore various features and future\nwork that could be relevant in this context.",
        "subjects": [
            "quant-ph",
            "cs.AI"
        ],
        "authors": [
            "Nicolas Dupuis",
            "Luca Buratti",
            "Sanjay Vishwakarma",
            "Aitana Viudes Forrat",
            "David Kremer",
            "Ismael Faro",
            "Ruchir Puri",
            "Juan Cruz-Benito"
        ],
        "published": "2024-05-29T20:21:00Z"
    },
    {
        "title": "Fast Gaussian Distributed Pseudorandom Number Generation in Java via the\n  Ziggurat Algorithm",
        "link": "http://arxiv.org/abs/2405.19493v1",
        "abstract": "We report on experiments with the ziggurat algorithm for generating Gaussian\ndistributed random numbers. The study utilizes our open source Java\nimplementation that was introduced originally for Java 11 at a time when the\nJava API only provided the much slower polar method. Our Java implementation of\nthe ziggurat algorithm is a port of the GNU Scientific Library's C\nimplementation. Java 17 introduced a significant overhaul of pseudorandom\nnumber generation, including several modern pseudorandom number generators\n(PRNGs) as well as additional functionality, among which includes switching\nfrom the polar method to a modified ziggurat algorithm. In the experiments of\nthis paper, we explore whether there is still a need for our implementation for\nJava 17+ applications. Our results show that Java 17's modified ziggurat is\nfaster than our implementation for the PRNGs that support it. However, Java 17+\ncontinues to use the polar method for the legacy PRNGs Random, SecureRandom,\nand ThreadLocalRandom. The linear congruential method of Java's Random class\nlacks the statistical properties required by Java's modified ziggurat\nimplementation; and SecureRandom and ThreadLocalRandom unfortunately use the\npolar method as a side-effect of extending Random. Our implementation of the\noriginal ziggurat algorithm does not require the same statistical properties of\nthe underlying PRNG as Java 17's optimized version, and can be used with any of\nthese PRNGs, and is especially relevant where pre-Java 17 support is required.",
        "subjects": [
            "cs.DS",
            "cs.DM",
            "math.PR",
            "68Q87, 68W20, 60-04, 60G15, 65C10",
            "F.2.1; I.1.2; D.2.13; G.3; G.4"
        ],
        "authors": [
            "Vincent A. Cicirello"
        ],
        "published": "2024-05-29T20:16:16Z"
    },
    {
        "title": "TotalSegmentator MRI: Sequence-Independent Segmentation of 59 Anatomical\n  Structures in MR images",
        "link": "http://arxiv.org/abs/2405.19492v1",
        "abstract": "Purpose: To develop an open-source and easy-to-use segmentation model that\ncan automatically and robustly segment most major anatomical structures in MR\nimages independently of the MR sequence.\n  Materials and Methods: In this study we extended the capabilities of\nTotalSegmentator to MR images. 298 MR scans and 227 CT scans were used to\nsegment 59 anatomical structures (20 organs, 18 bones, 11 muscles, 7 vessels, 3\ntissue types) relevant for use cases such as organ volumetry, disease\ncharacterization, and surgical planning. The MR and CT images were randomly\nsampled from routine clinical studies and thus represent a real-world dataset\n(different ages, pathologies, scanners, body parts, sequences, contrasts, echo\ntimes, repetition times, field strengths, slice thicknesses and sites). We\ntrained an nnU-Net segmentation algorithm on this dataset and calculated Dice\nsimilarity coefficients (Dice) to evaluate the model's performance.\n  Results: The model showed a Dice score of 0.824 (CI: 0.801, 0.842) on the\ntest set, which included a wide range of clinical data with major pathologies.\nThe model significantly outperformed two other publicly available segmentation\nmodels (Dice score, 0.824 versus 0.762; p<0.001 and 0.762 versus 0.542;\np<0.001). On the CT image test set of the original TotalSegmentator paper it\nalmost matches the performance of the original TotalSegmentator (Dice score,\n0.960 versus 0.970; p<0.001).\n  Conclusion: Our proposed model extends the capabilities of TotalSegmentator\nto MR images. The annotated dataset\n(https://zenodo.org/doi/10.5281/zenodo.11367004) and open-source toolkit\n(https://www.github.com/wasserth/TotalSegmentator) are publicly available.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Tugba Akinci D'Antonoli",
            "Lucas K. Berger",
            "Ashraya K. Indrakanti",
            "Nathan Vishwanathan",
            "Jakob Wei",
            "Matthias Jung",
            "Zeynep Berkarda",
            "Alexander Rau",
            "Marco Reisert",
            "Thomas Kstner",
            "Alexandra Walter",
            "Elmar M. Merkle",
            "Martin Segeroth",
            "Joshy Cyriac",
            "Shan Yang",
            "Jakob Wasserthal"
        ],
        "published": "2024-05-29T20:15:54Z"
    },
    {
        "title": "Calibration and Validation of a Phase-Field Model of Brittle Fracture\n  within the Damage Mechanics Challenge",
        "link": "http://arxiv.org/abs/2405.19491v1",
        "abstract": "In the context of the Damage Mechanics Challenge, we adopt a phase-field\nmodel of brittle fracture to blindly predict the behavior up to failure of a\nnotched three-point-bending specimen loaded under mixed-mode conditions. The\nbeam is additively manufactured using a geo-architected gypsum based on the\ncombination of bassanite and a water-based binder. The calibration of the\nmaterial parameters involved in the model is based on a set of available\nindependent experimental tests and on a two-stage procedure. In the first stage\nan estimate of most of the elastic parameters is obtained, whereas the\nremaining parameters are optimized in the second stage so as to minimize the\ndiscrepancy between the numerical predictions and a set of experimental results\non notched three-point-bending beams. The good agreement between numerical\npredictions and experimental results in terms of load-displacement curves and\ncrack paths demonstrates the predictive ability of the model and the\nreliability of the calibration procedure.",
        "subjects": [
            "cs.CE"
        ],
        "authors": [
            "Jonas Heinzmann",
            "Pietro Carrara",
            "Chenyi Luo",
            "Manav Manav",
            "Akanksha Mishra",
            "Sindhu Nagaraja",
            "Hamza Oudich",
            "Francesco Vicentini",
            "Laura De Lorenzis"
        ],
        "published": "2024-05-29T20:09:06Z"
    },
    {
        "title": "A Full-duplex Speech Dialogue Scheme Based On Large Language Models",
        "link": "http://arxiv.org/abs/2405.19487v1",
        "abstract": "We present a generative dialogue system capable of operating in a full-duplex\nmanner, allowing for seamless interaction. It is based on a large language\nmodel (LLM) carefully aligned to be aware of a perception module, a motor\nfunction module, and the concept of a simple finite state machine (called\nneural FSM) with two states. The perception and motor function modules operate\nsimultaneously, allowing the system to simultaneously speak and listen to the\nuser. The LLM generates textual tokens for inquiry responses and makes\nautonomous decisions to start responding to, wait for, or interrupt the user by\nemitting control tokens to the neural FSM. All these tasks of the LLM are\ncarried out as next token prediction on a serialized view of the dialogue in\nreal-time. In automatic quality evaluations simulating real-life interaction,\nthe proposed system reduces the average conversation response latency by more\nthan 3 folds compared with LLM-based half-duplex dialogue systems while\nresponding within less than 500 milliseconds in more than 50% of evaluated\ninteractions. Running a LLM with only 8 billion parameters, our system exhibits\na 8% higher interruption precision rate than the best available commercial LLM\nfor voice-based dialogue.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Peng Wang",
            "Songshuo Lu",
            "Yaohua Tang",
            "Sijie Yan",
            "Yuanjun Xiong",
            "Wei Xia"
        ],
        "published": "2024-05-29T20:05:46Z"
    },
    {
        "title": "Online Nonparametric Supervised Learning for Massive Data",
        "link": "http://arxiv.org/abs/2405.19486v1",
        "abstract": "Despite their benefits in terms of simplicity, low computational cost and\ndata requirement, parametric machine learning algorithms, such as linear\ndiscriminant analysis, quadratic discriminant analysis or logistic regression,\nsuffer from serious drawbacks including linearity, poor fit of features to the\nusually imposed normal distribution and high dimensionality. Batch kernel-based\nnonparametric classifier, which overcomes the linearity and normality of\nfeatures constraints, represent an interesting alternative for supervised\nclassification problem. However, it suffers from the ``curse of dimension\". The\nproblem can be alleviated by the explosive sample size in the era of big data,\nwhile large-scale data size presents some challenges in the storage of data and\nthe calculation of the classifier. These challenges make the classical batch\nnonparametric classifier no longer applicable. This motivates us to develop a\nfast algorithm adapted to the real-time calculation of the nonparametric\nclassifier in massive as well as streaming data frameworks. This online\nclassifier includes two steps. First, we consider an online principle\ncomponents analysis to reduce the dimension of the features with a very low\ncomputation cost. Then, a stochastic approximation algorithm is deployed to\nobtain a real-time calculation of the nonparametric classifier. The proposed\nmethods are evaluated and compared to some commonly used machine learning\nalgorithms for real-time fetal well-being monitoring. The study revealed that,\nin terms of accuracy, the offline (or Batch), as well as, the online\nclassifiers are good competitors to the random forest algorithm. Moreover, we\nshow that the online classifier gives the best trade-off accuracy/computation\ncost compared to the offline classifier.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Mohamed Chaouch",
            "Omama M. Al-Hamed"
        ],
        "published": "2024-05-29T20:04:23Z"
    },
    {
        "title": "IMEX methods for thin-film equations and Cahn-Hilliard equations with\n  variable mobility",
        "link": "http://arxiv.org/abs/2405.19483v1",
        "abstract": "We explore a class of splitting schemes employing implicit-explicit (IMEX)\ntime-stepping to achieve accurate and energy-stable solutions for thin-film\nequations and Cahn-Hilliard models with variable mobility. This splitting\nmethod incorporates a linear, constant coefficient implicit step, facilitating\nefficient computational implementation. We investigate the influence of\nstabilizing splitting parameters on the numerical solution computationally,\nconsidering various initial conditions. Furthermore, we generate\nenergy-stability plots for the proposed methods, examining different choices of\nsplitting parameter values and timestep sizes. These methods enhance the\naccuracy of the original bi-harmonic-modified (BHM) approach, while preserving\nits energy-decreasing property and achieving second-order accuracy. We present\nnumerical experiments to illustrate the performance of the proposed methods.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "math-ph",
            "math.MP"
        ],
        "authors": [
            "Saulo Orizaga",
            "Thomas Witelski"
        ],
        "published": "2024-05-29T19:57:02Z"
    },
    {
        "title": "RANFusion: A Comprehensive Tool for Simulating Handover In Next-G RAN",
        "link": "http://arxiv.org/abs/2405.19480v1",
        "abstract": "The rapid advancement of 5G networks and the upcoming transition to 6G\nnecessitate the use of the Open Radio Access Network (O-RAN) architecture to\nenable greater flexibility, interoperability, and innovation. This shift\ntowards 6G and O-RAN requires the development of advanced simulation tools for\ntesting, analyzing, and optimizing Radio Access Network (RAN) operations. This\nneed becomes critical due to the complex dynamics of mobility management\ninherent in the 6G vision and next-generation networks. These networks\nanticipate advanced handover methods for mobile users, UAVs, IoT devices, and\nbeyond. Addressing this gap, this paper introduces RANFusion: a robust RAN\nsimulator specifically created to explore a variety of handover scenarios and\nto test and balance resources between users. This tool enables precise\nsimulations for refining handover strategies within RAN and O-RAN environments,\nthereby ensuring optimal performance and reliability in these advanced network\ninfrastructures.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Seyed Bagher Hashemi Natanzi",
            "Bo Tang"
        ],
        "published": "2024-05-29T19:53:45Z"
    },
    {
        "title": "Participation in the age of foundation models",
        "link": "http://dx.doi.org/10.1145/3630106.3658992",
        "abstract": "Growing interest and investment in the capabilities of foundation models has\npositioned such systems to impact a wide array of public services. Alongside\nthese opportunities is the risk that these systems reify existing power\nimbalances and cause disproportionate harm to marginalized communities.\nParticipatory approaches hold promise to instead lend agency and\ndecision-making power to marginalized stakeholders. But existing approaches in\nparticipatory AI/ML are typically deeply grounded in context - how do we apply\nthese approaches to foundation models, which are, by design, disconnected from\ncontext? Our paper interrogates this question.\n  First, we examine existing attempts at incorporating participation into\nfoundation models. We highlight the tension between participation and scale,\ndemonstrating that it is intractable for impacted communities to meaningfully\nshape a foundation model that is intended to be universally applicable. In\nresponse, we develop a blueprint for participatory foundation models that\nidentifies more local, application-oriented opportunities for meaningful\nparticipation. In addition to the \"foundation\" layer, our framework proposes\nthe \"subfloor'' layer, in which stakeholders develop shared technical\ninfrastructure, norms and governance for a grounded domain, and the \"surface''\nlayer, in which affected communities shape the use of a foundation model for a\nspecific downstream task. The intermediate \"subfloor'' layer scopes the range\nof potential harms to consider, and affords communities more concrete avenues\nfor deliberation and intervention. At the same time, it avoids duplicative\neffort by scaling input across relevant use cases. Through three case studies\nin clinical care, financial services, and journalism, we illustrate how this\nmulti-layer model can create more meaningful opportunities for participation\nthan solely intervening at the foundation layer.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.HC",
            "cs.LG"
        ],
        "authors": [
            "Harini Suresh",
            "Emily Tseng",
            "Meg Young",
            "Mary L. Gray",
            "Emma Pierson",
            "Karen Levy"
        ],
        "published": "2024-05-29T19:53:23Z"
    },
    {
        "title": "The Data Minimization Principle in Machine Learning",
        "link": "http://arxiv.org/abs/2405.19471v1",
        "abstract": "The principle of data minimization aims to reduce the amount of data\ncollected, processed or retained to minimize the potential for misuse,\nunauthorized access, or data breaches. Rooted in privacy-by-design principles,\ndata minimization has been endorsed by various global data protection\nregulations. However, its practical implementation remains a challenge due to\nthe lack of a rigorous formulation. This paper addresses this gap and\nintroduces an optimization framework for data minimization based on its legal\ndefinitions. It then adapts several optimization algorithms to perform data\nminimization and conducts a comprehensive evaluation in terms of their\ncompliance with minimization objectives as well as their impact on user\nprivacy. Our analysis underscores the mismatch between the privacy expectations\nof data minimization and the actual privacy benefits, emphasizing the need for\napproaches that account for multiple facets of real-world privacy risks.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "authors": [
            "Prakhar Ganesh",
            "Cuong Tran",
            "Reza Shokri",
            "Ferdinando Fioretto"
        ],
        "published": "2024-05-29T19:40:27Z"
    },
    {
        "title": "Posterior Sampling via Autoregressive Generation",
        "link": "http://arxiv.org/abs/2405.19466v1",
        "abstract": "Real-world decision-making requires grappling with a perpetual lack of data\nas environments change; intelligent agents must comprehend uncertainty and\nactively gather information to resolve it. We propose a new framework for\nlearning bandit algorithms from massive historical data, which we demonstrate\nin a cold-start recommendation problem. First, we use historical data to\npretrain an autoregressive model to predict a sequence of repeated\nfeedback/rewards (e.g., responses to news articles shown to different users\nover time). In learning to make accurate predictions, the model implicitly\nlearns an informed prior based on rich action features (e.g., article\nheadlines) and how to sharpen beliefs as more rewards are gathered (e.g.,\nclicks as each article is recommended). At decision-time, we autoregressively\nsample (impute) an imagined sequence of rewards for each action, and choose the\naction with the largest average imputed reward. Far from a heuristic, our\napproach is an implementation of Thompson sampling (with a learned prior), a\nprominent active exploration algorithm. We prove our pretraining loss directly\ncontrols online decision-making performance, and we demonstrate our framework\non a news recommendation task where we integrate end-to-end fine-tuning of a\npretrained language model to process news article headline text to improve\nperformance.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Kelly W Zhang",
            " Tiffany",
            " Cai",
            "Hongseok Namkoong",
            "Daniel Russo"
        ],
        "published": "2024-05-29T19:24:44Z"
    },
    {
        "title": "RAP: Efficient Text-Video Retrieval with Sparse-and-Correlated Adapter",
        "link": "http://arxiv.org/abs/2405.19465v1",
        "abstract": "Text-Video Retrieval (TVR) aims to align relevant video content with natural\nlanguage queries. To date, most state-of-the-art TVR methods learn\nimage-to-video transfer learning based on large-scale pre-trained\nvisionlanguage models (e.g., CLIP). However, fully fine-tuning these\npre-trained models for TVR incurs prohibitively expensive computation costs. To\nthis end, we propose to conduct efficient text-video Retrieval with a\nsparse-andcorrelated AdaPter (RAP), i.e., fine-tuning the pre-trained model\nwith a few parameterized layers. To accommodate the text-video scenario, we\nequip our RAP with two indispensable characteristics: temporal sparsity and\ncorrelation. Specifically, we propose a low-rank modulation module to refine\nthe per-image features from the frozen CLIP backbone, which accentuates salient\nframes within the video features while alleviating temporal redundancy.\nBesides, we introduce an asynchronous self-attention mechanism that first\nselects the top responsive visual patches and augments the correlation modeling\nbetween them with learnable temporal and patch offsets. Extensive experiments\non four TVR datasets demonstrate that RAP achieves superior or comparable\nperformance compared to the fully fine-tuned counterpart and other\nparameter-efficient fine-tuning methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Meng Cao",
            "Haoran Tang",
            "Jinfa Huang",
            "Peng Jin",
            "Can Zhang",
            "Ruyang Liu",
            "Long Chen",
            "Xiaodan Liang",
            "Li Yuan",
            "Ge Li"
        ],
        "published": "2024-05-29T19:23:53Z"
    },
    {
        "title": "Leveraging Generative AI for Smart City Digital Twins: A Survey on the\n  Autonomous Generation of Data, Scenarios, 3D City Models, and Urban Designs",
        "link": "http://arxiv.org/abs/2405.19464v1",
        "abstract": "The digital transformation of modern cities by integrating advanced\ninformation, communication, and computing technologies has marked the epoch of\ndata-driven smart city applications for efficient and sustainable urban\nmanagement. Despite their effectiveness, these applications often rely on\nmassive amounts of high-dimensional and multi-domain data for monitoring and\ncharacterizing different urban sub-systems, presenting challenges in\napplication areas that are limited by data quality and availability, as well as\ncostly efforts for generating urban scenarios and design alternatives. As an\nemerging research area in deep learning, Generative Artificial Intelligence\n(AI) models have demonstrated their unique values in data and code generation.\nThis survey paper aims to explore the innovative integration of generative AI\ntechniques and urban digital twins to address challenges in the realm of smart\ncities in various urban sectors, such as transportation and mobility\nmanagement, energy system operations, building and infrastructure management,\nand urban design. The survey starts with the introduction of popular generative\nAI models with their application areas, followed by a structured review of the\nexisting urban science applications that leverage the autonomous capability of\nthe generative AI techniques to facilitate (a) data augmentation for promoting\nurban monitoring and predictive analytics, (b) synthetic data and scenario\ngeneration, (c) automated 3D city modeling, and (d) generative urban design and\noptimization. Based on the review, this survey discusses potential\nopportunities and technical strategies that integrate generative AI models into\nthe next-generation urban digital twins for more reliable, scalable, and\nautomated management of smart cities.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Haowen Xu",
            "Femi Omitaomu",
            "Soheil Sabri",
            "Xiao Li",
            "Yongze Song"
        ],
        "published": "2024-05-29T19:23:07Z"
    },
    {
        "title": "Stochastic Optimization Algorithms for Instrumental Variable Regression\n  with Streaming Data",
        "link": "http://arxiv.org/abs/2405.19463v1",
        "abstract": "We develop and analyze algorithms for instrumental variable regression by\nviewing the problem as a conditional stochastic optimization problem. In the\ncontext of least-squares instrumental variable regression, our algorithms\nneither require matrix inversions nor mini-batches and provides a fully online\napproach for performing instrumental variable regression with streaming data.\nWhen the true model is linear, we derive rates of convergence in expectation,\nthat are of order $\\mathcal{O}(\\log T/T)$ and $\\mathcal{O}(1/T^{1-\\iota})$ for\nany $\\iota>0$, respectively under the availability of two-sample and one-sample\noracles, respectively, where $T$ is the number of iterations. Importantly,\nunder the availability of the two-sample oracle, our procedure avoids\nexplicitly modeling and estimating the relationship between confounder and the\ninstrumental variables, demonstrating the benefit of the proposed approach over\nrecent works based on reformulating the problem as minimax optimization\nproblems. Numerical experiments are provided to corroborate the theoretical\nresults.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "econ.EM",
            "math.OC"
        ],
        "authors": [
            "Xuxing Chen",
            "Abhishek Roy",
            "Yifan Hu",
            "Krishnakumar Balasubramanian"
        ],
        "published": "2024-05-29T19:21:55Z"
    },
    {
        "title": "Critical Learning Periods: Leveraging Early Training Dynamics for\n  Efficient Data Pruning",
        "link": "http://arxiv.org/abs/2405.19462v1",
        "abstract": "Neural Machine Translation models are extremely data and compute-hungry.\nHowever, not all data points contribute equally to model training and\ngeneralization. Data pruning to remove the low-value data points has the\nbenefit of drastically reducing the compute budget without significant drop in\nmodel performance. In this paper, we propose a new data pruning technique:\nCheckpoints Across Time (CAT), that leverages early model training dynamics to\nidentify the most relevant data points for model performance. We benchmark CAT\nagainst several data pruning techniques including COMET-QE, LASER and LaBSE. We\nfind that CAT outperforms the benchmarks on Indo-European languages on multiple\ntest sets. When applied to English-German, English-French and English-Swahili\ntranslation tasks, CAT achieves comparable performance to using the full\ndataset, while pruning up to 50% of training data. We inspect the data points\nthat CAT selects and find that it tends to favour longer sentences and\nsentences with unique or rare words.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Everlyn Asiko Chimoto",
            "Jay Gala",
            "Orevaoghene Ahia",
            "Julia Kreutzer",
            "Bruce A. Bassett",
            "Sara Hooker"
        ],
        "published": "2024-05-29T19:21:49Z"
    },
    {
        "title": "Clustering-Based Validation Splits for Domain Generalisation",
        "link": "http://arxiv.org/abs/2405.19461v1",
        "abstract": "This paper considers the problem of model selection under domain shift. In\nthis setting, it is proposed that a high maximum mean discrepancy (MMD) between\nthe training and validation sets increases the generalisability of selected\nmodels. A data splitting algorithm based on kernel k-means clustering, which\nmaximises this objective, is presented. The algorithm leverages linear\nprogramming to control the size, label, and (optionally) group distributions of\nthe splits, and comes with convergence guarantees. The technique consistently\noutperforms alternative splitting strategies across a range of datasets and\ntraining algorithms, for both domain generalisation (DG) and unsupervised\ndomain adaptation (UDA) tasks. Analysis also shows the MMD between the training\nand validation sets to be strongly rank-correlated ($\\rho=0.63$) with test\ndomain accuracy, further substantiating the validity of this approach.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Andrea Napoli",
            "Paul White"
        ],
        "published": "2024-05-29T19:21:17Z"
    },
    {
        "title": "Evaluating Micro Parsons Problems as Exam Questions",
        "link": "http://arxiv.org/abs/2405.19460v1",
        "abstract": "Parsons problems are a type of programming activity that present learners\nwith blocks of existing code and requiring them to arrange those blocks to form\na program rather than write the code from scratch. Micro Parsons problems\nextend this concept by having students assemble segments of code to form a\nsingle line of code rather than an entire program. Recent investigations into\nmicro Parsons problems have primarily focused on supporting learners leaving\nopen the question of micro Parsons efficacy as an exam item and how students\nperceive it when preparing for exams.\n  To fill this gap, we included a variety of micro Parsons problems on four\nexams in an introductory programming course taught in Python. We use Item\nResponse Theory to investigate the difficulty of the micro Parsons problems as\nwell as the ability of the questions to differentiate between high and low\nability students. We then compare these results to results for related\nquestions where students are asked to write a single line of code from scratch.\nFinally, we conduct a thematic analysis of the survey responses to investigate\nhow students' perceptions of micro Parsons both when practicing for exams and\nas they appear on exams.",
        "subjects": [
            "cs.HC",
            "K.3.2; K.3.1; H.5.2"
        ],
        "authors": [
            "Zihan Wu",
            "David H. Smith IV"
        ],
        "published": "2024-05-29T19:16:14Z"
    },
    {
        "title": "MemControl: Mitigating Memorization in Medical Diffusion Models via\n  Automated Parameter Selection",
        "link": "http://arxiv.org/abs/2405.19458v1",
        "abstract": "Diffusion models show a remarkable ability in generating images that closely\nmirror the training distribution. However, these models are prone to training\ndata memorization, leading to significant privacy, ethical, and legal concerns,\nparticularly in sensitive fields such as medical imaging. We hypothesize that\nmemorization is driven by the overparameterization of deep models, suggesting\nthat regularizing model capacity during fine-tuning could be an effective\nmitigation strategy. Parameter-efficient fine-tuning (PEFT) methods offer a\npromising approach to capacity control by selectively updating specific\nparameters. However, finding the optimal subset of learnable parameters that\nbalances generation quality and memorization remains elusive. To address this\nchallenge, we propose a bi-level optimization framework that guides automated\nparameter selection by utilizing memorization and generation quality metrics as\nrewards. Our framework successfully identifies the optimal parameter set to be\nupdated to satisfy the generation-memorization tradeoff. We perform our\nexperiments for the specific task of medical image generation and outperform\nexisting state-of-the-art training-time mitigation strategies by fine-tuning as\nfew as 0.019% of model parameters. Furthermore, we show that the strategies\nlearned through our framework are transferable across different datasets and\ndomains. Our proposed framework is scalable to large datasets and agnostic to\nthe choice of reward functions. Finally, we show that our framework can be\ncombined with existing approaches for further memorization mitigation.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Raman Dutt",
            "Pedro Sanchez",
            "Ondrej Bohdal",
            "Sotirios A. Tsaftaris",
            "Timothy Hospedales"
        ],
        "published": "2024-05-29T19:12:08Z"
    },
    {
        "title": "Construction of a Byzantine Linearizable SWMR Atomic Register from SWSR\n  Atomic Registers",
        "link": "http://arxiv.org/abs/2405.19457v1",
        "abstract": "The SWMR atomic register is a fundamental building block in shared memory\ndistributed systems and implementing it from SWSR atomic registers is an\nimportant problem. While this problem has been solved in crash-prone systems,\nit has received less attention in Byzantine systems. Recently, Hu and Toueg\ngave such an implementation of the SWMR register from SWSR registers. While\ntheir definition of register linearizability is consistent with the definition\nof Byzantine linearizability of a concurrent history of Cohen and Keidar, it\nhas these drawbacks. (1) If the writer is Byzantine, the register is\nlinearizable no matter what values the correct readers return. (2) It ignores\nvalues written consistently by a Byzantine writer. We need a stronger notion of\na {\\em correct write operation}. (3) It allows a value written to just one or a\nfew readers' SWSR registers to be returned, thereby not validating the\nintention of the writer to write that value honestly. (4) Its notion of a\n``current'' value returned by a correct reader is not related to the most\nrecent value written by a correct write operation of a Byzantine writer. We\nneed a more up to date version of the value that can be returned by a correct\nreader. In this paper, we give a stronger definition of a Byzantine\nlinearizable register that overcomes the above drawbacks. Then we give a\nconstruction of a Byzantine linearizable SWMR atomic register from SWSR\nregisters that meets our stronger definition. The construction is correct when\n$n>3f$, where $n$ is the number of readers, $f$ is the maximum number of\nByzantine readers, and the writer can also be Byzantine. The construction\nrelies on a public-key infrastructure.",
        "subjects": [
            "cs.DC",
            "cs.DS",
            "C.2.4; D.1.3"
        ],
        "authors": [
            "Ajay D. Kshemkalyani",
            "Manaswini Piduguralla",
            "Sathya Peri",
            "Anshuman Misra"
        ],
        "published": "2024-05-29T19:08:26Z"
    },
    {
        "title": "An Automated Startup Evaluation Pipeline: Startup Success Forecasting\n  Framework (SSFF)",
        "link": "http://arxiv.org/abs/2405.19456v1",
        "abstract": "Evaluating startups in their early stages is a complex task that requires\ndetailed analysis by experts. While automating this process on a large scale\ncan significantly impact businesses, the inherent complexity poses challenges.\nThis paper addresses this challenge by introducing the Startup Success\nForecasting Framework (SSFF), a new automated system that combines traditional\nmachine learning with advanced language models. This intelligent agent-based\narchitecture is designed to reason, act, synthesize, and decide like a venture\ncapitalist to perform the analysis end-to-end. The SSFF is made up of three\nmain parts: - Prediction Block: Uses random forests and neural networks to make\npredictions. - Analyst Block: Simulates VC analysis scenario and uses SOTA\nprompting techniques - External Knowledge Block: Gathers real-time information\nfrom external sources. This framework requires minimal input data about the\nfounder and startup description, enhances it with additional data from external\nresources, and performs a detailed analysis with high accuracy, all in an\nautomated manner",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Xisen Wang",
            "Yigit Ihlamur"
        ],
        "published": "2024-05-29T19:07:42Z"
    },
    {
        "title": "Deep Grokking: Would Deep Neural Networks Generalize Better?",
        "link": "http://arxiv.org/abs/2405.19454v1",
        "abstract": "Recent research on the grokking phenomenon has illuminated the intricacies of\nneural networks' training dynamics and their generalization behaviors. Grokking\nrefers to a sharp rise of the network's generalization accuracy on the test\nset, which occurs long after an extended overfitting phase, during which the\nnetwork perfectly fits the training set. While the existing research primarily\nfocus on shallow networks such as 2-layer MLP and 1-layer Transformer, we\nexplore grokking on deep networks (e.g. 12-layer MLP). We empirically replicate\nthe phenomenon and find that deep neural networks can be more susceptible to\ngrokking than its shallower counterparts. Meanwhile, we observe an intriguing\nmulti-stage generalization phenomenon when increase the depth of the MLP model\nwhere the test accuracy exhibits a secondary surge, which is scarcely seen on\nshallow models. We further uncover compelling correspondences between the\ndecreasing of feature ranks and the phase transition from overfitting to the\ngeneralization stage during grokking. Additionally, we find that the\nmulti-stage generalization phenomenon often aligns with a double-descent\npattern in feature ranks. These observations suggest that internal feature rank\ncould serve as a more promising indicator of the model's generalization\nbehavior compared to the weight-norm. We believe our work is the first one to\ndive into grokking in deep neural networks, and investigate the relationship of\nfeature rank and generalization performance.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Simin Fan",
            "Razvan Pascanu",
            "Martin Jaggi"
        ],
        "published": "2024-05-29T19:05:11Z"
    },
    {
        "title": "Optimizing Split Points for Error-Resilient SplitFed Learning",
        "link": "http://arxiv.org/abs/2405.19453v1",
        "abstract": "Recent advancements in decentralized learning, such as Federated Learning\n(FL), Split Learning (SL), and Split Federated Learning (SplitFed), have\nexpanded the potentials of machine learning. SplitFed aims to minimize the\ncomputational burden on individual clients in FL and parallelize SL while\nmaintaining privacy. This study investigates the resilience of SplitFed to\npacket loss at model split points. It explores various parameter aggregation\nstrategies of SplitFed by examining the impact of splitting the model at\ndifferent points-either shallow split or deep split-on the final global model\nperformance. The experiments, conducted on a human embryo image segmentation\ntask, reveal a statistically significant advantage of a deeper split point.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Chamani Shiranthika",
            "Parvaneh Saeedi",
            "Ivan V. Baji"
        ],
        "published": "2024-05-29T19:03:27Z"
    },
    {
        "title": "Gaitor: Learning a Unified Representation Across Gaits for Real-World\n  Quadruped Locomotion",
        "link": "http://arxiv.org/abs/2405.19452v1",
        "abstract": "The current state-of-the-art in quadruped locomotion is able to produce\nrobust motion for terrain traversal but requires the segmentation of a desired\nrobot trajectory into a discrete set of locomotion skills such as trot and\ncrawl. In contrast, in this work we demonstrate the feasibility of learning a\nsingle, unified representation for quadruped locomotion enabling continuous\nblending between gait types and characteristics. We present Gaitor, which\nlearns a disentangled representation of locomotion skills, thereby sharing\ninformation common to all gait types seen during training. The structure\nemerging in the learnt representation is interpretable in that it is found to\nencode phase correlations between the different gait types. These can be\nleveraged to produce continuous gait transitions. In addition, foot swing\ncharacteristics are disentangled and directly addressable. Together with a\nrudimentary terrain encoding and a learned planner operating in this structured\nlatent representation, Gaitor is able to take motion commands including desired\ngait type and characteristics from a user while reacting to uneven terrain. We\nevaluate Gaitor in both simulated and real-world settings on the ANYmal C\nplatform. To the best of our knowledge, this is the first work learning such a\nunified and interpretable latent representation for multiple gaits, resulting\nin on-demand continuous blending between different locomotion modes on a real\nquadruped robot.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "authors": [
            "Alexander L. Mitchell",
            "Wolfgang Merkt",
            "Aristotelis Papatheodorou",
            "Ioannis Havoutis",
            "Ingmar Posner"
        ],
        "published": "2024-05-29T19:02:57Z"
    },
    {
        "title": "FourierMamba: Fourier Learning Integration with State Space Models for\n  Image Deraining",
        "link": "http://arxiv.org/abs/2405.19450v1",
        "abstract": "Image deraining aims to remove rain streaks from rainy images and restore\nclear backgrounds. Currently, some research that employs the Fourier transform\nhas proved to be effective for image deraining, due to it acting as an\neffective frequency prior for capturing rain streaks. However, despite there\nexists dependency of low frequency and high frequency in images, these\nFourier-based methods rarely exploit the correlation of different frequencies\nfor conjuncting their learning procedures, limiting the full utilization of\nfrequency information for image deraining. Alternatively, the recently emerged\nMamba technique depicts its effectiveness and efficiency for modeling\ncorrelation in various domains (e.g., spatial, temporal), and we argue that\nintroducing Mamba into its unexplored Fourier spaces to correlate different\nfrequencies would help improve image deraining. This motivates us to propose a\nnew framework termed FourierMamba, which performs image deraining with Mamba in\nthe Fourier space. Owning to the unique arrangement of frequency orders in\nFourier space, the core of FourierMamba lies in the scanning encoding of\ndifferent frequencies, where the low-high frequency order formats exhibit\ndifferently in the spatial dimension (unarranged in axis) and channel dimension\n(arranged in axis). Therefore, we design FourierMamba that correlates Fourier\nspace information in the spatial and channel dimensions with distinct designs.\nSpecifically, in the spatial dimension Fourier space, we introduce the zigzag\ncoding to scan the frequencies to rearrange the orders from low to high\nfrequencies, thereby orderly correlating the connections between frequencies;\nin the channel dimension Fourier space with arranged orders of frequencies in\naxis, we can directly use Mamba to perform frequency correlation and improve\nthe channel information representation.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Dong Li",
            "Yidi Liu",
            "Xueyang Fu",
            "Senyan Xu",
            "Zheng-Jun Zha"
        ],
        "published": "2024-05-29T18:58:59Z"
    },
    {
        "title": "Tangible Scenography as a Holistic Design Method for Human-Robot\n  Interaction",
        "link": "http://dx.doi.org/10.1145/3643834.3661530",
        "abstract": "Traditional approaches to human-robot interaction design typically examine\nrobot behaviors in controlled environments and narrow tasks. These methods are\nimpractical for designing robots that interact with diverse user groups in\ncomplex human environments. Drawing from the field of theater, we present the\nconstruct of scenes -- individual environments consisting of specific people,\nobjects, spatial arrangements, and social norms -- and tangible scenography, as\na holistic design approach for human-robot interactions. We created a design\ntool, Tangible Scenography Kit (TaSK), with physical props to aid in design\nbrainstorming. We conducted design sessions with eight professional designers\nto generate exploratory designs. Designers used tangible scenography and TaSK\ncomponents to create multiple scenes with specific interaction goals,\ncharacterize each scene's social environment, and design scene-specific robot\nbehaviors. From these sessions, we found that this method can encourage\ndesigners to think beyond a robot's narrow capabilities and consider how they\ncan facilitate complex social interactions.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Amy Koike",
            "Bengisu Cagiltay",
            "Bilge Mutlu"
        ],
        "published": "2024-05-29T18:55:13Z"
    },
    {
        "title": "MathChat: Benchmarking Mathematical Reasoning and Instruction Following\n  in Multi-Turn Interactions",
        "link": "http://arxiv.org/abs/2405.19444v1",
        "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\nmathematical problem solving, particularly in single turn question answering\nformats. However, real world scenarios often involve mathematical question\nanswering that requires multi turn or interactive information exchanges, and\nthe performance of LLMs on these tasks is still underexplored. This paper\nintroduces MathChat, a comprehensive benchmark specifically designed to\nevaluate LLMs across a broader spectrum of mathematical tasks. These tasks are\nstructured to assess the models' abilities in multiturn interactions and open\nended generation. We evaluate the performance of various SOTA LLMs on the\nMathChat benchmark, and we observe that while these models excel in single turn\nquestion answering, they significantly underperform in more complex scenarios\nthat require sustained reasoning and dialogue understanding. To address the\nabove limitations of existing LLMs when faced with multiturn and open ended\ntasks, we develop MathChat sync, a synthetic dialogue based math dataset for\nLLM finetuning, focusing on improving models' interaction and instruction\nfollowing capabilities in conversations. Experimental results emphasize the\nneed for training LLMs with diverse, conversational instruction tuning datasets\nlike MathChatsync. We believe this work outlines one promising direction for\nimproving the multiturn mathematical reasoning abilities of LLMs, thus pushing\nforward the development of LLMs that are more adept at interactive mathematical\nproblem solving and real world applications.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Zhenwen Liang",
            "Dian Yu",
            "Wenhao Yu",
            "Wenlin Yao",
            "Zhihan Zhang",
            "Xiangliang Zhang",
            "Dong Yu"
        ],
        "published": "2024-05-29T18:45:55Z"
    },
    {
        "title": "Large-scale DSM registration via motion averaging",
        "link": "http://dx.doi.org/10.5194/isprs-annals-x-1-2024-275-2024",
        "abstract": "Generating wide-area digital surface models (DSMs) requires registering a\nlarge number of individual, and partially overlapped DSMs. This presents a\nchallenging problem for a typical registration algorithm, since when a large\nnumber of observations from these multiple DSMs are considered, it may easily\ncause memory overflow. Sequential registration algorithms, although can\nsignificantly reduce the computation, are especially vulnerable for small\noverlapped pairs, leading to a large error accumulation. In this work, we\npropose a novel solution that builds the DSM registration task as a motion\naveraging problem: pair-wise DSMs are registered to build a scene graph, with\nedges representing relative poses between DSMs. Specifically, based on the grid\nstructure of the large DSM, the pair-wise registration is performed using a\nnovel nearest neighbor search method. We show that the scene graph can be\noptimized via an extremely fast motion average algorithm with O(N) complexity\n(N refers to the number of images). Evaluation of high-resolution\nsatellite-derived DSM demonstrates significant improvement in computation and\naccuracy.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ningli Xu",
            "Rongjun Qin"
        ],
        "published": "2024-05-29T18:40:11Z"
    },
    {
        "title": "On the Convergence of Multi-objective Optimization under Generalized\n  Smoothness",
        "link": "http://arxiv.org/abs/2405.19440v1",
        "abstract": "Multi-objective optimization (MOO) is receiving more attention in various\nfields such as multi-task learning. Recent works provide some effective\nalgorithms with theoretical analysis but they are limited by the standard\n$L$-smooth or bounded-gradient assumptions, which are typically unsatisfactory\nfor neural networks, such as recurrent neural networks (RNNs) and transformers.\nIn this paper, we study a more general and realistic class of $\\ell$-smooth\nloss functions, where $\\ell$ is a general non-decreasing function of gradient\nnorm. We develop two novel single-loop algorithms for $\\ell$-smooth MOO\nproblems, Generalized Smooth Multi-objective Gradient descent (GSMGrad) and its\nstochastic variant, Stochastic Generalized Smooth Multi-objective Gradient\ndescent (SGSMGrad), which approximate the conflict-avoidant (CA) direction that\nmaximizes the minimum improvement among objectives. We provide a comprehensive\nconvergence analysis of both algorithms and show that they converge to an\n$\\epsilon$-accurate Pareto stationary point with a guaranteed $\\epsilon$-level\naverage CA distance (i.e., the gap between the updating direction and the CA\ndirection) over all iterations, where totally $\\mathcal{O}(\\epsilon^{-2})$ and\n$\\mathcal{O}(\\epsilon^{-4})$ samples are needed for deterministic and\nstochastic settings, respectively. Our algorithms can also guarantee a tighter\n$\\epsilon$-level CA distance in each iteration using more samples. Moreover, we\npropose a practical variant of GSMGrad named GSMGrad-FA using only\nconstant-level time and space, while achieving the same performance guarantee\nas GSMGrad. Our experiments validate our theory and demonstrate the\neffectiveness of the proposed methods.",
        "subjects": [
            "cs.LG",
            "math.OC",
            "stat.ML"
        ],
        "authors": [
            "Qi Zhang",
            "Peiyao Xiao",
            "Kaiyi Ji",
            "Shaofeng Zou"
        ],
        "published": "2024-05-29T18:36:59Z"
    },
    {
        "title": "Towards an Autonomous Minimally Invasive Spinal Fixation Surgery Using a\n  Concentric Tube Steerable Drilling Robot",
        "link": "http://arxiv.org/abs/2405.19438v1",
        "abstract": "Towards performing a realistic autonomous minimally invasive spinal fixation\nprocedure, in this paper, we introduce a unique robotic drilling system\nutilizing a concentric tube steerable drilling robot (CT-SDR) integrated with a\nseven degree-of-freedom robotic manipulator. The CT-SDR in integration with the\nrobotic arm enables creating precise J-shape trajectories enabling access to\nthe areas within the vertebral body that currently are not accessible utilizing\nexisting rigid instruments. To ensure safety and accuracy of the autonomous\ndrilling procedure, we also performed required calibration procedures. The\nperformance of the proposed robotic system and the calibration steps were\nthoroughly evaluated by performing various drilling experiments on simulated\nSawbone samples.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Susheela Sharma",
            "Sarah Go",
            "Jeff Bonyun",
            "Jordan P. Amadio",
            "Mohsen Khadem",
            "Farshid Alambeigi"
        ],
        "published": "2024-05-29T18:32:52Z"
    },
    {
        "title": "Beyond Agreement: Diagnosing the Rationale Alignment of Automated Essay\n  Scoring Methods based on Linguistically-informed Counterfactuals",
        "link": "http://arxiv.org/abs/2405.19433v1",
        "abstract": "While current automated essay scoring (AES) methods show high agreement with\nhuman raters, their scoring mechanisms are not fully explored. Our proposed\nmethod, using counterfactual intervention assisted by Large Language Models\n(LLMs), reveals that when scoring essays, BERT-like models primarily focus on\nsentence-level features, while LLMs are attuned to conventions, language\ncomplexity, as well as organization, indicating a more comprehensive alignment\nwith scoring rubrics. Moreover, LLMs can discern counterfactual interventions\nduring feedback. Our approach improves understanding of neural AES methods and\ncan also apply to other domains seeking transparency in model-driven decisions.\nThe codes and data will be released at GitHub.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yupei Wang",
            "Renfen Hu",
            "Zhe Zhao"
        ],
        "published": "2024-05-29T18:16:32Z"
    },
    {
        "title": "Understanding Grasp Synergies during Reach-to-grasp using an\n  Instrumented Data Glove",
        "link": "http://arxiv.org/abs/2405.19430v1",
        "abstract": "Data gloves play a crucial role in study of human grasping, and could provide\ninsights into grasp synergies. Grasp synergies lead to identification of\nunderlying patterns to develop control strategies for hand exoskeletons. This\npaper presents the design and implementation of a data glove that has been\nenhanced with instrumentation and fabricated using 3D printing technology. The\nglove utilizes flexible sensors for the fingers and force sensors integrated\ninto the glove at the fingertips to accurately capture grasp postures and\nforces. Understanding the kinematics and dynamics of human grasp including\nreach-to-grasp is undertaken. A comprehensive study involving 10 healthy\nsubjects was conducted. Grasp synergy analysis is carried out to identify\nunderlying patterns for robotic grasping. The t-SNE visualization showcased\nclusters of grasp postures and forces, unveiling similarities and patterns\namong different GTs. These findings could serve as a comprehensive guide in\ndesign and control of tendon-driven soft hand exoskeletons for rehabilitation\napplications, enabling the replication of natural hand movements and grasp\nforces.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Subhash Pratap",
            "Yoshiyuki Hatta",
            "Kazuaki Ito",
            "Shyamanta M. Hazarika"
        ],
        "published": "2024-05-29T18:10:52Z"
    },
    {
        "title": "Conformal Recursive Feature Elimination",
        "link": "http://arxiv.org/abs/2405.19429v1",
        "abstract": "Unlike traditional statistical methods, Conformal Prediction (CP) allows for\nthe determination of valid and accurate confidence levels associated with\nindividual predictions based only on exchangeability of the data. We here\nintroduce a new feature selection method that takes advantage of the CP\nframework. Our proposal, named Conformal Recursive Feature Elimination (CRFE),\nidentifies and recursively removes features that increase the non-conformity of\na dataset. We also present an automatic stopping criterion for CRFE, as well as\na new index to measure consistency between subsets of features. CRFE selections\nare compared to the classical Recursive Feature Elimination (RFE) method on\nseveral multiclass datasets by using multiple partitions of the data. The\nresults show that CRFE clearly outperforms RFE in half of the datasets, while\nachieving similar performance in the rest. The automatic stopping criterion\nprovides subsets of effective and non-redundant features without computing any\nclassification performance.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Marcos Lpez-De-Castro",
            "Alberto Garca-Galindo",
            "Rubn Armaanzas"
        ],
        "published": "2024-05-29T18:10:36Z"
    },
    {
        "title": "Deep Learning for Assessment of Oral Reading Fluency",
        "link": "http://arxiv.org/abs/2405.19426v1",
        "abstract": "Reading fluency assessment is a critical component of literacy programmes,\nserving to guide and monitor early education interventions. Given the resource\nintensive nature of the exercise when conducted by teachers, the development of\nautomatic tools that can operate on audio recordings of oral reading is\nattractive as an objective and highly scalable solution. Multiple complex\naspects such as accuracy, rate and expressiveness underlie human judgements of\nreading fluency. In this work, we investigate end-to-end modeling on a training\ndataset of children's audio recordings of story texts labeled by human experts.\nThe pre-trained wav2vec2.0 model is adopted due its potential to alleviate the\nchallenges from the limited amount of labeled data. We report the performance\nof a number of system variations on the relevant measures, and also probe the\nlearned embeddings for lexical and acoustic-prosodic features known to be\nimportant to the perception of reading fluency.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Mithilesh Vaidya",
            "Binaya Kumar Sahoo",
            "Preeti Rao"
        ],
        "published": "2024-05-29T18:09:35Z"
    },
    {
        "title": "Adaptive In-conversation Team Building for Language Model Agents",
        "link": "http://arxiv.org/abs/2405.19425v1",
        "abstract": "Leveraging multiple large language model (LLM) agents has shown to be a\npromising approach for tackling complex tasks, while the effective design of\nmultiple agents for a particular application remains an art. It is thus\nintriguing to answer a critical question: Given a task, how can we build a team\nof LLM agents to solve it effectively? Our new adaptive team-building paradigm\noffers a flexible solution, realized through a novel agent design named Captain\nAgent. It dynamically forms and manages teams for each step of a task-solving\nprocess, utilizing nested group conversations and reflection to ensure diverse\nexpertise and prevent stereotypical outputs. It allows for a flexible yet\nstructured approach to problem-solving and can help reduce redundancy and\nenhance output diversity. A comprehensive evaluation across six real-world\nscenarios demonstrates that Captain Agent significantly outperforms existing\nmulti-agent methods with 21.94% improvement in average accuracy, providing\noutstanding performance without requiring task-specific prompt engineering.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Linxin Song",
            "Jiale Liu",
            "Jieyu Zhang",
            "Shaokun Zhang",
            "Ao Luo",
            "Shijian Wang",
            "Qingyun Wu",
            "Chi Wang"
        ],
        "published": "2024-05-29T18:08:37Z"
    },
    {
        "title": "Diffusion Policy Attacker: Crafting Adversarial Attacks for\n  Diffusion-based Policies",
        "link": "http://arxiv.org/abs/2405.19424v1",
        "abstract": "Diffusion models (DMs) have emerged as a promising approach for behavior\ncloning (BC). Diffusion policies (DP) based on DMs have elevated BC performance\nto new heights, demonstrating robust efficacy across diverse tasks, coupled\nwith their inherent flexibility and ease of implementation. Despite the\nincreasing adoption of DP as a foundation for policy generation, the critical\nissue of safety remains largely unexplored. While previous attempts have\ntargeted deep policy networks, DP used diffusion models as the policy network,\nmaking it ineffective to be attacked using previous methods because of its\nchained structure and randomness injected. In this paper, we undertake a\ncomprehensive examination of DP safety concerns by introducing adversarial\nscenarios, encompassing offline and online attacks, and global and patch-based\nattacks. We propose DP-Attacker, a suite of algorithms that can craft effective\nadversarial attacks across all aforementioned scenarios. We conduct attacks on\npre-trained diffusion policies across various manipulation tasks. Through\nextensive experiments, we demonstrate that DP-Attacker has the capability to\nsignificantly decrease the success rate of DP for all scenarios. Particularly\nin offline scenarios, DP-Attacker can generate highly transferable\nperturbations applicable to all frames. Furthermore, we illustrate the creation\nof adversarial physical patches that, when applied to the environment,\neffectively deceive the model. Video results are put in:\nhttps://sites.google.com/view/diffusion-policy-attacker.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yipu Chen",
            "Haotian Xue",
            "Yongxin Chen"
        ],
        "published": "2024-05-29T18:06:25Z"
    },
    {
        "title": "Evaluating Vision-Language Models on Bistable Images",
        "link": "http://arxiv.org/abs/2405.19423v1",
        "abstract": "Bistable images, also known as ambiguous or reversible images, present visual\nstimuli that can be seen in two distinct interpretations, though not\nsimultaneously by the observer. In this study, we conduct the most extensive\nexamination of vision-language models using bistable images to date. We\nmanually gathered a dataset of 29 bistable images, along with their associated\nlabels, and subjected them to 116 different manipulations in brightness, tint,\nand rotation. We evaluated twelve different models in both classification and\ngenerative tasks across six model architectures. Our findings reveal that, with\nthe exception of models from the Idefics family and LLaVA1.5-13b, there is a\npronounced preference for one interpretation over another among the models, and\nminimal variance under image manipulations, with few exceptions on image\nrotations. Additionally, we compared the model preferences with humans, noting\nthat the models do not exhibit the same continuity biases as humans and often\ndiverge from human initial interpretations. We also investigated the influence\nof variations in prompts and the use of synonymous labels, discovering that\nthese factors significantly affect model interpretations more than image\nmanipulations showing a higher influence of the language priors on bistable\nimage interpretations compared to image-text training data. All code and data\nis open sourced.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Artemis Panagopoulou",
            "Coby Melkin",
            "Chris Callison-Burch"
        ],
        "published": "2024-05-29T18:04:59Z"
    },
    {
        "title": "Using Contrastive Learning with Generative Similarity to Learn Spaces\n  that Capture Human Inductive Biases",
        "link": "http://arxiv.org/abs/2405.19420v1",
        "abstract": "Humans rely on strong inductive biases to learn from few examples and\nabstract useful information from sensory data. Instilling such biases in\nmachine learning models has been shown to improve their performance on various\nbenchmarks including few-shot learning, robustness, and alignment. However,\nfinding effective training procedures to achieve that goal can be challenging\nas psychologically-rich training data such as human similarity judgments are\nexpensive to scale, and Bayesian models of human inductive biases are often\nintractable for complex, realistic domains. Here, we address this challenge by\nintroducing a Bayesian notion of generative similarity whereby two datapoints\nare considered similar if they are likely to have been sampled from the same\ndistribution. This measure can be applied to complex generative processes,\nincluding probabilistic programs. We show that generative similarity can be\nused to define a contrastive learning objective even when its exact form is\nintractable, enabling learning of spatial embeddings that express specific\ninductive biases. We demonstrate the utility of our approach by showing how it\ncan be used to capture human inductive biases for geometric shapes, and to\nbetter distinguish different abstract drawing styles that are parameterized by\nprobabilistic programs.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.NC"
        ],
        "authors": [
            "Raja Marjieh",
            "Sreejan Kumar",
            "Declan Campbell",
            "Liyi Zhang",
            "Gianluca Bencomo",
            "Jake Snell",
            "Thomas L. Griffiths"
        ],
        "published": "2024-05-29T18:01:58Z"
    },
    {
        "title": "Safety through Permissibility: Shield Construction for Fast and Safe\n  Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.19414v1",
        "abstract": "Designing Reinforcement Learning (RL) solutions for real-life problems\nremains a significant challenge. A major area of concern is safety. \"Shielding\"\nis a popular technique to enforce safety in RL by turning user-defined safety\nspecifications into safe agent behavior. However, these methods either suffer\nfrom extreme learning delays, demand extensive human effort in designing models\nand safe domains in the problem, or require pre-computation. In this paper, we\npropose a new permissibility-based framework to deal with safety and shield\nconstruction. Permissibility was originally designed for eliminating\n(non-permissible) actions that will not lead to an optimal solution to improve\nRL training efficiency. This paper shows that safety can be naturally\nincorporated into this framework, i.e. extending permissibility to include\nsafety, and thereby we can achieve both safety and improved efficiency.\nExperimental evaluation using three standard RL applications shows the\neffectiveness of the approach.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Alexander Politowicz",
            "Sahisnu Mazumder",
            "Bing Liu"
        ],
        "published": "2024-05-29T18:00:21Z"
    },
    {
        "title": "VisTA-SR: Improving the Accuracy and Resolution of Low-Cost Thermal\n  Imaging Cameras for Agriculture",
        "link": "http://arxiv.org/abs/2405.19413v1",
        "abstract": "Thermal cameras are an important tool for agricultural research because they\nallow for non-invasive measurement of plant temperature, which relates to\nimportant photochemical, hydraulic, and agronomic traits. Utilizing low-cost\nthermal cameras can lower the barrier to introducing thermal imaging in\nagricultural research and production. This paper presents an approach to\nimprove the temperature accuracy and image quality of low-cost thermal imaging\ncameras for agricultural applications. Leveraging advancements in computer\nvision techniques, particularly deep learning networks, we propose a method,\ncalled $\\textbf{VisTA-SR}$ ($\\textbf{Vis}$ual \\& $\\textbf{T}$hermal\n$\\textbf{A}$lignment and $\\textbf{S}$uper-$\\textbf{R}$esolution Enhancement)\nthat combines RGB and thermal images to enhance the capabilities of\nlow-resolution thermal cameras. The research includes calibration and\nvalidation of temperature measurements, acquisition of paired image datasets,\nand the development of a deep learning network tailored for agricultural\nthermal imaging. Our study addresses the challenges of image enhancement in the\nagricultural domain and explores the potential of low-cost thermal cameras to\nreplace high-resolution industrial cameras. Experimental results demonstrate\nthe effectiveness of our approach in enhancing temperature accuracy and image\nsharpness, paving the way for more accessible and efficient thermal imaging\nsolutions in agriculture.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Heesup Yun",
            "Sassoum Lo",
            "Christine H. Diepenbrock",
            "Brian N. Bailey",
            "J. Mason Earles"
        ],
        "published": "2024-05-29T18:00:20Z"
    },
    {
        "title": "Ground state phases of the two-dimension electron gas with a unified\n  variational approach",
        "link": "http://arxiv.org/abs/2405.19397v1",
        "abstract": "The two-dimensional electron gas (2DEG) is a fundamental model, which is\ndrawing increasing interest because of recent advances in experimental and\ntheoretical studies of 2D materials. Current understanding of the ground state\nof the 2DEG relies on quantum Monte Carlo calculations, based on variational\ncomparisons of different ansatze for different phases. We use a single\nvariational ansatz, a general backflow-type wave function using a\nmessage-passing neural quantum state architecture, for a unified description\nacross the entire density range. The variational optimization consistently\nleads to lower ground-state energies than previous best results. Transition\ninto a Wigner crystal (WC) phase occurs automatically at rs = 37 +/- 1, a\ndensity lower than currently believed. Between the liquid and WC phases, the\nsame ansatz and variational search strongly suggest the existence of\nintermediate states in a broad range of densities, with enhanced short-range\nnematic spin correlations.",
        "subjects": [
            "cond-mat.str-el",
            "cs.LG",
            "physics.comp-ph",
            "quant-ph"
        ],
        "authors": [
            "Conor Smith",
            "Yixiao Chen",
            "Ryan Levy",
            "Yubo Yang",
            "Miguel A. Morales",
            "Shiwei Zhang"
        ],
        "published": "2024-05-29T18:00:01Z"
    },
    {
        "title": "Neural Scaling Laws From Large-N Field Theory: Solvable Model Beyond the\n  Ridgeless Limit",
        "link": "http://arxiv.org/abs/2405.19398v1",
        "abstract": "Many machine learning models based on neural networks exhibit scaling laws:\ntheir performance scales as power laws with respect to the sizes of the model\nand training data set. We use large-N field theory methods to solve a model\nrecently proposed by Maloney, Roberts and Sully which provides a simplified\nsetting to study neural scaling laws. Our solution extends the result in this\nlatter paper to general nonzero values of the ridge parameter, which are\nessential to regularize the behavior of the model. In addition to obtaining new\nand more precise scaling laws, we also uncover a duality transformation at the\ndiagrams level which explains the symmetry between model and training data set\nsizes. The same duality underlies recent efforts to design neural networks to\nsimulate quantum field theories.",
        "subjects": [
            "hep-th",
            "cond-mat.dis-nn",
            "cs.LG",
            "hep-ph"
        ],
        "authors": [
            "Zhengkang Zhang"
        ],
        "published": "2024-05-29T18:00:01Z"
    },
    {
        "title": "X-VILA: Cross-Modality Alignment for Large Language Model",
        "link": "http://arxiv.org/abs/2405.19335v1",
        "abstract": "We introduce X-VILA, an omni-modality model designed to extend the\ncapabilities of large language models (LLMs) by incorporating image, video, and\naudio modalities. By aligning modality-specific encoders with LLM inputs and\ndiffusion decoders with LLM outputs, X-VILA achieves cross-modality\nunderstanding, reasoning, and generation. To facilitate this cross-modality\nalignment, we curate an effective interleaved any-to-any modality\ninstruction-following dataset. Furthermore, we identify a significant problem\nwith the current cross-modality alignment method, which results in visual\ninformation loss. To address the issue, we propose a visual alignment mechanism\nwith a visual embedding highway module. We then introduce a resource-efficient\nrecipe for training X-VILA, that exhibits proficiency in any-to-any modality\nconversation, surpassing previous approaches by large margins. X-VILA also\nshowcases emergent properties across modalities even in the absence of similar\ntraining data. The project will be made open-source.",
        "subjects": [
            "cs.CV",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Hanrong Ye",
            "De-An Huang",
            "Yao Lu",
            "Zhiding Yu",
            "Wei Ping",
            "Andrew Tao",
            "Jan Kautz",
            "Song Han",
            "Dan Xu",
            "Pavlo Molchanov",
            "Hongxu Yin"
        ],
        "published": "2024-05-29T17:59:58Z"
    },
    {
        "title": "LLMs Meet Multimodal Generation and Editing: A Survey",
        "link": "http://arxiv.org/abs/2405.19334v1",
        "abstract": "With the recent advancement in large language models (LLMs), there is a\ngrowing interest in combining LLMs with multimodal learning. Previous surveys\nof multimodal large language models (MLLMs) mainly focus on understanding. This\nsurvey elaborates on multimodal generation across different domains, including\nimage, video, 3D, and audio, where we highlight the notable advancements with\nmilestone works in these fields. Specifically, we exhaustively investigate the\nkey technical components behind methods and multimodal datasets utilized in\nthese studies. Moreover, we dig into tool-augmented multimodal agents that can\nuse existing generative models for human-computer interaction. Lastly, we also\ncomprehensively discuss the advancement in AI safety and investigate emerging\napplications as well as future prospects. Our work provides a systematic and\ninsightful overview of multimodal generation, which is expected to advance the\ndevelopment of Artificial Intelligence for Generative Content (AIGC) and world\nmodels. A curated list of all related papers can be found at\nhttps://github.com/YingqingHe/Awesome-LLMs-meet-Multimodal-Generation",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "authors": [
            "Yingqing He",
            "Zhaoyang Liu",
            "Jingye Chen",
            "Zeyue Tian",
            "Hongyu Liu",
            "Xiaowei Chi",
            "Runtao Liu",
            "Ruibin Yuan",
            "Yazhou Xing",
            "Wenhai Wang",
            "Jifeng Dai",
            "Yong Zhang",
            "Wei Xue",
            "Qifeng Liu",
            "Yike Guo",
            "Qifeng Chen"
        ],
        "published": "2024-05-29T17:59:20Z"
    },
    {
        "title": "Multi-Modal Generative Embedding Model",
        "link": "http://arxiv.org/abs/2405.19333v1",
        "abstract": "Most multi-modal tasks can be formulated into problems of either generation\nor embedding. Existing models usually tackle these two types of problems by\ndecoupling language modules into a text decoder for generation, and a text\nencoder for embedding. To explore the minimalism of multi-modal paradigms, we\nattempt to achieve only one model per modality in this work. We propose a\nMulti-Modal Generative Embedding Model (MM-GEM), whereby the generative and\nembedding objectives are encapsulated in one Large Language Model. We also\npropose a PoolAggregator to boost efficiency and enable the ability of\nfine-grained embedding and generation. A surprising finding is that these two\nobjectives do not significantly conflict with each other. For example, MM-GEM\ninstantiated from ViT-Large and TinyLlama shows competitive performance on\nbenchmarks for multimodal embedding models such as cross-modal retrieval and\nzero-shot classification, while has good ability of image captioning.\nAdditionally, MM-GEM can seamlessly execute region-level image caption\ngeneration and retrieval tasks. Besides, the advanced text model in MM-GEM\nbrings over 5% improvement in Recall@1 for long text and image retrieval.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Feipeng Ma",
            "Hongwei Xue",
            "Guangting Wang",
            "Yizhou Zhou",
            "Fengyun Rao",
            "Shilin Yan",
            "Yueyi Zhang",
            "Siying Wu",
            "Mike Zheng Shou",
            "Xiaoyan Sun"
        ],
        "published": "2024-05-29T17:59:10Z"
    },
    {
        "title": "Self-Exploring Language Models: Active Preference Elicitation for Online\n  Alignment",
        "link": "http://arxiv.org/abs/2405.19332v1",
        "abstract": "Preference optimization, particularly through Reinforcement Learning from\nHuman Feedback (RLHF), has achieved significant success in aligning Large\nLanguage Models (LLMs) to adhere to human intentions. Unlike offline alignment\nwith a fixed dataset, online feedback collection from humans or AI on model\ngenerations typically leads to more capable reward models and better-aligned\nLLMs through an iterative process. However, achieving a globally accurate\nreward model requires systematic exploration to generate diverse responses that\nspan the vast space of natural language. Random sampling from standard\nreward-maximizing LLMs alone is insufficient to fulfill this requirement. To\naddress this issue, we propose a bilevel objective optimistically biased\ntowards potentially high-reward responses to actively explore\nout-of-distribution regions. By solving the inner-level problem with the\nreparameterized reward function, the resulting algorithm, named Self-Exploring\nLanguage Models (SELM), eliminates the need for a separate RM and iteratively\nupdates the LLM with a straightforward objective. Compared to Direct Preference\nOptimization (DPO), the SELM objective reduces indiscriminate favor of unseen\nextrapolations and enhances exploration efficiency. Our experimental results\ndemonstrate that when finetuned on Zephyr-7B-SFT and Llama-3-8B-Instruct\nmodels, SELM significantly boosts the performance on instruction-following\nbenchmarks such as MT-Bench and AlpacaEval 2.0, as well as various standard\nacademic benchmarks in different settings. Our code and models are available at\nhttps://github.com/shenao-zhang/SELM.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Shenao Zhang",
            "Donghan Yu",
            "Hiteshi Sharma",
            "Ziyi Yang",
            "Shuohang Wang",
            "Hany Hassan",
            "Zhaoran Wang"
        ],
        "published": "2024-05-29T17:59:07Z"
    },
    {
        "title": "NPGA: Neural Parametric Gaussian Avatars",
        "link": "http://arxiv.org/abs/2405.19331v1",
        "abstract": "The creation of high-fidelity, digital versions of human heads is an\nimportant stepping stone in the process of further integrating virtual\ncomponents into our everyday lives. Constructing such avatars is a challenging\nresearch problem, due to a high demand for photo-realism and real-time\nrendering performance. In this work, we propose Neural Parametric Gaussian\nAvatars (NPGA), a data-driven approach to create high-fidelity, controllable\navatars from multi-view video recordings. We build our method around 3D\nGaussian Splatting for its highly efficient rendering and to inherit the\ntopological flexibility of point clouds. In contrast to previous work, we\ncondition our avatars' dynamics on the rich expression space of neural\nparametric head models (NPHM), instead of mesh-based 3DMMs. To this end, we\ndistill the backward deformation field of our underlying NPHM into forward\ndeformations which are compatible with rasterization-based rendering. All\nremaining fine-scale, expression-dependent details are learned from the\nmulti-view videos. To increase the representational capacity of our avatars, we\naugment the canonical Gaussian point cloud using per-primitive latent features\nwhich govern its dynamic behavior. To regularize this increased dynamic\nexpressivity, we propose Laplacian terms on the latent features and predicted\ndynamics. We evaluate our method on the public NeRSemble dataset, demonstrating\nthat NPGA significantly outperforms the previous state-of-the-art avatars on\nthe self-reenactment task by 2.6 PSNR. Furthermore, we demonstrate accurate\nanimation capabilities from real-world monocular videos.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR"
        ],
        "authors": [
            "Simon Giebenhain",
            "Tobias Kirschstein",
            "Martin Rnz",
            "Lourdes Agapito",
            "Matthias Niener"
        ],
        "published": "2024-05-29T17:58:09Z"
    },
    {
        "title": "Normative Modules: A Generative Agent Architecture for Learning Norms\n  that Supports Multi-Agent Cooperation",
        "link": "http://arxiv.org/abs/2405.19328v1",
        "abstract": "Generative agents, which implement behaviors using a large language model\n(LLM) to interpret and evaluate an environment, has demonstrated the capacity\nto solve complex tasks across many social and technological domains. However,\nwhen these agents interact with other agents and humans in presence of social\nstructures such as existing norms, fostering cooperation between them is a\nfundamental challenge. In this paper, we develop the framework of a 'Normative\nModule': an architecture designed to enhance cooperation by enabling agents to\nrecognize and adapt to the normative infrastructure of a given environment. We\nfocus on the equilibrium selection aspect of the cooperation problem and inform\nour agent design based on the existence of classification institutions that\nimplement correlated equilibrium to provide effective resolution of the\nequilibrium selection problem. Specifically, the normative module enables\nagents to learn through peer interactions which of multiple candidate\ninstitutions in the environment, does a group treat as authoritative. By\nenabling normative competence in this sense, agents gain ability to coordinate\ntheir sanctioning behaviour; coordinated sanctioning behaviour in turn shapes\nprimary behaviour within a social environment, leading to higher average\nwelfare. We design a new environment that supports institutions and evaluate\nthe proposed framework based on two key criteria derived from agent\ninteractions with peers and institutions: (i) the agent's ability to disregard\nnon-authoritative institutions and (ii) the agent's ability to identify\nauthoritative institutions among several options. We show that these\ncapabilities allow the agent to achieve more stable cooperative outcomes\ncompared to baseline agents without the normative module, paving the way for\nresearch in a new avenue of designing environments and agents that account for\nnormative infrastructure.",
        "subjects": [
            "cs.MA"
        ],
        "authors": [
            "Atrisha Sarkar",
            "Andrei Ioan Muresanu",
            "Carter Blair",
            "Aaryam Sharma",
            "Rakshit S Trivedi",
            "Gillian K Hadfield"
        ],
        "published": "2024-05-29T17:57:30Z"
    },
    {
        "title": "MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model\n  Series",
        "link": "http://arxiv.org/abs/2405.19327v2",
        "abstract": "Large Language Models (LLMs) have made great strides in recent years to\nachieve unprecedented performance across different tasks. However, due to\ncommercial interest, the most competitive models like GPT, Gemini, and Claude\nhave been gated behind proprietary interfaces without disclosing the training\ndetails. Recently, many institutions have open-sourced several strong LLMs like\nLLaMA-3, comparable to existing closed-source LLMs. However, only the model's\nweights are provided with most details (e.g., intermediate checkpoints,\npre-training corpus, and training code, etc.) being undisclosed. To improve the\ntransparency of LLMs, the research community has formed to open-source truly\nopen LLMs (e.g., Pythia, Amber, OLMo), where more details (e.g., pre-training\ncorpus and training code) are being provided. These models have greatly\nadvanced the scientific study of these large models including their strengths,\nweaknesses, biases and risks. However, we observe that the existing truly open\nLLMs on reasoning, knowledge, and coding tasks are still inferior to existing\nstate-of-the-art LLMs with similar model sizes. To this end, we open-source\nMAP-Neo, a highly capable and transparent bilingual language model with 7B\nparameters trained from scratch on 4.5T high-quality tokens. Our MAP-Neo is the\nfirst fully open-sourced bilingual LLM with comparable performance compared to\nexisting state-of-the-art LLMs. Moreover, we open-source all details to\nreproduce our MAP-Neo, where the cleaned pre-training corpus, data cleaning\npipeline, checkpoints, and well-optimized training/evaluation framework are\nprovided. Finally, we hope our MAP-Neo will enhance and strengthen the open\nresearch community and inspire more innovations and creativities to facilitate\nthe further improvements of LLMs.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Ge Zhang",
            "Scott Qu",
            "Jiaheng Liu",
            "Chenchen Zhang",
            "Chenghua Lin",
            "Chou Leuang Yu",
            "Danny Pan",
            "Esther Cheng",
            "Jie Liu",
            "Qunshu Lin",
            "Raven Yuan",
            "Tuney Zheng",
            "Wei Pang",
            "Xinrun Du",
            "Yiming Liang",
            "Yinghao Ma",
            "Yizhi Li",
            "Ziyang Ma",
            "Bill Lin",
            "Emmanouil Benetos",
            "Huan Yang",
            "Junting Zhou",
            "Kaijing Ma",
            "Minghao Liu",
            "Morry Niu",
            "Noah Wang",
            "Quehry Que",
            "Ruibo Liu",
            "Sine Liu",
            "Shawn Guo",
            "Soren Gao",
            "Wangchunshu Zhou",
            "Xinyue Zhang",
            "Yizhi Zhou",
            "Yubo Wang",
            "Yuelin Bai",
            "Yuhan Zhang",
            "Yuxiang Zhang",
            "Zenith Wang",
            "Zhenzhu Yang",
            "Zijian Zhao",
            "Jiajun Zhang",
            "Wanli Ouyang",
            "Wenhao Huang",
            "Wenhu Chen"
        ],
        "published": "2024-05-29T17:57:16Z"
    },
    {
        "title": "Video Anomaly Detection in 10 Years: A Survey and Outlook",
        "link": "http://arxiv.org/abs/2405.19387v1",
        "abstract": "Video anomaly detection (VAD) holds immense importance across diverse domains\nsuch as surveillance, healthcare, and environmental monitoring. While numerous\nsurveys focus on conventional VAD methods, they often lack depth in exploring\nspecific approaches and emerging trends. This survey explores deep\nlearning-based VAD, expanding beyond traditional supervised training paradigms\nto encompass emerging weakly supervised, self-supervised, and unsupervised\napproaches. A prominent feature of this review is the investigation of core\nchallenges within the VAD paradigms including large-scale datasets, features\nextraction, learning methods, loss functions, regularization, and anomaly score\nprediction. Moreover, this review also investigates the vision language models\n(VLMs) as potent feature extractors for VAD. VLMs integrate visual data with\ntextual descriptions or spoken language from videos, enabling a nuanced\nunderstanding of scenes crucial for anomaly detection. By addressing these\nchallenges and proposing future research directions, this review aims to foster\nthe development of robust and efficient VAD systems leveraging the capabilities\nof VLMs for enhanced anomaly detection in complex real-world scenarios. This\ncomprehensive analysis seeks to bridge existing knowledge gaps, provide\nresearchers with valuable insights, and contribute to shaping the future of VAD\nresearch.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Moshira Abdalla",
            "Sajid Javed",
            "Muaz Al Radi",
            "Anwaar Ulhaq",
            "Naoufel Werghi"
        ],
        "published": "2024-05-29T17:56:31Z"
    },
    {
        "title": "Reasoning3D -- Grounding and Reasoning in 3D: Fine-Grained Zero-Shot\n  Open-Vocabulary 3D Reasoning Part Segmentation via Large Vision-Language\n  Models",
        "link": "http://arxiv.org/abs/2405.19326v1",
        "abstract": "In this paper, we introduce a new task: Zero-Shot 3D Reasoning Segmentation\nfor parts searching and localization for objects, which is a new paradigm to 3D\nsegmentation that transcends limitations for previous category-specific 3D\nsemantic segmentation, 3D instance segmentation, and open-vocabulary 3D\nsegmentation. We design a simple baseline method, Reasoning3D, with the\ncapability to understand and execute complex commands for (fine-grained)\nsegmenting specific parts for 3D meshes with contextual awareness and reasoned\nanswers for interactive segmentation. Specifically, Reasoning3D leverages an\noff-the-shelf pre-trained 2D segmentation network, powered by Large Language\nModels (LLMs), to interpret user input queries in a zero-shot manner. Previous\nresearch have shown that extensive pre-training endows foundation models with\nprior world knowledge, enabling them to comprehend complex commands, a\ncapability we can harness to \"segment anything\" in 3D with limited 3D datasets\n(source efficient). Experimentation reveals that our approach is generalizable\nand can effectively localize and highlight parts of 3D objects (in 3D mesh)\nbased on implicit textual queries, including these articulated 3d objects and\nreal-world scanned data. Our method can also generate natural language\nexplanations corresponding to these 3D models and the decomposition. Moreover,\nour training-free approach allows rapid deployment and serves as a viable\nuniversal baseline for future research of part-level 3d (semantic) object\nunderstanding in various fields including robotics, object manipulation, part\nassembly, autonomous driving applications, augment reality and virtual reality\n(AR/VR), and medical applications. The code, the model weight, the deployment\nguide, and the evaluation protocol are: http://tianrun-chen.github.io/Reason3D/",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "cs.HC"
        ],
        "authors": [
            "Tianrun Chen",
            "Chunan Yu",
            "Jing Li",
            "Jianqi Zhang",
            "Lanyun Zhu",
            "Deyi Ji",
            "Yong Zhang",
            "Ying Zang",
            "Zejian Li",
            "Lingyun Sun"
        ],
        "published": "2024-05-29T17:56:07Z"
    },
    {
        "title": "Nearest Neighbor Speculative Decoding for LLM Generation and Attribution",
        "link": "http://arxiv.org/abs/2405.19325v1",
        "abstract": "Large language models (LLMs) often hallucinate and lack the ability to\nprovide attribution for their generations. Semi-parametric LMs, such as kNN-LM,\napproach these limitations by refining the output of an LM for a given prompt\nusing its nearest neighbor matches in a non-parametric data store. However,\nthese models often exhibit slow inference speeds and produce non-fluent texts.\nIn this paper, we introduce Nearest Neighbor Speculative Decoding (NEST), a\nnovel semi-parametric language modeling approach that is capable of\nincorporating real-world text spans of arbitrary length into the LM generations\nand providing attribution to their sources. NEST performs token-level retrieval\nat each inference step to compute a semi-parametric mixture distribution and\nidentify promising span continuations in a corpus. It then uses an approximate\nspeculative decoding procedure that accepts a prefix of the retrieved span or\ngenerates a new token. NEST significantly enhances the generation quality and\nattribution rate of the base LM across a variety of knowledge-intensive tasks,\nsurpassing the conventional kNN-LM method and performing competitively with\nin-context retrieval augmentation. In addition, NEST substantially improves the\ngeneration speed, achieving a 1.8x speedup in inference time when applied to\nLlama-2-Chat 70B.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Minghan Li",
            "Xilun Chen",
            "Ari Holtzman",
            "Beidi Chen",
            "Jimmy Lin",
            "Wen-tau Yih",
            "Xi Victoria Lin"
        ],
        "published": "2024-05-29T17:55:03Z"
    },
    {
        "title": "Are Large Language Models Chameleons?",
        "link": "http://arxiv.org/abs/2405.19323v1",
        "abstract": "Do large language models (LLMs) have their own worldviews and personality\ntendencies? Simulations in which an LLM was asked to answer subjective\nquestions were conducted more than 1 million times. Comparison of the responses\nfrom different LLMs with real data from the European Social Survey (ESS)\nsuggests that the effect of prompts on bias and variability is fundamental,\nhighlighting major cultural, age, and gender biases. Methods for measuring the\ndifference between LLMs and survey data are discussed, such as calculating\nweighted means and a new proposed measure inspired by Jaccard similarity. We\nconclude that it is important to analyze the robustness and variability of\nprompts before using LLMs to model individual decisions or collective behavior,\nas their imitation abilities are approximate at best.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CY",
            "cs.LG"
        ],
        "authors": [
            "Mingmeng Geng",
            "Sihong He",
            "Roberto Trotta"
        ],
        "published": "2024-05-29T17:54:22Z"
    },
    {
        "title": "DGD: Dynamic 3D Gaussians Distillation",
        "link": "http://arxiv.org/abs/2405.19321v1",
        "abstract": "We tackle the task of learning dynamic 3D semantic radiance fields given a\nsingle monocular video as input. Our learned semantic radiance field captures\nper-point semantics as well as color and geometric properties for a dynamic 3D\nscene, enabling the generation of novel views and their corresponding\nsemantics. This enables the segmentation and tracking of a diverse set of 3D\nsemantic entities, specified using a simple and intuitive interface that\nincludes a user click or a text prompt. To this end, we present DGD, a unified\n3D representation for both the appearance and semantics of a dynamic 3D scene,\nbuilding upon the recently proposed dynamic 3D Gaussians representation. Our\nrepresentation is optimized over time with both color and semantic information.\nKey to our method is the joint optimization of the appearance and semantic\nattributes, which jointly affect the geometric properties of the scene. We\nevaluate our approach in its ability to enable dense semantic 3D object\ntracking and demonstrate high-quality results that are fast to render, for a\ndiverse set of scenes. Our project webpage is available on\nhttps://isaaclabe.github.io/DGD-Website/",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Isaac Labe",
            "Noam Issachar",
            "Itai Lang",
            "Sagie Benaim"
        ],
        "published": "2024-05-29T17:52:22Z"
    },
    {
        "title": "Value-Incentivized Preference Optimization: A Unified Approach to Online\n  and Offline RLHF",
        "link": "http://arxiv.org/abs/2405.19320v1",
        "abstract": "Reinforcement learning from human feedback (RLHF) has demonstrated great\npromise in aligning large language models (LLMs) with human preference.\nDepending on the availability of preference data, both online and offline RLHF\nare active areas of investigation. A key bottleneck is understanding how to\nincorporate uncertainty estimation in the reward function learned from the\npreference data for RLHF, regardless of how the preference data is collected.\nWhile the principles of optimism or pessimism under uncertainty are\nwell-established in standard reinforcement learning (RL), a\npractically-implementable and theoretically-grounded form amenable to large\nlanguage models is not yet available, as standard techniques for constructing\nconfidence intervals become intractable under arbitrary policy\nparameterizations.\n  In this paper, we introduce a unified approach to online and offline RLHF --\nvalue-incentivized preference optimization (VPO) -- which regularizes the\nmaximum-likelihood estimate of the reward function with the corresponding value\nfunction, modulated by a $\\textit{sign}$ to indicate whether the optimism or\npessimism is chosen. VPO also directly optimizes the policy with implicit\nreward modeling, and therefore shares a simpler RLHF pipeline similar to direct\npreference optimization. Theoretical guarantees of VPO are provided for both\nonline and offline settings, matching the rates of their standard RL\ncounterparts. Moreover, experiments on text summarization and dialog verify the\npracticality and effectiveness of VPO.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Shicong Cen",
            "Jincheng Mei",
            "Katayoon Goshvadi",
            "Hanjun Dai",
            "Tong Yang",
            "Sherry Yang",
            "Dale Schuurmans",
            "Yuejie Chi",
            "Bo Dai"
        ],
        "published": "2024-05-29T17:51:42Z"
    },
    {
        "title": "Adaptive Generalized Neyman Allocation: Local Asymptotic Minimax Optimal\n  Best Arm Identification",
        "link": "http://arxiv.org/abs/2405.19317v1",
        "abstract": "This study investigates a local asymptotic minimax optimal strategy for\nfixed-budget best arm identification (BAI). We propose the Adaptive Generalized\nNeyman Allocation (AGNA) strategy and show that its worst-case upper bound of\nthe probability of misidentifying the best arm aligns with the worst-case lower\nbound under the small-gap regime, where the gap between the expected outcomes\nof the best and suboptimal arms is small. Our strategy corresponds to a\ngeneralization of the Neyman allocation for two-armed bandits (Neyman, 1934;\nKaufmann et al., 2016) and a refinement of existing strategies such as the ones\nproposed by Glynn & Juneja (2004) and Shin et al. (2018). Compared to Komiyama\net al. (2022), which proposes a minimax rate-optimal strategy, our proposed\nstrategy has a tighter upper bound that exactly matches the lower bound,\nincluding the constant terms, by restricting the class of distributions to the\nclass of small-gap distributions. Our result contributes to the longstanding\nopen issue about the existence of asymptotically optimal strategies in\nfixed-budget BAI, by presenting the local asymptotic minimax optimal strategy.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "econ.EM",
            "stat.ME",
            "stat.ML"
        ],
        "authors": [
            "Masahiro Kato"
        ],
        "published": "2024-05-29T17:43:13Z"
    },
    {
        "title": "Robust Preference Optimization through Reward Model Distillation",
        "link": "http://arxiv.org/abs/2405.19316v1",
        "abstract": "Language model (LM) post-training (or alignment) involves maximizing a reward\nfunction that is derived from preference annotations. Direct Preference\nOptimization (DPO) is a popular offline alignment method that trains a policy\ndirectly on preference data without the need to train a reward model or apply\nreinforcement learning. However, typical preference datasets have only a\nsingle, or at most a few, annotation per preference pair, which causes DPO to\noverconfidently assign rewards that trend towards infinite magnitude. This\nfrequently leads to degenerate policies, sometimes causing even the\nprobabilities of the preferred generations to go to zero. In this work, we\nanalyze this phenomenon and propose distillation to get a better proxy for the\ntrue preference distribution over generation pairs: we train the LM to produce\nprobabilities that match the distribution induced by a reward model trained on\nthe preference data. Moreover, to account for uncertainty in the reward model\nwe are distilling from, we optimize against a family of reward models that, as\na whole, is likely to include at least one reasonable proxy for the preference\ndistribution. Our results show that distilling from such a family of reward\nmodels leads to improved robustness to distribution shift in preference\nannotations, while preserving the simple supervised nature of DPO.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "authors": [
            "Adam Fisch",
            "Jacob Eisenstein",
            "Vicky Zayats",
            "Alekh Agarwal",
            "Ahmad Beirami",
            "Chirag Nagpal",
            "Pete Shaw",
            "Jonathan Berant"
        ],
        "published": "2024-05-29T17:39:48Z"
    },
    {
        "title": "Matryoshka Query Transformer for Large Vision-Language Models",
        "link": "http://arxiv.org/abs/2405.19315v1",
        "abstract": "Large Vision-Language Models (LVLMs) typically encode an image into a fixed\nnumber of visual tokens (e.g., 576) and process these tokens with a language\nmodel. Despite their strong performance, LVLMs face challenges in adapting to\nvarying computational constraints. This raises the question: can we achieve\nflexibility in the number of visual tokens to suit different tasks and\ncomputational resources? We answer this with an emphatic yes. Inspired by\nMatryoshka Representation Learning, we introduce the Matryoshka Query\nTransformer (MQT), capable of encoding an image into m visual tokens during\ninference, where m can be any number up to a predefined maximum. This is\nachieved by employing a query transformer with M latent query tokens to\ncompress the visual embeddings. During each training step, we randomly select m\n<= M latent query tokens and train the model using only these first m tokens,\ndiscarding the rest. Combining MQT with LLaVA, we train a single model once,\nand flexibly and drastically reduce the number of inference-time visual tokens\nwhile maintaining similar or better performance compared to training\nindependent models for each number of tokens. Our model, MQT-LLAVA, matches\nLLaVA-1.5 performance across 11 benchmarks using a maximum of 256 tokens\ninstead of LLaVA's fixed 576. Reducing to 16 tokens (8x less TFLOPs) only\nsacrifices the performance by 2.4 points on MMBench. On certain tasks such as\nScienceQA and MMMU, we can even go down to only 2 visual tokens with\nperformance drops of just 3% and 6% each. Our exploration of the trade-off\nbetween the accuracy and computational cost brought about by the number of\nvisual tokens facilitates future research to achieve the best of both worlds.",
        "subjects": [
            "cs.CV",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Wenbo Hu",
            "Zi-Yi Dou",
            "Liunian Harold Li",
            "Amita Kamath",
            "Nanyun Peng",
            "Kai-Wei Chang"
        ],
        "published": "2024-05-29T17:39:42Z"
    },
    {
        "title": "Language Models Trained to do Arithmetic Predict Human Risky and\n  Intertemporal Choice",
        "link": "http://arxiv.org/abs/2405.19313v1",
        "abstract": "The observed similarities in the behavior of humans and Large Language Models\n(LLMs) have prompted researchers to consider the potential of using LLMs as\nmodels of human cognition. However, several significant challenges must be\naddressed before LLMs can be legitimately regarded as cognitive models. For\ninstance, LLMs are trained on far more data than humans typically encounter,\nand may have been directly trained on human data in specific cognitive tasks or\naligned with human preferences. Consequently, the origins of these behavioral\nsimilarities are not well understood. In this paper, we propose a novel way to\nenhance the utility of LLMs as cognitive models. This approach involves (i)\nleveraging computationally equivalent tasks that both an LLM and a rational\nagent need to master for solving a cognitive problem and (ii) examining the\nspecific task distributions required for an LLM to exhibit human-like\nbehaviors. We apply this approach to decision-making -- specifically risky and\nintertemporal choice -- where the key computationally equivalent task is the\narithmetic of expected value calculations. We show that an LLM pretrained on an\necologically valid arithmetic dataset, which we call Arithmetic-GPT, predicts\nhuman behavior better than many traditional cognitive models. Pretraining LLMs\non ecologically valid arithmetic datasets is sufficient to produce a strong\ncorrespondence between these models and human decision-making. Our results also\nsuggest that LLMs used as cognitive models should be carefully investigated via\nablation studies of the pretraining data.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "econ.GN",
            "q-fin.EC"
        ],
        "authors": [
            "Jian-Qiao Zhu",
            "Haijiang Yan",
            "Thomas L. Griffiths"
        ],
        "published": "2024-05-29T17:37:14Z"
    },
    {
        "title": "Network Connectivity--Information Freshness Tradeoff in Information\n  Dissemination Over Networks",
        "link": "http://arxiv.org/abs/2405.19310v1",
        "abstract": "We consider a gossip network consisting of a source generating updates and\n$n$ nodes connected according to a given graph structure. The source keeps\nupdates of a process, that might be generated or observed, and shares them with\nthe gossiping network. The nodes in the network communicate with their\nneighbors and disseminate these version updates using a push-style gossip\nstrategy. We use the version age metric to quantify the timeliness of\ninformation at the nodes. We first find an upper bound for the average version\nage for a set of nodes in a general network. Using this, we find the average\nversion age scaling of a node in several network graph structures, such as\ntwo-dimensional grids, generalized rings and hyper-cubes. Prior to our work, it\nwas known that when $n$ nodes are connected on a ring the version age scales as\n$O(n^{\\frac{1}{2}})$, and when they are connected on a fully-connected graph\nthe version age scales as $O(\\log n)$. Ours is the first work to show an age\nscaling result for a connectivity structure other than the ring and the\nfully-connected network, which constitute the two extremes of network\nconnectivity. Our work helps fill the gap between these two extremes by\nanalyzing a large variety of graphs with intermediate connectivity, thus\nproviding insight into the relationship between the connectivity structure of\nthe network and the version age, and uncovering a network\nconnectivity--information freshness tradeoff.",
        "subjects": [
            "cs.IT",
            "cs.NI",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Arunabh Srivastava",
            "Sennur Ulukus"
        ],
        "published": "2024-05-29T17:35:46Z"
    },
    {
        "title": "SDPRLayers: Certifiable Backpropagation Through Polynomial Optimization\n  Problems in Robotics",
        "link": "http://arxiv.org/abs/2405.19309v1",
        "abstract": "Differentiable optimization is a powerful new paradigm capable of reconciling\nmodel-based and learning-based approaches in robotics. However, the majority of\nrobotics optimization problems are non-convex and current differentiable\noptimization techniques are therefore prone to convergence to local minima.\nWhen this occurs, the gradients provided by these existing solvers can be\nwildly inaccurate and will ultimately corrupt the training process. On the\nother hand, any non-convex robotics problems can be framed as polynomial\noptimization problems and, in turn, admit convex relaxations that can be used\nto recover a global solution via so-called certifiably correct methods. We\npresent SDPRLayers, an approach that leverages these methods as well as\nstate-of-the-art convex implicit differentiation techniques to provide\ncertifiably correct gradients throughout the training process. We introduce\nthis approach and showcase theoretical results that provide conditions under\nwhich correctness of the gradients is guaranteed. We demonstrate our approach\non two simple-but-demonstrative simulated examples, which expose the potential\npitfalls of existing, state-of-the-art, differentiable optimization methods. We\napply our method in a real-world application: we train a deep neural network to\ndetect image keypoints for robot localization in challenging lighting\nconditions. An open-source, PyTorch implementation of SDPRLayers will be made\navailable upon paper acceptance.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Connor Holmes",
            "Frederike Dmbgen",
            "Timothy D. Barfoot"
        ],
        "published": "2024-05-29T17:33:34Z"
    },
    {
        "title": "Data Efficient Behavior Cloning for Fine Manipulation via\n  Continuity-based Corrective Labels",
        "link": "http://arxiv.org/abs/2405.19307v1",
        "abstract": "We consider imitation learning with access only to expert demonstrations,\nwhose real-world application is often limited by covariate shift due to\ncompounding errors during execution. We investigate the effectiveness of the\nContinuity-based Corrective Labels for Imitation Learning (CCIL) framework in\nmitigating this issue for real-world fine manipulation tasks. CCIL generates\ncorrective labels by learning a locally continuous dynamics model from\ndemonstrations to guide the agent back toward expert states. Through extensive\nexperiments on peg insertion and fine grasping, we provide the first empirical\nvalidation that CCIL can significantly improve imitation learning performance\ndespite discontinuities present in contact-rich manipulation. We find that: (1)\nreal-world manipulation exhibits sufficient local smoothness to apply CCIL, (2)\ngenerated corrective labels are most beneficial in low-data regimes, and (3)\nlabel filtering based on estimated dynamics model error enables performance\ngains. To effectively apply CCIL to robotic domains, we offer a practical\ninstantiation of the framework and insights into design choices and\nhyperparameter selection. Our work demonstrates CCIL's practicality for\nalleviating compounding errors in imitation learning on physical robots.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Abhay Deshpande",
            "Liyiming Ke",
            "Quinn Pfeifer",
            "Abhishek Gupta",
            "Siddhartha S. Srinivasa"
        ],
        "published": "2024-05-29T17:31:25Z"
    },
    {
        "title": "Real-Time Environment Condition Classification for Autonomous Vehicles",
        "link": "http://arxiv.org/abs/2405.19305v1",
        "abstract": "Current autonomous driving technologies are being rolled out in geo-fenced\nareas with well-defined operation conditions such as time of operation, area,\nweather conditions and road conditions. In this way, challenging conditions as\nadverse weather, slippery road or densely-populated city centers can be\nexcluded. In order to lift the geo-fenced restriction and allow a more dynamic\navailability of autonomous driving functions, it is necessary for the vehicle\nto autonomously perform an environment condition assessment in real time to\nidentify when the system cannot operate safely and either stop operation or\nrequire the resting passenger to take control. In particular, adverse-weather\nchallenges are a fundamental limitation as sensor performance degenerates\nquickly, prohibiting the use of sensors such as cameras to locate and monitor\nroad signs, pedestrians or other vehicles. To address this issue, we train a\ndeep learning model to identify outdoor weather and dangerous road conditions,\nenabling a quick reaction to new situations and environments. We achieve this\nby introducing an improved taxonomy and label hierarchy for a state-of-the-art\nadverse-weather dataset, relabelling it with a novel semi-automated labeling\npipeline. Using the novel proposed dataset and hierarchy, we train RECNet, a\ndeep learning model for the classification of environment conditions from a\nsingle RGB frame. We outperform baseline models by relative 16% in F1- Score,\nwhile maintaining a real-time capable performance of 20 Hz.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Marco Introvigne",
            "Andrea Ramazzina",
            "Stefanie Walz",
            "Dominik Scheuble",
            "Mario Bijelic"
        ],
        "published": "2024-05-29T17:29:55Z"
    },
    {
        "title": "Set Descriptive Complexity of Solvable Functions",
        "link": "http://arxiv.org/abs/2405.19304v1",
        "abstract": "In a recent article, we introduced and studied a precise class of dynamical\nsystems called solvable systems. These systems present a dynamic ruled by\ndiscontinuous ordinary differential equations with solvable right-hand terms\nand unique evolution. They correspond to a class of systems for which a\ntransfinite method exist to compute the solution. We also presented several\nexamples including a nontrivial one whose solution yields, at an integer time,\na real encoding of the halting set for Turing machines; therefore showcasing\nthat the behavior of solvable systems might describe ordinal Turing\ncomputations. In the current article, we study in more depth solvable systems,\nusing tools from descriptive set theory. By establishing a correspondence with\nthe class of well-founded trees, we construct a coanalytic ranking over the set\nof solvable functions and discuss its relation with other existing rankings for\ndifferentiable functions, in particular with the Kechris-Woodin, Denjoy and\nZalcwasser ranking. We prove that our ranking is unbounded below the first\nuncountable ordinal.",
        "subjects": [
            "cs.CC",
            "cs.LO",
            "math.DS"
        ],
        "authors": [
            "Gozzi Riccardo",
            "Bournez Olivier"
        ],
        "published": "2024-05-29T17:29:54Z"
    },
    {
        "title": "Safe and Efficient Estimation for Robotics through the Optimal Use of\n  Resources",
        "link": "http://arxiv.org/abs/2405.19301v1",
        "abstract": "In order to operate in and interact with the physical world, robots need to\nhave estimates of the current and future state of the environment. We thus\nequip robots with sensors and build models and algorithms that, given some\nmeasurements, produce estimates of the current or future states. Environments\ncan be unpredictable and sensors are not perfect. Therefore, it is important to\nboth use all information available, and to do so optimally: making sure that we\nget the best possible answer from the amount of information we have. However,\nin prevalent research, uncommon sensors, such as sound or radio-frequency\nsignals, are commonly ignored for state estimation; and the most popular\nsolvers employed to produce state estimates are only of local nature, meaning\nthey may produce suboptimal estimates for the typically non-convex estimation\nproblems. My research aims to use resources more optimally, by building on 1)\nmulti-modality: using ubiquitous RF transceivers and microphones to support\nstate estimation, 2) building certifiably optimal solvers and 3) learning and\nimproving adequate models from data.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Frederike Dmbgen"
        ],
        "published": "2024-05-29T17:27:30Z"
    },
    {
        "title": "Measuring and Mitigating Bias for Tabular Datasets with Multiple\n  Protected Attributes",
        "link": "http://arxiv.org/abs/2405.19300v1",
        "abstract": "Motivated by the recital (67) of the current corrigendum of the AI Act in the\nEuropean Union, we propose and present measures and mitigation strategies for\ndiscrimination in tabular datasets. We specifically focus on datasets that\ncontain multiple protected attributes, such as nationality, age, and sex. This\nmakes measuring and mitigating bias more challenging, as many existing methods\nare designed for a single protected attribute. This paper comes with a twofold\ncontribution: Firstly, new discrimination measures are introduced. These\nmeasures are categorized in our framework along with existing ones, guiding\nresearchers and practitioners in choosing the right measure to assess the\nfairness of the underlying dataset. Secondly, a novel application of an\nexisting bias mitigation method, FairDo, is presented. We show that this\nstrategy can mitigate any type of discrimination, including intersectional\ndiscrimination, by transforming the dataset. By conducting experiments on\nreal-world datasets (Adult, Bank, Compas), we demonstrate that de-biasing\ndatasets with multiple protected attributes is achievable. Further, the\ntransformed fair datasets do not compromise any of the tested machine learning\nmodels' performances significantly when trained on these datasets compared to\nthe original datasets. Discrimination was reduced by up to 83% in our\nexperimentation. For most experiments, the disparity between protected groups\nwas reduced by at least 7% and 27% on average. Generally, the findings show\nthat the mitigation strategy used is effective, and this study contributes to\nthe ongoing discussion on the implementation of the European Union's AI Act.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Manh Khoi Duong",
            "Stefan Conrad"
        ],
        "published": "2024-05-29T17:27:08Z"
    },
    {
        "title": "Expert-Guided Extinction of Toxic Tokens for Debiased Generation",
        "link": "http://arxiv.org/abs/2405.19299v1",
        "abstract": "Large language models (LLMs) can elicit social bias during generations,\nespecially when inference with toxic prompts. Controlling the sensitive\nattributes in generation encounters challenges in data distribution,\ngeneralizability, and efficiency. Specifically, fine-tuning and retrieval\ndemand extensive unbiased corpus, while direct prompting requires meticulously\ncurated instructions for correcting the output in multiple rounds of thoughts\nbut poses challenges on memory and inference latency. In this work, we propose\nthe Expert-Guided Extinction of Toxic Tokens for Debiased Generation (EXPOSED)\nto eliminate the undesired harmful outputs for LLMs without the aforementioned\nrequirements. EXPOSED constructs a debiasing expert based on the abundant toxic\ncorpus to expose and elicit the potentially dangerous tokens. It then processes\nthe output to the LLMs and constructs a fair distribution by suppressing and\nattenuating the toxic tokens. EXPOSED is evaluated on fairness benchmarks over\nthree LLM families. Extensive experiments demonstrate that compared with other\nbaselines, the proposed EXPOSED significantly reduces the potential social bias\nwhile balancing fairness and generation performance.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Xueyao Sun",
            "Kaize Shi",
            "Haoran Tang",
            "Guandong Xu",
            "Qing Li"
        ],
        "published": "2024-05-29T17:26:52Z"
    },
    {
        "title": "Adaptive Image Quality Assessment via Teaching Large Multimodal Model to\n  Compare",
        "link": "http://arxiv.org/abs/2405.19298v1",
        "abstract": "While recent advancements in large multimodal models (LMMs) have\nsignificantly improved their abilities in image quality assessment (IQA)\nrelying on absolute quality rating, how to transfer reliable relative quality\ncomparison outputs to continuous perceptual quality scores remains largely\nunexplored. To address this gap, we introduce Compare2Score-an all-around\nLMM-based no-reference IQA (NR-IQA) model, which is capable of producing\nqualitatively comparative responses and effectively translating these discrete\ncomparative levels into a continuous quality score. Specifically, during\ntraining, we present to generate scaled-up comparative instructions by\ncomparing images from the same IQA dataset, allowing for more flexible\nintegration of diverse IQA datasets. Utilizing the established large-scale\ntraining corpus, we develop a human-like visual quality comparator. During\ninference, moving beyond binary choices, we propose a soft comparison method\nthat calculates the likelihood of the test image being preferred over multiple\npredefined anchor images. The quality score is further optimized by maximum a\nposteriori estimation with the resulting probability matrix. Extensive\nexperiments on nine IQA datasets validate that the Compare2Score effectively\nbridges text-defined comparative levels during training with converted single\nimage quality score for inference, surpassing state-of-the-art IQA models\nacross diverse scenarios. Moreover, we verify that the probability-matrix-based\ninference conversion not only improves the rating accuracy of Compare2Score but\nalso zero-shot general-purpose LMMs, suggesting its intrinsic effectiveness.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Hanwei Zhu",
            "Haoning Wu",
            "Yixuan Li",
            "Zicheng Zhang",
            "Baoliang Chen",
            "Lingyu Zhu",
            "Yuming Fang",
            "Guangtao Zhai",
            "Weisi Lin",
            "Shiqi Wang"
        ],
        "published": "2024-05-29T17:26:09Z"
    },
    {
        "title": "Neural Isometries: Taming Transformations for Equivariant ML",
        "link": "http://arxiv.org/abs/2405.19296v1",
        "abstract": "Real-world geometry and 3D vision tasks are replete with challenging\nsymmetries that defy tractable analytical expression. In this paper, we\nintroduce Neural Isometries, an autoencoder framework which learns to map the\nobservation space to a general-purpose latent space wherein encodings are\nrelated by isometries whenever their corresponding observations are\ngeometrically related in world space. Specifically, we regularize the latent\nspace such that maps between encodings preserve a learned inner product and\ncommute with a learned functional operator, in the same manner as rigid-body\ntransformations commute with the Laplacian. This approach forms an effective\nbackbone for self-supervised representation learning, and we demonstrate that a\nsimple off-the-shelf equivariant network operating in the pre-trained latent\nspace can achieve results on par with meticulously-engineered, handcrafted\nnetworks designed to handle complex, nonlinear symmetries. Furthermore,\nisometric maps capture information about the respective transformations in\nworld space, and we show that this allows us to regress camera poses directly\nfrom the coefficients of the maps between encodings of adjacent views of a\nscene.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR",
            "cs.LG"
        ],
        "authors": [
            "Thomas W. Mitchel",
            "Michael Taylor",
            "Vincent Sitzmann"
        ],
        "published": "2024-05-29T17:24:25Z"
    },
    {
        "title": "3D Neural Edge Reconstruction",
        "link": "http://arxiv.org/abs/2405.19295v1",
        "abstract": "Real-world objects and environments are predominantly composed of edge\nfeatures, including straight lines and curves. Such edges are crucial elements\nfor various applications, such as CAD modeling, surface meshing, lane mapping,\netc. However, existing traditional methods only prioritize lines over curves\nfor simplicity in geometric modeling. To this end, we introduce EMAP, a new\nmethod for learning 3D edge representations with a focus on both lines and\ncurves. Our method implicitly encodes 3D edge distance and direction in\nUnsigned Distance Functions (UDF) from multi-view edge maps. On top of this\nneural representation, we propose an edge extraction algorithm that robustly\nabstracts parametric 3D edges from the inferred edge points and their\ndirections. Comprehensive evaluations demonstrate that our method achieves\nbetter 3D edge reconstruction on multiple challenging datasets. We further show\nthat our learned UDF field enhances neural surface reconstruction by capturing\nmore details.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Lei Li",
            "Songyou Peng",
            "Zehao Yu",
            "Shaohui Liu",
            "Rmi Pautrat",
            "Xiaochuan Yin",
            "Marc Pollefeys"
        ],
        "published": "2024-05-29T17:23:51Z"
    },
    {
        "title": "Act Natural! Projecting Autonomous System Trajectories Into Naturalistic\n  Behavior Sets",
        "link": "http://arxiv.org/abs/2405.19292v1",
        "abstract": "Autonomous agents operating around human actors must consider how their\nbehaviors might affect those humans, even when not directly interacting with\nthem. To this end, it is often beneficial to be predictable and appear\nnaturalistic. Existing methods to address this problem use human actor intent\nmodeling or imitation learning techniques, but these approaches rarely capture\nall possible motivations for human behavior or require significant amounts of\ndata. In contrast, we propose a technique for modeling naturalistic behavior as\na set of convex hulls computed over a relatively small dataset of human\nbehavior. Given this set, we design an optimization-based filter which projects\narbitrary trajectories into it to make them more naturalistic for autonomous\nagents to execute while also satisfying dynamics constraints. We demonstrate\nour methods on real-world human driving data from the inD intersection dataset\n(Bock et al., 2020).",
        "subjects": [
            "cs.MA"
        ],
        "authors": [
            "Hamzah I. Khan",
            "Adam J. Thorpe",
            "David Fridovich-Keil"
        ],
        "published": "2024-05-29T17:21:25Z"
    },
    {
        "title": "Grasp as You Say: Language-guided Dexterous Grasp Generation",
        "link": "http://arxiv.org/abs/2405.19291v1",
        "abstract": "This paper explores a novel task \"\"Dexterous Grasp as You Say\"\" (DexGYS),\nenabling robots to perform dexterous grasping based on human commands expressed\nin natural language. However, the development of this field is hindered by the\nlack of datasets with natural human guidance; thus, we propose a\nlanguage-guided dexterous grasp dataset, named DexGYSNet, offering high-quality\ndexterous grasp annotations along with flexible and fine-grained human language\nguidance. Our dataset construction is cost-efficient, with the carefully-design\nhand-object interaction retargeting strategy, and the LLM-assisted language\nguidance annotation system. Equipped with this dataset, we introduce the\nDexGYSGrasp framework for generating dexterous grasps based on human language\ninstructions, with the capability of producing grasps that are intent-aligned,\nhigh quality and diversity. To achieve this capability, our framework\ndecomposes the complex learning process into two manageable progressive\nobjectives and introduce two components to realize them. The first component\nlearns the grasp distribution focusing on intention alignment and generation\ndiversity. And the second component refines the grasp quality while maintaining\nintention consistency. Extensive experiments are conducted on DexGYSNet and\nreal world environment for validation.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Yi-Lin Wei",
            "Jian-Jian Jiang",
            "Chengyi Xing",
            "Xiantuo Tan",
            "Xiao-Ming Wu",
            "Hao Li",
            "Mark Cutkosky",
            "Wei-Shi Zheng"
        ],
        "published": "2024-05-29T17:19:15Z"
    },
    {
        "title": "Integrating Multi-scale Contextualized Information for Byte-based Neural\n  Machine Translation",
        "link": "http://arxiv.org/abs/2405.19290v1",
        "abstract": "Subword tokenization is a common method for vocabulary building in Neural\nMachine Translation (NMT) models. However, increasingly complex tasks have\nrevealed its disadvantages. First, a vocabulary cannot be modified once it is\nlearned, making it hard to adapt to new words. Second, in multilingual\ntranslation, the imbalance in data volumes across different languages spreads\nto the vocabulary, exacerbating translations involving low-resource languages.\nWhile byte-based tokenization addresses these issues, byte-based models\nstruggle with the low information density inherent in UTF-8 byte sequences.\nPrevious works enhance token semantics through local contextualization but fail\nto select an appropriate contextualizing scope based on the input.\nConsequently, we propose the Multi-Scale Contextualization (MSC) method, which\nlearns contextualized information of varying scales across different hidden\nstate dimensions. It then leverages the attention module to dynamically\nintegrate the multi-scale contextualized information. Experiments show that MSC\nsignificantly outperforms subword-based and other byte-based methods in both\nmultilingual and out-of-domain scenarios. Code can be found in\nhttps://github.com/ictnlp/Multiscale-Contextualization.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Langlin Huang",
            "Yang Feng"
        ],
        "published": "2024-05-29T17:19:04Z"
    },
    {
        "title": "MASSIVE Multilingual Abstract Meaning Representation: A Dataset and\n  Baselines for Hallucination Detection",
        "link": "http://arxiv.org/abs/2405.19285v1",
        "abstract": "Abstract Meaning Representation (AMR) is a semantic formalism that captures\nthe core meaning of an utterance. There has been substantial work developing\nAMR corpora in English and more recently across languages, though the limited\nsize of existing datasets and the cost of collecting more annotations are\nprohibitive. With both engineering and scientific questions in mind, we\nintroduce MASSIVE-AMR, a dataset with more than 84,000 text-to-graph\nannotations, currently the largest and most diverse of its kind: AMR graphs for\n1,685 information-seeking utterances mapped to 50+ typologically diverse\nlanguages. We describe how we built our resource and its unique features before\nreporting on experiments using large language models for multilingual AMR and\nSPARQL parsing as well as applying AMRs for hallucination detection in the\ncontext of knowledge base question answering, with results shedding light on\npersistent issues using LLMs for structured parsing.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Michael Regan",
            "Shira Wein",
            "George Baker",
            "Emilio Monti"
        ],
        "published": "2024-05-29T17:17:22Z"
    },
    {
        "title": "Optimizing Foundation Model Inference on a Many-tiny-core Open-source\n  RISC-V Platform",
        "link": "http://arxiv.org/abs/2405.19284v1",
        "abstract": "Transformer-based foundation models have become crucial for various domains,\nmost notably natural language processing (NLP) or computer vision (CV). These\nmodels are predominantly deployed on high-performance GPUs or hardwired\naccelerators with highly customized, proprietary instruction sets. Until now,\nlimited attention has been given to RISC-V-based general-purpose platforms. In\nour work, we present the first end-to-end inference results of transformer\nmodels on an open-source many-tiny-core RISC-V platform implementing\ndistributed Softmax primitives and leveraging ISA extensions for SIMD\nfloating-point operand streaming and instruction repetition, as well as\nspecialized DMA engines to minimize costly main memory accesses and to tolerate\ntheir latency. We focus on two foundational transformer topologies,\nencoder-only and decoder-only models. For encoder-only models, we demonstrate a\nspeedup of up to 12.8x between the most optimized implementation and the\nbaseline version. We reach over 79% FPU utilization and 294 GFLOPS/W,\noutperforming State-of-the-Art (SoA) accelerators by more than 2x utilizing the\nHW platform while achieving comparable throughput per computational unit. For\ndecoder-only topologies, we achieve 16.1x speedup in the Non-Autoregressive\n(NAR) mode and up to 35.6x speedup in the Autoregressive (AR) mode compared to\nthe baseline implementation. Compared to the best SoA dedicated accelerator, we\nachieve 2.04x higher FPU utilization.",
        "subjects": [
            "cs.DC",
            "cs.AI",
            "cs.AR",
            "C.4; C.3; I.2"
        ],
        "authors": [
            "Viviane Potocnik",
            "Luca Colagrande",
            "Tim Fischer",
            "Luca Bertaccini",
            "Daniele Jahier Pagliari",
            "Alessio Burrello",
            "Luca Benini"
        ],
        "published": "2024-05-29T17:16:59Z"
    },
    {
        "title": "Programmable Motion Generation for Open-Set Motion Control Tasks",
        "link": "http://arxiv.org/abs/2405.19283v1",
        "abstract": "Character animation in real-world scenarios necessitates a variety of\nconstraints, such as trajectories, key-frames, interactions, etc. Existing\nmethodologies typically treat single or a finite set of these constraint(s) as\nseparate control tasks. They are often specialized, and the tasks they address\nare rarely extendable or customizable. We categorize these as solutions to the\nclose-set motion control problem. In response to the complexity of practical\nmotion control, we propose and attempt to solve the open-set motion control\nproblem. This problem is characterized by an open and fully customizable set of\nmotion control tasks. To address this, we introduce a new paradigm,\nprogrammable motion generation. In this paradigm, any given motion control task\nis broken down into a combination of atomic constraints. These constraints are\nthen programmed into an error function that quantifies the degree to which a\nmotion sequence adheres to them. We utilize a pre-trained motion generation\nmodel and optimize its latent code to minimize the error function of the\ngenerated motion. Consequently, the generated motion not only inherits the\nprior of the generative model but also satisfies the required constraints.\nExperiments show that we can generate high-quality motions when addressing a\nwide range of unseen tasks. These tasks encompass motion control by motion\ndynamics, geometric constraints, physical laws, interactions with scenes,\nobjects or the character own body parts, etc. All of these are achieved in a\nunified approach, without the need for ad-hoc paired training data collection\nor specialized network designs. During the programming of novel tasks, we\nobserved the emergence of new skills beyond those of the prior model. With the\nassistance of large language models, we also achieved automatic programming. We\nhope that this work will pave the way for the motion control of general AI\nagents.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hanchao Liu",
            "Xiaohang Zhan",
            "Shaoli Huang",
            "Tai-Jiang Mu",
            "Ying Shan"
        ],
        "published": "2024-05-29T17:14:55Z"
    },
    {
        "title": "Understanding and Minimising Outlier Features in Neural Network Training",
        "link": "http://arxiv.org/abs/2405.19279v1",
        "abstract": "Outlier Features (OF) are neurons whose activation magnitudes significantly\nexceed the average over a neural network's (NN) width. They are well known to\nemerge during standard transformer training and have the undesirable effect of\nhindering quantisation in afflicted models. Despite their practical importance,\nlittle is known behind why OFs emerge during training, nor how one can minimise\nthem.\n  Our work focuses on the above questions, first identifying several\nquantitative metrics, such as the kurtosis over neuron activation norms, to\nmeasure OFs. With these metrics, we study how architectural and optimisation\nchoices influence OFs, and provide practical insights to minimise OFs during\ntraining. As highlights, we emphasise the importance of controlling signal\npropagation throughout training, and propose the Outlier Protected transformer\nblock, which removes standard Pre-Norm layers to mitigate OFs, without loss of\nconvergence speed or training stability. Overall, our findings shed new light\non our understanding of, our ability to prevent, and the complexity of this\nimportant facet in NN training dynamics.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Bobby He",
            "Lorenzo Noci",
            "Daniele Paliotta",
            "Imanol Schlag",
            "Thomas Hofmann"
        ],
        "published": "2024-05-29T17:11:28Z"
    },
    {
        "title": "Deep Latent Variable Modeling of Physiological Signals",
        "link": "http://arxiv.org/abs/2405.19277v2",
        "abstract": "A deep latent variable model is a powerful method for capturing complex\ndistributions. These models assume that underlying structures, but unobserved,\nare present within the data. In this dissertation, we explore high-dimensional\nproblems related to physiological monitoring using latent variable models.\nFirst, we present a novel deep state-space model to generate electrical\nwaveforms of the heart using optically obtained signals as inputs. This can\nbring about clinical diagnoses of heart disease via simple assessment through\nwearable devices. Second, we present a brain signal modeling scheme that\ncombines the strengths of probabilistic graphical models and deep adversarial\nlearning. The structured representations can provide interpretability and\nencode inductive biases to reduce the data complexity of neural oscillations.\nThe efficacy of the learned representations is further studied in epilepsy\nseizure detection formulated as an unsupervised learning problem. Third, we\npropose a framework for the joint modeling of physiological measures and\nbehavior. Existing methods to combine multiple sources of brain data provided\nare limited. Direct analysis of the relationship between different types of\nphysiological measures usually does not involve behavioral data. Our method can\nidentify the unique and shared contributions of brain regions to behavior and\ncan be used to discover new functions of brain regions. The success of these\ninnovative computational methods would allow the translation of biomarker\nfindings across species and provide insight into neurocognitive analysis in\nnumerous biological studies and clinical diagnoses, as well as emerging\nconsumer applications.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Khuong Vo"
        ],
        "published": "2024-05-29T17:07:33Z"
    },
    {
        "title": "A Recipe for Charge Density Prediction",
        "link": "http://arxiv.org/abs/2405.19276v1",
        "abstract": "In density functional theory, charge density is the core attribute of atomic\nsystems from which all chemical properties can be derived. Machine learning\nmethods are promising in significantly accelerating charge density prediction,\nyet existing approaches either lack accuracy or scalability. We propose a\nrecipe that can achieve both. In particular, we identify three key ingredients:\n(1) representing the charge density with atomic and virtual orbitals (spherical\nfields centered at atom/virtual coordinates); (2) using expressive and\nlearnable orbital basis sets (basis function for the spherical fields); and (3)\nusing high-capacity equivariant neural network architecture. Our method\nachieves state-of-the-art accuracy while being more than an order of magnitude\nfaster than existing methods. Furthermore, our method enables flexible\nefficiency-accuracy trade-offs by adjusting the model/basis sizes.",
        "subjects": [
            "physics.comp-ph",
            "cs.LG"
        ],
        "authors": [
            "Xiang Fu",
            "Andrew Rosen",
            "Kyle Bystrom",
            "Rui Wang",
            "Albert Musaelian",
            "Boris Kozinsky",
            "Tess Smidt",
            "Tommi Jaakkola"
        ],
        "published": "2024-05-29T17:07:24Z"
    },
    {
        "title": "The Future of Child Development in the AI Era. Cross-Disciplinary\n  Perspectives Between AI and Child Development Experts",
        "link": "http://arxiv.org/abs/2405.19275v1",
        "abstract": "This report explores the potential implications of rapidly integrating\nArtificial Intelligence (AI) applications into children's environments. The\nintroduction of AI in our daily lives necessitates scrutiny considering the\nsignificant role of the environment in shaping cognition, socio-emotional\nskills, and behaviors, especially during the first 25 years of cerebral\ndevelopment. As AI becomes prevalent in educational and leisure activities, it\nwill significantly modify the experiences of children and adolescents,\npresenting both challenges and opportunities for their developmental\ntrajectories. This analysis was informed by consulting with 15 experts from\npertinent disciplines (AI, product development, child development, and\nneurosciences), along with a comprehensive review of scientific literature on\nchildren development and child-technology interactions. Overall, AI experts\nanticipate that AI will transform leisure activities, revolutionize education,\nand redefine human-machine interactions. While AI offers substantial benefits\nin fostering interactive engagement, it also poses risks that require careful\nconsiderations, especially during sensitive developmental periods. The report\nadvocates for proactive international collaboration across multiple disciplines\nand increased research into how technological innovations affect child\ndevelopment. Such efforts are crucial for designing a sustainable and ethical\nfuture for the next generation through specific child-centered regulations, and\nhelping to educate all potential stakeholders (regulators, developers, parents\nand educators, children) about responsible AI use and its potential impacts on\nchild development.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Mathilde Neugnot-Cerioli",
            "Olga Muss Laurenty"
        ],
        "published": "2024-05-29T17:07:02Z"
    },
    {
        "title": "Mitigating Disparate Impact of Differential Privacy in Federated\n  Learning through Robust Clustering",
        "link": "http://arxiv.org/abs/2405.19272v1",
        "abstract": "Federated Learning (FL) is a decentralized machine learning (ML) approach\nthat keeps data localized and often incorporates Differential Privacy (DP) to\nenhance privacy guarantees. Similar to previous work on DP in ML, we observed\nthat differentially private federated learning (DPFL) introduces performance\ndisparities, particularly affecting minority groups. Recent work has attempted\nto address performance fairness in vanilla FL through clustering, but this\nmethod remains sensitive and prone to errors, which are further exacerbated by\nthe DP noise in DPFL. To fill this gap, in this paper, we propose a novel\nclustered DPFL algorithm designed to effectively identify clients' clusters in\nhighly heterogeneous settings while maintaining high accuracy with DP\nguarantees. To this end, we propose to cluster clients based on both their\nmodel updates and training loss values. Our proposed approach also addresses\nthe server's uncertainties in clustering clients' model updates by employing\nlarger batch sizes along with Gaussian Mixture Model (GMM) to alleviate the\nimpact of noise and potential clustering errors, especially in\nprivacy-sensitive scenarios. We provide theoretical analysis of the\neffectiveness of our proposed approach. We also extensively evaluate our\napproach across diverse data distributions and privacy budgets and show its\neffectiveness in mitigating the disparate impact of DP in FL settings with a\nsmall computational cost.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "cs.DC"
        ],
        "authors": [
            "Saber Malekmohammadi",
            "Afaf Taik",
            "Golnoosh Farnadi"
        ],
        "published": "2024-05-29T17:03:31Z"
    },
    {
        "title": "Formalising the Local Compactness of the Adele Ring",
        "link": "http://arxiv.org/abs/2405.19270v1",
        "abstract": "The adele ring of a number field is a central object in modern number theory.\nIts status as a locally compact topological ring is one of the key reasons why,\nleading to its widespread use within the Langlands Program. We describe a\nformal proof that the adele ring of a number field is locally compact in the\nLean 4 theorem prover. Our work includes the formalisations of new types,\nincluding the completion of a number field at an infinite place and the finite\n$S$-adele ring, as well as formal proofs that completions of a number field are\nlocally compact and their rings of integers at finite places are compact.",
        "subjects": [
            "cs.LO",
            "math.NT"
        ],
        "authors": [
            "Salvatore Mercuri"
        ],
        "published": "2024-05-29T17:02:58Z"
    },
    {
        "title": "Rich-Observation Reinforcement Learning with Continuous Latent Dynamics",
        "link": "http://arxiv.org/abs/2405.19269v1",
        "abstract": "Sample-efficiency and reliability remain major bottlenecks toward wide\nadoption of reinforcement learning algorithms in continuous settings with\nhigh-dimensional perceptual inputs. Toward addressing these challenges, we\nintroduce a new theoretical framework, RichCLD (Rich-Observation RL with\nContinuous Latent Dynamics), in which the agent performs control based on\nhigh-dimensional observations, but the environment is governed by\nlow-dimensional latent states and Lipschitz continuous dynamics. Our main\ncontribution is a new algorithm for this setting that is provably statistically\nand computationally efficient. The core of our algorithm is a new\nrepresentation learning objective; we show that prior representation learning\nschemes tailored to discrete dynamics do not naturally extend to the continuous\nsetting. Our new objective is amenable to practical implementation, and\nempirically, we find that it compares favorably to prior schemes in a standard\nevaluation protocol. We further provide several insights into the statistical\ncomplexity of the RichCLD framework, in particular proving that certain notions\nof Lipschitzness that admit sample-efficient learning in the absence of rich\nobservations are insufficient in the rich-observation setting.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yuda Song",
            "Lili Wu",
            "Dylan J. Foster",
            "Akshay Krishnamurthy"
        ],
        "published": "2024-05-29T17:02:49Z"
    },
    {
        "title": "PediatricsGPT: Large Language Models as Chinese Medical Assistants for\n  Pediatric Applications",
        "link": "http://arxiv.org/abs/2405.19266v1",
        "abstract": "Developing intelligent pediatric consultation systems offers promising\nprospects for improving diagnostic efficiency, especially in China, where\nhealthcare resources are scarce. Despite recent advances in Large Language\nModels (LLMs) for Chinese medicine, their performance is sub-optimal in\npediatric applications due to inadequate instruction data and vulnerable\ntraining procedures. To address the above issues, this paper builds PedCorpus,\na high-quality dataset of over 300,000 multi-task instructions from pediatric\ntextbooks, guidelines, and knowledge graph resources to fulfil diverse\ndiagnostic demands. Upon well-designed PedCorpus, we propose PediatricsGPT, the\nfirst Chinese pediatric LLM assistant built on a systematic and robust training\npipeline. In the continuous pre-training phase, we introduce a hybrid\ninstruction pre-training mechanism to mitigate the internal-injected knowledge\ninconsistency of LLMs for medical domain adaptation. Immediately, the\nfull-parameter Supervised Fine-Tuning (SFT) is utilized to incorporate the\ngeneral medical knowledge schema into the models. After that, we devise a\ndirect following preference optimization to enhance the generation of\npediatrician-like humanistic responses. In the parameter-efficient secondary\nSFT phase, a mixture of universal-specific experts strategy is presented to\nresolve the competency conflict between medical generalist and pediatric\nexpertise mastery. Extensive results based on the metrics, GPT-4, and doctor\nevaluations on distinct doctor downstream tasks show that PediatricsGPT\nconsistently outperforms previous Chinese medical LLMs. Our model and dataset\nwill be open-source for community development.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Dingkang Yang",
            "Jinjie Wei",
            "Dongling Xiao",
            "Shunli Wang",
            "Tong Wu",
            "Gang Li",
            "Mingcheng Li",
            "Shuaibing Wang",
            "Jiawei Chen",
            "Yue Jiang",
            "Qingyao Xu",
            "Ke Li",
            "Peng Zhai",
            "Lihua Zhang"
        ],
        "published": "2024-05-29T16:59:38Z"
    },
    {
        "title": "AlchemistCoder: Harmonizing and Eliciting Code Capability by Hindsight\n  Tuning on Multi-source Data",
        "link": "http://arxiv.org/abs/2405.19265v1",
        "abstract": "Open-source Large Language Models (LLMs) and their specialized variants,\nparticularly Code LLMs, have recently delivered impressive performance.\nHowever, previous Code LLMs are typically fine-tuned on single-source data with\nlimited quality and diversity, which may insufficiently elicit the potential of\npre-trained Code LLMs. In this paper, we present AlchemistCoder, a series of\nCode LLMs with enhanced code generation and generalization capabilities\nfine-tuned on multi-source data. To achieve this, we pioneer to unveil inherent\nconflicts among the various styles and qualities in multi-source code corpora\nand introduce data-specific prompts with hindsight relabeling, termed\nAlchemistPrompts, to harmonize different data sources and instruction-response\npairs. Additionally, we propose incorporating the data construction process\ninto the fine-tuning data as code comprehension tasks, including instruction\nevolution, data filtering, and code review. Extensive experiments demonstrate\nthat AlchemistCoder holds a clear lead among all models of the same size\n(6.7B/7B) and rivals or even surpasses larger models (15B/33B/70B), showcasing\nthe efficacy of our method in refining instruction-following capabilities and\nadvancing the boundaries of code intelligence.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Zifan Song",
            "Yudong Wang",
            "Wenwei Zhang",
            "Kuikun Liu",
            "Chengqi Lyu",
            "Demin Song",
            "Qipeng Guo",
            "Hang Yan",
            "Dahua Lin",
            "Kai Chen",
            "Cairong Zhao"
        ],
        "published": "2024-05-29T16:57:33Z"
    },
    {
        "title": "Weak-to-Strong Search: Align Large Language Models via Searching over\n  Small Language Models",
        "link": "http://arxiv.org/abs/2405.19262v1",
        "abstract": "Large language models are usually fine-tuned to align with human preferences.\nHowever, fine-tuning a large language model can be challenging. In this work,\nwe introduce $\\textit{weak-to-strong search}$, framing the alignment of a large\nlanguage model as a test-time greedy search to maximize the log-likelihood\ndifference between small tuned and untuned models while sampling from the\nfrozen large model. This method serves both as (i) a compute-efficient model\nup-scaling strategy that avoids directly tuning the large model and as (ii) an\ninstance of weak-to-strong generalization that enhances a strong model with\nweak test-time guidance. Empirically, we demonstrate the flexibility of\nweak-to-strong search across different tasks. In controlled-sentiment\ngeneration and summarization, we use tuned and untuned $\\texttt{gpt2}$s to\neffectively improve the alignment of large models without additional training.\nCrucially, in a more difficult instruction-following benchmark, AlpacaEval 2.0,\nwe show that reusing off-the-shelf small model pairs (e.g.,\n$\\texttt{zephyr-7b-beta}$ and its untuned version) can significantly improve\nthe length-controlled win rates of both white-box and black-box large models\nagainst $\\texttt{gpt-4-turbo}$ (e.g., $34.4 \\rightarrow 37.9$ for\n$\\texttt{Llama-3-70B-Instruct}$ and $16.0 \\rightarrow 20.1$ for\n$\\texttt{gpt-3.5-turbo-instruct}$), despite the small models' low win rates\n$\\approx 10.0$.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Zhanhui Zhou",
            "Zhixuan Liu",
            "Jie Liu",
            "Zhichen Dong",
            "Chao Yang",
            "Yu Qiao"
        ],
        "published": "2024-05-29T16:55:32Z"
    },
    {
        "title": "Faster Cascades via Speculative Decoding",
        "link": "http://arxiv.org/abs/2405.19261v1",
        "abstract": "Cascades and speculative decoding are two common approaches to improving\nlanguage models' inference efficiency. Both approaches involve interleaving\nmodels of different sizes, but via fundamentally distinct mechanisms: cascades\nemploy a deferral rule that invokes the larger model only for \"hard\" inputs,\nwhile speculative decoding uses speculative execution to primarily invoke the\nlarger model in parallel verification mode. These mechanisms offer different\nbenefits: empirically, cascades are often capable of yielding better quality\nthan even the larger model, while theoretically, speculative decoding offers a\nguarantee of quality-neutrality. In this paper, we leverage the best of both\nthese approaches by designing new speculative cascading techniques that\nimplement their deferral rule through speculative execution. We characterize\nthe optimal deferral rule for our speculative cascades, and employ a plug-in\napproximation to the optimal rule. Through experiments with T5 models on\nbenchmark language tasks, we show that the proposed approach yields better\ncost-quality trade-offs than cascading and speculative decoding baselines.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Harikrishna Narasimhan",
            "Wittawat Jitkrittum",
            "Ankit Singh Rawat",
            "Seungyeon Kim",
            "Neha Gupta",
            "Aditya Krishna Menon",
            "Sanjiv Kumar"
        ],
        "published": "2024-05-29T16:55:08Z"
    },
    {
        "title": "A Privacy-Preserving Graph Encryption Scheme Based on Oblivious RAM",
        "link": "http://arxiv.org/abs/2405.19259v1",
        "abstract": "Graph encryption schemes play a crucial role in facilitating secure queries\non encrypted graphs hosted on untrusted servers. With applications spanning\nnavigation systems, network topology, and social networks, the need to\nsafeguard sensitive data becomes paramount. Existing graph encryption methods,\nhowever, exhibit vulnerabilities by inadvertently revealing aspects of the\ngraph structure and query patterns, posing threats to security and privacy. In\nresponse, we propose a novel graph encryption scheme designed to mitigate\naccess pattern and query pattern leakage through the integration of oblivious\nRAM and trusted execution environment techniques, exemplified by a Trusted\nExecution Environment (TEE). Our solution establishes two key security\nobjectives: (1) ensuring that adversaries, when presented with an encrypted\ngraph, remain oblivious to any information regarding the underlying graph, and\n(2) achieving query indistinguishability by concealing access patterns.\nAdditionally, we conducted experimentation to evaluate the efficiency of the\nproposed schemes when dealing with real-world location navigation services.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Seyni Kane",
            "Anis Bkakria"
        ],
        "published": "2024-05-29T16:47:38Z"
    },
    {
        "title": "Hybrid-Parallel: Achieving High Performance and Energy Efficient\n  Distributed Inference on Robots",
        "link": "http://arxiv.org/abs/2405.19257v1",
        "abstract": "The rapid advancements in machine learning techniques have led to significant\nachievements in various real-world robotic tasks. These tasks heavily rely on\nfast and energy-efficient inference of deep neural network (DNN) models when\ndeployed on robots. To enhance inference performance, distributed inference has\nemerged as a promising approach, parallelizing inference across multiple\npowerful GPU devices in modern data centers using techniques such as data\nparallelism, tensor parallelism, and pipeline parallelism. However, when\ndeployed on real-world robots, existing parallel methods fail to provide low\ninference latency and meet the energy requirements due to the limited bandwidth\nof robotic IoT. We present Hybrid-Parallel, a high-performance distributed\ninference system optimized for robotic IoT. Hybrid-Parallel employs a\nfine-grained approach to parallelize inference at the granularity of local\noperators within DNN layers (i.e., operators that can be computed independently\nwith the partial input, such as the convolution kernel in the convolution\nlayer). By doing so, Hybrid-Parallel enables different operators of different\nlayers to be computed and transmitted concurrently, and overlap the computation\nand transmission phases within the same inference task. The evaluation\ndemonstrate that Hybrid-Parallel reduces inference time by 14.9% ~41.1% and\nenergy consumption per inference by up to 35.3% compared to the\nstate-of-the-art baselines.",
        "subjects": [
            "cs.RO",
            "cs.DC"
        ],
        "authors": [
            "Zekai Sun",
            "Xiuxian Guan",
            "Junming Wang",
            "Haoze Song",
            "Yuhao Qing",
            "Tianxiang Shen",
            "Dong Huang",
            "Fangming Liu",
            "Heming Cui"
        ],
        "published": "2024-05-29T16:44:09Z"
    },
    {
        "title": "Weak Generative Sampler to Efficiently Sample Invariant Distribution of\n  Stochastic Differential Equation",
        "link": "http://arxiv.org/abs/2405.19256v1",
        "abstract": "Sampling invariant distributions from an Ito diffusion process presents a\nsignificant challenge in stochastic simulation. Traditional numerical solvers\nfor stochastic differential equations require both a fine step size and a\nlengthy simulation period, resulting in both biased and correlated samples.\nCurrent deep learning-based method solves the stationary Fokker--Planck\nequation to determine the invariant probability density function in form of\ndeep neural networks, but they generally do not directly address the problem of\nsampling from the computed density function. In this work, we introduce a\nframework that employs a weak generative sampler (WGS) to directly generate\nindependent and identically distributed (iid) samples induced by a\ntransformation map derived from the stationary Fokker--Planck equation. Our\nproposed loss function is based on the weak form of the Fokker--Planck\nequation, integrating normalizing flows to characterize the invariant\ndistribution and facilitate sample generation from the base distribution. Our\nrandomized test function circumvents the need for mini-max optimization in the\ntraditional weak formulation. Distinct from conventional generative models, our\nmethod neither necessitates the computationally intensive calculation of the\nJacobian determinant nor the invertibility of the transformation map. A crucial\ncomponent of our framework is the adaptively chosen family of test functions in\nthe form of Gaussian kernel functions with centres selected from the generated\ndata samples. Experimental results on several benchmark examples demonstrate\nthe effectiveness of our method, which offers both low computational costs and\nexcellent capability in exploring multiple metastable states.",
        "subjects": [
            "cs.LG",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Zhiqiang Cai",
            "Yu Cao",
            "Yuanfei Huang",
            "Xiang Zhou"
        ],
        "published": "2024-05-29T16:41:42Z"
    },
    {
        "title": "Towards Next-Generation Urban Decision Support Systems through\n  AI-Powered Generation of Scientific Ontology using Large Language Models -- A\n  Case in Optimizing Intermodal Freight Transportation",
        "link": "http://arxiv.org/abs/2405.19255v1",
        "abstract": "The incorporation of Artificial Intelligence (AI) models into various\noptimization systems is on the rise. Yet, addressing complex urban and\nenvironmental management problems normally requires in-depth domain science and\ninformatics expertise. This expertise is essential for deriving data and\nsimulation-driven for informed decision support. In this context, we\ninvestigate the potential of leveraging the pre-trained Large Language Models\n(LLMs). By adopting ChatGPT API as the reasoning core, we outline an integrated\nworkflow that encompasses natural language processing, methontology-based\nprompt tuning, and transformers. This workflow automates the creation of\nscenario-based ontology using existing research articles and technical manuals\nof urban datasets and simulations. The outcomes of our methodology are\nknowledge graphs in widely adopted ontology languages (e.g., OWL, RDF, SPARQL).\nThese facilitate the development of urban decision support systems by enhancing\nthe data and metadata modeling, the integration of complex datasets, the\ncoupling of multi-domain simulation models, and the formulation of\ndecision-making metrics and workflow. The feasibility of our methodology is\nevaluated through a comparative analysis that juxtaposes our AI-generated\nontology with the well-known Pizza Ontology employed in tutorials for popular\nontology software (e.g., prot\\'eg\\'e). We close with a real-world case study of\noptimizing the complex urban system of multi-modal freight transportation by\ngenerating anthologies of various domain data and simulations to support\ninformed decision-making.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Jose Tupayachi",
            "Haowen Xu",
            "Olufemi A. Omitaomu",
            "Mustafa Can Camur",
            "Aliza Sharmin",
            "Xueping Li"
        ],
        "published": "2024-05-29T16:40:31Z"
    },
    {
        "title": "Kotlin ML Pack: Technical Report",
        "link": "http://arxiv.org/abs/2405.19250v1",
        "abstract": "In this technical report, we present three novel datasets of Kotlin code:\nKStack, KStack-clean, and KExercises. We also describe the results of\nfine-tuning CodeLlama and DeepSeek models on this data. Additionally, we\npresent a version of the HumanEval benchmark rewritten by human experts into\nKotlin - both the solutions and the tests. Our results demonstrate that small,\nhigh-quality datasets (KStack-clean and KExercises) can significantly improve\nmodel performance on code generation tasks, achieving up to a 16-point increase\nin pass rate on the HumanEval benchmark. Lastly, we discuss potential future\nwork in the field of improving language modeling for Kotlin, including the use\nof static analysis tools in the learning process and the introduction of more\nintricate and realistic benchmarks.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.PL"
        ],
        "authors": [
            "Sergey Titov",
            "Mikhail Evtikhiev",
            "Anton Shapkin",
            "Oleg Smirnov",
            "Sergei Boytsov",
            "Sergei Boytsov",
            "Dariia Karaeva",
            "Maksim Sheptyakov",
            "Mikhail Arkhipov",
            "Timofey Bryksin",
            "Egor Bogomolov"
        ],
        "published": "2024-05-29T16:33:50Z"
    },
    {
        "title": "Comparative Study of Neighbor-based Methods for Local Outlier Detection",
        "link": "http://arxiv.org/abs/2405.19247v1",
        "abstract": "The neighbor-based method has become a powerful tool to handle the outlier\ndetection problem, which aims to infer the abnormal degree of the sample based\non the compactness of the sample and its neighbors. However, the existing\nmethods commonly focus on designing different processes to locate outliers in\nthe dataset, while the contributions of different types neighbors to outlier\ndetection has not been well discussed. To this end, this paper studies the\nneighbor in the existing outlier detection algorithms and a taxonomy is\nintroduced, which uses the three-level components of information, neighbor and\nmethodology to define hybrid methods. This taxonomy can serve as a paradigm\nwhere a novel neighbor-based outlier detection method can be proposed by\ncombining different components in this taxonomy. A large number of comparative\nexperiments were conducted on synthetic and real-world datasets in terms of\nperformance comparison and case study, and the results show that reverse\nK-nearest neighbor based methods achieve promising performance and dynamic\nselection method is suitable for working in high-dimensional space. Notably, it\nis verified that rationally selecting components from this taxonomy may create\nan algorithms superior to existing methods.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Zhuang Qi",
            "Junlin Zhang",
            "Xiaming Chen",
            "Xin Qi"
        ],
        "published": "2024-05-29T16:28:12Z"
    },
    {
        "title": "A numerical algorithm with linear complexity for Multi-marginal Optimal\n  Transport with $L^1$ Cost",
        "link": "http://arxiv.org/abs/2405.19246v1",
        "abstract": "Numerically solving multi-marginal optimal transport (MMOT) problems is\ncomputationally prohibitive, even for moderate-scale instances involving\n$l\\ge4$ marginals with support sizes of $N\\ge1000$. The cost in MMOT is\nrepresented as a tensor with $N^l$ elements. Even accessing each element once\nincurs a significant computational burden. In fact, many algorithms require\ndirect computation of tensor-vector products, leading to a computational\ncomplexity of $O(N^l)$ or beyond. In this paper, inspired by our previous work\n[$Comm. \\ Math. \\ Sci.$, 20 (2022), pp. 2053 - 2057], we observe that the\ncostly tensor-vector products in the Sinkhorn Algorithm can be computed with a\nrecursive process by separating summations and dynamic programming. Based on\nthis idea, we propose a fast tensor-vector product algorithm to solve the MMOT\nproblem with $L^1$ cost, achieving a miraculous reduction in the computational\ncost of the entropy regularized solution to $O(N)$. Numerical experiment\nresults confirm such high performance of this novel method which can be several\norders of magnitude faster than the original Sinkhorn algorithm.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Chunhui Chen",
            "Jing Chen",
            "Baojia Luo",
            "Shi Jin",
            "Hao Wu"
        ],
        "published": "2024-05-29T16:27:50Z"
    },
    {
        "title": "Challenge-Device-Synthesis: A multi-disciplinary approach for the\n  development of social innovation competences for students of Artificial\n  Intelligence",
        "link": "http://arxiv.org/abs/2405.19243v1",
        "abstract": "The advent of Artificial Intelligence is expected to imply profound changes\nin the short-term. It is therefore imperative for Academia, and particularly\nfor the Computer Science scope, to develop cross-disciplinary tools that bond\nAI developments to their social dimension. To this aim, we introduce the\nChallenge-Device-Synthesis methodology (CDS), in which a specific challenge is\npresented to the students of AI, who are required to develop a device as a\nsolution for the challenge. The device becomes the object of study for the\ndifferent dimensions of social transformation, and the conclusions addressed by\nthe students during the discussion around the device are presented in a\nsynthesis piece in the shape of a 10-page scientific paper. The latter is\nevaluated taking into account both the depth of analysis and the level to which\nit genuinely reflects the social transformations associated with the proposed\nAI-based device. We provide data obtained during the pilot for the\nimplementation phase of CDS within the subject of Social Innovation, a 6-ECTS\nsubject from the 6th semester of the Degree of Artificial Intelligence,\nUAB-Barcelona. We provide details on temporalisation, task distribution,\nmethodological tools used and assessment delivery procedure, as well as\nqualitative analysis of the results obtained.",
        "subjects": [
            "cs.AI",
            "physics.ed-ph"
        ],
        "authors": [
            "Matas Bilkis",
            "Joan Moya Kohler",
            "Fernando Vilario"
        ],
        "published": "2024-05-29T16:24:38Z"
    },
    {
        "title": "Explanation-based Belief Revision: Moving Beyond Minimalism to\n  Explanatory Understanding",
        "link": "http://arxiv.org/abs/2405.19238v1",
        "abstract": "In belief revision, agents typically modify their beliefs when they receive\nsome new piece of information that is in conflict with them. The guiding\nprinciple behind most belief revision frameworks is that of minimalism, which\nadvocates minimal changes to existing beliefs. However, minimalism may not\nnecessarily capture the nuanced ways in which human agents reevaluate and\nmodify their beliefs. In contrast, the explanatory hypothesis indicates that\npeople are inherently driven to seek explanations for inconsistencies, thereby\nstriving for explanatory coherence rather than minimal changes when revising\nbeliefs. Our contribution in this paper is two-fold. Motivated by the\nexplanatory hypothesis, we first present a novel, yet simple belief revision\noperator that, given a belief base and an explanation for an explanandum, it\nrevises the belief bases in a manner that preserves the explanandum and is not\nnecessarily minimal. We call this operator explanation-based belief revision.\nSecond, we conduct two human-subject studies to empirically validate our\napproach and investigate belief revision behavior in real-world scenarios. Our\nfindings support the explanatory hypothesis and provide insights into the\nstrategies people employ when resolving inconsistencies.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Stylianos Loukas Vasileiou",
            "William Yeoh"
        ],
        "published": "2024-05-29T16:20:51Z"
    },
    {
        "title": "ConceptPrune: Concept Editing in Diffusion Models via Skilled Neuron\n  Pruning",
        "link": "http://arxiv.org/abs/2405.19237v1",
        "abstract": "While large-scale text-to-image diffusion models have demonstrated impressive\nimage-generation capabilities, there are significant concerns about their\npotential misuse for generating unsafe content, violating copyright, and\nperpetuating societal biases. Recently, the text-to-image generation community\nhas begun addressing these concerns by editing or unlearning undesired concepts\nfrom pre-trained models. However, these methods often involve data-intensive\nand inefficient fine-tuning or utilize various forms of token remapping,\nrendering them susceptible to adversarial jailbreaks. In this paper, we present\na simple and effective training-free approach, ConceptPrune, wherein we first\nidentify critical regions within pre-trained models responsible for generating\nundesirable concepts, thereby facilitating straightforward concept unlearning\nvia weight pruning. Experiments across a range of concepts including artistic\nstyles, nudity, object erasure, and gender debiasing demonstrate that target\nconcepts can be efficiently erased by pruning a tiny fraction, approximately\n0.12% of total weights, enabling multi-concept erasure and robustness against\nvarious white-box and black-box adversarial attacks.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Ruchika Chavhan",
            "Da Li",
            "Timothy Hospedales"
        ],
        "published": "2024-05-29T16:19:37Z"
    },
    {
        "title": "Exploring the impact of traffic signal control and connected and\n  automated vehicles on intersections safety: A deep reinforcement learning\n  approach",
        "link": "http://arxiv.org/abs/2405.19236v1",
        "abstract": "In transportation networks, intersections pose significant risks of\ncollisions due to conflicting movements of vehicles approaching from different\ndirections. To address this issue, various tools can exert influence on traffic\nsafety both directly and indirectly. This study focuses on investigating the\nimpact of adaptive signal control and connected and automated vehicles (CAVs)\non intersection safety using a deep reinforcement learning approach. The\nobjective is to assess the individual and combined effects of CAVs and adaptive\ntraffic signal control on traffic safety, considering rear-end and crossing\nconflicts. The study employs a Deep Q Network (DQN) to regulate traffic signals\nand driving behaviors of both CAVs and Human Drive Vehicles (HDVs), and uses\nTime To Collision (TTC) metric to evaluate safety. The findings demonstrate a\nsignificant reduction in rear-end and crossing conflicts through the combined\nimplementation of CAVs and DQNs-based traffic signal control. Additionally, the\nlong-term positive effects of CAVs on safety are similar to the short-term\neffects of combined CAVs and DQNs-based traffic signal control. Overall, the\nstudy emphasizes the potential benefits of integrating CAVs and adaptive\ntraffic signal control approaches in order to enhance traffic safety. The\nfindings of this study could provide valuable insights for city officials and\ntransportation authorities in developing effective strategies to improve safety\nat signalized intersections.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Amir Hossein Karbasi",
            "Hao Yang",
            "Saiedeh Razavi"
        ],
        "published": "2024-05-29T16:17:19Z"
    },
    {
        "title": "Forward-Backward Knowledge Distillation for Continual Clustering",
        "link": "http://arxiv.org/abs/2405.19234v1",
        "abstract": "Unsupervised Continual Learning (UCL) is a burgeoning field in machine\nlearning, focusing on enabling neural networks to sequentially learn tasks\nwithout explicit label information. Catastrophic Forgetting (CF), where models\nforget previously learned tasks upon learning new ones, poses a significant\nchallenge in continual learning, especially in UCL, where labeled information\nof data is not accessible. CF mitigation strategies, such as knowledge\ndistillation and replay buffers, often face memory inefficiency and privacy\nissues. Although current research in UCL has endeavored to refine data\nrepresentations and address CF in streaming data contexts, there is a\nnoticeable lack of algorithms specifically designed for unsupervised\nclustering. To fill this gap, in this paper, we introduce the concept of\nUnsupervised Continual Clustering (UCC). We propose Forward-Backward Knowledge\nDistillation for unsupervised Continual Clustering (FBCC) to counteract CF\nwithin the context of UCC. FBCC employs a single continual learner (the\n``teacher'') with a cluster projector, along with multiple student models, to\naddress the CF issue. The proposed method consists of two phases: Forward\nKnowledge Distillation, where the teacher learns new clusters while retaining\nknowledge from previous tasks with guidance from specialized student models,\nand Backward Knowledge Distillation, where a student model mimics the teacher's\nbehavior to retain task-specific knowledge, aiding the teacher in subsequent\ntasks. FBCC marks a pioneering approach to UCC, demonstrating enhanced\nperformance and memory efficiency in clustering across various tasks,\noutperforming the application of clustering algorithms to the latent space of\nstate-of-the-art UCL algorithms.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Mohammadreza Sadeghi",
            "Zihan Wang",
            "Narges Armanfard"
        ],
        "published": "2024-05-29T16:13:54Z"
    },
    {
        "title": "DiPPeST: Diffusion-based Path Planner for Synthesizing Trajectories\n  Applied on Quadruped Robots",
        "link": "http://arxiv.org/abs/2405.19232v1",
        "abstract": "We present DiPPeST, a novel image and goal conditioned diffusion-based\ntrajectory generator for quadrupedal robot path planning. DiPPeST is a\nzero-shot adaptation of our previously introduced diffusion-based 2D global\ntrajectory generator (DiPPeR). The introduced system incorporates a novel\nstrategy for local real-time path refinements, that is reactive to camera\ninput, without requiring any further training, image processing, or environment\ninterpretation techniques. DiPPeST achieves 92% success rate in obstacle\navoidance for nominal environments and an average of 88% success rate when\ntested in environments that are up to 3.5 times more complex in pixel variation\nthan DiPPeR. A visual-servoing framework is developed to allow for real-world\nexecution, tested on the quadruped robot, achieving 80% success rate in\ndifferent environments and showcasing improved behavior than complex\nstate-of-the-art local planners, in narrow environments.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Maria Stamatopoulou",
            "Jianwei Liu",
            "Dimitrios Kanoulas"
        ],
        "published": "2024-05-29T16:12:14Z"
    },
    {
        "title": "Valid Conformal Prediction for Dynamic GNNs",
        "link": "http://arxiv.org/abs/2405.19230v1",
        "abstract": "Graph neural networks (GNNs) are powerful black-box models which have shown\nimpressive empirical performance. However, without any form of uncertainty\nquantification, it can be difficult to trust such models in high-risk\nscenarios. Conformal prediction aims to address this problem, however, an\nassumption of exchangeability is required for its validity which has limited\nits applicability to static graphs and transductive regimes. We propose to use\nunfolding, which allows any existing static GNN to output a dynamic graph\nembedding with exchangeability properties. Using this, we extend the validity\nof conformal prediction to dynamic GNNs in both transductive and semi-inductive\nregimes. We provide a theoretical guarantee of valid conformal prediction in\nthese cases and demonstrate the empirical validity, as well as the performance\ngains, of unfolded GNNs against standard GNN architectures on both simulated\nand real datasets.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "62H30"
        ],
        "authors": [
            "Ed Davis",
            "Ian Gallagher",
            "Daniel John Lawson",
            "Patrick Rubin-Delanchy"
        ],
        "published": "2024-05-29T16:07:39Z"
    },
    {
        "title": "On Generating Monolithic and Model Reconciling Explanations in\n  Probabilistic Scenarios",
        "link": "http://arxiv.org/abs/2405.19229v1",
        "abstract": "Explanation generation frameworks aim to make AI systems' decisions\ntransparent and understandable to human users. However, generating explanations\nin uncertain environments characterized by incomplete information and\nprobabilistic models remains a significant challenge. In this paper, we propose\na novel framework for generating probabilistic monolithic explanations and\nmodel reconciling explanations. Monolithic explanations provide self-contained\nreasons for an explanandum without considering the agent receiving the\nexplanation, while model reconciling explanations account for the knowledge of\nthe agent receiving the explanation. For monolithic explanations, our approach\nintegrates uncertainty by utilizing probabilistic logic to increase the\nprobability of the explanandum. For model reconciling explanations, we propose\na framework that extends the logic-based variant of the model reconciliation\nproblem to account for probabilistic human models, where the goal is to find\nexplanations that increase the probability of the explanandum while minimizing\nconflicts between the explanation and the probabilistic human model. We\nintroduce explanatory gain and explanatory power as quantitative metrics to\nassess the quality of these explanations. Further, we present algorithms that\nexploit the duality between minimal correction sets and minimal unsatisfiable\nsets to efficiently compute both types of explanations in probabilistic\ncontexts. Extensive experimental evaluations on various benchmarks demonstrate\nthe effectiveness and scalability of our approach in generating explanations\nunder uncertainty.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Stylianos Loukas Vasileiou",
            "William Yeoh",
            "Alessandro Previti",
            "Tran Cao Son"
        ],
        "published": "2024-05-29T16:07:31Z"
    },
    {
        "title": "ContextBLIP: Doubly Contextual Alignment for Contrastive Image Retrieval\n  from Linguistically Complex Descriptions",
        "link": "http://arxiv.org/abs/2405.19226v1",
        "abstract": "Image retrieval from contextual descriptions (IRCD) aims to identify an image\nwithin a set of minimally contrastive candidates based on linguistically\ncomplex text. Despite the success of VLMs, they still significantly lag behind\nhuman performance in IRCD. The main challenges lie in aligning key contextual\ncues in two modalities, where these subtle cues are concealed in tiny areas of\nmultiple contrastive images and within the complex linguistics of textual\ndescriptions. This motivates us to propose ContextBLIP, a simple yet effective\nmethod that relies on a doubly contextual alignment scheme for challenging\nIRCD. Specifically, 1) our model comprises a multi-scale adapter, a matching\nloss, and a text-guided masking loss. The adapter learns to capture\nfine-grained visual cues. The two losses enable iterative supervision for the\nadapter, gradually highlighting the focal patches of a single image to the key\ntextual cues. We term such a way as intra-contextual alignment. 2) Then,\nContextBLIP further employs an inter-context encoder to learn dependencies\namong candidates, facilitating alignment between the text to multiple images.\nWe term this step as inter-contextual alignment. Consequently, the nuanced cues\nconcealed in each modality can be effectively aligned. Experiments on two\nbenchmarks show the superiority of our method. We observe that ContextBLIP can\nyield comparable results with GPT-4V, despite involving about 7,500 times fewer\nparameters.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "authors": [
            "Honglin Lin",
            "Siyu Li",
            "Guoshun Nan",
            "Chaoyue Tang",
            "Xueting Wang",
            "Jingxin Xu",
            "Rong Yankai",
            "Zhili Zhou",
            "Yutong Gao",
            "Qimei Cui",
            "Xiaofeng Tao"
        ],
        "published": "2024-05-29T16:06:21Z"
    },
    {
        "title": "Synthetic Potential Outcomes for Mixtures of Treatment Effects",
        "link": "http://arxiv.org/abs/2405.19225v1",
        "abstract": "Modern data analysis frequently relies on the use of large datasets, often\nconstructed as amalgamations of diverse populations or data-sources.\nHeterogeneity across these smaller datasets constitutes two major challenges\nfor causal inference: (1) the source of each sample can introduce latent\nconfounding between treatment and effect, and (2) diverse populations may\nrespond differently to the same treatment, giving rise to heterogeneous\ntreatment effects (HTEs). The issues of latent confounding and HTEs have been\nstudied separately but not in conjunction. In particular, previous works only\nreport the conditional average treatment effect (CATE) among similar\nindividuals (with respect to the measured covariates). CATEs cannot resolve\nmixtures of potential treatment effects driven by latent heterogeneity, which\nwe call mixtures of treatment effects (MTEs). Inspired by method of moment\napproaches to mixture models, we propose \"synthetic potential outcomes\" (SPOs).\nOur new approach deconfounds heterogeneity while also guaranteeing the\nidentifiability of MTEs. This technique bypasses full recovery of a mixture,\nwhich significantly simplifies its requirements for identifiability. We\ndemonstrate the efficacy of SPOs on synthetic data.",
        "subjects": [
            "cs.LG",
            "econ.EM",
            "stat.ME"
        ],
        "authors": [
            "Bijan Mazaheri",
            "Chandler Squires",
            "Caroline Uhler"
        ],
        "published": "2024-05-29T16:05:57Z"
    },
    {
        "title": "A study on the adequacy of common IQA measures for medical images",
        "link": "http://arxiv.org/abs/2405.19224v1",
        "abstract": "Image quality assessment (IQA) is standard practice in the development stage\nof novel machine learning algorithms that operate on images. The most commonly\nused IQA measures have been developed and tested for natural images, but not in\nthe medical setting. Reported inconsistencies arising in medical images are not\nsurprising, as they have different properties than natural images. In this\nstudy, we test the applicability of common IQA measures for medical image data\nby comparing their assessment to manually rated chest X-ray (5 experts) and\nphotoacoustic image data (1 expert). Moreover, we include supplementary studies\non grayscale natural images and accelerated brain MRI data. The results of all\nexperiments show a similar outcome in line with previous findings for medical\nimaging: PSNR and SSIM in the default setting are in the lower range of the\nresult list and HaarPSI outperforms the other tested measures in the overall\nperformance. Also among the top performers in our medical experiments are the\nfull reference measures DISTS, FSIM, LPIPS and MS-SSIM. Generally, the results\non natural images yield considerably higher correlations, suggesting that the\nadditional employment of tailored IQA measures for medical imaging algorithms\nis needed.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Anna Breger",
            "Clemens Karner",
            "Ian Selby",
            "Janek Grhl",
            "Sren Dittmer",
            "Edward Lilley",
            "Judith Babar",
            "Jake Beckford",
            "Timothy J Sadler",
            "Shahab Shahipasand",
            "Arthikkaa Thavakumar",
            "Michael Roberts",
            "Carola-Bibiane Schnlieb"
        ],
        "published": "2024-05-29T16:04:03Z"
    },
    {
        "title": "On the Problem of Separating Variables in Multivariate Polynomial Ideals",
        "link": "http://dx.doi.org/10.1145/3666000.366968",
        "abstract": "For a given ideal I in K[x_1,...,x_n,y_1,...,y_m] in a polynomial ring with\nn+m variables, we want to find all elements that can be written as f-g for some\nf in K[x_1,...,x_n] and some g in K[y_1,...,y_m], i.e., all elements of I that\ncontain no term involving at the same time one of the x_1,...,x_n and one of\nthe y_1,...,y_m. For principal ideals and for ideals of dimension zero, we give\na algorithms that compute all these polynomials in a finite number of steps.",
        "subjects": [
            "cs.SC"
        ],
        "authors": [
            "Manfred Buchacher",
            "Manuel Kauers"
        ],
        "published": "2024-05-29T16:03:48Z"
    },
    {
        "title": "Lower Bounds on the Expressivity of Recurrent Neural Language Models",
        "link": "http://arxiv.org/abs/2405.19222v1",
        "abstract": "The recent successes and spread of large neural language models (LMs) call\nfor a thorough understanding of their computational ability. Describing their\ncomputational abilities through LMs' \\emph{representational capacity} is a\nlively area of research. However, investigation into the representational\ncapacity of neural LMs has predominantly focused on their ability to\n\\emph{recognize} formal languages. For example, recurrent neural networks\n(RNNs) with Heaviside activations are tightly linked to regular languages,\ni.e., languages defined by finite-state automata (FSAs). Such results, however,\nfall short of describing the capabilities of RNN \\emph{language models} (LMs),\nwhich are definitionally \\emph{distributions} over strings. We take a fresh\nlook at the representational capacity of RNN LMs by connecting them to\n\\emph{probabilistic} FSAs and demonstrate that RNN LMs with linearly bounded\nprecision can express arbitrary regular LMs.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Anej Svete",
            "Franz Nowak",
            "Anisha Mohamed Sahabdeen",
            "Ryan Cotterell"
        ],
        "published": "2024-05-29T16:02:09Z"
    },
    {
        "title": "Domain adaptation in small-scale and heterogeneous biological datasets",
        "link": "http://arxiv.org/abs/2405.19221v1",
        "abstract": "Machine learning techniques are steadily becoming more important in modern\nbiology, and are used to build predictive models, discover patterns, and\ninvestigate biological problems. However, models trained on one dataset are\noften not generalizable to other datasets from different cohorts or\nlaboratories, due to differences in the statistical properties of these\ndatasets. These could stem from technical differences, such as the measurement\ntechnique used, or from relevant biological differences between the populations\nstudied. Domain adaptation, a type of transfer learning, can alleviate this\nproblem by aligning the statistical distributions of features and samples among\ndifferent datasets so that similar models can be applied across them. However,\na majority of state-of-the-art domain adaptation methods are designed to work\nwith large-scale data, mostly text and images, while biological datasets often\nsuffer from small sample sizes, and possess complexities such as heterogeneity\nof the feature space. This Review aims to synthetically discuss domain\nadaptation methods in the context of small-scale and highly heterogeneous\nbiological data. We describe the benefits and challenges of domain adaptation\nin biological research and critically discuss some of its objectives,\nstrengths, and weaknesses through key representative methodologies. We argue\nfor the incorporation of domain adaptation techniques to the computational\nbiologist's toolkit, with further development of customized approaches.",
        "subjects": [
            "q-bio.QM",
            "cs.LG"
        ],
        "authors": [
            "Seyedmehdi Orouji",
            "Martin C. Liu",
            "Tal Korem",
            "Megan A. K. Peters"
        ],
        "published": "2024-05-29T16:01:15Z"
    },
    {
        "title": "WRDScore: New Metric for Evaluation of Natural Language Generation\n  Models",
        "link": "http://arxiv.org/abs/2405.19220v1",
        "abstract": "The problem of natural language generation, and, more specifically, method\nname prediction, faces significant difficulties when proposed models need to be\nevaluated on test data. Such a metric would need to consider the versatility\nwith which a single method can be named, with respect to both semantics and\nsyntax. Measuring the direct overlap between the predicted and reference (true)\nsequences will not be able to capture these subtleties. Other existing\nembedding based metrics either do not measure precision and recall or impose\nstrict unrealistic assumptions on both sequences. To address these issues, we\npropose a new metric that, on the one hand, is very simple and lightweight,\nand, on the other hand, is able to calculate precision and recall without\nresorting to any assumptions while obtaining good performance with respect to\nthe human judgement.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Ravil Mussabayev"
        ],
        "published": "2024-05-29T16:00:46Z"
    },
    {
        "title": "LoByITFL: Low Communication Secure and Private Federated Learning",
        "link": "http://arxiv.org/abs/2405.19217v1",
        "abstract": "Federated Learning (FL) faces several challenges, such as the privacy of the\nclients data and security against Byzantine clients. Existing works treating\nprivacy and security jointly make sacrifices on the privacy guarantee. In this\nwork, we introduce LoByITFL, the first communication-efficient\nInformation-Theoretic (IT) private and secure FL scheme that makes no\nsacrifices on the privacy guarantees while ensuring security against Byzantine\nadversaries. The key ingredients are a small and representative dataset\navailable to the federator, a careful transformation of the FLTrust algorithm\nand the use of a trusted third party only in a one-time preprocessing phase\nbefore the start of the learning algorithm. We provide theoretical guarantees\non privacy and Byzantine-resilience, and provide convergence guarantee and\nexperimental results validating our theoretical findings.",
        "subjects": [
            "cs.IT",
            "cs.CR",
            "cs.DC",
            "cs.LG",
            "math.IT"
        ],
        "authors": [
            "Yue Xia",
            "Christoph Hofmeister",
            "Maximilian Egger",
            "Rawad Bitar"
        ],
        "published": "2024-05-29T16:00:19Z"
    },
    {
        "title": "HawkVision: Low-Latency Modeless Edge AI Serving",
        "link": "http://arxiv.org/abs/2405.19213v1",
        "abstract": "The trend of modeless ML inference is increasingly growing in popularity as\nit hides the complexity of model inference from users and caters to diverse\nuser and application accuracy requirements. Previous work mostly focuses on\nmodeless inference in data centers. To provide low-latency inference, in this\npaper, we promote modeless inference at the edge. The edge environment\nintroduces additional challenges related to low power consumption, limited\ndevice memory, and volatile network environments.\n  To address these challenges, we propose HawkVision, which provides\nlow-latency modeless serving of vision DNNs. HawkVision leverages a two-layer\nedge-DC architecture that employs confidence scaling to reduce the number of\nmodel options while meeting diverse accuracy requirements. It also supports\nlossy inference under volatile network environments. Our experimental results\nshow that HawkVision outperforms current serving systems by up to 1.6X in P99\nlatency for providing modeless service. Our FPGA prototype demonstrates similar\nperformance at certain accuracy levels with up to a 3.34X reduction in power\nconsumption.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.LG",
            "cs.NI",
            "cs.SY"
        ],
        "authors": [
            "ChonLam Lao",
            "Jiaqi Gao",
            "Ganesh Ananthanarayanan",
            "Aditya Akella",
            "Minlan Yu"
        ],
        "published": "2024-05-29T15:56:33Z"
    },
    {
        "title": "Partial Information Decomposition for Data Interpretability and Feature\n  Selection",
        "link": "http://arxiv.org/abs/2405.19212v1",
        "abstract": "In this paper, we introduce Partial Information Decomposition of Features\n(PIDF), a new paradigm for simultaneous data interpretability and feature\nselection. Contrary to traditional methods that assign a single importance\nvalue, our approach is based on three metrics per feature: the mutual\ninformation shared with the target variable, the feature's contribution to\nsynergistic information, and the amount of this information that is redundant.\nIn particular, we develop a novel procedure based on these three metrics, which\nreveals not only how features are correlated with the target but also the\nadditional and overlapping information provided by considering them in\ncombination with other features. We extensively evaluate PIDF using both\nsynthetic and real-world data, demonstrating its potential applications and\neffectiveness, by considering case studies from genetics and neuroscience.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Charles Westphal",
            "Stephen Hailes",
            "Mirco Musolesi"
        ],
        "published": "2024-05-29T15:54:03Z"
    },
    {
        "title": "Gone but Not Forgotten: Improved Benchmarks for Machine Unlearning",
        "link": "http://arxiv.org/abs/2405.19211v1",
        "abstract": "Machine learning models are vulnerable to adversarial attacks, including\nattacks that leak information about the model's training data. There has\nrecently been an increase in interest about how to best address privacy\nconcerns, especially in the presence of data-removal requests. Machine\nunlearning algorithms aim to efficiently update trained models to comply with\ndata deletion requests while maintaining performance and without having to\nresort to retraining the model from scratch, a costly endeavor. Several\nalgorithms in the machine unlearning literature demonstrate some level of\nprivacy gains, but they are often evaluated only on rudimentary membership\ninference attacks, which do not represent realistic threats. In this paper we\ndescribe and propose alternative evaluation methods for three key shortcomings\nin the current evaluation of unlearning algorithms. We show the utility of our\nalternative evaluations via a series of experiments of state-of-the-art\nunlearning algorithms on different computer vision datasets, presenting a more\ndetailed picture of the state of the field.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Keltin Grimes",
            "Collin Abidi",
            "Cole Frank",
            "Shannon Gallagher"
        ],
        "published": "2024-05-29T15:53:23Z"
    },
    {
        "title": "Gradient Guided Hypotheses: A unified solution to enable machine\n  learning models on scarce and noisy data regimes",
        "link": "http://arxiv.org/abs/2405.19210v1",
        "abstract": "Ensuring high-quality data is paramount for maximizing the performance of\nmachine learning models and business intelligence systems. However, challenges\nin data quality, including noise in data capture, missing records, limited data\nproduction, and confounding variables, significantly constrain the potential\nperformance of these systems. In this study, we propose an\narchitecture-agnostic algorithm, Gradient Guided Hypotheses (GGH), designed to\naddress these challenges. GGH analyses gradients from hypotheses as a proxy of\ndistinct and possibly contradictory patterns in the data. This framework\nentails an additional step in machine learning training, where gradients can be\nincluded or excluded from backpropagation. In this manner, missing and noisy\ndata are addressed through a unified solution that perceives both challenges as\nfacets of the same overarching issue: the propagation of erroneous information.\nExperimental validation of GGH is conducted using real-world open-source\ndatasets, where records with missing rates of up to 98.5% are simulated.\nComparative analysis with state-of-the-art imputation methods demonstrates a\nsubstantial improvement in model performance achieved by GGH. Specifically in\nvery high scarcity regimes, GGH was found to be the only viable solution.\nAdditionally, GGH's noise detection capabilities are showcased by introducing\nsimulated noise into the datasets and observing enhanced model performance\nafter filtering out the noisy data. This study presents GGH as a promising\nsolution for improving data quality and model performance in various\napplications.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Paulo Neves",
            "Joerg K. Wegner",
            "Philippe Schwaller"
        ],
        "published": "2024-05-29T15:51:40Z"
    },
    {
        "title": "VideoTree: Adaptive Tree-based Video Representation for LLM Reasoning on\n  Long Videos",
        "link": "http://arxiv.org/abs/2405.19209v1",
        "abstract": "Video-language understanding tasks have focused on short video clips, often\nstruggling with long-form video understanding tasks. Recently, many long\nvideo-language understanding approaches have leveraged the reasoning\ncapabilities of Large Language Models (LLMs) to perform long video QA,\ntransforming videos into densely sampled frame captions, and asking LLMs to\nrespond to text queries over captions. However, the frames used for captioning\nare often redundant and contain irrelevant information, making dense sampling\ninefficient, and ignoring the fact that video QA requires varying levels of\ngranularity, with some video segments being highly relevant to the question\n(needing more fine-grained detail) while others being less relevant. Thus,\nthese LLM-based approaches are prone to missing information and operate on\nlarge numbers of irrelevant captions, lowering both performance and efficiency.\nTo address these issues, we introduce VideoTree, a query-adaptive and\nhierarchical framework for long-video understanding with LLMs. VideoTree\ndynamically extracts query-related information from a video and builds a\ntree-based representation for LLM reasoning. First, VideoTree adaptively\nselects frames for captioning by iteratively clustering frames based on their\nvisual features and scoring clusters using their relevance to the query.\nSecond, it organizes visual clusters into a query-adaptive and hierarchical\ntree structure; the tree encodes varying levels of granularity, with higher\nresolution on relevant segments. Finally, VideoTree produces an answer by\ntraversing the tree's keyframes and passing their captions to an LLM answerer.\nOur method improves both reasoning accuracy and efficiency compared to existing\nmethods: VideoTree achieves a 7.0%, 2.2%, and 2.7% accuracy gain over baselines\non the EgoSchema, NExT-QA, and IntentQA benchmarks, respectively, while\nreducing inference time by 40%.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Ziyang Wang",
            "Shoubin Yu",
            "Elias Stengel-Eskin",
            "Jaehong Yoon",
            "Feng Cheng",
            "Gedas Bertasius",
            "Mohit Bansal"
        ],
        "published": "2024-05-29T15:49:09Z"
    },
    {
        "title": "A Multi-Source Retrieval Question Answering Framework Based on RAG",
        "link": "http://arxiv.org/abs/2405.19207v1",
        "abstract": "With the rapid development of large-scale language models,\nRetrieval-Augmented Generation (RAG) has been widely adopted. However, existing\nRAG paradigms are inevitably influenced by erroneous retrieval information,\nthereby reducing the reliability and correctness of generated results.\nTherefore, to improve the relevance of retrieval information, this study\nproposes a method that replaces traditional retrievers with GPT-3.5, leveraging\nits vast corpus knowledge to generate retrieval information. We also propose a\nweb retrieval based method to implement fine-grained knowledge retrieval,\nUtilizing the powerful reasoning capability of GPT-3.5 to realize semantic\npartitioning of problem.In order to mitigate the illusion of GPT retrieval and\nreduce noise in Web retrieval,we proposes a multi-source retrieval framework,\nnamed MSRAG, which combines GPT retrieval with web retrieval. Experiments on\nmultiple knowledge-intensive QA datasets demonstrate that the proposed\nframework in this study performs better than existing RAG framework in\nenhancing the overall efficiency and accuracy of QA systems.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "authors": [
            "Ridong Wu",
            "Shuhong Chen",
            "Xiangbiao Su",
            "Yuankai Zhu",
            "Yifei Liao",
            "Jianming Wu"
        ],
        "published": "2024-05-29T15:47:57Z"
    },
    {
        "title": "Matrix Manifold Neural Networks++",
        "link": "http://arxiv.org/abs/2405.19206v1",
        "abstract": "Deep neural networks (DNNs) on Riemannian manifolds have garnered increasing\ninterest in various applied areas. For instance, DNNs on spherical and\nhyperbolic manifolds have been designed to solve a wide range of computer\nvision and nature language processing tasks. One of the key factors that\ncontribute to the success of these networks is that spherical and hyperbolic\nmanifolds have the rich algebraic structures of gyrogroups and gyrovector\nspaces. This enables principled and effective generalizations of the most\nsuccessful DNNs to these manifolds. Recently, some works have shown that many\nconcepts in the theory of gyrogroups and gyrovector spaces can also be\ngeneralized to matrix manifolds such as Symmetric Positive Definite (SPD) and\nGrassmann manifolds. As a result, some building blocks for SPD and Grassmann\nneural networks, e.g., isometric models and multinomial logistic regression\n(MLR) can be derived in a way that is fully analogous to their spherical and\nhyperbolic counterparts. Building upon these works, we design fully-connected\n(FC) and convolutional layers for SPD neural networks. We also develop MLR on\nSymmetric Positive Semi-definite (SPSD) manifolds, and propose a method for\nperforming backpropagation with the Grassmann logarithmic map in the projector\nperspective. We demonstrate the effectiveness of the proposed approach in the\nhuman action recognition and node classification tasks.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Xuan Son Nguyen",
            "Shuo Yang",
            "Aymeric Histace"
        ],
        "published": "2024-05-29T15:47:35Z"
    },
    {
        "title": "Contrastive-Adversarial and Diffusion: Exploring pre-training and\n  fine-tuning strategies for sulcal identification",
        "link": "http://arxiv.org/abs/2405.19204v1",
        "abstract": "In the last decade, computer vision has witnessed the establishment of\nvarious training and learning approaches. Techniques like adversarial learning,\ncontrastive learning, diffusion denoising learning, and ordinary reconstruction\nlearning have become standard, representing state-of-the-art methods\nextensively employed for fully training or pre-training networks across various\nvision tasks. The exploration of fine-tuning approaches has emerged as a\ncurrent focal point, addressing the need for efficient model tuning with\nreduced GPU memory usage and time costs while enhancing overall performance, as\nexemplified by methodologies like low-rank adaptation (LoRA). Key questions\narise: which pre-training technique yields optimal results - adversarial,\ncontrastive, reconstruction, or diffusion denoising? How does the performance\nof these approaches vary as the complexity of fine-tuning is adjusted? This\nstudy aims to elucidate the advantages of pre-training techniques and\nfine-tuning strategies to enhance the learning process of neural networks in\nindependent identical distribution (IID) cohorts. We underscore the\nsignificance of fine-tuning by examining various cases, including full tuning,\ndecoder tuning, top-level tuning, and fine-tuning of linear parameters using\nLoRA. Systematic summaries of model performance and efficiency are presented,\nleveraging metrics such as accuracy, time cost, and memory efficiency. To\nempirically demonstrate our findings, we focus on a multi-task\nsegmentation-classification challenge involving the paracingulate sulcus (PCS)\nusing different 3D Convolutional Neural Network (CNN) architectures by using\nthe TOP-OSLO cohort comprising 596 subjects.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Michail Mamalakis",
            "Hlose de Vareilles",
            "Shun-Chin Jim Wu",
            "Ingrid Agartz",
            "Lynn Egeland Mrch-Johnsen",
            "Jane Garrison",
            "Jon Simons",
            "Pietro Lio",
            "John Suckling",
            "Graham Murray"
        ],
        "published": "2024-05-29T15:44:51Z"
    },
    {
        "title": "$E^{3}$Gen: Efficient, Expressive and Editable Avatars Generation",
        "link": "http://arxiv.org/abs/2405.19203v2",
        "abstract": "This paper aims to introduce 3D Gaussian for efficient, expressive, and\neditable digital avatar generation. This task faces two major challenges: (1)\nThe unstructured nature of 3D Gaussian makes it incompatible with current\ngeneration pipelines; (2) the expressive animation of 3D Gaussian in a\ngenerative setting that involves training with multiple subjects remains\nunexplored. In this paper, we propose a novel avatar generation method named\n$E^3$Gen, to effectively address these challenges. First, we propose a novel\ngenerative UV features plane representation that encodes unstructured 3D\nGaussian onto a structured 2D UV space defined by the SMPL-X parametric model.\nThis novel representation not only preserves the representation ability of the\noriginal 3D Gaussian but also introduces a shared structure among subjects to\nenable generative learning of the diffusion model. To tackle the second\nchallenge, we propose a part-aware deformation module to achieve robust and\naccurate full-body expressive pose control. Extensive experiments demonstrate\nthat our method achieves superior performance in avatar generation and enables\nexpressive full-body pose control and editing. Our project page is\nhttps://olivia23333.github.io/E3Gen.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Weitian Zhang",
            "Yichao Yan",
            "Yunhui Liu",
            "Xingdong Sheng",
            "Xiaokang Yang"
        ],
        "published": "2024-05-29T15:43:49Z"
    },
    {
        "title": "Vulnerable Road User Detection and Safety Enhancement: A Comprehensive\n  Survey",
        "link": "http://arxiv.org/abs/2405.19202v1",
        "abstract": "Traffic incidents involving vulnerable road users (VRUs) constitute a\nsignificant proportion of global road accidents. Advances in traffic\ncommunication ecosystems, coupled with sophisticated signal processing and\nmachine learning techniques, have facilitated the utilization of data from\ndiverse sensors. Despite these advancements and the availability of extensive\ndatasets, substantial progress is required to mitigate traffic casualties. This\npaper provides a comprehensive survey of state-of-the-art technologies and\nmethodologies to enhance the safety of VRUs. The study delves into the\ncommunication networks between vehicles and VRUs, emphasizing the integration\nof advanced sensors and the availability of relevant datasets. It explores\npreprocessing techniques and data fusion methods to enhance sensor data\nquality. Furthermore, our study assesses critical simulation environments\nessential for developing and testing VRU safety systems. Our research also\nhighlights recent advances in VRU detection and classification algorithms,\naddressing challenges such as variable environmental conditions. Additionally,\nwe cover cutting-edge research in predicting VRU intentions and behaviors,\nwhich is crucial for proactive collision avoidance strategies. Through this\nsurvey, we aim to provide a comprehensive understanding of the current\nlandscape of VRU safety technologies, identifying areas of progress and areas\nneeding further research and development.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Renato M. Silva",
            "Gregrio F. Azevedo",
            "Matheus V. V. Berto",
            "Jean R. Rocha",
            "Eduardo C. Fidelis",
            "Matheus V. Nogueira",
            "Pedro H. Lisboa",
            "Tiago A. Almeida"
        ],
        "published": "2024-05-29T15:42:10Z"
    },
    {
        "title": "Going beyond compositional generalization, DDPMs can produce zero-shot\n  interpolation",
        "link": "http://arxiv.org/abs/2405.19201v1",
        "abstract": "Denoising Diffusion Probabilistic Models (DDPMs) exhibit remarkable\ncapabilities in image generation, with studies suggesting that they can\ngeneralize by composing latent factors learned from the training data. In this\nwork, we go further and study DDPMs trained on strictly separate subsets of the\ndata distribution with large gaps on the support of the latent factors. We show\nthat such a model can effectively generate images in the unexplored,\nintermediate regions of the distribution. For instance, when trained on clearly\nsmiling and non-smiling faces, we demonstrate a sampling procedure which can\ngenerate slightly smiling faces without reference images (zero-shot\ninterpolation). We replicate these findings for other attributes as well as\nother datasets.\n$\\href{https://github.com/jdeschena/ddpm-zero-shot-interpolation}{\\text{Our\ncode is available on GitHub.}}$",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.NE"
        ],
        "authors": [
            "Justin Deschenaux",
            "Igor Krawczuk",
            "Grigorios Chrysos",
            "Volkan Cevher"
        ],
        "published": "2024-05-29T15:41:53Z"
    },
    {
        "title": "LOGO: Video Text Spotting with Language Collaboration and Glyph\n  Perception Model",
        "link": "http://arxiv.org/abs/2405.19194v1",
        "abstract": "Video text spotting aims to simultaneously localize, recognize and track text\ninstances in videos. To address the limited recognition capability of\nend-to-end methods, tracking the zero-shot results of state-of-the-art image\ntext spotters directly can achieve impressive performance. However, owing to\nthe domain gap between different datasets, these methods usually obtain limited\ntracking trajectories on extreme dataset. Fine-tuning transformer-based text\nspotters on specific datasets could yield performance enhancements, albeit at\nthe expense of considerable training resources. In this paper, we propose a\nLanguage Collaboration and Glyph Perception Model, termed LOGO to enhance the\nperformance of conventional text spotters through the integration of a synergy\nmodule. To achieve this goal, a language synergy classifier (LSC) is designed\nto explicitly discern text instances from background noise in the recognition\nstage. Specially, the language synergy classifier can output text content or\nbackground code based on the legibility of text regions, thus computing\nlanguage scores. Subsequently, fusion scores are computed by taking the average\nof detection scores and language scores, and are utilized to re-score the\ndetection results before tracking. By the re-scoring mechanism, the proposed\nLSC facilitates the detection of low-resolution text instances while filtering\nout text-like regions. Besides, the glyph supervision and visual position\nmixture module are proposed to enhance the recognition accuracy of noisy text\nregions, and acquire more discriminative tracking features, respectively.\nExtensive experiments on public benchmarks validate the effectiveness of the\nproposed method.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hongen Liu",
            "Yi Liu",
            "Di Sun",
            "Jiahao Wang",
            "Gang Pan"
        ],
        "published": "2024-05-29T15:35:09Z"
    },
    {
        "title": "Sparse High Dimensional Expanders via Local Lifts",
        "link": "http://arxiv.org/abs/2405.19191v1",
        "abstract": "High dimensional expanders (HDXs) are a hypergraph generalization of expander\ngraphs. They are extensively studied in the math and TCS communities due to\ntheir many applications. Like expander graphs, HDXs are especially interesting\nfor applications when they are bounded degree, namely, if the number of edges\nadjacent to every vertex is bounded. However, only a handful of constructions\nare known to have this property, all of which rely on non-trivial algebraic\ntechniques. In particular, no random or combinatorial construction of bounded\ndegree HDXs is known. As a result, our understanding of these objects is\nlimited.\n  The degree of an $i$-face in an HDX is the number of $(i+1)$-faces containing\nit. In this work we construct HDXs whose higher dimensional faces have bounded\ndegree. This is done by giving an elementary and deterministic algorithm that\ntakes as input a regular $k$-dimensional HDX $X$ and outputs another\n$k$-dimensional HDX $\\widehat{X}$ with twice as many vertices. While the degree\nof vertices in $\\widehat{X}$ grows, the degree of the $(k-1)$-faces in\n$\\widehat{X}$ stays the same. As a result, we obtain a new `algebra-free'\nconstruction of HDXs whose $(k-1)$-face degree is bounded.\n  Our algorithm is based on a simple and natural generalization of the\nconstruction by Bilu and Linial (Combinatorica, 2006), which build expanders\nusing lifts coming from edge signings. Our construction is based on local lifts\nof HDXs, where a local lift is a complex whose top-level links are lifts of\nlinks in the original complex. We demonstrate that a local lift of an HDX is an\nHDX in many cases.\n  In addition, combining local lifts with existing bounded degree constructions\ncreates new families of bounded degree HDXs with significantly different links\nthan before. We use this technique to construct bounded degree high dimensional\nexpanders with links that have arbitrarily large diameters.",
        "subjects": [
            "cs.DM",
            "cs.CC",
            "math.CO"
        ],
        "authors": [
            "Inbar Ben Yaacov",
            "Yotam Dikstein",
            "Gal Maor"
        ],
        "published": "2024-05-29T15:33:15Z"
    },
    {
        "title": "Diffusion-based Dynamics Models for Long-Horizon Rollout in Offline\n  Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.19189v1",
        "abstract": "With the great success of diffusion models (DMs) in generating realistic\nsynthetic vision data, many researchers have investigated their potential in\ndecision-making and control. Most of these works utilized DMs to sample\ndirectly from the trajectory space, where DMs can be viewed as a combination of\ndynamics models and policies. In this work, we explore how to decouple DMs'\nability as dynamics models in fully offline settings, allowing the learning\npolicy to roll out trajectories. As DMs learn the data distribution from the\ndataset, their intrinsic policy is actually the behavior policy induced from\nthe dataset, which results in a mismatch between the behavior policy and the\nlearning policy. We propose Dynamics Diffusion, short as DyDiff, which can\ninject information from the learning policy to DMs iteratively. DyDiff ensures\nlong-horizon rollout accuracy while maintaining policy consistency and can be\neasily deployed on model-free algorithms. We provide theoretical analysis to\nshow the advantage of DMs on long-horizon rollout over models and demonstrate\nthe effectiveness of DyDiff in the context of offline reinforcement learning,\nwhere the rollout dataset is provided but no online environment for\ninteraction. Our code is at https://github.com/FineArtz/DyDiff.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Hanye Zhao",
            "Xiaoshen Han",
            "Zhengbang Zhu",
            "Minghuan Liu",
            "Yong Yu",
            "Weinan Zhang"
        ],
        "published": "2024-05-29T15:29:46Z"
    },
    {
        "title": "Personalized Interiors at Scale: Leveraging AI for Efficient and\n  Customizable Design Solutions",
        "link": "http://arxiv.org/abs/2405.19188v1",
        "abstract": "In this paper, we introduce an innovative application of artificial\nintelligence in the realm of interior design through the integration of Stable\nDiffusion and Dreambooth models. This paper explores the potential of these\nadvanced generative models to streamline and democratize the process of room\ninterior generation, offering a significant departure from conventional,\nlabor-intensive techniques. Our approach leverages the capabilities of Stable\nDiffusion for generating high-quality images and Dreambooth for rapid\ncustomization with minimal training data, addressing the need for efficiency\nand personalization in the design industry. We detail a comprehensive\nmethodology that combines these models, providing a robust framework for the\ncreation of tailored room interiors that reflect individual tastes and\nfunctional requirements. We presents an extensive evaluation of our method,\nsupported by experimental results that demonstrate its effectiveness and a\nseries of case studies that illustrate its practical application in interior\ndesign projects. Our study contributes to the ongoing discourse on the role of\nAI in creative fields, highlighting the benefits of leveraging generative\nmodels to enhance creativity and reshape the future of interior design.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Kaiwen Zhou",
            "Tianyu Wang"
        ],
        "published": "2024-05-29T15:29:21Z"
    },
    {
        "title": "Algorithmic Transparency and Participation through the Handoff Lens:\n  Lessons Learned from the U.S. Census Bureau's Adoption of Differential\n  Privacy",
        "link": "http://arxiv.org/abs/2405.19187v1",
        "abstract": "Emerging discussions on the responsible government use of algorithmic\ntechnologies propose transparency and public participation as key mechanisms\nfor preserving accountability and trust. But in practice, the adoption and use\nof any technology shifts the social, organizational, and political context in\nwhich it is embedded. Therefore translating transparency and participation\nefforts into meaningful, effective accountability must take into account these\nshifts. We adopt two theoretical frames, Mulligan and Nissenbaum's handoff\nmodel and Star and Griesemer's boundary objects, to reveal such shifts during\nthe U.S. Census Bureau's adoption of differential privacy (DP) in its updated\ndisclosure avoidance system (DAS) for the 2020 census. This update preserved\n(and arguably strengthened) the confidentiality protections that the Bureau is\nmandated to uphold, and the Bureau engaged in a range of activities to\nfacilitate public understanding of and participation in the system design\nprocess. Using publicly available documents concerning the Census'\nimplementation of DP, this case study seeks to expand our understanding of how\ntechnical shifts implicate values, how such shifts can afford (or fail to\nafford) greater transparency and participation in system design, and the\nimportance of localized expertise throughout. We present three lessons from\nthis case study toward grounding understandings of algorithmic transparency and\nparticipation: (1) efforts towards transparency and participation in\nalgorithmic governance must center values and policy decisions, not just\ntechnical design decisions; (2) the handoff model is a useful tool for\nrevealing how such values may be cloaked beneath technical decisions; and (3)\nboundary objects alone cannot bridge distant communities without trusted\nexperts traveling alongside to broker their adoption.",
        "subjects": [
            "cs.CY"
        ],
        "authors": [
            "Amina A. Abdu",
            "Lauren M. Chambers",
            "Deirdre K. Mulligan",
            "Abigail Z. Jacobs"
        ],
        "published": "2024-05-29T15:29:16Z"
    },
    {
        "title": "MetaToken: Detecting Hallucination in Image Descriptions by Meta\n  Classification",
        "link": "http://arxiv.org/abs/2405.19186v1",
        "abstract": "Large Vision Language Models (LVLMs) have shown remarkable capabilities in\nmultimodal tasks like visual question answering or image captioning. However,\ninconsistencies between the visual information and the generated text, a\nphenomenon referred to as hallucinations, remain an unsolved problem with\nregard to the trustworthiness of LVLMs. To address this problem, recent works\nproposed to incorporate computationally costly Large (Vision) Language Models\nin order to detect hallucinations on a sentence- or subsentence-level. In this\nwork, we introduce MetaToken, a lightweight binary classifier to detect\nhallucinations on the token-level at negligible cost. Based on a statistical\nanalysis, we reveal key factors of hallucinations in LVLMs which have been\noverseen in previous works. MetaToken can be applied to any open-source LVLM\nwithout any knowledge about ground truth data providing a reliable detection of\nhallucinations. We evaluate our method on four state-of-the-art LVLMs\ndemonstrating the effectiveness of our approach.",
        "subjects": [
            "cs.CV",
            "cs.CL",
            "cs.LG",
            "I.4"
        ],
        "authors": [
            "Laura Fieback",
            "Jakob Spiegelberg",
            "Hanno Gottschalk"
        ],
        "published": "2024-05-29T15:28:42Z"
    },
    {
        "title": "Promoting Two-sided Fairness in Dynamic Vehicle Routing Problem",
        "link": "http://dx.doi.org/10.1145/3638529.3654207",
        "abstract": "Dynamic Vehicle Routing Problem (DVRP), is an extension of the classic\nVehicle Routing Problem (VRP), which is a fundamental problem in logistics and\ntransportation. Typically, DVRPs involve two stakeholders: service providers\nthat deliver services to customers and customers who raise requests from\ndifferent locations. Many real-world applications can be formulated as DVRP\nsuch as ridesharing and non-compliance capture. Apart from original objectives\nlike optimising total utility or efficiency, DVRP should also consider fairness\nfor all parties. Unfairness can induce service providers and customers to give\nup on the systems, leading to negative financial and social impacts. However,\nmost existing DVRP-related applications focus on improving fairness from a\nsingle side, and there have been few works considering two-sided fairness and\nutility optimisation concurrently. To this end, we propose a novel framework, a\nTwo-sided Fairness-aware Genetic Algorithm (named 2FairGA), which expands the\ngenetic algorithm from the original objective solely focusing on utility to\nmulti-objectives that incorporate two-sided fairness. Subsequently, the impact\nof injecting two fairness definitions into the utility-focused model and the\ncorrelation between any pair of the three objectives are explored. Extensive\nexperiments demonstrate the superiority of our proposed framework compared to\nthe state-of-the-art.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Yufan Kang",
            "Rongsheng Zhang",
            "Wei Shao",
            "Flora D. Salim",
            "Jeffrey Chan"
        ],
        "published": "2024-05-29T15:24:28Z"
    },
    {
        "title": "Conditional Latent ODEs for Motion Prediction in Autonomous Driving",
        "link": "http://arxiv.org/abs/2405.19183v1",
        "abstract": "This paper addresses imitation learning for motion prediction problem in\nautonomous driving, especially in multi-agent setting. Different from previous\nmethods based on GAN, we present the conditional latent ordinary differential\nequation (cLODE) to leverage both the generative strength of conditional VAE\nand the continuous representation of neural ODE. Our network architecture is\ninspired from the Latent-ODE model. The experiment shows that our method\noutperform the baseline methods in the simulation of multi-agent driving and is\nvery efficient in term of GPU memory consumption. Our code and docker image are\npublicly available: https://github.com/TruongKhang/cLODE;\nhttps://hub.docker.com/r/kim4375731/clode.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Khang Truong Giang",
            "Yongjae Kim",
            "Andrea Finazzi"
        ],
        "published": "2024-05-29T15:24:22Z"
    },
    {
        "title": "Delay-Doppler Domain Pulse Design for OTFS-NOMA",
        "link": "http://arxiv.org/abs/2405.19182v1",
        "abstract": "We address the challenge of developing an orthogonal time-frequency space\n(OTFS)-based non-orthogonal multiple access (NOMA) system where each user is\nmodulated using orthogonal pulses in the delay Doppler domain. Building upon\nthe concept of the sufficient (bi)orthogonality train-pulse [1], we extend this\nidea by introducing Hermite functions, known for their orthogonality\nproperties. Simulation results demonstrate that our proposed Hermite functions\noutperform the traditional OTFS-NOMA schemes, including power-domain (PDM) NOMA\nand code-domain (CDM) NOMA, in terms of bit error rate (BER) over a\nhigh-mobility channel. The algorithm's complexity is minimal, primarily\ninvolving the demodulation of OTFS. The spectrum efficiency of Hermite-based\nOTFS-NOMA is K times that of OTFS-CDM-NOMA scheme, where K is the spreading\nlength of the NOMA waveform.",
        "subjects": [
            "eess.SP",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Michel Kulhandjian",
            "Hovannes Kulhandjian",
            "Gunes Karabulut Kurt",
            "Halim Yanikomeroglu"
        ],
        "published": "2024-05-29T15:23:42Z"
    },
    {
        "title": "Model Agnostic Defense against Adversarial Patch Attacks on Object\n  Detection in Unmanned Aerial Vehicles",
        "link": "http://arxiv.org/abs/2405.19179v1",
        "abstract": "Object detection forms a key component in Unmanned Aerial Vehicles (UAVs) for\ncompleting high-level tasks that depend on the awareness of objects on the\nground from an aerial perspective. In that scenario, adversarial patch attacks\non an onboard object detector can severely impair the performance of upstream\ntasks. This paper proposes a novel model-agnostic defense mechanism against the\nthreat of adversarial patch attacks in the context of UAV-based object\ndetection. We formulate adversarial patch defense as an occlusion removal task.\nThe proposed defense method can neutralize adversarial patches located on\nobjects of interest, without exposure to adversarial patches during training.\nOur lightweight single-stage defense approach allows us to maintain a\nmodel-agnostic nature, that once deployed does not require to be updated in\nresponse to changes in the object detection pipeline. The evaluations in\ndigital and physical domains show the feasibility of our method for deployment\nin UAV object detection pipelines, by significantly decreasing the Attack\nSuccess Ratio without incurring significant processing costs. As a result, the\nproposed defense solution can improve the reliability of object detection for\nUAVs.",
        "subjects": [
            "cs.CV",
            "cs.RO",
            "I.4.4; I.4.9"
        ],
        "authors": [
            "Saurabh Pathak",
            "Samridha Shrestha",
            "Abdelrahman AlMahmoud"
        ],
        "published": "2024-05-29T15:19:07Z"
    },
    {
        "title": "Model-independent cosmological inference post DESI DR1 BAO measurements",
        "link": "http://arxiv.org/abs/2405.19178v1",
        "abstract": "In this work, we implement Gaussian process regression to reconstruct the\nexpansion history of the universe in a model-agnostic manner, using the\nPantheon-Plus SN-Ia compilation in combination with two different BAO\nmeasurements (SDSS-IV and DESI DR1). In both the reconstructions, the\n$\\Lambda$CDM model is always included in the 95\\% confidence intervals. We find\nevidence that the DESI LRG data at $z_{\\text{eff}} = 0.51$ is not an outlier\nwithin our model-independent framework. We study the $\\mathcal{O}m$-diagnostics\nand the evolution of the total equation of state (EoS) of our universe, which\nhint towards the possibility of a quintessence-like dark energy scenario with a\nvery slowly varying EoS, and a phantom-crossing in higher $z$. The entire\nexercise is later complemented by considering two more SN-Ia compilations -\nDES-5YR and Union3 - in combination with DESI BAO. Reconstruction with the DESI\nBAO + DES-5YR SN data sets predicts that the $\\Lambda$CDM model lies outside\nthe 3$\\sigma$ confidence levels, whereas with DESI BAO + Union3 data, the\n$\\Lambda$CDM model is always included within 1$\\sigma$. We also report\nconstraints on $H_0 r_d$ from our model-agnostic analysis, independent of the\npre-recombination physics. Our results point towards an $\\approx$ 2$\\sigma$\ndiscrepancy between the DESI + Pantheon-Plus and DESI + DES-5YR data sets,\nwhich calls for further investigation.",
        "subjects": [
            "astro-ph.CO",
            "cs.LG",
            "gr-qc"
        ],
        "authors": [
            "Purba Mukherjee",
            "Anjan Ananda Sen"
        ],
        "published": "2024-05-29T15:18:39Z"
    },
    {
        "title": "The ethical situation of DALL-E 2",
        "link": "http://arxiv.org/abs/2405.19176v1",
        "abstract": "A hot topic of Artificial Intelligence right now is image generation from\nprompts. DALL-E 2 is one of the biggest names in this domain, as it allows\npeople to create images from simple text inputs, to even more complicated ones.\nThe company that made this possible, OpenAI, has assured everyone that visited\ntheir website that their mission is to ensure that artificial general\nintelligence benefits all humanity. A noble idea in our opinion, that also\nstood as the motive behind us choosing this subject. This paper analyzes the\nethical implications of an AI image generative system, with an emphasis on how\nsociety is responding to it, how it probably will and how it should if all the\nright measures are taken.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "authors": [
            "Eduard Hogea",
            "Josem Rocafortf"
        ],
        "published": "2024-05-29T15:18:13Z"
    },
    {
        "title": "Online Linear Regression in Dynamic Environments via Discounting",
        "link": "http://arxiv.org/abs/2405.19175v1",
        "abstract": "We develop algorithms for online linear regression which achieve optimal\nstatic and dynamic regret guarantees \\emph{even in the complete absence of\nprior knowledge}. We present a novel analysis showing that a discounted variant\nof the Vovk-Azoury-Warmuth forecaster achieves dynamic regret of the form\n$R_{T}(\\vec{u})\\le O\\left(d\\log(T)\\vee\n\\sqrt{dP_{T}^{\\gamma}(\\vec{u})T}\\right)$, where $P_{T}^{\\gamma}(\\vec{u})$ is a\nmeasure of variability of the comparator sequence, and show that the discount\nfactor achieving this result can be learned on-the-fly. We show that this\nresult is optimal by providing a matching lower bound. We also extend our\nresults to \\emph{strongly-adaptive} guarantees which hold over every\nsub-interval $[a,b]\\subseteq[1,T]$ simultaneously.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Andrew Jacobsen",
            "Ashok Cutkosky"
        ],
        "published": "2024-05-29T15:17:53Z"
    },
    {
        "title": "Exploring AI-based Anonymization of Industrial Image and Video Data in\n  the Context of Feature Preservation",
        "link": "http://arxiv.org/abs/2405.19173v1",
        "abstract": "With rising technologies, the protection of privacy-sensitive information is\nbecoming increasingly important. In industry and production facilities, image\nor video recordings are beneficial for documentation, tracing production errors\nor coordinating workflows. Individuals in images or videos need to be\nanonymized. However, the anonymized data should be reusable for further\napplications. In this work, we apply the Deep Learning-based full-body\nanonymization framework DeepPrivacy2, which generates artificial identities, to\nindustrial image and video data. We compare its performance with conventional\nanonymization techniques. Therefore, we consider the quality of identity\ngeneration, temporal consistency, and the applicability of pose estimation and\naction recognition.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Sabrina Cynthia Triess",
            "Timo Leitritz",
            "Christian Jauch"
        ],
        "published": "2024-05-29T15:15:52Z"
    },
    {
        "title": "Greedy Kernel Methods for Approximating Breakthrough Curves for Reactive\n  Flow from 3D Porous Geometry Data",
        "link": "http://arxiv.org/abs/2405.19170v1",
        "abstract": "We address the challenging application of 3D pore scale reactive flow under\nvarying geometry parameters. The task is to predict time-dependent integral\nquantities, i.e., breakthrough curves, from the given geometries. As the 3D\nreactive flow simulation is highly complex and computationally expensive, we\nare interested in data-based surrogates that can give a rapid prediction of the\ntarget quantities of interest. This setting is an example of an application\nwith scarce data, i.e., only having available few data samples, while the input\nand output dimensions are high. In this scarce data setting, standard machine\nlearning methods are likely to ail. Therefore, we resort to greedy kernel\napproximation schemes that have shown to be efficient meshless approximation\ntechniques for multivariate functions. We demonstrate that such methods can\nefficiently be used in the high-dimensional input/output case under scarce\ndata. Especially, we show that the vectorial kernel orthogonal greedy\napproximation (VKOGA) procedure with a data-adapted two-layer kernel yields\nexcellent predictors for learning from 3D geometry voxel data via both\nmorphological descriptors or principal component analysis.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Robin Herkert",
            "Patrick Buchfink",
            "Tizian Wenzel",
            "Bernard Haasdonk",
            "Pavel Toktaliev",
            "Oleg Iliev"
        ],
        "published": "2024-05-29T15:14:28Z"
    },
    {
        "title": "Transformers as Neural Operators for Solutions of Differential Equations\n  with Finite Regularity",
        "link": "http://arxiv.org/abs/2405.19166v1",
        "abstract": "Neural operator learning models have emerged as very effective surrogates in\ndata-driven methods for partial differential equations (PDEs) across different\napplications from computational science and engineering. Such operator learning\nmodels not only predict particular instances of a physical or biological system\nin real-time but also forecast classes of solutions corresponding to a\ndistribution of initial and boundary conditions or forcing terms. % DeepONet is\nthe first neural operator model and has been tested extensively for a broad\nclass of solutions, including Riemann problems. Transformers have not been used\nin that capacity, and specifically, they have not been tested for solutions of\nPDEs with low regularity. %\n  In this work, we first establish the theoretical groundwork that transformers\npossess the universal approximation property as operator learning models.\n  We then apply transformers to forecast solutions of diverse dynamical systems\nwith solutions of finite regularity for a plurality of initial conditions and\nforcing terms. In particular, we consider three examples: the Izhikevich neuron\nmodel, the tempered fractional-order Leaky Integrate-and-Fire (LIF) model, and\nthe one-dimensional Euler equation Riemann problem. For the latter problem, we\nalso compare with variants of DeepONet, and we find that transformers\noutperform DeepONet in accuracy but they are computationally more expensive.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Benjamin Shih",
            "Ahmad Peyvan",
            "Zhongqiang Zhang",
            "George Em Karniadakis"
        ],
        "published": "2024-05-29T15:10:24Z"
    },
    {
        "title": "Learning from Litigation: Graphs and LLMs for Retrieval and Reasoning in\n  eDiscovery",
        "link": "http://arxiv.org/abs/2405.19164v1",
        "abstract": "Electronic Discovery (eDiscovery) involves identifying relevant documents\nfrom a vast collection based on legal production requests. The integration of\nartificial intelligence (AI) and natural language processing (NLP) has\ntransformed this process, helping document review and enhance efficiency and\ncost-effectiveness. Although traditional approaches like BM25 or fine-tuned\npre-trained models are common in eDiscovery, they face performance,\ncomputational, and interpretability challenges. In contrast, Large Language\nModel (LLM)-based methods prioritize interpretability but sacrifice performance\nand throughput. This paper introduces DISCOvery Graph (DISCOG), a hybrid\napproach that combines the strengths of two worlds: a heterogeneous graph-based\nmethod for accurate document relevance prediction and subsequent LLM-driven\napproach for reasoning. Graph representational learning generates embeddings\nand predicts links, ranking the corpus for a given request, and the LLMs\nprovide reasoning for document relevance. Our approach handles datasets with\nbalanced and imbalanced distributions, outperforming baselines in F1-score,\nprecision, and recall by an average of 12%, 3%, and 16%, respectively. In an\nenterprise context, our approach drastically reduces document review costs by\n99.9% compared to manual processes and by 95% compared to LLM-based\nclassification methods",
        "subjects": [
            "cs.AI",
            "cs.IR"
        ],
        "authors": [
            "Sounak Lahiri",
            "Sumit Pai",
            "Tim Weninger",
            "Sanmitra Bhattacharya"
        ],
        "published": "2024-05-29T15:08:55Z"
    },
    {
        "title": "Does learning the right latent variables necessarily improve in-context\n  learning?",
        "link": "http://arxiv.org/abs/2405.19162v1",
        "abstract": "Large autoregressive models like Transformers can solve tasks through\nin-context learning (ICL) without learning new weights, suggesting avenues for\nefficiently solving new tasks. For many tasks, e.g., linear regression, the\ndata factorizes: examples are independent given a task latent that generates\nthe data, e.g., linear coefficients. While an optimal predictor leverages this\nfactorization by inferring task latents, it is unclear if Transformers\nimplicitly do so or if they instead exploit heuristics and statistical\nshortcuts enabled by attention layers. Both scenarios have inspired active\nongoing work. In this paper, we systematically investigate the effect of\nexplicitly inferring task latents. We minimally modify the Transformer\narchitecture with a bottleneck designed to prevent shortcuts in favor of more\nstructured solutions, and then compare performance against standard\nTransformers across various ICL tasks. Contrary to intuition and some recent\nworks, we find little discernible difference between the two; biasing towards\ntask-relevant latent variables does not lead to better out-of-distribution\nperformance, in general. Curiously, we find that while the bottleneck\neffectively learns to extract latent task variables from context, downstream\nprocessing struggles to utilize them for robust prediction. Our study\nhighlights the intrinsic limitations of Transformers in achieving structured\nICL solutions that generalize, and shows that while inferring the right latents\naids interpretability, it is not sufficient to alleviate this problem.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Sarthak Mittal",
            "Eric Elmoznino",
            "Leo Gagnon",
            "Sangnie Bhardwaj",
            "Dhanya Sridhar",
            "Guillaume Lajoie"
        ],
        "published": "2024-05-29T15:06:10Z"
    },
    {
        "title": "Which are the True Defeasible Logics?",
        "link": "http://arxiv.org/abs/2405.19157v1",
        "abstract": "The class of defeasible logics is only vaguely defined -- it is defined by a\nfew exemplars and the general idea of efficient reasoning with defeasible\nrules. The recent definition of the defeasible logic $DL(\\partial_{||})$\nintroduced new features to such logics, which have repercussions that we\nexplore. In particular, we define a class of logics that accommodates the new\nlogic while retaining the traditional properties of defeasible logics.",
        "subjects": [
            "cs.LO",
            "03B70, 03B60, 68T27",
            "I.2.3; I.2.4; F.4.1"
        ],
        "authors": [
            "Michael J. Maher"
        ],
        "published": "2024-05-29T15:00:42Z"
    },
    {
        "title": "Beyond Discrepancy: A Closer Look at the Theory of Distribution Shift",
        "link": "http://arxiv.org/abs/2405.19156v1",
        "abstract": "Many machine learning models appear to deploy effortlessly under distribution\nshift, and perform well on a target distribution that is considerably different\nfrom the training distribution. Yet, learning theory of distribution shift\nbounds performance on the target distribution as a function of the discrepancy\nbetween the source and target, rarely guaranteeing high target accuracy.\nMotivated by this gap, this work takes a closer look at the theory of\ndistribution shift for a classifier from a source to a target distribution.\nInstead of relying on the discrepancy, we adopt an Invariant-Risk-Minimization\n(IRM)-like assumption connecting the distributions, and characterize conditions\nunder which data from a source distribution is sufficient for accurate\nclassification of the target. When these conditions are not met, we show when\nonly unlabeled data from the target is sufficient, and when labeled target data\nis needed. In all cases, we provide rigorous theoretical guarantees in the\nlarge sample regime.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Robi Bhattacharjee",
            "Nick Rittler",
            "Kamalika Chaudhuri"
        ],
        "published": "2024-05-29T15:00:19Z"
    },
    {
        "title": "A Study of Plasticity Loss in On-Policy Deep Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.19153v1",
        "abstract": "Continual learning with deep neural networks presents challenges distinct\nfrom both the fixed-dataset and convex continual learning regimes. One such\nchallenge is plasticity loss, wherein a neural network trained in an online\nfashion displays a degraded ability to fit new tasks. This problem has been\nextensively studied in both supervised learning and off-policy reinforcement\nlearning (RL), where a number of remedies have been proposed. Still, plasticity\nloss has received less attention in the on-policy deep RL setting. Here we\nperform an extensive set of experiments examining plasticity loss and a variety\nof mitigation methods in on-policy deep RL. We demonstrate that plasticity loss\nis pervasive under domain shift in this regime, and that a number of methods\ndeveloped to resolve it in other settings fail, sometimes even resulting in\nperformance that is worse than performing no intervention at all. In contrast,\nwe find that a class of ``regenerative'' methods are able to consistently\nmitigate plasticity loss in a variety of contexts, including in gridworld tasks\nand more challenging environments like Montezuma's Revenge and ProcGen.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Arthur Juliani",
            "Jordan T. Ash"
        ],
        "published": "2024-05-29T14:59:49Z"
    },
    {
        "title": "CaLa: Complementary Association Learning for Augmenting Composed Image\n  Retrieval",
        "link": "http://dx.doi.org/10.1145/3626772.3657823",
        "abstract": "Composed Image Retrieval (CIR) involves searching for target images based on\nan image-text pair query. While current methods treat this as a query-target\nmatching problem, we argue that CIR triplets contain additional associations\nbeyond this primary relation. In our paper, we identify two new relations\nwithin triplets, treating each triplet as a graph node. Firstly, we introduce\nthe concept of text-bridged image alignment, where the query text serves as a\nbridge between the query image and the target image. We propose a hinge-based\ncross-attention mechanism to incorporate this relation into network learning.\nSecondly, we explore complementary text reasoning, considering CIR as a form of\ncross-modal retrieval where two images compose to reason about complementary\ntext. To integrate these perspectives effectively, we design a twin\nattention-based compositor. By combining these complementary associations with\nthe explicit query pair-target image relation, we establish a comprehensive set\nof constraints for CIR. Our framework, CaLa (Complementary Association Learning\nfor Augmenting Composed Image Retrieval), leverages these insights. We evaluate\nCaLa on CIRR and FashionIQ benchmarks with multiple backbones, demonstrating\nits superiority in composed image retrieval.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.IR"
        ],
        "authors": [
            "Xintong Jiang",
            "Yaxiong Wang",
            "Mengjian Li",
            "Yujiao Wu",
            "Bingwen Hu",
            "Xueming Qian"
        ],
        "published": "2024-05-29T14:52:10Z"
    },
    {
        "title": "Dress Anyone : Automatic Physically-Based Garment Pattern Refitting",
        "link": "http://arxiv.org/abs/2405.19148v1",
        "abstract": "Well-fitted clothing is essential for both real and virtual garments to\nenable self-expression and accurate representation for a large variety of body\ntypes. Common practice in the industry is to provide a pre-made selection of\ndistinct garment sizes such as small, medium and large. While these may cater\nto certain groups of individuals that fall within this distribution, they often\nexclude large sections of the population. In contrast, individually tailored\nclothing offers a solution to obtain custom-fit garments that are tailored to\neach individual. However, manual tailoring is time-consuming and requires\nspecialized knowledge, prohibiting the approach from being applied to produce\nfitted clothing at scale. To address this challenge, we propose a novel method\nleveraging differentiable simulation for refitting and draping 3D garments and\ntheir corresponding 2D pattern panels onto a new body shape, enabling a\nworkflow where garments only need to be designed once, in a single size, and\nthey can be automatically refitted to support numerous body size and shape\nvariations. Our method enables downstream applications, where our optimized 3D\ndrape can be directly ingested into game engines or other applications. Our 2D\nsewing patterns allow for accurate physics-based simulations and enables\nmanufacturing clothing for the real world.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Hsiao-yu Chen",
            "Egor Larionov",
            "Ladislav Kavan",
            "Gene Lin",
            "Doug Roble",
            "Olga Sorkine-Hornung",
            "Tuur Stuyck"
        ],
        "published": "2024-05-29T14:51:59Z"
    },
    {
        "title": "Homomorphism Counts to Trees",
        "link": "http://arxiv.org/abs/2405.19147v1",
        "abstract": "We construct a pair of non-isomorphic, bipartite graphs which are not\ndistinguished by counting the number of homomorphisms to any tree. This answers\na question raised by Atserias et al. (LICS 2021). In order to establish the\nconstruction, we analyse the equivalence relations induced by counting\nhomomorphisms to trees of diameter two and three and obtain necessary and\nsufficient conditions for two graphs to be equivalent. We show that three is\nthe optimal diameter for our construction.",
        "subjects": [
            "cs.DM",
            "math.CO",
            "05C60 (primary) 68R10 (secondary)",
            "G.2.1; G.2.2"
        ],
        "authors": [
            "Anuj Dawar"
        ],
        "published": "2024-05-29T14:51:54Z"
    },
    {
        "title": "I Bet You Did Not Mean That: Testing Semantic Importance via Betting",
        "link": "http://arxiv.org/abs/2405.19146v1",
        "abstract": "Recent works have extended notions of feature importance to \\emph{semantic\nconcepts} that are inherently interpretable to the users interacting with a\nblack-box predictive model. Yet, precise statistical guarantees, such as false\npositive rate control, are needed to communicate findings transparently and to\navoid unintended consequences in real-world scenarios. In this paper, we\nformalize the global (i.e., over a population) and local (i.e., for a sample)\nstatistical importance of semantic concepts for the predictions of opaque\nmodels, by means of conditional independence, which allows for rigorous\ntesting. We use recent ideas of sequential kernelized testing (SKIT) to induce\na rank of importance across concepts, and showcase the effectiveness and\nflexibility of our framework on synthetic datasets as well as on image\nclassification tasks using vision-language models such as CLIP.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Jacopo Teneggi",
            "Jeremias Sulam"
        ],
        "published": "2024-05-29T14:51:41Z"
    },
    {
        "title": "DeepOKAN: Deep Operator Network Based on Kolmogorov Arnold Networks for\n  Mechanics Problems",
        "link": "http://arxiv.org/abs/2405.19143v1",
        "abstract": "The modern digital engineering design often requires costly repeated\nsimulations for different scenarios. The prediction capability of neural\nnetworks (NNs) makes them suitable surrogates for providing design insights.\nHowever, only a few NNs can efficiently handle complex engineering scenario\npredictions. We introduce a new version of the neural operators called\nDeepOKAN, which utilizes Kolmogorov Arnold networks (KANs) rather than the\nconventional neural network architectures. Our DeepOKAN uses Gaussian radial\nbasis functions (RBFs) rather than the B-splines. The DeepOKAN is used to\ndevelop surrogates for different mechanics problems. This approach should pave\nthe way for further improving the performance of neural operators. Based on the\ncurrent investigations, we observe that DeepOKANs require a smaller number of\nlearnable parameters than current MLP-based DeepONets to achieve comparable\naccuracy.",
        "subjects": [
            "cs.CE"
        ],
        "authors": [
            "Diab W. Abueidda",
            "Panos Pantidis",
            "Mostafa E. Mobasher"
        ],
        "published": "2024-05-29T14:48:49Z"
    },
    {
        "title": "DGRC: An Effective Fine-tuning Framework for Distractor Generation in\n  Chinese Multi-choice Reading Comprehension",
        "link": "http://arxiv.org/abs/2405.19139v1",
        "abstract": "When evaluating a learner's knowledge proficiency, the multiple-choice\nquestion is an efficient and widely used format in standardized tests.\nNevertheless, generating these questions, particularly plausible distractors\n(incorrect options), poses a considerable challenge. Generally, the distractor\ngeneration can be classified into cloze-style distractor generation (CDG) and\nnatural questions distractor generation (NQDG). In contrast to the CDG,\nutilizing pre-trained language models (PLMs) for NQDG presents three primary\nchallenges: (1) PLMs are typically trained to generate ``correct'' content,\nlike answers, while rarely trained to generate ``plausible\" content, like\ndistractors; (2) PLMs often struggle to produce content that aligns well with\nspecific knowledge and the style of exams; (3) NQDG necessitates the model to\nproduce longer, context-sensitive, and question-relevant distractors. In this\nstudy, we introduce a fine-tuning framework named DGRC for NQDG in Chinese\nmulti-choice reading comprehension from authentic examinations. DGRC comprises\nthree major components: hard chain-of-thought, multi-task learning, and\ngeneration mask patterns. The experiment results demonstrate that DGRC\nsignificantly enhances generation performance, achieving a more than 2.5-fold\nimprovement in BLEU scores.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Runfeng Lin",
            "Dacheng Xu",
            "Huijiang Wang",
            "Zebiao Chen",
            "Yating Wang",
            "Shouqiang Liu"
        ],
        "published": "2024-05-29T14:47:01Z"
    },
    {
        "title": "Multi-Source Coflow Scheduling in Collaborative Edge Computing with\n  Multihop Network",
        "link": "http://arxiv.org/abs/2405.19136v1",
        "abstract": "Collaborative edge computing has become a popular paradigm where edge devices\ncollaborate by sharing resources. Data dissemination is a fundamental problem\nin CEC to decide what data is transmitted from which device and how. Existing\nworks on data dissemination have not focused on coflow scheduling in CEC, which\ninvolves deciding the order of flows within and across coflows at network\nlinks. Coflow implies a set of parallel flows with a shared objective. The\nexisting works on coflow scheduling in data centers usually assume a\nnon-blocking switch and do not consider congestion at different links in the\nmulti-hop path in CEC, leading to increased coflow completion time (CCT).\nFurthermore, existing works do not consider multiple flow sources that cannot\nbe ignored, as data can have duplicate copies at different edge devices. This\nwork formulates the multi-source coflow scheduling problem in CEC, which\nincludes jointly deciding the source and flow ordering for multiple coflows to\nminimize the sum of CCT. This problem is shown to be NP-hard and challenging as\neach flow can have multiple dependent conflicts at multiple links. We propose a\nsource and coflow-aware search and adjust (SCASA) heuristic that first provides\nan initial solution considering the coflow characteristics. SCASA further\nimproves the initial solution using the source search and adjust heuristic by\nleveraging the knowledge of both coflows and network congestion at links.\nEvaluation done using simulation experiments shows that SCASA leads to up to\n83% reduction in the sum of CCT compared to benchmarks without a joint\nsolution.",
        "subjects": [
            "cs.NI",
            "cs.DC"
        ],
        "authors": [
            "Yuvraj Sahni",
            "Jiannong Cao",
            "Lei Yang",
            "Shengwei Wang"
        ],
        "published": "2024-05-29T14:41:57Z"
    },
    {
        "title": "Preamble Design and Burst-Mode DSP for Upstream Reception of 200G\n  Coherent TDM-PON",
        "link": "http://arxiv.org/abs/2405.19133v1",
        "abstract": "Burst-mode DSP based on 10ns preamble is proposed for upstream reception of\n200G coherent TDM-PON. The 128-symbol tone preamble is used for SOP, frequency\noffset, and sampling phase estimation, while the 192-symbol CAZAC preamble is\nused for frame synchronization and channel estimation.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Haide Wang",
            "Ji Zhou",
            "Jinyang Yang",
            "Zhiyang Liu",
            "Cheng Li",
            "Weiping Liu",
            "Changyuan Yu"
        ],
        "published": "2024-05-29T14:39:58Z"
    },
    {
        "title": "Analyzing Chat Protocols of Novice Programmers Solving Introductory\n  Programming Tasks with ChatGPT",
        "link": "http://arxiv.org/abs/2405.19132v1",
        "abstract": "Large Language Models (LLMs) have taken the world by storm, and students are\nassumed to use related tools at a great scale. In this research paper we aim to\ngain an understanding of how introductory programming students chat with LLMs\nand related tools, e.g., ChatGPT-3.5. To address this goal, computing students\nat a large German university were motivated to solve programming exercises with\nthe assistance of ChatGPT as part of their weekly introductory course\nexercises. Then students (n=213) submitted their chat protocols (with 2335\nprompts in sum) as data basis for this analysis. The data was analyzed w.r.t.\nthe prompts, frequencies, the chats' progress, contents, and other use pattern,\nwhich revealed a great variety of interactions, both potentially supportive and\nconcerning. Learning about students' interactions with ChatGPT will help inform\nand align teaching practices and instructions for future introductory\nprogramming courses in higher education.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Andreas Scholl",
            "Daniel Schiffner",
            "Natalie Kiesler"
        ],
        "published": "2024-05-29T14:38:32Z"
    },
    {
        "title": "Learning Interpretable Scheduling Algorithms for Data Processing\n  Clusters",
        "link": "http://arxiv.org/abs/2405.19131v1",
        "abstract": "Workloads in data processing clusters are often represented in the form of\nDAG (Directed Acyclic Graph) jobs. Scheduling DAG jobs is challenging. Simple\nheuristic scheduling algorithms are often adopted in practice in production\ndata centres. There is much room for scheduling performance optimisation for\ncost saving. Recently, reinforcement learning approaches (like decima) have\nbeen attempted to optimise DAG job scheduling and demonstrate clear performance\ngain in comparison to traditional algorithms. However, reinforcement learning\n(RL) approaches face their own problems in real-world deployment. In\nparticular, their black-box decision making processes and generalizability in\nunseen workloads may add a non-trivial burden to the cluster administrators.\nMoreover, adapting RL models on unseen workloads often requires significant\namount of training data, which leaves edge cases run in a sub-optimal mode. To\nfill the gap, we propose a new method to distill a simple scheduling policy\nbased on observations of the behaviours of a complex deep learning model. The\nsimple model not only provides interpretability of scheduling decisions, but\nalso adaptive to edge cases easily through tuning. We show that our method\nachieves high fidelity to the decisions made by deep learning models and\noutperforms these models when additional heuristics are taken into account.",
        "subjects": [
            "cs.DC",
            "68M20",
            "I.2.8; D.4.1"
        ],
        "authors": [
            "Zhibo Hu",
            "Chen Wang",
            " Helen",
            " Paik",
            "Yanfeng Shu",
            "Liming Zhu"
        ],
        "published": "2024-05-29T14:37:48Z"
    },
    {
        "title": "Federated Assemblies",
        "link": "http://arxiv.org/abs/2405.19129v1",
        "abstract": "A citizens' assembly is a group of people who are randomly selected to\nrepresent a larger population in a deliberation. While this approach has\nsuccessfully strengthened democracy, it has certain limitations that suggest\nthe need for assemblies to form and associate more organically. In response, we\npropose federated assemblies, where assemblies are interconnected, and each\nparent assembly is selected from members of its child assemblies. The main\ntechnical challenge is to develop random selection algorithms that meet new\nrepresentation constraints inherent in this hierarchical structure. We design\nand analyze several algorithms that provide different representation guarantees\nunder various assumptions on the structure of the underlying graph.",
        "subjects": [
            "cs.GT",
            "cs.DC"
        ],
        "authors": [
            "Daniel Halpern",
            "Ariel D. Procaccia",
            "Ehud Shapiro",
            "Nimrod Talmon"
        ],
        "published": "2024-05-29T14:35:57Z"
    },
    {
        "title": "Early Detection of Critical Urban Events using Mobile Phone Network Data",
        "link": "http://arxiv.org/abs/2405.19125v1",
        "abstract": "Network Signalling Data (NSD) have the potential to provide continuous\nspatio-temporal information about the presence, mobility, and usage patterns of\ncell phone services by individuals. Such information is invaluable for\nmonitoring large urban areas and supporting the implementation of\ndecision-making services. When analyzed in real time, NSD can enable the early\ndetection of critical urban events, including fires, large accidents,\nstampedes, terrorist attacks, and sports and leisure gatherings, especially if\nthese events significantly impact mobile phone network activity in the affected\nareas. This paper presents empirical evidence that advanced NSD can detect\nanomalies in mobile traffic service consumption, attributable to critical urban\nevents, with fine spatial and temporal resolutions. We introduce two\nmethodologies for real-time anomaly detection from multivariate time series\nextracted from large-scale NSD, utilizing a range of algorithms adapted from\nthe state-of-the-art in unsupervised machine learning techniques for anomaly\ndetection. Our research includes a comprehensive quantitative evaluation of\nthese algorithms on a large-scale dataset of NSD service consumption for the\nParis region. The evaluation uses an original dataset of documented critical or\nunusual urban events. This dataset has been built as a ground truth basis for\nassessing the algorithms performance. The obtained results demonstrate that our\nframework can detect unusual events almost instantaneously and locate the\naffected areas with high precision, largely outperforming random classifiers.\nThis efficiency and effectiveness underline the potential of NSD-based anomaly\ndetection in significantly enhancing emergency response strategies and urban\nplanning.",
        "subjects": [
            "cs.CY",
            "physics.soc-ph"
        ],
        "authors": [
            "Pierre Lemaire",
            "Angelo Furno",
            "Stefania Rubrichi",
            "Alexis Bondu",
            "Zbigniew Smoreda",
            "Cezary Ziemlicki",
            "Nour-Eddin El Faouzi",
            "Eric Gaume"
        ],
        "published": "2024-05-29T14:31:39Z"
    },
    {
        "title": "ACCSAMS: Automatic Conversion of Exam Documents to Accessible Learning\n  Material for Blind and Visually Impaired",
        "link": "http://arxiv.org/abs/2405.19124v1",
        "abstract": "Exam documents are essential educational materials for exam preparation.\nHowever, they pose a significant academic barrier for blind and visually\nimpaired students, as they are often created without accessibility\nconsiderations. Typically, these documents are incompatible with screen\nreaders, contain excessive white space, and lack alternative text for visual\nelements. This situation frequently requires intervention by experienced\nsighted individuals to modify the format and content for accessibility. We\npropose ACCSAMS, a semi-automatic system designed to enhance the accessibility\nof exam documents. Our system offers three key contributions: (1) creating an\naccessible layout and removing unnecessary white space, (2) adding navigational\nstructures, and (3) incorporating alternative text for visual elements that\nwere previously missing. Additionally, we present the first multilingual\nmanually annotated dataset, comprising 1,293 German and 900 English exam\ndocuments which could serve as a good training source for deep learning models.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "David Wilkening",
            "Omar Moured",
            "Thorsten Schwarz",
            "Karin Muller",
            "Rainer Stiefelhagen"
        ],
        "published": "2024-05-29T14:30:06Z"
    },
    {
        "title": "Spatio-Spectral Graph Neural Networks",
        "link": "http://arxiv.org/abs/2405.19121v1",
        "abstract": "Spatial Message Passing Graph Neural Networks (MPGNNs) are widely used for\nlearning on graph-structured data. However, key limitations of l-step MPGNNs\nare that their \"receptive field\" is typically limited to the l-hop neighborhood\nof a node and that information exchange between distant nodes is limited by\nover-squashing. Motivated by these limitations, we propose Spatio-Spectral\nGraph Neural Networks (S$^2$GNNs) -- a new modeling paradigm for Graph Neural\nNetworks (GNNs) that synergistically combines spatially and spectrally\nparametrized graph filters. Parameterizing filters partially in the frequency\ndomain enables global yet efficient information propagation. We show that\nS$^2$GNNs vanquish over-squashing and yield strictly tighter\napproximation-theoretic error bounds than MPGNNs. Further, rethinking graph\nconvolutions at a fundamental level unlocks new design spaces. For example,\nS$^2$GNNs allow for free positional encodings that make them strictly more\nexpressive than the 1-Weisfeiler-Lehman (WL) test. Moreover, to obtain\ngeneral-purpose S$^2$GNNs, we propose spectrally parametrized filters for\ndirected graphs. S$^2$GNNs outperform spatial MPGNNs, graph transformers, and\ngraph rewirings, e.g., on the peptide long-range benchmark tasks, and are\ncompetitive with state-of-the-art sequence modeling. On a 40 GB GPU, S$^2$GNNs\nscale to millions of nodes.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Simon Geisler",
            "Arthur Kosmala",
            "Daniel Herbst",
            "Stephan Gnnemann"
        ],
        "published": "2024-05-29T14:28:08Z"
    },
    {
        "title": "Can Graph Learning Improve Task Planning?",
        "link": "http://arxiv.org/abs/2405.19119v1",
        "abstract": "Task planning is emerging as an important research topic alongside the\ndevelopment of large language models (LLMs). It aims to break down complex user\nrequests into solvable sub-tasks, thereby fulfilling the original requests. In\nthis context, the sub-tasks can be naturally viewed as a graph, where the nodes\nrepresent the sub-tasks, and the edges denote the dependencies among them.\nConsequently, task planning is a decision-making problem that involves\nselecting a connected path or subgraph within the corresponding graph and\ninvoking it. In this paper, we explore graph learning-based methods for task\nplanning, a direction that is orthogonal to the prevalent focus on prompt\ndesign. Our interest in graph learning stems from a theoretical discovery: the\nbiases of attention and auto-regressive loss impede LLMs' ability to\neffectively navigate decision-making on graphs, which is adeptly addressed by\ngraph neural networks (GNNs). This theoretical insight led us to integrate GNNs\nwith LLMs to enhance overall performance. Extensive experiments demonstrate\nthat GNN-based methods surpass existing solutions even without training, and\nminimal training can further enhance their performance. Additionally, our\napproach complements prompt engineering and fine-tuning techniques, with\nperformance further enhanced by improved prompts or a fine-tuned model.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Xixi Wu",
            "Yifei Shen",
            "Caihua Shan",
            "Kaitao Song",
            "Siwei Wang",
            "Bohang Zhang",
            "Jiarui Feng",
            "Hong Cheng",
            "Wei Chen",
            "Yun Xiong",
            "Dongsheng Li"
        ],
        "published": "2024-05-29T14:26:24Z"
    },
    {
        "title": "ChartFormer: A Large Vision Language Model for Converting Chart Images\n  into Tactile Accessible SVGs",
        "link": "http://arxiv.org/abs/2405.19117v1",
        "abstract": "Visualizations, such as charts, are crucial for interpreting complex data.\nHowever, they are often provided as raster images, which are not compatible\nwith assistive technologies for people with blindness and visual impairments,\nsuch as embossed papers or tactile displays. At the same time, creating\naccessible vector graphics requires a skilled sighted person and is\ntime-intensive. In this work, we leverage advancements in the field of chart\nanalysis to generate tactile charts in an end-to-end manner. Our three key\ncontributions are as follows: (1) introducing the ChartFormer model trained to\nconvert raster chart images into tactile-accessible SVGs, (2) training this\nmodel on the Chart2Tactile dataset, a synthetic chart dataset we created\nfollowing accessibility standards, and (3) evaluating the effectiveness of our\nSVGs through a pilot user study with an refreshable two-dimensional tactile\ndisplay. Our work is publicly available at\nhttps://github.com/nsothman/ChartFormer .",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Omar Moured",
            "Sara Alzalabny",
            "Anas Osman",
            "Thorsten Schwarz",
            "Karin Muller",
            "Rainer Stiefelhagen"
        ],
        "published": "2024-05-29T14:24:42Z"
    },
    {
        "title": "Reconstructing Interpretable Features in Computational Super-Resolution\n  microscopy via Regularized Latent Search",
        "link": "http://arxiv.org/abs/2405.19112v1",
        "abstract": "Supervised deep learning approaches can artificially increase the resolution\nof microscopy images by learning a mapping between two image resolutions or\nmodalities. However, such methods often require a large set of hard-to-get\nlow-res/high-res image pairs and produce synthetic images with a moderate\nincrease in resolution. Conversely, recent methods based on GAN latent search\noffered a drastic increase in resolution without the need of paired images.\nHowever, they offer limited reconstruction of the high-resolution image\ninterpretable features. Here, we propose a robust super-resolution method based\non regularized latent search~(RLS) that offers an actionable balance between\nfidelity to the ground-truth and realism of the recovered image given a\ndistribution prior. The latter allows to split the analysis of a low-resolution\nimage into a computational super-resolution task performed by deep learning\nfollowed by a quantification task performed by a handcrafted algorithm and\nbased on interpretable biological features. This two-step process holds\npotential for various applications such as diagnostics on mobile devices, where\nthe main aim is not to recover the high-resolution details of a specific sample\nbut rather to obtain high-resolution images that preserve explainable and\nquantifiable differences between conditions.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Marzieh Gheisari",
            "Auguste Genovesio"
        ],
        "published": "2024-05-29T14:20:46Z"
    },
    {
        "title": "Alt4Blind: A User Interface to Simplify Charts Alt-Text Creation",
        "link": "http://arxiv.org/abs/2405.19111v1",
        "abstract": "Alternative Texts (Alt-Text) for chart images are essential for making\ngraphics accessible to people with blindness and visual impairments.\nTraditionally, Alt-Text is manually written by authors but often encounters\nissues such as oversimplification or complication. Recent trends have seen the\nuse of AI for Alt-Text generation. However, existing models are susceptible to\nproducing inaccurate or misleading information. We address this challenge by\nretrieving high-quality alt-texts from similar chart images, serving as a\nreference for the user when creating alt-texts. Our three contributions are as\nfollows: (1) we introduce a new benchmark comprising 5,000 real images with\nsemantically labeled high-quality Alt-Texts, collected from Human Computer\nInteraction venues. (2) We developed a deep learning-based model to rank and\nretrieve similar chart images that share the same visual and textual semantics.\n(3) We designed a user interface (UI) to facilitate the alt-text creation\nprocess. Our preliminary interviews and investigations highlight the usability\nof our UI. For the dataset and further details, please refer to our project\npage: https://moured.github.io/alt4blind/.",
        "subjects": [
            "cs.CV",
            "cs.HC"
        ],
        "authors": [
            "Omar Moured",
            "Shahid Ali Farooqui",
            "Karin Muller",
            "Sharifeh Fadaeijouybari",
            "Thorsten Schwarz",
            "Mohammed Javed",
            "Rainer Stiefelhagen"
        ],
        "published": "2024-05-29T14:19:57Z"
    },
    {
        "title": "PathReasoner: Modeling Reasoning Path with Equivalent Extension for\n  Logical Question Answering",
        "link": "http://arxiv.org/abs/2405.19109v1",
        "abstract": "Logical reasoning task has attracted great interest since it was proposed.\nFaced with such a task, current competitive models, even large language models\n(e.g., ChatGPT and PaLM 2), still perform badly. Previous promising LMs\nstruggle in logical consistency modeling and logical structure perception. To\nthis end, we model the logical reasoning task by transforming each logical\nsample into reasoning paths and propose an architecture \\textbf{PathReasoner}.\nIt addresses the task from the views of both data and model. To expand the\ndiversity of the logical samples, we propose an atom extension strategy\nsupported by equivalent logical formulas, to form new reasoning paths. From the\nmodel perspective, we design a stack of transformer-style blocks. In\nparticular, we propose a path-attention module to joint model in-atom and\ncross-atom relations with the high-order diffusion strategy. Experiments show\nthat PathReasoner achieves competitive performances on two logical reasoning\nbenchmarks and great generalization abilities.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Fangzhi Xu",
            "Qika Lin",
            "Tianzhe Zhao",
            "Jiawei Han",
            "Jun Liu"
        ],
        "published": "2024-05-29T14:14:05Z"
    },
    {
        "title": "Offline Regularised Reinforcement Learning for Large Language Models\n  Alignment",
        "link": "http://arxiv.org/abs/2405.19107v1",
        "abstract": "The dominant framework for alignment of large language models (LLM), whether\nthrough reinforcement learning from human feedback or direct preference\noptimisation, is to learn from preference data. This involves building datasets\nwhere each element is a quadruplet composed of a prompt, two independent\nresponses (completions of the prompt) and a human preference between the two\nindependent responses, yielding a preferred and a dis-preferred response. Such\ndata is typically scarce and expensive to collect. On the other hand,\n\\emph{single-trajectory} datasets where each element is a triplet composed of a\nprompt, a response and a human feedback is naturally more abundant. The\ncanonical element of such datasets is for instance an LLM's response to a\nuser's prompt followed by a user's feedback such as a thumbs-up/down.\nConsequently, in this work, we propose DRO, or \\emph{Direct Reward\nOptimisation}, as a framework and associated algorithms that do not require\npairwise preferences. DRO uses a simple mean-squared objective that can be\nimplemented in various ways. We validate our findings empirically, using T5\nencoder-decoder language models, and show DRO's performance over selected\nbaselines such as Kahneman-Tversky Optimization (KTO). Thus, we confirm that\nDRO is a simple and empirically compelling method for single-trajectory policy\noptimisation.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Pierre Harvey Richemond",
            "Yunhao Tang",
            "Daniel Guo",
            "Daniele Calandriello",
            "Mohammad Gheshlaghi Azar",
            "Rafael Rafailov",
            "Bernardo Avila Pires",
            "Eugene Tarassov",
            "Lucas Spangher",
            "Will Ellsworth",
            "Aliaksei Severyn",
            "Jonathan Mallinson",
            "Lior Shani",
            "Gil Shamir",
            "Rishabh Joshi",
            "Tianqi Liu",
            "Remi Munos",
            "Bilal Piot"
        ],
        "published": "2024-05-29T14:11:29Z"
    },
    {
        "title": "Voice Jailbreak Attacks Against GPT-4o",
        "link": "http://arxiv.org/abs/2405.19103v1",
        "abstract": "Recently, the concept of artificial assistants has evolved from science\nfiction into real-world applications. GPT-4o, the newest multimodal large\nlanguage model (MLLM) across audio, vision, and text, has further blurred the\nline between fiction and reality by enabling more natural human-computer\ninteractions. However, the advent of GPT-4o's voice mode may also introduce a\nnew attack surface. In this paper, we present the first systematic measurement\nof jailbreak attacks against the voice mode of GPT-4o. We show that GPT-4o\ndemonstrates good resistance to forbidden questions and text jailbreak prompts\nwhen directly transferring them to voice mode. This resistance is primarily due\nto GPT-4o's internal safeguards and the difficulty of adapting text jailbreak\nprompts to voice mode. Inspired by GPT-4o's human-like behaviors, we propose\nVoiceJailbreak, a novel voice jailbreak attack that humanizes GPT-4o and\nattempts to persuade it through fictional storytelling (setting, character, and\nplot). VoiceJailbreak is capable of generating simple, audible, yet effective\njailbreak prompts, which significantly increases the average attack success\nrate (ASR) from 0.033 to 0.778 in six forbidden scenarios. We also conduct\nextensive experiments to explore the impacts of interaction steps, key elements\nof fictional writing, and different languages on VoiceJailbreak's effectiveness\nand further enhance the attack performance with advanced fictional writing\ntechniques. We hope our study can assist the research community in building\nmore secure and well-regulated MLLMs.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "authors": [
            "Xinyue Shen",
            "Yixin Wu",
            "Michael Backes",
            "Yang Zhang"
        ],
        "published": "2024-05-29T14:07:44Z"
    },
    {
        "title": "Poseidon: Efficient Foundation Models for PDEs",
        "link": "http://arxiv.org/abs/2405.19101v1",
        "abstract": "We introduce Poseidon, a foundation model for learning the solution operators\nof PDEs. It is based on a multiscale operator transformer, with\ntime-conditioned layer norms that enable continuous-in-time evaluations. A\nnovel training strategy leveraging the semi-group property of time-dependent\nPDEs to allow for significant scaling-up of the training data is also proposed.\nPoseidon is pretrained on a diverse, large scale dataset for the governing\nequations of fluid dynamics. It is then evaluated on a suite of 15 challenging\ndownstream tasks that include a wide variety of PDE types and operators. We\nshow that Poseidon exhibits excellent performance across the board by\noutperforming baselines significantly, both in terms of sample efficiency and\naccuracy. Poseidon also generalizes very well to new physics that is not seen\nduring pretraining. Moreover, Poseidon scales with respect to model and data\nsize, both for pretraining and for downstream tasks. Taken together, our\nresults showcase the surprising ability of Poseidon to learn effective\nrepresentations from a very small set of PDEs during pretraining in order to\ngeneralize well to unseen and unrelated PDEs downstream, demonstrating its\npotential as an effective, general purpose PDE foundation model. Finally, the\nPoseidon model as well as underlying pretraining and downstream datasets are\nopen sourced, with code being available at\nhttps://github.com/camlab-ethz/poseidon and pretrained models and datasets at\nhttps://huggingface.co/camlab-ethz.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Maximilian Herde",
            "Bogdan Raoni",
            "Tobias Rohner",
            "Roger Kppeli",
            "Roberto Molinaro",
            "Emmanuel de Bzenac",
            "Siddhartha Mishra"
        ],
        "published": "2024-05-29T14:06:51Z"
    },
    {
        "title": "Enhancing Zero-Shot Facial Expression Recognition by LLM Knowledge\n  Transfer",
        "link": "http://arxiv.org/abs/2405.19100v1",
        "abstract": "Current facial expression recognition (FER) models are often designed in a\nsupervised learning manner thus are constrained by the lack of large-scale\nfacial expression images with high-quality annotations. Consequently, these\nmodels often fail to generalize well, performing poorly on unseen images in\ntraining. Vision-language-based zero-shot models demonstrate a promising\npotential for addressing such challenges. However, these models lack\ntask-specific knowledge therefore are not optimized for the nuances of\nrecognizing facial expressions. To bridge this gap, this work proposes a novel\nmethod, Exp-CLIP, to enhance zero-shot FER by transferring the task knowledge\nfrom large language models (LLMs). Specifically, based on the pre-trained\nvision-language encoders, we incorporate a projection head designed to map the\ninitial joint vision-language space into a space that captures representations\nof facial actions. To train this projection head for subsequent zero-shot\npredictions, we propose to align the projected visual representations with\ntask-specific semantic meanings derived from the LLM encoder, and the text\ninstruction-based strategy is employed to customize the LLM knowledge. Given\nunlabelled facial data and efficient training of the projection head, Exp-CLIP\nachieves superior zero-shot results to the CLIP models and several other large\nvision-language models (LVLMs) on seven in-the-wild FER datasets. The code and\npre-trained models are available at\n\\url{https://github.com/zengqunzhao/Exp-CLIP}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zengqun Zhao",
            "Yu Cao",
            "Shaogang Gong",
            "Ioannis Patras"
        ],
        "published": "2024-05-29T14:06:09Z"
    },
    {
        "title": "DataSafe: Copyright Protection with PUF Watermarking and Blockchain\n  Tracking",
        "link": "http://arxiv.org/abs/2405.19099v1",
        "abstract": "Digital watermarking methods are commonly used to safeguard digital media\ncopyrights by confirming ownership and deterring unauthorized use. However,\nwithout reliable third-party oversight, these methods risk security\nvulnerabilities during watermark extraction. Furthermore, digital media lacks\ntangible ownership attributes, posing challenges for secure copyright transfer\nand tracing. This study introduces DataSafe, a copyright protection scheme that\ncombines physical unclonable functions (PUFs) and blockchain technology. PUF\ndevices use their unique fingerprints for blockchain registration.\nSubsequently, these devices incorporate invisible watermarking techniques to\nembed digital watermarks into media for copyright protection. The watermark\nverification process is confined within the devices, preserving confidentiality\nduring extraction, validating identities during copyright exchanges, and\nfacilitating blockchain-based traceability of copyright transfers. The\nimplementation of a prototype system on the LPC55S69-EVK development board is\ndetailed, illustrating the practicality and effectiveness of the proposed\nsolution.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Xiaolong Xue",
            "Guangyong Shang",
            "Zhen Ma",
            "Minghui Xu",
            "Hechuan Guo",
            "Kun Li",
            "Xiuzhen Cheng"
        ],
        "published": "2024-05-29T14:05:19Z"
    },
    {
        "title": "Efficient Black-box Adversarial Attacks via Bayesian Optimization Guided\n  by a Function Prior",
        "link": "http://arxiv.org/abs/2405.19098v1",
        "abstract": "This paper studies the challenging black-box adversarial attack that aims to\ngenerate adversarial examples against a black-box model by only using output\nfeedback of the model to input queries. Some previous methods improve the query\nefficiency by incorporating the gradient of a surrogate white-box model into\nquery-based attacks due to the adversarial transferability. However, the\nlocalized gradient is not informative enough, making these methods still\nquery-intensive. In this paper, we propose a Prior-guided Bayesian Optimization\n(P-BO) algorithm that leverages the surrogate model as a global function prior\nin black-box adversarial attacks. As the surrogate model contains rich prior\ninformation of the black-box one, P-BO models the attack objective with a\nGaussian process whose mean function is initialized as the surrogate model's\nloss. Our theoretical analysis on the regret bound indicates that the\nperformance of P-BO may be affected by a bad prior. Therefore, we further\npropose an adaptive integration strategy to automatically adjust a coefficient\non the function prior by minimizing the regret bound. Extensive experiments on\nimage classifiers and large vision-language models demonstrate the superiority\nof the proposed algorithm in reducing queries and improving attack success\nrates compared with the state-of-the-art black-box attacks. Code is available\nat https://github.com/yibo-miao/PBO-Attack.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR",
            "cs.CV",
            "stat.ML"
        ],
        "authors": [
            "Shuyu Cheng",
            "Yibo Miao",
            "Yinpeng Dong",
            "Xiao Yang",
            "Xiao-Shan Gao",
            "Jun Zhu"
        ],
        "published": "2024-05-29T14:05:16Z"
    },
    {
        "title": "A study of why we need to reassess full reference image quality\n  assessment with medical images",
        "link": "http://arxiv.org/abs/2405.19097v1",
        "abstract": "Image quality assessment (IQA) is not just indispensable in clinical practice\nto ensure high standards, but also in the development stage of novel algorithms\nthat operate on medical images with reference data. This paper provides a\nstructured and comprehensive collection of examples where the two most common\nfull reference (FR) image quality measures prove to be unsuitable for the\nassessment of novel algorithms using different kinds of medical images,\nincluding real-world MRI, CT, OCT, X-Ray, digital pathology and photoacoustic\nimaging data. In particular, the FR-IQA measures PSNR and SSIM are known and\ntested for working successfully in many natural imaging tasks, but\ndiscrepancies in medical scenarios have been noted in the literature.\nInconsistencies arising in medical images are not surprising, as they have very\ndifferent properties than natural images which have not been targeted nor\ntested in the development of the mentioned measures, and therefore might imply\nwrong judgement of novel methods for medical images. Therefore, improvement is\nurgently needed in particular in this era of AI to increase explainability,\nreproducibility and generalizability in machine learning for medical imaging\nand beyond. On top of the pitfalls we will provide ideas for future research as\nwell as suggesting guidelines for the usage of FR-IQA measures applied to\nmedical images.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Anna Breger",
            "Ander Biguri",
            "Malena Sabat Landman",
            "Ian Selby",
            "Nicole Amberg",
            "Elisabeth Brunner",
            "Janek Grhl",
            "Sepideh Hatamikia",
            "Clemens Karner",
            "Lipeng Ning",
            "Sren Dittmer",
            "Michael Roberts",
            "AIX-COVNET Collaboration",
            "Carola-Bibiane Schnlieb"
        ],
        "published": "2024-05-29T14:01:40Z"
    },
    {
        "title": "The Precise Complexity of Reasoning in $\\mathcal{ALC}$ with\n  $$-Admissible Concrete Domains (Extended Version)",
        "link": "http://arxiv.org/abs/2405.19096v1",
        "abstract": "Concrete domains have been introduced in the context of Description Logics to\nallow references to qualitative and quantitative values. In particular, the\nclass of $\\omega$-admissible concrete domains, which includes Allen's interval\nalgebra, the region connection calculus (RCC8), and the rational numbers with\nordering and equality, has been shown to yield extensions of $\\mathcal{ALC}$\nfor which concept satisfiability w.r.t. a general TBox is decidable. In this\npaper, we present an algorithm based on type elimination and use it to show\nthat deciding the consistency of an $\\mathcal{ALC}(\\mathfrak{D})$ ontology is\nExpTime-complete if the concrete domain $\\mathfrak{D}$ is $\\omega$-admissible\nand its constraint satisfaction problem is decidable in exponential time.\n  While this allows us to reason with concept and role assertions, we also\ninvestigate feature assertions $f(a,c)$ that can specify a constant $c$ as the\nvalue of a feature $f$ for an individual $a$. We show that, under conditions\nsatisfied by all known $\\omega$-admissible domains, we can add feature\nassertions without affecting the complexity.",
        "subjects": [
            "cs.LO"
        ],
        "authors": [
            "Stefan Borgwardt",
            "Filippo De Bortoli",
            "Patrick Koopmann"
        ],
        "published": "2024-05-29T13:57:16Z"
    },
    {
        "title": "Groupoidal Realizability for Intensional Type Theory",
        "link": "http://arxiv.org/abs/2405.19095v1",
        "abstract": "We develop realizability models of intensional type theory, based on\ngroupoids, wherein realizers themselves carry non-trivial (non-discrete)\nhomotopical structure. In the spirit of realizability, this is intended to\nformalize a homotopical BHK interpretation, whereby evidence for an\nidentification is a path. Specifically, we study partitioned groupoidal\nassemblies. Categories of such are parameterised by \"realizer categories\"\n(instead of the usual partial combinatory algebras) that come equipped with an\ninterval qua internal cogroupoid. The interval furnishes a notion of homotopy\nas well as a fundamental groupoid construction. Objects in a base groupoid are\nrealized by points in the fundamental groupoid of some object from the realizer\ncategory; isomorphisms in the base groupoid are realized by paths in said\nfundamental groupoid. The main result is that, under mild conditions on the\nrealizer category, the ensuing category of partitioned groupoidal assemblies\nmodels intensional (1-truncated) type theory without function extensionality.\nMoreover, when the underlying realizer category is \"untyped\", there exists an\nimpredicative universe of 1-types (the modest fibrations). This is a groupoidal\nanalogue of the traditional situation.",
        "subjects": [
            "cs.LO",
            "math.CT",
            "math.LO"
        ],
        "authors": [
            "Sam Speight"
        ],
        "published": "2024-05-29T13:56:43Z"
    },
    {
        "title": "Faithful Chart Summarization with ChaTS-Pi",
        "link": "http://arxiv.org/abs/2405.19094v1",
        "abstract": "Chart-to-summary generation can help explore data, communicate insights, and\nhelp the visually impaired people. Multi-modal generative models have been used\nto produce fluent summaries, but they can suffer from factual and perceptual\nerrors. In this work we present CHATS-CRITIC, a reference-free chart\nsummarization metric for scoring faithfulness. CHATS-CRITIC is composed of an\nimage-to-text model to recover the table from a chart, and a tabular entailment\nmodel applied to score the summary sentence by sentence. We find that\nCHATS-CRITIC evaluates the summary quality according to human ratings better\nthan reference-based metrics, either learned or n-gram based, and can be\nfurther used to fix candidate summaries by removing not supported sentences. We\nthen introduce CHATS-PI, a chart-to-summary pipeline that leverages\nCHATS-CRITIC during inference to fix and rank sampled candidates from any\nchart-summarization model. We evaluate CHATS-PI and CHATS-CRITIC using human\nraters, establishing state-of-the-art results on two popular chart-to-summary\ndatasets.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Syrine Krichene",
            "Francesco Piccinno",
            "Fangyu Liu",
            "Julian Martin Eisenschlos"
        ],
        "published": "2024-05-29T13:55:06Z"
    },
    {
        "title": "Multi-stage Retrieve and Re-rank Model for Automatic Medical Coding\n  Recommendation",
        "link": "http://arxiv.org/abs/2405.19093v1",
        "abstract": "The International Classification of Diseases (ICD) serves as a definitive\nmedical classification system encompassing a wide range of diseases and\nconditions. The primary objective of ICD indexing is to allocate a subset of\nICD codes to a medical record, which facilitates standardized documentation and\nmanagement of various health conditions. Most existing approaches have suffered\nfrom selecting the proper label subsets from an extremely large ICD collection\nwith a heavy long-tailed label distribution. In this paper, we leverage a\nmulti-stage ``retrieve and re-rank'' framework as a novel solution to ICD\nindexing, via a hybrid discrete retrieval method, and re-rank retrieved\ncandidates with contrastive learning that allows the model to make more\naccurate predictions from a simplified label space. The retrieval model is a\nhybrid of auxiliary knowledge of the electronic health records (EHR) and a\ndiscrete retrieval method (BM25), which efficiently collects high-quality\ncandidates. In the last stage, we propose a label co-occurrence guided\ncontrastive re-ranking model, which re-ranks the candidate labels by pulling\ntogether the clinical notes with positive ICD codes. Experimental results show\nthe proposed method achieves state-of-the-art performance on a number of\nmeasures on the MIMIC-III benchmark.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "authors": [
            "Xindi Wang",
            "Robert E. Mercer",
            "Frank Rudzicz"
        ],
        "published": "2024-05-29T13:54:30Z"
    },
    {
        "title": "Benchmarking and Improving Detail Image Caption",
        "link": "http://arxiv.org/abs/2405.19092v2",
        "abstract": "Image captioning has long been regarded as a fundamental task in visual\nunderstanding. Recently, however, few large vision-language model (LVLM)\nresearch discusses model's image captioning performance because of the outdated\nshort-caption benchmarks and unreliable evaluation metrics. In this work, we\npropose to benchmark detail image caption task by curating high-quality\nevaluation datasets annotated by human experts, GPT-4V and Gemini-1.5-Pro. We\nalso design a more reliable caption evaluation metric called CAPTURE (CAPtion\nevaluation by exTracting and coUpling coRE information). CAPTURE extracts\nvisual elements, e.g., objects, attributes and relations from captions, and\nthen matches these elements through three stages, achieving the highest\nconsistency with expert judgements over other rule-based or model-based caption\nmetrics. The proposed benchmark and metric provide reliable evaluation for\nLVLM's detailed image captioning ability. Guided by this evaluation, we further\nexplore to unleash LVLM's detail caption capabilities by synthesizing\nhigh-quality data through a five-stage data construction pipeline. Our pipeline\nonly uses a given LVLM itself and other open-source tools, without any human or\nGPT-4V annotation in the loop. Experiments show that the proposed data\nconstruction strategy significantly improves model-generated detail caption\ndata quality for LVLMs with leading performance, and the data quality can be\nfurther improved in a self-looping paradigm. All code and dataset will be\npublicly available at https://github.com/foundation-multimodal-models/CAPTURE.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hongyuan Dong",
            "Jiawen Li",
            "Bohong Wu",
            "Jiacong Wang",
            "Yuan Zhang",
            "Haoyuan Guo"
        ],
        "published": "2024-05-29T13:54:12Z"
    },
    {
        "title": "Cracking the Code of Juxtaposition: Can AI Models Understand the\n  Humorous Contradictions",
        "link": "http://arxiv.org/abs/2405.19088v1",
        "abstract": "Recent advancements in large multimodal language models have demonstrated\nremarkable proficiency across a wide range of tasks. Yet, these models still\nstruggle with understanding the nuances of human humor through juxtaposition,\nparticularly when it involves nonlinear narratives that underpin many jokes and\nhumor cues. This paper investigates this challenge by focusing on comics with\ncontradictory narratives, where each comic consists of two panels that create a\nhumorous contradiction. We introduce the YesBut benchmark, which comprises\ntasks of varying difficulty aimed at assessing AI's capabilities in recognizing\nand interpreting these comics, ranging from literal content comprehension to\ndeep narrative reasoning. Through extensive experimentation and analysis of\nrecent commercial or open-sourced large (vision) language models, we assess\ntheir capability to comprehend the complex interplay of the narrative humor\ninherent in these comics. Our results show that even state-of-the-art models\nstill lag behind human performance on this task. Our findings offer insights\ninto the current limitations and potential improvements for AI in understanding\nhuman creative expressions.",
        "subjects": [
            "cs.CL",
            "cs.CV"
        ],
        "authors": [
            "Zhe Hu",
            "Tuo Liang",
            "Jing Li",
            "Yiren Lu",
            "Yunlai Zhou",
            "Yiran Qiao",
            "Jing Ma",
            "Yu Yin"
        ],
        "published": "2024-05-29T13:51:43Z"
    },
    {
        "title": "MEMoE: Enhancing Model Editing with Mixture of Experts Adaptors",
        "link": "http://arxiv.org/abs/2405.19086v1",
        "abstract": "Model editing aims to efficiently alter the behavior of Large Language Models\n(LLMs) within a desired scope, while ensuring no adverse impact on other\ninputs. Recent years have witnessed various model editing methods been\nproposed. However, these methods either exhibit poor overall performance or\nstruggle to strike a balance between generalization and locality. We propose\nMOMoE, a model editing adapter utilizing a Mixture of Experts (MoE)\narchitecture with a knowledge anchor routing strategy. MOMoE updates knowledge\nusing a bypass MoE structure, keeping the original parameters unchanged to\npreserve the general ability of LLMs. And, the knowledge anchor routing ensures\nthat inputs requiring similar knowledge are routed to the same expert, thereby\nenhancing the generalization of the updated knowledge. Experimental results\nshow the superiority of our approach over both batch editing and sequential\nbatch editing tasks, exhibiting exceptional overall performance alongside\noutstanding balance between generalization and locality. Our code will be\navailable.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Renzhi Wang",
            "Piji Li"
        ],
        "published": "2024-05-29T13:49:44Z"
    },
    {
        "title": "Patch-enhanced Mask Encoder Prompt Image Generation",
        "link": "http://arxiv.org/abs/2405.19085v1",
        "abstract": "Artificial Intelligence Generated Content(AIGC), known for its superior\nvisual results, represents a promising mitigation method for high-cost\nadvertising applications. Numerous approaches have been developed to manipulate\ngenerated content under different conditions. However, a crucial limitation\nlies in the accurate description of products in advertising applications.\nApplying previous methods directly may lead to considerable distortion and\ndeformation of advertised products, primarily due to oversimplified content\ncontrol conditions. Hence, in this work, we propose a patch-enhanced mask\nencoder approach to ensure accurate product descriptions while preserving\ndiverse backgrounds. Our approach consists of three components Patch Flexible\nVisibility, Mask Encoder Prompt Adapter and an image Foundation Model. Patch\nFlexible Visibility is used for generating a more reasonable background image.\nMask Encoder Prompt Adapter enables region-controlled fusion. We also conduct\nan analysis of the structure and operational mechanisms of the Generation\nModule. Experimental results show our method can achieve the highest visual\nresults and FID scores compared with other methods.",
        "subjects": [
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Shusong Xu",
            "Peiye Liu"
        ],
        "published": "2024-05-29T13:47:32Z"
    },
    {
        "title": "Auxiliary Knowledge-Induced Learning for Automatic Multi-Label Medical\n  Document Classification",
        "link": "http://arxiv.org/abs/2405.19084v1",
        "abstract": "The International Classification of Diseases (ICD) is an authoritative\nmedical classification system of different diseases and conditions for clinical\nand management purposes. ICD indexing assigns a subset of ICD codes to a\nmedical record. Since human coding is labour-intensive and error-prone, many\nstudies employ machine learning to automate the coding process. ICD coding is a\nchallenging task, as it needs to assign multiple codes to each medical document\nfrom an extremely large hierarchically organized collection. In this paper, we\npropose a novel approach for ICD indexing that adopts three ideas: (1) we use a\nmulti-level deep dilated residual convolution encoder to aggregate the\ninformation from the clinical notes and learn document representations across\ndifferent lengths of the texts; (2) we formalize the task of ICD classification\nwith auxiliary knowledge of the medical records, which incorporates not only\nthe clinical texts but also different clinical code terminologies and drug\nprescriptions for better inferring the ICD codes; and (3) we introduce a graph\nconvolutional network to leverage the co-occurrence patterns among ICD codes,\naiming to enhance the quality of label representations. Experimental results\nshow the proposed method achieves state-of-the-art performance on a number of\nmeasures.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Xindi Wang",
            "Robert E. Mercer",
            "Frank Rudzicz"
        ],
        "published": "2024-05-29T13:44:07Z"
    },
    {
        "title": "Uniform vs. Lognormal Kinematics in Robots: Perceptual Preferences for\n  Robotic Movements",
        "link": "http://dx.doi.org/10.3390/app122312045",
        "abstract": "Collaborative robots or cobots interact with humans in a common work\nenvironment. In cobots, one under investigated but important issue is related\nto their movement and how it is perceived by humans. This paper tries to\nanalyze whether humans prefer a robot moving in a human or in a robotic\nfashion. To this end, the present work lays out what differentiates the\nmovement performed by an industrial robotic arm from that performed by a human\none. The main difference lies in the fact that the robotic movement has a\ntrapezoidal speed profile, while for the human arm, the speed profile is\nbell-shaped and during complex movements, it can be considered as a sum of\nsuperimposed bell-shaped movements. Based on the lognormality principle, a\nprocedure was developed for a robotic arm to perform human-like movements. Both\nspeed profiles were implemented in two industrial robots, namely, an ABB IRB\n120 and a Universal Robot UR3. Three tests were used to study the subjects'\npreference when seeing both movements and another analyzed the same when\ninteracting with the robot by touching its ends with their fingers.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "authors": [
            "Jose J. Quintana",
            "Miguel A. Ferrer",
            "Moises Diaz",
            "Jose J. Feo",
            "Adam Wolniakowski",
            "Konstantsin Miatliuk"
        ],
        "published": "2024-05-29T13:36:47Z"
    },
    {
        "title": "OMPO: A Unified Framework for RL under Policy and Dynamics Shifts",
        "link": "http://arxiv.org/abs/2405.19080v1",
        "abstract": "Training reinforcement learning policies using environment interaction data\ncollected from varying policies or dynamics presents a fundamental challenge.\nExisting works often overlook the distribution discrepancies induced by policy\nor dynamics shifts, or rely on specialized algorithms with task priors, thus\noften resulting in suboptimal policy performances and high learning variances.\nIn this paper, we identify a unified strategy for online RL policy learning\nunder diverse settings of policy and dynamics shifts: transition occupancy\nmatching. In light of this, we introduce a surrogate policy learning objective\nby considering the transition occupancy discrepancies and then cast it into a\ntractable min-max optimization problem through dual reformulation. Our method,\ndubbed Occupancy-Matching Policy Optimization (OMPO), features a specialized\nactor-critic structure equipped with a distribution discriminator and a\nsmall-size local buffer. We conduct extensive experiments based on the OpenAI\nGym, Meta-World, and Panda Robots environments, encompassing policy shifts\nunder stationary and nonstationary dynamics, as well as domain adaption. The\nresults demonstrate that OMPO outperforms the specialized baselines from\ndifferent categories in all settings. We also find that OMPO exhibits\nparticularly strong performance when combined with domain randomization,\nhighlighting its potential in RL-based robotics applications",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Yu Luo",
            "Tianying Ji",
            "Fuchun Sun",
            "Jianwei Zhang",
            "Huazhe Xu",
            "Xianyuan Zhan"
        ],
        "published": "2024-05-29T13:36:36Z"
    },
    {
        "title": "On the Influence of Smoothness Constraints in Computed Tomography Motion\n  Compensation",
        "link": "http://arxiv.org/abs/2405.19079v1",
        "abstract": "Computed tomography (CT) relies on precise patient immobilization during\nimage acquisition. Nevertheless, motion artifacts in the reconstructed images\ncan persist. Motion compensation methods aim to correct such artifacts\npost-acquisition, often incorporating temporal smoothness constraints on the\nestimated motion patterns. This study analyzes the influence of a spline-based\nmotion model within an existing rigid motion compensation algorithm for\ncone-beam CT on the recoverable motion frequencies. Results demonstrate that\nthe choice of motion model crucially influences recoverable frequencies. The\noptimization-based motion compensation algorithm is able to accurately fit the\nspline nodes for frequencies almost up to the node-dependent theoretical limit\naccording to the Nyquist-Shannon theorem. Notably, a higher node count does not\ncompromise reconstruction performance for slow motion patterns, but can extend\nthe range of recoverable high frequencies for the investigated algorithm.\nEventually, the optimal motion model is dependent on the imaged anatomy,\nclinical use case, and scanning protocol and should be tailored carefully to\nthe expected motion frequency spectrum to ensure accurate motion compensation.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Mareike Thies",
            "Fabian Wagner",
            "Noah Maul",
            "Siyuan Mei",
            "Mingxuan Gu",
            "Laura Pfaff",
            "Nastassia Vysotskaya",
            "Haijun Yu",
            "Andreas Maier"
        ],
        "published": "2024-05-29T13:36:16Z"
    },
    {
        "title": "Cephalo: Multi-Modal Vision-Language Models for Bio-Inspired Materials\n  Analysis and Design",
        "link": "http://arxiv.org/abs/2405.19076v1",
        "abstract": "We present Cephalo, a series of multimodal vision large language models\n(V-LLMs) designed for materials science applications, integrating visual and\nlinguistic data for enhanced understanding and interaction within human-AI and\nmulti-agent AI frameworks. A key innovation of Cephalo is its advanced dataset\ngeneration method, which employs a sophisticated algorithm to accurately detect\nand separate images and their corresponding textual descriptions from PDF\ndocuments, such as scientific papers. The method includes a careful refinement\nof image-text pairs through integrated vision and language processing, ensuring\nhigh-quality, contextually relevant, and well reasoned training data. Cephalo\nis trained on integrated image and text data extracted from thousands of\nscientific papers and science-focused Wikipedia pages demonstrates can\ninterpret complex visual scenes, generate precise language descriptions, and\nanswer queries about images effectively. The combination of a vision encoder\nwith an autoregressive transformer supports complex natural language\nunderstanding in an integrated model, which can be coupled with other\ngenerative methods to create an image-to-text-to-image or image-to-text-to-3D\npipeline. To explore the development of larger models from smaller ones, we\nmerge sets of layers that originate from different pre-trained source models.\nThis hybrid approach allows us to leverage the domain-specific expertise and\ngeneral conversational capabilities to harness the strengths of multiple\nmodels. We examine the models in diverse use cases that incorporate biological\nmaterials, fracture and engineering analysis, protein biophysics, and\nbio-inspired design based on insect behavior. Generative applications include\nbio-inspired designs, including pollen-inspired architected materials, as well\nas the synthesis of bio-inspired material microstructures from a photograph of\na solar eclipse.",
        "subjects": [
            "cs.CV",
            "cond-mat.mes-hall",
            "cond-mat.mtrl-sci",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Markus J. Buehler"
        ],
        "published": "2024-05-29T13:34:32Z"
    },
    {
        "title": "Resurrecting Old Classes with New Data for Exemplar-Free Continual\n  Learning",
        "link": "http://arxiv.org/abs/2405.19074v1",
        "abstract": "Continual learning methods are known to suffer from catastrophic forgetting,\na phenomenon that is particularly hard to counter for methods that do not store\nexemplars of previous tasks. Therefore, to reduce potential drift in the\nfeature extractor, existing exemplar-free methods are typically evaluated in\nsettings where the first task is significantly larger than subsequent tasks.\nTheir performance drops drastically in more challenging settings starting with\na smaller first task. To address this problem of feature drift estimation for\nexemplar-free methods, we propose to adversarially perturb the current samples\nsuch that their embeddings are close to the old class prototypes in the old\nmodel embedding space. We then estimate the drift in the embedding space from\nthe old to the new model using the perturbed images and compensate the\nprototypes accordingly. We exploit the fact that adversarial samples are\ntransferable from the old to the new feature space in a continual learning\nsetting. The generation of these images is simple and computationally cheap. We\ndemonstrate in our experiments that the proposed approach better tracks the\nmovement of prototypes in embedding space and outperforms existing methods on\nseveral standard continual learning benchmarks as well as on fine-grained\ndatasets. Code is available at https://github.com/dipamgoswami/ADC.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Dipam Goswami",
            "Albin Soutif--Cormerais",
            "Yuyang Liu",
            "Sandesh Kamath",
            "Bartomiej Twardowski",
            "Joost van de Weijer"
        ],
        "published": "2024-05-29T13:31:42Z"
    },
    {
        "title": "An engine not a camera: Measuring performative power of online search",
        "link": "http://arxiv.org/abs/2405.19073v1",
        "abstract": "The power of digital platforms is at the center of major ongoing policy and\nregulatory efforts. To advance existing debates, we designed and executed an\nexperiment to measure the power of online search providers, building on the\nrecent definition of performative power. Instantiated in our setting,\nperformative power quantifies the ability of a search engine to steer web\ntraffic by rearranging results. To operationalize this definition we developed\na browser extension that performs unassuming randomized experiments in the\nbackground. These randomized experiments emulate updates to the search\nalgorithm and identify the causal effect of different content arrangements on\nclicks. We formally relate these causal effects to performative power.\nAnalyzing tens of thousands of clicks, we discuss what our robust quantitative\nfindings say about the power of online search engines. More broadly, we\nenvision our work to serve as a blueprint for how performative power and online\nexperiments can be integrated with future investigations into the economic\npower of digital platforms.",
        "subjects": [
            "cs.CY",
            "cs.IR"
        ],
        "authors": [
            "Celestine Mendler-Dnner",
            "Gabriele Carovano",
            "Moritz Hardt"
        ],
        "published": "2024-05-29T13:31:12Z"
    },
    {
        "title": "Relevance-aware Algorithmic Recourse",
        "link": "http://arxiv.org/abs/2405.19072v1",
        "abstract": "As machine learning continues to gain prominence, transparency and\nexplainability are increasingly critical. Without an understanding of these\nmodels, they can replicate and worsen human bias, adversely affecting\nmarginalized communities. Algorithmic recourse emerges as a tool for clarifying\ndecisions made by predictive models, providing actionable insights to alter\noutcomes. They answer, 'What do I have to change?' to achieve the desired\nresult. Despite their importance, current algorithmic recourse methods treat\nall domain values equally, which is unrealistic in real-world settings. In this\npaper, we propose a novel framework, Relevance-Aware Algorithmic Recourse\n(RAAR), that leverages the concept of relevance in applying algorithmic\nrecourse to regression tasks. We conducted multiple experiments on 15 datasets\nto outline how relevance influences recourses. Results show that relevance\ncontributes algorithmic recourses comparable to well-known baselines, with\ngreater efficiency and lower relative costs.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Dongwhi Kim",
            "Nuno Moniz"
        ],
        "published": "2024-05-29T13:25:49Z"
    },
    {
        "title": "Computational bounds on randomized algorithms for online bin stretching",
        "link": "http://arxiv.org/abs/2405.19071v1",
        "abstract": "A frequently studied performance measure in online optimization is\ncompetitive analysis. It corresponds to the worst-case ratio, over all possible\ninputs of an algorithm, between the performance of the algorithm and the\noptimal offline performance. However, this analysis may be too pessimistic to\ngive valuable insight on a problem. Several workarounds exist, such as\nrandomized algorithms. This paper aims to propose computational methods to\nconstruct randomized algorithms and to bound their performance on the classical\nonline bin stretching problem. A game theory method is adapted to construct\nlower bounds on the performance of randomized online algorithms via linear\nprogramming. Another computational method is then proposed to construct\nrandomized algorithms which perform better than the best deterministic\nalgorithms known. Finally, another lower bound method for a restricted class of\nrandomized algorithm for this problem is proposed.",
        "subjects": [
            "math.OC",
            "cs.GT"
        ],
        "authors": [
            "Antoine Lhomme",
            "Nicolas Catusse",
            "Nadia Brauner"
        ],
        "published": "2024-05-29T13:25:30Z"
    },
    {
        "title": "xTern: Energy-Efficient Ternary Neural Network Inference on RISC-V-Based\n  Edge Systems",
        "link": "http://arxiv.org/abs/2405.19065v1",
        "abstract": "Ternary neural networks (TNNs) offer a superior accuracy-energy trade-off\ncompared to binary neural networks. However, until now, they have required\nspecialized accelerators to realize their efficiency potential, which has\nhindered widespread adoption. To address this, we present xTern, a lightweight\nextension of the RISC-V instruction set architecture (ISA) targeted at\naccelerating TNN inference on general-purpose cores. To complement the ISA\nextension, we developed a set of optimized kernels leveraging xTern, achieving\n67% higher throughput than their 2-bit equivalents. Power consumption is only\nmarginally increased by 5.2%, resulting in an energy efficiency improvement by\n57.1%. We demonstrate that the proposed xTern extension, integrated into an\nocta-core compute cluster, incurs a minimal silicon area overhead of 0.9% with\nno impact on timing. In end-to-end benchmarks, we demonstrate that xTern\nenables the deployment of TNNs achieving up to 1.6 percentage points higher\nCIFAR-10 classification accuracy than 2-bit networks at equal inference\nlatency. Our results show that xTern enables RISC-V-based ultra-low-power edge\nAI platforms to benefit from the efficiency potential of TNNs.",
        "subjects": [
            "cs.AR",
            "cs.LG"
        ],
        "authors": [
            "Georg Rutishauser",
            "Joan Mihali",
            "Moritz Scherer",
            "Luca Benini"
        ],
        "published": "2024-05-29T13:16:46Z"
    },
    {
        "title": "SIG: Efficient Self-Interpretable Graph Neural Network for\n  Continuous-time Dynamic Graphs",
        "link": "http://arxiv.org/abs/2405.19062v1",
        "abstract": "While dynamic graph neural networks have shown promise in various\napplications, explaining their predictions on continuous-time dynamic graphs\n(CTDGs) is difficult. This paper investigates a new research task:\nself-interpretable GNNs for CTDGs. We aim to predict future links within the\ndynamic graph while simultaneously providing causal explanations for these\npredictions. There are two key challenges: (1) capturing the underlying\nstructural and temporal information that remains consistent across both\nindependent and identically distributed (IID) and out-of-distribution (OOD)\ndata, and (2) efficiently generating high-quality link prediction results and\nexplanations. To tackle these challenges, we propose a novel causal inference\nmodel, namely the Independent and Confounded Causal Model (ICCM). ICCM is then\nintegrated into a deep learning architecture that considers both effectiveness\nand efficiency. Extensive experiments demonstrate that our proposed model\nsignificantly outperforms existing methods across link prediction accuracy,\nexplanation quality, and robustness to shortcut features. Our code and datasets\nare anonymously released at https://github.com/2024SIG/SIG.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Lanting Fang",
            "Yulian Yang",
            "Kai Wang",
            "Shanshan Feng",
            "Kaiyu Feng",
            "Jie Gui",
            "Shuliang Wang",
            "Yew-Soon Ong"
        ],
        "published": "2024-05-29T13:09:33Z"
    },
    {
        "title": "New perspectives on the optimal placement of detectors for suicide\n  bombers using metaheuristics",
        "link": "http://dx.doi.org/10.1007/s11047-018-9710-1",
        "abstract": "We consider an operational model of suicide bombing attacks -- an\nincreasingly prevalent form of terrorism -- against specific targets, and the\nuse of protective countermeasures based on the deployment of detectors over the\narea under threat. These detectors have to be carefully located in order to\nminimize the expected number of casualties or the economic damage suffered,\nresulting in a hard optimization problem for which different metaheuristics\nhave been proposed. Rather than assuming random decisions by the attacker, the\nproblem is approached by considering different models of the latter, whereby he\ntakes informed decisions on which objective must be targeted and through which\npath it has to be reached based on knowledge on the importance or value of the\nobjectives or on the defensive strategy of the defender (a scenario that can be\nregarded as an adversarial game). We consider four different algorithms, namely\na greedy heuristic, a hill climber, tabu search and an evolutionary algorithm,\nand study their performance on a broad collection of problem instances trying\nto resemble different realistic settings such as a coastal area, a modern urban\narea, and the historic core of an old town. It is shown that the adversarial\nscenario is harder for all techniques, and that the evolutionary algorithm\nseems to adapt better to the complexity of the resulting search landscape.",
        "subjects": [
            "cs.NE"
        ],
        "authors": [
            "Carlos Cotta",
            "Jos E. Gallardo"
        ],
        "published": "2024-05-29T13:06:10Z"
    },
    {
        "title": "Robust Entropy Search for Safe Efficient Bayesian Optimization",
        "link": "http://arxiv.org/abs/2405.19059v1",
        "abstract": "The practical use of Bayesian Optimization (BO) in engineering applications\nimposes special requirements: high sampling efficiency on the one hand and\nfinding a robust solution on the other hand. We address the case of adversarial\nrobustness, where all parameters are controllable during the optimization\nprocess, but a subset of them is uncontrollable or even adversely perturbed at\nthe time of application. To this end, we develop an efficient information-based\nacquisition function that we call Robust Entropy Search (RES). We empirically\ndemonstrate its benefits in experiments on synthetic and real-life data. The\nresults showthat RES reliably finds robust optima, outperforming\nstate-of-the-art algorithms.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Dorina Weichert",
            "Alexander Kister",
            "Patrick Link",
            "Sebastian Houben",
            "Gunar Ernis"
        ],
        "published": "2024-05-29T13:00:10Z"
    },
    {
        "title": "Neural Scene Baking for Permutation Invariant Transparency Rendering\n  with Real-time Global Illumination",
        "link": "http://arxiv.org/abs/2405.19056v1",
        "abstract": "Neural rendering provides a fundamentally new way to render photorealistic\nimages. Similar to traditional light-baking methods, neural rendering utilizes\nneural networks to bake representations of scenes, materials, and lights into\nlatent vectors learned from path-tracing ground truths. However, existing\nneural rendering algorithms typically use G-buffers to provide position,\nnormal, and texture information of scenes, which are prone to occlusion by\ntransparent surfaces, leading to distortions and loss of detail in the rendered\nimages. To address this limitation, we propose a novel neural rendering\npipeline that accurately renders the scene behind transparent surfaces with\nglobal illumination and variable scenes. Our method separates the G-buffers of\nopaque and transparent objects, retaining G-buffer information behind\ntransparent objects. Additionally, to render the transparent objects with\npermutation invariance, we designed a new permutation-invariant neural blending\nfunction. We integrate our algorithm into an efficient custom renderer to\nachieve real-time performance. Our results show that our method is capable of\nrendering photorealistic images with variable scenes and viewpoints, accurately\ncapturing complex transparent structures along with global illumination. Our\nrenderer can achieve real-time performance ($256\\times 256$ at 63 FPS and\n$512\\times 512$ at 32 FPS) on scenes with multiple variable transparent\nobjects.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Ziyang Zhang",
            "Edgar Simo-Serra"
        ],
        "published": "2024-05-29T12:56:18Z"
    },
    {
        "title": "FUSU: A Multi-temporal-source Land Use Change Segmentation Dataset for\n  Fine-grained Urban Semantic Understanding",
        "link": "http://arxiv.org/abs/2405.19055v1",
        "abstract": "Fine urban change segmentation using multi-temporal remote sensing images is\nessential for understanding human-environment interactions. Despite advances in\nremote sensing data for urban monitoring, coarse-grained classification systems\nand the lack of continuous temporal observations hinder the application of deep\nlearning to urban change analysis. To address this, we introduce FUSU, a\nmulti-source, multi-temporal change segmentation dataset for fine-grained urban\nsemantic understanding. FUSU features the most detailed land use classification\nsystem to date, with 17 classes and 30 billion pixels of annotations. It\nincludes bi-temporal high-resolution satellite images with 20-50 cm ground\nsample distance and monthly optical and radar satellite time series, covering\n847 km2 across five urban areas in China. The fine-grained pixel-wise\nannotations and high spatial-temporal resolution data provide a robust\nfoundation for deep learning models to understand urbanization and land use\nchanges. To fully leverage FUSU, we propose a unified time-series architecture\nfor both change detection and segmentation and benchmark FUSU on various\nmethods for several tasks. Dataset and code will be available at:\nhttps://github.com/yuanshuai0914/FUSU.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Shuai Yuan",
            "Guancong Lin",
            "Lixian Zhang",
            "Runmin Dong",
            "Jinxiao Zhang",
            "Shuang Chen",
            "Juepeng Zheng",
            "Jie Wang",
            "Haohuan Fu"
        ],
        "published": "2024-05-29T12:56:11Z"
    },
    {
        "title": "Dependency equilibria: Boundary cases and their real algebraic geometry",
        "link": "http://arxiv.org/abs/2405.19054v1",
        "abstract": "This paper is a significant step forward in understanding dependency\nequilibria within the framework of real algebraic geometry encompassing both\npure and mixed equilibria. We start by breaking down the concept for a general\naudience, using concrete examples to illustrate the main results. In alignment\nwith Spohn's original definition of dependency equilibria, we propose three\nalternative definitions, allowing for an algebro-geometric comprehensive study\nof all dependency equilibria. We give a sufficient condition for the existence\nof a pure dependency equilibrium and show that every Nash equilibrium lies on\nthe Spohn variety, the algebraic model for dependency equilibria. For generic\ngames, the set of real points of the Spohn variety is Zariski dense.\nFurthermore, every Nash equilibrium in this case is a dependency equilibrium.\nFinally, we present a detailed analysis of the geometric structure of\ndependency equilibria for $(2\\times2)$-games.",
        "subjects": [
            "math.AG",
            "cs.GT",
            "91A35, 91B52, 91A05, 91A06, 14P05, 14P10"
        ],
        "authors": [
            "Irem Portakal",
            "Daniel Windisch"
        ],
        "published": "2024-05-29T12:56:07Z"
    },
    {
        "title": "Multiscale Spatio-Temporal Enhanced Short-term Load Forecasting of\n  Electric Vehicle Charging Stations",
        "link": "http://arxiv.org/abs/2405.19053v1",
        "abstract": "The rapid expansion of electric vehicles (EVs) has rendered the load\nforecasting of electric vehicle charging stations (EVCS) increasingly critical.\nThe primary challenge in achieving precise load forecasting for EVCS lies in\naccounting for the nonlinear of charging behaviors, the spatial interactions\namong different stations, and the intricate temporal variations in usage\npatterns. To address these challenges, we propose a Multiscale Spatio-Temporal\nEnhanced Model (MSTEM) for effective load forecasting at EVCS. MSTEM\nincorporates a multiscale graph neural network to discern hierarchical\nnonlinear temporal dependencies across various time scales. Besides, it also\nintegrates a recurrent learning component and a residual fusion mechanism,\nenhancing its capability to accurately capture spatial and temporal variations\nin charging patterns. The effectiveness of the proposed MSTEM has been\nvalidated through comparative analysis with six baseline models using three\nevaluation metrics. The case studies utilize real-world datasets for both fast\nand slow charging loads at EVCS in Perth, UK. The experimental results\ndemonstrate the superiority of MSTEM in short-term continuous load forecasting\nfor EVCS.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.LG",
            "cs.SY"
        ],
        "authors": [
            "Zongbao Zhang",
            "Jiao Hao",
            "Wenmeng Zhao",
            "Yan Liu",
            "Yaohui Huang",
            "Xinhang Luo"
        ],
        "published": "2024-05-29T12:54:22Z"
    },
    {
        "title": "Quantum Circuit Switching with One-Way Repeaters in Star Networks",
        "link": "http://arxiv.org/abs/2405.19049v1",
        "abstract": "Distributing quantum states reliably among distant locations is a key\nchallenge in the field of quantum networks. One-way quantum networks address\nthis by using one-way communication and quantum error correction. Here, we\nanalyze quantum circuit switching as a protocol to distribute quantum states in\none-way quantum networks. In quantum circuit switching, pairs of users can\nrequest the delivery of multiple quantum states from one user to the other.\nAfter waiting for approval from the network, the states can be distributed\neither sequentially, forwarding one at a time along a path of quantum\nrepeaters, or in parallel, sending batches of quantum states from repeater to\nrepeater. Since repeaters can only forward a finite number of quantum states at\na time, a pivotal question arises: is it advantageous to send them sequentially\n(allowing for multiple requests simultaneously) or in parallel (reducing\nprocessing time but handling only one request at a time)? We compare both\napproaches in a quantum network with a star topology. Using tools from queuing\ntheory, we show that requests are met at a higher rate when packets are\ndistributed in parallel, although sequential distribution can generally provide\nservice to a larger number of users simultaneously. We also show that using a\nlarge number of quantum repeaters to combat channel losses limits the maximum\ndistance between users, as each repeater introduces additional processing\ndelays. These findings provide insight into the design of protocols for\ndistributing quantum states in one-way quantum networks.",
        "subjects": [
            "quant-ph",
            "cs.NI"
        ],
        "authors": [
            "lvaro G. Iesta",
            "Hyeongrak Choi",
            "Dirk Englund",
            "Stephanie Wehner"
        ],
        "published": "2024-05-29T12:46:57Z"
    },
    {
        "title": "Periodic Adjoint Sensitivity Analysis",
        "link": "http://arxiv.org/abs/2405.19048v1",
        "abstract": "This paper proposes the utilization of a periodic Parareal with a periodic\ncoarse problem to efficiently perform adjoint sensitivity analysis for the\nsteady state of time-periodic nonlinear circuits. In order to implement this\nmethod, a modified formulation for adjoint sensitivity analysis based on the\ntransient approach is derived.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Julian Sarpe",
            "Andreas Klaedtke",
            "Herbert De Gersem"
        ],
        "published": "2024-05-29T12:45:01Z"
    },
    {
        "title": "Statistical Context Detection for Deep Lifelong Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.19047v1",
        "abstract": "Context detection involves labeling segments of an online stream of data as\nbelonging to different tasks. Task labels are used in lifelong learning\nalgorithms to perform consolidation or other procedures that prevent\ncatastrophic forgetting. Inferring task labels from online experiences remains\na challenging problem. Most approaches assume finite and low-dimension\nobservation spaces or a preliminary training phase during which task labels are\nlearned. Moreover, changes in the transition or reward functions can be\ndetected only in combination with a policy, and therefore are more difficult to\ndetect than changes in the input distribution. This paper presents an approach\nto learning both policies and labels in an online deep reinforcement learning\nsetting. The key idea is to use distance metrics, obtained via optimal\ntransport methods, i.e., Wasserstein distance, on suitable latent action-reward\nspaces to measure distances between sets of data points from past and current\nstreams. Such distances can then be used for statistical tests based on an\nadapted Kolmogorov-Smirnov calculation to assign labels to sequences of\nexperiences. A rollback procedure is introduced to learn multiple policies by\nensuring that only the appropriate data is used to train the corresponding\npolicy. The combination of task detection and policy deployment allows for the\noptimization of lifelong reinforcement learning agents without an oracle that\nprovides task labels. The approach is tested using two benchmarks and the\nresults show promising performance when compared with related context detection\nalgorithms. The results suggest that optimal transport statistical methods\nprovide an explainable and justifiable procedure for online context detection\nand reward optimization in lifelong reinforcement learning.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Jeffery Dick",
            "Saptarshi Nath",
            "Christos Peridis",
            "Eseoghene Benjamin",
            "Soheil Kolouri",
            "Andrea Soltoggio"
        ],
        "published": "2024-05-29T12:44:41Z"
    },
    {
        "title": "Continual Collaborative Distillation for Recommender System",
        "link": "http://arxiv.org/abs/2405.19046v1",
        "abstract": "Knowledge distillation (KD) has emerged as a promising technique for\naddressing the computational challenges associated with deploying large-scale\nrecommender systems. KD transfers the knowledge of a massive teacher system to\na compact student model, to reduce the huge computational burdens for inference\nwhile retaining high accuracy. The existing KD studies primarily focus on\none-time distillation in static environments, leaving a substantial gap in\ntheir applicability to real-world scenarios dealing with continuously incoming\nusers, items, and their interactions. In this work, we delve into a systematic\napproach to operating the teacher-student KD in a non-stationary data stream.\nOur goal is to enable efficient deployment through a compact student, which\npreserves the high performance of the massive teacher, while effectively\nadapting to continuously incoming data. We propose Continual Collaborative\nDistillation (CCD) framework, where both the teacher and the student\ncontinually and collaboratively evolve along the data stream. CCD facilitates\nthe student in effectively adapting to new data, while also enabling the\nteacher to fully leverage accumulated knowledge. We validate the effectiveness\nof CCD through extensive quantitative, ablative, and exploratory experiments on\ntwo real-world datasets. We expect this research direction to contribute to\nnarrowing the gap between existing KD studies and practical applications,\nthereby enhancing the applicability of KD in real-world systems.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Gyuseok Lee",
            "SeongKu Kang",
            "Wonbin Kweon",
            "Hwanjo Yu"
        ],
        "published": "2024-05-29T12:43:39Z"
    },
    {
        "title": "To RL or not to RL? An Algorithmic Cheat-Sheet for AI-Based Radio\n  Resource Management",
        "link": "http://arxiv.org/abs/2405.19045v2",
        "abstract": "Several Radio Resource Management (RRM) use cases can be framed as sequential\ndecision planning problems, where an agent (the base station, typically) makes\ndecisions that influence the network utility and state. While Reinforcement\nLearning (RL) in its general form can address this scenario, it is known to be\nsample inefficient. Following the principle of Occam's razor, we argue that the\nchoice of the solution technique for RRM should be guided by questions such as,\n\"Is it a short or long-term planning problem?\", \"Is the underlying model known\nor does it need to be learned?\", \"Can we solve the problem analytically?\" or\n\"Is an expert-designed policy available?\". A wide range of techniques exists to\naddress these questions, including static and stochastic optimization, bandits,\nmodel predictive control (MPC) and, indeed, RL. We review some of these\ntechniques that have already been successfully applied to RRM, and we believe\nthat others, such as MPC, may present exciting research opportunities for the\nfuture.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Lorenzo Maggi",
            "Matthew Andrews",
            "Ryo Koblitz"
        ],
        "published": "2024-05-29T12:41:43Z"
    },
    {
        "title": "On adaptive stochastic extended iterative methods for solving least\n  squares",
        "link": "http://arxiv.org/abs/2405.19044v1",
        "abstract": "In this paper, we propose a novel adaptive stochastic extended iterative\nmethod, which can be viewed as an improved extension of the randomized extended\nKaczmarz (REK) method, for finding the unique minimum Euclidean norm\nleast-squares solution of a given linear system. In particular, we introduce\nthree equivalent stochastic reformulations of the linear least-squares problem:\nstochastic unconstrained and constrained optimization problems, and the\nstochastic multiobjective optimization problem. We then alternately employ the\nadaptive variants of the stochastic heavy ball momentum (SHBM) method, which\nutilize iterative information to update the parameters, to solve the stochastic\nreformulations. We prove that our method converges linearly in expectation,\naddressing an open problem in the literature related to designing theoretically\nsupported adaptive SHBM methods. Numerical experiments show that our adaptive\nstochastic extended iterative method has strong advantages over the\nnon-adaptive one.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Yun Zeng",
            "Deren Han",
            "Yansheng Su",
            "Jiaxin Xie"
        ],
        "published": "2024-05-29T12:38:01Z"
    },
    {
        "title": "BLSP-KD: Bootstrapping Language-Speech Pre-training via Knowledge\n  Distillation",
        "link": "http://arxiv.org/abs/2405.19041v1",
        "abstract": "Recent end-to-end approaches have shown promise in extending large language\nmodels (LLMs) to speech inputs, but face limitations in directly assessing and\noptimizing alignment quality and fail to achieve fine-grained alignment due to\nspeech-text length mismatch. We introduce BLSP-KD, a novel approach for\nBootstrapping Language-Speech Pretraining via Knowledge Distillation, which\naddresses these limitations through two key techniques. First, it optimizes\nspeech-text alignment by minimizing the divergence between the LLM's next-token\nprediction distributions for speech and text inputs using knowledge\ndistillation. Second, it employs a continuous-integrate-andfire strategy to\nsegment speech into tokens that correspond one-to-one with text tokens,\nenabling fine-grained alignment. We also introduce Partial LoRA (PLoRA), a new\nadaptation method supporting LLM finetuning for speech inputs under knowledge\ndistillation. Quantitative evaluation shows that BLSP-KD outperforms previous\nend-to-end baselines and cascaded systems with comparable scale of parameters,\nfacilitating general instruction-following capabilities for LLMs with speech\ninputs. This approach provides new possibilities for extending LLMs to spoken\nlanguage interactions.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Chen Wang",
            "Minpeng Liao",
            "Zhongqiang Huang",
            "Jiajun Zhang"
        ],
        "published": "2024-05-29T12:32:08Z"
    },
    {
        "title": "Finite-Choice Logic Programming",
        "link": "http://arxiv.org/abs/2405.19040v1",
        "abstract": "Logic programming, as exemplified by datalog, defines the meaning of a\nprogram as the canonical smallest model derived from deductive closure over its\ninference rules. However, many problems call for an enumeration of models that\nvary along some set of choices while maintaining structural and logical\nconstraints -- there is no single canonical model. The notion of stable models\nhas successfully captured programmer intuition about the set of valid solutions\nfor such problems, giving rise to a family of programming languages and\nassociated solvers collectively known as answer set programming. Unfortunately,\nthe definition of a stable model is frustratingly indirect, especially in the\npresence of rules containing free variables.\n  We propose a new formalism, called finite-choice logic programing, for which\nthe set of stable models can be characterized as the least fixed point of an\nimmediate consequence operator. Our formalism allows straightforward expression\nof common idioms in both datalog and answer set programming, gives meaning to a\nnew and useful class of programs, enjoys a constructive and direct operational\nsemantics, and admits a predictive cost semantics, which we demonstrate through\nour implementation.",
        "subjects": [
            "cs.PL",
            "cs.LO"
        ],
        "authors": [
            "Robert J. Simmons",
            "Michael Arntzenius",
            "Chris Martens"
        ],
        "published": "2024-05-29T12:27:19Z"
    },
    {
        "title": "PointNetPGAP-SLC: A 3D LiDAR-based Place Recognition Approach with\n  Segment-level Consistency Training for Mobile Robots in Horticulture",
        "link": "http://arxiv.org/abs/2405.19038v1",
        "abstract": "This paper addresses robotic place recognition in horticultural environments\nusing 3D-LiDAR technology and deep learning. Three main contributions are\nproposed: (i) a novel model called PointNetPGAP, which combines a global\naverage pooling aggregator and a pairwise feature interaction aggregator; (ii)\na Segment-Level Consistency (SLC) model, used only during training, with the\ngoal of augmenting the contrastive loss with a context-specific training signal\nto enhance descriptors; and (iii) a novel dataset named HORTO-3DLM featuring\nsequences from orchards and strawberry plantations. The experimental\nevaluation, conducted on the new HORTO-3DLM dataset, compares PointNetPGAP at\nthe sequence- and segment-level with state-of-the-art (SOTA) models, including\nOverlapTransformer, PointNetVLAD, and LOGG3D. Additionally, all models were\ntrained and evaluated using the SLC. Empirical results obtained through a\ncross-validation evaluation protocol demonstrate the superiority of\nPointNetPGAP compared to existing SOTA models. PointNetPGAP emerges as the best\nmodel in retrieving the top-1 candidate, outperforming PointNetVLAD (the\nsecond-best model). Moreover, when comparing the impact of training with the\nSLC model, performance increased on four out of the five evaluated models,\nindicating that adding a context-specific signal to the contrastive loss leads\nto improved descriptors.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "T. Barros",
            "L. Garrote",
            "P. Conde",
            "M. J. Coombes",
            "C. Liu",
            "C. Premebida",
            "U. J. Nunes"
        ],
        "published": "2024-05-29T12:24:34Z"
    },
    {
        "title": "On the formalization of the notion of an interactive algorithm",
        "link": "http://arxiv.org/abs/2405.19037v1",
        "abstract": "An earlier paper gives an account of a quest for a satisfactory formalization\nof the classical informal notion of an algorithm. In this paper, an attempt is\nmade to generalize the results of that quest to the informal notion of an\ninteractive algorithm. The notion of an interactive proto-algorithm is\nintroduced. Interactive algorithms are expected to be equivalence classes of\ninteractive proto-algorithms under an appropriate equivalence relation. As in\nthe non-interactive case, three equivalence relations are defined. Two of them\nare deemed to be bounds for an appropriate equivalence relation and the third\nis likely an appropriate one.",
        "subjects": [
            "cs.CC",
            "cs.DS",
            "cs.LO",
            "F.1.1; F.2.0"
        ],
        "authors": [
            "C. A. Middelburg"
        ],
        "published": "2024-05-29T12:24:08Z"
    },
    {
        "title": "State Space Models are Comparable to Transformers in Estimating\n  Functions with Dynamic Smoothness",
        "link": "http://arxiv.org/abs/2405.19036v1",
        "abstract": "Deep neural networks based on state space models (SSMs) are attracting much\nattention in sequence modeling since their computational cost is significantly\nsmaller than that of Transformers. While the capabilities of SSMs have been\nprimarily investigated through experimental comparisons, theoretical\nunderstanding of SSMs is still limited. In particular, there is a lack of\nstatistical and quantitative evaluation of whether SSM can replace\nTransformers. In this paper, we theoretically explore in which tasks SSMs can\nbe alternatives of Transformers from the perspective of estimating\nsequence-to-sequence functions. We consider the setting where the target\nfunction has direction-dependent smoothness and prove that SSMs can estimate\nsuch functions with the same convergence rate as Transformers. Additionally, we\nprove that SSMs can estimate the target function, even if the smoothness\nchanges depending on the input sequence, as well as Transformers. Our results\nshow the possibility that SSMs can replace Transformers when estimating the\nfunctions in certain classes that appear in practice.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Naoki Nishikawa",
            "Taiji Suzuki"
        ],
        "published": "2024-05-29T12:23:48Z"
    },
    {
        "title": "A Good Foundation is Worth Many Labels: Label-Efficient Panoptic\n  Segmentation",
        "link": "http://arxiv.org/abs/2405.19035v1",
        "abstract": "A key challenge for the widespread application of learning-based models for\nrobotic perception is to significantly reduce the required amount of annotated\ntraining data while achieving accurate predictions. This is essential not only\nto decrease operating costs but also to speed up deployment time. In this work,\nwe address this challenge for PAnoptic SegmenTation with fEw Labels (PASTEL) by\nexploiting the groundwork paved by visual foundation models. We leverage\ndescriptive image features from such a model to train two lightweight network\nheads for semantic segmentation and object boundary detection, using very few\nannotated training samples. We then merge their predictions via a novel fusion\nmodule that yields panoptic maps based on normalized cut. To further enhance\nthe performance, we utilize self-training on unlabeled images selected by a\nfeature-driven similarity scheme. We underline the relevance of our approach by\nemploying PASTEL to important robot perception use cases from autonomous\ndriving and agricultural robotics. In extensive experiments, we demonstrate\nthat PASTEL significantly outperforms previous methods for label-efficient\nsegmentation even when using fewer annotations. The code of our work is\npublicly available at http://pastel.cs.uni-freiburg.de.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "authors": [
            "Niclas Vdisch",
            "Krsat Petek",
            "Markus Kppeler",
            "Abhinav Valada",
            "Wolfram Burgard"
        ],
        "published": "2024-05-29T12:23:29Z"
    },
    {
        "title": "CiliaGraph: Enabling Expression-enhanced Hyper-Dimensional Computation\n  in Ultra-Lightweight and One-Shot Graph Classification on Edge",
        "link": "http://arxiv.org/abs/2405.19033v1",
        "abstract": "Graph Neural Networks (GNNs) are computationally demanding and inefficient\nwhen applied to graph classification tasks in resource-constrained edge\nscenarios due to their inherent process, involving multiple rounds of forward\nand backward propagation. As a lightweight alternative, Hyper-Dimensional\nComputing (HDC), which leverages high-dimensional vectors for data encoding and\nprocessing, offers a more efficient solution by addressing computational\nbottleneck. However, current HDC methods primarily focus on static graphs and\nneglect to effectively capture node attributes and structural information,\nwhich leads to poor accuracy. In this work, we propose CiliaGraph, an enhanced\nexpressive yet ultra-lightweight HDC model for graph classification. This model\nintroduces a novel node encoding strategy that preserves relative distance\nisomorphism for accurate node connection representation. In addition, node\ndistances are utilized as edge weights for information aggregation, and the\nencoded node attributes and structural information are concatenated to obtain a\ncomprehensive graph representation. Furthermore, we explore the relationship\nbetween orthogonality and dimensionality to reduce the dimensions, thereby\nfurther enhancing computational efficiency. Compared to the SOTA GNNs,\nextensive experiments show that CiliaGraph reduces memory usage and accelerates\ntraining speed by an average of 292 times(up to 2341 times) and 103 times(up to\n313 times) respectively while maintaining comparable accuracy.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Yuxi Han",
            "Jihe Wang",
            "Danghui Wang"
        ],
        "published": "2024-05-29T12:22:59Z"
    },
    {
        "title": "Large Language Models for Code Summarization",
        "link": "http://arxiv.org/abs/2405.19032v1",
        "abstract": "Recently, there has been increasing activity in using deep learning for\nsoftware engineering, including tasks like code generation and summarization.\nIn particular, the most recent coding Large Language Models seem to perform\nwell on these problems. In this technical report, we aim to review how these\nmodels perform in code explanation/summarization, while also investigating\ntheir code generation capabilities (based on natural language descriptions).",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.PL",
            "cs.SE"
        ],
        "authors": [
            "Balzs Szalontai",
            "Gerg Szalay",
            "Tams Mrton",
            "Anna Sike",
            "Balzs Pintr",
            "Tibor Gregorics"
        ],
        "published": "2024-05-29T12:18:51Z"
    },
    {
        "title": "SynerGraph: An Integrated Graph Convolution Network for Multimodal\n  Recommendation",
        "link": "http://arxiv.org/abs/2405.19031v1",
        "abstract": "This article presents a novel approach to multimodal recommendation systems,\nfocusing on integrating and purifying multimodal data. Our methodology starts\nby developing a filter to remove noise from various types of data, making the\nrecommendations more reliable. We studied the impact of top-K sparsification on\ndifferent datasets, finding optimal values that strike a balance between\nunderfitting and overfitting concerns. The study emphasizes the significant\nrole of textual information compared to visual data in providing a deep\nunderstanding of items. We conducted sensitivity analyses to understand how\ndifferent modalities and the use of purifier circle loss affect the efficiency\nof the model. The findings indicate that systems that incorporate multiple\nmodalities perform better than those relying on just one modality. Our approach\nhighlights the importance of modality purifiers in filtering out irrelevant\ndata, ensuring that user preferences remain relevant. Models without modality\npurifiers showed reduced performance, emphasizing the need for effective\nintegration of pre-extracted features. The proposed model, which includes an\nnovel self supervised auxiliary task, shows promise in accurately capturing\nuser preferences. The main goal of the fusion technique is to enhance the\nmodeling of user preferences by combining knowledge with item information,\nutilizing sophisticated language models. Extensive experiments show that our\nmodel produces better results than the existing state-of-the-art multimodal\nrecommendation systems.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Mert Burabak",
            "Tevfik Aytekin"
        ],
        "published": "2024-05-29T12:18:32Z"
    },
    {
        "title": "Convex neural network synthesis for robustness in the 1-norm",
        "link": "http://arxiv.org/abs/2405.19029v1",
        "abstract": "With neural networks being used to control safety-critical systems, they\nincreasingly have to be both accurate (in the sense of matching inputs to\noutputs) and robust. However, these two properties are often at odds with each\nother and a trade-off has to be navigated. To address this issue, this paper\nproposes a method to generate an approximation of a neural network which is\ncertifiably more robust. Crucially, the method is fully convex and posed as a\nsemi-definite programme. An application to robustifying model predictive\ncontrol is used to demonstrate the results. The aim of this work is to\nintroduce a method to navigate the neural network robustness/accuracy\ntrade-off.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.SY"
        ],
        "authors": [
            "Ross Drummond",
            "Chris Guiver",
            "Matthew C. Turner"
        ],
        "published": "2024-05-29T12:17:09Z"
    },
    {
        "title": "A Dual-functional Blockchain Framework for Solving Distributed\n  Optimization",
        "link": "http://arxiv.org/abs/2405.19027v1",
        "abstract": "Proof of Work (PoW) has been extensively utilized as the foundation of\nblockchain's security, consistency, and tamper-resistance. However, long has it\nbeen criticized for its tremendous and inefficient utilization of computational\npower and energy. In this work, we design a dual-functional blockchain\nframework that uses solving optimization problems to reach consensus as an\nalternative to PoW, channeling wasted resources into useful work. We model and\nanalyze our framework by developing discrete Markov chains, and derive the\nsecurity conditions to ensure that selfish miners behave honestly. Based on the\nsecurity conditions, we derive a lower bound for the security overhead and\nanalyze the trade-off between useful work efficiency and PoW safeguard. We\nfurther dive deep into the reward function design for the proposed\ndual-functional blockchain and provide practical design guidelines for reward\nfunctions assuming concavity and linearity respectively. Finally, simulation\nresults are presented to validate and illustrate our analytical results.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Weihang Cao",
            "Xintong Ling",
            "Jiaheng Wang",
            "Xiqi Gao",
            "Zhi Ding"
        ],
        "published": "2024-05-29T12:13:03Z"
    },
    {
        "title": "DiveR-CT: Diversity-enhanced Red Teaming with Relaxing Constraints",
        "link": "http://arxiv.org/abs/2405.19026v1",
        "abstract": "Recent advances in large language models (LLMs) have made them indispensable,\nraising significant concerns over managing their safety. Automated red teaming\noffers a promising alternative to the labor-intensive and error-prone manual\nprobing for vulnerabilities, providing more consistent and scalable safety\nevaluations. However, existing approaches often compromise diversity by\nfocusing on maximizing attack success rate. Additionally, methods that decrease\nthe cosine similarity from historical embeddings with semantic diversity\nrewards lead to novelty stagnation as history grows. To address these issues,\nwe introduce DiveR-CT, which relaxes conventional constraints on the objective\nand semantic reward, granting greater freedom for the policy to enhance\ndiversity. Our experiments demonstrate DiveR-CT's marked superiority over\nbaselines by 1) generating data that perform better in various diversity\nmetrics across different attack success rate levels, 2) better-enhancing\nresiliency in blue team models through safety tuning based on collected data,\n3) allowing dynamic control of objective weights for reliable and controllable\nattack success rates, and 4) reducing susceptibility to reward\noveroptimization. Project details and code can be found at\nhttps://andrewzh112.github.io/#diverct.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.CR"
        ],
        "authors": [
            "Andrew Zhao",
            "Quentin Xu",
            "Matthieu Lin",
            "Shenzhi Wang",
            "Yong-jin Liu",
            "Zilong Zheng",
            "Gao Huang"
        ],
        "published": "2024-05-29T12:12:09Z"
    },
    {
        "title": "Inverse Concave-Utility Reinforcement Learning is Inverse Game Theory",
        "link": "http://arxiv.org/abs/2405.19024v1",
        "abstract": "We consider inverse reinforcement learning problems with concave utilities.\nConcave Utility Reinforcement Learning (CURL) is a generalisation of the\nstandard RL objective, which employs a concave function of the state occupancy\nmeasure, rather than a linear function. CURL has garnered recent attention for\nits ability to represent instances of many important applications including the\nstandard RL such as imitation learning, pure exploration, constrained MDPs,\noffline RL, human-regularized RL, and others. Inverse reinforcement learning is\na powerful paradigm that focuses on recovering an unknown reward function that\ncan rationalize the observed behaviour of an agent. There has been recent\ntheoretical advances in inverse RL where the problem is formulated as\nidentifying the set of feasible reward functions. However, inverse RL for CURL\nproblems has not been considered previously. In this paper we show that most of\nthe standard IRL results do not apply to CURL in general, since CURL\ninvalidates the classical Bellman equations. This calls for a new theoretical\nframework for the inverse CURL problem. Using a recent equivalence result\nbetween CURL and Mean-field Games, we propose a new definition for the feasible\nrewards for I-CURL by proving that this problem is equivalent to an inverse\ngame theory problem in a subclass of mean-field games. We present initial query\nand sample complexity results for the I-CURL problem under assumptions such as\nLipschitz-continuity. Finally, we outline future directions and applications in\nhuman--AI collaboration enabled by our results.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.GT",
            "cs.MA"
        ],
        "authors": [
            "Mustafa Mert elikok",
            "Frans A. Oliehoek",
            "Jan-Willem van de Meent"
        ],
        "published": "2024-05-29T12:07:17Z"
    },
    {
        "title": "Towards Standardizing AI Bias Exploration",
        "link": "http://arxiv.org/abs/2405.19022v1",
        "abstract": "Creating fair AI systems is a complex problem that involves the assessment of\ncontext-dependent bias concerns. Existing research and programming libraries\nexpress specific concerns as measures of bias that they aim to constrain or\nmitigate. In practice, one should explore a wide variety of (sometimes\nincompatible) measures before deciding which ones warrant corrective action,\nbut their narrow scope means that most new situations can only be examined\nafter devising new measures. In this work, we present a mathematical framework\nthat distils literature measures of bias into building blocks, hereby\nfacilitating new combinations to cover a wide range of fairness concerns, such\nas classification or recommendation differences across multiple multi-value\nsensitive attributes (e.g., many genders and races, and their intersections).\nWe show how this framework generalizes existing concepts and present frequently\nused blocks. We provide an open-source implementation of our framework as a\nPython library, called FairBench, that facilitates systematic and extensible\nexploration of potential bias concerns.",
        "subjects": [
            "cs.LG",
            "cs.CY",
            "cs.HC"
        ],
        "authors": [
            "Emmanouil Krasanakis",
            "Symeon Papadopoulos"
        ],
        "published": "2024-05-29T12:03:45Z"
    },
    {
        "title": "Physics-Aware Neural Implicit Solvers for multiscale, parametric PDEs\n  with applications in heterogeneous media",
        "link": "http://arxiv.org/abs/2405.19019v1",
        "abstract": "We propose Physics-Aware Neural Implicit Solvers (PANIS), a novel,\ndata-driven framework for learning surrogates for parametrized Partial\nDifferential Equations (PDEs). It consists of a probabilistic, learning\nobjective in which weighted residuals are used to probe the PDE and provide a\nsource of {\\em virtual} data i.e. the actual PDE never needs to be solved. This\nis combined with a physics-aware implicit solver that consists of a much\ncoarser, discretized version of the original PDE, which provides the requisite\ninformation bottleneck for high-dimensional problems and enables generalization\nin out-of-distribution settings (e.g. different boundary conditions). We\ndemonstrate its capability in the context of random heterogeneous materials\nwhere the input parameters represent the material microstructure. We extend the\nframework to multiscale problems and show that a surrogate can be learned for\nthe effective (homogenized) solution without ever solving the reference\nproblem. We further demonstrate how the proposed framework can accommodate and\ngeneralize several existing learning objectives and architectures while\nyielding probabilistic surrogates that can quantify predictive uncertainty.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Matthaios Chatzopoulos",
            "Phaedon-Stelios Koutsourelakis"
        ],
        "published": "2024-05-29T12:01:49Z"
    },
    {
        "title": "Efficient Exploration in Average-Reward Constrained Reinforcement\n  Learning: Achieving Near-Optimal Regret With Posterior Sampling",
        "link": "http://arxiv.org/abs/2405.19017v1",
        "abstract": "We present a new algorithm based on posterior sampling for learning in\nConstrained Markov Decision Processes (CMDP) in the infinite-horizon\nundiscounted setting. The algorithm achieves near-optimal regret bounds while\nbeing advantageous empirically compared to the existing algorithms. Our main\ntheoretical result is a Bayesian regret bound for each cost component of\n$\\tilde{O} (DS\\sqrt{AT})$ for any communicating CMDP with $S$ states, $A$\nactions, and diameter $D$. This regret bound matches the lower bound in order\nof time horizon $T$ and is the best-known regret bound for communicating CMDPs\nachieved by a computationally tractable algorithm. Empirical results show that\nour posterior sampling algorithm outperforms the existing algorithms for\nconstrained reinforcement learning.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Danil Provodin",
            "Maurits Kaptein",
            "Mykola Pechenizkiy"
        ],
        "published": "2024-05-29T11:59:56Z"
    },
    {
        "title": "Distributed Management of Fluctuating Energy Resources in Dynamic\n  Networked Systems",
        "link": "http://arxiv.org/abs/2405.19015v1",
        "abstract": "Modern power systems integrate renewable distributed energy resources (DERs)\nas an environment-friendly enhancement to meet the ever-increasing demands.\nHowever, the inherent unreliability of renewable energy renders developing DER\nmanagement algorithms imperative. We study the energy-sharing problem in a\nsystem consisting of several DERs. Each agent harvests and distributes\nrenewable energy in its neighborhood to optimize the network's performance\nwhile minimizing energy waste. We model this problem as a bandit convex\noptimization problem with constraints that correspond to each node's\nlimitations for energy production. We propose distributed decision-making\npolicies to solve the formulated problem, where we utilize the notion of\ndynamic regret as the performance metric. We also include an adjustment\nstrategy in our developed algorithm to reduce the constraint violations.\nBesides, we design a policy that deals with the non-stationary environment.\nTheoretical analysis shows the effectiveness of our proposed algorithm.\nNumerical experiments using a real-world dataset show superior performance of\nour proposal compared to state-of-the-art methods.",
        "subjects": [
            "eess.SY",
            "cs.LG",
            "cs.MA",
            "cs.SY"
        ],
        "authors": [
            "Xiaotong Cheng",
            "Ioannis Tsetis",
            "Setareh Maghsudi"
        ],
        "published": "2024-05-29T11:54:11Z"
    },
    {
        "title": "Trust the Model Where It Trusts Itself -- Model-Based Actor-Critic with\n  Uncertainty-Aware Rollout Adaption",
        "link": "http://arxiv.org/abs/2405.19014v1",
        "abstract": "Dyna-style model-based reinforcement learning (MBRL) combines model-free\nagents with predictive transition models through model-based rollouts. This\ncombination raises a critical question: 'When to trust your model?'; i.e.,\nwhich rollout length results in the model providing useful data? Janner et al.\n(2019) address this question by gradually increasing rollout lengths throughout\nthe training. While theoretically tempting, uniform model accuracy is a fallacy\nthat collapses at the latest when extrapolating. Instead, we propose asking the\nquestion 'Where to trust your model?'. Using inherent model uncertainty to\nconsider local accuracy, we obtain the Model-Based Actor-Critic with\nUncertainty-Aware Rollout Adaption (MACURA) algorithm. We propose an\neasy-to-tune rollout mechanism and demonstrate substantial improvements in data\nefficiency and performance compared to state-of-the-art deep MBRL methods on\nthe MuJoCo benchmark.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Bernd Frauenknecht",
            "Artur Eisele",
            "Devdutt Subhasish",
            "Friedrich Solowjow",
            "Sebastian Trimpe"
        ],
        "published": "2024-05-29T11:53:07Z"
    },
    {
        "title": "On Dissipativity of Cross-Entropy Loss in Training ResNets",
        "link": "http://arxiv.org/abs/2405.19013v1",
        "abstract": "The training of ResNets and neural ODEs can be formulated and analyzed from\nthe perspective of optimal control. This paper proposes a dissipative\nformulation of the training of ResNets and neural ODEs for classification\nproblems by including a variant of the cross-entropy as a regularization in the\nstage cost. Based on the dissipative formulation of the training, we prove that\nthe trained ResNet exhibit the turnpike phenomenon. We then illustrate that the\ntraining exhibits the turnpike phenomenon by training on the two spirals and\nMNIST datasets. This can be used to find very shallow networks suitable for a\ngiven classification task.",
        "subjects": [
            "cs.LG",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ],
        "authors": [
            "Jens Pttschneider",
            "Timm Faulwasser"
        ],
        "published": "2024-05-29T11:52:53Z"
    },
    {
        "title": "Implicit Neural Image Field for Biological Microscopy Image Compression",
        "link": "http://arxiv.org/abs/2405.19012v1",
        "abstract": "The rapid pace of innovation in biological microscopy imaging has led to\nlarge images, putting pressure on data storage and impeding efficient sharing,\nmanagement, and visualization. This necessitates the development of efficient\ncompression solutions. Traditional CODEC methods struggle to adapt to the\ndiverse bioimaging data and often suffer from sub-optimal compression. In this\nstudy, we propose an adaptive compression workflow based on Implicit Neural\nRepresentation (INR). This approach permits application-specific compression\nobjectives, capable of compressing images of any shape and arbitrary pixel-wise\ndecompression. We demonstrated on a wide range of microscopy images from real\napplications that our workflow not only achieved high, controllable compression\nratios (e.g., 512x) but also preserved detailed information critical for\ndownstream analysis.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Gaole Dai",
            "Cheng-Ching Tseng",
            "Qingpo Wuwu",
            "Rongyu Zhang",
            "Shaokang Wang",
            "Ming Lu",
            "Tiejun Huang",
            "Yu Zhou",
            "Ali Ata Tuz",
            "Matthias Gunzer",
            "Jianxu Chen",
            "Shanghang Zhang"
        ],
        "published": "2024-05-29T11:51:33Z"
    },
    {
        "title": "Evaluating the External and Parametric Knowledge Fusion of Large\n  Language Models",
        "link": "http://arxiv.org/abs/2405.19010v1",
        "abstract": "Integrating external knowledge into large language models (LLMs) presents a\npromising solution to overcome the limitations imposed by their antiquated and\nstatic parametric memory. Prior studies, however, have tended to over-reliance\non external knowledge, underestimating the valuable contributions of an LLMs'\nintrinsic parametric knowledge. The efficacy of LLMs in blending external and\nparametric knowledge remains largely unexplored, especially in cases where\nexternal knowledge is incomplete and necessitates supplementation by their\nparametric knowledge. We propose to deconstruct knowledge fusion into four\ndistinct scenarios, offering the first thorough investigation of LLM behavior\nacross each. We develop a systematic pipeline for data construction and\nknowledge infusion to simulate these fusion scenarios, facilitating a series of\ncontrolled experiments. Our investigation reveals that enhancing parametric\nknowledge within LLMs can significantly bolster their capability for knowledge\nintegration. Nonetheless, we identify persistent challenges in memorizing and\neliciting parametric knowledge, and determining parametric knowledge\nboundaries. Our findings aim to steer future explorations on harmonizing\nexternal and parametric knowledge within LLMs.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "authors": [
            "Hao Zhang",
            "Yuyang Zhang",
            "Xiaoguang Li",
            "Wenxuan Shi",
            "Haonan Xu",
            "Huanshuo Liu",
            "Yasheng Wang",
            "Lifeng Shang",
            "Qun Liu",
            "Yong Liu",
            "Ruiming Tang"
        ],
        "published": "2024-05-29T11:48:27Z"
    },
    {
        "title": "Enhancing Vision-Language Model with Unmasked Token Alignment",
        "link": "http://arxiv.org/abs/2405.19009v1",
        "abstract": "Contrastive pre-training on image-text pairs, exemplified by CLIP, becomes a\nstandard technique for learning multi-modal visual-language representations.\nAlthough CLIP has demonstrated remarkable performance, training it from scratch\non noisy web-scale datasets is computationally demanding. On the other hand,\nmask-then-predict pre-training approaches, like Masked Image Modeling (MIM),\noffer efficient self-supervised learning for single-modal representations. This\npaper introduces Unmasked Token Alignment (UTA), a method that leverages\nexisting CLIP models to further enhance its vision-language representations.\nUTA trains a Vision Transformer (ViT) by aligning unmasked visual tokens to the\ncorresponding image tokens from a frozen CLIP vision encoder, which\nautomatically aligns the ViT model with the CLIP text encoder. The pre-trained\nViT can be directly applied for zero-shot evaluation even without training on\nimage-text pairs. Compared to MIM approaches, UTA does not suffer from\ntraining-finetuning inconsistency and is much more training-efficient by\navoiding using the extra [MASK] tokens. Extensive experimental results\ndemonstrate that UTA can enhance CLIP models and outperform existing MIM\nmethods on various uni- and multi-modal benchmarks. Code and models are\navailable at https://github.com/jihaonew/UTA.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jihao Liu",
            "Jinliang Zheng",
            "Boxiao Liu",
            "Yu Liu",
            "Hongsheng Li"
        ],
        "published": "2024-05-29T11:48:17Z"
    },
    {
        "title": "Auto-selected Knowledge Adapters for Lifelong Person Re-identification",
        "link": "http://arxiv.org/abs/2405.19005v2",
        "abstract": "Lifelong Person Re-Identification (LReID) extends traditional ReID by\nrequiring systems to continually learn from non-overlapping datasets across\ndifferent times and locations, adapting to new identities while preserving\nknowledge of previous ones. Existing approaches, either rehearsal-free or\nrehearsal-based, still suffer from the problem of catastrophic forgetting since\nthey try to cram diverse knowledge into one fixed model. To overcome this\nlimitation, we introduce a novel framework AdalReID, that adopts knowledge\nadapters and a parameter-free auto-selection mechanism for lifelong learning.\nConcretely, we incrementally build distinct adapters to learn domain-specific\nknowledge at each step, which can effectively learn and preserve knowledge\nacross different datasets. Meanwhile, the proposed auto-selection strategy\nadaptively calculates the knowledge similarity between the input set and the\nadapters. On the one hand, the appropriate adapters are selected for the inputs\nto process ReID, and on the other hand, the knowledge interaction and fusion\nbetween adapters are enhanced to improve the generalization ability of the\nmodel. Extensive experiments are conducted to demonstrate the superiority of\nour AdalReID, which significantly outperforms SOTAs by about 10$\\sim$20\\% mAP\non both seen and unseen domains.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xuelin Qian",
            "Ruiqi Wu",
            "Gong Cheng",
            "Junwei Han"
        ],
        "published": "2024-05-29T11:42:02Z"
    },
    {
        "title": "An implementation of tensor product patch smoothers on GPU",
        "link": "http://arxiv.org/abs/2405.19004v2",
        "abstract": "We present a GPU implementation of vertex-patch smoothers for higher order\nfinite element methods in two and three dimensions. Analysis shows that they\nare not memory bound with respect to GPU DRAM, but with respect to on-chip\nscratchpad memory. Multigrid operations are optimized through localization and\nreorganized local operations in on-chip memory, achieving minimal global data\ntransfer and a conflict free memory access pattern. Performance tests\ndemonstrate that the optimized kernel is at least 2 times faster than the\nstraightforward implementation for the Poisson problem, across various\npolynomial degrees in 2D and 3D, achieving up to 36% of the peak performance in\nboth single and double precision on Nvidia A100 GPU.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "65N55, 65Y20"
        ],
        "authors": [
            "Cu Cui",
            "Paul Grosse-Bley",
            "Guido Kanschat",
            "Robert Strzodka"
        ],
        "published": "2024-05-29T11:41:38Z"
    },
    {
        "title": "A structure-preserving scheme for computing effective diffusivity and\n  anomalous diffusion phenomena of random flows",
        "link": "http://arxiv.org/abs/2405.19003v1",
        "abstract": "This paper aims to investigate the diffusion behavior of particles moving in\nstochastic flows under a structure-preserving scheme. We compute the effective\ndiffusivity for normal diffusive random flows and establish the power law\nbetween spatial and temporal variables for cases with anomalous diffusion\nphenomena. From a Lagrangian approach, we separate the corresponding stochastic\ndifferential equations (SDEs) into sub-problems and construct a one-step\nstructure-preserving method to solve them. Then by modified equation systems,\nthe convergence analysis in calculating the effective diffusivity is provided\nand compared between the structure-preserving scheme and the Euler-Maruyama\nscheme. Also, we provide the error estimate for the structure-preserving scheme\nin calculating the power law for a series of super-diffusive random flows.\nFinally, we calculate the effective diffusivity and anomalous diffusion\nphenomena for a series of 2D and 3D random fields.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "37M25, 60J60, 60H35, 65P10, 65M75, 76M50"
        ],
        "authors": [
            "Tan Zhang",
            "Zhongjian Wang",
            "Jack Xin",
            "Zhiwen Zhang"
        ],
        "published": "2024-05-29T11:37:36Z"
    },
    {
        "title": "Dynamic Throwing with Robotic Material Handling Machines",
        "link": "http://arxiv.org/abs/2405.19001v1",
        "abstract": "Automation of hydraulic material handling machinery is currently limited to\nsemi-static pick-and-place cycles. Dynamic throwing motions which utilize the\npassive joints, can greatly improve time efficiency as well as increase the\ndumping workspace. In this work, we use Reinforcement Learning (RL) to design\ndynamic controllers for material handlers with underactuated arms as commonly\nused in logistics. The controllers are tested both in simulation and in\nreal-world experiments on a 12-ton test platform. The method is able to exploit\nthe passive joints of the gripper to perform dynamic throwing motions. With the\nproposed controllers, the machine is able to throw individual objects to\ntargets outside the static reachability zone with good accuracy for its\npractical applications. The work demonstrates the possibility of using RL to\nperform highly dynamic tasks with heavy machinery, suggesting a potential for\nimproving the efficiency and precision of autonomous material handling tasks.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Lennart Werner",
            "Fang Nan",
            "Pol Eyschen",
            "Filippo A. Spinelli",
            "Hongyi Yang",
            "Marco Hutter"
        ],
        "published": "2024-05-29T11:31:15Z"
    },
    {
        "title": "FedMAP: Unlocking Potential in Personalized Federated Learning through\n  Bi-Level MAP Optimization",
        "link": "http://arxiv.org/abs/2405.19000v1",
        "abstract": "Federated Learning (FL) enables collaborative training of machine learning\nmodels on decentralized data while preserving data privacy. However, data\nacross clients often differs significantly due to class imbalance, feature\ndistribution skew, sample size imbalance, and other phenomena. Leveraging\ninformation from these not identically distributed (non-IID) datasets poses\nsubstantial challenges. FL methods based on a single global model cannot\neffectively capture the variations in client data and underperform in non-IID\nsettings. Consequently, Personalized FL (PFL) approaches that adapt to each\nclient's data distribution but leverage other clients' data are essential but\ncurrently underexplored. We propose a novel Bayesian PFL framework using\nbi-level optimization to tackle the data heterogeneity challenges. Our proposed\nframework utilizes the global model as a prior distribution within a Maximum A\nPosteriori (MAP) estimation of personalized client models. This approach\nfacilitates PFL by integrating shared knowledge from the prior, thereby\nenhancing local model performance, generalization ability, and communication\nefficiency. We extensively evaluated our bi-level optimization approach on\nreal-world and synthetic datasets, demonstrating significant improvements in\nmodel accuracy compared to existing methods while reducing communication\noverhead. This study contributes to PFL by establishing a solid theoretical\nfoundation for the proposed method and offering a robust, ready-to-use\nframework that effectively addresses the challenges posed by non-IID data in\nFL.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Fan Zhang",
            "Carlos Esteve-Yage",
            "Sren Dittmer",
            "Carola-Bibiane Schnlieb",
            "Michael Roberts"
        ],
        "published": "2024-05-29T11:28:06Z"
    },
    {
        "title": "Continuously Optimizing Radar Placement with Model Predictive Path\n  Integrals",
        "link": "http://arxiv.org/abs/2405.18999v2",
        "abstract": "Continuously optimizing sensor placement is essential for precise target\nlocalization in various military and civilian applications. While information\ntheory has shown promise in optimizing sensor placement, many studies\noversimplify sensor measurement models or neglect dynamic constraints of mobile\nsensors. To address these challenges, we employ a range measurement model that\nincorporates radar parameters and radar-target distance, coupled with Model\nPredictive Path Integral (MPPI) control to manage complex environmental\nobstacles and dynamic constraints. We compare the proposed approach against\nstationary radars or simplified range measurement models based on the root mean\nsquared error (RMSE) of the Cubature Kalman Filter (CKF) estimator for the\ntargets' state. Additionally, we visualize the evolving geometry of radars and\ntargets over time, highlighting areas of highest measurement information gain,\ndemonstrating the strengths of the approach. The proposed strategy outperforms\nstationary radars and simplified range measurement models in target\nlocalization, achieving a 38-74% reduction in mean RMSE and a 33-79% reduction\nin the upper tail of the 90% Highest Density Interval (HDI) over 500 Monte Carl\n(MC) trials across all time steps.\n  Code will be made publicly available upon acceptance.",
        "subjects": [
            "stat.AP",
            "cs.AI",
            "cs.RO"
        ],
        "authors": [
            "Michael Potter",
            "Shuo Tang",
            "Paul Ghanem",
            "Milica Stojanovic",
            "Pau Closas",
            "Murat Akcakaya",
            "Ben Wright",
            "Marius Necsoiu",
            "Deniz Erdogmus",
            "Michael Everett",
            "Tales Imbiriba"
        ],
        "published": "2024-05-29T11:25:53Z"
    },
    {
        "title": "Derandomized Non-Abelian Homomorphism Testing in Low Soundness Regime",
        "link": "http://arxiv.org/abs/2405.18998v1",
        "abstract": "We give a randomness-efficient homomorphism test in the low soundness regime\nfor functions, $f: G\\to \\mathbb{U}_t$, from an arbitrary finite group $G$ to\n$t\\times t$ unitary matrices. We show that if such a function passes a\nderandomized Blum--Luby--Rubinfeld (BLR) test (using small-bias sets), then (i)\nit correlates with a function arising from a genuine homomorphism, and (ii) it\nhas a non-trivial Fourier mass on a low-dimensional irreducible representation.\n  In the full randomness regime, such a test for matrix-valued functions on\nfinite groups implicitly appears in the works of Gowers and Hatami [Sbornik:\nMathematics '17], and Moore and Russell [SIAM Journal on Discrete Mathematics\n'15]. Thus, our work can be seen as a near-optimal derandomization of their\nresults. Our key technical contribution is a \"degree-2 expander mixing lemma''\nthat shows that Gowers' $\\mathrm{U}^2$ norm can be efficiently estimated by\nrestricting it to a small-bias subset. Another corollary is a \"derandomized''\nversion of a useful lemma due to Babai, Nikolov, and Pyber [SODA'08].",
        "subjects": [
            "cs.CC",
            "cs.DM",
            "math.GR",
            "math.RT"
        ],
        "authors": [
            "Tushant Mittal",
            "Sourya Roy"
        ],
        "published": "2024-05-29T11:25:31Z"
    },
    {
        "title": "Kernel Semi-Implicit Variational Inference",
        "link": "http://arxiv.org/abs/2405.18997v1",
        "abstract": "Semi-implicit variational inference (SIVI) extends traditional variational\nfamilies with semi-implicit distributions defined in a hierarchical manner. Due\nto the intractable densities of semi-implicit distributions, classical SIVI\noften resorts to surrogates of evidence lower bound (ELBO) that would introduce\nbiases for training. A recent advancement in SIVI, named SIVI-SM, utilizes an\nalternative score matching objective made tractable via a minimax formulation,\nalbeit requiring an additional lower-level optimization. In this paper, we\npropose kernel SIVI (KSIVI), a variant of SIVI-SM that eliminates the need for\nlower-level optimization through kernel tricks. Specifically, we show that when\noptimizing over a reproducing kernel Hilbert space (RKHS), the lower-level\nproblem has an explicit solution. This way, the upper-level objective becomes\nthe kernel Stein discrepancy (KSD), which is readily computable for stochastic\ngradient descent due to the hierarchical structure of semi-implicit variational\ndistributions. An upper bound for the variance of the Monte Carlo gradient\nestimators of the KSD objective is derived, which allows us to establish novel\nconvergence guarantees of KSIVI. We demonstrate the effectiveness and\nefficiency of KSIVI on both synthetic distributions and a variety of real data\nBayesian inference tasks.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Ziheng Cheng",
            "Longlin Yu",
            "Tianyu Xie",
            "Shiyue Zhang",
            "Cheng Zhang"
        ],
        "published": "2024-05-29T11:21:25Z"
    },
    {
        "title": "Using multi-orbit cyclic subspace codes for constructing optical\n  orthogonal codes",
        "link": "http://arxiv.org/abs/2405.18996v1",
        "abstract": "We present a new application of multi-orbit cyclic subspace codes to\nconstruct large optical orthogonal codes, with the aid of the multiplicative\nstructure of finite fields extensions. This approach is different from earlier\napproaches using combinatorial and additive (character sum) structures of\nfinite fields. Consequently, we immediately obtain new classes of optical\northogonal codes with different parameters.",
        "subjects": [
            "cs.IT",
            "math.CO",
            "math.IT"
        ],
        "authors": [
            "Ferruh Ozbudak",
            "Paolo Santonastaso",
            "Ferdinando Zullo"
        ],
        "published": "2024-05-29T11:19:56Z"
    },
    {
        "title": "Best Ergodic Averages via Optimal Graph Filters in Reversible Markov\n  Chains",
        "link": "http://arxiv.org/abs/2405.18995v1",
        "abstract": "In this paper, we address the problem of finding the best ergodic or Birkhoff\naverages in the ergodic theorem to ensure rapid convergence to a desired value,\nusing graph filters. Our approach begins by representing a function on the\nstate space as a graph signal, where the (directed) graph is formed by the\ntransition probabilities of a reversible Markov chain. We introduce a concept\nof graph variation, enabling the definition of the graph Fourier transform for\ngraph signals on this directed graph. Viewing the iteration in the ergodic\ntheorem as a graph filter, we recognize its non-optimality and propose three\noptimization problems aimed at determining optimal graph filters. These\noptimization problems yield the Bernstein, Chebyshev, and Legendre filters.\nNumerical testing reveals that while the Bernstein filter performs slightly\nbetter than the traditional ergodic average, the Chebyshev and Legendre filters\nsignificantly outperform the ergodic average, demonstrating rapid convergence\nto the desired value.",
        "subjects": [
            "eess.SY",
            "cs.SY",
            "math.PR"
        ],
        "authors": [
            "Naci Saldi"
        ],
        "published": "2024-05-29T11:17:26Z"
    },
    {
        "title": "ParsEval: Evaluation of Parsing Behavior using Real-world\n  Out-in-the-wild X.509 Certificates",
        "link": "http://dx.doi.org/10.1145/3664476.3669935",
        "abstract": "X.509 certificates play a crucial role in establishing secure communication\nover the internet by enabling authentication and data integrity. Equipped with\na rich feature set, the X.509 standard is defined by multiple, comprehensive\nISO/IEC documents. Due to its internet-wide usage, there are different\nimplementations in multiple programming languages leading to a large and\nfragmented ecosystem. This work addresses the research question \"Are there\nuser-visible and security-related differences between X.509 certificate\nparsers?\". Relevant libraries offering APIs for parsing X.509 certificates were\ninvestigated and an appropriate test suite was developed. From 34 libraries 6\nwere chosen for further analysis. The X.509 parsing modules of the chosen\nlibraries were called with 186,576,846 different certificates from a real-world\ndataset and the observed error codes were investigated. This study reveals an\nanomaly in wolfSSL's X.509 parsing module and that there are fundamental\ndifferences in the ecosystem. While related studies nowadays mostly focus on\nfuzzing techniques resulting in artificial certificates, this study confirms\nthat available X.509 parsing modules differ largely and yield different\nresults, even for real-world out-in-the-wild certificates.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Stefan Tatschner",
            "Sebastian N. Peters",
            "Michael P. Heinl",
            "Tobias Specht",
            "Thomas Newe"
        ],
        "published": "2024-05-29T11:15:12Z"
    },
    {
        "title": "EasyAnimate: A High-Performance Long Video Generation Method based on\n  Transformer Architecture",
        "link": "http://arxiv.org/abs/2405.18991v1",
        "abstract": "This paper presents EasyAnimate, an advanced method for video generation that\nleverages the power of transformer architecture for high-performance outcomes.\nWe have expanded the DiT framework originally designed for 2D image synthesis\nto accommodate the complexities of 3D video generation by incorporating a\nmotion module block. It is used to capture temporal dynamics, thereby ensuring\nthe production of consistent frames and seamless motion transitions. The motion\nmodule can be adapted to various DiT baseline methods to generate video with\ndifferent styles. It can also generate videos with different frame rates and\nresolutions during both training and inference phases, suitable for both images\nand videos. Moreover, we introduce slice VAE, a novel approach to condense the\ntemporal axis, facilitating the generation of long duration videos. Currently,\nEasyAnimate exhibits the proficiency to generate videos with 144 frames. We\nprovide a holistic ecosystem for video production based on DiT, encompassing\naspects such as data pre-processing, VAE training, DiT models training (both\nthe baseline model and LoRA model), and end-to-end video inference. Code is\navailable at: https://github.com/aigc-apps/EasyAnimate. We are continuously\nworking to enhance the performance of our method.",
        "subjects": [
            "cs.CV",
            "cs.CL",
            "cs.MM"
        ],
        "authors": [
            "Jiaqi Xu",
            "Xinyi Zou",
            "Kunzhe Huang",
            "Yunkuo Chen",
            "Bo Liu",
            "MengLi Cheng",
            "Xing Shi",
            "Jun Huang"
        ],
        "published": "2024-05-29T11:11:07Z"
    },
    {
        "title": "Robust Optimization in Protein Fitness Landscapes Using Reinforcement\n  Learning in Latent Space",
        "link": "http://arxiv.org/abs/2405.18986v1",
        "abstract": "Proteins are complex molecules responsible for different functions in nature.\nEnhancing the functionality of proteins and cellular fitness can significantly\nimpact various industries. However, protein optimization using computational\nmethods remains challenging, especially when starting from low-fitness\nsequences. We propose LatProtRL, an optimization method to efficiently traverse\na latent space learned by an encoder-decoder leveraging a large protein\nlanguage model. To escape local optima, our optimization is modeled as a Markov\ndecision process using reinforcement learning acting directly in latent space.\nWe evaluate our approach on two important fitness optimization tasks,\ndemonstrating its ability to achieve comparable or superior fitness over\nbaseline methods. Our findings and in vitro evaluation show that the generated\nsequences can reach high-fitness regions, suggesting a substantial potential of\nLatProtRL in lab-in-the-loop scenarios.",
        "subjects": [
            "cs.LG",
            "q-bio.BM",
            "q-bio.QM"
        ],
        "authors": [
            "Minji Lee",
            "Luiz Felipe Vecchietti",
            "Hyunkyu Jung",
            "Hyun Joo Ro",
            "Meeyoung Cha",
            "Ho Min Kim"
        ],
        "published": "2024-05-29T11:03:42Z"
    },
    {
        "title": "Optimizing Vehicular Networks with Variational Quantum Circuits-based\n  Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.18984v1",
        "abstract": "In vehicular networks (VNets), ensuring both road safety and dependable\nnetwork connectivity is of utmost importance. Achieving this necessitates the\ncreation of resilient and efficient decision-making policies that prioritize\nmultiple objectives. In this paper, we develop a Variational Quantum Circuit\n(VQC)-based multi-objective reinforcement learning (MORL) framework to\ncharacterize efficient network selection and autonomous driving policies in a\nvehicular network (VNet). Numerical results showcase notable enhancements in\nboth convergence rates and rewards when compared to conventional deep-Q\nnetworks (DQNs), validating the efficacy of the VQC-MORL solution.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.NI"
        ],
        "authors": [
            "Zijiang Yan",
            "Ramsundar Tanikella",
            "Hina Tabassum"
        ],
        "published": "2024-05-29T10:57:25Z"
    },
    {
        "title": "Federated Learning under Partially Class-Disjoint Data via Manifold\n  Reshaping",
        "link": "http://arxiv.org/abs/2405.18983v1",
        "abstract": "Statistical heterogeneity severely limits the performance of federated\nlearning (FL), motivating several explorations e.g., FedProx, MOON and FedDyn,\nto alleviate this problem. Despite effectiveness, their considered scenario\ngenerally requires samples from almost all classes during the local training of\neach client, although some covariate shifts may exist among clients. In fact,\nthe natural case of partially class-disjoint data (PCDD), where each client\ncontributes a few classes (instead of all classes) of samples, is practical yet\nunderexplored. Specifically, the unique collapse and invasion characteristics\nof PCDD can induce the biased optimization direction in local training, which\nprevents the efficiency of federated learning. To address this dilemma, we\npropose a manifold reshaping approach called FedMR to calibrate the feature\nspace of local training. Our FedMR adds two interplaying losses to the vanilla\nfederated learning: one is intra-class loss to decorrelate feature dimensions\nfor anti-collapse; and the other one is inter-class loss to guarantee the\nproper margin among categories in the feature expansion. We conduct extensive\nexperiments on a range of datasets to demonstrate that our FedMR achieves much\nhigher accuracy and better communication efficiency. Source code is available\nat: https://github.com/MediaBrain-SJTU/FedMR.git.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "authors": [
            "Ziqing Fan",
            "Jiangchao Yao",
            "Ruipeng Zhang",
            "Lingjuan Lyu",
            "Ya Zhang",
            "Yanfeng Wang"
        ],
        "published": "2024-05-29T10:56:13Z"
    },
    {
        "title": "Multilevel Interior Penalty Methods on GPUs",
        "link": "http://arxiv.org/abs/2405.18982v2",
        "abstract": "We present a matrix-free multigrid method for high-order discontinuous\nGalerkin (DG) finite element methods with GPU acceleration. A performance\nanalysis is conducted, comparing various data and compute layouts. Smoother\nimplementations are optimized through localization and fast diagonalization\ntechniques. Leveraging conflict-free access patterns in shared memory,\narithmetic throughput of up to 39% of the peak performance on Nvidia A100 GPUs\nare achieved. Experimental results affirm the effectiveness of mixed-precision\napproaches and MPI parallelization in accelerating algorithms. Furthermore, an\nassessment of solver efficiency and robustness is provided across both two and\nthree dimensions, with applications to Poisson problems.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "65N55, 65Y20"
        ],
        "authors": [
            "Cu Cui",
            "Guido Kanschat"
        ],
        "published": "2024-05-29T10:55:52Z"
    },
    {
        "title": "MANO: Exploiting Matrix Norm for Unsupervised Accuracy Estimation Under\n  Distribution Shifts",
        "link": "http://arxiv.org/abs/2405.18979v1",
        "abstract": "Leveraging the models' outputs, specifically the logits, is a common approach\nto estimating the test accuracy of a pre-trained neural network on\nout-of-distribution (OOD) samples without requiring access to the corresponding\nground truth labels. Despite their ease of implementation and computational\nefficiency, current logit-based methods are vulnerable to overconfidence\nissues, leading to prediction bias, especially under the natural shift. In this\nwork, we first study the relationship between logits and generalization\nperformance from the view of low-density separation assumption. Our findings\nmotivate our proposed method MaNo which (1) applies a data-dependent\nnormalization on the logits to reduce prediction bias, and (2) takes the $L_p$\nnorm of the matrix of normalized logits as the estimation score. Our\ntheoretical analysis highlights the connection between the provided score and\nthe model's uncertainty. We conduct an extensive empirical study on common\nunsupervised accuracy estimation benchmarks and demonstrate that MaNo achieves\nstate-of-the-art performance across various architectures in the presence of\nsynthetic, natural, or subpopulation shifts.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Renchunzi Xie",
            "Ambroise Odonnat",
            "Vasilii Feofanov",
            "Weijian Deng",
            "Jianfeng Zhang",
            "Bo An"
        ],
        "published": "2024-05-29T10:45:06Z"
    },
    {
        "title": "Comparing Lazy Constraint Selection Strategies in Train Routing with\n  Moving Block Control",
        "link": "http://arxiv.org/abs/2405.18977v1",
        "abstract": "Railroad transportation plays a vital role in the future of sustainable\nmobility. Besides building new infrastructure, capacity can be improved by\nmodern train control systems, e.g., based on moving blocks. At the same time,\nthere is only limited work on how to optimally route trains using the potential\ngained by these systems. Recently, an initial approach for train routing with\nmoving block control has been proposed to address this demand. However,\ndetailed evaluations on so-called lazy constraints are missing, and no publicly\navailable implementation exists. In this work, we close this gap by providing\nan extended approach as well as a flexible open-source implementation that can\nuse different solving strategies. Using that, we experimentally evaluate what\nchoices should be made when implementing a lazy constraint approach. The\ncorresponding implementation and benchmarks are publicly available as part of\nthe Munich Train Control Toolkit (MTCT) at https://github.com/cda-tum/mtct.",
        "subjects": [
            "eess.SY",
            "cs.CE",
            "cs.SY"
        ],
        "authors": [
            "Stefan Engels",
            "Robert Wille"
        ],
        "published": "2024-05-29T10:42:36Z"
    },
    {
        "title": "Hierarchical Classification Auxiliary Network for Time Series\n  Forecasting",
        "link": "http://arxiv.org/abs/2405.18975v1",
        "abstract": "Deep learning has significantly advanced time series forecasting through its\npowerful capacity to capture sequence relationships. However, training these\nmodels with the Mean Square Error (MSE) loss often results in over-smooth\npredictions, making it challenging to handle the complexity and learn\nhigh-entropy features from time series data with high variability and\nunpredictability. In this work, we introduce a novel approach by tokenizing\ntime series values to train forecasting models via cross-entropy loss, while\nconsidering the continuous nature of time series data. Specifically, we propose\nHierarchical Classification Auxiliary Network, HCAN, a general model-agnostic\ncomponent that can be integrated with any forecasting model. HCAN is based on a\nHierarchy-Aware Attention module that integrates multi-granularity high-entropy\nfeatures at different hierarchy levels. At each level, we assign a class label\nfor timesteps to train an Uncertainty-Aware Classifier. This classifier\nmitigates the over-confidence in softmax loss via evidence theory. We also\nimplement a Hierarchical Consistency Loss to maintain prediction consistency\nacross hierarchy levels. Extensive experiments integrating HCAN with\nstate-of-the-art forecasting models demonstrate substantial improvements over\nbaselines on several real-world datasets. Code is available\nat:https://github.com/syrGitHub/HCAN.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yanru Sun",
            "Zongxia Xie",
            "Dongyue Chen",
            "Emadeldeen Eldele",
            "Qinghua Hu"
        ],
        "published": "2024-05-29T10:38:25Z"
    },
    {
        "title": "Encoding Hierarchical Schema via Concept Flow for Multifaceted Ideology\n  Detection",
        "link": "http://arxiv.org/abs/2405.18974v1",
        "abstract": "Multifaceted ideology detection (MID) aims to detect the ideological leanings\nof texts towards multiple facets. Previous studies on ideology detection mainly\nfocus on one generic facet and ignore label semantics and explanatory\ndescriptions of ideologies, which are a kind of instructive information and\nreveal the specific concepts of ideologies. In this paper, we develop a novel\nconcept semantics-enhanced framework for the MID task. Specifically, we propose\na bidirectional iterative concept flow (BICo) method to encode multifaceted\nideologies. BICo enables the concepts to flow across levels of the schema tree\nand enriches concept representations with multi-granularity semantics.\nFurthermore, we explore concept attentive matching and concept-guided\ncontrastive learning strategies to guide the model to capture ideology features\nwith the learned concept semantics. Extensive experiments on the benchmark\ndataset show that our approach achieves state-of-the-art performance in MID,\nincluding in the cross-topic scenario.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Songtao Liu",
            "Bang Wang",
            "Wei Xiang",
            "Han Xu",
            "Minghua Xu"
        ],
        "published": "2024-05-29T10:37:28Z"
    },
    {
        "title": "Federated Learning with Bilateral Curation for Partially Class-Disjoint\n  Data",
        "link": "http://arxiv.org/abs/2405.18972v1",
        "abstract": "Partially class-disjoint data (PCDD), a common yet under-explored data\nformation where each client contributes a part of classes (instead of all\nclasses) of samples, severely challenges the performance of federated\nalgorithms. Without full classes, the local objective will contradict the\nglobal objective, yielding the angle collapse problem for locally missing\nclasses and the space waste problem for locally existing classes. As far as we\nknow, none of the existing methods can intrinsically mitigate PCDD challenges\nto achieve holistic improvement in the bilateral views (both global view and\nlocal view) of federated learning. To address this dilemma, we are inspired by\nthe strong generalization of simplex Equiangular Tight Frame~(ETF) on the\nimbalanced data, and propose a novel approach called FedGELA where the\nclassifier is globally fixed as a simplex ETF while locally adapted to the\npersonal distributions. Globally, FedGELA provides fair and equal\ndiscrimination for all classes and avoids inaccurate updates of the classifier,\nwhile locally it utilizes the space of locally missing classes for locally\nexisting classes. We conduct extensive experiments on a range of datasets to\ndemonstrate that our FedGELA achieves promising performance~(averaged\nimprovement of 3.9% to FedAvg and 1.5% to best baselines) and provide both\nlocal and global convergence guarantees. Source code is available\nat:https://github.com/MediaBrain-SJTU/FedGELA.git.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "authors": [
            "Ziqing Fan",
            "Ruipeng Zhang",
            "Jiangchao Yao",
            "Bo Han",
            "Ya Zhang",
            "Yanfeng Wang"
        ],
        "published": "2024-05-29T10:34:44Z"
    },
    {
        "title": "Mitigate Position Bias with Coupled Ranking Bias on CTR Prediction",
        "link": "http://arxiv.org/abs/2405.18971v1",
        "abstract": "Position bias, i.e., users' preference of an item is affected by its placing\nposition, is well studied in the recommender system literature. However, most\nexisting methods ignore the widely coupled ranking bias, which is also related\nto the placing position of the item. Using both synthetic and industrial\ndatasets, we first show how this widely coexisted ranking bias deteriorates the\nperformance of the existing position bias estimation methods. To mitigate the\nposition bias with the presence of the ranking bias, we propose a novel\nposition bias estimation method, namely gradient interpolation, which fuses two\nestimation methods using a fusing weight. We further propose an adaptive method\nto automatically determine the optimal fusing weight. Extensive experiments on\nboth synthetic and industrial datasets demonstrate the superior performance of\nthe proposed methods.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Yao Zhao",
            "Zhining Liu",
            "Tianchi Cai",
            "Haipeng Zhang",
            "Chenyi Zhuang",
            "Jinjie Gu"
        ],
        "published": "2024-05-29T10:31:53Z"
    },
    {
        "title": "Global and local observability of hypergraphs",
        "link": "http://arxiv.org/abs/2405.18969v1",
        "abstract": "This paper studies observability for non-uniform hypergraphs with inputs and\noutputs. To capture higher-order interactions, we define a canonical\nnon-homogeneous dynamical system with nonlinear outputs on hypergraphs. We then\nconstruct algebraic necessary and sufficient conditions based on polynomial\nideals and varieties for global observability at an initial state of\nhypergraphs. An example is given to illustrate the proposed criteria for\nobservability. Further, necessary and sufficient conditions for local\nobservability are derived based on rank conditions of observability matrices,\nwhich provide a framework to study local observability for non-uniform\nhypergraphs. Finally, the similarity of observability for hypergraphs is\nproposed using similarity of tensors, which reveals the relation of\nobservability between two hypergraphs and helps to check the observability\nintuitively.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Chencheng Zhang",
            "Hao Yang",
            "Shaoxuan Cui",
            "Bin Jiang",
            "Ming Cao"
        ],
        "published": "2024-05-29T10:27:48Z"
    },
    {
        "title": "UniIF: Unified Molecule Inverse Folding",
        "link": "http://arxiv.org/abs/2405.18968v1",
        "abstract": "Molecule inverse folding has been a long-standing challenge in chemistry and\nbiology, with the potential to revolutionize drug discovery and material\nscience. Despite specified models have been proposed for different small- or\nmacro-molecules, few have attempted to unify the learning process, resulting in\nredundant efforts. Complementary to recent advancements in molecular structure\nprediction, such as RoseTTAFold All-Atom and AlphaFold3, we propose the unified\nmodel UniIF for the inverse folding of all molecules. We do such unification in\ntwo levels: 1) Data-Level: We propose a unified block graph data form for all\nmolecules, including the local frame building and geometric feature\ninitialization. 2) Model-Level: We introduce a geometric block attention\nnetwork, comprising a geometric interaction, interactive attention and virtual\nlong-term dependency modules, to capture the 3D interactions of all molecules.\nThrough comprehensive evaluations across various tasks such as protein design,\nRNA design, and material design, we demonstrate that our proposed method\nsurpasses state-of-the-art methods on all tasks. UniIF offers a versatile and\neffective solution for general molecule inverse folding.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "q-bio.QM"
        ],
        "authors": [
            "Zhangyang Gao",
            "Jue Wang",
            "Cheng Tan",
            "Lirong Wu",
            "Yufei Huang",
            "Siyuan Li",
            "Zhirui Ye",
            "Stan Z. Li"
        ],
        "published": "2024-05-29T10:26:16Z"
    },
    {
        "title": "svds-C: A Multi-Thread C Code for Computing Truncated Singular Value\n  Decomposition",
        "link": "http://arxiv.org/abs/2405.18966v1",
        "abstract": "This article presents svds-C, an open-source and high-performance C program\nfor accurately and robustly computing truncated SVD, e.g. computing several\nlargest singular values and corresponding singular vectors. We have\nre-implemented the algorithm of svds in Matlab in C based on MKL or OpenBLAS\nand multi-thread computing to obtain the parallel program named svds-C. svds-C\nrunning on shared-memory computer consumes less time and memory than svds\nthanks to careful implementation of multi-thread parallelization and memory\nmanagement. Numerical experiments on different test cases which are\nsynthetically generated or directly from real world datasets show that, svds-C\nruns remarkably faster than svds with averagely 4.7X and at most 12X speedup\nfor 16-thread parallel computing on a computer with Intel CPU, while preserving\nsame accuracy and consuming about half memory space. Experimental results also\ndemonstrate that svds-C has similar advantages over svds on the computer with\nAMD CPU, and outperforms other state-of-the-art algorithms for truncated SVD on\ncomputing time and robustness.",
        "subjects": [
            "cs.MS"
        ],
        "authors": [
            "Xu Feng",
            "Wenjian Yu",
            "Yuyang Xie"
        ],
        "published": "2024-05-29T10:24:56Z"
    },
    {
        "title": "Exploring Probabilistic Distance Fields in Robotics",
        "link": "http://arxiv.org/abs/2405.18965v1",
        "abstract": "The success of intelligent robotic missions relies on integrating various\nresearch tasks, each demanding distinct representations. Designing\ntask-specific representations for each task is costly and impractical. Unified\nrepresentations suitable for multiple tasks remain unexplored. My outline\nintroduces a series of research outcomes of GP-based probabilistic distance\nfield (GPDF) representation that mathematically models the fundamental property\nof Euclidean distance field (EDF) along with gradients, surface normals and\ndense reconstruction. The progress to date and ongoing future works show that\nGPDF has the potential to offer a unified solution of representation for\nmultiple tasks such as localisation, mapping, motion planning, obstacle\navoidance, grasping, human-robot collaboration, and dense visualisation. I\nbelieve that GPDF serves as the cornerstone for robots to accomplish more\ncomplex and challenging tasks. By leveraging GPDF, robots can navigate through\nintricate environments, understand spatial relationships, and interact with\nobjects and humans seamlessly.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Lan Wu"
        ],
        "published": "2024-05-29T10:24:40Z"
    },
    {
        "title": "Diagonalization-Based Parallel-in-Time Preconditioners for Instationary\n  Fluid Flow Control Problems",
        "link": "http://arxiv.org/abs/2405.18964v1",
        "abstract": "We derive a new parallel-in-time approach for solving large-scale\noptimization problems constrained by time-dependent partial differential\nequations arising from fluid dynamics. The solver involves the use of a block\ncirculant approximation of the original matrices, enabling\nparallelization-in-time via the use of fast Fourier transforms, and we devise\nbespoke matrix approximations which may be applied within this framework. These\nmake use of permutations, saddle-point approximations, commutator arguments, as\nwell as inner solvers such as the Uzawa method, Chebyshev semi-iteration, and\nmultigrid. Theoretical results underpin our strategy of applying a block\ncirculant strategy, and numerical experiments demonstrate the effectiveness and\nrobustness of our approach on Stokes and Oseen problems. Noteably, satisfying\nresults for the strong and weak scaling of our methods are provided within a\nfully parallel architecture.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Bernhard Heinzelreiter",
            "John W. Pearson"
        ],
        "published": "2024-05-29T10:24:24Z"
    },
    {
        "title": "Beyond the fundamental lemma: from finite time series to linear system",
        "link": "http://arxiv.org/abs/2405.18962v1",
        "abstract": "We state necessary and sufficient conditions to uniquely identify (modulo\nstate isomorphism) a linear time-invariant minimal input-state-output system\nfrom finite input-output data and upper- and lower bounds on lag and state\nspace dimension.",
        "subjects": [
            "math.OC",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Kanat Camlibel",
            "Paolo Rapisarda"
        ],
        "published": "2024-05-29T10:23:52Z"
    },
    {
        "title": "Transcending Fusion: A Multi-Scale Alignment Method for Remote Sensing\n  Image-Text Retrieval",
        "link": "http://arxiv.org/abs/2405.18959v1",
        "abstract": "Remote Sensing Image-Text Retrieval (RSITR) is pivotal for knowledge services\nand data mining in the remote sensing (RS) domain. Considering the multi-scale\nrepresentations in image content and text vocabulary can enable the models to\nlearn richer representations and enhance retrieval. Current multi-scale RSITR\napproaches typically align multi-scale fused image features with text features,\nbut overlook aligning image-text pairs at distinct scales separately. This\noversight restricts their ability to learn joint representations suitable for\neffective retrieval. We introduce a novel Multi-Scale Alignment (MSA) method to\novercome this limitation. Our method comprises three key innovations: (1)\nMulti-scale Cross-Modal Alignment Transformer (MSCMAT), which computes\ncross-attention between single-scale image features and localized text\nfeatures, integrating global textual context to derive a matching score matrix\nwithin a mini-batch, (2) a multi-scale cross-modal semantic alignment loss that\nenforces semantic alignment across scales, and (3) a cross-scale multi-modal\nsemantic consistency loss that uses the matching matrix from the largest scale\nto guide alignment at smaller scales. We evaluated our method across multiple\ndatasets, demonstrating its efficacy with various visual backbones and\nestablishing its superiority over existing state-of-the-art methods. The GitHub\nURL for our project is: https://github.com/yr666666/MSA",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "authors": [
            "Rui Yang",
            "Shuang Wang",
            "Yingping Han",
            "Yuanheng Li",
            "Dong Zhao",
            "Dou Quan",
            "Yanhe Guo",
            "Licheng Jiao"
        ],
        "published": "2024-05-29T10:19:11Z"
    },
    {
        "title": "Pessimism of the Will, Optimism of the Intellect: Fair Protocols with\n  Malicious but Rational Agents",
        "link": "http://arxiv.org/abs/2405.18958v1",
        "abstract": "Fairness is a desirable and crucial property of many protocols that handle,\nfor instance, exchanges of message.\n  It states that if at least one agent engaging in the protocol is honest, then\neither the protocol will unfold correctly and fulfill its intended goal for all\nparticipants, or it will fail for everyone.\n  In this work, we present a game-based framework for the study of fairness\nprotocols, that does not define a priori an attacker model.\n  It is based on the notion of strong secure equilibria, and leverages the\nconceptual and algorithmic toolbox of game theory.\n  In the case of finite games, we provide decision procedures with tight\ncomplexity bounds for determining whether a protocol is immune to nefarious\nattacks from a coalition of participants, and whether such a protocol could\nexist based on the underlying graph structure and objectives.",
        "subjects": [
            "cs.GT",
            "cs.CC",
            "cs.CR"
        ],
        "authors": [
            "Lonard Brice",
            "Jean-Franois Raskin",
            "Mathieu Sassolas",
            "Guillaume Scerri",
            "Marie van den Bogaard"
        ],
        "published": "2024-05-29T10:15:36Z"
    },
    {
        "title": "RGB-T Object Detection via Group Shuffled Multi-receptive Attention and\n  Multi-modal Supervision",
        "link": "http://arxiv.org/abs/2405.18955v1",
        "abstract": "Multispectral object detection, utilizing both visible (RGB) and thermal\ninfrared (T) modals, has garnered significant attention for its robust\nperformance across diverse weather and lighting conditions. However,\neffectively exploiting the complementarity between RGB-T modals while\nmaintaining efficiency remains a critical challenge. In this paper, a very\nsimple Group Shuffled Multi-receptive Attention (GSMA) module is proposed to\nextract and combine multi-scale RGB and thermal features. Then, the extracted\nmulti-modal features are directly integrated with a multi-level path\naggregation neck, which significantly improves the fusion effect and\nefficiency. Meanwhile, multi-modal object detection often adopts union\nannotations for both modals. This kind of supervision is not sufficient and\nunfair, since objects observed in one modal may not be seen in the other modal.\nTo solve this issue, Multi-modal Supervision (MS) is proposed to sufficiently\nsupervise RGB-T object detection. Comprehensive experiments on two challenging\nbenchmarks, KAIST and DroneVehicle, demonstrate the proposed model achieves the\nstate-of-the-art accuracy while maintaining competitive efficiency.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jinzhong Wang",
            "Xuetao Tian",
            "Shun Dai",
            "Tao Zhuo",
            "Haorui Zeng",
            "Hongjuan Liu",
            "Jiaqi Liu",
            "Xiuwei Zhang",
            "Yanning Zhang"
        ],
        "published": "2024-05-29T10:11:36Z"
    },
    {
        "title": "MAGIC: Modular Auto-encoder for Generalisable Model Inversion with Bias\n  Corrections",
        "link": "http://arxiv.org/abs/2405.18953v1",
        "abstract": "Scientists often model physical processes to understand the natural world and\nuncover the causation behind observations. Due to unavoidable simplification,\ndiscrepancies often arise between model predictions and actual observations, in\nthe form of systematic biases, whose impact varies with model completeness.\nClassical model inversion methods such as Bayesian inference or regressive\nneural networks tend either to overlook biases or make assumptions about their\nnature during data preprocessing, potentially leading to implausible results.\nInspired by recent work in inverse graphics, we replace the decoder stage of a\nstandard autoencoder with a physical model followed by a bias-correction layer.\nThis generalisable approach simultaneously inverts the model and corrects its\nbiases in an end-to-end manner without making strong assumptions about the\nnature of the biases. We demonstrate the effectiveness of our approach using\ntwo physical models from disparate domains: a complex radiative transfer model\nfrom remote sensing; and a volcanic deformation model from geodesy. Our method\nmatches or surpasses results from classical approaches without requiring biases\nto be explicitly filtered out, suggesting an effective pathway for\nunderstanding the causation of various physical processes.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yihang She",
            "Clement Atzberger",
            "Andrew Blake",
            "Adriano Gualandi",
            "Srinivasan Keshav"
        ],
        "published": "2024-05-29T10:11:10Z"
    },
    {
        "title": "Are You Sure? Rank Them Again: Repeated Ranking For Better Preference\n  Datasets",
        "link": "http://arxiv.org/abs/2405.18952v1",
        "abstract": "Training Large Language Models (LLMs) with Reinforcement Learning from AI\nFeedback (RLAIF) aligns model outputs more closely with human preferences. This\ninvolves an evaluator model ranking multiple candidate responses to user\nprompts. However, the rankings from popular evaluator models such as GPT-4 can\nbe inconsistent. We propose the Repeat Ranking method - where we evaluate the\nsame responses multiple times and train only on those responses which are\nconsistently ranked. Using 2,714 prompts in 62 languages, we generated\nresponses from 7 top multilingual LLMs and had GPT-4 rank them five times each.\nEvaluating on MT-Bench chat benchmarks in six languages, our method\noutperformed the standard practice of training on all available prompts. Our\nwork highlights the quality versus quantity trade-off in RLAIF dataset\ngeneration and offers a stackable strategy for enhancing dataset and thus model\nquality.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Peter Devine"
        ],
        "published": "2024-05-29T10:08:31Z"
    },
    {
        "title": "Encouraging Bystander Assistance for Urban Robots: Introducing Playful\n  Robot Help-Seeking as a Strategy",
        "link": "http://dx.doi.org/10.1145/3643834.3661505",
        "abstract": "Robots in urban environments will inevitably encounter situations beyond\ntheir capabilities (e.g., delivery robots unable to press traffic light\nbuttons), necessitating bystander assistance. These spontaneous collaborations\npossess challenges distinct from traditional human-robot collaboration,\nrequiring design investigation and tailored interaction strategies. This study\ninvestigates playful help-seeking as a strategy to encourage such bystander\nassistance. We compared our designed playful help-seeking concepts against two\nexisting robot help-seeking strategies: verbal speech and emotional expression.\nTo assess these strategies and their impact on bystanders' experience and\nattitudes towards urban robots, we conducted a virtual reality evaluation study\nwith 24 participants. Playful help-seeking enhanced people's willingness to\nhelp robots, a tendency more pronounced in scenarios requiring greater physical\neffort. Verbal help-seeking was perceived less polite, raising stronger\ndiscomfort assessments. Emotional expression help-seeking elicited empathy\nwhile leading to lower cognitive trust. The triangulation of quantitative and\nqualitative results highlights considerations for robot help-seeking from\nbystanders.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Xinyan Yu",
            "Marius Hoggenmueller",
            "Martin Tomitsch"
        ],
        "published": "2024-05-29T10:06:34Z"
    },
    {
        "title": "Learning to Recover from Plan Execution Errors during Robot\n  Manipulation: A Neuro-symbolic Approach",
        "link": "http://arxiv.org/abs/2405.18948v1",
        "abstract": "Automatically detecting and recovering from failures is an important but\nchallenging problem for autonomous robots. Most of the recent work on learning\nto plan from demonstrations lacks the ability to detect and recover from errors\nin the absence of an explicit state representation and/or a (sub-) goal check\nfunction. We propose an approach (blending learning with symbolic search) for\nautomated error discovery and recovery, without needing annotated data of\nfailures. Central to our approach is a neuro-symbolic state representation, in\nthe form of dense scene graph, structured based on the objects present within\nthe environment. This enables efficient learning of the transition function and\na discriminator that not only identifies failures but also localizes them\nfacilitating fast re-planning via computation of heuristic distance function.\nWe also present an anytime version of our algorithm, where instead of\nrecovering to the last correct state, we search for a sub-goal in the original\nplan minimizing the total distance to the goal given a re-planning budget.\nExperiments on a physics simulator with a variety of simulated failures show\nthe effectiveness of our approach compared to existing baselines, both in terms\nof efficiency as well as accuracy of our recovery mechanism.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "authors": [
            "Namasivayam Kalithasan",
            "Arnav Tuli",
            "Vishal Bindal",
            "Himanshu Gaurav Singh",
            "Parag Singla",
            "Rohan Paul"
        ],
        "published": "2024-05-29T10:03:57Z"
    },
    {
        "title": "WTTFNet: A Weather-Time-Trajectory Fusion Network for Pedestrian\n  Trajectory Prediction in Urban Complex",
        "link": "http://arxiv.org/abs/2405.18945v1",
        "abstract": "Pedestrian trajectory modelling in an urban complex is challenging because\npedestrians can have many possible destinations, such as shops, escalators, and\nattractions. Moreover, weather and time-of-day may affect pedestrian behavior.\nIn this paper, a new weather-time-trajectory fusion network (WTTFNet) is\nproposed to improve the performance of baseline deep neural network\narchitecture. By incorporating weather and time-of-day information as an\nembedding structure, a novel WTTFNet based on gate multimodal unit is used to\nfuse the multimodal information and deep representation of trajectories. A\njoint loss function based on focal loss is used to co-optimize both the deep\ntrajectory features and final classifier, which helps to improve the accuracy\nin predicting the intended destination of pedestrians and hence the\ntrajectories under possible scenarios of class imbalances. Experimental results\nusing the Osaka Asia and Pacific Trade Center (ATC) dataset shows improved\nperformance of the proposed approach over state-of-the-art algorithms by 23.67%\nincrease in classification accuracy, 9.16% and 7.07% reduction of average and\nfinal displacement error. The proposed approach may serve as an attractive\napproach for improving existing baseline trajectory prediction models when they\nare applied to scenarios with influences of weather-time conditions. It can be\nemployed in numerous applications such as pedestrian facility engineering,\npublic space development and technology-driven retail.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Ho Chun Wu",
            "Esther Hoi Shan Lau",
            "Paul Yuen",
            "Kevin Hung",
            "John Kwok Tai Chui",
            "Andrew Kwok Fai Lui"
        ],
        "published": "2024-05-29T09:56:54Z"
    },
    {
        "title": "Predicting Many Properties of Crystals by a Single Deep Learning Model",
        "link": "http://arxiv.org/abs/2405.18944v1",
        "abstract": "The use of machine learning methods for predicting the properties of\ncrystalline materials encounters significant challenges, primarily related to\ninput encoding, output versatility, and interpretability. Here, we introduce\nCrystalBERT, an adaptable transformer-based framework with novel structure that\nintegrates space group, elemental, and unit cell information. The method's\nadaptability lies not only in its ability to seamlessly combine diverse\nfeatures but also in its capability to accurately predict a wide range of\nphysically important properties, including topological properties,\nsuperconducting transition temperatures, dielectric constants, and more.\nCrystalBERT also provides insightful physical interpretations regarding the\nfeatures that most significantly influence the target properties. Our findings\nindicate that space group and elemental information are more important for\npredicting topological and superconducting properties, in contrast to some\nproperties that primarily depend on the unit cell information. This underscores\nthe intricate nature of topological and superconducting properties. By\nincorporating all these features, we achieve a high accuracy of 91% in\ntopological classification, surpassing prior studies and identifying previously\nmisclassified topological materials, further demonstrating the effectiveness of\nour model.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cond-mat.mes-hall",
            "cs.LG"
        ],
        "authors": [
            "Haosheng Xu",
            "Dongheng Qian",
            "Jing Wang"
        ],
        "published": "2024-05-29T09:56:00Z"
    },
    {
        "title": "Verifiably Robust Conformal Prediction",
        "link": "http://arxiv.org/abs/2405.18942v1",
        "abstract": "Conformal Prediction (CP) is a popular uncertainty quantification method that\nprovides distribution-free, statistically valid prediction sets, assuming that\ntraining and test data are exchangeable. In such a case, CP's prediction sets\nare guaranteed to cover the (unknown) true test output with a user-specified\nprobability. Nevertheless, this guarantee is violated when the data is\nsubjected to adversarial attacks, which often result in a significant loss of\ncoverage. Recently, several approaches have been put forward to recover CP\nguarantees in this setting. These approaches leverage variations of randomised\nsmoothing to produce conservative sets which account for the effect of the\nadversarial perturbations. They are, however, limited in that they only support\n$\\ell^2$-bounded perturbations and classification tasks. This paper introduces\n\\emph{VRCP (Verifiably Robust Conformal Prediction)}, a new framework that\nleverages recent neural network verification methods to recover coverage\nguarantees under adversarial attacks. Our VRCP method is the first to support\nperturbations bounded by arbitrary norms including $\\ell^1$, $\\ell^2$, and\n$\\ell^\\infty$, as well as regression tasks. We evaluate and compare our\napproach on image classification tasks (CIFAR10, CIFAR100, and TinyImageNet)\nand regression tasks for deep reinforcement learning environments. In every\ncase, VRCP achieves above nominal coverage and yields significantly more\nefficient and informative prediction regions than the SotA.",
        "subjects": [
            "cs.LO",
            "cs.AI",
            "cs.LG",
            "68T37 (Primary) 68T27 (Secondary)",
            "G.3; I.2.4; F.4.1"
        ],
        "authors": [
            "Linus Jeary",
            "Tom Kuipers",
            "Mehran Hosseini",
            "Nicola Paoletti"
        ],
        "published": "2024-05-29T09:50:43Z"
    },
    {
        "title": "Content-Agnostic Moderation for Stance-Neutral Recommendation",
        "link": "http://arxiv.org/abs/2405.18941v1",
        "abstract": "Personalized recommendation systems often drive users towards more extreme\ncontent, exacerbating opinion polarization. While (content-aware) moderation\nhas been proposed to mitigate these effects, such approaches risk curtailing\nthe freedom of speech and of information. To address this concern, we propose\nand explore the feasibility of \\emph{content-agnostic} moderation as an\nalternative approach for reducing polarization. Content-agnostic moderation\ndoes not rely on the actual content being moderated, arguably making it less\nprone to forms of censorship. We establish theoretically that content-agnostic\nmoderation cannot be guaranteed to work in a fully generic setting. However, we\nshow that it can often be effectively achieved in practice with plausible\nassumptions. We introduce two novel content-agnostic moderation methods that\nmodify the recommendations from the content recommender to disperse user-item\nco-clusters without relying on content features.\n  To evaluate the potential of content-agnostic moderation in controlled\nexperiments, we built a simulation environment to analyze the closed-loop\nbehavior of a system with a given set of users, recommendation system, and\nmoderation approach. Through comprehensive experiments in this environment, we\nshow that our proposed moderation methods significantly enhance stance\nneutrality and maintain high recommendation quality across various data\nscenarios. Our results indicate that achieving stance neutrality without direct\ncontent information is not only feasible but can also help in developing more\nbalanced and informative recommendation systems without substantially degrading\nuser engagement.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "authors": [
            "Nan Li",
            "Bo Kang",
            "Tijl De Bie"
        ],
        "published": "2024-05-29T09:50:39Z"
    },
    {
        "title": "HLOB -- Information Persistence and Structure in Limit Order Books",
        "link": "http://arxiv.org/abs/2405.18938v2",
        "abstract": "We introduce a novel large-scale deep learning model for Limit Order Book\nmid-price changes forecasting, and we name it `HLOB'. This architecture (i)\nexploits the information encoded by an Information Filtering Network, namely\nthe Triangulated Maximally Filtered Graph, to unveil deeper and non-trivial\ndependency structures among volume levels; and (ii) guarantees deterministic\ndesign choices to handle the complexity of the underlying system by drawing\ninspiration from the groundbreaking class of Homological Convolutional Neural\nNetworks. We test our model against 9 state-of-the-art deep learning\nalternatives on 3 real-world Limit Order Book datasets, each including 15\nstocks traded on the NASDAQ exchange, and we systematically characterize the\nscenarios where HLOB outperforms state-of-the-art architectures. Our approach\nsheds new light on the spatial distribution of information in Limit Order Books\nand on its degradation over increasing prediction horizons, narrowing the gap\nbetween microstructural modeling and deep learning-based forecasting in\nhigh-frequency financial markets.",
        "subjects": [
            "q-fin.TR",
            "cs.LG"
        ],
        "authors": [
            "Antonio Briola",
            "Silvia Bartolucci",
            "Tomaso Aste"
        ],
        "published": "2024-05-29T09:46:44Z"
    },
    {
        "title": "Kestrel: Point Grounding Multimodal LLM for Part-Aware 3D\n  Vision-Language Understanding",
        "link": "http://arxiv.org/abs/2405.18937v1",
        "abstract": "While 3D MLLMs have achieved significant progress, they are restricted to\nobject and scene understanding and struggle to understand 3D spatial structures\nat the part level. In this paper, we introduce Kestrel, representing a novel\napproach that empowers 3D MLLMs with part-aware understanding, enabling better\ninterpretation and segmentation grounding of 3D objects at the part level.\nDespite its significance, the current landscape lacks tasks and datasets that\nendow and assess this capability. Therefore, we propose two novel tasks: (1)\nPart-Aware Point Grounding, the model is tasked with directly predicting a\npart-level segmentation mask based on user instructions, and (2) Part-Aware\nPoint Grounded Captioning, the model provides a detailed caption that includes\npart-level descriptions and their corresponding masks. To support learning and\nevaluating for these tasks, we introduce 3DCoMPaT Grounded Instructions Dataset\n(3DCoMPaT-GRIN). 3DCoMPaT-GRIN Vanilla, comprising 789k part-aware point\ncloud-instruction-segmentation mask triplets, is used to evaluate MLLMs'\nability of part-aware segmentation grounding. 3DCoMPaT-GRIN Grounded Caption,\ncontaining 107k part-aware point cloud-instruction-grounded caption triplets,\nassesses both MLLMs' part-aware language comprehension and segmentation\ngrounding capabilities. Our introduced tasks, dataset, and Kestrel represent a\npreliminary effort to bridge the gap between human cognition and 3D MLLMs,\ni.e., the ability to perceive and engage with the environment at both global\nand part levels. Extensive experiments on the 3DCoMPaT-GRIN show that Kestrel\ncan generate user-specified segmentation masks, a capability not present in any\nexisting 3D MLLM. Kestrel thus established a benchmark for evaluating the\npart-aware language comprehension and segmentation grounding of 3D objects.\nProject page at https://feielysia.github.io/Kestrel.github.io/",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "authors": [
            "Junjie Fei",
            "Mahmoud Ahmed",
            "Jian Ding",
            "Eslam Mohamed Bakr",
            "Mohamed Elhoseiny"
        ],
        "published": "2024-05-29T09:43:48Z"
    },
    {
        "title": "LSPI: Heterogeneous Graph Neural Network Classification Aggregation\n  Algorithm Based on Size Neighbor Path Identification",
        "link": "http://arxiv.org/abs/2405.18933v1",
        "abstract": "Existing heterogeneous graph neural network algorithms (HGNNs) mostly rely on\nmeta-paths to capture the rich semantic information contained in heterogeneous\ngraphs (also known as heterogeneous information networks (HINs)), but most of\nthese HGNNs focus on different ways of feature aggre gation and ignore the\nproperties of the meta-paths themselves. This paper studies meta-paths in three\ncommonly used data sets and finds that there are huge differences in the number\nof neighbors connected by different meta paths. At the same time, the noise\ninformation contained in large neigh bor paths will have an adverse impact on\nmodel performance. Therefore, this paper proposes a Heterogeneous Graph Neural\nNetwork Classification and Aggregation Algorithm Based on Large and Small\nNeighbor Path Iden tification(LSPI). LSPI firstly divides the meta-paths into\nlarge and small neighbor paths through the path discriminator , and in order to\nreduce the noise interference problem in large neighbor paths, LSPI selects\nneighbor nodes with higher similarity from both topology and feature\nperspectives, and passes small neighbor paths and filtered large neighbor paths\nthrough different graph convolution components. Aggregation is performed to\nobtain feature information under different subgraphs, and then LSPI uses\nsubgraph level attention to fuse the feature information under different\nsubgraphs to generate the final node embedding. Finally this paper verifies the\nsuperiority of the method through extensive experiments and also gives\nsuggestions on the number of nodes to be retained in large neighbor paths\nthrough exper iments. The complete reproducible code adn data has been\npublished at: https://github.com/liuhua811/LSPIA.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yufei Zhaoa",
            "Shiduo Wanga",
            "Hua Duana"
        ],
        "published": "2024-05-29T09:37:23Z"
    },
    {
        "title": "A Mallows-like Criterion for Anomaly Detection with Random Forest\n  Implementation",
        "link": "http://arxiv.org/abs/2405.18932v1",
        "abstract": "The effectiveness of anomaly signal detection can be significantly undermined\nby the inherent uncertainty of relying on one specified model. Under the\nframework of model average methods, this paper proposes a novel criterion to\nselect the weights on aggregation of multiple models, wherein the focal loss\nfunction accounts for the classification of extremely imbalanced data. This\nstrategy is further integrated into Random Forest algorithm by replacing the\nconventional voting method. We have evaluated the proposed method on benchmark\ndatasets across various domains, including network intrusion. The findings\nindicate that our proposed method not only surpasses the model averaging with\ntypical loss functions but also outstrips common anomaly detection algorithms\nin terms of accuracy and robustness.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Gaoxiang Zhao",
            "Lu Wang",
            "Xiaoqiang Wang"
        ],
        "published": "2024-05-29T09:36:57Z"
    },
    {
        "title": "EntProp: High Entropy Propagation for Improving Accuracy and Robustness",
        "link": "http://arxiv.org/abs/2405.18931v1",
        "abstract": "Deep neural networks (DNNs) struggle to generalize to out-of-distribution\ndomains that are different from those in training despite their impressive\nperformance. In practical applications, it is important for DNNs to have both\nhigh standard accuracy and robustness against out-of-distribution domains. One\ntechnique that achieves both of these improvements is disentangled learning\nwith mixture distribution via auxiliary batch normalization layers (ABNs). This\ntechnique treats clean and transformed samples as different domains, allowing a\nDNN to learn better features from mixed domains. However, if we distinguish the\ndomains of the samples based on entropy, we find that some transformed samples\nare drawn from the same domain as clean samples, and these samples are not\ncompletely different domains. To generate samples drawn from a completely\ndifferent domain than clean samples, we hypothesize that transforming clean\nhigh-entropy samples to further increase the entropy generates\nout-of-distribution samples that are much further away from the in-distribution\ndomain. On the basis of the hypothesis, we propose high entropy\npropagation~(EntProp), which feeds high-entropy samples to the network that\nuses ABNs. We introduce two techniques, data augmentation and free adversarial\ntraining, that increase entropy and bring the sample further away from the\nin-distribution domain. These techniques do not require additional training\ncosts. Our experimental results show that EntProp achieves higher standard\naccuracy and robustness with a lower training cost than the baseline methods.\nIn particular, EntProp is highly effective at training on small datasets.",
        "subjects": [
            "stat.ML",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Shohei Enomoto"
        ],
        "published": "2024-05-29T09:36:20Z"
    },
    {
        "title": "Deep Positive-Unlabeled Anomaly Detection for Contaminated Unlabeled\n  Data",
        "link": "http://arxiv.org/abs/2405.18929v1",
        "abstract": "Semi-supervised anomaly detection, which aims to improve the performance of\nthe anomaly detector by using a small amount of anomaly data in addition to\nunlabeled data, has attracted attention. Existing semi-supervised approaches\nassume that unlabeled data are mostly normal. They train the anomaly detector\nto minimize the anomaly scores for the unlabeled data, and to maximize those\nfor the anomaly data. However, in practice, the unlabeled data are often\ncontaminated with anomalies. This weakens the effect of maximizing the anomaly\nscores for anomalies, and prevents us from improving the detection performance.\nTo solve this problem, we propose the positive-unlabeled autoencoder, which is\nbased on positive-unlabeled learning and the anomaly detector such as the\nautoencoder. With our approach, we can approximate the anomaly scores for\nnormal data using the unlabeled and anomaly data. Therefore, without the\nlabeled normal data, we can train the anomaly detector to minimize the anomaly\nscores for normal data, and to maximize those for the anomaly data. In\naddition, our approach is applicable to various anomaly detectors such as the\nDeepSVDD. Experiments on various datasets show that our approach achieves\nbetter detection performance than existing approaches.",
        "subjects": [
            "stat.ML",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Hiroshi Takahashi",
            "Tomoharu Iwata",
            "Atsutoshi Kumagai",
            "Yuuki Yamanaka"
        ],
        "published": "2024-05-29T09:34:47Z"
    },
    {
        "title": "Federated Continual Learning Goes Online: Leveraging Uncertainty for\n  Modality-Agnostic Class-Incremental Learning",
        "link": "http://arxiv.org/abs/2405.18925v1",
        "abstract": "Given the ability to model more realistic and dynamic problems, Federated\nContinual Learning (FCL) has been increasingly investigated recently. A\nwell-known problem encountered in this setting is the so-called catastrophic\nforgetting, for which the learning model is inclined to focus on more recent\ntasks while forgetting the previously learned knowledge. The majority of the\ncurrent approaches in FCL propose generative-based solutions to solve said\nproblem. However, this setting requires multiple training epochs over the data,\nimplying an offline setting where datasets are stored locally and remain\nunchanged over time. Furthermore, the proposed solutions are tailored for\nvision tasks solely. To overcome these limitations, we propose a new\nmodality-agnostic approach to deal with the online scenario where new data\narrive in streams of mini-batches that can only be processed once. To solve\ncatastrophic forgetting, we propose an uncertainty-aware memory-based approach.\nIn particular, we suggest using an estimator based on the Bregman Information\n(BI) to compute the model's variance at the sample level. Through measures of\npredictive uncertainty, we retrieve samples with specific characteristics, and\n- by retraining the model on such samples - we demonstrate the potential of\nthis approach to reduce the forgetting effect in realistic settings.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Giuseppe Serra",
            "Florian Buettner"
        ],
        "published": "2024-05-29T09:29:39Z"
    },
    {
        "title": "MDIW-13: a New Multi-Lingual and Multi-Script Database and Benchmark for\n  Script Identification",
        "link": "http://dx.doi.org/10.1007/s12559-023-10193-w",
        "abstract": "Script identification plays a vital role in applications that involve\nhandwriting and document analysis within a multi-script and multi-lingual\nenvironment. Moreover, it exhibits a profound connection with human cognition.\nThis paper provides a new database for benchmarking script identification\nalgorithms, which contains both printed and handwritten documents collected\nfrom a wide variety of scripts, such as Arabic, Bengali (Bangla), Gujarati,\nGurmukhi, Devanagari, Japanese, Kannada, Malayalam, Oriya, Roman, Tamil,\nTelugu, and Thai. The dataset consists of 1,135 documents scanned from local\nnewspaper and handwritten letters as well as notes from different native\nwriters. Further, these documents are segmented into lines and words,\ncomprising a total of 13,979 and 86,655 lines and words, respectively, in the\ndataset. Easy-to-go benchmarks are proposed with handcrafted and deep learning\nmethods. The benchmark includes results at the document, line, and word levels\nwith printed and handwritten documents. Results of script identification\nindependent of the document/line/word level and independent of the\nprinted/handwritten letters are also given. The new multi-lingual database is\nexpected to create new script identifiers, present various challenges,\nincluding identifying handwritten and printed samples and serve as a foundation\nfor future research in script identification based on the reported results of\nthe three benchmarks.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Miguel A. Ferrer",
            "Abhijit Das",
            "Moises Diaz",
            "Aythami Morales",
            "Cristina Carmona-Duarte",
            "Umapada Pal"
        ],
        "published": "2024-05-29T09:29:09Z"
    },
    {
        "title": "Understanding and Addressing the Under-Translation Problem from the\n  Perspective of Decoding Objective",
        "link": "http://arxiv.org/abs/2405.18922v1",
        "abstract": "Neural Machine Translation (NMT) has made remarkable progress over the past\nyears. However, under-translation and over-translation remain two challenging\nproblems in state-of-the-art NMT systems. In this work, we conduct an in-depth\nanalysis on the underlying cause of under-translation in NMT, providing an\nexplanation from the perspective of decoding objective. To optimize the beam\nsearch objective, the model tends to overlook words it is less confident about,\nleading to the under-translation phenomenon. Correspondingly, the model's\nconfidence in predicting the End Of Sentence (EOS) diminishes when\nunder-translation occurs, serving as a mild penalty for under-translated\ncandidates. Building upon this analysis, we propose employing the confidence of\npredicting EOS as a detector for under-translation, and strengthening the\nconfidence-based penalty to penalize candidates with a high risk of\nunder-translation. Experiments on both synthetic and real-world data show that\nour method can accurately detect and rectify under-translated outputs, with\nminor impact on other correct translations.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Chenze Shao",
            "Fandong Meng",
            "Jiali Zeng",
            "Jie Zhou"
        ],
        "published": "2024-05-29T09:25:49Z"
    },
    {
        "title": "GLANCE: Global Actions in a Nutshell for Counterfactual Explainability",
        "link": "http://arxiv.org/abs/2405.18921v1",
        "abstract": "Counterfactual explanations have emerged as an important tool to understand,\ndebug, and audit complex machine learning models. To offer global\ncounterfactual explainability, state-of-the-art methods construct summaries of\nlocal explanations, offering a trade-off among conciseness, counterfactual\neffectiveness, and counterfactual cost or burden imposed on instances. In this\nwork, we provide a concise formulation of the problem of identifying global\ncounterfactuals and establish principled criteria for comparing solutions,\ndrawing inspiration from Pareto dominance. We introduce innovative algorithms\ndesigned to address the challenge of finding global counterfactuals for either\nthe entire input space or specific partitions, employing clustering and\ndecision trees as key components. Additionally, we conduct a comprehensive\nexperimental evaluation, considering various instances of the problem and\ncomparing our proposed algorithms with state-of-the-art methods. The results\nhighlight the consistent capability of our algorithms to generate meaningful\nand interpretable global counterfactual explanations.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ioannis Emiris",
            "Dimitris Fotakis",
            "Giorgos Giannopoulos",
            "Dimitrios Gunopulos",
            "Loukas Kavouras",
            "Kleopatra Markou",
            "Eleni Psaroudaki",
            "Dimitrios Rontogiannis",
            "Dimitris Sacharidis",
            "Nikolaos Theologitis",
            "Dimitrios Tomaras",
            "Konstantinos Tsopelas"
        ],
        "published": "2024-05-29T09:24:25Z"
    },
    {
        "title": "Achievable Rate Optimization for Large Stacked Intelligent Metasurfaces\n  Based on Statistical CSI",
        "link": "http://arxiv.org/abs/2405.18920v1",
        "abstract": "Stacked intelligent metasurface (SIM) is an emerging design that consists of\nmultiple layers of metasurfaces. A SIM enables holographic multiple-input\nmultiple-output (HMIMO) precoding in the wave domain, which results in the\nreduction of energy consumption and hardware cost. On the ground of multiuser\nbeamforming, this letter focuses on the downlink achievable rate and its\nmaximization. Contrary to previous works on multiuser SIM, we consider\nstatistical channel state information (CSI) as opposed to instantaneous CSI to\novercome challenges such as large overhead. Also, we examine the performance of\nlarge surfaces. We apply an alternating optimization (AO) algorithm regarding\nthe phases of the SIM and the allocated transmit power. Simulations illustrate\nthe performance of the considered large SIM-assisted design as well as the\ncomparison between different CSI considerations.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Anastasios Papazafeiropoulos",
            "Pandelis Kourtessis",
            "Symeon Chatzinotas",
            "Dimitra I. Kaklamani",
            "Iakovos S. Venieris"
        ],
        "published": "2024-05-29T09:24:19Z"
    },
    {
        "title": "Exploiting Inter-Satellite Links for In-Flight Connectivity Scheme in\n  Space-Air-Ground Integrated Networks",
        "link": "http://arxiv.org/abs/2405.18919v1",
        "abstract": "Space-air-ground integrated networks (SAGIN) are pivotal for achieving\nuninterrupted in-flight connectivity (IFC). Most existing studies, however,\nmerely treat satellites as transparent forwarding nodes, and overlook their\ncaching capabilities in enhancing the IFC data rate. In this paper, we consider\nan IFC-oriented SAGIN, where the satellites collaboratively deliver the content\nto airborne passengers to facilitate airborne communication. Considering the\ncached files instantaneously accessible via satellites, this work pioneers the\nintegration of multiple inter-satellite links (ISLs) into the IFC framework,\nthereby innovating the content delivery process. To minimize the average delay\nof content delivery, we formulate an optimization problem and propose an exact\npenalty-based method to derive the satellite association scheme. Our proposed\nframework has a low complexity and thus paves the way for high-speed Internet\nconnectivity to aviation passengers. Finally, simulation results are presented\nto demonstrate the effectiveness of our proposed IFC framework for SAGIN.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Qian Chen",
            "Chenyu Wu",
            "Shuai Han",
            "Weixiao Meng",
            "Tony Q. S. Quek"
        ],
        "published": "2024-05-29T09:22:25Z"
    },
    {
        "title": "Computing low-thrust transfers in the asteroid belt, a comparison\n  between astrodynamical manipulations and a machine learning approach",
        "link": "http://arxiv.org/abs/2405.18918v1",
        "abstract": "Low-thrust trajectories play a crucial role in optimizing scientific output\nand cost efficiency in asteroid belt missions. Unlike high-thrust transfers,\nlow-thrust trajectories require solving complex optimal control problems. This\ncomplexity grows exponentially with the number of asteroids visited due to\norbital mechanics intricacies. In the literature, methods for approximating\nlow-thrust transfers without full optimization have been proposed, including\nanalytical and machine learning techniques. In this work, we propose new\nanalytical approximations and compare their accuracy and performance to machine\nlearning methods. While analytical approximations leverage orbit theory to\nestimate trajectory costs, machine learning employs a more black-box approach,\nutilizing neural networks to predict optimal transfers based on various\nattributes. We build a dataset of about 3 million transfers, found by solving\nthe time and fuel optimal control problems, for different time of flights,\nwhich we also release open-source. Comparison between the two methods on this\ndatabase reveals the superiority of machine learning, especially for longer\ntransfers. Despite challenges such as multi revolution transfers, both\napproaches maintain accuracy within a few percent in the final mass errors, on\na database of trajectories involving numerous asteroids. This work contributes\nto the efficient exploration of mission opportunities in the asteroid belt,\nproviding insights into the strengths and limitations of different\napproximation strategies.",
        "subjects": [
            "astro-ph.EP",
            "astro-ph.IM",
            "cs.LG",
            "physics.space-ph"
        ],
        "authors": [
            "Giacomo Acciarini",
            "Laurent Beauregard",
            "Dario Izzo"
        ],
        "published": "2024-05-29T09:20:54Z"
    },
    {
        "title": "Causal Action Influence Aware Counterfactual Data Augmentation",
        "link": "http://arxiv.org/abs/2405.18917v1",
        "abstract": "Offline data are both valuable and practical resources for teaching robots\ncomplex behaviors. Ideally, learning agents should not be constrained by the\nscarcity of available demonstrations, but rather generalize beyond the training\ndistribution. However, the complexity of real-world scenarios typically\nrequires huge amounts of data to prevent neural network policies from picking\nup on spurious correlations and learning non-causal relationships. We propose\nCAIAC, a data augmentation method that can create feasible synthetic\ntransitions from a fixed dataset without having access to online environment\ninteractions. By utilizing principled methods for quantifying causal influence,\nwe are able to perform counterfactual reasoning by swapping\n$\\it{action}$-unaffected parts of the state-space between independent\ntrajectories in the dataset. We empirically show that this leads to a\nsubstantial increase in robustness of offline learning algorithms against\ndistributional shift.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.RO"
        ],
        "authors": [
            "Nria Armengol Urp",
            "Marco Bagatella",
            "Marin Vlastelica",
            "Georg Martius"
        ],
        "published": "2024-05-29T09:19:50Z"
    },
    {
        "title": "Towards Faithful Chain-of-Thought: Large Language Models are Bridging\n  Reasoners",
        "link": "http://arxiv.org/abs/2405.18915v1",
        "abstract": "Large language models (LLMs) suffer from serious unfaithful chain-of-thought\n(CoT) issues. Previous work attempts to measure and explain it but lacks\nin-depth analysis within CoTs and does not consider the interactions among all\nreasoning components jointly. In this paper, we first study the CoT\nfaithfulness issue at the granularity of CoT steps, identify two reasoning\nparadigms: centralized reasoning and distributed reasoning, and find their\nrelationship with faithfulness. Subsequently, we conduct a joint analysis of\nthe causal relevance among the context, CoT, and answer during reasoning. The\nresult proves that, when the LLM predicts answers, it can recall correct\ninformation missing in the CoT from the context, leading to unfaithfulness\nissues. Finally, we propose the inferential bridging method to mitigate this\nissue, in which we use the attribution method to recall information as hints\nfor CoT generation and filter out noisy CoTs based on their semantic\nconsistency and attribution scores. Extensive experiments demonstrate that our\napproach effectively alleviates the unfaithful CoT problem.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Jiachun Li",
            "Pengfei Cao",
            "Yubo Chen",
            "Kang Liu",
            "Jun Zhao"
        ],
        "published": "2024-05-29T09:17:46Z"
    },
    {
        "title": "Leveraging Time-Series Foundation Models in Smart Agriculture for Soil\n  Moisture Forecasting",
        "link": "http://arxiv.org/abs/2405.18913v1",
        "abstract": "The recent surge in foundation models for natural language processing and\ncomputer vision has fueled innovation across various domains. Inspired by this\nprogress, we explore the potential of foundation models for time-series\nforecasting in smart agriculture, a field often plagued by limited data\navailability. Specifically, this work presents a novel application of\n$\\texttt{TimeGPT}$, a state-of-the-art (SOTA) time-series foundation model, to\npredict soil water potential ($\\psi_\\mathrm{soil}$), a key indicator of field\nwater status that is typically used for irrigation advice. Traditionally, this\ntask relies on a wide array of input variables. We explore\n$\\psi_\\mathrm{soil}$'s ability to forecast $\\psi_\\mathrm{soil}$ in: ($i$) a\nzero-shot setting, ($ii$) a fine-tuned setting relying solely on historic\n$\\psi_\\mathrm{soil}$ measurements, and ($iii$) a fine-tuned setting where we\nalso add exogenous variables to the model. We compare $\\texttt{TimeGPT}$'s\nperformance to established SOTA baseline models for forecasting\n$\\psi_\\mathrm{soil}$. Our results demonstrate that $\\texttt{TimeGPT}$ achieves\ncompetitive forecasting accuracy using only historical $\\psi_\\mathrm{soil}$\ndata, highlighting its remarkable potential for agricultural applications. This\nresearch paves the way for foundation time-series models for sustainable\ndevelopment in agriculture by enabling forecasting tasks that were\ntraditionally reliant on extensive data collection and domain expertise.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Boje Deforce",
            "Bart Baesens",
            "Estefana Serral Asensio"
        ],
        "published": "2024-05-29T09:16:03Z"
    },
    {
        "title": "Exploring Human-in-the-Loop Test-Time Adaptation by Synergizing Active\n  Learning and Model Selection",
        "link": "http://arxiv.org/abs/2405.18911v1",
        "abstract": "Existing test-time adaptation (TTA) approaches often adapt models with the\nunlabeled testing data stream. A recent attempt relaxed the assumption by\nintroducing limited human annotation, referred to as Human-In-the-Loop\nTest-Time Adaptation (HILTTA) in this study. The focus of existing HILTTA lies\non selecting the most informative samples to label, a.k.a. active learning. In\nthis work, we are motivated by a pitfall of TTA, i.e. sensitive to\nhyper-parameters, and propose to approach HILTTA by synergizing active learning\nand model selection. Specifically, we first select samples for human annotation\n(active learning) and then use the labeled data to select optimal\nhyper-parameters (model selection). A sample selection strategy is tailored for\nchoosing samples by considering the balance between active learning and model\nselection purposes. We demonstrate on 4 TTA datasets that the proposed HILTTA\napproach is compatible with off-the-shelf TTA methods which outperform the\nstate-of-the-art HILTTA methods and stream-based active learning methods.\nImportantly, our proposed method can always prevent choosing the worst\nhyper-parameters on all off-the-shelf TTA methods. The source code will be\nreleased upon publication.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yushu Li",
            "Yongyi Su",
            "Xulei Yang",
            "Kui Jia",
            "Xun Xu"
        ],
        "published": "2024-05-29T09:13:30Z"
    },
    {
        "title": "NeuralODEs for VLEO simulations: Introducing thermoNET for Thermosphere\n  Modeling",
        "link": "http://arxiv.org/abs/2405.19384v1",
        "abstract": "We introduce a novel neural architecture termed thermoNET, designed to\nrepresent thermospheric density in satellite orbital propagation using a\nreduced amount of differentiable computations. Due to the appearance of a\nneural network on the right-hand side of the equations of motion, the resulting\nsatellite dynamics is governed by a NeuralODE, a neural Ordinary Differential\nEquation, characterized by its fully differentiable nature, allowing the\nderivation of variational equations (hence of the state transition matrix) and\nfacilitating its use in connection to advanced numerical techniques such as\nTaylor-based numerical propagation and differential algebraic techniques.\nEfficient training of the network parameters occurs through two distinct\napproaches. In the first approach, the network undergoes training independently\nof spacecraft dynamics, engaging in a pure regression task against ground truth\nmodels, including JB-08 and NRLMSISE-00. In the second paradigm, network\nparameters are learned based on observed dynamics, adapting through ODE\nsensitivities. In both cases, the outcome is a flexible, compact model of the\nthermosphere density greatly enhancing numerical propagation efficiency while\nmaintaining accuracy in the orbital predictions.",
        "subjects": [
            "astro-ph.EP",
            "cs.LG",
            "physics.ao-ph",
            "physics.space-ph"
        ],
        "authors": [
            "Dario Izzo",
            "Giacomo Acciarini",
            "Francesco Biscani"
        ],
        "published": "2024-05-29T09:12:44Z"
    },
    {
        "title": "Predicting Parking Availability in Singapore with Cross-Domain Data: A\n  New Dataset and A Data-Driven Approach",
        "link": "http://arxiv.org/abs/2405.18910v1",
        "abstract": "The increasing number of vehicles highlights the need for efficient parking\nspace management. Predicting real-time Parking Availability (PA) can help\nmitigate traffic congestion and the corresponding social problems, which is a\npressing issue in densely populated cities like Singapore. In this study, we\naim to collectively predict future PA across Singapore with complex factors\nfrom various domains. The contributions in this paper are listed as follows:\n(1) A New Dataset: We introduce the \\texttt{SINPA} dataset, containing a year's\nworth of PA data from 1,687 parking lots in Singapore, enriched with various\nspatial and temporal factors. (2) A Data-Driven Approach: We present DeepPA, a\nnovel deep-learning framework, to collectively and efficiently predict future\nPA across thousands of parking lots. (3) Extensive Experiments and Deployment:\nDeepPA demonstrates a 9.2% reduction in prediction error for up to 3-hour\nforecasts compared to existing advanced models. Furthermore, we implement\nDeepPA in a practical web-based platform to provide real-time PA predictions to\naid drivers and inform urban planning for the governors in Singapore. We\nrelease the dataset and source code at https://github.com/yoshall/SINPA.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Huaiwu Zhang",
            "Yutong Xia",
            "Siru Zhong",
            "Kun Wang",
            "Zekun Tong",
            "Qingsong Wen",
            "Roger Zimmermann",
            "Yuxuan Liang"
        ],
        "published": "2024-05-29T09:11:51Z"
    },
    {
        "title": "Language Generation with Strictly Proper Scoring Rules",
        "link": "http://arxiv.org/abs/2405.18906v1",
        "abstract": "Language generation based on maximum likelihood estimation (MLE) has become\nthe fundamental approach for text generation. Maximum likelihood estimation is\ntypically performed by minimizing the log-likelihood loss, also known as the\nlogarithmic score in statistical decision theory. The logarithmic score is\nstrictly proper in the sense that it encourages honest forecasts, where the\nexpected score is maximized only when the model reports true probabilities.\nAlthough many strictly proper scoring rules exist, the logarithmic score is the\nonly local scoring rule among them that depends exclusively on the probability\nof the observed sample, making it capable of handling the exponentially large\nsample space of natural text. In this work, we propose a straightforward\nstrategy for adapting scoring rules to language generation, allowing for\nlanguage modeling with any non-local scoring rules. Leveraging this strategy,\nwe train language generation models using two classic strictly proper scoring\nrules, the Brier score and the Spherical score, as alternatives to the\nlogarithmic score. Experimental results indicate that simply substituting the\nloss function, without adjusting other hyperparameters, can yield substantial\nimprovements in model's generation capabilities. Moreover, these improvements\ncan scale up to large language models (LLMs) such as LLaMA-7B and LLaMA-13B.\nSource code: \\url{https://github.com/shaochenze/ScoringRulesLM}.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Chenze Shao",
            "Fandong Meng",
            "Yijin Liu",
            "Jie Zhou"
        ],
        "published": "2024-05-29T09:09:00Z"
    },
    {
        "title": "A Causal Framework for Evaluating Deferring Systems",
        "link": "http://arxiv.org/abs/2405.18902v1",
        "abstract": "Deferring systems extend supervised Machine Learning (ML) models with the\npossibility to defer predictions to human experts. However, evaluating the\nimpact of a deferring strategy on system accuracy is still an overlooked area.\nThis paper fills this gap by evaluating deferring systems through a causal\nlens. We link the potential outcomes framework for causal inference with\ndeferring systems. This allows us to identify the causal impact of the\ndeferring strategy on predictive accuracy. We distinguish two scenarios. In the\nfirst one, we can access both the human and the ML model predictions for the\ndeferred instances. In such a case, we can identify the individual causal\neffects for deferred instances and aggregates of them. In the second scenario,\nonly human predictions are available for the deferred instances. In this case,\nwe can resort to regression discontinuity design to estimate a local causal\neffect. We empirically evaluate our approach on synthetic and real datasets for\nseven deferring systems from the literature.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Filippo Palomba",
            "Andrea Pugnana",
            "Jos Manuel Alvarez",
            "Salvatore Ruggieri"
        ],
        "published": "2024-05-29T09:03:44Z"
    },
    {
        "title": "Spectral Fidelity and Spatial Enhancement: An Assessment and Cascading\n  of Pan-Sharpening Techniques for Satellite Imagery",
        "link": "http://arxiv.org/abs/2405.18900v1",
        "abstract": "This research presents a comprehensive assessment of pan-sharpening\ntechniques for satellite imagery, focusing on the critical aspects of spectral\nfidelity and spatial enhancement. Motivated by the need for informed algorithm\nselection in remote sensing, A novel cascaded and structured evaluation\nframework has been proposed with a detailed comparative analysis of existing\nmethodologies. The research findings underscore the intricate trade-offs\nbetween spectral accuracy of about 88\\% with spatial resolution enhancement.\nThe research sheds light on the practical implications of pan-sharpening and\nemphasizes the significance of both spectral and spatial aspects in remote\nsensing applications. Various pan-sharpening algorithms were systematically\nemployed to provide a holistic view of their performance, contributing to a\ndeeper understanding of their capabilities and limitations.",
        "subjects": [
            "cs.CV",
            "eess.IV",
            "65D19"
        ],
        "authors": [
            "Abdul Aziz A. B",
            "A. B Abdul Rahim"
        ],
        "published": "2024-05-29T09:00:48Z"
    },
    {
        "title": "MLAE: Masked LoRA Experts for Parameter-Efficient Fine-Tuning",
        "link": "http://arxiv.org/abs/2405.18897v1",
        "abstract": "In response to the challenges posed by the extensive parameter updates\nrequired for full fine-tuning of large-scale pre-trained models,\nparameter-efficient fine-tuning (PEFT) methods, exemplified by Low-Rank\nAdaptation (LoRA), have emerged. LoRA simplifies the fine-tuning process but\nmay still struggle with a certain level of redundancy in low-rank matrices and\nlimited effectiveness from merely increasing their rank. To address these\nissues, a natural idea is to enhance the independence and diversity of the\nlearning process for the low-rank matrices. Therefore, we propose Masked LoRA\nExperts (MLAE), an innovative approach that applies the concept of masking to\nPEFT. Our method incorporates a cellular decomposition strategy that transforms\na low-rank matrix into independent rank-1 submatrices, or ``experts'', thus\nenhancing independence. Additionally, we introduce a binary mask matrix that\nselectively activates these experts during training to promote more diverse and\nanisotropic learning, based on expert-level dropout strategies. Our\ninvestigations reveal that this selective activation not only enhances\nperformance but also fosters a more diverse acquisition of knowledge with a\nmarked decrease in parameter similarity among MLAE, significantly boosting the\nquality of the model while barely increasing the parameter count. Remarkably,\nMLAE achieves new SOTA performance with an average accuracy score of 78.8% on\nthe VTAB-1k benchmark and 90.9% on the FGVC benchmark, demonstrating superior\nperformance. Our code is available at https://github.com/jie040109/MLAE.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Junjie Wang",
            "Guangjing Yang",
            "Wentao Chen",
            "Huahui Yi",
            "Xiaohu Wu",
            "Qicheng Lao"
        ],
        "published": "2024-05-29T08:57:23Z"
    },
    {
        "title": "Unit-Aware Genetic Programming for the Development of Empirical\n  Equations",
        "link": "http://arxiv.org/abs/2405.18896v1",
        "abstract": "When developing empirical equations, domain experts require these to be\naccurate and adhere to physical laws. Often, constants with unknown units need\nto be discovered alongside the equations. Traditional unit-aware genetic\nprogramming (GP) approaches cannot be used when unknown constants with\nundetermined units are included. This paper presents a method for dimensional\nanalysis that propagates unknown units as ''jokers'' and returns the magnitude\nof unit violations. We propose three methods, namely evolutive culling, a\nrepair mechanism, and a multi-objective approach, to integrate the dimensional\nanalysis in the GP algorithm. Experiments on datasets with ground truth\ndemonstrate comparable performance of evolutive culling and the multi-objective\napproach to a baseline without dimensional analysis. Extensive analysis of the\nresults on datasets without ground truth reveals that the unit-aware algorithms\nmake only low sacrifices in accuracy, while producing unit-adherent solutions.\nOverall, we presented a promising novel approach for developing unit-adherent\nempirical equations.",
        "subjects": [
            "cs.LG",
            "cs.SC"
        ],
        "authors": [
            "Julia Reuter",
            "Viktor Martinek",
            "Roland Herzog",
            "Sanaz Mostaghim"
        ],
        "published": "2024-05-29T08:57:00Z"
    },
    {
        "title": "Few-Shot Testing: Estimating Uncertainty of Memristive Deep Neural\n  Networks Using One Bayesian Test Vector",
        "link": "http://arxiv.org/abs/2405.18894v1",
        "abstract": "The performance of deep learning algorithms such as neural networks (NNs) has\nincreased tremendously recently, and they can achieve state-of-the-art\nperformance in many domains. However, due to memory and computation resource\nconstraints, implementing NNs on edge devices is a challenging task. Therefore,\nhardware accelerators such as computation-in-memory (CIM) with memristive\ndevices have been developed to accelerate the most common operations, i.e.,\nmatrix-vector multiplication. However, due to inherent device properties,\nexternal environmental factors such as temperature, and an immature fabrication\nprocess, memristors suffer from various non-idealities, including defects and\nvariations occurring during manufacturing and runtime. Consequently, there is a\nlack of complete confidence in the predictions made by the model. To improve\nconfidence in NN predictions made by hardware accelerators in the presence of\ndevice non-idealities, in this paper, we propose a Bayesian test vector\ngeneration framework that can estimate the model uncertainty of NNs implemented\non memristor-based CIM hardware. Compared to the conventional point estimate\ntest vector generation method, our method is more generalizable across\ndifferent model dimensions and requires storing only one test Bayesian vector\nin the hardware. Our method is evaluated on different model dimensions, tasks,\nfault rates, and variation noise to show that it can consistently achieve\n$100\\%$ coverage with only $0.024$ MB of memory overhead.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.ET"
        ],
        "authors": [
            "Soyed Tuhin Ahmed",
            "Mehdi Tahoori"
        ],
        "published": "2024-05-29T08:53:16Z"
    },
    {
        "title": "EVM Analysis of Distributed Massive MIMO with 1-Bit Radio-Over-Fiber\n  Fronthaul",
        "link": "http://arxiv.org/abs/2405.18892v1",
        "abstract": "We analyze the uplink performance of a distributed massive multiple-input\nmultiple-output (MIMO) architecture in which the remotely located access points\n(APs) are connected to a central processing unit via a fiber-optical fronthaul\ncarrying a dithered and 1-bit quantized version of the received radio-frequency\n(RF) signal. The innovative feature of the proposed architecture is that no\ndown-conversion is performed at the APs. This eliminates the need to equip the\nAPs with local oscillators, which may be difficult to synchronize. Under the\nassumption that a constraint is imposed on the amount of data that can be\nexchanged across the fiber-optical fronthaul, we investigate the tradeoff\nbetween spatial oversampling, defined in terms of the total number of APs, and\ntemporal oversampling, defined in terms of the oversampling factor selected at\nthe central processing unit, to facilitate the recovery of the transmitted\nsignal from 1-bit samples of the RF received signal. Using the so-called\nerror-vector magnitude (EVM) as performance metric, we shed light on the\noptimal design of the dither signal, and quantify, for a given number of APs,\nthe minimum fronthaul rate required for our proposed distributed massive MIMO\narchitecture to outperform a standard co-located massive MIMO architecture in\nterms of EVM.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Anzhong Hu",
            "Lise Aabel",
            "Giuseppe Durisi",
            "Sven Jacobsson",
            "Mikael Coldrey",
            "Christian Fager",
            "Christoph Studer"
        ],
        "published": "2024-05-29T08:52:48Z"
    },
    {
        "title": "Network Analytics for Anti-Money Laundering -- A Systematic Literature\n  Review and Experimental Evaluation",
        "link": "http://arxiv.org/abs/2405.19383v1",
        "abstract": "Money laundering presents a pervasive challenge, burdening society by\nfinancing illegal activities. To more effectively combat and detect money\nlaundering, the use of network information is increasingly being explored,\nexploiting that money laundering necessarily involves interconnected parties.\nThis has lead to a surge in literature on network analytics (NA) for anti-money\nlaundering (AML). The literature, however, is fragmented and a comprehensive\noverview of existing work is missing. This results in limited understanding of\nthe methods that may be applied and their comparative detection power.\nTherefore, this paper presents an extensive and systematic review of the\nliterature. We identify and analyse 97 papers in the Web of Science and Scopus\ndatabases, resulting in a taxonomy of approaches following the fraud analytics\nframework of Bockel-Rickermann et al.. Moreover, this paper presents a\ncomprehensive experimental framework to evaluate and compare the performance of\nprominent NA methods in a uniform setup. The framework is applied on the\npublicly available Elliptic data set and implements manual feature engineering,\nrandom walk-based methods, and deep learning GNNs. We conclude from the results\nthat network analytics increases the predictive power of the AML model with\ngraph neural networks giving the best results. An open source implementation of\nthe experimental framework is provided to facilitate researchers and\npractitioners to extend upon these results and experiment on proprietary data.\nAs such, we aim to promote a standardised approach towards the analysis and\nevaluation of network analytics for AML.",
        "subjects": [
            "cs.SI",
            "cs.LG"
        ],
        "authors": [
            "Bruno Deprez",
            "Toon Vanderschueren",
            "Wouter Verbeke",
            "Bart Baesens",
            "Tim Verdonck"
        ],
        "published": "2024-05-29T08:48:52Z"
    },
    {
        "title": "Locally Estimated Global Perturbations are Better than Local\n  Perturbations for Federated Sharpness-aware Minimization",
        "link": "http://arxiv.org/abs/2405.18890v1",
        "abstract": "In federated learning (FL), the multi-step update and data heterogeneity\namong clients often lead to a loss landscape with sharper minima, degenerating\nthe performance of the resulted global model. Prevalent federated approaches\nincorporate sharpness-aware minimization (SAM) into local training to mitigate\nthis problem. However, the local loss landscapes may not accurately reflect the\nflatness of global loss landscape in heterogeneous environments; as a result,\nminimizing local sharpness and calculating perturbations on client data might\nnot align the efficacy of SAM in FL with centralized training. To overcome this\nchallenge, we propose FedLESAM, a novel algorithm that locally estimates the\ndirection of global perturbation on client side as the difference between\nglobal models received in the previous active and current rounds. Besides the\nimproved quality, FedLESAM also speed up federated SAM-based approaches since\nit only performs once backpropagation in each iteration. Theoretically, we\nprove a slightly tighter bound than its original FedSAM by ensuring consistent\nperturbation. Empirically, we conduct comprehensive experiments on four\nfederated benchmark datasets under three partition strategies to demonstrate\nthe superior performance and efficiency of FedLESAM.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "authors": [
            "Ziqing Fan",
            "Shengchao Hu",
            "Jiangchao Yao",
            "Gang Niu",
            "Ya Zhang",
            "Masashi Sugiyama",
            "Yanfeng Wang"
        ],
        "published": "2024-05-29T08:46:21Z"
    },
    {
        "title": "On Perception of Prevalence of Cheating and Usage of Generative AI",
        "link": "http://arxiv.org/abs/2405.18889v1",
        "abstract": "This report investigates the perceptions of teaching staff on the prevalence\nof student cheating and the impact of Generative AI on academic integrity. Data\nwas collected via an anonymous survey of teachers at the Department of\nInformation Technology at Uppsala University and analyzed alongside\ninstitutional statistics on cheating investigations from 2004 to 2023. The\nresults indicate that while teachers generally do not view cheating as highly\nprevalent, there is a strong belief that its incidence is increasing,\npotentially due to the accessibility of Generative AI. Most teachers do not\nequate AI usage with cheating but acknowledge its widespread use among\nstudents. Furthermore, teachers' perceptions align with objective data on\ncheating trends, highlighting their awareness of the evolving landscape of\nacademic dishonesty.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "authors": [
            "Roman Denkin"
        ],
        "published": "2024-05-29T08:46:00Z"
    },
    {
        "title": "Proactive Load-Shaping Strategies with Privacy-Cost Trade-offs in\n  Residential Households based on Deep Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.18888v1",
        "abstract": "Smart meters play a crucial role in enhancing energy management and\nefficiency, but they raise significant privacy concerns by potentially\nrevealing detailed user behaviors through energy consumption patterns. Recent\nscholarly efforts have focused on developing battery-aided load-shaping\ntechniques to protect user privacy while balancing costs. This paper proposes a\nnovel deep reinforcement learning-based load-shaping algorithm (PLS-DQN)\ndesigned to protect user privacy by proactively creating artificial load\nsignatures that mislead potential attackers. We evaluate our proposed algorithm\nagainst a non-intrusive load monitoring (NILM) adversary. The results\ndemonstrate that our approach not only effectively conceals real energy usage\npatterns but also outperforms state-of-the-art methods in enhancing user\nprivacy while maintaining cost efficiency.",
        "subjects": [
            "eess.SY",
            "cs.LG",
            "cs.SY"
        ],
        "authors": [
            "Ruichang Zhang",
            "Youcheng Sun",
            "Mustafa A. Mustafa"
        ],
        "published": "2024-05-29T08:45:04Z"
    },
    {
        "title": "4Doodle: Two-handed Gestures for Immersive Sketching of Architectural\n  Models",
        "link": "http://arxiv.org/abs/2405.18887v1",
        "abstract": "Three-dimensional immersive sketching for content creation and modeling has\nbeen studied for some time. However, research in this domain mainly focused on\nCAVE-like scenarios. These setups can be expensive and offer a narrow\ninteraction space. Building more affordable setups using head-mounted displays\nis possible, allowing greater immersion and a larger space for user physical\nmovements. This paper presents a fully immersive environment using bi-manual\ngestures to sketch and create content freely in the virtual world. This\napproach can be applied to many scenarios, allowing people to express their\nideas or review existing designs. To cope with known motor difficulties and\ninaccuracy of freehand 3D sketching, we explore proxy geometry and a laser-like\nmetaphor to draw content directly from models and create content surfaces. Our\ncurrent prototype offers 24 cubic meters for movement, limited by the room\nsize. It features infinite virtual drawing space through pan and scale\ntechniques and is larger than the typical 6-sided cave at a fraction of the\ncost. In a preliminary study conducted with architects and engineers, our\nsystem showed a clear promise as a tool for sketching and 3D content creation\nin virtual reality with a great emphasis on bi-manual gestures.",
        "subjects": [
            "cs.HC",
            "H.5.2, I.3.4, I.3.7",
            "H.5.2; I.3.4; I.3.7"
        ],
        "authors": [
            "Fernando Fonseca",
            "Maurcio Sousa",
            "Daniel Mendes",
            "Alfredo Ferreira",
            "Joaquim Jorge"
        ],
        "published": "2024-05-29T08:42:49Z"
    },
    {
        "title": "Compressing Large Language Models using Low Rank and Low Precision\n  Decomposition",
        "link": "http://arxiv.org/abs/2405.18886v1",
        "abstract": "The prohibitive sizes of Large Language Models (LLMs) today make it difficult\nto deploy them on memory-constrained edge devices. This work introduces $\\rm\nCALDERA$ -- a new post-training LLM compression algorithm that harnesses the\ninherent low-rank structure of a weight matrix $\\mathbf{W}$ by approximating it\nvia a low-rank, low-precision decomposition as $\\mathbf{W} \\approx \\mathbf{Q} +\n\\mathbf{L}\\mathbf{R}$. Here, $\\mathbf{L}$ and $\\mathbf{R}$ are low rank\nfactors, and the entries of $\\mathbf{Q}$, $\\mathbf{L}$ and $\\mathbf{R}$ are\nquantized. The model is compressed by substituting each layer with its\n$\\mathbf{Q} + \\mathbf{L}\\mathbf{R}$ decomposition, and the zero-shot\nperformance of the compressed model is evaluated. Additionally, $\\mathbf{L}$\nand $\\mathbf{R}$ are readily amenable to low-rank adaptation, consequently\nenhancing the zero-shot performance. $\\rm CALDERA$ obtains this decomposition\nby formulating it as an optimization problem\n$\\min_{\\mathbf{Q},\\mathbf{L},\\mathbf{R}}\\lVert(\\mathbf{Q} +\n\\mathbf{L}\\mathbf{R} - \\mathbf{W})\\mathbf{X}^\\top\\rVert_{\\rm F}^2$, where\n$\\mathbf{X}$ is the calibration data, and $\\mathbf{Q}, \\mathbf{L}, \\mathbf{R}$\nare constrained to be representable using low-precision formats. Theoretical\nupper bounds on the approximation error of $\\rm CALDERA$ are established using\na rank-constrained regression framework, and the tradeoff between compression\nratio and model performance is studied by analyzing the impact of target rank\nand quantization bit budget. Results illustrate that compressing LlaMa-$2$\n$7$B/$70$B and LlaMa-$3$ $8$B models obtained using $\\rm CALDERA$ outperforms\nexisting post-training LLM compression techniques in the regime of less than\n$2.5$ bits per parameter. The implementation is available at:\n\\href{https://github.com/pilancilab/caldera}{https://github.com/pilancilab/caldera}.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.OC",
            "stat.ML"
        ],
        "authors": [
            "Rajarshi Saha",
            "Naomi Sagan",
            "Varun Srivastava",
            "Andrea J. Goldsmith",
            "Mert Pilanci"
        ],
        "published": "2024-05-29T08:42:30Z"
    },
    {
        "title": "Learning Mixture-of-Experts for General-Purpose Black-Box Discrete\n  Optimization",
        "link": "http://arxiv.org/abs/2405.18884v1",
        "abstract": "Real-world applications involve various discrete optimization problems.\nDesigning a specialized optimizer for each of these problems is challenging,\ntypically requiring significant domain knowledge and human efforts. Hence,\ndeveloping general-purpose optimizers as an off-the-shelf tool for a wide range\nof problems has been a long-standing research target. This article introduces\nMEGO, a novel general-purpose neural optimizer trained through a fully\ndata-driven learning-to-optimize (L2O) approach. MEGO consists of a\nmixture-of-experts trained on experiences from solving training problems and\ncan be viewed as a foundation model for optimization problems with binary\ndecision variables. When presented with a problem to solve, MEGO actively\nselects relevant expert models to generate high-quality solutions. MEGO can be\nused as a standalone sample-efficient optimizer or in conjunction with existing\nsearch methods as an initial solution generator. The generality of MEGO is\nvalidated across six problem classes, including three classic problem classes\nand three problem classes arising from real-world applications in compilers,\nnetwork analysis, and 3D reconstruction. Trained solely on classic problem\nclasses, MEGO performs very well on all six problem classes, significantly\nsurpassing widely used general-purpose optimizers in both solution quality and\nefficiency. In some cases, MEGO even surpasses specialized state-of-the-art\noptimizers. Additionally, MEGO provides a similarity measure between problems,\nyielding a new perspective for problem classification. In the pursuit of\ngeneral-purpose optimizers through L2O, MEGO represents an initial yet\nsignificant step forward.",
        "subjects": [
            "cs.NE"
        ],
        "authors": [
            "Shengcai Liu",
            "Zhiyuan Wang",
            "Yew-Soon Ong",
            "Xin Yao",
            "Ke Tang"
        ],
        "published": "2024-05-29T08:41:08Z"
    },
    {
        "title": "DecomCAM: Advancing Beyond Saliency Maps through Decomposition and\n  Integration",
        "link": "http://arxiv.org/abs/2405.18882v1",
        "abstract": "Interpreting complex deep networks, notably pre-trained vision-language\nmodels (VLMs), is a formidable challenge. Current Class Activation Map (CAM)\nmethods highlight regions revealing the model's decision-making basis but lack\nclear saliency maps and detailed interpretability. To bridge this gap, we\npropose DecomCAM, a novel decomposition-and-integration method that distills\nshared patterns from channel activation maps. Utilizing singular value\ndecomposition, DecomCAM decomposes class-discriminative activation maps into\northogonal sub-saliency maps (OSSMs), which are then integrated together based\non their contribution to the target concept. Extensive experiments on six\nbenchmarks reveal that DecomCAM not only excels in locating accuracy but also\nachieves an optimizing balance between interpretability and computational\nefficiency. Further analysis unveils that OSSMs correlate with discernible\nobject components, facilitating a granular understanding of the model's\nreasoning. This positions DecomCAM as a potential tool for fine-grained\ninterpretation of advanced deep learning models. The code is avaible at\nhttps://github.com/CapricornGuang/DecomCAM.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yuguang Yang",
            "Runtang Guo",
            "Sheng Wu",
            "Yimi Wang",
            "Linlin Yang",
            "Bo Fan",
            "Jilong Zhong",
            "Juan Zhang",
            "Baochang Zhang"
        ],
        "published": "2024-05-29T08:40:11Z"
    },
    {
        "title": "Tuning-Free Alignment of Diffusion Models with Direct Noise Optimization",
        "link": "http://arxiv.org/abs/2405.18881v1",
        "abstract": "In this work, we focus on the alignment problem of diffusion models with a\ncontinuous reward function, which represents specific objectives for downstream\ntasks, such as improving human preference. The central goal of the alignment\nproblem is to adjust the distribution learned by diffusion models such that the\ngenerated samples maximize the target reward function. We propose a novel\nalignment approach, named Direct Noise Optimization (DNO), that optimizes the\ninjected noise during the sampling process of diffusion models. By design, DNO\nis tuning-free and prompt-agnostic, as the alignment occurs in an online\nfashion during generation. We rigorously study the theoretical properties of\nDNO and also propose variants to deal with non-differentiable reward functions.\nFurthermore, we identify that naive implementation of DNO occasionally suffers\nfrom the out-of-distribution reward hacking problem, where optimized samples\nhave high rewards but are no longer in the support of the pretrained\ndistribution. To remedy this issue, we leverage classical high-dimensional\nstatistics theory and propose to augment the DNO loss with certain probability\nregularization. We conduct extensive experiments on several popular reward\nfunctions trained on human feedback data and demonstrate that the proposed DNO\napproach achieves state-of-the-art reward scores as well as high image quality,\nall within a reasonable time budget for generation.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Zhiwei Tang",
            "Jiangweizhi Peng",
            "Jiasheng Tang",
            "Mingyi Hong",
            "Fan Wang",
            "Tsung-Hui Chang"
        ],
        "published": "2024-05-29T08:39:39Z"
    },
    {
        "title": "EventZoom: A Progressive Approach to Event-Based Data Augmentation for\n  Enhanced Neuromorphic Vision",
        "link": "http://arxiv.org/abs/2405.18880v1",
        "abstract": "Event data captured by Dynamic Vision Sensors (DVS) offers a unique approach\nto visual processing that differs from traditional video capture, showcasing\nits efficiency in dynamic and real-time scenarios. Despite advantages such as\nhigh temporal resolution and low energy consumption, the application of event\ndata faces challenges due to limited dataset size and diversity. To address\nthis, we developed EventZoom -- a data augmentation strategy specifically\ndesigned for event data. EventZoom employs a progressive temporal strategy that\nintelligently blends time and space to enhance the diversity and complexity of\nthe data while maintaining its authenticity. This method aims to improve the\nquality of data for model training and enhance the adaptability and robustness\nof algorithms in handling complex dynamic scenes. We have experimentally\nvalidated EventZoom across various supervised learning frameworks, including\nsupervised, semi-supervised, and unsupervised learning. Our results demonstrate\nthat EventZoom consistently outperforms other data augmentation methods,\nconfirming its effectiveness and applicability as a powerful event-based data\naugmentation tool in diverse learning settings.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yiting Dong",
            "Xiang He",
            "Guobin Shen",
            "Dongcheng Zhao",
            "Yang Li",
            "Yi Zeng"
        ],
        "published": "2024-05-29T08:39:31Z"
    },
    {
        "title": "Spatiotemporal Forecasting Meets Efficiency: Causal Graph Process Neural\n  Networks",
        "link": "http://arxiv.org/abs/2405.18879v1",
        "abstract": "Graph Neural Networks (GNNs) have advanced spatiotemporal forecasting by\nleveraging relational inductive biases among sensors (or any other measuring\nscheme) represented as nodes in a graph. However, current methods often rely on\nRecurrent Neural Networks (RNNs), leading to increased runtimes and memory use.\nMoreover, these methods typically operate within 1-hop neighborhoods,\nexacerbating the reduction of the receptive field. Causal Graph Processes\n(CGPs) offer an alternative, using graph filters instead of MLP layers to\nreduce parameters and minimize memory consumption. This paper introduces the\nCausal Graph Process Neural Network (CGProNet), a non-linear model combining\nCGPs and GNNs for spatiotemporal forecasting. CGProNet employs higher-order\ngraph filters, optimizing the model with fewer parameters, reducing memory\nusage, and improving runtime efficiency. We present a comprehensive theoretical\nand experimental stability analysis, highlighting key aspects of CGProNet.\nExperiments on synthetic and real data demonstrate CGProNet's superior\nefficiency, minimizing memory and time requirements while maintaining\ncompetitive forecasting performance.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Aref Einizade",
            "Fragkiskos D. Malliaros",
            "Jhony H. Giraldo"
        ],
        "published": "2024-05-29T08:37:48Z"
    },
    {
        "title": "Privacy Preserving Data Imputation via Multi-party Computation for\n  Medical Applications",
        "link": "http://arxiv.org/abs/2405.18878v1",
        "abstract": "Handling missing data is crucial in machine learning, but many datasets\ncontain gaps due to errors or non-response. Unlike traditional methods such as\nlistwise deletion, which are simple but inadequate, the literature offers more\nsophisticated and effective methods, thereby improving sample size and\naccuracy. However, these methods require accessing the whole dataset, which\ncontradicts the privacy regulations when the data is distributed among multiple\nsources. Especially in the medical and healthcare domain, such access reveals\nsensitive information about patients. This study addresses privacy-preserving\nimputation methods for sensitive data using secure multi-party computation,\nenabling secure computations without revealing any party's sensitive\ninformation. In this study, we realized the mean, median, regression, and kNN\nimputation methods in a privacy-preserving way. We specifically target the\nmedical and healthcare domains considering the significance of protection of\nthe patient data, showcasing our methods on a diabetes dataset. Experiments on\nthe diabetes dataset validated the correctness of our privacy-preserving\nimputation methods, yielding the largest error around $3 \\times 10^{-3}$,\nclosely matching plaintext methods. We also analyzed the scalability of our\nmethods to varying numbers of samples, showing their applicability to\nreal-world healthcare problems. Our analysis demonstrated that all our methods\nscale linearly with the number of samples. Except for kNN, the runtime of all\nour methods indicates that they can be utilized for large datasets.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "authors": [
            "Julia Jentsch",
            "Ali Burak nal",
            "eyma Selcan Maara",
            "Mete Akgn"
        ],
        "published": "2024-05-29T08:36:42Z"
    },
    {
        "title": "Continuous Product Graph Neural Networks",
        "link": "http://arxiv.org/abs/2405.18877v1",
        "abstract": "Processing multidomain data defined on multiple graphs holds significant\npotential in various practical applications in computer science. However,\ncurrent methods are mostly limited to discrete graph filtering operations.\nTensorial partial differential equations on graphs (TPDEGs) provide a\nprincipled framework for modeling structured data across multiple interacting\ngraphs, addressing the limitations of the existing discrete methodologies. In\nthis paper, we introduce Continuous Product Graph Neural Networks (CITRUS) that\nemerge as a natural solution to the TPDEG. CITRUS leverages the separability of\ncontinuous heat kernels from Cartesian graph products to efficiently implement\ngraph spectral decomposition. We conduct thorough theoretical analyses of the\nstability and over-smoothing properties of CITRUS in response to\ndomain-specific graph perturbations and graph spectra effects on the\nperformance. We evaluate CITRUS on well-known traffic and weather\nspatiotemporal forecasting datasets, demonstrating superior performance over\nexisting approaches.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Aref Einizade",
            "Fragkiskos D. Malliaros",
            "Jhony H. Giraldo"
        ],
        "published": "2024-05-29T08:36:09Z"
    },
    {
        "title": "On Fairness Concerns in the Blockchain Ecosystem",
        "link": "http://dx.doi.org/10.22028/D291-41983",
        "abstract": "Blockchains revolutionized centralized sectors like banking and finance by\npromoting decentralization and transparency. In a blockchain, information is\ntransmitted through transactions issued by participants or applications. Miners\ncrucially select, order, and validate pending transactions for block inclusion,\nprioritizing those with higher incentives or fees. The order in which\ntransactions are included can impact the blockchain final state. Moreover,\napplications running on top of a blockchain often rely on governance protocols\nto decentralize the decision-making power to make changes to their core\nfunctionality. These changes can affect how participants interact with these\napplications. Since one token equals one vote, participants holding multiple\ntokens have a higher voting power to support or reject the proposed changes.\nThe extent to which this voting power is distributed is questionable and if\nhighly concentrated among a few holders can lead to governance attacks. In this\nthesis, we audit the Bitcoin and Ethereum blockchains to investigate the norms\nfollowed by miners in determining the transaction prioritization. We also audit\ndecentralized governance protocols such as Compound to evaluate whether the\nvoting power is fairly distributed among the participants. Our findings have\nsignificant implications for future developments of blockchains and\ndecentralized applications.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Johnnatan Messias Peixoto Afonso"
        ],
        "published": "2024-05-29T08:35:37Z"
    },
    {
        "title": "Counterfactual Metarules for Local and Global Recourse",
        "link": "http://arxiv.org/abs/2405.18875v1",
        "abstract": "We introduce T-CREx, a novel model-agnostic method for local and global\ncounterfactual explanation (CE), which summarises recourse options for both\nindividuals and groups in the form of human-readable rules. It leverages\ntree-based surrogate models to learn the counterfactual rules, alongside\n'metarules' denoting their regions of optimality, providing both a global\nanalysis of model behaviour and diverse recourse options for users. Experiments\nindicate that T-CREx achieves superior aggregate performance over existing\nrule-based baselines on a range of CE desiderata, while being orders of\nmagnitude faster to run.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Tom Bewley",
            "Salim I. Amoukou",
            "Saumitra Mishra",
            "Daniele Magazzeni",
            "Manuela Veloso"
        ],
        "published": "2024-05-29T08:35:17Z"
    },
    {
        "title": "Are queries and keys always relevant? A case study on Transformer wave\n  functions",
        "link": "http://arxiv.org/abs/2405.18874v1",
        "abstract": "The dot product attention mechanism, originally designed for natural language\nprocessing (NLP) tasks, is a cornerstone of modern Transformers. It adeptly\ncaptures semantic relationships between word pairs in sentences by computing a\nsimilarity overlap between queries and keys. In this work, we explore the\nsuitability of Transformers, focusing on their attention mechanisms, in the\nspecific domain of the parametrization of variational wave functions to\napproximate ground states of quantum many-body spin Hamiltonians. Specifically,\nwe perform numerical simulations on the two-dimensional $J_1$-$J_2$ Heisenberg\nmodel, a common benchmark in the field of quantum-many body systems on lattice.\nBy comparing the performance of standard attention mechanisms with a simplified\nversion that excludes queries and keys, relying solely on positions, we achieve\ncompetitive results while reducing computational cost and parameter usage.\nFurthermore, through the analysis of the attention maps generated by standard\nattention mechanisms, we show that the attention weights become effectively\ninput-independent at the end of the optimization. We support the numerical\nresults with analytical calculations, providing physical insights of why\nqueries and keys should be, in principle, omitted from the attention mechanism\nwhen studying large systems. Interestingly, the same arguments can be extended\nto the NLP domain, in the limit of long input sentences.",
        "subjects": [
            "cond-mat.dis-nn",
            "cs.CL",
            "physics.comp-ph"
        ],
        "authors": [
            "Riccardo Rende",
            "Luciano Loris Viteritti"
        ],
        "published": "2024-05-29T08:32:37Z"
    },
    {
        "title": "A Return to Biased Nets: New Specifications and Approximate Bayesian\n  Inference",
        "link": "http://dx.doi.org/10.1080/0022250X.2024.2340137",
        "abstract": "The biased net paradigm was the first general and empirically tractable\nscheme for parameterizing complex patterns of dependence in networks,\nexpressing deviations from uniform random graph structure in terms of latent\n``bias events,'' whose realizations enhance reciprocity, transitivity, or other\nstructural features. Subsequent developments have introduced local\nspecifications of biased nets, which reduce the need for approximations\nrequired in early specifications based on tracing processes. Here, we show that\nwhile one such specification leads to inconsistencies, a closely related\nMarkovian specification both evades these difficulties and can be extended to\nincorporate new types of effects. We introduce the notion of inhibitory bias\nevents, with satiation as an example, which are useful for avoiding\ndegeneracies that can arise from closure bias terms. Although our approach does\nnot lead to a computable likelihood, we provide a strategy for approximate\nBayesian inference using random forest prevision. We demonstrate our approach\non a network of friendship ties among college students, recapitulating a\nrelationship between the sibling bias and tie strength posited in earlier work\nby Fararo.",
        "subjects": [
            "stat.ME",
            "cs.SI"
        ],
        "authors": [
            "Carter T. Butts"
        ],
        "published": "2024-05-29T08:32:28Z"
    },
    {
        "title": "New Approaches to Old Problems? Thinking About a New Design of the\n  AML/CFT Strategy",
        "link": "http://arxiv.org/abs/2405.18517v1",
        "abstract": "The entry of new technological infrastructures into the financial markets\nposes serious concerns about the misuse of the economic system for illicit\npurposes, such as money laundering and financing of terrorism. Although there\nare cases in which this connection has already been discovered by malicious\nactors, distributed ledger technologies can nevertheless represent a powerful\ntool at the disposal of competent authorities to trace illicit flows and to\nbetter monitor risks in financial markets. However, this possibility may go\nthrough an interdisciplinary analysis of the phenomena. The search for\nalternative systems to move funds, rather than the traditional financial\nintermediaries, such as banks, is not a new circumstance and not necessarily\nfor criminal purposes. Nevertheless, some of the already-known value transfer\nsystems may benefit from the use of distributed ledger technology and make\ntheir detection more difficult. The European institutions are discussing the\nneeded legislative packages to enforce the current regulations and to extend\ntheir application to the crypto space, as well as the establishment of a new\ncompetent authority.",
        "subjects": [
            "econ.TH",
            "cs.ET"
        ],
        "authors": [
            "Chiara Ferri"
        ],
        "published": "2024-05-29T08:32:06Z"
    },
    {
        "title": "Single image super-resolution based on trainable feature matching\n  attention network",
        "link": "http://dx.doi.org/10.1016/j.patcog.2024.110289",
        "abstract": "Convolutional Neural Networks (CNNs) have been widely employed for image\nSuper-Resolution (SR) in recent years. Various techniques enhance SR\nperformance by altering CNN structures or incorporating improved self-attention\nmechanisms. Interestingly, these advancements share a common trait. Instead of\nexplicitly learning high-frequency details, they learn an implicit feature\nprocessing mode that utilizes weighted sums of a feature map's own elements for\nreconstruction, akin to convolution and non-local. In contrast, early\ndictionary-based approaches learn feature decompositions explicitly to match\nand rebuild Low-Resolution (LR) features. Building on this analysis, we\nintroduce Trainable Feature Matching (TFM) to amalgamate this explicit feature\nlearning into CNNs, augmenting their representation capabilities. Within TFM,\ntrainable feature sets are integrated to explicitly learn features from\ntraining images through feature matching. Furthermore, we integrate non-local\nand channel attention into our proposed Trainable Feature Matching Attention\nNetwork (TFMAN) to further enhance SR performance. To alleviate the\ncomputational demands of non-local operations, we propose a streamlined variant\ncalled Same-size-divided Region-level Non-Local (SRNL). SRNL conducts non-local\ncomputations in parallel on blocks uniformly divided from the input feature\nmap. The efficacy of TFM and SRNL is validated through ablation studies and\nmodule explorations. We employ a recurrent convolutional network as the\nbackbone of our TFMAN to optimize parameter utilization. Comprehensive\nexperiments on benchmark datasets demonstrate that TFMAN achieves superior\nresults in most comparisons while using fewer parameters. The code is available\nat https://github.com/qizhou000/tfman.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Qizhou Chen",
            "Qing Shao"
        ],
        "published": "2024-05-29T08:31:54Z"
    },
    {
        "title": "DFAMiner: Mining minimal separating DFAs from labelled samples",
        "link": "http://arxiv.org/abs/2405.18871v1",
        "abstract": "We propose DFAMiner, a passive learning tool for learning minimal separating\ndeterministic finite automata (DFA) from a set of labelled samples. Separating\nautomata are an interesting class of automata that occurs generally in regular\nmodel checking and has raised interest in foundational questions of parity game\nsolving. We first propose a simple and linear-time algorithm that incrementally\nconstructs a three-valued DFA (3DFA) from a set of labelled samples given in\nthe usual lexicographical order. This 3DFA has accepting and rejecting states\nas well as don't-care states, so that it can exactly recognise the labelled\nexamples. We then apply our tool to mining a minimal separating DFA for the\nlabelled samples by minimising the constructed automata via a reduction to\nsolving SAT problems. Empirical evaluation shows that our tool outperforms\ncurrent state-of-the-art tools significantly on standard benchmarks for\nlearning minimal separating DFAs from samples. Progress in the efficient\nconstruction of separating DFAs can also lead to finding the lower bound of\nparity game solving, where we show that DFAMiner can create optimal separating\nautomata for simple languages with up to 7 colours. Future improvements might\noffer inroads to better data structures.",
        "subjects": [
            "cs.FL",
            "cs.LG",
            "F.4.3; I.2.6"
        ],
        "authors": [
            "Daniele Dell'Erba",
            "Yong Li",
            "Sven Schewe"
        ],
        "published": "2024-05-29T08:31:34Z"
    },
    {
        "title": "LLMs achieve adult human performance on higher-order theory of mind\n  tasks",
        "link": "http://arxiv.org/abs/2405.18870v1",
        "abstract": "This paper examines the extent to which large language models (LLMs) have\ndeveloped higher-order theory of mind (ToM); the human ability to reason about\nmultiple mental and emotional states in a recursive manner (e.g. I think that\nyou believe that she knows). This paper builds on prior work by introducing a\nhandwritten test suite -- Multi-Order Theory of Mind Q&A -- and using it to\ncompare the performance of five LLMs to a newly gathered adult human benchmark.\nWe find that GPT-4 and Flan-PaLM reach adult-level and near adult-level\nperformance on ToM tasks overall, and that GPT-4 exceeds adult performance on\n6th order inferences. Our results suggest that there is an interplay between\nmodel size and finetuning for the realisation of ToM abilities, and that the\nbest-performing LLMs have developed a generalised capacity for ToM. Given the\nrole that higher-order ToM plays in a wide range of cooperative and competitive\nhuman behaviours, these findings have significant implications for user-facing\nLLM applications.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.HC"
        ],
        "authors": [
            "Winnie Street",
            "John Oliver Siy",
            "Geoff Keeling",
            "Adrien Baranes",
            "Benjamin Barnett",
            "Michael McKibben",
            "Tatenda Kanyere",
            "Alison Lentz",
            "Blaise Aguera y Arcas",
            "Robin I. M. Dunbar"
        ],
        "published": "2024-05-29T08:31:16Z"
    },
    {
        "title": "Towards Data-Driven Electricity Management: Multi-Region Harmonized Data\n  and Knowledge Graph",
        "link": "http://arxiv.org/abs/2405.18869v1",
        "abstract": "Due to growing population and technological advances, global electricity\nconsumption, and consequently also CO2 emissions are increasing. The\nresidential sector makes up 25% of global electricity consumption and has great\npotential to increase efficiency and reduce CO2 footprint without sacrificing\ncomfort. However, a lack of uniform consumption data at the household level\nspanning multiple regions hinders large-scale studies and robust multi-region\nmodel development. This paper introduces a multi-region dataset compiled from\npublicly available sources and presented in a uniform format. This data enables\nmachine learning tasks such as disaggregation, demand forecasting, appliance\nON/OFF classification, etc. Furthermore, we develop an RDF knowledge graph that\ncharacterizes the electricity consumption of the households and contextualizes\nit with household related properties enabling semantic queries and\ninteroperability with other open knowledge bases like Wikidata and DBpedia.\nThis structured data can be utilized to inform various stakeholders towards\ndata-driven policy and business development.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Vid Hanel",
            "Bla Bertalani",
            "Carolina Fortuna"
        ],
        "published": "2024-05-29T08:30:34Z"
    },
    {
        "title": "Topological Perspectives on Optimal Multimodal Embedding Spaces",
        "link": "http://arxiv.org/abs/2405.18867v1",
        "abstract": "Recent strides in multimodal model development have ignited a paradigm shift\nin the realm of text-to-image generation. Among these advancements, CLIP stands\nout as a remarkable achievement which is a sophisticated autoencoder adept at\nencoding both textual and visual information within a unified latent space.\nThis paper delves into a comparative analysis between CLIP and its recent\ncounterpart, CLOOB. To unravel the intricate distinctions within the embedding\nspaces crafted by these models, we employ topological data analysis. Our\napproach encompasses a comprehensive examination of the modality gap drivers,\nthe clustering structures existing across both high and low dimensions, and the\npivotal role that dimension collapse plays in shaping their respective\nembedding spaces. Empirical experiments substantiate the implications of our\nanalyses on downstream performance across various contextual scenarios. Through\nthis investigation, we aim to shed light on the nuanced intricacies that\nunderlie the comparative efficacy of CLIP and CLOOB, offering insights into\ntheir respective strengths and weaknesses, and providing a foundation for\nfurther refinement and advancement in multimodal model research.",
        "subjects": [
            "cs.AI",
            "68T05"
        ],
        "authors": [
            "Abdul Aziz A. B",
            "A. B Abdul Rahim"
        ],
        "published": "2024-05-29T08:28:23Z"
    },
    {
        "title": "The Structural Complexity Landscape of Finding Balance-Fair Shortest\n  Paths",
        "link": "http://arxiv.org/abs/2405.18866v1",
        "abstract": "We study the parameterized complexity of finding shortest s-t-paths with an\nadditional fairness requirement. The task is to compute a shortest path in a\nvertex-colored graph where each color appears (roughly) equally often in the\nsolution. We provide a complete picture of the parameterized complexity\nlandscape of the problem with respect to structural parameters by showing a\ntetrachotomy including polynomial kernels, fixed-parameter tractability,\nXP-time algorithms (and W[1]-hardness), and para-NP-hardness.",
        "subjects": [
            "cs.DS",
            "cs.CC"
        ],
        "authors": [
            "Matthias Bentert",
            "Leon Kellerhals",
            "Rolf Niedermeier"
        ],
        "published": "2024-05-29T08:27:59Z"
    },
    {
        "title": "Neural Radiance Fields for Novel View Synthesis in Monocular Gastroscopy",
        "link": "http://arxiv.org/abs/2405.18863v1",
        "abstract": "Enabling the synthesis of arbitrarily novel viewpoint images within a\npatient's stomach from pre-captured monocular gastroscopic images is a\npromising topic in stomach diagnosis. Typical methods to achieve this objective\nintegrate traditional 3D reconstruction techniques, including\nstructure-from-motion (SfM) and Poisson surface reconstruction. These methods\nproduce explicit 3D representations, such as point clouds and meshes, thereby\nenabling the rendering of the images from novel viewpoints. However, the\nexistence of low-texture and non-Lambertian regions within the stomach often\nresults in noisy and incomplete reconstructions of point clouds and meshes,\nhindering the attainment of high-quality image rendering. In this paper, we\napply the emerging technique of neural radiance fields (NeRF) to monocular\ngastroscopic data for synthesizing photo-realistic images for novel viewpoints.\nTo address the performance degradation due to view sparsity in local regions of\nmonocular gastroscopy, we incorporate geometry priors from a pre-reconstructed\npoint cloud into the training of NeRF, which introduces a novel geometry-based\nloss to both pre-captured observed views and generated unobserved views.\nCompared to other recent NeRF methods, our approach showcases high-fidelity\nimage renderings from novel viewpoints within the stomach both qualitatively\nand quantitatively.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zijie Jiang",
            "Yusuke Monno",
            "Masatoshi Okutomi",
            "Sho Suzuki",
            "Kenji Miki"
        ],
        "published": "2024-05-29T08:25:04Z"
    },
    {
        "title": "Domain-Inspired Sharpness-Aware Minimization Under Domain Shifts",
        "link": "http://arxiv.org/abs/2405.18861v1",
        "abstract": "This paper presents a Domain-Inspired Sharpness-Aware Minimization (DISAM)\nalgorithm for optimization under domain shifts. It is motivated by the\ninconsistent convergence degree of SAM across different domains, which induces\noptimization bias towards certain domains and thus impairs the overall\nconvergence. To address this issue, we consider the domain-level convergence\nconsistency in the sharpness estimation to prevent the overwhelming (deficient)\nperturbations for less (well) optimized domains. Specifically, DISAM introduces\nthe constraint of minimizing variance in the domain loss, which allows the\nelastic gradient calibration in perturbation generation: when one domain is\noptimized above the averaging level \\textit{w.r.t.} loss, the gradient\nperturbation towards that domain will be weakened automatically, and vice\nversa. Under this mechanism, we theoretically show that DISAM can achieve\nfaster overall convergence and improved generalization in principle when\ninconsistent convergence emerges. Extensive experiments on various domain\ngeneralization benchmarks show the superiority of DISAM over a range of\nstate-of-the-art methods. Furthermore, we show the superior efficiency of DISAM\nin parameter-efficient fine-tuning combined with the pretraining models. The\nsource code is released at https://github.com/MediaBrain-SJTU/DISAM.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Ruipeng Zhang",
            "Ziqing Fan",
            "Jiangchao Yao",
            "Ya Zhang",
            "Yanfeng Wang"
        ],
        "published": "2024-05-29T08:22:33Z"
    },
    {
        "title": "Empowering Embodied Manipulation: A Bimanual-Mobile Robot Manipulation\n  Dataset for Household Tasks",
        "link": "http://arxiv.org/abs/2405.18860v1",
        "abstract": "As Embodied AI advances, it increasingly enables robots to handle the\ncomplexity of household manipulation tasks more effectively. However, the\napplication of robots in these settings remains limited due to the scarcity of\nbimanual-mobile robot manipulation datasets. Existing datasets either focus\nsolely on simple grasping tasks using single-arm robots without mobility, or\ncollect sensor data limited to a narrow scope of sensory inputs. As a result,\nthese datasets often fail to encapsulate the intricate and dynamic nature of\nreal-world tasks that bimanual-mobile robots are expected to perform. To\naddress these limitations, we introduce BRMData, a Bimanual-mobile Robot\nManipulation Dataset designed specifically for household applications. The\ndataset includes 10 diverse household tasks, ranging from simple single-arm\nmanipulation to more complex dual-arm and mobile manipulations. It is collected\nusing multi-view and depth-sensing data acquisition strategies. Human-robot\ninteractions and multi-object manipulations are integrated into the task\ndesigns to closely simulate real-world household applications. Moreover, we\npresent a Manipulation Efficiency Score (MES) metric to evaluate both the\nprecision and efficiency of robot manipulation methods. BRMData aims to drive\nthe development of versatile robot manipulation technologies, specifically\nfocusing on advancing imitation learning methods from human demonstrations. The\ndataset is now open-sourced and available at https://embodiedrobot.github.io/,\nenhancing research and development efforts in the field of Embodied\nManipulation.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Tianle Zhang",
            "Dongjiang Li",
            "Yihang Li",
            "Zecui Zeng",
            "Lin Zhao",
            "Lei Sun",
            "Yue Chen",
            "Xuelong Wei",
            "Yibing Zhan",
            "Lusong Li",
            "Xiaodong He"
        ],
        "published": "2024-05-29T08:15:56Z"
    },
    {
        "title": "SSGA-Net: Stepwise Spatial Global-local Aggregation Networks for for\n  Autonomous Driving",
        "link": "http://arxiv.org/abs/2405.18857v1",
        "abstract": "Visual-based perception is the key module for autonomous driving. Among those\nvisual perception tasks, video object detection is a primary yet challenging\none because of feature degradation caused by fast motion or multiple poses.\nCurrent models usually aggregate features from the neighboring frames to\nenhance the object representations for the task heads to generate more accurate\npredictions. Though getting better performance, these methods rely on the\ninformation from the future frames and suffer from high computational\ncomplexity. Meanwhile, the aggregation process is not reconfigurable during the\ninference time. These issues make most of the existing models infeasible for\nonline applications. To solve these problems, we introduce a stepwise spatial\nglobal-local aggregation network. Our proposed models mainly contain three\nparts: 1). Multi-stage stepwise network gradually refines the predictions and\nobject representations from the previous stage; 2). Spatial global-local\naggregation fuses the local information from the neighboring frames and global\nsemantics from the current frame to eliminate the feature degradation; 3).\nDynamic aggregation strategy stops the aggregation process early based on the\nrefinement results to remove redundancy and improve efficiency. Extensive\nexperiments on the ImageNet VID benchmark validate the effectiveness and\nefficiency of our proposed models.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yiming Cui",
            "Cheng Han",
            "Dongfang Liu"
        ],
        "published": "2024-05-29T08:12:51Z"
    },
    {
        "title": "Supervised Contrastive Learning for Snapshot Spectral Imaging Face\n  Anti-Spoofing",
        "link": "http://arxiv.org/abs/2405.18853v1",
        "abstract": "This study reveals a cutting-edge re-balanced contrastive learning strategy\naimed at strengthening face anti-spoofing capabilities within facial\nrecognition systems, with a focus on countering the challenges posed by printed\nphotos, and highly realistic silicone or latex masks. Leveraging the HySpeFAS\ndataset, which benefits from Snapshot Spectral Imaging technology to provide\nhyperspectral images, our approach harmonizes class-level contrastive learning\nwith data resampling and an innovative real-face oriented reweighting\ntechnique. This method effectively mitigates dataset imbalances and reduces\nidentity-related biases. Notably, our strategy achieved an unprecedented\n0.0000\\% Average Classification Error Rate (ACER) on the HySpeFAS dataset,\nranking first at the Chalearn Snapshot Spectral Imaging Face Anti-spoofing\nChallenge on CVPR 2024.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Chuanbiao Song",
            "Yan Hong",
            "Jun Lan",
            "Huijia Zhu",
            "Weiqiang Wang",
            "Jianfu Zhang"
        ],
        "published": "2024-05-29T08:03:52Z"
    },
    {
        "title": "LetsMap: Unsupervised Representation Learning for Semantic BEV Mapping",
        "link": "http://arxiv.org/abs/2405.18852v1",
        "abstract": "Semantic Bird's Eye View (BEV) maps offer a rich representation with strong\nocclusion reasoning for various decision making tasks in autonomous driving.\nHowever, most BEV mapping approaches employ a fully supervised learning\nparadigm that relies on large amounts of human-annotated BEV ground truth data.\nIn this work, we address this limitation by proposing the first unsupervised\nrepresentation learning approach to generate semantic BEV maps from a monocular\nfrontal view (FV) image in a label-efficient manner. Our approach pretrains the\nnetwork to independently reason about scene geometry and scene semantics using\ntwo disjoint neural pathways in an unsupervised manner and then finetunes it\nfor the task of semantic BEV mapping using only a small fraction of labels in\nthe BEV. We achieve label-free pretraining by exploiting spatial and temporal\nconsistency of FV images to learn scene geometry while relying on a novel\ntemporal masked autoencoder formulation to encode the scene representation.\nExtensive evaluations on the KITTI-360 and nuScenes datasets demonstrate that\nour approach performs on par with the existing state-of-the-art approaches\nwhile using only 1% of BEV labels and no additional labeled data.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "authors": [
            "Nikhil Gosala",
            "Krsat Petek",
            "B Ravi Kiran",
            "Senthil Yogamani",
            "Paulo Drews-Jr",
            "Wolfram Burgard",
            "Abhinav Valada"
        ],
        "published": "2024-05-29T08:03:36Z"
    },
    {
        "title": "SFANet: Spatial-Frequency Attention Network for Weather Forecasting",
        "link": "http://arxiv.org/abs/2405.18849v1",
        "abstract": "Weather forecasting plays a critical role in various sectors, driving\ndecision-making and risk management. However, traditional methods often\nstruggle to capture the complex dynamics of meteorological systems,\nparticularly in the presence of high-resolution data. In this paper, we propose\nthe Spatial-Frequency Attention Network (SFANet), a novel deep learning\nframework designed to address these challenges and enhance the accuracy of\nspatiotemporal weather prediction. Drawing inspiration from the limitations of\nexisting methodologies, we present an innovative approach that seamlessly\nintegrates advanced token mixing and attention mechanisms. By leveraging both\npooling and spatial mixing strategies, SFANet optimizes the processing of\nhigh-dimensional spatiotemporal sequences, preserving inter-component\nrelational information and modeling extensive long-range relationships. To\nfurther enhance feature integration, we introduce a novel spatial-frequency\nattention module, enabling the model to capture intricate cross-modal\ncorrelations. Our extensive experimental evaluation on two distinct datasets,\nthe Storm EVent ImageRy (SEVIR) and the Institute for Climate and Application\nResearch (ICAR) - El Ni\\~{n}o Southern Oscillation (ENSO) dataset, demonstrates\nthe remarkable performance of SFANet. Notably, SFANet achieves substantial\nadvancements over state-of-the-art methods, showcasing its proficiency in\nforecasting precipitation patterns and predicting El Ni\\~{n}o events.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jiaze Wang",
            "Hao Chen",
            "Hongcan Xu",
            "Jinpeng Li",
            "Bowen Wang",
            "Kun Shao",
            "Furui Liu",
            "Huaxi Chen",
            "Guangyong Chen",
            "Pheng-Ann Heng"
        ],
        "published": "2024-05-29T08:00:15Z"
    },
    {
        "title": "Anomaly Detection by Context Contrasting",
        "link": "http://arxiv.org/abs/2405.18848v1",
        "abstract": "Anomaly Detection focuses on identifying samples that deviate from the norm.\nWhen working with high-dimensional data such as images, a crucial requirement\nfor detecting anomalous patterns is learning lower-dimensional representations\nthat capture normal concepts seen during training. Recent advances in\nself-supervised learning have shown great promise in this regard. However, many\nof the most successful self-supervised anomaly detection methods assume prior\nknowledge about the structure of anomalies and leverage synthetic anomalies\nduring training. Yet, in many real-world applications, we do not know what to\nexpect from unseen data, and we can solely leverage knowledge about normal\ndata. In this work, we propose Con2, which addresses this problem by setting\nnormal training data into distinct contexts while preserving its normal\nproperties, letting us observe the data from different perspectives. Unseen\nnormal data consequently adheres to learned context representations while\nanomalies fail to do so, letting us detect them without any knowledge about\nanomalies during training. Our experiments demonstrate that our approach\nachieves state-of-the-art performance on various benchmarks while exhibiting\nsuperior performance in a more realistic healthcare setting, where knowledge\nabout potential anomalies is often scarce.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Alain Ryser",
            "Thomas M. Sutter",
            "Alexander Marx",
            "Julia E. Vogt"
        ],
        "published": "2024-05-29T07:59:06Z"
    },
    {
        "title": "Defining Requirements Strategies in Agile: A Design Science Research\n  Study",
        "link": "http://arxiv.org/abs/2405.18847v1",
        "abstract": "Research shows that many of the challenges currently encountered with agile\ndevelopment are related to requirements engineering. Based on design science\nresearch, this paper investigates critical challenges that arise in agile\ndevelopment from an undefined requirements strategy. We explore potential ways\nto address these challenges and synthesize the key building blocks of\nrequirements strategies. Our design science research rests on a multiple case\nstudy with three industrial cases in the domains of communication technology,\nsecurity services, and automotive. We relied on a total of 20 interviews, two\nworkshops, participant observation in two cases, and document analysis in each\nof the cases to understand concrete challenges and workflows. In each case, we\ndefine a requirements strategy in collaboration with process managers and\nexperienced engineers. From this experience, we extract guidelines for defining\nrequirements strategies in agile development.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Amna Pir Muhammad",
            "Eric Knauss",
            "Odzaya Batsaikhan",
            "Nassiba El Haskouri",
            "Yi-Chun Lin",
            "Alessia Knauss"
        ],
        "published": "2024-05-29T07:57:32Z"
    },
    {
        "title": "Simulation, Modelling and Classification of Wiki Contributors: Spotting\n  The Good, The Bad, and The Ugly",
        "link": "http://dx.doi.org/10.1016/j.simpat.2022.102616",
        "abstract": "Data crowdsourcing is a data acquisition process where groups of voluntary\ncontributors feed platforms with highly relevant data ranging from news,\ncomments, and media to knowledge and classifications. It typically processes\nuser-generated data streams to provide and refine popular services such as\nwikis, collaborative maps, e-commerce sites, and social networks. Nevertheless,\nthis modus operandi raises severe concerns regarding ill-intentioned data\nmanipulation in adversarial environments. This paper presents a simulation,\nmodelling, and classification approach to automatically identify human and\nnon-human (bots) as well as benign and malign contributors by using data\nfabrication to balance classes within experimental data sets, data stream\nmodelling to build and update contributor profiles and, finally, autonomic data\nstream classification. By employing WikiVoyage - a free worldwide wiki travel\nguide open to contribution from the general public - as a testbed, our approach\nproves to significantly boost the confidence and quality of the classifier by\nusing a class-balanced data stream, comprising both real and synthetic data.\nOur empirical results show that the proposed method distinguishes between\nbenign and malign bots as well as human contributors with a classification\naccuracy of up to 92 %.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Silvia Garca Mndez",
            "Ftima Leal",
            "Benedita Malheiro",
            "Juan Carlos Burguillo Rial",
            "Bruno Veloso",
            "Adriana E. Chis",
            "Horacio Gonzlez Vlez"
        ],
        "published": "2024-05-29T07:56:08Z"
    },
    {
        "title": "Optical IRS for Visible Light Communication: Modeling, Design, and Open\n  Issues",
        "link": "http://arxiv.org/abs/2405.18844v1",
        "abstract": "Optical intelligent reflecting surface (OIRS) offers a new and effective\napproach to resolving the line-of-sight blockage issue in visible light\ncommunication (VLC) by enabling redirection of light to bypass obstacles,\nthereby dramatically enhancing indoor VLC coverage and reliability. This\narticle provides a comprehensive overview of OIRS for VLC, including channel\nmodeling, design techniques, and open issues. First, we present the\ncharacteristics of OIRS-reflected channels and introduce two practical models,\nnamely, optics model and association model, which are then compared in terms of\napplicable conditions, configuration methods, and channel parameters. Next,\nunder the more practically appealing association model, we discuss the main\ndesign techniques for OIRS-aided VLC systems, including beam alignment, channel\nestimation, and OIRS reflection optimization. Finally, open issues are\nidentified to stimulate future research in this area.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Shiyuan Sun",
            "Fang Yang",
            "Weidong Mei",
            "Jian Song",
            "Zhu Han",
            "Rui Zhang"
        ],
        "published": "2024-05-29T07:54:17Z"
    },
    {
        "title": "Data-driven Machinery Fault Detection: A Comprehensive Review",
        "link": "http://arxiv.org/abs/2405.18843v1",
        "abstract": "In this era of advanced manufacturing, it's now more crucial than ever to\ndiagnose machine faults as early as possible to guarantee their safe and\nefficient operation. With the massive surge in industrial big data and\nadvancement in sensing and computational technologies, data-driven Machinery\nFault Diagnosis (MFD) solutions based on machine/deep learning approaches have\nbeen used ubiquitously in manufacturing. Timely and accurately identifying\nfaulty machine signals is vital in industrial applications for which many\nrelevant solutions have been proposed and are reviewed in many articles.\nDespite the availability of numerous solutions and reviews on MFD, existing\nworks often lack several aspects. Most of the available literature has limited\napplicability in a wide range of manufacturing settings due to their\nconcentration on a particular type of equipment or method of analysis.\nAdditionally, discussions regarding the challenges associated with implementing\ndata-driven approaches, such as dealing with noisy data, selecting appropriate\nfeatures, and adapting models to accommodate new or unforeseen faults, are\noften superficial or completely overlooked. Thus, this survey provides a\ncomprehensive review of the articles using different types of machine learning\napproaches for the detection and diagnosis of various types of machinery\nfaults, highlights their strengths and limitations, provides a review of the\nmethods used for condition-based analyses, comprehensively discusses the\navailable machinery fault datasets, introduces future researchers to the\npossible challenges they have to encounter while using these approaches for MFD\nand recommends the probable solutions to mitigate those problems. The future\nresearch prospects are also pointed out for a better understanding of the\nfield. We believe this article will help researchers and contribute to the\nfurther development of the field.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Dhiraj Neupane",
            "Mohamed Reda Bouadjenek",
            "Richard Dazeley",
            "Sunil Aryal"
        ],
        "published": "2024-05-29T07:50:47Z"
    },
    {
        "title": "Descriptive Image Quality Assessment in the Wild",
        "link": "http://arxiv.org/abs/2405.18842v1",
        "abstract": "With the rapid advancement of Vision Language Models (VLMs), VLM-based Image\nQuality Assessment (IQA) seeks to describe image quality linguistically to\nalign with human expression and capture the multifaceted nature of IQA tasks.\nHowever, current methods are still far from practical usage. First, prior works\nfocus narrowly on specific sub-tasks or settings, which do not align with\ndiverse real-world applications. Second, their performance is sub-optimal due\nto limitations in dataset coverage, scale, and quality. To overcome these\nchallenges, we introduce Depicted image Quality Assessment in the Wild\n(DepictQA-Wild). Our method includes a multi-functional IQA task paradigm that\nencompasses both assessment and comparison tasks, brief and detailed responses,\nfull-reference and non-reference scenarios. We introduce a\nground-truth-informed dataset construction approach to enhance data quality,\nand scale up the dataset to 495K under the brief-detail joint framework.\nConsequently, we construct a comprehensive, large-scale, and high-quality\ndataset, named DQ-495K. We also retain image resolution during training to\nbetter handle resolution-related quality issues, and estimate a confidence\nscore that is helpful to filter out low-quality responses. Experimental results\ndemonstrate that DepictQA-Wild significantly outperforms traditional\nscore-based methods, prior VLM-based IQA models, and proprietary GPT-4V in\ndistortion identification, instant rating, and reasoning tasks. Our advantages\nare further confirmed by real-world applications including assessing the\nweb-downloaded images and ranking model-processed images. Datasets and codes\nwill be released in https://depictqa.github.io/depictqa-wild/.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhiyuan You",
            "Jinjin Gu",
            "Zheyuan Li",
            "Xin Cai",
            "Kaiwen Zhu",
            "Tianfan Xue",
            "Chao Dong"
        ],
        "published": "2024-05-29T07:49:15Z"
    },
    {
        "title": "Managing Human Factors in Automated Vehicle Development: Towards\n  Challenges and Practices",
        "link": "http://arxiv.org/abs/2405.18841v1",
        "abstract": "Due to the technical complexity and social impact, automated vehicle (AV)\ndevelopment challenges the current state of automotive engineering practice.\nResearch shows that it is important to consider human factors (HF) knowledge\nwhen developing AVs to make them safe and accepted. This study explores the\ncurrent practices and challenges of the automotive industries for incorporating\nHF requirements during agile AV development. We interviewed ten industry\nprofessionals from several Swedish automotive companies, including HF experts\nand AV engineers. Based on our qualitative analysis of the semi-structured\ninterviews, a number of current approaches for communicating and incorporating\nHF knowledge into agile AV development and associated challenges are discussed.\nOur findings may help to focus future research on issues that are critical to\neffectively incorporate HF knowledge into agile AV development.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Amna Pir Muhammad",
            "Eric Knauss",
            "Jonas Brgman",
            "Alessia Knauss"
        ],
        "published": "2024-05-29T07:48:43Z"
    },
    {
        "title": "Parameter-efficient Fine-tuning in Hyperspherical Space for\n  Open-vocabulary Semantic Segmentation",
        "link": "http://arxiv.org/abs/2405.18840v1",
        "abstract": "Open-vocabulary semantic segmentation seeks to label each pixel in an image\nwith arbitrary text descriptions. Vision-language foundation models, especially\nCLIP, have recently emerged as powerful tools for acquiring open-vocabulary\ncapabilities. However, fine-tuning CLIP to equip it with pixel-level prediction\nability often suffers three issues: 1) high computational cost, 2) misalignment\nbetween the two inherent modalities of CLIP, and 3) degraded generalization\nability on unseen categories. To address these issues, we propose H-CLIP a\nsymmetrical parameter-efficient fine-tuning (PEFT) strategy conducted in\nhyperspherical space for both of the two CLIP modalities. Specifically, the\nPEFT strategy is achieved by a series of efficient block-diagonal learnable\ntransformation matrices and a dual cross-relation communication module among\nall learnable matrices. Since the PEFT strategy is conducted symmetrically to\nthe two CLIP modalities, the misalignment between them is mitigated.\nFurthermore, we apply an additional constraint to PEFT on the CLIP text encoder\naccording to the hyperspherical energy principle, i.e., minimizing\nhyperspherical energy during fine-tuning preserves the intrinsic structure of\nthe original parameter space, to prevent the destruction of the generalization\nability offered by the CLIP text encoder. Extensive evaluations across various\nbenchmarks show that H-CLIP achieves new SOTA open-vocabulary semantic\nsegmentation results while only requiring updating approximately 4% of the\ntotal parameters of CLIP.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zelin Peng",
            "Zhengqin Xu",
            "Zhilin Zeng",
            "Yaoming Wang",
            "Lingxi Xie",
            "Qi Tian",
            "Wei Shen"
        ],
        "published": "2024-05-29T07:41:34Z"
    },
    {
        "title": "MEGA: Masked Generative Autoencoder for Human Mesh Recovery",
        "link": "http://arxiv.org/abs/2405.18839v1",
        "abstract": "Human Mesh Recovery (HMR) from a single RGB image is a highly ambiguous\nproblem, as similar 2D projections can correspond to multiple 3D\ninterpretations. Nevertheless, most HMR methods overlook this ambiguity and\nmake a single prediction without accounting for the associated uncertainty. A\nfew approaches generate a distribution of human meshes, enabling the sampling\nof multiple predictions; however, none of them is competitive with the latest\nsingle-output model when making a single prediction. This work proposes a new\napproach based on masked generative modeling. By tokenizing the human pose and\nshape, we formulate the HMR task as generating a sequence of discrete tokens\nconditioned on an input image. We introduce MEGA, a MaskEd Generative\nAutoencoder trained to recover human meshes from images and partial human mesh\ntoken sequences. Given an image, our flexible generation scheme allows us to\npredict a single human mesh in deterministic mode or to generate multiple human\nmeshes in stochastic mode. MEGA enables us to propose multiple outputs and to\nevaluate the uncertainty of the predictions. Experiments on in-the-wild\nbenchmarks show that MEGA achieves state-of-the-art performance in\ndeterministic and stochastic modes, outperforming single-output and\nmulti-output approaches.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Gunol Fiche",
            "Simon Leglaive",
            "Xavier Alameda-Pineda",
            "Francesc Moreno-Noguer"
        ],
        "published": "2024-05-29T07:40:31Z"
    },
    {
        "title": "Requirements Strategy for Managing Human Factors in Automated Vehicle\n  Development",
        "link": "http://arxiv.org/abs/2405.18838v1",
        "abstract": "The integration of human factors (HF) knowledge is crucial when developing\nsafety-critical systems, such as automated vehicles (AVs). Ensuring that HF\nknowledge is considered continuously throughout the AV development process is\nessential for several reasons, including efficacy, safety, and acceptance of\nthese advanced systems. However, it is challenging to include HF as\nrequirements in agile development. Recently, Requirements Strategies have been\nsuggested to address requirements engineering challenges in agile development.\nBy applying the concept of Requirements Strategies as a lens to the\ninvestigation of HF requirements in agile development of AVs, this paper\narrives at three areas for investigation: a) ownership and responsibility for\nHF requirements, b) structure of HF requirements and information models, and c)\ndefinition of work and feature flows related to HF requirements. Based on 13\nsemi-structured interviews with professionals from the global automotive\nindustry, we provide qualitative insights in these three areas. The diverse\nperspectives and experiences shared by the interviewees provide insightful\nviews and helped to reason about the potential solution spaces in each area for\nintegrating HF within the industry, highlighting the real-world practices and\nstrategies used.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Amna Pir Muhammad",
            "Alessia Knauss",
            "Eric Knauss",
            "Jonas Brgman"
        ],
        "published": "2024-05-29T07:37:57Z"
    },
    {
        "title": "Do Finetti: On Causal Effects for Exchangeable Data",
        "link": "http://arxiv.org/abs/2405.18836v1",
        "abstract": "We study causal effect estimation in a setting where the data are not i.i.d.\n(independent and identically distributed). We focus on exchangeable data\nsatisfying an assumption of independent causal mechanisms. Traditional causal\neffect estimation frameworks, e.g., relying on structural causal models and\ndo-calculus, are typically limited to i.i.d. data and do not extend to more\ngeneral exchangeable generative processes, which naturally arise in\nmulti-environment data. To address this gap, we develop a generalized framework\nfor exchangeable data and introduce a truncated factorization formula that\nfacilitates both the identification and estimation of causal effects in our\nsetting. To illustrate potential applications, we introduce a causal P\\'olya\nurn model and demonstrate how intervention propagates effects in exchangeable\ndata settings. Finally, we develop an algorithm that performs simultaneous\ncausal discovery and effect estimation given multi-environment data.",
        "subjects": [
            "stat.ME",
            "cs.LG"
        ],
        "authors": [
            "Siyuan Guo",
            "Chi Zhang",
            "Karthika Mohan",
            "Ferenc Huszr",
            "Bernhard Schlkopf"
        ],
        "published": "2024-05-29T07:31:18Z"
    },
    {
        "title": "Geometric Bipartite Matching is in NC",
        "link": "http://arxiv.org/abs/2405.18833v1",
        "abstract": "In this work, we study the parallel complexity of the Euclidean\nminimum-weight perfect matching (EWPM) problem. Here our graph is the complete\nbipartite graph $G$ on two sets of points $A$ and $B$ in $\\mathbb{R}^2$ and the\nweight of each edge is the Euclidean distance between the corresponding points.\nThe weighted perfect matching problem on general bipartite graphs is known to\nbe in RNC [Mulmuley, Vazirani, and Vazirani, 1987], and Quasi-NC [Fenner,\nGurjar, and Thierauf, 2016]. Both of these results work only when the weights\nare of $O(\\log n)$ bits. It is a long-standing open question to show the\nproblem to be in NC.\n  First, we show that for EWPM, a linear number of bits of approximation is\nrequired to distinguish between the minimum-weight perfect matching and other\nperfect matchings. Next, we show that the EWPM problem that allows up to\n$\\frac{1}{poly(n)}$ additive error, is in NC.",
        "subjects": [
            "cs.CG",
            "cs.CC"
        ],
        "authors": [
            "Sujoy Bhore",
            "Sarfaraz Equbal",
            "Rohit Gurjar"
        ],
        "published": "2024-05-29T07:24:23Z"
    },
    {
        "title": "MoNDE: Mixture of Near-Data Experts for Large-Scale Sparse Models",
        "link": "http://arxiv.org/abs/2405.18832v1",
        "abstract": "Mixture-of-Experts (MoE) large language models (LLM) have memory requirements\nthat often exceed the GPU memory capacity, requiring costly parameter movement\nfrom secondary memories to the GPU for expert computation. In this work, we\npresent Mixture of Near-Data Experts (MoNDE), a near-data computing solution\nthat efficiently enables MoE LLM inference. MoNDE reduces the volume of MoE\nparameter movement by transferring only the $\\textit{hot}$ experts to the GPU,\nwhile computing the remaining $\\textit{cold}$ experts inside the host memory\ndevice. By replacing the transfers of massive expert parameters with the ones\nof small activations, MoNDE enables far more communication-efficient MoE\ninference, thereby resulting in substantial speedups over the existing\nparameter offloading frameworks for both encoder and decoder operations.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.AR"
        ],
        "authors": [
            "Taehyun Kim",
            "Kwanseok Choi",
            "Youngmock Cho",
            "Jaehoon Cho",
            "Hyuk-Jae Lee",
            "Jaewoong Sim"
        ],
        "published": "2024-05-29T07:23:29Z"
    },
    {
        "title": "Evaluating Zero-Shot GPT-4V Performance on 3D Visual Question Answering\n  Benchmarks",
        "link": "http://arxiv.org/abs/2405.18831v1",
        "abstract": "As interest in \"reformulating\" the 3D Visual Question Answering (VQA) problem\nin the context of foundation models grows, it is imperative to assess how these\nnew paradigms influence existing closed-vocabulary datasets. In this case\nstudy, we evaluate the zero-shot performance of foundational models (GPT-4\nVision and GPT-4) on well-established 3D VQA benchmarks, namely 3D-VQA and\nScanQA. We provide an investigation to contextualize the performance of\nGPT-based agents relative to traditional modeling approaches. We find that\nGPT-based agents without any fine-tuning perform on par with the closed\nvocabulary approaches. Our findings corroborate recent results that \"blind\"\nmodels establish a surprisingly strong baseline in closed-vocabulary settings.\nWe demonstrate that agents benefit significantly from scene-specific vocabulary\nvia in-context textual grounding. By presenting a preliminary comparison with\nprevious baselines, we hope to inform the community's ongoing efforts to refine\nmulti-modal 3D benchmarks.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Simranjit Singh",
            "Georgios Pavlakos",
            "Dimitrios Stamoulis"
        ],
        "published": "2024-05-29T07:20:28Z"
    },
    {
        "title": "Visual Servoing Based on 3D Features: Design and Implementation for\n  Robotic Insertion Tasks",
        "link": "http://arxiv.org/abs/2405.18830v1",
        "abstract": "This paper proposes a feature-based Visual Servoing (VS) method for insertion\ntask skills. A camera mounted on the robot's end-effector provides the pose\nrelative to a cylinder (hole), allowing a contact-free and damage-free search\nof the hole and avoiding uncertainties emerging when the pose is computed via\nrobot kinematics. Two points located on the hole's principal axis and three\nmutually orthogonal planes defining the flange's reference frame are associated\nwith the pose of the hole and the flange, respectively. The proposed VS drives\nto zero the distance between the two points and the three planes aligning the\nrobot's flange with the hole's direction. Compared with conventional VS where\nthe Jacobian is difficult to compute in practice, the proposed featured-based\nuses a Jacobian easily calculated from the measured hole pose. Furthermore, the\nfeature-based VS design considers the robot's maximum cartesian velocity. The\nVS method is implemented in an industrial robot and the experimental results\nsupport its usefulness.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Antonio Rosales",
            "Tapio Heikkil",
            "Markku Suomalainen"
        ],
        "published": "2024-05-29T07:19:44Z"
    },
    {
        "title": "Theoretical insights and an experimental comparison of tango trees and\n  multi-splay trees",
        "link": "http://arxiv.org/abs/2405.18825v1",
        "abstract": "The tango tree is the first proven $O(\\lg \\lg n)$-competitive binary search\ntree (BST). We present the first ever experimental implementation of tango\ntrees and compare the running time of the tango tree with the multi-splay tree\nand the splay tree on a variety of families of access sequences. We construct\naccess sequences that are intended to test specific properties of BSTs. The\nresults of the other experiments demonstrate the optimality of the splay tree\nand multi-splay tree on these accesses, while simultaneously demonstrating the\ntango trees inability to achieve optimality. We prove that the running time of\ntango trees on the sequential access is $\\Theta(n \\lg \\lg n)$, which provides\ninsight into why the $\\Theta(\\lg \\lg n)$ slow down exists on many access\nsequences. Motivated by experimental results, we conduct a deeper analysis of\nthe working set access on multi-splay trees, leading to new insights about\nmulti-splay tree behavior. Finally, all of the experiments also reveal insights\nabout large constants and lower order terms in the multi-splay tree, which make\nit less practical than the splay tree, even though its proven competitive bound\nis tighter.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Khaleel Al-Adhami",
            "Dev Chheda"
        ],
        "published": "2024-05-29T07:11:58Z"
    },
    {
        "title": "Node Injection Attack Based on Label Propagation Against Graph Neural\n  Network",
        "link": "http://dx.doi.org/10.1109/TCSS.2024.3395794",
        "abstract": "Graph Neural Network (GNN) has achieved remarkable success in various graph\nlearning tasks, such as node classification, link prediction and graph\nclassification. The key to the success of GNN lies in its effective structure\ninformation representation through neighboring aggregation. However, the\nattacker can easily perturb the aggregation process through injecting fake\nnodes, which reveals that GNN is vulnerable to the graph injection attack.\nExisting graph injection attack methods primarily focus on damaging the\nclassical feature aggregation process while overlooking the neighborhood\naggregation process via label propagation. To bridge this gap, we propose the\nlabel-propagation-based global injection attack (LPGIA) which conducts the\ngraph injection attack on the node classification task. Specifically, we\nanalyze the aggregation process from the perspective of label propagation and\ntransform the graph injection attack problem into a global injection label\nspecificity attack problem. To solve this problem, LPGIA utilizes a label\npropagation-based strategy to optimize the combinations of the nodes connected\nto the injected node. Then, LPGIA leverages the feature mapping to generate\nmalicious features for injected nodes. In extensive experiments against\nrepresentative GNNs, LPGIA outperforms the previous best-performing injection\nattack method in various datasets, demonstrating its superiority and\ntransferability.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Peican Zhu",
            "Zechen Pan",
            "Keke Tang",
            "Xiaodong Cui",
            "Jinhuan Wang",
            "Qi Xuan"
        ],
        "published": "2024-05-29T07:09:16Z"
    },
    {
        "title": "Why Reinforcement Learning in Energy Systems Needs Explanations",
        "link": "http://arxiv.org/abs/2405.18823v1",
        "abstract": "With economic development, the complexity of infrastructure has increased\ndrastically. Similarly, with the shift from fossil fuels to renewable sources\nof energy, there is a dire need for such systems that not only predict and\nforecast with accuracy but also help in understanding the process of\npredictions. Artificial intelligence and machine learning techniques have\nhelped in finding out wellperforming solutions to different problems in the\nenergy sector. However, the usage of state-of-the-art techniques like\nreinforcement learning is not surprisingly convincing. This paper discusses the\napplication of reinforcement techniques in energy systems and how explanations\nof these models can be helpful",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Hallah Shahid Butt",
            "Benjamin Schfer"
        ],
        "published": "2024-05-29T07:09:00Z"
    },
    {
        "title": "Toxicity Detection for Free",
        "link": "http://arxiv.org/abs/2405.18822v1",
        "abstract": "Current LLMs are generally aligned to follow safety requirements and tend to\nrefuse toxic prompts. However, LLMs can fail to refuse toxic prompts or be\novercautious and refuse benign examples. In addition, state-of-the-art toxicity\ndetectors have low TPRs at low FPR, incurring high costs in real-world\napplications where toxic examples are rare. In this paper, we explore\nModeration Using LLM Introspection (MULI), which detects toxic prompts using\nthe information extracted directly from LLMs themselves. We found significant\ngaps between benign and toxic prompts in the distribution of alternative\nrefusal responses and in the distribution of the first response token's logits.\nThese gaps can be used to detect toxicities: We show that a toy model based on\nthe logits of specific starting tokens gets reliable performance, while\nrequiring no training or additional computational cost. We build a more robust\ndetector using a sparse logistic regression model on the first response token\nlogits, which greatly exceeds SOTA detectors under multiple metrics.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Zhanhao Hu",
            "Julien Piet",
            "Geng Zhao",
            "Jiantao Jiao",
            "David Wagner"
        ],
        "published": "2024-05-29T07:03:31Z"
    },
    {
        "title": "Diffeomorphic interpolation for efficient persistence-based topological\n  optimization",
        "link": "http://arxiv.org/abs/2405.18820v1",
        "abstract": "Topological Data Analysis (TDA) provides a pipeline to extract quantitative\ntopological descriptors from structured objects. This enables the definition of\ntopological loss functions, which assert to what extent a given object exhibits\nsome topological properties. These losses can then be used to perform\ntopological optimizationvia gradient descent routines. While theoretically\nsounded, topological optimization faces an important challenge: gradients tend\nto be extremely sparse, in the sense that the loss function typically depends\non only very few coordinates of the input object, yielding dramatically slow\noptimization schemes in practice.Focusing on the central case of topological\noptimization for point clouds, we propose in this work to overcome this\nlimitation using diffeomorphic interpolation, turning sparse gradients into\nsmooth vector fields defined on the whole space, with quantifiable Lipschitz\nconstants. In particular, we show that our approach combines efficiently with\nsubsampling techniques routinely used in TDA, as the diffeomorphism derived\nfrom the gradient computed on a subsample can be used to update the coordinates\nof the full input object, allowing us to perform topological optimization on\npoint clouds at an unprecedented scale. Finally, we also showcase the relevance\nof our approach for black-box autoencoder (AE) regularization, where we aim at\nenforcing topological priors on the latent spaces associated to fixed,\npre-trained, black-box AE models, and where we show thatlearning a\ndiffeomorphic flow can be done once and then re-applied to new data in linear\ntime (while vanilla topological optimization has to be re-run from scratch).\nMoreover, reverting the flow allows us to generate data by sampling the\ntopologically-optimized latent space directly, yielding better interpretability\nof the model.",
        "subjects": [
            "cs.AI",
            "cs.CG",
            "math.OC"
        ],
        "authors": [
            "Mathieu Carriere",
            "Marc Theveneau",
            "Tho Lacombe"
        ],
        "published": "2024-05-29T07:00:28Z"
    },
    {
        "title": "Flow Priors for Linear Inverse Problems via Iterative Corrupted\n  Trajectory Matching",
        "link": "http://arxiv.org/abs/2405.18816v1",
        "abstract": "Generative models based on flow matching have attracted significant attention\nfor their simplicity and superior performance in high-resolution image\nsynthesis. By leveraging the instantaneous change-of-variables formula, one can\ndirectly compute image likelihoods from a learned flow, making them enticing\ncandidates as priors for downstream tasks such as inverse problems. In\nparticular, a natural approach would be to incorporate such image probabilities\nin a maximum-a-posteriori (MAP) estimation problem. A major obstacle, however,\nlies in the slow computation of the log-likelihood, as it requires\nbackpropagating through an ODE solver, which can be prohibitively slow for\nhigh-dimensional problems. In this work, we propose an iterative algorithm to\napproximate the MAP estimator efficiently to solve a variety of linear inverse\nproblems. Our algorithm is mathematically justified by the observation that the\nMAP objective can be approximated by a sum of $N$ ``local MAP'' objectives,\nwhere $N$ is the number of function evaluations. By leveraging Tweedie's\nformula, we show that we can perform gradient steps to sequentially optimize\nthese objectives. We validate our approach for various linear inverse problems,\nsuch as super-resolution, deblurring, inpainting, and compressed sensing, and\ndemonstrate that we can outperform other methods based on flow matching.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Yasi Zhang",
            "Peiyu Yu",
            "Yaxuan Zhu",
            "Yingshan Chang",
            "Feng Gao",
            "Ying Nian Wu",
            "Oscar Leong"
        ],
        "published": "2024-05-29T06:56:12Z"
    },
    {
        "title": "MindSemantix: Deciphering Brain Visual Experiences with a Brain-Language\n  Model",
        "link": "http://arxiv.org/abs/2405.18812v1",
        "abstract": "Deciphering the human visual experience through brain activities captured by\nfMRI represents a compelling and cutting-edge challenge in the field of\nneuroscience research. Compared to merely predicting the viewed image itself,\ndecoding brain activity into meaningful captions provides a higher-level\ninterpretation and summarization of visual information, which naturally\nenhances the application flexibility in real-world situations. In this work, we\nintroduce MindSemantix, a novel multi-modal framework that enables LLMs to\ncomprehend visually-evoked semantic content in brain activity. Our MindSemantix\nexplores a more ideal brain captioning paradigm by weaving LLMs into brain\nactivity analysis, crafting a seamless, end-to-end Brain-Language Model. To\neffectively capture semantic information from brain responses, we propose\nBrain-Text Transformer, utilizing a Brain Q-Former as its core architecture. It\nintegrates a pre-trained brain encoder with a frozen LLM to achieve multi-modal\nalignment of brain-vision-language and establish a robust brain-language\ncorrespondence. To enhance the generalizability of neural representations, we\npre-train our brain encoder on a large-scale, cross-subject fMRI dataset using\nself-supervised learning techniques. MindSemantix provides more feasibility to\ndownstream brain decoding tasks such as stimulus reconstruction. Conditioned by\nMindSemantix captioning, our framework facilitates this process by integrating\nwith advanced generative models like Stable Diffusion and excels in\nunderstanding brain visual perception. MindSemantix generates high-quality\ncaptions that are deeply rooted in the visual and semantic information derived\nfrom brain activity. This approach has demonstrated substantial quantitative\nimprovements over prior art. Our code will be released.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ziqi Ren",
            "Jie Li",
            "Xuetong Xue",
            "Xin Li",
            "Fan Yang",
            "Zhicheng Jiao",
            "Xinbo Gao"
        ],
        "published": "2024-05-29T06:55:03Z"
    },
    {
        "title": "UniPTS: A Unified Framework for Proficient Post-Training Sparsity",
        "link": "http://arxiv.org/abs/2405.18810v1",
        "abstract": "Post-training Sparsity (PTS) is a recently emerged avenue that chases\nefficient network sparsity with limited data in need. Existing PTS methods,\nhowever, undergo significant performance degradation compared with traditional\nmethods that retrain the sparse networks via the whole dataset, especially at\nhigh sparsity ratios. In this paper, we attempt to reconcile this disparity by\ntransposing three cardinal factors that profoundly alter the performance of\nconventional sparsity into the context of PTS. Our endeavors particularly\ncomprise (1) A base-decayed sparsity objective that promotes efficient\nknowledge transferring from dense network to the sparse counterpart. (2) A\nreducing-regrowing search algorithm designed to ascertain the optimal sparsity\ndistribution while circumventing overfitting to the small calibration set in\nPTS. (3) The employment of dynamic sparse training predicated on the preceding\naspects, aimed at comprehensively optimizing the sparsity structure while\nensuring training stability. Our proposed framework, termed UniPTS, is\nvalidated to be much superior to existing PTS methods across extensive\nbenchmarks. As an illustration, it amplifies the performance of POT, a recently\nproposed recipe, from 3.9% to 68.6% when pruning ResNet-50 at 90% sparsity\nratio on ImageNet. We release the code of our paper at\nhttps://github.com/xjjxmu/UniPTS.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Jingjing Xie",
            "Yuxin Zhang",
            "Mingbao Lin",
            "Zhihang Lin",
            "Liujuan Cao",
            "Rongrong Ji"
        ],
        "published": "2024-05-29T06:53:18Z"
    },
    {
        "title": "Multiplicative Weights Update, Area Convexity and Random Coordinate\n  Descent for Densest Subgraph Problems",
        "link": "http://arxiv.org/abs/2405.18809v1",
        "abstract": "We study the densest subgraph problem and give algorithms via multiplicative\nweights updated area convexity that converge in $O\\left(\\frac{\\log\nm}{\\epsilon^{2}}\\right)$ and $O\\left(\\frac{\\log m}{\\epsilon}\\right)$\niterations, respectively, both with nearly-linear time per iteration. Compared\nwith the work by Bahmani et al. (2014), our MWU algorithm uses a very different\nand much simpler procedure for recovering the dense subgraph from the\nfractional solution and does not employ a binary search. Compared with the work\nby Boob et al. (2019), our algorithm via area convexity improves the iteration\ncomplexity by a factor $\\Delta$ -- the maximum degree in the graph, and matches\nthe fastest theoretical runtime currently known via flows (Chekuri et al.,\n2022) in total time. Next, we study the dense subgraph decomposition problem\nand give the first practical iterative algorithm with linear convergence rate\n$O\\left(mn\\log\\frac{1}{\\epsilon}\\right)$ via accelerated random coordinate\ndescent. This significantly improves over\n$O\\left(\\frac{m\\sqrt{mn\\Delta}}{\\epsilon}\\right)$ time of the FISTA-based\nalgorithm by Harb et al. (2022). In the high precision regime\n$\\epsilon\\ll\\frac{1}{n}$ where we can even recover the exact solution, our\nalgorithm has a total runtime of $O\\left(mn\\log n\\right)$, matching the exact\nalgorithm via parametric flows (Gallo et al., 1989). Empirically, we show that\nthis algorithm is very practical and scales to very large graphs, and its\nperformance is competitive with widely used methods that have significantly\nweaker theoretical guarantees.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Ta Duy Nguyen",
            "Alina Ene"
        ],
        "published": "2024-05-29T06:52:03Z"
    },
    {
        "title": "BRACTIVE: A Brain Activation Approach to Human Visual Brain Learning",
        "link": "http://arxiv.org/abs/2405.18808v1",
        "abstract": "The human brain is a highly efficient processing unit, and understanding how\nit works can inspire new algorithms and architectures in machine learning. In\nthis work, we introduce a novel framework named Brain Activation Network\n(BRACTIVE), a transformer-based approach to studying the human visual brain.\nThe main objective of BRACTIVE is to align the visual features of subjects with\ncorresponding brain representations via fMRI signals. It allows us to identify\nthe brain's Regions of Interest (ROI) of the subjects. Unlike previous brain\nresearch methods, which can only identify ROIs for one subject at a time and\nare limited by the number of subjects, BRACTIVE automatically extends this\nidentification to multiple subjects and ROIs. Our experiments demonstrate that\nBRACTIVE effectively identifies person-specific regions of interest, such as\nface and body-selective areas, aligning with neuroscience findings and\nindicating potential applicability to various object categories. More\nimportantly, we found that leveraging human visual brain activity to guide deep\nneural networks enhances performance across various benchmarks. It encourages\nthe potential of BRACTIVE in both neuroscience and machine intelligence\nstudies.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xuan-Bac Nguyen",
            "Hojin Jang",
            "Xin Li",
            "Samee U. Khan",
            "Pawan Sinha",
            "Khoa Luu"
        ],
        "published": "2024-05-29T06:50:13Z"
    },
    {
        "title": "Semiring Activation in Neural Networks",
        "link": "http://arxiv.org/abs/2405.18805v1",
        "abstract": "We introduce a class of trainable nonlinear operators based on semirings that\nare suitable for use in neural networks. These operators generalize the\ntraditional alternation of linear operators with activation functions in neural\nnetworks. Semirings are algebraic structures that describe a generalised\nnotation of linearity, greatly expanding the range of trainable operators that\ncan be included in neural networks. In fact, max- or min-pooling operations are\nconvolutions in the tropical semiring with a fixed kernel.\n  We perform experiments where we replace the activation functions for\ntrainable semiring-based operators to show that these are viable operations to\ninclude in fully connected as well as convolutional neural networks (ConvNeXt).\nWe discuss some of the challenges of replacing traditional activation functions\nwith trainable semiring activations and the trade-offs of doing so.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Bart M. N. Smets",
            "Peter D. Donker",
            "Jim W. Portegies",
            "Remco Duits"
        ],
        "published": "2024-05-29T06:47:45Z"
    },
    {
        "title": "Tilde: Teleoperation for Dexterous In-Hand Manipulation Learning with a\n  DeltaHand",
        "link": "http://arxiv.org/abs/2405.18804v1",
        "abstract": "Dexterous robotic manipulation remains a challenging domain due to its strict\ndemands for precision and robustness on both hardware and software. While\ndexterous robotic hands have demonstrated remarkable capabilities in complex\ntasks, efficiently learning adaptive control policies for hands still presents\na significant hurdle given the high dimensionalities of hands and tasks. To\nbridge this gap, we propose Tilde, an imitation learning-based in-hand\nmanipulation system on a dexterous DeltaHand. It leverages 1) a low-cost,\nconfigurable, simple-to-control, soft dexterous robotic hand, DeltaHand, 2) a\nuser-friendly, precise, real-time teleoperation interface, TeleHand, and 3) an\nefficient and generalizable imitation learning approach with diffusion\npolicies. Our proposed TeleHand has a kinematic twin design to the DeltaHand\nthat enables precise one-to-one joint control of the DeltaHand during\nteleoperation. This facilitates efficient high-quality data collection of human\ndemonstrations in the real world. To evaluate the effectiveness of our system,\nwe demonstrate the fully autonomous closed-loop deployment of diffusion\npolicies learned from demonstrations across seven dexterous manipulation tasks\nwith an average 90% success rate.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Zilin Si",
            "Kevin Lee Zhang",
            "Zeynep Temel",
            "Oliver Kroemer"
        ],
        "published": "2024-05-29T06:47:34Z"
    },
    {
        "title": "Information Dynamics in Evolving Networks Based on the Birth-Death\n  Process: Random Drift and Natural Selection Perspective",
        "link": "http://dx.doi.org/10.1109/TSMC.2024.3389095",
        "abstract": "Dynamic processes in complex networks are crucial for better understanding\ncollective behavior in human societies, biological systems, and the internet.\nIn this paper, we first focus on the continuous Markov-based modeling of\nevolving networks with the birth-death of individuals. A new individual arrives\nat the group by the Poisson process, while new links are established in the\nnetwork through either uniform connection or preferential attachment. Moreover,\nan existing individual has a limited lifespan before leaving the network. We\ndetermine stationary topological properties of these networks, including their\nsize and mean degree. To address the effect of the birth-death evolution, we\nfurther study the information dynamics in the proposed network model from the\nrandom drift and natural selection perspective, based on assumptions of\ntotal-stochastic and fitness-driven evolution, respectively. In simulations, we\nanalyze the fixation probability of individual information and find that means\nof new connections affect the random drift process but do not affect the\nnatural selection process.",
        "subjects": [
            "cs.SI"
        ],
        "authors": [
            "Minyu Feng",
            "Ziyan Zeng",
            "Qin Li",
            "Matja Perc",
            "Jrgen Kurths"
        ],
        "published": "2024-05-29T06:47:00Z"
    },
    {
        "title": "Enhancing Security and Privacy in Federated Learning using Update\n  Digests and Voting-Based Defense",
        "link": "http://arxiv.org/abs/2405.18802v1",
        "abstract": "Federated Learning (FL) is a promising privacy-preserving machine learning\nparadigm that allows data owners to collaboratively train models while keeping\ntheir data localized. Despite its potential, FL faces challenges related to the\ntrustworthiness of both clients and servers, especially in the presence of\ncurious or malicious adversaries. In this paper, we introduce a novel framework\nnamed \\underline{\\textbf{F}}ederated \\underline{\\textbf{L}}earning with\n\\underline{\\textbf{U}}pdate \\underline{\\textbf{D}}igest (FLUD), which addresses\nthe critical issues of privacy preservation and resistance to Byzantine attacks\nwithin distributed learning environments. FLUD utilizes an innovative approach,\nthe $\\mathsf{LinfSample}$ method, allowing clients to compute the $l_{\\infty}$\nnorm across sliding windows of updates as an update digest. This digest enables\nthe server to calculate a shared distance matrix, significantly reducing the\noverhead associated with Secure Multi-Party Computation (SMPC) by three orders\nof magnitude while effectively distinguishing between benign and malicious\nupdates. Additionally, FLUD integrates a privacy-preserving, voting-based\ndefense mechanism that employs optimized SMPC protocols to minimize\ncommunication rounds. Our comprehensive experiments demonstrate FLUD's\neffectiveness in countering Byzantine adversaries while incurring low\ncommunication and runtime overhead. FLUD offers a scalable framework for secure\nand reliable FL in distributed environments, facilitating its application in\nscenarios requiring robust data management and security.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "authors": [
            "Wenjie Li",
            "Kai Fan",
            "Jingyuan Zhang",
            "Hui Li",
            "Wei Yang Bryan Lim",
            "Qiang Yang"
        ],
        "published": "2024-05-29T06:46:10Z"
    },
    {
        "title": "SketchTriplet: Self-Supervised Scenarized Sketch-Text-Image Triplet\n  Generation",
        "link": "http://arxiv.org/abs/2405.18801v1",
        "abstract": "The scarcity of free-hand sketch presents a challenging problem. Despite the\nemergence of some large-scale sketch datasets, these datasets primarily consist\nof sketches at the single-object level. There continues to be a lack of\nlarge-scale paired datasets for scene sketches. In this paper, we propose a\nself-supervised method for scene sketch generation that does not rely on any\nexisting scene sketch, enabling the transformation of single-object sketches\ninto scene sketches. To accomplish this, we introduce a method for vector\nsketch captioning and sketch semantic expansion. Additionally, we design a\nsketch generation network that incorporates a fusion of multi-modal perceptual\nconstraints, suitable for application in zero-shot image-to-sketch downstream\ntask, demonstrating state-of-the-art performance through experimental\nvalidation. Finally, leveraging our proposed sketch-to-sketch generation\nmethod, we contribute a large-scale dataset centered around scene sketches,\ncomprising highly semantically consistent \"text-sketch-image\" triplets. Our\nresearch confirms that this dataset can significantly enhance the capabilities\nof existing models in sketch-based image retrieval and sketch-controlled image\nsynthesis tasks. We will make our dataset and code publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhenbei Wu",
            "Qiang Wang",
            "Jie Yang"
        ],
        "published": "2024-05-29T06:43:49Z"
    },
    {
        "title": "Face processing emerges from object-trained convolutional neural\n  networks",
        "link": "http://arxiv.org/abs/2405.18800v1",
        "abstract": "Whether face processing depends on unique, domain-specific neurocognitive\nmechanisms or domain-general object recognition mechanisms has long been\ndebated. Directly testing these competing hypotheses in humans has proven\nchallenging due to extensive exposure to both faces and objects. Here, we\nsystematically test these hypotheses by capitalizing on recent progress in\nconvolutional neural networks (CNNs) that can be trained without face exposure\n(i.e., pre-trained weights). Domain-general mechanism accounts posit that face\nprocessing can emerge from a neural network without specialized pre-training on\nfaces. Consequently, we trained CNNs solely on objects and tested their ability\nto recognize and represent faces as well as objects that look like faces (face\npareidolia stimuli).... Due to the character limits, for more details see in\nattached pdf",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhenhua Zhao",
            "Ji Chen",
            "Zhicheng Lin",
            "Haojiang Ying"
        ],
        "published": "2024-05-29T06:35:33Z"
    },
    {
        "title": "User Association and Channel Allocation in 5G Mobile Asymmetric\n  Multi-band Heterogeneous Networks",
        "link": "http://arxiv.org/abs/2405.18797v1",
        "abstract": "With the proliferation of mobile terminals and the continuous upgrading of\nservices, 4G LTE networks are showing signs of weakness. To enhance the\ncapacity of wireless networks, millimeter waves are introduced to drive the\nevolution of networks towards multi-band 5G heterogeneous networks. The\ndistinct propagation characteristics of mmWaves and microwaves, as well as the\nvastly different hardware configurations of heterogeneous base stations, make\ntraditional access strategies no longer effective. Therefore, to narrowing the\ngap between theory and practice, we investigate the access strategy in\nmulti-band 5G heterogeneous networks, taking into account the characteristics\nof mobile users, asynchronous switching between uplink and downlink of pico\nbase stations, asymmetric service requirements, and user communication\ncontinuity. We formulate the problem as integer nonlinear programming and prove\nits intractability. Thereby, we decouple it into three subproblems: user\nassociation, switch point selection, and subchannel allocation, and design an\nalgorithm based on optimal matching and spectral clustering to solve it\nefficiently. The simulation results show that the proposed algorithm\noutperforms the comparison methods in terms of overall data rate, effective\ndata rate, and number of satisfied users.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Miao Dai",
            "Gang Sun",
            "Hongfang Yu",
            "Sheng Wang",
            "Dusit Niyato"
        ],
        "published": "2024-05-29T06:33:25Z"
    },
    {
        "title": "Federated Q-Learning with Reference-Advantage Decomposition: Almost\n  Optimal Regret and Logarithmic Communication Cost",
        "link": "http://arxiv.org/abs/2405.18795v1",
        "abstract": "In this paper, we consider model-free federated reinforcement learning for\ntabular episodic Markov decision processes. Under the coordination of a central\nserver, multiple agents collaboratively explore the environment and learn an\noptimal policy without sharing their raw data. Despite recent advances in\nfederated Q-learning algorithms achieving near-linear regret speedup with low\ncommunication cost, existing algorithms only attain suboptimal regrets compared\nto the information bound. We propose a novel model-free federated Q-learning\nalgorithm, termed FedQ-Advantage. Our algorithm leverages reference-advantage\ndecomposition for variance reduction and operates under two distinct\nmechanisms: synchronization between the agents and the server, and policy\nupdate, both triggered by events. We prove that our algorithm not only requires\na lower logarithmic communication cost but also achieves an almost optimal\nregret, reaching the information bound up to a logarithmic factor and\nnear-linear regret speedup compared to its single-agent counterpart when the\ntime horizon is sufficiently large.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Zhong Zheng",
            "Haochen Zhang",
            "Lingzhou Xue"
        ],
        "published": "2024-05-29T06:26:52Z"
    },
    {
        "title": "Adaptive Discretization-based Non-Episodic Reinforcement Learning in\n  Metric Spaces",
        "link": "http://arxiv.org/abs/2405.18793v1",
        "abstract": "We study non-episodic Reinforcement Learning for Lipschitz MDPs in which\nstate-action space is a metric space, and the transition kernel and rewards are\nLipschitz functions. We develop computationally efficient UCB-based algorithm,\n$\\textit{ZoRL-}\\epsilon$ that adaptively discretizes the state-action space and\nshow that their regret as compared with $\\epsilon$-optimal policy is bounded as\n$\\mathcal{O}(\\epsilon^{-(2 d_\\mathcal{S} + d^\\epsilon_z + 1)}\\log{(T)})$, where\n$d^\\epsilon_z$ is the $\\epsilon$-zooming dimension. In contrast, if one uses\nthe vanilla $\\textit{UCRL-}2$ on a fixed discretization of the MDP, the regret\nw.r.t. a $\\epsilon$-optimal policy scales as $\\mathcal{O}(\\epsilon^{-(2\nd_\\mathcal{S} + d + 1)}\\log{(T)})$ so that the adaptivity gains are huge when\n$d^\\epsilon_z \\ll d$. Note that the absolute regret of any 'uniformly good'\nalgorithm for a large family of continuous MDPs asymptotically scales as at\nleast $\\Omega(\\log{(T)})$. Though adaptive discretization has been shown to\nyield $\\mathcal{\\tilde{O}}(H^{2.5}K^\\frac{d_z + 1}{d_z + 2})$ regret in\nepisodic RL, an attempt to extend this to the non-episodic case by employing\nconstant duration episodes whose duration increases with $T$, is futile since\n$d_z \\to d$ as $T \\to \\infty$. The current work shows how to obtain adaptivity\ngains for non-episodic RL. The theoretical results are supported by simulations\non two systems where the performance of $\\textit{ZoRL-}\\epsilon$ is compared\nwith that of '$\\textit{UCRL-C}$,' the fixed discretization-based extension of\n$\\textit{UCRL-}2$ for systems with continuous state-action spaces.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Avik Kar",
            "Rahul Singh"
        ],
        "published": "2024-05-29T06:18:09Z"
    },
    {
        "title": "Kernel Metric Learning for In-Sample Off-Policy Evaluation of\n  Deterministic RL Policies",
        "link": "http://arxiv.org/abs/2405.18792v1",
        "abstract": "We consider off-policy evaluation (OPE) of deterministic target policies for\nreinforcement learning (RL) in environments with continuous action spaces.\nWhile it is common to use importance sampling for OPE, it suffers from high\nvariance when the behavior policy deviates significantly from the target\npolicy. In order to address this issue, some recent works on OPE proposed\nin-sample learning with importance resampling. Yet, these approaches are not\napplicable to deterministic target policies for continuous action spaces. To\naddress this limitation, we propose to relax the deterministic target policy\nusing a kernel and learn the kernel metrics that minimize the overall mean\nsquared error of the estimated temporal difference update vector of an action\nvalue function, where the action value function is used for policy evaluation.\nWe derive the bias and variance of the estimation error due to this relaxation\nand provide analytic solutions for the optimal kernel metric. In empirical\nstudies using various test domains, we show that the OPE with in-sample\nlearning using the kernel with optimized metric achieves significantly improved\naccuracy than other baselines.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Haanvid Lee",
            "Tri Wahyu Guntara",
            "Jongmin Lee",
            "Yung-Kyun Noh",
            "Kee-Eung Kim"
        ],
        "published": "2024-05-29T06:17:33Z"
    },
    {
        "title": "A new platooning model for connected and autonomous vehicles to improve\n  string stability",
        "link": "http://arxiv.org/abs/2405.18791v1",
        "abstract": "This paper introduces a novel idea of coordinated vehicle platooning such\nthat platoon followers inside the platoon communicates only to the platoon\nleader. A novel dynamic model is proposed to take driving safety into account\nwhen there is communication delay. Some general results of linear stability are\nproved mathematically, and numerical simulations are conducted to show the\neffect of model parameters for both ring road with an initial disturbance and\ninfinite road with a periodic disturbance. The simulation results are\nconsistent with theoretical analysis, and demonstrate that the proposed\nlook-to-the-leader platooning strategy is far superior than the\nfollow-one-vehicle-ahead or follow-two-vehicle-ahead conventional car-following\n(CF) strategies in stabilizing traffic flow. This paper provides a new\nperspective for the organization of platoons of autonomous vehicles.",
        "subjects": [
            "eess.SY",
            "cs.SY",
            "math.DS"
        ],
        "authors": [
            "Shouwei Hui",
            "Michael Zhang"
        ],
        "published": "2024-05-29T06:11:09Z"
    },
    {
        "title": "Opinion-Unaware Blind Image Quality Assessment using Multi-Scale Deep\n  Feature Statistics",
        "link": "http://arxiv.org/abs/2405.18790v1",
        "abstract": "Deep learning-based methods have significantly influenced the blind image\nquality assessment (BIQA) field, however, these methods often require training\nusing large amounts of human rating data. In contrast, traditional\nknowledge-based methods are cost-effective for training but face challenges in\neffectively extracting features aligned with human visual perception. To bridge\nthese gaps, we propose integrating deep features from pre-trained visual models\nwith a statistical analysis model into a Multi-scale Deep Feature Statistics\n(MDFS) model for achieving opinion-unaware BIQA (OU-BIQA), thereby eliminating\nthe reliance on human rating data and significantly improving training\nefficiency. Specifically, we extract patch-wise multi-scale features from\npre-trained vision models, which are subsequently fitted into a multivariate\nGaussian (MVG) model. The final quality score is determined by quantifying the\ndistance between the MVG model derived from the test image and the benchmark\nMVG model derived from the high-quality image set. A comprehensive series of\nexperiments conducted on various datasets show that our proposed model exhibits\nsuperior consistency with human visual perception compared to state-of-the-art\nBIQA models. Furthermore, it shows improved generalizability across diverse\ntarget-specific BIQA tasks. Our code is available at:\nhttps://github.com/eezkni/MDFS",
        "subjects": [
            "cs.CV",
            "cs.MM",
            "eess.IV"
        ],
        "authors": [
            "Zhangkai Ni",
            "Yue Liu",
            "Keyan Ding",
            "Wenhan Yang",
            "Hanli Wang",
            "Shiqi Wang"
        ],
        "published": "2024-05-29T06:09:34Z"
    },
    {
        "title": "An overview of some single machine scheduling problems: polynomial\n  algorithms, complexity and approximability",
        "link": "http://arxiv.org/abs/2405.18789v1",
        "abstract": "Since the publication of the first scheduling paper in 1954, a huge number of\nworks dealing with different types of single machine problems appeared. They\naddressed many heuristics and enumerative procedures, complexity results or\nstructural properties of certain problems. Regarding surveys, often particular\nsubjects like special objective functions are discussed, or more general\nscheduling problems were surveyed, where a substantial part is devoted to\nsingle machine problems. In this paper we present some results on polynomial\nalgorithms, complexity and approximation issues, where the main focus is on\nresults, which have been published during the last decades in papers, where at\nleast one of the first two authors of this paper was involved. We hope that the\nreviewed results will stimulate further investigation in related research\nfields.",
        "subjects": [
            "cs.DS",
            "90B35 (Primary), 90C59 (Secondary)"
        ],
        "authors": [
            "Nodari Vakhania",
            "Frank Werner",
            "Kevin Johedan Ramrez-Fuentes",
            "Vctor Pacheco-Valencia"
        ],
        "published": "2024-05-29T06:05:47Z"
    },
    {
        "title": "Modeling and Control of a Novel Bi-Quadcopter with Auxiliary Thruster\n  Mechanism",
        "link": "http://arxiv.org/abs/2405.18787v1",
        "abstract": "In this paper, a new under-actuated Bi-Quadcopter Unmanned Aerial Vehicle is\nintroduced. The proposed drone configuration can be controlled similar to a\nBicopter. The dynamics of the proposed Bi-Quadcopter is developed using the\nNewton-Euler approach. Using the force decomposition technique, a mapping\nbetween the control wrench and actuator inputs is developed. A nonlinear\nposition control is applied for the Bi-Quadcopter using the quaternion-based\ncascaded attitude controller. The performance of the proposed UAV with the\ncontrol algorithm is verified through simulations. Finally, the actuator\nfailure scenarios were analyzed.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Vijay Reddy Vundela",
            "Vijay Muralidharan"
        ],
        "published": "2024-05-29T06:03:31Z"
    },
    {
        "title": "MOKD: Cross-domain Finetuning for Few-shot Classification via Maximizing\n  Optimized Kernel Dependence",
        "link": "http://arxiv.org/abs/2405.18786v1",
        "abstract": "In cross-domain few-shot classification, \\emph{nearest centroid classifier}\n(NCC) aims to learn representations to construct a metric space where few-shot\nclassification can be performed by measuring the similarities between samples\nand the prototype of each class. An intuition behind NCC is that each sample is\npulled closer to the class centroid it belongs to while pushed away from those\nof other classes. However, in this paper, we find that there exist high\nsimilarities between NCC-learned representations of two samples from different\nclasses. In order to address this problem, we propose a bi-level optimization\nframework, \\emph{maximizing optimized kernel dependence} (MOKD) to learn a set\nof class-specific representations that match the cluster structures indicated\nby labeled data of the given task. Specifically, MOKD first optimizes the\nkernel adopted in \\emph{Hilbert-Schmidt independence criterion} (HSIC) to\nobtain the optimized kernel HSIC (opt-HSIC) that can capture the dependence\nmore precisely. Then, an optimization problem regarding the opt-HSIC is\naddressed to simultaneously maximize the dependence between representations and\nlabels and minimize the dependence among all samples. Extensive experiments on\nMeta-Dataset demonstrate that MOKD can not only achieve better generalization\nperformance on unseen domains in most cases but also learn better data\nrepresentation clusters. The project repository of MOKD is available at:\n\\href{https://github.com/tmlr-group/MOKD}{https://github.com/tmlr-group/MOKD}.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Hongduan Tian",
            "Feng Liu",
            "Tongliang Liu",
            "Bo Du",
            "Yiu-ming Cheung",
            "Bo Han"
        ],
        "published": "2024-05-29T05:59:52Z"
    },
    {
        "title": "LP-3DGS: Learning to Prune 3D Gaussian Splatting",
        "link": "http://arxiv.org/abs/2405.18784v1",
        "abstract": "Recently, 3D Gaussian Splatting (3DGS) has become one of the mainstream\nmethodologies for novel view synthesis (NVS) due to its high quality and fast\nrendering speed. However, as a point-based scene representation, 3DGS\npotentially generates a large number of Gaussians to fit the scene, leading to\nhigh memory usage. Improvements that have been proposed require either an\nempirical and preset pruning ratio or importance score threshold to prune the\npoint cloud. Such hyperparamter requires multiple rounds of training to\noptimize and achieve the maximum pruning ratio, while maintaining the rendering\nquality for each scene. In this work, we propose learning-to-prune 3DGS\n(LP-3DGS), where a trainable binary mask is applied to the importance score\nthat can find optimal pruning ratio automatically. Instead of using the\ntraditional straight-through estimator (STE) method to approximate the binary\nmask gradient, we redesign the masking function to leverage the Gumbel-Sigmoid\nmethod, making it differentiable and compatible with the existing training\nprocess of 3DGS. Extensive experiments have shown that LP-3DGS consistently\nproduces a good balance that is both efficient and high quality.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhaoliang Zhang",
            "Tianchen Song",
            "Yongjae Lee",
            "Li Yang",
            "Cheng Peng",
            "Rama Chellappa",
            "Deliang Fan"
        ],
        "published": "2024-05-29T05:58:34Z"
    },
    {
        "title": "Principled Probabilistic Imaging using Diffusion Models as Plug-and-Play\n  Priors",
        "link": "http://arxiv.org/abs/2405.18782v1",
        "abstract": "Diffusion models (DMs) have recently shown outstanding capability in modeling\ncomplex image distributions, making them expressive image priors for solving\nBayesian inverse problems. However, most existing DM-based methods rely on\napproximations in the generative process to be generic to different inverse\nproblems, leading to inaccurate sample distributions that deviate from the\ntarget posterior defined within the Bayesian framework. To harness the\ngenerative power of DMs while avoiding such approximations, we propose a Markov\nchain Monte Carlo algorithm that performs posterior sampling for general\ninverse problems by reducing it to sampling the posterior of a Gaussian\ndenoising problem. Crucially, we leverage a general DM formulation as a unified\ninterface that allows for rigorously solving the denoising problem with a range\nof state-of-the-art DMs. We demonstrate the effectiveness of the proposed\nmethod on six inverse problems (three linear and three nonlinear), including a\nreal-world black hole imaging problem. Experimental results indicate that our\nproposed method offers more accurate reconstructions and posterior estimation\ncompared to existing DM-based imaging inverse methods.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "stat.ML"
        ],
        "authors": [
            "Zihui Wu",
            "Yu Sun",
            "Yifan Chen",
            "Bingliang Zhang",
            "Yisong Yue",
            "Katherine L. Bouman"
        ],
        "published": "2024-05-29T05:42:25Z"
    },
    {
        "title": "On the Role of Attention Masks and LayerNorm in Transformers",
        "link": "http://arxiv.org/abs/2405.18781v1",
        "abstract": "Self-attention is the key mechanism of transformers, which are the essential\nbuilding blocks of modern foundation models. Recent studies have shown that\npure self-attention suffers from an increasing degree of rank collapse as depth\nincreases, limiting model expressivity and further utilization of model depth.\nThe existing literature on rank collapse, however, has mostly overlooked other\ncritical components in transformers that may alleviate the rank collapse issue.\nIn this paper, we provide a general analysis of rank collapse under\nself-attention, taking into account the effects of attention masks and layer\nnormalization (LayerNorm). In particular, we find that although pure masked\nattention still suffers from exponential collapse to a rank one subspace, local\nmasked attention can provably slow down the collapse rate. In the case of\nself-attention with LayerNorm, we first show that for certain classes of value\nmatrices, collapse to a rank one subspace still happens exponentially. However,\nthrough construction of nontrivial counterexamples, we then establish that with\nproper choice of value matrices, a general class of sequences may not converge\nto a rank one subspace, and the self-attention dynamics with LayerNorm can\nsimultaneously possess a rich set of equilibria with any possible rank between\none and full. Our result refutes the previous hypothesis that LayerNorm plays\nno role in the rank collapse of self-attention and suggests that self-attention\nwith LayerNorm constitutes a much more expressive, versatile nonlinear\ndynamical system than what was originally thought.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Xinyi Wu",
            "Amir Ajorlou",
            "Yifei Wang",
            "Stefanie Jegelka",
            "Ali Jadbabaie"
        ],
        "published": "2024-05-29T05:41:28Z"
    },
    {
        "title": "Quantitative Certification of Bias in Large Language Models",
        "link": "http://arxiv.org/abs/2405.18780v1",
        "abstract": "Large Language Models (LLMs) can produce responses that exhibit social biases\nand support stereotypes. However, conventional benchmarking is insufficient to\nthoroughly evaluate LLM bias, as it can not scale to large sets of prompts and\nprovides no guarantees. Therefore, we propose a novel certification framework\nQuaCer-B (Quantitative Certification of Bias) that provides formal guarantees\non obtaining unbiased responses from target LLMs under large sets of prompts. A\ncertificate consists of high-confidence bounds on the probability of obtaining\nbiased responses from the LLM for any set of prompts containing sensitive\nattributes, sampled from a distribution. We illustrate the bias certification\nin LLMs for prompts with various prefixes drawn from given distributions. We\nconsider distributions of random token sequences, mixtures of manual\njailbreaks, and jailbreaks in the LLM's embedding space to certify its bias. We\ncertify popular LLMs with QuaCer-B and present novel insights into their\nbiases.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Isha Chaudhary",
            "Qian Hu",
            "Manoj Kumar",
            "Morteza Ziyadi",
            "Rahul Gupta",
            "Gagandeep Singh"
        ],
        "published": "2024-05-29T05:39:37Z"
    },
    {
        "title": "SPABA: A Single-Loop and Probabilistic Stochastic Bilevel Algorithm\n  Achieving Optimal Sample Complexity",
        "link": "http://arxiv.org/abs/2405.18777v1",
        "abstract": "While stochastic bilevel optimization methods have been extensively studied\nfor addressing large-scale nested optimization problems in machine learning, it\nremains an open question whether the optimal complexity bounds for solving\nbilevel optimization are the same as those in single-level optimization. Our\nmain result resolves this question: SPABA, an adaptation of the PAGE method for\nnonconvex optimization in (Li et al., 2021) to the bilevel setting, can achieve\noptimal sample complexity in both the finite-sum and expectation settings. We\nshow the optimality of SPABA by proving that there is no gap in complexity\nanalysis between stochastic bilevel and single-level optimization when\nimplementing PAGE. Notably, as indicated by the results of (Dagr\\'eou et al.,\n2022), there might exist a gap in complexity analysis when implementing other\nstochastic gradient estimators, like SGD and SAGA. In addition to SPABA, we\npropose several other single-loop stochastic bilevel algorithms, that either\nmatch or improve the state-of-the-art sample complexity results, leveraging our\nconvergence rate and complexity analysis. Numerical experiments demonstrate the\nsuperior practical performance of the proposed methods.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "authors": [
            "Tianshu Chu",
            "Dachuan Xu",
            "Wei Yao",
            "Jin Zhang"
        ],
        "published": "2024-05-29T05:36:03Z"
    },
    {
        "title": "LMO-DP: Optimizing the Randomization Mechanism for Differentially\n  Private Fine-Tuning (Large) Language Models",
        "link": "http://arxiv.org/abs/2405.18776v1",
        "abstract": "Differentially Private Stochastic Gradient Descent (DP-SGD) and its variants\nhave been proposed to ensure rigorous privacy for fine-tuning large-scale\npre-trained language models. However, they rely heavily on the Gaussian\nmechanism, which may overly perturb the gradients and degrade the accuracy,\nespecially in stronger privacy regimes (e.g., the privacy budget $\\epsilon <\n3$). To address such limitations, we propose a novel Language Model-based\nOptimal Differential Privacy (LMO-DP) mechanism, which takes the first step to\nenable the tight composition of accurately fine-tuning (large) language models\nwith a sub-optimal DP mechanism, even in strong privacy regimes (e.g., $0.1\\leq\n\\epsilon<3$). Furthermore, we propose a novel offline optimal noise search\nmethod to efficiently derive the sub-optimal DP that significantly reduces the\nnoise magnitude. For instance, fine-tuning RoBERTa-large (with 300M parameters)\non the SST-2 dataset can achieve an accuracy of 92.20% (given $\\epsilon=0.3$,\n$\\delta=10^{-10}$) by drastically outperforming the Gaussian mechanism (e.g.,\n$\\sim 50\\%$ for small $\\epsilon$ and $\\delta$). We also draw similar findings\non the text generation tasks on GPT-2. Finally, to our best knowledge, LMO-DP\nis also the first solution to accurately fine-tune Llama-2 with strong\ndifferential privacy guarantees. The code will be released soon and available\nupon request.",
        "subjects": [
            "cs.CR",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Qin Yang",
            "Meisam Mohammad",
            "Han Wang",
            "Ali Payani",
            "Ashish Kundu",
            "Kai Shu",
            "Yan Yan",
            "Yuan Hong"
        ],
        "published": "2024-05-29T05:32:50Z"
    },
    {
        "title": "LLaMA-Reg: Using LLaMA 2 for Unsupervised Medical Image Registration",
        "link": "http://arxiv.org/abs/2405.18774v1",
        "abstract": "Medical image registration is an essential topic in medical image analysis.\nIn this paper, we propose a method for medical image registration using a\npretrained large language model. We find that using the pretrained large\nlanguage model to encode deep features of the medical images in the\nregistration model can effectively improve image registration accuracy,\nindicating the great potential of the large language model in medical image\nregistration tasks. We use dual encoders to perform deep feature extraction on\nimage pairs and then input the features into the pretrained large language\nmodel. To adapt the large language model to our registration task, the weights\nof the large language model are frozen in the registration model, and an\nadapter is utilized to fine-tune the large language model, which aims at (a)\nmapping the visual tokens to the language space before the large language model\ncomputing, (b) project the modeled language tokens output from the large\nlanguage model to the visual space. Our method combines output features from\nthe fine-tuned large language model with the features output from each encoder\nlayer to gradually generate the deformation fields required for registration in\nthe decoder. To demonstrate the effectiveness of the large prediction model in\nregistration tasks, we conducted experiments on knee and brain MRI and achieved\nstate-of-the-art results.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Mingrui Ma",
            "Yu Yang"
        ],
        "published": "2024-05-29T05:26:25Z"
    },
    {
        "title": "Evolving Reliable Differentiating Constraints for the Chance-constrained\n  Maximum Coverage Problem",
        "link": "http://arxiv.org/abs/2405.18772v1",
        "abstract": "Chance-constrained problems involve stochastic components in the constraints\nwhich can be violated with a small probability. We investigate the impact of\ndifferent types of chance constraints on the performance of iterative search\nalgorithms and study the classical maximum coverage problem in graphs with\nchance constraints. Our goal is to evolve reliable chance constraint settings\nfor a given graph where the performance of algorithms differs significantly not\njust in expectation but with high confidence. This allows to better learn and\nunderstand how different types of algorithms can deal with different types of\nconstraint settings and supports automatic algorithm selection. We develop an\nevolutionary algorithm that provides sets of chance constraints that\ndifferentiate the performance of two stochastic search algorithms with high\nconfidence. We initially use traditional approximation ratio as the fitness\nfunction of (1+1)~EA to evolve instances, which shows inadequacy to generate\nreliable instances. To address this issue, we introduce a new measure to\ncalculate the performance difference for two algorithms, which considers\nvariances of performance ratios. Our experiments show that our approach is\nhighly successful in solving the instability issue of the performance ratios\nand leads to evolving reliable sets of chance constraints with significantly\ndifferent performance for various types of algorithms.",
        "subjects": [
            "cs.NE"
        ],
        "authors": [
            "Saba Sadeghi Ahouei",
            "Jacob de Nobel",
            "Aneta Neumann",
            "Thomas Bck",
            "Frank Neumann"
        ],
        "published": "2024-05-29T05:22:31Z"
    },
    {
        "title": "Leveraging Many-To-Many Relationships for Defending Against\n  Visual-Language Adversarial Attacks",
        "link": "http://arxiv.org/abs/2405.18770v1",
        "abstract": "Recent studies have revealed that vision-language (VL) models are vulnerable\nto adversarial attacks for image-text retrieval (ITR). However, existing\ndefense strategies for VL models primarily focus on zero-shot image\nclassification, which do not consider the simultaneous manipulation of image\nand text, as well as the inherent many-to-many (N:N) nature of ITR, where a\nsingle image can be described in numerous ways, and vice versa. To this end,\nthis paper studies defense strategies against adversarial attacks on VL models\nfor ITR for the first time. Particularly, we focus on how to leverage the N:N\nrelationship in ITR to enhance adversarial robustness. We found that, although\nadversarial training easily overfits to specific one-to-one (1:1) image-text\npairs in the train data, diverse augmentation techniques to create one-to-many\n(1:N) / many-to-one (N:1) image-text pairs can significantly improve\nadversarial robustness in VL models. Additionally, we show that the alignment\nof the augmented image-text pairs is crucial for the effectiveness of the\ndefense strategy, and that inappropriate augmentations can even degrade the\nmodel's performance. Based on these findings, we propose a novel defense\nstrategy that leverages the N:N relationship in ITR, which effectively\ngenerates diverse yet highly-aligned N:N pairs using basic augmentations and\ngenerative model-based augmentations. This work provides a novel perspective on\ndefending against adversarial attacks in VL tasks and opens up new research\ndirections for future work.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.IR"
        ],
        "authors": [
            "Futa Waseda",
            "Antonio Tejero-de-Pablos"
        ],
        "published": "2024-05-29T05:20:02Z"
    },
    {
        "title": "OUS: Scene-Guided Dynamic Facial Expression Recognition",
        "link": "http://arxiv.org/abs/2405.18769v1",
        "abstract": "Dynamic Facial Expression Recognition (DFER) is crucial for affective\ncomputing but often overlooks the impact of scene context. We have identified a\nsignificant issue in current DFER tasks: human annotators typically integrate\nemotions from various angles, including environmental cues and body language,\nwhereas existing DFER methods tend to consider the scene as noise that needs to\nbe filtered out, focusing solely on facial information. We refer to this as the\nRigid Cognitive Problem. The Rigid Cognitive Problem can lead to discrepancies\nbetween the cognition of annotators and models in some samples. To align more\nclosely with the human cognitive paradigm of emotions, we propose an Overall\nUnderstanding of the Scene DFER method (OUS). OUS effectively integrates scene\nand facial features, combining scene-specific emotional knowledge for DFER.\nExtensive experiments on the two largest datasets in the DFER field, DFEW and\nFERV39k, demonstrate that OUS significantly outperforms existing methods. By\nanalyzing the Rigid Cognitive Problem, OUS successfully understands the complex\nrelationship between scene context and emotional expression, closely aligning\nwith human emotional understanding in real-world scenarios.",
        "subjects": [
            "cs.CV",
            "I.4; I.5.1"
        ],
        "authors": [
            "Xinji Mai",
            "Haoran Wang",
            "Zeng Tao",
            "Junxiong Lin",
            "Shaoqi Yan",
            "Yan Wang",
            "Jing Liu",
            "Jiawen Yu",
            "Xuan Tong",
            "Yating Li",
            "Wenqiang Zhang"
        ],
        "published": "2024-05-29T05:12:16Z"
    },
    {
        "title": "RNAFlow: RNA Structure & Sequence Design via Inverse Folding-Based Flow\n  Matching",
        "link": "http://arxiv.org/abs/2405.18768v1",
        "abstract": "The growing significance of RNA engineering in diverse biological\napplications has spurred interest in developing AI methods for structure-based\nRNA design. While diffusion models have excelled in protein design, adapting\nthem for RNA presents new challenges due to RNA's conformational flexibility\nand the computational cost of fine-tuning large structure prediction models. To\nthis end, we propose RNAFlow, a flow matching model for protein-conditioned RNA\nsequence-structure design. Its denoising network integrates an RNA inverse\nfolding model and a pre-trained RosettaFold2NA network for generation of RNA\nsequences and structures. The integration of inverse folding in the structure\ndenoising process allows us to simplify training by fixing the structure\nprediction network. We further enhance the inverse folding model by\nconditioning it on inferred conformational ensembles to model dynamic RNA\nconformations. Evaluation on protein-conditioned RNA structure and sequence\ngeneration tasks demonstrates RNAFlow's advantage over existing RNA design\nmethods.",
        "subjects": [
            "q-bio.BM",
            "cs.LG"
        ],
        "authors": [
            "Divya Nori",
            "Wengong Jin"
        ],
        "published": "2024-05-29T05:10:25Z"
    },
    {
        "title": "Large Brain Model for Learning Generic Representations with Tremendous\n  EEG Data in BCI",
        "link": "http://arxiv.org/abs/2405.18765v1",
        "abstract": "The current electroencephalogram (EEG) based deep learning models are\ntypically designed for specific datasets and applications in brain-computer\ninteraction (BCI), limiting the scale of the models and thus diminishing their\nperceptual capabilities and generalizability. Recently, Large Language Models\n(LLMs) have achieved unprecedented success in text processing, prompting us to\nexplore the capabilities of Large EEG Models (LEMs). We hope that LEMs can\nbreak through the limitations of different task types of EEG datasets, and\nobtain universal perceptual capabilities of EEG signals through unsupervised\npre-training. Then the models can be fine-tuned for different downstream tasks.\nHowever, compared to text data, the volume of EEG datasets is generally small\nand the format varies widely. For example, there can be mismatched numbers of\nelectrodes, unequal length data samples, varied task designs, and low\nsignal-to-noise ratio. To overcome these challenges, we propose a unified\nfoundation model for EEG called Large Brain Model (LaBraM). LaBraM enables\ncross-dataset learning by segmenting the EEG signals into EEG channel patches.\nVector-quantized neural spectrum prediction is used to train a semantically\nrich neural tokenizer that encodes continuous raw EEG channel patches into\ncompact neural codes. We then pre-train neural Transformers by predicting the\noriginal neural codes for the masked EEG channel patches. The LaBraMs were\npre-trained on about 2,500 hours of various types of EEG signals from around 20\ndatasets and validated on multiple different types of downstream tasks.\nExperiments on abnormal detection, event type classification, emotion\nrecognition, and gait prediction show that our LaBraM outperforms all compared\nSOTA methods in their respective fields. Our code is available at\nhttps://github.com/935963004/LaBraM.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Wei-Bang Jiang",
            "Li-Ming Zhao",
            "Bao-Liang Lu"
        ],
        "published": "2024-05-29T05:08:16Z"
    },
    {
        "title": "Inpaint Biases: A Pathway to Accurate and Unbiased Image Generation",
        "link": "http://arxiv.org/abs/2405.18762v2",
        "abstract": "This paper examines the limitations of advanced text-to-image models in\naccurately rendering unconventional concepts which are scarcely represented or\nabsent in their training datasets. We identify how these limitations not only\nconfine the creative potential of these models but also pose risks of\nreinforcing stereotypes. To address these challenges, we introduce the Inpaint\nBiases framework, which employs user-defined masks and inpainting techniques to\nenhance the accuracy of image generation, particularly for novel or\ninaccurately rendered objects. Through experimental validation, we demonstrate\nhow this framework significantly improves the fidelity of generated images to\nthe user's intent, thereby expanding the models' creative capabilities and\nmitigating the risk of perpetuating biases. Our study contributes to the\nadvancement of text-to-image models as unbiased, versatile tools for creative\nexpression.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Jiyoon Myung",
            "Jihyeon Park"
        ],
        "published": "2024-05-29T05:04:07Z"
    },
    {
        "title": "FDQN: A Flexible Deep Q-Network Framework for Game Automation",
        "link": "http://arxiv.org/abs/2405.18761v1",
        "abstract": "In reinforcement learning, it is often difficult to automate\nhigh-dimensional, rapid decision-making in dynamic environments, especially\nwhen domains require real-time online interaction and adaptive strategies such\nas web-based games. This work proposes a state-of-the-art Flexible Deep\nQ-Network (FDQN) framework that can address this challenge with a selfadaptive\napproach that is processing high-dimensional sensory data in realtime using a\nCNN and dynamically adapting the model architecture to varying action spaces of\ndifferent gaming environments and outperforming previous baseline models in\nvarious Atari games and the Chrome Dino game as baselines. Using the\nepsilon-greedy policy, it effectively balances the new learning and\nexploitation for improved performance, and it has been designed with a modular\nstructure that it can be easily adapted to other HTML-based games without\ntouching the core part of the framework. It is demonstrated that the FDQN\nframework can successfully solve a well-defined task in a laboratory condition,\nbut more importantly it also discusses potential applications to more\nchallenging real-world cases and serve as the starting point for future further\nexploration into automated game play and beyond.",
        "subjects": [
            "cs.LG",
            "68T05, 93E35",
            "I.2.8; I.2.6; I.5.1"
        ],
        "authors": [
            "Prabhath Reddy Gujavarthy"
        ],
        "published": "2024-05-29T05:00:50Z"
    },
    {
        "title": "EvaGaussians: Event Stream Assisted Gaussian Splatting from Blurry\n  Images",
        "link": "http://arxiv.org/abs/2405.20224v1",
        "abstract": "3D Gaussian Splatting (3D-GS) has demonstrated exceptional capabilities in 3D\nscene reconstruction and novel view synthesis. However, its training heavily\ndepends on high-quality, sharp images and accurate camera poses. Fulfilling\nthese requirements can be challenging in non-ideal real-world scenarios, where\nmotion-blurred images are commonly encountered in high-speed moving cameras or\nlow-light environments that require long exposure times. To address these\nchallenges, we introduce Event Stream Assisted Gaussian Splatting\n(EvaGaussians), a novel approach that integrates event streams captured by an\nevent camera to assist in reconstructing high-quality 3D-GS from blurry images.\nCapitalizing on the high temporal resolution and dynamic range offered by the\nevent camera, we leverage the event streams to explicitly model the formation\nprocess of motion-blurred images and guide the deblurring reconstruction of\n3D-GS. By jointly optimizing the 3D-GS parameters and recovering camera motion\ntrajectories during the exposure time, our method can robustly facilitate the\nacquisition of high-fidelity novel views with intricate texture details. We\ncomprehensively evaluated our method and compared it with previous\nstate-of-the-art deblurring rendering methods. Both qualitative and\nquantitative comparisons demonstrate that our method surpasses existing\ntechniques in restoring fine details from blurry images and producing\nhigh-fidelity novel views.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Wangbo Yu",
            "Chaoran Feng",
            "Jiye Tang",
            "Xu Jia",
            "Li Yuan",
            "Yonghong Tian"
        ],
        "published": "2024-05-29T04:59:27Z"
    },
    {
        "title": "Learning to Continually Learn with the Bayesian Principle",
        "link": "http://arxiv.org/abs/2405.18758v1",
        "abstract": "In the present era of deep learning, continual learning research is mainly\nfocused on mitigating forgetting when training a neural network with stochastic\ngradient descent on a non-stationary stream of data. On the other hand, in the\nmore classical literature of statistical machine learning, many models have\nsequential Bayesian update rules that yield the same learning outcome as the\nbatch training, i.e., they are completely immune to catastrophic forgetting.\nHowever, they are often overly simple to model complex real-world data. In this\nwork, we adopt the meta-learning paradigm to combine the strong\nrepresentational power of neural networks and simple statistical models'\nrobustness to forgetting. In our novel meta-continual learning framework,\ncontinual learning takes place only in statistical models via ideal sequential\nBayesian update rules, while neural networks are meta-learned to bridge the raw\ndata and the statistical models. Since the neural networks remain fixed during\ncontinual learning, they are protected from catastrophic forgetting. This\napproach not only achieves significantly improved performance but also exhibits\nexcellent scalability. Since our approach is domain-agnostic and\nmodel-agnostic, it can be applied to a wide range of problems and easily\nintegrated with existing model architectures.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Soochan Lee",
            "Hyeonseong Jeon",
            "Jaehyeon Son",
            "Gunhee Kim"
        ],
        "published": "2024-05-29T04:53:31Z"
    },
    {
        "title": "Multi-objective Cross-task Learning via Goal-conditioned GPT-based\n  Decision Transformers for Surgical Robot Task Automation",
        "link": "http://arxiv.org/abs/2405.18757v1",
        "abstract": "Surgical robot task automation has been a promising research topic for\nimproving surgical efficiency and quality. Learning-based methods have been\nrecognized as an interesting paradigm and been increasingly investigated.\nHowever, existing approaches encounter difficulties in long-horizon\ngoal-conditioned tasks due to the intricate compositional structure, which\nrequires decision-making for a sequence of sub-steps and understanding of\ninherent dynamics of goal-reaching tasks. In this paper, we propose a new\nlearning-based framework by leveraging the strong reasoning capability of the\nGPT-based architecture to automate surgical robotic tasks. The key to our\napproach is developing a goal-conditioned decision transformer to achieve\nsequential representations with goal-aware future indicators in order to\nenhance temporal reasoning. Moreover, considering to exploit a general\nunderstanding of dynamics inherent in manipulations, thus making the model's\nreasoning ability to be task-agnostic, we also design a cross-task pretraining\nparadigm that uses multiple training objectives associated with data from\ndiverse tasks. We have conducted extensive experiments on 10 tasks using the\nsurgical robot learning simulator SurRoL~\\cite{long2023human}. The results show\nthat our new approach achieves promising performance and task versatility\ncompared to existing methods. The learned trajectories can be deployed on the\nda Vinci Research Kit (dVRK) for validating its practicality in real surgical\nrobot settings. Our project website is at: https://med-air.github.io/SurRoL.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Jiawei Fu",
            "Yonghao Long",
            "Kai Chen",
            "Wang Wei",
            "Qi Dou"
        ],
        "published": "2024-05-29T04:50:53Z"
    },
    {
        "title": "Provable Contrastive Continual Learning",
        "link": "http://arxiv.org/abs/2405.18756v1",
        "abstract": "Continual learning requires learning incremental tasks with dynamic data\ndistributions. So far, it has been observed that employing a combination of\ncontrastive loss and distillation loss for training in continual learning\nyields strong performance. To the best of our knowledge, however, this\ncontrastive continual learning framework lacks convincing theoretical\nexplanations. In this work, we fill this gap by establishing theoretical\nperformance guarantees, which reveal how the performance of the model is\nbounded by training losses of previous tasks in the contrastive continual\nlearning framework. Our theoretical explanations further support the idea that\npre-training can benefit continual learning. Inspired by our theoretical\nanalysis of these guarantees, we propose a novel contrastive continual learning\nalgorithm called CILA, which uses adaptive distillation coefficients for\ndifferent tasks. These distillation coefficients are easily computed by the\nratio between average distillation losses and average contrastive losses from\nprevious tasks. Our method shows great improvement on standard benchmarks and\nachieves new state-of-the-art performance.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "stat.AP",
            "stat.ML"
        ],
        "authors": [
            "Yichen Wen",
            "Zhiquan Tan",
            "Kaipeng Zheng",
            "Chuanlong Xie",
            "Weiran Huang"
        ],
        "published": "2024-05-29T04:48:11Z"
    },
    {
        "title": "GIST: Greedy Independent Set Thresholding for Diverse Data Summarization",
        "link": "http://arxiv.org/abs/2405.18754v1",
        "abstract": "We propose a novel subset selection task called min-distance diverse data\nsummarization ($\\textsf{MDDS}$), which has a wide variety of applications in\nmachine learning, e.g., data sampling and feature selection. Given a set of\npoints in a metric space, the goal is to maximize an objective that combines\nthe total utility of the points and a diversity term that captures the minimum\ndistance between any pair of selected points, subject to the constraint $|S|\n\\le k$. For example, the points may correspond to training examples in a data\nsampling problem, e.g., learned embeddings of images extracted from a deep\nneural network. This work presents the $\\texttt{GIST}$ algorithm, which\nachieves a $\\frac{2}{3}$-approximation guarantee for $\\textsf{MDDS}$ by\napproximating a series of maximum independent set problems with a bicriteria\ngreedy algorithm. We also prove a complementary\n$(\\frac{2}{3}+\\varepsilon)$-hardness of approximation, for any $\\varepsilon >\n0$. Finally, we provide an empirical study that demonstrates $\\texttt{GIST}$\noutperforms existing methods for $\\textsf{MDDS}$ on synthetic data, and also\nfor a real-world image classification experiment the studies single-shot subset\nselection for ImageNet.",
        "subjects": [
            "cs.DS",
            "cs.LG"
        ],
        "authors": [
            "Matthew Fahrbach",
            "Srikumar Ramalingam",
            "Morteza Zadimoghaddam",
            "Sara Ahmadian",
            "Gui Citovsky",
            "Giulia DeSalvo"
        ],
        "published": "2024-05-29T04:39:24Z"
    },
    {
        "title": "Confronting the Reproducibility Crisis: A Case Study in Validating\n  Certified Robustness",
        "link": "http://arxiv.org/abs/2405.18753v1",
        "abstract": "Reproducibility is a cornerstone of scientific research, enabling validation,\nextension, and progress. However, the rapidly evolving nature of software and\ndependencies poses significant challenges to reproducing research results,\nparticularly in fields like adversarial robustness for deep neural networks,\nwhere complex codebases and specialized toolkits are utilized. This paper\npresents a case study of attempting to validate the results on certified\nadversarial robustness in \"SoK: Certified Robustness for Deep Neural Networks\"\nusing the VeriGauge toolkit. Despite following the documented methodology,\nnumerous software and hardware compatibility issues were encountered, including\noutdated or unavailable dependencies, version conflicts, and driver\nincompatibilities. While a subset of the original results could be run, key\nfindings related to the empirical robust accuracy of various verification\nmethods proved elusive due to these technical obstacles, as well as slight\ndiscrepancies in the test results. This practical experience sheds light on the\nreproducibility crisis afflicting adversarial robustness research, where a lack\nof reproducibility threatens scientific integrity and hinders progress. The\npaper discusses the broader implications of this crisis, proposing potential\nsolutions such as containerization, software preservation, and comprehensive\ndocumentation practices. Furthermore, it highlights the need for collaboration\nand standardization efforts within the research community to develop robust\nframeworks for reproducible research. By addressing the reproducibility crisis\nhead-on, this work aims to contribute to the ongoing discourse on scientific\nreproducibility and advocate for best practices that ensure the reliability and\nvalidity of research findings within not only adversarial robustness, but\nsecurity and technology research as a whole.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Richard H. Moulton",
            "Gary A. McCully",
            "John D. Hastings"
        ],
        "published": "2024-05-29T04:37:19Z"
    },
    {
        "title": "Resilient Average Consensus with Adversaries via Distributed Detection\n  and Recovery",
        "link": "http://arxiv.org/abs/2405.18752v1",
        "abstract": "We study the problem of resilient average consensus in multi-agent systems\nwhere some of the agents are subject to failures or attacks. The objective of\nresilient average consensus is for non-faulty/normal agents to converge to the\naverage of their initial values despite the erroneous effects from malicious\nagents. To this end, we propose a successful distributed iterative resilient\naverage consensus algorithm for the multi-agent networks with general directed\ntopologies. The proposed algorithm has two parts at each iteration: detection\nand averaging. For the detection part, we propose two distributed algorithms\nand one of them can detect malicious agents with only the information from\ndirect in-neighbors. For the averaging part, we extend the applicability of an\nexisting averaging algorithm where normal agents can remove the effects from\nmalicious agents so far, after they are detected. Another important feature of\nour method is that it can handle the case where malicious agents are\nneighboring and collaborating with each other to mislead the normal ones from\naveraging. This case cannot be solved by existing detection approaches in\nrelated literature. Moreover, our algorithm is efficient in storage usage\nespecially for large-scale networks as each agent only requires the values of\nneighbors within two hops. Lastly, numerical examples are given to verify the\nefficacy of the proposed algorithms.",
        "subjects": [
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Liwei Yuan",
            "Hideaki Ishii"
        ],
        "published": "2024-05-29T04:32:28Z"
    },
    {
        "title": "On the Limits of Multi-modal Meta-Learning with Auxiliary Task\n  Modulation Using Conditional Batch Normalization",
        "link": "http://arxiv.org/abs/2405.18751v2",
        "abstract": "Few-shot learning aims to learn representations that can tackle novel tasks\ngiven a small number of examples. Recent studies show that cross-modal learning\ncan improve representations for few-shot classification. More specifically,\nlanguage is a rich modality that can be used to guide visual learning. In this\nwork, we experiment with a multi-modal architecture for few-shot learning that\nconsists of three components: a classifier, an auxiliary network, and a bridge\nnetwork. While the classifier performs the main classification task, the\nauxiliary network learns to predict language representations from the same\ninput, and the bridge network transforms high-level features of the auxiliary\nnetwork into modulation parameters for layers of the few-shot classifier using\nconditional batch normalization. The bridge should encourage a form of\nlightweight semantic alignment between language and vision which could be\nuseful for the classifier. However, after evaluating the proposed approach on\ntwo popular few-shot classification benchmarks we find that a) the improvements\ndo not reproduce across benchmarks, and b) when they do, the improvements are\ndue to the additional compute and parameters introduced by the bridge network.\nWe contribute insights and recommendations for future work in multi-modal\nmeta-learning, especially when using language representations.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Jordi Armengol-Estap",
            "Vincent Michalski",
            "Ramnath Kumar",
            "Pierre-Luc St-Charles",
            "Doina Precup",
            "Samira Ebrahimi Kahou"
        ],
        "published": "2024-05-29T04:29:12Z"
    },
    {
        "title": "T2V-Turbo: Breaking the Quality Bottleneck of Video Consistency Model\n  with Mixed Reward Feedback",
        "link": "http://arxiv.org/abs/2405.18750v1",
        "abstract": "Diffusion-based text-to-video (T2V) models have achieved significant success\nbut continue to be hampered by the slow sampling speed of their iterative\nsampling processes. To address the challenge, consistency models have been\nproposed to facilitate fast inference, albeit at the cost of sample quality. In\nthis work, we aim to break the quality bottleneck of a video consistency model\n(VCM) to achieve $\\textbf{both fast and high-quality video generation}$. We\nintroduce T2V-Turbo, which integrates feedback from a mixture of differentiable\nreward models into the consistency distillation (CD) process of a pre-trained\nT2V model. Notably, we directly optimize rewards associated with single-step\ngenerations that arise naturally from computing the CD loss, effectively\nbypassing the memory constraints imposed by backpropagating gradients through\nan iterative sampling process. Remarkably, the 4-step generations from our\nT2V-Turbo achieve the highest total score on VBench, even surpassing Gen-2 and\nPika. We further conduct human evaluations to corroborate the results,\nvalidating that the 4-step generations from our T2V-Turbo are preferred over\nthe 50-step DDIM samples from their teacher models, representing more than a\ntenfold acceleration while improving video generation quality.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jiachen Li",
            "Weixi Feng",
            "Tsu-Jui Fu",
            "Xinyi Wang",
            "Sugato Basu",
            "Wenhu Chen",
            "William Yang Wang"
        ],
        "published": "2024-05-29T04:26:17Z"
    },
    {
        "title": "A SARS-CoV-2 Interaction Dataset and VHH Sequence Corpus for Antibody\n  Language Models",
        "link": "http://arxiv.org/abs/2405.18749v1",
        "abstract": "Antibodies are crucial proteins produced by the immune system to eliminate\nharmful foreign substances and have become pivotal therapeutic agents for\ntreating human diseases. To accelerate the discovery of antibody therapeutics,\nthere is growing interest in constructing language models using antibody\nsequences. However, the applicability of pre-trained language models for\nantibody discovery has not been thoroughly evaluated due to the scarcity of\nlabeled datasets. To overcome these limitations, we introduce AVIDa-SARS-CoV-2,\na dataset featuring the antigen-variable domain of heavy chain of heavy chain\nantibody (VHH) interactions obtained from two alpacas immunized with severe\nacute respiratory syndrome coronavirus 2 (SARS-CoV-2) spike proteins.\nAVIDa-SARS-CoV-2 includes binary labels indicating the binding or non-binding\nof diverse VHH sequences to 12 SARS-CoV-2 mutants, such as the Delta and\nOmicron variants. Furthermore, we release VHHCorpus-2M, a pre-training dataset\nfor antibody language models, containing over two million VHH sequences. We\nreport benchmark results for predicting SARS-CoV-2-VHH binding using VHHBERT\npre-trained on VHHCorpus-2M and existing general protein and antibody-specific\npre-trained language models. These results confirm that AVIDa-SARS-CoV-2\nprovides valuable benchmarks for evaluating the representation capabilities of\nantibody language models for binding prediction, thereby facilitating the\ndevelopment of AI-driven antibody discovery. The datasets are available at\nhttps://datasets.cognanous.com.",
        "subjects": [
            "cs.LG",
            "q-bio.GN"
        ],
        "authors": [
            "Hirofumi Tsuruta",
            "Hiroyuki Yamazaki",
            "Ryota Maeda",
            "Ryotaro Tamura",
            "Akihiro Imura"
        ],
        "published": "2024-05-29T04:22:18Z"
    },
    {
        "title": "STIQ: Safeguarding Training and Inferencing of Quantum Neural Networks\n  from Untrusted Cloud",
        "link": "http://arxiv.org/abs/2405.18746v1",
        "abstract": "The high expenses imposed by current quantum cloud providers, coupled with\nthe escalating need for quantum resources, may incentivize the emergence of\ncheaper cloud-based quantum services from potentially untrusted providers.\nDeploying or hosting quantum models, such as Quantum Neural Networks (QNNs), on\nthese untrusted platforms introduces a myriad of security concerns, with the\nmost critical one being model theft. This vulnerability stems from the cloud\nprovider's full access to these circuits during training and/or inference. In\nthis work, we introduce STIQ, a novel ensemble-based strategy designed to\nsafeguard QNNs against such cloud-based adversaries. Our method innovatively\ntrains two distinct QNNs concurrently, hosting them on same or different\nplatforms, in a manner that each network yields obfuscated outputs rendering\nthe individual QNNs ineffective for adversaries operating within cloud\nenvironments. However, when these outputs are combined locally (using an\naggregate function), they reveal the correct result. Through extensive\nexperiments across various QNNs and datasets, our technique has proven to\neffectively masks the accuracy and losses of the individually hosted models by\nupto 76\\%, albeit at the expense of $\\leq 2\\times$ increase in the total\ncomputational overhead. This trade-off, however, is a small price to pay for\nthe enhanced security and integrity of QNNs in a cloud-based environment prone\nto untrusted adversaries. We also demonstrated STIQ's practical application by\nevaluating it on real 127-qubit IBM\\_Sherbrooke hardware, showing that STIQ\nachieves up to 60\\% obfuscation, with combined performance comparable to an\nunobfuscated model.",
        "subjects": [
            "quant-ph",
            "cs.LG"
        ],
        "authors": [
            "Satwik Kundu",
            "Swaroop Ghosh"
        ],
        "published": "2024-05-29T04:09:46Z"
    },
    {
        "title": "PanoNormal: Monocular Indoor 360 Surface Normal Estimation",
        "link": "http://arxiv.org/abs/2405.18745v1",
        "abstract": "The presence of spherical distortion on the Equirectangular image is an\nacknowledged challenge in dense regression computer vision tasks, such as\nsurface normal estimation. Recent advances in convolutional neural networks\n(CNNs) strive to mitigate spherical distortion but often fall short in\ncapturing holistic structures effectively, primarily due to their fixed\nreceptive field. On the other hand, vision transformers (ViTs) excel in\nestablishing long-range dependencies through a global self-attention mechanism,\nyet they encounter limitations in preserving local details. We introduce\n\\textit{PanoNormal}, a monocular surface normal estimation architecture\ndesigned for 360{\\deg} images, which combines the strengths of CNNs and ViTs.\nSpecifically, we employ a multi-level global self-attention scheme with the\nconsideration of the spherical feature distribution, enhancing the\ncomprehensive understanding of the scene. Our experimental results demonstrate\nthat our approach achieves state-of-the-art performance across multiple popular\n360{\\deg} monocular datasets. The code and models will be released.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Kun Huang",
            "Fanglue Zhang",
            "Neil Dodgson"
        ],
        "published": "2024-05-29T04:07:14Z"
    },
    {
        "title": "PermLLM: Private Inference of Large Language Models within 3 Seconds\n  under WAN",
        "link": "http://arxiv.org/abs/2405.18744v1",
        "abstract": "The emergence of ChatGPT marks the arrival of the large language model (LLM)\nera. While LLMs demonstrate their power in a variety of fields, they also raise\nserious privacy concerns as the users' queries are sent to the model provider.\nOn the other side, deploying the LLM on the user's device will also leak all\nthe model data. Existing methods based on secure multiparty computation (MPC)\nmanaged to protect both the privacy of the model parameters and user queries.\nHowever, they require gigabytes of data transfer and several minutes to\ngenerate just one token, making them impractical for most real-world\napplications. To improve the efficiency of private LLM inference, we propose\nPermLLM, which accelerates the evaluation of non-linear functions using secure\nrandom permutation. Along with the optimized secret sharing protocols and\nhomomorphic encryption, PermLLM achieves two-party private inference of the\nChatGLM-6B model at the speed of around 3s/token, under a realistic network\nsetting (10ms RTT and 1Gbps bandwidth), which is magnitudes faster than\nexisting MPC solutions.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Fei Zheng",
            "Chaochao Chen",
            "Zhongxuan Han",
            "Xiaolin Zheng"
        ],
        "published": "2024-05-29T04:06:50Z"
    },
    {
        "title": "Musical Phrase Segmentation via Grammatical Induction",
        "link": "http://arxiv.org/abs/2405.18742v1",
        "abstract": "We outline a solution to the challenge of musical phrase segmentation that\nuses grammatical induction algorithms, a class of algorithms which infer a\ncontext-free grammar from an input sequence. We analyze the performance of five\ngrammatical induction algorithms on three datasets using various musical\nviewpoint combinations. Our experiments show that the LONGESTFIRST algorithm\nachieves the best F1 scores across all three datasets and that input encodings\nthat include the duration viewpoint result in the best performance.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Reed Perkins",
            "Dan Ventura"
        ],
        "published": "2024-05-29T04:04:36Z"
    },
    {
        "title": "Genshin: General Shield for Natural Language Processing with Large\n  Language Models",
        "link": "http://arxiv.org/abs/2405.18741v1",
        "abstract": "Large language models (LLMs) like ChatGPT, Gemini, or LLaMA have been\ntrending recently, demonstrating considerable advancement and generalizability\npower in countless domains. However, LLMs create an even bigger black box\nexacerbating opacity, with interpretability limited to few approaches. The\nuncertainty and opacity embedded in LLMs' nature restrict their application in\nhigh-stakes domains like financial fraud, phishing, etc. Current approaches\nmainly rely on traditional textual classification with posterior interpretable\nalgorithms, suffering from attackers who may create versatile adversarial\nsamples to break the system's defense, forcing users to make trade-offs between\nefficiency and robustness. To address this issue, we propose a novel cascading\nframework called Genshin (General Shield for Natural Language Processing with\nLarge Language Models), utilizing LLMs as defensive one-time plug-ins. Unlike\nmost applications of LLMs that try to transform text into something new or\nstructural, Genshin uses LLMs to recover text to its original state. Genshin\naims to combine the generalizability of the LLM, the discrimination of the\nmedian model, and the interpretability of the simple model. Our experiments on\nthe task of sentimental analysis and spam detection have shown fatal flaws of\nthe current median models and exhilarating results on LLMs' recovery ability,\ndemonstrating that Genshin is both effective and efficient. In our ablation\nstudy, we unearth several intriguing observations. Utilizing the LLM defender,\na tool derived from the 4th paradigm, we have reproduced BERT's 15% optimal\nmask rate results in the 3rd paradigm of NLP. Additionally, when employing the\nLLM as a potential adversarial tool, attackers are capable of executing\neffective attacks that are nearly semantically lossless.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Xiao Peng",
            "Tao Liu",
            "Ying Wang"
        ],
        "published": "2024-05-29T04:04:05Z"
    },
    {
        "title": "Reverse Image Retrieval Cues Parametric Memory in Multimodal LLMs",
        "link": "http://arxiv.org/abs/2405.18740v1",
        "abstract": "Despite impressive advances in recent multimodal large language models\n(MLLMs), state-of-the-art models such as from the GPT-4 suite still struggle\nwith knowledge-intensive tasks. To address this, we consider Reverse Image\nRetrieval (RIR) augmented generation, a simple yet effective strategy to\naugment MLLMs with web-scale reverse image search results. RIR robustly\nimproves knowledge-intensive visual question answering (VQA) of GPT-4V by\n37-43%, GPT-4 Turbo by 25-27%, and GPT-4o by 18-20% in terms of open-ended VQA\nevaluation metrics. To our surprise, we discover that RIR helps the model to\nbetter access its own world knowledge. Concretely, our experiments suggest that\nRIR augmentation helps by providing further visual and textual cues without\nnecessarily containing the direct answer to a query. In addition, we elucidate\ncases in which RIR can hurt performance and conduct a human evaluation.\nFinally, we find that the overall advantage of using RIR makes it difficult for\nan agent that can choose to use RIR to perform better than an approach where\nRIR is the default setting.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Jialiang Xu",
            "Michael Moor",
            "Jure Leskovec"
        ],
        "published": "2024-05-29T04:00:41Z"
    },
    {
        "title": "FlocOff: Data Heterogeneity Resilient Federated Learning with\n  Communication-Efficient Edge Offloading",
        "link": "http://arxiv.org/abs/2405.18739v1",
        "abstract": "Federated Learning (FL) has emerged as a fundamental learning paradigm to\nharness massive data scattered at geo-distributed edge devices in a\nprivacy-preserving way. Given the heterogeneous deployment of edge devices,\nhowever, their data are usually Non-IID, introducing significant challenges to\nFL including degraded training accuracy, intensive communication costs, and\nhigh computing complexity. Towards that, traditional approaches typically\nutilize adaptive mechanisms, which may suffer from scalability issues,\nincreased computational overhead, and limited adaptability to diverse edge\nenvironments. To address that, this paper instead leverages the observation\nthat the computation offloading involves inherent functionalities such as node\nmatching and service correlation to achieve data reshaping and proposes\nFederated learning based on computing Offloading (FlocOff) framework, to\naddress data heterogeneity and resource-constrained challenges. Specifically,\nFlocOff formulates the FL process with Non-IID data in edge scenarios and\nderives rigorous analysis on the impact of imbalanced data distribution. Based\non this, FlocOff decouples the optimization in two steps, namely : (1)\nMinimizes the Kullback-Leibler (KL) divergence via Computation Offloading\nscheduling (MKL-CO); (2) Minimizes the Communication Cost through Resource\nAllocation (MCC-RA). Extensive experimental results demonstrate that the\nproposed FlocOff effectively improves model convergence and accuracy by\n14.3\\%-32.7\\% while reducing data heterogeneity under various data\ndistributions.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "authors": [
            "Mulei Ma",
            "Chenyu Gong",
            "Liekang Zeng",
            "Yang Yang",
            "Liantao Wu"
        ],
        "published": "2024-05-29T03:53:52Z"
    },
    {
        "title": "WLC-Net: a robust and fast deep-learning wood-leaf classification method",
        "link": "http://arxiv.org/abs/2405.18737v1",
        "abstract": "Wood-leaf classification is an essential and fundamental prerequisite in the\nanalysis and estimation of forest attributes from terrestrial laser scanning\n(TLS) point clouds,including critical measurements such as diameter at breast\nheight(DBH),above-ground biomass(AGB),wood volume.To address this,we introduce\nthe Wood-Leaf Classification Network(WLC-Net),a deep learning model derived\nfrom PointNet++,designed to differentiate between wood and leaf points within\ntree point clouds.WLC-Net enhances classification accuracy,completeness,and\nspeed by incorporating linearity as an inherent feature,refining the\ninput-output framework,and optimizing the centroid sampling technique.WLC-Net\nwas trained and assessed using three distinct tree species datasets,comprising\na total of 102 individual tree point clouds:21 Chinese ash trees,21 willow\ntrees,and 60 tropical trees.For comparative evaluation,five alternative\nmethods,including PointNet++,DGCNN,Krishna Moorthy's method,LeWoS, and Sun's\nmethod,were also applied to these datasets.The classification accuracy of all\nsix methods was quantified using three metrics:overall accuracy(OA),mean\nIntersection over Union(mIoU),and F1-score.Across all three datasets,WLC-Net\ndemonstrated superior performance, achieving OA scores of 0.9778, 0.9712, and\n0.9508;mIoU scores of 0.9761, 0.9693,and 0.9141;and F1-scores of 0.8628,\n0.7938,and 0.9019,respectively.The time costs of WLC-Net were also recorded to\nevaluate the efficiency.The average processing time was 102.74s per million\npoints for WLC-Net.In terms of visual inspect,accuracy evaluation and\nefficiency evaluation,the results suggest that WLC-Net presents a promising\napproach for wood-leaf classification,distinguished by its high accuracy. In\naddition,WLC-Net also exhibits strong applicability across various tree point\nclouds and holds promise for further optimization.",
        "subjects": [
            "cs.CV",
            "I.4.6"
        ],
        "authors": [
            "Hanlong Li",
            "Pei Wang",
            "Yuhan Wu",
            "Jing Ren",
            "Yuhang Gao",
            "Lingyun Zhang",
            "Mingtai Zhang",
            "Wenxin Chen"
        ],
        "published": "2024-05-29T03:39:23Z"
    },
    {
        "title": "PillarHist: A Quantization-aware Pillar Feature Encoder based on\n  Height-aware Histogram",
        "link": "http://arxiv.org/abs/2405.18734v1",
        "abstract": "Real-time and high-performance 3D object detection plays a critical role in\nautonomous driving and robotics. Recent pillar-based 3D object detectors have\ngained significant attention due to their compact representation and low\ncomputational overhead, making them suitable for onboard deployment and\nquantization. However, existing pillar-based detectors still suffer from\ninformation loss along height dimension and large numerical distribution\ndifference during pillar feature encoding (PFE), which severely limits their\nperformance and quantization potential. To address above issue, we first unveil\nthe importance of different input information during PFE and identify the\nheight dimension as a key factor in enhancing 3D detection performance.\nMotivated by this observation, we propose a height-aware pillar feature encoder\nnamed PillarHist. Specifically, PillarHist statistics the discrete distribution\nof points at different heights within one pillar. This simple yet effective\ndesign greatly preserves the information along the height dimension while\nsignificantly reducing the computation overhead of the PFE. Meanwhile,\nPillarHist also constrains the arithmetic distribution of PFE input to a stable\nrange, making it quantization-friendly. Notably, PillarHist operates\nexclusively within the PFE stage to enhance performance, enabling seamless\nintegration into existing pillar-based methods without introducing complex\noperations. Extensive experiments show the effectiveness of PillarHist in terms\nof both efficiency and performance.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Sifan Zhou",
            "Zhihang Yuan",
            "Dawei Yang",
            "Xubin Wen",
            "Xing Hu",
            "Yuguang Shi",
            "Ziyu Zhao",
            "Xiaobo Lu"
        ],
        "published": "2024-05-29T03:28:16Z"
    },
    {
        "title": "Efficient Learning in Chinese Checkers: Comparing Parameter Sharing in\n  Multi-Agent Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.18733v1",
        "abstract": "We show that multi-agent reinforcement learning (MARL) with full parameter\nsharing outperforms independent and partially shared architectures in the\ncompetitive perfect-information homogenous game of Chinese Checkers. To run our\nexperiments, we develop a new MARL environment: variable-size, six-player\nChinese Checkers. This custom environment was developed in PettingZoo and\nsupports all traditional rules of the game including chaining jumps. This is,\nto the best of our knowledge, the first implementation of Chinese Checkers that\nremains faithful to the true game.\n  Chinese Checkers is difficult to learn due to its large branching factor and\npotentially infinite horizons. We borrow the concept of branching actions\n(submoves) from complex action spaces in other RL domains, where a submove may\nnot end a player's turn immediately. This drastically reduces the\ndimensionality of the action space. Our observation space is inspired by\nAlphaGo with many binary game boards stacked in a 3D array to encode\ninformation.\n  The PettingZoo environment, training and evaluation logic, and analysis\nscripts can be found on\n\\href{https://github.com/noahadhikari/pettingzoo-chinese-checkers}{Github}.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Noah Adhikari",
            "Allen Gu"
        ],
        "published": "2024-05-29T03:27:30Z"
    },
    {
        "title": "Approximate Thompson Sampling for Learning Linear Quadratic Regulators\n  with $O(\\sqrt{T})$ Regret",
        "link": "http://arxiv.org/abs/2405.19380v1",
        "abstract": "We propose an approximate Thompson sampling algorithm that learns linear\nquadratic regulators (LQR) with an improved Bayesian regret bound of\n$O(\\sqrt{T})$. Our method leverages Langevin dynamics with a meticulously\ndesigned preconditioner as well as a simple excitation mechanism. We show that\nthe excitation signal induces the minimum eigenvalue of the preconditioner to\ngrow over time, thereby accelerating the approximate posterior sampling\nprocess. Moreover, we identify nontrivial concentration properties of the\napproximate posteriors generated by our algorithm. These properties enable us\nto bound the moments of the system state and attain an $O(\\sqrt{T})$ regret\nbound without the unrealistic restrictive assumptions on parameter sets that\nare often used in the literature.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Yeoneung Kim",
            "Gihun Kim",
            "Insoon Yang"
        ],
        "published": "2024-05-29T03:24:56Z"
    },
    {
        "title": "Gemini & Physical World: Large Language Models Can Estimate the\n  Intensity of Earthquake Shaking from Multi-Modal Social Media Posts",
        "link": "http://arxiv.org/abs/2405.18732v1",
        "abstract": "This paper presents a novel approach for estimating the ground shaking\nintensity using social media data and CCTV footage. Employing the Gemini Pro\n(Reid et al. 2024) model, a multi-modal language model, we demonstrate the\nability to extract relevant information from unstructured data utilizing\ngenerative AI and natural language processing. The model output, in the form of\nModified Mercalli Intensity (MMI) values, align well with independent\nobservational data. Furthermore, our results suggest that beyond its advanced\nvisual and auditory understanding abilities, Gemini appears to utilize\nadditional sources of knowledge, including a simplified understanding of the\ngeneral relationship between earthquake magnitude, distance, and MMI intensity,\nwhich it presumably acquired during its training, in its reasoning and\ndecision-making processes. These findings raise intriguing questions about the\nextent of Gemini's general understanding of the physical world and its\nphenomena. The ability of Gemini to generate results consistent with\nestablished scientific knowledge highlights the potential of LLMs like Gemini\nin augmenting our understanding of complex physical phenomena such as\nearthquakes. More specifically, the results of this study highlight the\npotential of LLMs like Gemini to revolutionize citizen seismology by enabling\nrapid, effective, and flexible analysis of crowdsourced data from eyewitness\naccounts for assessing earthquake impact and providing crisis situational\nawareness. This approach holds great promise for improving early warning\nsystems, disaster response, and overall resilience in earthquake-prone regions.\nThis study provides a significant step toward harnessing the power of social\nmedia and AI for earthquake disaster mitigation.",
        "subjects": [
            "physics.geo-ph",
            "cs.AI",
            "cs.LG",
            "physics.app-ph"
        ],
        "authors": [
            "S. Mostafa Mousavi",
            "Marc Stogaitis",
            "Tajinder Gadh",
            "Richard M Allen",
            "Alexei Barski",
            "Robert Bosch",
            "Patrick Robertson",
            "Nivetha Thiruverahan",
            "Youngmin Cho"
        ],
        "published": "2024-05-29T03:23:34Z"
    },
    {
        "title": "VBIM-Net: Variational Born Iterative Network for Inverse Scattering\n  Problems",
        "link": "http://arxiv.org/abs/2405.18731v1",
        "abstract": "Recently, studies have shown the potential of integrating field-type\niterative methods with deep learning (DL) techniques in solving inverse\nscattering problems (ISPs). In this article, we propose a novel Variational\nBorn Iterative Network, namely, VBIM-Net, to solve the full-wave ISPs with\nsignificantly improved flexibility and inversion quality. The proposed VBIM-Net\nemulates the alternating updates of the total electric field and the contrast\nin the variational Born iterative method (VBIM) by multiple layers of\nsubnetworks. We embed the calculation of the contrast variation into each of\nthe subnetworks, converting the scattered field residual into an approximate\ncontrast variation and then enhancing it by a U-Net, thus avoiding the\nrequirement of matched measurement dimension and grid resolution as in existing\napproaches. The total field and contrast of each layer's output is supervised\nin the loss function of VBIM-Net, which guarantees the physical\ninterpretability of variables of the subnetworks. In addition, we design a\ntraining scheme with extra noise to enhance the model's stability. Extensive\nnumerical results on synthetic and experimental data both verify the inversion\nquality, generalization ability, and robustness of the proposed VBIM-Net. This\nwork may provide some new inspiration for the design of efficient field-type DL\nschemes.",
        "subjects": [
            "eess.SP",
            "cs.AI",
            "physics.comp-ph"
        ],
        "authors": [
            "Ziqing Xing",
            "Zhaoyang Zhang",
            "Zirui Chen",
            "Yusong Wang",
            "Haoran Ma",
            "Zhun Wei",
            "Gang Bao"
        ],
        "published": "2024-05-29T03:21:09Z"
    },
    {
        "title": "Development of a Novel Impedance-Controlled Quasi-Direct-Drive Robotic\n  Hand",
        "link": "http://arxiv.org/abs/2405.18730v1",
        "abstract": "Most robotic hands and grippers rely on actuators with large gearboxes and\nforce sensors for controlling gripping force. However, this might not be ideal\nfor tasks that require the robot to interact with an unstructured and unknown\nenvironment. In this paper, we introduce a novel quasi-direct-drive\ntwo-fingered robotic hand with variable impedance control in the joint space\nand Cartesian space. The hand has a total of four degrees of freedom,\nbackdrivable differential gear trains, and four brushless direct current (BLDC)\nmotors. Motor torque is controlled through Field-Oriented Control (FOC) with\ncurrent sensing. Variable impedance control enables the robotic hand to execute\ndexterous manipulation tasks safely during environment-robot and human-robot\ninteractions. The quasi-direct-drive actuators eliminate the need for complex\ntactile/force sensors or precise motion planning when handling environmental\ncontact. A majority-3D-printed assembly makes this a low-cost research platform\nbuilt with affordable, readily available off-the-shelf components. Experimental\nvalidation demonstrates the robotic hand's capability for stable force-closure\nand form-closure grasps in the presence of disturbances, reliable in-hand\nmanipulation, and safe dynamic manipulations despite contact with the\nenvironment.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Jay Best",
            "Amin Fakhari"
        ],
        "published": "2024-05-29T03:20:46Z"
    },
    {
        "title": "Preferred-Action-Optimized Diffusion Policies for Offline Reinforcement\n  Learning",
        "link": "http://arxiv.org/abs/2405.18729v1",
        "abstract": "Offline reinforcement learning (RL) aims to learn optimal policies from\npreviously collected datasets. Recently, due to their powerful representational\ncapabilities, diffusion models have shown significant potential as policy\nmodels for offline RL issues. However, previous offline RL algorithms based on\ndiffusion policies generally adopt weighted regression to improve the policy.\nThis approach optimizes the policy only using the collected actions and is\nsensitive to Q-values, which limits the potential for further performance\nenhancement. To this end, we propose a novel preferred-action-optimized\ndiffusion policy for offline RL. In particular, an expressive conditional\ndiffusion model is utilized to represent the diverse distribution of a behavior\npolicy. Meanwhile, based on the diffusion model, preferred actions within the\nsame behavior distribution are automatically generated through the critic\nfunction. Moreover, an anti-noise preference optimization is designed to\nachieve policy improvement by using the preferred actions, which can adapt to\nnoise-preferred actions for stable training. Extensive experiments demonstrate\nthat the proposed method provides competitive or superior performance compared\nto previous state-of-the-art offline RL methods, particularly in sparse reward\ntasks such as Kitchen and AntMaze. Additionally, we empirically prove the\neffectiveness of anti-noise preference optimization.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Tianle Zhang",
            "Jiayi Guan",
            "Lin Zhao",
            "Yihang Li",
            "Dongjiang Li",
            "Zecui Zeng",
            "Lei Sun",
            "Yue Chen",
            "Xuelong Wei",
            "Lusong Li",
            "Xiaodong He"
        ],
        "published": "2024-05-29T03:19:59Z"
    },
    {
        "title": "CtrlA: Adaptive Retrieval-Augmented Generation via Probe-Guided Control",
        "link": "http://arxiv.org/abs/2405.18727v1",
        "abstract": "Retrieval-augmented generation (RAG) has emerged as a promising solution for\nmitigating hallucinations of large language models (LLMs) with retrieved\nexternal knowledge. Adaptive RAG enhances this approach by dynamically\nassessing the retrieval necessity, aiming to balance external and internal\nknowledge usage. However, existing adaptive RAG methods primarily realize\nretrieval on demand by relying on superficially verbalize-based or\nprobability-based feedback of LLMs, or directly fine-tuning LLMs via carefully\ncrafted datasets, resulting in unreliable retrieval necessity decisions, heavy\nextra costs, and sub-optimal response generation. We present the first attempts\nto delve into the internal states of LLMs to mitigate such issues by\nintroducing an effective probe-guided adaptive RAG framework, termed CtrlA.\nSpecifically, CtrlA employs an honesty probe to regulate the LLM's behavior by\nmanipulating its representations for increased honesty, and a confidence probe\nto monitor the internal states of LLM and assess confidence levels, determining\nthe retrieval necessity during generation. Experiments show that CtrlA is\nsuperior to existing adaptive RAG methods on a diverse set of tasks, the\nhonesty control can effectively make LLMs more honest and confidence monitoring\nis proven to be a promising indicator of retrieval trigger. Our codes are\navailable at https://github.com/HSLiu-Initial/CtrlA.git.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "authors": [
            "Huanshuo Liu",
            "Hao Zhang",
            "Zhijiang Guo",
            "Kuicai Dong",
            "Xiangyang Li",
            "Yi Quan Lee",
            "Cong Zhang",
            "Yong Liu"
        ],
        "published": "2024-05-29T03:17:16Z"
    },
    {
        "title": "Reverse the auditory processing pathway: Coarse-to-fine audio\n  reconstruction from fMRI",
        "link": "http://arxiv.org/abs/2405.18726v1",
        "abstract": "Drawing inspiration from the hierarchical processing of the human auditory\nsystem, which transforms sound from low-level acoustic features to high-level\nsemantic understanding, we introduce a novel coarse-to-fine audio\nreconstruction method. Leveraging non-invasive functional Magnetic Resonance\nImaging (fMRI) data, our approach mimics the inverse pathway of auditory\nprocessing. Initially, we utilize CLAP to decode fMRI data coarsely into a\nlow-dimensional semantic space, followed by a fine-grained decoding into the\nhigh-dimensional AudioMAE latent space guided by semantic features. These\nfine-grained neural features serve as conditions for audio reconstruction\nthrough a Latent Diffusion Model (LDM). Validation on three public fMRI\ndatasets-Brain2Sound, Brain2Music, and Brain2Speech-underscores the superiority\nof our coarse-to-fine decoding method over stand-alone fine-grained approaches,\nshowcasing state-of-the-art performance in metrics like FD, FAD, and KL.\nMoreover, by employing semantic prompts during decoding, we enhance the quality\nof reconstructed audio when semantic features are suboptimal. The demonstrated\nversatility of our model across diverse stimuli highlights its potential as a\nuniversal brain-to-audio framework. This research contributes to the\ncomprehension of the human auditory system, pushing boundaries in neural\ndecoding and audio reconstruction methodologies.",
        "subjects": [
            "cs.SD",
            "cs.CV",
            "cs.MM",
            "eess.AS"
        ],
        "authors": [
            "Che Liu",
            "Changde Du",
            "Xiaoyu Chen",
            "Huiguang He"
        ],
        "published": "2024-05-29T03:16:14Z"
    },
    {
        "title": "Can We Enhance the Quality of Mobile Crowdsensing Data Without Ground\n  Truth?",
        "link": "http://arxiv.org/abs/2405.18725v1",
        "abstract": "Mobile crowdsensing (MCS) has emerged as a prominent trend across various\ndomains. However, ensuring the quality of the sensing data submitted by mobile\nusers (MUs) remains a complex and challenging problem. To address this\nchallenge, an advanced method is required to detect low-quality sensing data\nand identify malicious MUs that may disrupt the normal operations of an MCS\nsystem. Therefore, this article proposes a prediction- and reputation-based\ntruth discovery (PRBTD) framework, which can separate low-quality data from\nhigh-quality data in sensing tasks. First, we apply a correlation-focused\nspatial-temporal transformer network to predict the ground truth of the input\nsensing data. Then, we extract the sensing errors of the data as features based\non the prediction results to calculate the implications among the data.\nFinally, we design a reputation-based truth discovery (TD) module for\nidentifying low-quality data with their implications. Given sensing data\nsubmitted by MUs, PRBTD can eliminate the data with heavy noise and identify\nmalicious MUs with high accuracy. Extensive experimental results demonstrate\nthat PRBTD outperforms the existing methods in terms of identification accuracy\nand data quality enhancement.",
        "subjects": [
            "cs.LG",
            "cs.MA"
        ],
        "authors": [
            "Jiajie Li",
            "Bo Gu",
            "Shimin Gong",
            "Zhou Su",
            "Mohsen Guizani"
        ],
        "published": "2024-05-29T03:16:12Z"
    },
    {
        "title": "Adapting Differential Molecular Representation with Hierarchical Prompts\n  for Multi-label Property Prediction",
        "link": "http://arxiv.org/abs/2405.18724v1",
        "abstract": "Accurate prediction of molecular properties is critical in the field of drug\ndiscovery. However, existing methods do not fully consider the fact that\nmolecules in the real world usually possess multiple property labels, and\ncomplex high-order relationships may exist among these labels. Therefore,\nmolecular representation learning models should generate differential molecular\nrepresentations that consider multi-granularity correlation information among\ntasks. To this end, our research introduces a Hierarchical Prompted Molecular\nRepresentation Learning Framework (HiPM), which enhances the differential\nexpression of tasks in molecular representations through task-aware prompts,\nand utilizes shared information among labels to mitigate negative transfer\nbetween different tasks. HiPM primarily consists of two core components: the\nMolecular Representation Encoder (MRE) and the Task-Aware Prompter (TAP). The\nMRE employs a hierarchical message-passing network architecture to capture\nmolecular features at both the atomic and motif levels, while the TAP uses\nagglomerative hierarchical clustering to build a prompt tree that reflects the\naffinity and distinctiveness of tasks, enabling the model to effectively handle\nthe complexity of multi-label property predictions. Extensive experiments\ndemonstrate that HiPM achieves state-of-the-art performance across various\nmulti-label datasets, offering a new perspective on multi-label molecular\nrepresentation learning.",
        "subjects": [
            "q-bio.QM",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Linjia Kang",
            "Songhua Zhou",
            "Shuyan Fang",
            "Shichao Liu",
            "Wen Zhang"
        ],
        "published": "2024-05-29T03:10:21Z"
    },
    {
        "title": "Conformal Depression Prediction",
        "link": "http://arxiv.org/abs/2405.18723v1",
        "abstract": "While existing depression recognition methods based on deep learning show\npromise, their practical application is hindered by the lack of\ntrustworthiness, as these deep models are often deployed as \\textit{black box}\nmodels, leaving us uncertain about the confidence of the model predictions. For\nhigh-risk clinical applications like depression recognition, uncertainty\nquantification is essential in decision-making. In this paper, we introduce\nconformal depression prediction (CDP), a depression recognition method with\nuncertainty quantification based on conformal prediction (CP), giving valid\nconfidence intervals with theoretical coverage guarantees for the model\npredictions. CDP is a plug-and-play module that requires neither model\nretraining nor an assumption about the depression data distribution. As CDP\nprovides only an average performance guarantee across all inputs rather than\nper-input performance guarantee, we propose CDP-ACC, an improved conformal\nprediction with approximate conditional coverage. CDP-ACC firstly estimates the\nprediction distribution through neighborhood relaxation, and then introduces a\nconformal score function by constructing nested sequences, so as to provide\ntighter prediction interval for each specific input. We empirically demonstrate\nthe application of uncertainty quantification in depression recognition, and\nthe effectiveness and superiority of CDP and CDP-ACC on the AVEC 2013 and AVEC\n2014 datasets",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Yonghong Li",
            "Shan Qu",
            "Xiuzhuang Zhou"
        ],
        "published": "2024-05-29T03:08:30Z"
    },
    {
        "title": "Correctable Landmark Discovery via Large Models for Vision-Language\n  Navigation",
        "link": "http://arxiv.org/abs/2405.18721v1",
        "abstract": "Vision-Language Navigation (VLN) requires the agent to follow language\ninstructions to reach a target position. A key factor for successful navigation\nis to align the landmarks implied in the instruction with diverse visual\nobservations. However, previous VLN agents fail to perform accurate modality\nalignment especially in unexplored scenes, since they learn from limited\nnavigation data and lack sufficient open-world alignment knowledge. In this\nwork, we propose a new VLN paradigm, called COrrectable LaNdmark DiScOvery via\nLarge ModEls (CONSOLE). In CONSOLE, we cast VLN as an open-world sequential\nlandmark discovery problem, by introducing a novel correctable landmark\ndiscovery scheme based on two large models ChatGPT and CLIP. Specifically, we\nuse ChatGPT to provide rich open-world landmark cooccurrence commonsense, and\nconduct CLIP-driven landmark discovery based on these commonsense priors. To\nmitigate the noise in the priors due to the lack of visual constraints, we\nintroduce a learnable cooccurrence scoring module, which corrects the\nimportance of each cooccurrence according to actual observations for accurate\nlandmark discovery. We further design an observation enhancement strategy for\nan elegant combination of our framework with different VLN agents, where we\nutilize the corrected landmark features to obtain enhanced observation features\nfor action decision. Extensive experimental results on multiple popular VLN\nbenchmarks (R2R, REVERIE, R4R, RxR) show the significant superiority of CONSOLE\nover strong baselines. Especially, our CONSOLE establishes the new\nstate-of-the-art results on R2R and R4R in unseen scenarios. Code is available\nat https://github.com/expectorlin/CONSOLE.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Bingqian Lin",
            "Yunshuang Nie",
            "Ziming Wei",
            "Yi Zhu",
            "Hang Xu",
            "Shikui Ma",
            "Jianzhuang Liu",
            "Xiaodan Liang"
        ],
        "published": "2024-05-29T03:05:59Z"
    },
    {
        "title": "Contextual Position Encoding: Learning to Count What's Important",
        "link": "http://arxiv.org/abs/2405.18719v2",
        "abstract": "The attention mechanism is a critical component of Large Language Models\n(LLMs) that allows tokens in a sequence to interact with each other, but is\norder-invariant. Incorporating position encoding (PE) makes it possible to\naddress by position, such as attending to the i-th token. However, current PE\nmethods use token counts to derive position, and thus cannot generalize to\nhigher levels of abstraction, such as attending to the i-th sentence. In this\npaper, we propose a new position encoding method, Contextual Position Encoding\n(CoPE), that allows positions to be conditioned on context by incrementing\nposition only on certain tokens determined by the model. This allows more\ngeneral position addressing such as attending to the $i$-th particular word,\nnoun, or sentence. We show that CoPE can solve the selective copy, counting and\nFlip-Flop tasks where popular position embeddings fail, and improves perplexity\non language modeling and coding tasks.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Olga Golovneva",
            "Tianlu Wang",
            "Jason Weston",
            "Sainbayar Sukhbaatar"
        ],
        "published": "2024-05-29T02:57:15Z"
    },
    {
        "title": "Efficient Model-agnostic Alignment via Bayesian Persuasion",
        "link": "http://arxiv.org/abs/2405.18718v1",
        "abstract": "With recent advancements in large language models (LLMs), alignment has\nemerged as an effective technique for keeping LLMs consensus with human intent.\nCurrent methods primarily involve direct training through Supervised\nFine-tuning (SFT) or Reinforcement Learning from Human Feedback (RLHF), both of\nwhich require substantial computational resources and extensive ground truth\ndata. This paper explores an efficient method for aligning black-box large\nmodels using smaller models, introducing a model-agnostic and lightweight\nBayesian Persuasion Alignment framework. We formalize this problem as an\noptimization of the signaling strategy from the small model's perspective. In\nthe persuasion process, the small model (Advisor) observes the information item\n(i.e., state) and persuades large models (Receiver) to elicit improved\nresponses. The Receiver then generates a response based on the input, the\nsignal from the Advisor, and its updated belief about the information item.\nThrough training using our framework, we demonstrate that the Advisor can\nsignificantly enhance the performance of various Receivers across a range of\ntasks. We theoretically analyze our persuasion framework and provide an upper\nbound on the Advisor's regret, confirming its effectiveness in learning the\noptimal signaling strategy. Our Empirical results demonstrates that GPT-2 can\nsignificantly improve the performance of various models, achieving an average\nenhancement of 16.1% in mathematical reasoning ability and 13.7% in code\ngeneration. We hope our work can provide an initial step toward rethinking the\nalignment framework from the Bayesian Persuasion perspective.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Fengshuo Bai",
            "Mingzhi Wang",
            "Zhaowei Zhang",
            "Boyuan Chen",
            "Yinda Xu",
            "Ying Wen",
            "Yaodong Yang"
        ],
        "published": "2024-05-29T02:57:07Z"
    },
    {
        "title": "SketchDeco: Decorating B&W Sketches with Colour",
        "link": "http://arxiv.org/abs/2405.18716v1",
        "abstract": "This paper introduces a novel approach to sketch colourisation, inspired by\nthe universal childhood activity of colouring and its professional applications\nin design and story-boarding. Striking a balance between precision and\nconvenience, our method utilises region masks and colour palettes to allow\nintuitive user control, steering clear of the meticulousness of manual colour\nassignments or the limitations of textual prompts. By strategically combining\nControlNet and staged generation, incorporating Stable Diffusion v1.5, and\nleveraging BLIP-2 text prompts, our methodology facilitates faithful image\ngeneration and user-directed colourisation. Addressing challenges of local and\nglobal consistency, we employ inventive solutions such as an inversion scheme,\nguided sampling, and a self-attention mechanism with a scaling factor. The\nresulting tool is not only fast and training-free but also compatible with\nconsumer-grade Nvidia RTX 4090 Super GPUs, making it a valuable asset for both\ncreative professionals and enthusiasts in various fields. Project Page:\n\\url{https://chaitron.github.io/SketchDeco/}",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Chaitat Utintu",
            "Pinaki Nath Chowdhury",
            "Aneeshan Sain",
            "Subhadeep Koley",
            "Ayan Kumar Bhunia",
            "Yi-Zhe Song"
        ],
        "published": "2024-05-29T02:53:59Z"
    },
    {
        "title": "NeRF On-the-go: Exploiting Uncertainty for Distractor-free NeRFs in the\n  Wild",
        "link": "http://arxiv.org/abs/2405.18715v1",
        "abstract": "Neural Radiance Fields (NeRFs) have shown remarkable success in synthesizing\nphotorealistic views from multi-view images of static scenes, but face\nchallenges in dynamic, real-world environments with distractors like moving\nobjects, shadows, and lighting changes. Existing methods manage controlled\nenvironments and low occlusion ratios but fall short in render quality,\nespecially under high occlusion scenarios. In this paper, we introduce NeRF\nOn-the-go, a simple yet effective approach that enables the robust synthesis of\nnovel views in complex, in-the-wild scenes from only casually captured image\nsequences. Delving into uncertainty, our method not only efficiently eliminates\ndistractors, even when they are predominant in captures, but also achieves a\nnotably faster convergence speed. Through comprehensive experiments on various\nscenes, our method demonstrates a significant improvement over state-of-the-art\ntechniques. This advancement opens new avenues for NeRF in diverse and dynamic\nreal-world applications.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Weining Ren",
            "Zihan Zhu",
            "Boyang Sun",
            "Jiaqi Chen",
            "Marc Pollefeys",
            "Songyou Peng"
        ],
        "published": "2024-05-29T02:53:40Z"
    },
    {
        "title": "Identifying the Most Influential Driver Nodes for Pinning Control of\n  Multi-Agent Systems with Time-Varying Topology",
        "link": "http://arxiv.org/abs/2405.18712v1",
        "abstract": "Identifying the most influential driver nodes to guarantee the fastest\nsynchronization speed is a key topic in pinning control of multi-agent systems.\nThis paper develops a methodology to find the most influential pinning nodes\nunder time-varying topologies. First, we provide the pinning control\nsynchronization conditions of multi-agent systems. Second, a method is proposed\nto identify the best driver nodes that can guarantee the fastest\nsynchronization speed under periodically switched systems. We show that the\ndetermination of the best driver nodes is independent of the system matrix\nunder certain conditions. Finally, we develop a method to estimate the\nswitching frequency threshold that can make the selected best driver nodes\nremain the same as the average system. Numerical simulations reveal the\nfeasibility of these methods.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Guangrui Zhang",
            "Zhaohui Liu",
            "Xinghuo Yu",
            "Mahdi Jalili"
        ],
        "published": "2024-05-29T02:45:07Z"
    },
    {
        "title": "Calibrating Reasoning in Language Models with Internal Consistency",
        "link": "http://arxiv.org/abs/2405.18711v1",
        "abstract": "Large language models (LLMs) have demonstrated impressive capabilities in\nvarious reasoning tasks, aided by techniques like chain-of-thought (CoT)\nprompting that elicits verbalized reasoning. However, LLMs often generate text\nwith obvious mistakes and contradictions, raising doubts about their ability to\nrobustly process and utilize generated rationales. In this work, we investigate\nCoT reasoning in LLMs through the lens of internal representations, focusing on\nhow these representations are influenced by generated rationales. Our\npreliminary analysis reveals that while generated rationales improve answer\naccuracy, inconsistencies emerge between the model's internal representations\nin middle layers and those in final layers, potentially undermining the\nreliability of their reasoning processes. To address this, we propose internal\nconsistency as a measure of the model's confidence by examining the agreement\nof latent predictions decoded from intermediate layers. Extensive empirical\nstudies across different models and datasets demonstrate that internal\nconsistency effectively distinguishes between correct and incorrect reasoning\npaths. Motivated by this, we propose a new approach to calibrate CoT reasoning\nby up-weighting reasoning paths with high internal consistency, resulting in a\nsignificant boost in reasoning performance. Further analysis uncovers distinct\npatterns in attention and feed-forward modules across layers, providing\ninsights into the emergence of internal inconsistency. In summary, our results\ndemonstrate the potential of using internal representations for self-evaluation\nof LLMs.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Zhihui Xie",
            "Jizhou Guo",
            "Tong Yu",
            "Shuai Li"
        ],
        "published": "2024-05-29T02:44:12Z"
    },
    {
        "title": "To FP8 and Back Again: Quantifying the Effects of Reducing Precision on\n  LLM Training Stability",
        "link": "http://arxiv.org/abs/2405.18710v1",
        "abstract": "The massive computational costs associated with large language model (LLM)\npretraining have spurred great interest in reduced-precision floating-point\nrepresentations to accelerate the process. As a result, the BrainFloat16 (BF16)\nprecision has become the de facto standard for LLM training, with hardware\nsupport included in recent accelerators. This trend has gone even further in\nthe latest processors, where FP8 has recently been introduced. However, prior\nexperience with FP16, which was found to be less stable than BF16, raises\nconcerns as to whether FP8, with even fewer bits than FP16, can be a\ncost-effective option for LLM training. We argue that reduced-precision\ntraining schemes must have similar training stability and hyperparameter\nsensitivities to their higher-precision counterparts in order to be\ncost-effective. However, we find that currently available methods for FP8\ntraining are not robust enough to allow their use as economical replacements.\nThis prompts us to investigate the stability of reduced-precision LLM training\nin terms of robustness across random seeds and learning rates. To this end, we\npropose new evaluation techniques and a new metric for quantifying loss\nlandscape sharpness in autoregressive language models. By simulating\nincremental bit reductions in floating-point representations, we analyze the\nrelationship between representational power and training stability with the\nintent of aiding future research into the field.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Joonhyung Lee",
            "Jeongin Bae",
            "Byeongwook Kim",
            "Se Jung Kwon",
            "Dongsoo Lee"
        ],
        "published": "2024-05-29T02:42:23Z"
    },
    {
        "title": "Cognitive Evolutionary Learning to Select Feature Interactions for\n  Recommender Systems",
        "link": "http://arxiv.org/abs/2405.18708v1",
        "abstract": "Feature interaction selection is a fundamental problem in commercial\nrecommender systems. Most approaches equally enumerate all features and\ninteractions by the same pre-defined operation under expert guidance. Their\nrecommendation is unsatisfactory sometimes due to the following issues:\n(1)~They cannot ensure the learning abilities of models because their\narchitectures are poorly adaptable to tasks and data; (2)~Useless features and\ninteractions can bring unnecessary noise and complicate the training process.\nIn this paper, we aim to adaptively evolve the model to select appropriate\noperations, features, and interactions under task guidance. Inspired by the\nevolution and functioning of natural organisms, we propose a novel\n\\textsl{Cognitive EvoLutionary Learning (CELL)} framework, where cognitive\nability refers to a property of organisms that allows them to react and survive\nin diverse environments. It consists of three stages, i.e., DNA search, genome\nsearch, and model functioning. Specifically, if we regard the relationship\nbetween models and tasks as the relationship between organisms and natural\nenvironments, interactions of feature pairs can be analogous to double-stranded\nDNA, of which relevant features and interactions can be analogous to genomes.\nAlong this line, we diagnose the fitness of the model on operations, features,\nand interactions to simulate the survival rates of organisms for natural\nselection. We show that CELL can adaptively evolve into different models for\ndifferent tasks and data, which enables practitioners to access off-the-shelf\nmodels. Extensive experiments on four real-world datasets demonstrate that CELL\nsignificantly outperforms state-of-the-art baselines. Also, we conduct\nsynthetic experiments to ascertain that CELL can consistently discover the\npre-defined interaction patterns for feature pairs.",
        "subjects": [
            "cs.AI",
            "cs.IR",
            "cs.NE"
        ],
        "authors": [
            "Runlong Yu",
            "Qixiang Shao",
            "Qi Liu",
            "Huan Liu",
            "Enhong Chen"
        ],
        "published": "2024-05-29T02:35:23Z"
    },
    {
        "title": "Adaptive and Parallel Split Federated Learning in Vehicular Edge\n  Computing",
        "link": "http://arxiv.org/abs/2405.18707v1",
        "abstract": "Vehicular edge intelligence (VEI) is a promising paradigm for enabling future\nintelligent transportation systems by accommodating artificial intelligence\n(AI) at the vehicular edge computing (VEC) system. Federated learning (FL)\nstands as one of the fundamental technologies facilitating collaborative model\ntraining locally and aggregation, while safeguarding the privacy of vehicle\ndata in VEI. However, traditional FL faces challenges in adapting to vehicle\nheterogeneity, training large models on resource-constrained vehicles, and\nremaining susceptible to model weight privacy leakage. Meanwhile, split\nlearning (SL) is proposed as a promising collaborative learning framework which\ncan mitigate the risk of model wights leakage, and release the training\nworkload on vehicles. SL sequentially trains a model between a vehicle and an\nedge cloud (EC) by dividing the entire model into a vehicle-side model and an\nEC-side model at a given cut layer. In this work, we combine the advantages of\nSL and FL to develop an Adaptive Split Federated Learning scheme for Vehicular\nEdge Computing (ASFV). The ASFV scheme adaptively splits the model and\nparallelizes the training process, taking into account mobile vehicle selection\nand resource allocation. Our extensive simulations, conducted on\nnon-independent and identically distributed data, demonstrate that the proposed\nASFV solution significantly reduces training latency compared to existing\nbenchmarks, while adapting to network dynamics and vehicles' mobility.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.NI"
        ],
        "authors": [
            "Xianke Qiang",
            "Zheng Chang",
            "Yun Hu",
            "Lei Liu",
            "Timo Hamalainen"
        ],
        "published": "2024-05-29T02:34:38Z"
    },
    {
        "title": "FocSAM: Delving Deeply into Focused Objects in Segmenting Anything",
        "link": "http://arxiv.org/abs/2405.18706v1",
        "abstract": "The Segment Anything Model (SAM) marks a notable milestone in segmentation\nmodels, highlighted by its robust zero-shot capabilities and ability to handle\ndiverse prompts. SAM follows a pipeline that separates interactive segmentation\ninto image preprocessing through a large encoder and interactive inference via\na lightweight decoder, ensuring efficient real-time performance. However, SAM\nfaces stability issues in challenging samples upon this pipeline. These issues\narise from two main factors. Firstly, the image preprocessing disables SAM from\ndynamically using image-level zoom-in strategies to refocus on the target\nobject during interaction. Secondly, the lightweight decoder struggles to\nsufficiently integrate interactive information with image embeddings. To\naddress these two limitations, we propose FocSAM with a pipeline redesigned on\ntwo pivotal aspects. First, we propose Dynamic Window Multi-head Self-Attention\n(Dwin-MSA) to dynamically refocus SAM's image embeddings on the target object.\nDwin-MSA localizes attention computations around the target object, enhancing\nobject-related embeddings with minimal computational overhead. Second, we\npropose Pixel-wise Dynamic ReLU (P-DyReLU) to enable sufficient integration of\ninteractive information from a few initial clicks that have significant impacts\non the overall segmentation results. Experimentally, FocSAM augments SAM's\ninteractive segmentation performance to match the existing state-of-the-art\nmethod in segmentation quality, requiring only about 5.6% of this method's\ninference time on CPUs.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "You Huang",
            "Zongyu Lan",
            "Liujuan Cao",
            "Xianming Lin",
            "Shengchuan Zhang",
            "Guannan Jiang",
            "Rongrong Ji"
        ],
        "published": "2024-05-29T02:34:13Z"
    },
    {
        "title": "A simple inverse power method for balanced graph cut",
        "link": "http://arxiv.org/abs/2405.18705v1",
        "abstract": "The existing inverse power ($\\mathbf{IP}$) method for solving the balanced\ngraph cut lacks local convergence and its inner subproblem requires a nonsmooth\nconvex solver. To address these issues, we develop a simple inverse power\n($\\mathbf{SIP}$) method using a novel equivalent continuous formulation of the\nbalanced graph cut, and its inner subproblem allows an explicit analytic\nsolution, which is the biggest advantage over $\\mathbf{IP}$ and constitutes the\nmain reason why we call it $\\mathit{simple}$. By fully exploiting the\nclosed-form of the inner subproblem solution, we design a boundary-detected\nsubgradient selection with which $\\mathbf{SIP}$ is proved to be locally\nconverged. We show that $\\mathbf{SIP}$ is also applicable to a new ternary\nvalued $\\theta$-balanced cut which reduces to the balanced cut when $\\theta=1$.\nWhen $\\mathbf{SIP}$ reaches its local optimum, we seamlessly transfer to solve\nthe $\\theta$-balanced cut within exactly the same iteration algorithm framework\nand thus obtain $\\mathbf{SIP}$-$\\mathbf{perturb}$ -- an efficient local\nbreakout improvement of $\\mathbf{SIP}$, which transforms some ``partitioned\"\nvertices back to the ``un-partitioned\" ones through the adjustable $\\theta$.\nNumerical experiments on G-set for Cheeger cut and Sparsest cut demonstrate\nthat $\\mathbf{SIP}$ is significantly faster than $\\mathbf{IP}$ while\nmaintaining approximate solutions of comparable quality, and\n$\\mathbf{SIP}$-$\\mathbf{perturb}$ outperforms $\\mathtt{Gurobi}$ in terms of\nboth computational cost and solution quality.",
        "subjects": [
            "math.OC",
            "cs.NA",
            "math.CO",
            "math.NA",
            "math.SP",
            "90C27, 05C50, 90C32, 35P30, 90C26"
        ],
        "authors": [
            "Sihong Shao",
            "Chuan Yang"
        ],
        "published": "2024-05-29T02:28:24Z"
    },
    {
        "title": "Bridging the Gap between Partially Observable Stochastic Games and\n  Sparse POMDP Methods",
        "link": "http://arxiv.org/abs/2405.18703v1",
        "abstract": "Many real-world decision problems involve interaction of multiple\nself-interested agents with limited sensing ability. The partially observable\nstochastic game (POSG) provides a mathematical framework for posing these\nproblems, however solving a POSG requires difficult reasoning about two\ncritical factors: (1) information revealed by partial observations and (2)\ndecisions other agents make. In the single agent case, partially observable\nMarkov decision process (POMDP) planning can efficiently address partial\nobservability with particle filtering. In the multi-agent case, imperfect\ninformation game solution methods account for other agent's decisions, but\npreclude belief approximation. We propose a unifying framework that combines\nPOMDP-inspired state distribution approximation and game-theoretic equilibrium\nsearch on information sets. This approach enables online planning in POSGs with\nvery large state spaces, paving the way for reliable autonomous interaction in\nreal-world physical environments and complementing offline multi-agent\nreinforcement learning. Experiments in several zero-sum examples show that the\nnew framework computes solutions for problems with both small and large state\nspaces.",
        "subjects": [
            "cs.GT"
        ],
        "authors": [
            "Tyler Becker",
            "Zachary Sunberg"
        ],
        "published": "2024-05-29T02:27:47Z"
    },
    {
        "title": "Multi-Condition Latent Diffusion Network for Scene-Aware Neural Human\n  Motion Prediction",
        "link": "http://arxiv.org/abs/2405.18700v2",
        "abstract": "Inferring 3D human motion is fundamental in many applications, including\nunderstanding human activity and analyzing one's intention. While many fruitful\nefforts have been made to human motion prediction, most approaches focus on\npose-driven prediction and inferring human motion in isolation from the\ncontextual environment, thus leaving the body location movement in the scene\nbehind. However, real-world human movements are goal-directed and highly\ninfluenced by the spatial layout of their surrounding scenes. In this paper,\ninstead of planning future human motion in a 'dark' room, we propose a\nMulti-Condition Latent Diffusion network (MCLD) that reformulates the human\nmotion prediction task as a multi-condition joint inference problem based on\nthe given historical 3D body motion and the current 3D scene contexts.\nSpecifically, instead of directly modeling joint distribution over the raw\nmotion sequences, MCLD performs a conditional diffusion process within the\nlatent embedding space, characterizing the cross-modal mapping from the past\nbody movement and current scene context condition embeddings to the future\nhuman motion embedding. Extensive experiments on large-scale human motion\nprediction datasets demonstrate that our MCLD achieves significant improvements\nover the state-of-the-art methods on both realistic and diverse predictions.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xuehao Gao",
            "Yang Yang",
            "Yang Wu",
            "Shaoyi Du",
            "Guo-Jun Qi"
        ],
        "published": "2024-05-29T02:21:31Z"
    },
    {
        "title": "Spectral-Risk Safe Reinforcement Learning with Convergence Guarantees",
        "link": "http://arxiv.org/abs/2405.18698v1",
        "abstract": "The field of risk-constrained reinforcement learning (RCRL) has been\ndeveloped to effectively reduce the likelihood of worst-case scenarios by\nexplicitly handling risk-measure-based constraints. However, the nonlinearity\nof risk measures makes it challenging to achieve convergence and optimality. To\novercome the difficulties posed by the nonlinearity, we propose a spectral risk\nmeasure-constrained RL algorithm, spectral-risk-constrained policy optimization\n(SRCPO), a bilevel optimization approach that utilizes the duality of spectral\nrisk measures. In the bilevel optimization structure, the outer problem\ninvolves optimizing dual variables derived from the risk measures, while the\ninner problem involves finding an optimal policy given these dual variables.\nThe proposed method, to the best of our knowledge, is the first to guarantee\nconvergence to an optimum in the tabular setting. Furthermore, the proposed\nmethod has been evaluated on continuous control tasks and showed the best\nperformance among other RCRL algorithms satisfying the constraints.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Dohyeong Kim",
            "Taehyun Cho",
            "Seungyub Han",
            "Hojun Chung",
            "Kyungjae Lee",
            "Songhwai Oh"
        ],
        "published": "2024-05-29T02:17:25Z"
    },
    {
        "title": "Data-Efficient Approach to Humanoid Control via Fine-Tuning a\n  Pre-Trained GPT on Action Data",
        "link": "http://arxiv.org/abs/2405.18695v1",
        "abstract": "There are several challenges in developing a model for multi-tasking humanoid\ncontrol. Reinforcement learning and imitation learning approaches are quite\npopular in this domain. However, there is a trade-off between the two.\nReinforcement learning is not the best option for training a humanoid to\nperform multiple behaviors due to training time and model size, and imitation\nlearning using kinematics data alone is not appropriate to realize the actual\nphysics of the motion. Training models to perform multiple complex tasks take\nlong training time due to high DoF and complexities of the movements. Although\ntraining models offline would be beneficial, another issue is the size of the\ndataset, usually being quite large to encapsulate multiple movements. Many\npapers have implemented state of the art deep learning models such as\ntransformers to control humanoid characters and predict their motion based on a\nlarge dataset of recorded/reference motion. In this paper, we train a GPT on a\nlarge dataset of noisy expert policy rollout observations from a humanoid\nmotion dataset as a pre-trained model and fine tune that model on a smaller\ndataset of noisy expert policy rollout observations and actions to\nautoregressively generate physically plausible motion trajectories. We show\nthat it is possible to train a GPT-based foundation model on a smaller dataset\nin shorter training time to control a humanoid in a realistic physics\nenvironment to perform human-like movements.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Siddharth Padmanabhan",
            "Kazuki Miyazawa",
            "Takato Horii",
            "Takayuki Nagai"
        ],
        "published": "2024-05-29T02:10:35Z"
    },
    {
        "title": "Signal-Comparison-Based Distributed Estimation Under Decaying Average\n  Bit Rate Communications",
        "link": "http://arxiv.org/abs/2405.18694v1",
        "abstract": "The paper investigates the distributed estimation problem under low bit rate\ncommunications. Based on the signal-comparison (SC) consensus protocol under\nbinary-valued communications, a new consensus+innovations type distributed\nestimation algorithm is proposed. Firstly, the high-dimensional estimates are\ncompressed into binary-valued messages by using a periodic compressive\nstrategy, dithered noises and a sign function. Next, based on the dithered\nnoises and expanding triggering thresholds, a new stochastic event-triggered\nmechanism is proposed to reduce the communication frequency. Then, a modified\nSC consensus protocol is applied to fuse the neighborhood information. Finally,\na stochastic approximation estimation algorithm is used to process innovations.\nThe proposed SC-based algorithm has the advantages of high effectiveness and\nlow communication cost. For the effectiveness, the estimates of the SC-based\nalgorithm converge to the true value in the almost sure and mean square sense.\nA polynomial almost sure convergence rate is also obtained. For the\ncommunication cost, the local and global average bit rates for communications\ndecay to zero at a polynomial rate. The trade-off between the convergence rate\nand the communication cost is established through event-triggered coefficients.\nA better convergence rate can be achieved by decreasing event-triggered\ncoefficients, while lower communication cost can be achieved by increasing\nevent-triggered coefficients. A simulation example is given to demonstrate the\ntheoretical results.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Jieming Ke",
            "Xiaodong Lu",
            "Yanlong Zhao",
            "Ji-Feng Zhang"
        ],
        "published": "2024-05-29T02:08:58Z"
    },
    {
        "title": "DeepHGNN: Study of Graph Neural Network based Forecasting Methods for\n  Hierarchically Related Multivariate Time Series",
        "link": "http://arxiv.org/abs/2405.18693v1",
        "abstract": "Graph Neural Networks (GNN) have gained significant traction in the\nforecasting domain, especially for their capacity to simultaneously account for\nintra-series temporal correlations and inter-series relationships. This paper\nintroduces a novel Hierarchical GNN (DeepHGNN) framework, explicitly designed\nfor forecasting in complex hierarchical structures. The uniqueness of DeepHGNN\nlies in its innovative graph-based hierarchical interpolation and an end-to-end\nreconciliation mechanism. This approach ensures forecast accuracy and coherence\nacross various hierarchical levels while sharing signals across them,\naddressing a key challenge in hierarchical forecasting. A critical insight in\nhierarchical time series is the variance in forecastability across levels, with\nupper levels typically presenting more predictable components. DeepHGNN\ncapitalizes on this insight by pooling and leveraging knowledge from all\nhierarchy levels, thereby enhancing the overall forecast accuracy. Our\ncomprehensive evaluation set against several state-of-the-art models confirm\nthe superior performance of DeepHGNN. This research not only demonstrates\nDeepHGNN's effectiveness in achieving significantly improved forecast accuracy\nbut also contributes to the understanding of graph-based methods in\nhierarchical time series forecasting.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Abishek Sriramulu",
            "Nicolas Fourrier",
            "Christoph Bergmeir"
        ],
        "published": "2024-05-29T02:06:17Z"
    },
    {
        "title": "Movable Antenna Empowered Downlink NOMA Systems: Power Allocation and\n  Antenna Position Optimization",
        "link": "http://arxiv.org/abs/2405.18692v1",
        "abstract": "This paper investigates a novel communication paradigm employing movable\nantennas (MAs) within a multiple-input single-output (MISO) non-orthogonal\nmultiple access (NOMA) downlink framework, where users are equipped with MAs.\nInitially, leveraging the far-field response, we delineate the channel\ncharacteristics concerning both the power allocation coefficient and positions\nof MAs. Subsequently, we endeavor to maximize the channel capacity by jointly\noptimizing power allocation and antenna positions. To tackle the resultant\nnon-convex problem, we propose an alternating optimization (AO) scheme\nunderpinned by successive convex approximation (SCA) to converge towards a\nstationary point. Through numerical simulations, our findings substantiate the\nsuperiority of the MA-assisted NOMA system over both orthogonal multiple access\n(OMA) and conventional NOMA configurations in terms of average sum rate and\noutage probability.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Yufeng Zhou",
            "Wen Chen",
            "Qingqing Wu",
            "Xusheng Zhu",
            "Nan Cheng"
        ],
        "published": "2024-05-29T02:04:36Z"
    },
    {
        "title": "Differentially-Private Distributed Model Predictive Control of Linear\n  Discrete-Time Systems with Global Constraints",
        "link": "http://arxiv.org/abs/2405.18690v1",
        "abstract": "Distributed model predictive control (DMPC) has attracted extensive attention\nas it can explicitly handle system constraints and achieve optimal control in a\ndecentralized manner. However, the deployment of DMPC strategies generally\nrequires the sharing of sensitive data among subsystems, which may violate the\nprivacy of participating systems. In this paper, we propose a\ndifferentially-private DMPC algorithm for linear discrete-time systems subject\nto coupled global constraints. Specifically, we first show that a conventional\ndistributed dual gradient algorithm can be used to address the considered DMPC\nproblem but cannot provide strong privacy preservation. Then, to protect\nprivacy against the eavesdropper, we incorporate a differential-privacy noise\ninjection mechanism into the DMPC framework and prove that the resulting\ndistributed optimization algorithm can ensure both provable convergence to a\nglobal optimal solution and rigorous $\\epsilon$-differential privacy. In\naddition, an implementation strategy of the DMPC is designed such that the\nrecursive feasibility and stability of the closed-loop system are guaranteed.\nNumerical simulation results confirm the effectiveness of the proposed\napproach.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Kaixiang Zhang",
            "Yongqiang Wang",
            "Ziyou Song",
            "Zhaojian Li"
        ],
        "published": "2024-05-29T01:58:22Z"
    },
    {
        "title": "Efficient Preference-based Reinforcement Learning via Aligned Experience\n  Estimation",
        "link": "http://arxiv.org/abs/2405.18688v1",
        "abstract": "Preference-based reinforcement learning (PbRL) has shown impressive\ncapabilities in training agents without reward engineering. However, a notable\nlimitation of PbRL is its dependency on substantial human feedback. This\ndependency stems from the learning loop, which entails accurate reward learning\ncompounded with value/policy learning, necessitating a considerable number of\nsamples. To boost the learning loop, we propose SEER, an efficient PbRL method\nthat integrates label smoothing and policy regularization techniques. Label\nsmoothing reduces overfitting of the reward model by smoothing human preference\nlabels. Additionally, we bootstrap a conservative estimate $\\widehat{Q}$ using\nwell-supported state-action pairs from the current replay memory to mitigate\noverestimation bias and utilize it for policy learning regularization. Our\nexperimental results across a variety of complex tasks, both in online and\noffline settings, demonstrate that our approach improves feedback efficiency,\noutperforming state-of-the-art methods by a large margin. Ablation studies\nfurther reveal that SEER achieves a more accurate Q-function compared to prior\nwork.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Fengshuo Bai",
            "Rui Zhao",
            "Hongming Zhang",
            "Sijia Cui",
            "Ying Wen",
            "Yaodong Yang",
            "Bo Xu",
            "Lei Han"
        ],
        "published": "2024-05-29T01:49:20Z"
    },
    {
        "title": "Advancing Household Robotics: Deep Interactive Reinforcement Learning\n  for Efficient Training and Enhanced Performance",
        "link": "http://dx.doi.org/10.52783/jes.1510",
        "abstract": "The market for domestic robots made to perform household chores is growing as\nthese robots relieve people of everyday responsibilities. Domestic robots are\ngenerally welcomed for their role in easing human labor, in contrast to\nindustrial robots, which are frequently criticized for displacing human\nworkers. But before these robots can carry out domestic chores, they need to\nbecome proficient in several minor activities, such as recognizing their\nsurroundings, making decisions, and picking up on human behaviors.\nReinforcement learning, or RL, has emerged as a key robotics technology that\nenables robots to interact with their environment and learn how to optimize\ntheir actions to maximize rewards. However, the goal of Deep Reinforcement\nLearning is to address more complicated, continuous action-state spaces in\nreal-world settings by combining RL with Neural Networks. The efficacy of\nDeepRL can be further augmented through interactive feedback, in which a\ntrainer offers real-time guidance to expedite the robot's learning process.\nNevertheless, the current methods have drawbacks, namely the transient\napplication of guidance that results in repeated learning under identical\nconditions. Therefore, we present a novel method to preserve and reuse\ninformation and advice via Deep Interactive Reinforcement Learning, which\nutilizes a persistent rule-based system. This method not only expedites the\ntraining process but also lessens the number of repetitions that instructors\nwill have to carry out. This study has the potential to advance the development\nof household robots and improve their effectiveness and efficiency as learners.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "authors": [
            "Arpita Soni",
            "Sujatha Alla",
            "Suresh Dodda",
            "Hemanth Volikatla"
        ],
        "published": "2024-05-29T01:46:50Z"
    },
    {
        "title": "Rejection via Learning Density Ratios",
        "link": "http://arxiv.org/abs/2405.18686v1",
        "abstract": "Classification with rejection emerges as a learning paradigm which allows\nmodels to abstain from making predictions. The predominant approach is to alter\nthe supervised learning pipeline by augmenting typical loss functions, letting\nmodel rejection incur a lower loss than an incorrect prediction. Instead, we\npropose a different distributional perspective, where we seek to find an\nidealized data distribution which maximizes a pretrained model's performance.\nThis can be formalized via the optimization of a loss's risk with a $\n\\phi$-divergence regularization term. Through this idealized distribution, a\nrejection decision can be made by utilizing the density ratio between this\ndistribution and the data distribution. We focus on the setting where our $\n\\phi $-divergences are specified by the family of $ \\alpha $-divergence. Our\nframework is tested empirically over clean and noisy datasets.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Alexander Soen",
            "Hisham Husain",
            "Philip Schulz",
            "Vu Nguyen"
        ],
        "published": "2024-05-29T01:32:17Z"
    },
    {
        "title": "Learning Diffeomorphism for Image Registration with Time-Continuous\n  Networks using Semigroup Regularization",
        "link": "http://arxiv.org/abs/2405.18684v1",
        "abstract": "Diffeomorphic image registration (DIR) is a critical task in 3D medical image\nanalysis, aimed at finding topology preserving deformations between pairs of\nimages. Focusing on the solution of the flow map differential equation as the\ndiffeomorphic deformation, recent methods use discrete timesteps along with\nvarious regularization terms to penalize the negative determinant of Jacobian\nand impose smoothness of the solution vector field. In this paper, we propose a\nnovel learning-based approach for diffeomorphic 3D-image registration which\nfinds the diffeomorphisms in the time continuum with fewer regularization terms\nand no additional integration. As one of the fundamental properties of flow\nmaps, we exploit the semigroup property as the only form of regularization,\nensuring temporally continuous diffeomorphic flows between pairs of images.\nLeveraging this property, our method alleviates the need for additional\nregularization terms and scaling and squaring integration during both training\nand evaluation. To achieve time-continuous diffeomorphisms, we employ\ntime-embedded UNets, a technique commonly utilized in diffusion models. The\nproposed method reveals that ensuring diffeomorphism in a continuous time\ninterval leads to better registration results. Experimental results on two\npublic datasets (OASIS and CANDI) demonstrate the superiority of our model over\nboth learning-based and optimization-based methods.",
        "subjects": [
            "cs.CV",
            "I.4.9; I.2.10; F.2.2"
        ],
        "authors": [
            "Mohammadjavad Matinkia",
            "Nilanjan Ray"
        ],
        "published": "2024-05-29T01:25:43Z"
    },
    {
        "title": "Can GPT Redefine Medical Understanding? Evaluating GPT on Biomedical\n  Machine Reading Comprehension",
        "link": "http://arxiv.org/abs/2405.18682v1",
        "abstract": "Large language models (LLMs) have shown remarkable performance on many tasks\nin different domains. However, their performance in closed-book biomedical\nmachine reading comprehension (MRC) has not been evaluated in depth. In this\nwork, we evaluate GPT on four closed-book biomedical MRC benchmarks. We\nexperiment with different conventional prompting techniques as well as\nintroduce our own novel prompting method. To solve some of the retrieval\nproblems inherent to LLMs, we propose a prompting strategy named Implicit\nRetrieval Augmented Generation (RAG) that alleviates the need for using vector\ndatabases to retrieve important chunks in traditional RAG setups. Moreover, we\nreport qualitative assessments on the natural language generation outputs from\nour approach. The results show that our new prompting technique is able to get\nthe best performance in two out of four datasets and ranks second in rest of\nthem. Experiments show that modern-day LLMs like GPT even in a zero-shot\nsetting can outperform supervised models, leading to new state-of-the-art\n(SoTA) results on two of the benchmarks.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Shubham Vatsal",
            "Ayush Singh"
        ],
        "published": "2024-05-29T01:12:53Z"
    },
    {
        "title": "A random-key GRASP for combinatorial optimization",
        "link": "http://arxiv.org/abs/2405.18681v2",
        "abstract": "This paper proposes a problem-independent GRASP metaheuristic using the\nrandom-key optimizer (RKO) paradigm. GRASP (greedy randomized adaptive search\nprocedure) is a metaheuristic for combinatorial optimization that repeatedly\napplies a semi-greedy construction procedure followed by a local search\nprocedure. The best solution found over all iterations is returned as the\nsolution of the GRASP. Continuous GRASP (C-GRASP) is an extension of GRASP for\ncontinuous optimization in the unit hypercube. A random-key optimizer (RKO)\nuses a vector of random keys to encode a solution to a combinatorial\noptimization problem. It uses a decoder to evaluate a solution encoded by the\nvector of random keys. A random-key GRASP is a C-GRASP where points in the unit\nhypercube are evaluated employing a decoder. We describe random key GRASP\nconsisting of a problem-independent component and a problem-dependent decoder.\nAs a proof of concept, the random-key GRASP is tested on five NP-hard\ncombinatorial optimization problems: traveling salesman problem, tree of hubs\nlocation problem, Steiner triple covering problem, node capacitated graph\npartitioning problem, and job sequencing and tool switching problem.",
        "subjects": [
            "cs.NE",
            "cs.AI",
            "math.OC",
            "90-02, 90B40, 90C27",
            "G.1.6; G.2.1; I.2.8"
        ],
        "authors": [
            "Antonio A. Chaves",
            "Mauricio G. C. Resende",
            "Ricardo M. A. Silva"
        ],
        "published": "2024-05-29T01:07:38Z"
    },
    {
        "title": "Navigable Graphs for High-Dimensional Nearest Neighbor Search:\n  Constructions and Limits",
        "link": "http://arxiv.org/abs/2405.18680v1",
        "abstract": "There has been significant recent interest in graph-based nearest neighbor\nsearch methods, many of which are centered on the construction of navigable\ngraphs over high-dimensional point sets. A graph is navigable if we can\nsuccessfully move from any starting node to any target node using a greedy\nrouting strategy where we always move to the neighbor that is closest to the\ndestination according to a given distance function. The complete graph is\nnavigable for any point set, but the important question for applications is if\nsparser graphs can be constructed. While this question is fairly well\nunderstood in low-dimensions, we establish some of the first upper and lower\nbounds for high-dimensional point sets. First, we give a simple and efficient\nway to construct a navigable graph with average degree $O(\\sqrt{n \\log n })$\nfor any set of $n$ points, in any dimension, for any distance function. We\ncompliment this result with a nearly matching lower bound: even under the\nEuclidean metric in $O(\\log n)$ dimensions, a random point set has no navigable\ngraph with average degree $O(n^{\\alpha})$ for any $\\alpha < 1/2$. Our lower\nbound relies on sharp anti-concentration bounds for binomial random variables,\nwhich we use to show that the near-neighborhoods of a set of random points do\nnot overlap significantly, forcing any navigable graph to have many edges.",
        "subjects": [
            "cs.DS",
            "cs.CG",
            "cs.DB",
            "cs.LG"
        ],
        "authors": [
            "Haya Diwan",
            "Jinrui Gou",
            "Cameron Musco",
            "Christopher Musco",
            "Torsten Suel"
        ],
        "published": "2024-05-29T01:07:26Z"
    },
    {
        "title": "Vim-F: Visual State Space Model Benefiting from Learning in the\n  Frequency Domain",
        "link": "http://arxiv.org/abs/2405.18679v1",
        "abstract": "In recent years, State Space Models (SSMs) with efficient hardware-aware\ndesigns, known as the Mamba deep learning models, have made significant\nprogress in modeling long sequences such as language understanding. Therefore,\nbuilding efficient and general-purpose visual backbones based on SSMs is a\npromising direction. Compared to traditional convolutional neural networks\n(CNNs) and Vision Transformers (ViTs), the performance of Vision Mamba (ViM)\nmethods is not yet fully competitive. To enable SSMs to process image data,\nViMs typically flatten 2D images into 1D sequences, inevitably ignoring some 2D\nlocal dependencies, thereby weakening the model's ability to interpret spatial\nrelationships from a global perspective. We use Fast Fourier Transform (FFT) to\nobtain the spectrum of the feature map and add it to the original feature map,\nenabling ViM to model a unified visual representation in both frequency and\nspatial domains. The introduction of frequency domain information enables ViM\nto have a global receptive field during scanning. We propose a novel model\ncalled Vim-F, which employs pure Mamba encoders and scans in both the frequency\nand spatial domains. Moreover, we question the necessity of position embedding\nin ViM and remove it accordingly in Vim-F, which helps to fully utilize the\nefficient long-sequence modeling capability of ViM. Finally, we redesign a\npatch embedding for Vim-F, leveraging a convolutional stem to capture more\nlocal correlations, further improving the performance of Vim-F. Code is\navailable at: \\url{https://github.com/yws-wxs/Vim-F}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Juntao Zhang",
            "Kun Bian",
            "Peng Cheng",
            "Wenbo An",
            "Jianning Liu",
            "Jun Zhou"
        ],
        "published": "2024-05-29T01:01:19Z"
    },
    {
        "title": "Zero-to-Hero: Enhancing Zero-Shot Novel View Synthesis via Attention Map\n  Filtering",
        "link": "http://arxiv.org/abs/2405.18677v1",
        "abstract": "Generating realistic images from arbitrary views based on a single source\nimage remains a significant challenge in computer vision, with broad\napplications ranging from e-commerce to immersive virtual experiences. Recent\nadvancements in diffusion models, particularly the Zero-1-to-3 model, have been\nwidely adopted for generating plausible views, videos, and 3D models. However,\nthese models still struggle with inconsistencies and implausibility in new\nviews generation, especially for challenging changes in viewpoint. In this\nwork, we propose Zero-to-Hero, a novel test-time approach that enhances view\nsynthesis by manipulating attention maps during the denoising process of\nZero-1-to-3. By drawing an analogy between the denoising process and stochastic\ngradient descent (SGD), we implement a filtering mechanism that aggregates\nattention maps, enhancing generation reliability and authenticity. This process\nimproves geometric consistency without requiring retraining or significant\ncomputational resources. Additionally, we modify the self-attention mechanism\nto integrate information from the source view, reducing shape distortions.\nThese processes are further supported by a specialized sampling schedule.\nExperimental results demonstrate substantial improvements in fidelity and\nconsistency, validated on a diverse set of out-of-distribution objects.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ido Sobol",
            "Chenfeng Xu",
            "Or Litany"
        ],
        "published": "2024-05-29T00:58:22Z"
    },
    {
        "title": "Deep Bayesian Filter for Bayes-faithful Data Assimilation",
        "link": "http://arxiv.org/abs/2405.18674v1",
        "abstract": "State estimation for nonlinear state space models is a challenging task.\nExisting assimilation methodologies predominantly assume Gaussian posteriors on\nphysical space, where true posteriors become inevitably non-Gaussian. We\npropose Deep Bayesian Filtering (DBF) for data assimilation on nonlinear state\nspace models (SSMs). DBF constructs new latent variables $h_t$ on a new latent\n(``fancy'') space and assimilates observations $o_t$. By (i) constraining the\nstate transition on fancy space to be linear and (ii) learning a Gaussian\ninverse observation operator $q(h_t|o_t)$, posteriors always remain Gaussian\nfor DBF. Quite distinctively, the structured design of posteriors provides an\nanalytic formula for the recursive computation of posteriors without\naccumulating Monte-Carlo sampling errors over time steps. DBF seeks the\nGaussian inverse observation operators $q(h_t|o_t)$ and other latent SSM\nparameters (e.g., dynamics matrix) by maximizing the evidence lower bound.\nExperiments show that DBF outperforms model-based approaches and latent\nassimilation methods in various tasks and conditions.",
        "subjects": [
            "cs.LG",
            "physics.ao-ph",
            "physics.data-an"
        ],
        "authors": [
            "Yuta Tarumi",
            "Keisuke Fukuda",
            "Shin-ichi Maeda"
        ],
        "published": "2024-05-29T00:42:00Z"
    },
    {
        "title": "LLM-based Hierarchical Concept Decomposition for Interpretable\n  Fine-Grained Image Classification",
        "link": "http://arxiv.org/abs/2405.18672v1",
        "abstract": "Recent advancements in interpretable models for vision-language tasks have\nachieved competitive performance; however, their interpretability often suffers\ndue to the reliance on unstructured text outputs from large language models\n(LLMs). This introduces randomness and compromises both transparency and\nreliability, which are essential for addressing safety issues in AI systems. We\nintroduce \\texttt{Hi-CoDe} (Hierarchical Concept Decomposition), a novel\nframework designed to enhance model interpretability through structured concept\nanalysis. Our approach consists of two main components: (1) We use GPT-4 to\ndecompose an input image into a structured hierarchy of visual concepts,\nthereby forming a visual concept tree. (2) We then employ an ensemble of simple\nlinear classifiers that operate on concept-specific features derived from CLIP\nto perform classification. Our approach not only aligns with the performance of\nstate-of-the-art models but also advances transparency by providing clear\ninsights into the decision-making process and highlighting the importance of\nvarious concepts. This allows for a detailed analysis of potential failure\nmodes and improves model compactness, therefore setting a new benchmark in\ninterpretability without compromising the accuracy.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "authors": [
            "Renyi Qu",
            "Mark Yatskar"
        ],
        "published": "2024-05-29T00:36:56Z"
    },
    {
        "title": "Watermarking Counterfactual Explanations",
        "link": "http://arxiv.org/abs/2405.18671v1",
        "abstract": "The field of Explainable Artificial Intelligence (XAI) focuses on techniques\nfor providing explanations to end-users about the decision-making processes\nthat underlie modern-day machine learning (ML) models. Within the vast universe\nof XAI techniques, counterfactual (CF) explanations are often preferred by\nend-users as they help explain the predictions of ML models by providing an\neasy-to-understand & actionable recourse (or contrastive) case to individual\nend-users who are adversely impacted by predicted outcomes. However, recent\nstudies have shown significant security concerns with using CF explanations in\nreal-world applications; in particular, malicious adversaries can exploit CF\nexplanations to perform query-efficient model extraction attacks on proprietary\nML models. In this paper, we propose a model-agnostic watermarking framework\n(for adding watermarks to CF explanations) that can be leveraged to detect\nunauthorized model extraction attacks (which rely on the watermarked CF\nexplanations). Our novel framework solves a bi-level optimization problem to\nembed an indistinguishable watermark into the generated CF explanation such\nthat any future model extraction attacks that rely on these watermarked CF\nexplanations can be detected using a null hypothesis significance testing\n(NHST) scheme, while ensuring that these embedded watermarks do not compromise\nthe quality of the generated CF explanations. We evaluate this framework's\nperformance across a diverse set of real-world datasets, CF explanation\nmethods, and model extraction techniques, and show that our watermarking\ndetection system can be used to accurately identify extracted ML models that\nare trained using the watermarked CF explanations. Our work paves the way for\nthe secure adoption of CF explanations in real-world applications.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "stat.ME"
        ],
        "authors": [
            "Hangzhi Guo",
            "Amulya Yadav"
        ],
        "published": "2024-05-29T00:33:56Z"
    },
    {
        "title": "Adapting Differentially Private Synthetic Data to Relational Databases",
        "link": "http://arxiv.org/abs/2405.18670v1",
        "abstract": "Existing differentially private (DP) synthetic data generation mechanisms\ntypically assume a single-source table. In practice, data is often distributed\nacross multiple tables with relationships across tables. In this paper, we\nintroduce the first-of-its-kind algorithm that can be combined with any\nexisting DP mechanisms to generate synthetic relational databases. Our\nalgorithm iteratively refines the relationship between individual synthetic\ntables to minimize their approximation errors in terms of low-order marginal\ndistributions while maintaining referential integrity. Finally, we provide both\nDP and theoretical utility guarantees for our algorithm.",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "cs.DB"
        ],
        "authors": [
            "Kaveh Alimohammadi",
            "Hao Wang",
            "Ojas Gulati",
            "Akash Srivastava",
            "Navid Azizan"
        ],
        "published": "2024-05-29T00:25:07Z"
    },
    {
        "title": "Zipper: A Multi-Tower Decoder Architecture for Fusing Modalities",
        "link": "http://arxiv.org/abs/2405.18669v1",
        "abstract": "Integrating multiple generative foundation models, especially those trained\non different modalities, into something greater than the sum of its parts poses\nsignificant challenges. Two key hurdles are the availability of aligned data\n(concepts that contain similar meaning but is expressed differently in\ndifferent modalities), and effectively leveraging unimodal representations in\ncross-domain generative tasks, without compromising their original unimodal\ncapabilities.\n  We propose Zipper, a multi-tower decoder architecture that addresses these\nconcerns by using cross-attention to flexibly compose multimodal generative\nmodels from independently pre-trained unimodal decoders. In our experiments\nfusing speech and text modalities, we show the proposed architecture performs\nvery competitively in scenarios with limited aligned text-speech data. We also\nshowcase the flexibility of our model to selectively maintain unimodal (e.g.,\ntext-to-text generation) generation performance by freezing the corresponding\nmodal tower (e.g. text). In cross-modal tasks such as automatic speech\nrecognition (ASR) where the output modality is text, we show that freezing the\ntext backbone results in negligible performance degradation. In cross-modal\ntasks such as text-to-speech generation (TTS) where the output modality is\nspeech, we show that using a pre-trained speech backbone results in superior\nperformance to the baseline.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "eess.AS"
        ],
        "authors": [
            "Vicky Zayats",
            "Peter Chen",
            "Melissa Merrari",
            "Dirk Padfield"
        ],
        "published": "2024-05-29T00:23:55Z"
    },
    {
        "title": "Non-Driving-Related Tasks Influencing Drivers' Takeover Time: A\n  Meta-Analysis",
        "link": "http://arxiv.org/abs/2405.18667v1",
        "abstract": "Before the era of fully automated vehicles, human is consistently an\nindispensable part of the driving system. Various studies have investigated\ndrivers' cooperation with the vehicle under different conditions. In this\narticle, we analyzed how non-driving-related tasks (NDRT) influence takeover\ntime (TOT) by conducting a meta-analysis on 37 related papers. NDRTs were\ntranscoded into combinations of five basic dimensions to unify and demonstrate\ntheir effects on drivers. In order to interpret experimental data\ncomprehensively, we implemented three methods. A synthetical analysis was\nconducted to compare the effect size between each study and subgroup. Studies\nwith eligible control groups have been examined by the two-group analysis,\nfollowed by moderator analysis on seven variables. The results from the\ntwo-group analysis showed that both visual-mental-motoric and visual-mental\ntasks have significant negative effects on the takeover time and the previous\ntype had a larger effect than the latter one. Moreover, the subgroup comparison\nand meta-regression in the meta-analysis part revealed the correlation between\nmoderators and the effect size, in which the Driving Experience and the\nAutomation Level affected the relation between NDRT and TOT. The findings of\nthis paper can contribute to the improvement and new directions for further\nscientific research and engineering design.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Yan Zhang"
        ],
        "published": "2024-05-29T00:07:41Z"
    },
    {
        "title": "Fast Explainability via Feasible Concept Sets Generator",
        "link": "http://arxiv.org/abs/2405.18664v1",
        "abstract": "A long-standing dilemma prevents the broader application of explanation\nmethods: general applicability and inference speed. On the one hand, existing\nmodel-agnostic explanation methods usually make minimal pre-assumptions about\nthe prediction models to be explained. Still, they require additional queries\nto the model through propagation or back-propagation to approximate the models'\nbehaviors, resulting in slow inference and hindering their use in\ntime-sensitive tasks. On the other hand, various model-dependent explanations\nhave been proposed that achieve low-cost, fast inference but at the expense of\nlimiting their applicability to specific model structures. In this study, we\nbridge the gap between the universality of model-agnostic approaches and the\nefficiency of model-specific approaches by proposing a novel framework without\nassumptions on the prediction model's structures, achieving high efficiency\nduring inference and allowing for real-time explanations. To achieve this, we\nfirst define explanations through a set of human-comprehensible concepts and\npropose a framework to elucidate model predictions via minimal feasible concept\nsets. Second, we show that a minimal feasible set generator can be learned as a\ncompanion explainer to the prediction model, generating explanations for\npredictions. Finally, we validate this framework by implementing a novel\nmodel-agnostic method that provides robust explanations while facilitating\nreal-time inference. Our claims are substantiated by comprehensive experiments,\nhighlighting the effectiveness and efficiency of our approach.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Deng Pan",
            "Nuno Moniz",
            "Nitesh Chawla"
        ],
        "published": "2024-05-29T00:01:40Z"
    }
]