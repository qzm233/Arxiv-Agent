[
    {
        "title": "OPERA: Automatic Offline Policy Evaluation with Re-weighted Aggregates\n  of Multiple Estimators",
        "link": "http://arxiv.org/abs/2405.17708v1",
        "abstract": "Offline policy evaluation (OPE) allows us to evaluate and estimate a new\nsequential decision-making policy's performance by leveraging historical\ninteraction data collected from other policies. Evaluating a new policy online\nwithout a confident estimate of its performance can lead to costly, unsafe, or\nhazardous outcomes, especially in education and healthcare. Several OPE\nestimators have been proposed in the last decade, many of which have\nhyperparameters and require training. Unfortunately, choosing the best OPE\nalgorithm for each task and domain is still unclear. In this paper, we propose\na new algorithm that adaptively blends a set of OPE estimators given a dataset\nwithout relying on an explicit selection using a statistical procedure. We\nprove that our estimator is consistent and satisfies several desirable\nproperties for policy evaluation. Additionally, we demonstrate that when\ncompared to alternative approaches, our estimator can be used to select\nhigher-performing policies in healthcare and robotics. Our work contributes to\nimproving ease of use for a general-purpose, estimator-agnostic, off-policy\nevaluation framework for offline RL.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Allen Nie",
            "Yash Chandak",
            "Christina J. Yuan",
            "Anirudhan Badrinath",
            "Yannis Flet-Berliac",
            "Emma Brunskil"
        ],
        "published": "2024-05-27T23:51:20Z"
    },
    {
        "title": "Video Enriched Retrieval Augmented Generation Using Aligned Video\n  Captions",
        "link": "http://arxiv.org/abs/2405.17706v1",
        "abstract": "In this work, we propose the use of \"aligned visual captions\" as a mechanism\nfor integrating information contained within videos into retrieval augmented\ngeneration (RAG) based chat assistant systems. These captions are able to\ndescribe the visual and audio content of videos in a large corpus while having\nthe advantage of being in a textual format that is both easy to reason about &\nincorporate into large language model (LLM) prompts, but also typically require\nless multimedia content to be inserted into the multimodal LLM context window,\nwhere typical configurations can aggressively fill up the context window by\nsampling video frames from the source video. Furthermore, visual captions can\nbe adapted to specific use cases by prompting the original foundational model /\ncaptioner for particular visual details or fine tuning. In hopes of helping\nadvancing progress in this area, we curate a dataset and describe automatic\nevaluation procedures on common RAG tasks.",
        "subjects": [
            "cs.AI",
            "cs.CV",
            "cs.IR"
        ],
        "authors": [
            "Kevin Dela Rosa"
        ],
        "published": "2024-05-27T23:39:17Z"
    },
    {
        "title": "DC-Gaussian: Improving 3D Gaussian Splatting for Reflective Dash Cam\n  Videos",
        "link": "http://arxiv.org/abs/2405.17705v2",
        "abstract": "We present DC-Gaussian, a new method for generating novel views from\nin-vehicle dash cam videos. While neural rendering techniques have made\nsignificant strides in driving scenarios, existing methods are primarily\ndesigned for videos collected by autonomous vehicles. However, these videos are\nlimited in both quantity and diversity compared to dash cam videos, which are\nmore widely used across various types of vehicles and capture a broader range\nof scenarios. Dash cam videos often suffer from severe obstructions such as\nreflections and occlusions on the windshields, which significantly impede the\napplication of neural rendering techniques. To address this challenge, we\ndevelop DC-Gaussian based on the recent real-time neural rendering technique 3D\nGaussian Splatting (3DGS). Our approach includes an adaptive image\ndecomposition module to model reflections and occlusions in a unified manner.\nAdditionally, we introduce illumination-aware obstruction modeling to manage\nreflections and occlusions under varying lighting conditions. Lastly, we employ\na geometry-guided Gaussian enhancement strategy to improve rendering details by\nincorporating additional geometry priors. Experiments on self-captured and\npublic dash cam videos show that our method not only achieves state-of-the-art\nperformance in novel view synthesis, but also accurately reconstructing\ncaptured scenes getting rid of obstructions.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Linhan Wang",
            "Kai Cheng",
            "Shuo Lei",
            "Shengkun Wang",
            "Wei Yin",
            "Chenyang Lei",
            "Xiaoxiao Long",
            "Chang-Tien Lu"
        ],
        "published": "2024-05-27T23:38:10Z"
    },
    {
        "title": "Consistency Regularisation for Unsupervised Domain Adaptation in\n  Monocular Depth Estimation",
        "link": "http://arxiv.org/abs/2405.17704v1",
        "abstract": "In monocular depth estimation, unsupervised domain adaptation has recently\nbeen explored to relax the dependence on large annotated image-based depth\ndatasets. However, this comes at the cost of training multiple models or\nrequiring complex training protocols. We formulate unsupervised domain\nadaptation for monocular depth estimation as a consistency-based\nsemi-supervised learning problem by assuming access only to the source domain\nground truth labels. To this end, we introduce a pairwise loss function that\nregularises predictions on the source domain while enforcing perturbation\nconsistency across multiple augmented views of the unlabelled target samples.\nImportantly, our approach is simple and effective, requiring only training of a\nsingle model in contrast to the prior work. In our experiments, we rely on the\nstandard depth estimation benchmarks KITTI and NYUv2 to demonstrate\nstate-of-the-art results compared to related approaches. Furthermore, we\nanalyse the simplicity and effectiveness of our approach in a series of\nablation studies. The code is available at\n\\url{https://github.com/AmirMaEl/SemiSupMDE}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Amir El-Ghoussani",
            "Julia Hornauer",
            "Gustavo Carneiro",
            "Vasileios Belagiannis"
        ],
        "published": "2024-05-27T23:32:06Z"
    },
    {
        "title": "Mechanistic Interpretability of Binary and Ternary Transformers",
        "link": "http://arxiv.org/abs/2405.17703v1",
        "abstract": "Recent research (arXiv:2310.11453, arXiv:2402.17764) has proposed binary and\nternary transformer networks as a way to significantly reduce memory and\nimprove inference speed in Large Language Models (LLMs) while maintaining\naccuracy. In this work, we apply techniques from mechanistic interpretability\nto investigate whether such networks learn distinctly different or similar\nalgorithms when compared to full-precision transformer networks. In particular,\nwe reverse engineer the algorithms learned for the toy problem of modular\naddition where we find that binary and ternary networks learn similar\nalgorithms as full precision networks. This provides evidence against the\npossibility of using binary and ternary networks as a more interpretable\nalternative in the LLM setting.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "authors": [
            "Jason Li"
        ],
        "published": "2024-05-27T23:22:23Z"
    },
    {
        "title": "A Two-sided Model for EV Market Dynamics and Policy Implications",
        "link": "http://arxiv.org/abs/2405.17702v1",
        "abstract": "The diffusion of Electric Vehicles (EVs) plays a pivotal role in mitigating\ngreenhouse gas emissions, particularly in the U.S., where ambitious\nzero-emission and carbon neutrality objectives have been set. In pursuit of\nthese goals, many states have implemented a range of incentive policies aimed\nat stimulating EV adoption and charging infrastructure development, especially\npublic EV charging stations (EVCS). This study examines the indirect network\neffect observed between EV adoption and EVCS deployment within urban\nlandscapes. We developed a two-sided log-log regression model with historical\ndata on EV purchases and EVCS development to quantify this effect. To test the\nrobustness, we then conducted a case study of the EV market in Los Angeles (LA)\nCounty, which suggests that a 1% increase in EVCS correlates with a 0.35%\nincrease in EV sales. Additionally, we forecasted the future EV market dynamics\nin LA County, revealing a notable disparity between current policies and the\ntargeted 80% EV market share for private cars by 2045. To bridge this gap, we\nproposed a combined policy recommendation that enhances EV incentives by 60%\nand EVCS rebates by 66%, facilitating the achievement of future EV market\nobjectives.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Haoxuan Ma",
            "Brian Yueshuai He",
            "Tomas Kaljevic",
            "Jiaqi Ma"
        ],
        "published": "2024-05-27T23:18:12Z"
    },
    {
        "title": "Compression and In-Situ Query Processing for Fine-Grained Array Lineage",
        "link": "http://arxiv.org/abs/2405.17701v1",
        "abstract": "Tracking data lineage is important for data integrity, reproducibility, and\ndebugging data science workflows. However, fine-grained lineage (i.e., at a\ncell level) is challenging to store, even for the smallest datasets. This paper\nintroduces DSLog, a storage system that efficiently stores, indexes, and\nqueries array data lineage, agnostic to capture methodology. A main\ncontribution is our new compression algorithm, named ProvRC, that compresses\ncaptured lineage relationships. Using ProvRC for lineage compression result in\na significant storage reduction over functions with simple spatial regularity,\nbeating alternative columnar-store baselines by up to 2000x}. We also show that\nProvRC facilitates in-situ query processing that allows forward and backward\nlineage queries without decompression - in the optimal case, surpassing\nbaselines by 20x in query latency on random numpy pipelines.",
        "subjects": [
            "cs.DB"
        ],
        "authors": [
            "Jinjin Zhao",
            "Sanjay Krishnan"
        ],
        "published": "2024-05-27T23:17:24Z"
    },
    {
        "title": "Learning Social Welfare Functions",
        "link": "http://arxiv.org/abs/2405.17700v1",
        "abstract": "Is it possible to understand or imitate a policy maker's rationale by looking\nat past decisions they made? We formalize this question as the problem of\nlearning social welfare functions belonging to the well-studied family of power\nmean functions. We focus on two learning tasks; in the first, the input is\nvectors of utilities of an action (decision or policy) for individuals in a\ngroup and their associated social welfare as judged by a policy maker, whereas\nin the second, the input is pairwise comparisons between the welfares\nassociated with a given pair of utility vectors. We show that power mean\nfunctions are learnable with polynomial sample complexity in both cases, even\nif the comparisons are social welfare information is noisy. Finally, we design\npractical algorithms for these tasks and evaluate their performance.",
        "subjects": [
            "cs.GT",
            "cs.LG"
        ],
        "authors": [
            "Kanad Shrikar Pardeshi",
            "Itai Shapira",
            "Ariel D. Procaccia",
            "Aarti Singh"
        ],
        "published": "2024-05-27T23:16:52Z"
    },
    {
        "title": "BaboonLand Dataset: Tracking Primates in the Wild and Automating\n  Behaviour Recognition from Drone Videos",
        "link": "http://arxiv.org/abs/2405.17698v2",
        "abstract": "Using drones to track multiple individuals simultaneously in their natural\nenvironment is a powerful approach for better understanding group primate\nbehavior. Previous studies have demonstrated that it is possible to automate\nthe classification of primate behavior from video data, but these studies have\nbeen carried out in captivity or from ground-based cameras. To understand group\nbehavior and the self-organization of a collective, the whole troop needs to be\nseen at a scale where behavior can be seen in relation to the natural\nenvironment in which ecological decisions are made. This study presents a novel\ndataset from drone videos for baboon detection, tracking, and behavior\nrecognition. The baboon detection dataset was created by manually annotating\nall baboons in drone videos with bounding boxes. A tiling method was\nsubsequently applied to create a pyramid of images at various scales from the\noriginal 5.3K resolution images, resulting in approximately 30K images used for\nbaboon detection. The tracking dataset is derived from the detection dataset,\nwhere all bounding boxes are assigned the same ID throughout the video. This\nprocess resulted in half an hour of very dense tracking data. The behavior\nrecognition dataset was generated by converting tracks into mini-scenes, a\nvideo subregion centered on each animal; each mini-scene was manually annotated\nwith 12 distinct behavior types, resulting in over 20 hours of data. Benchmark\nresults show mean average precision (mAP) of 92.62\\% for the YOLOv8-X detection\nmodel, multiple object tracking precision (MOTA) of 63.81\\% for the BotSort\ntracking algorithm, and micro top-1 accuracy of 63.97\\% for the X3D behavior\nrecognition model. Using deep learning to classify wildlife behavior from drone\nfootage facilitates non-invasive insight into the collective behavior of an\nentire group.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Isla Duporge",
            "Maksim Kholiavchenko",
            "Roi Harel",
            "Scott Wolf",
            "Dan Rubenstein",
            "Meg Crofoot",
            "Tanya Berger-Wolf",
            "Stephen Lee",
            "Julie Barreau",
            "Jenna Kline",
            "Michelle Ramirez",
            "Chuck Stewart"
        ],
        "published": "2024-05-27T23:09:37Z"
    },
    {
        "title": "P4: Towards private, personalized, and Peer-to-Peer learning",
        "link": "http://arxiv.org/abs/2405.17697v1",
        "abstract": "Personalized learning is a proposed approach to address the problem of data\nheterogeneity in collaborative machine learning. In a decentralized setting,\nthe two main challenges of personalization are client clustering and data\nprivacy. In this paper, we address these challenges by developing P4\n(Personalized Private Peer-to-Peer) a method that ensures that each client\nreceives a personalized model while maintaining differential privacy guarantee\nof each client's local dataset during and after the training. Our approach\nincludes the design of a lightweight algorithm to identify similar clients and\ngroup them in a private, peer-to-peer (P2P) manner. Once grouped, we develop\ndifferentially-private knowledge distillation for clients to co-train with\nminimal impact on accuracy. We evaluate our proposed method on three benchmark\ndatasets (FEMNIST or Federated EMNIST, CIFAR-10 and CIFAR-100) and two\ndifferent neural network architectures (Linear and CNN-based networks) across a\nrange of privacy parameters. The results demonstrate the potential of P4, as it\noutperforms the state-of-the-art of differential private P2P by up to 40\npercent in terms of accuracy. We also show the practicality of P4 by\nimplementing it on resource constrained devices, and validating that it has\nminimal overhead, e.g., about 7 seconds to run collaborative training between\ntwo clients.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Mohammad Mahdi Maheri",
            "Sandra Siby",
            "Ali Shahin Shamsabadi",
            "Sina Abdollahi",
            "Anastasia Borovykh",
            "Hamed Haddadi"
        ],
        "published": "2024-05-27T23:04:37Z"
    },
    {
        "title": "Physics-guided Full Waveform Inversion using Encoder-Solver\n  Convolutional Neural Networks",
        "link": "http://arxiv.org/abs/2405.17696v1",
        "abstract": "Full Waveform Inversion (FWI) is an inverse problem for estimating the wave\nvelocity distribution in a given domain, based on observed data on the\nboundaries. The inversion is computationally demanding because we are required\nto solve multiple forward problems, either in time or frequency domains, to\nsimulate data that are then iteratively fitted to the observed data. We\nconsider FWI in the frequency domain, where the Helmholtz equation is used as a\nforward model, and its repeated solution is the main computational bottleneck\nof the inversion process. To ease this cost, we integrate a learning process of\nan encoder-solver preconditioner that is based on convolutional neural networks\n(CNNs). The encoder-solver is trained to effectively precondition the\ndiscretized Helmholtz operator given velocity medium parameters. Then, by\nre-training the CNN between the iterations of the optimization process, the\nencoder-solver is adapted to the iteratively evolving velocity medium as part\nof the inversion. Without retraining, the performance of the solver\ndeteriorates as the medium changes. Using our light retraining procedures, we\nobtain the forward simulations effectively throughout the process. We\ndemonstrate our approach to solving FWI problems using 2D geophysical models\nwith high-frequency data.",
        "subjects": [
            "cs.LG",
            "physics.comp-ph",
            "68T07 (Primary), 65N21 (Secondary)"
        ],
        "authors": [
            "Matan Goren",
            "Eran Treister"
        ],
        "published": "2024-05-27T23:03:21Z"
    },
    {
        "title": "Bias Detection Via Signaling",
        "link": "http://arxiv.org/abs/2405.17694v1",
        "abstract": "We introduce and study the problem of detecting whether an agent is updating\ntheir prior beliefs given new evidence in an optimal way that is Bayesian, or\nwhether they are biased towards their own prior. In our model, biased agents\nform posterior beliefs that are a convex combination of their prior and the\nBayesian posterior, where the more biased an agent is, the closer their\nposterior is to the prior. Since we often cannot observe the agent's beliefs\ndirectly, we take an approach inspired by information design. Specifically, we\nmeasure an agent's bias by designing a signaling scheme and observing the\nactions they take in response to different signals, assuming that they are\nmaximizing their own expected utility; our goal is to detect bias with a\nminimum number of signals. Our main results include a characterization of\nscenarios where a single signal suffices and a computationally efficient\nalgorithm to compute optimal signaling schemes.",
        "subjects": [
            "cs.GT"
        ],
        "authors": [
            "Yiling Chen",
            "Tao Lin",
            "Ariel D. Procaccia",
            "Aaditya Ramdas",
            "Itai Shapira"
        ],
        "published": "2024-05-27T23:02:24Z"
    },
    {
        "title": "Tamed Langevin sampling under weaker conditions",
        "link": "http://arxiv.org/abs/2405.17693v1",
        "abstract": "Motivated by applications to deep learning which often fail standard\nLipschitz smoothness requirements, we examine the problem of sampling from\ndistributions that are not log-concave and are only weakly dissipative, with\nlog-gradients allowed to grow superlinearly at infinity. In terms of structure,\nwe only assume that the target distribution satisfies either a log-Sobolev or a\nPoincar\\'e inequality and a local Lipschitz smoothness assumption with modulus\ngrowing possibly polynomially at infinity. This set of assumptions greatly\nexceeds the operational limits of the \"vanilla\" unadjusted Langevin algorithm\n(ULA), making sampling from such distributions a highly involved affair. To\naccount for this, we introduce a taming scheme which is tailored to the growth\nand decay properties of the target distribution, and we provide explicit\nnon-asymptotic guarantees for the proposed sampler in terms of the\nKullback-Leibler (KL) divergence, total variation, and Wasserstein distance to\nthe target distribution.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "cs.NA",
            "math.NA",
            "math.OC",
            "math.PR",
            "Primary 65C05, 60H10, secondary 68Q32"
        ],
        "authors": [
            "Iosif Lytras",
            "Panayotis Mertikopoulos"
        ],
        "published": "2024-05-27T23:00:40Z"
    },
    {
        "title": "Fully Subexponential Time Approximation Scheme for Product Partition",
        "link": "http://arxiv.org/abs/2405.17692v1",
        "abstract": "In this paper we study the Product Partition Problem (PPP), i.e. we are given\na set of $n$ natural numbers represented on $m$ bits each and we are asked if a\nsubset exists such that the product of the numbers in the subset equals the\nproduct of the numbers not in the subset. Our approach is to obtain the integer\nfactorization of each number. This is the subexponential step. We then form a\nmatrix with the exponents of the primes and propose a novel procedure which\nmodifies the given numbers in such a way that their integer factorization\ncontains sufficient primes to facilitate the search for the solution to the\npartition problem, while maintaining a similar product. We show that the\nrequired time and memory to run the proposed algorithm is subexponential.",
        "subjects": [
            "cs.DS",
            "math.OC"
        ],
        "authors": [
            "Marius Costandin"
        ],
        "published": "2024-05-27T22:52:49Z"
    },
    {
        "title": "Ontology-Enhanced Decision-Making for Autonomous Agents in Dynamic and\n  Partially Observable Environments",
        "link": "http://arxiv.org/abs/2405.17691v1",
        "abstract": "Agents, whether software or hardware, perceive their environment through\nsensors and act using actuators, often operating in dynamic, partially\nobservable settings. They face challenges like incomplete and noisy data,\nunforeseen situations, and the need to adapt goals in real-time. Traditional\nreasoning and ML methods, including Reinforcement Learning (RL), help but are\nlimited by data needs, predefined goals, and extensive exploration periods.\nOntologies offer a solution by integrating diverse information sources,\nenhancing decision-making in complex environments. This thesis introduces an\nontology-enhanced decision-making model (OntoDeM) for autonomous agents.\nOntoDeM enriches agents' domain knowledge, allowing them to interpret\nunforeseen events, generate or adapt goals, and make better decisions. Key\ncontributions include: 1. An ontology-based method to improve agents' real-time\nobservations using prior knowledge. 2. The OntoDeM model for handling dynamic,\nunforeseen situations by evolving or generating new goals. 3. Implementation\nand evaluation in four real-world applications, demonstrating its\neffectiveness. Compared to traditional and advanced learning algorithms,\nOntoDeM shows superior performance in improving agents' observations and\ndecision-making in dynamic, partially observable environments.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Saeedeh Ghanadbashi",
            "Fatemeh Golpayegani"
        ],
        "published": "2024-05-27T22:52:23Z"
    },
    {
        "title": "Data Makes Better Data Scientists",
        "link": "http://arxiv.org/abs/2405.17690v1",
        "abstract": "With the goal of identifying common practices in data science projects, this\npaper proposes a framework for logging and understanding incremental code\nexecutions in Jupyter notebooks. This framework aims to allow reasoning about\nhow insights are generated in data science and extract key observations into\nbest data science practices in the wild. In this paper, we show an early\nprototype of this framework and ran an experiment to log a machine learning\nproject for 25 undergraduate students.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Jinjin Zhao",
            "Avidgor Gal",
            "Sanjay Krishnan"
        ],
        "published": "2024-05-27T22:46:17Z"
    },
    {
        "title": "Towards Causal Physical Error Discovery in Video Analytics Systems",
        "link": "http://arxiv.org/abs/2405.17686v1",
        "abstract": "Video analytics systems based on deep learning models are often opaque and\nbrittle and require explanation systems to help users debug. Current model\nexplanation system are very good at giving literal explanations of behavior in\nterms of pixel contributions but cannot integrate information about the\nphysical or systems processes that might influence a prediction. This paper\nintroduces the idea that a simple form of causal reasoning, called a regression\ndiscontinuity design, can be used to associate changes in multiple key\nperformance indicators to physical real world phenomena to give users a more\nactionable set of video analytics explanations. We overview the system\narchitecture and describe a vision of the impact that such a system might have.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jinjin Zhao",
            "Ted Shaowang",
            "Stavos Sintos",
            "Sanjay Krishnan"
        ],
        "published": "2024-05-27T22:40:33Z"
    },
    {
        "title": "Cryogenic Characterization of Low-Frequency Noise in 40-nm CMOS",
        "link": "http://arxiv.org/abs/2405.17685v1",
        "abstract": "This paper presents an extensive characterization of the low-frequency noise\n(LFN) at room temperature (RT) and cryogenic temperature (4.2 K) of 40-nm\nbulk-CMOS transistors. The noise is measured over a wide range of bias\nconditions and geometries to generate a comprehensive overview of LFN in this\ntechnology. While the RT results are in-line with the literature and the\nfoundry models, the cryogenic behavior diverges in many aspects. These\ndeviations include changes with respect to RT in magnitude and bias dependence\nthat are conditional on transistor type and geometry, and even an additional\nsystematic Lorentzian feature that is common among individual devices.\nFurthermore, we find the scaling of the average LFN with the area and its\nvariability to be similar between RT and 4.2 K, with the cryogenic scaling\nreported systematically for the first time. The findings suggest that, as no\nconsistent decrease of LFN at lower temperatures is observed while the white\nnoise is reduced, the impact of LFN for precision analog design at cryogenic\ntemperatures gains a more predominant role.",
        "subjects": [
            "physics.app-ph",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Gerd Kiene",
            "Sadik Ilik",
            "Luigi Mastrodomenico",
            "Masoud Babaie",
            "Fabio Sebastiano"
        ],
        "published": "2024-05-27T22:33:57Z"
    },
    {
        "title": "Synthesizing JSON Schema Transformers",
        "link": "http://arxiv.org/abs/2405.17681v1",
        "abstract": "JSON (JavaScript Object Notation) is a data encoding that allows structured\ndata to be used in a standardized and straightforward manner across systems.\nSchemas for JSON-formatted data can be constructed using the JSON Schema\nstandard, which describes the data types, structure, and meaning of\nJSON-formatted data. JSON is commonly used for storing and transmitting\ninformation such as program configurations, web API requests and responses, or\nremote procedure calls; or data records, such as healthcare information or\nother structured documents. Since JSON is a plaintext format with potentially\nhighly complex definitions, it can be an arduous process to change code which\nhandles structured JSON data when its storage or transmission schemas are\nmodified. Our work describes a program synthesis method to generate a program\nthat accepts data conforming to a given input JSON Schema and automatically\nconverts it to conform to a resulting, target JSON Schema. We use a top-down,\ntype-directed approach to search for programs using a set of rewrite rules\nwhich constrain the ways in which a schema can be modified without unintended\ndata loss or corruption. Once a satisfying sequence of rewrites has been found,\nwe pass an intermediate representation of the rewrite sequence to a code\ngeneration backend, which synthesizes a program which executes the data\ntransformation. This system allows users to quickly and efficiently modify or\naugment their existing systems in safe ways at their interfaces.",
        "subjects": [
            "cs.PL"
        ],
        "authors": [
            "Jack Stanek",
            "Daniel Killough"
        ],
        "published": "2024-05-27T22:17:50Z"
    },
    {
        "title": "Deciphering Movement: Unified Trajectory Generation Model for\n  Multi-Agent",
        "link": "http://arxiv.org/abs/2405.17680v1",
        "abstract": "Understanding multi-agent behavior is critical across various fields. The\nconventional approach involves analyzing agent movements through three primary\ntasks: trajectory prediction, imputation, and spatial-temporal recovery.\nConsidering the unique input formulation and constraint of these tasks, most\nexisting methods are tailored to address only one specific task. However, in\nreal-world applications, these scenarios frequently occur simultaneously.\nConsequently, methods designed for one task often fail to adapt to others,\nresulting in performance drops. To overcome this limitation, we propose a\nUnified Trajectory Generation model, UniTraj, that processes arbitrary\ntrajectories as masked inputs, adaptable to diverse scenarios. Specifically, we\nintroduce a Ghost Spatial Masking (GSM) module embedded within a Transformer\nencoder for spatial feature extraction. We further extend recent successful\nState Space Models (SSMs), particularly the Mamba model, into a Bidirectional\nTemporal Mamba to effectively capture temporal dependencies. Additionally, we\nincorporate a Bidirectional Temporal Scaled (BTS) module to comprehensively\nscan trajectories while maintaining the temporal missing relationships within\nthe sequence. We curate and benchmark three practical sports game datasets,\nBasketball-U, Football-U, and Soccer-U, for evaluation. Extensive experiments\ndemonstrate the superior performance of our model. To the best of our\nknowledge, this is the first work that addresses this unified problem through a\nversatile generative framework, thereby enhancing our understanding of\nmulti-agent movement. Our datasets, code, and model weights are available at\nhttps://github.com/colorfulfuture/UniTraj-pytorch.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yi Xu",
            "Yun Fu"
        ],
        "published": "2024-05-27T22:15:23Z"
    },
    {
        "title": "TIMA: Text-Image Mutual Awareness for Balancing Zero-Shot Adversarial\n  Robustness and Generalization Ability",
        "link": "http://arxiv.org/abs/2405.17678v1",
        "abstract": "This work addresses the challenge of achieving zero-shot adversarial\nrobustness while preserving zero-shot generalization in large-scale foundation\nmodels, with a focus on the popular Contrastive Language-Image Pre-training\n(CLIP). Although foundation models were reported to have exceptional zero-shot\ngeneralization, they are highly vulnerable to adversarial perturbations.\nExisting methods achieve a comparable good tradeoff between zero-shot\nadversarial robustness and generalization under small adversarial\nperturbations. However, they fail to achieve a good tradeoff under large\nadversarial perturbations. To this end, we propose a novel Text-Image Mutual\nAwareness (TIMA) method that strikes a balance between zero-shot adversarial\nrobustness and generalization. More precisely, we propose an Image-Aware Text\n(IAT) tuning mechanism that increases the inter-class distance of text\nembeddings by incorporating the Minimum Hyperspherical Energy (MHE).\nSimultaneously, fixed pre-trained image embeddings are used as cross-modal\nauxiliary supervision to maintain the similarity between the MHE-tuned and\noriginal text embeddings by the knowledge distillation, preserving semantic\ninformation between different classes. Besides, we introduce a Text-Aware Image\n(TAI) tuning mechanism, which increases inter-class distance between image\nembeddings during the training stage by Text-distance based Adaptive Margin\n(TAM). Similarly, a knowledge distillation is utilized to retain the similarity\nbetween fine-tuned and pre-trained image embeddings. Extensive experimental\nresults demonstrate the effectiveness of our approach, showing impressive\nzero-shot performance against a wide range of adversarial perturbations while\npreserving the zero-shot generalization capabilities of the original CLIP\nmodel.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Fengji Ma",
            "Li Liu",
            "Hei Victor Cheng"
        ],
        "published": "2024-05-27T22:10:17Z"
    },
    {
        "title": "Understanding differences in applying DETR to natural and medical images",
        "link": "http://arxiv.org/abs/2405.17677v1",
        "abstract": "Transformer-based detectors have shown success in computer vision tasks with\nnatural images. These models, exemplified by the Deformable DETR, are optimized\nthrough complex engineering strategies tailored to the typical characteristics\nof natural scenes. However, medical imaging data presents unique challenges\nsuch as extremely large image sizes, fewer and smaller regions of interest, and\nobject classes which can be differentiated only through subtle differences.\nThis study evaluates the applicability of these transformer-based design\nchoices when applied to a screening mammography dataset that represents these\ndistinct medical imaging data characteristics. Our analysis reveals that common\ndesign choices from the natural image domain, such as complex encoder\narchitectures, multi-scale feature fusion, query initialization, and iterative\nbounding box refinement, do not improve and sometimes even impair object\ndetection performance in medical imaging. In contrast, simpler and shallower\narchitectures often achieve equal or superior results. This finding suggests\nthat the adaptation of transformer models for medical imaging data requires a\nreevaluation of standard practices, potentially leading to more efficient and\nspecialized frameworks for medical diagnosis.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yanqi Xu",
            "Yiqiu Shen",
            "Carlos Fernandez-Granda",
            "Laura Heacock",
            "Krzysztof J. Geras"
        ],
        "published": "2024-05-27T22:06:42Z"
    },
    {
        "title": "Utilising a Quantum Hybrid Solver for Bi-objective Quadratic Assignment\n  Problems",
        "link": "http://dx.doi.org/10.1145/3638530.3664097",
        "abstract": "The intersection between quantum computing and optimisation has been an area\nof interest in recent years. There have been numerous studies exploring the\napplication of quantum and quantum-hybrid solvers to various optimisation\nproblems. This work explores scalarisation methods within the context of\nsolving the bi-objective quadratic assignment problem using a quantum-hybrid\nsolver. We show results that are consistent with previous research on a\ndifferent Ising machine.",
        "subjects": [
            "quant-ph",
            "cs.AI",
            "G.1.6"
        ],
        "authors": [
            "Mayowa Ayodele"
        ],
        "published": "2024-05-27T22:03:26Z"
    },
    {
        "title": "Fast Samplers for Inverse Problems in Iterative Refinement Models",
        "link": "http://arxiv.org/abs/2405.17673v1",
        "abstract": "Constructing fast samplers for unconditional diffusion and flow-matching\nmodels has received much attention recently; however, existing methods for\nsolving inverse problems, such as super-resolution, inpainting, or deblurring,\nstill require hundreds to thousands of iterative steps to obtain high-quality\nresults. We propose a plug-and-play framework for constructing efficient\nsamplers for inverse problems, requiring only pre-trained diffusion or\nflow-matching models. We present Conditional Conjugate Integrators, which\nleverage the specific form of the inverse problem to project the respective\nconditional diffusion/flow dynamics into a more amenable space for sampling.\nOur method complements popular posterior approximation methods for solving\ninverse problems using diffusion/flow models. We evaluate the proposed method's\nperformance on various linear image restoration tasks across multiple datasets,\nemploying diffusion and flow-matching models. Notably, on challenging inverse\nproblems like 4$\\times$ super-resolution on the ImageNet dataset, our method\ncan generate high-quality samples in as few as 5 conditional sampling steps and\noutperforms competing baselines requiring 20-1000 steps. Our code and models\nwill be publicly available at https://github.com/mandt-lab/CI2RM.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Kushagra Pandey",
            "Ruihan Yang",
            "Stephan Mandt"
        ],
        "published": "2024-05-27T21:50:16Z"
    },
    {
        "title": "Exploring Loss Design Techniques For Decision Tree Robustness To Label\n  Noise",
        "link": "http://arxiv.org/abs/2405.17672v1",
        "abstract": "In the real world, data is often noisy, affecting not only the quality of\nfeatures but also the accuracy of labels. Current research on mitigating label\nerrors stems primarily from advances in deep learning, and a gap exists in\nexploring interpretable models, particularly those rooted in decision trees. In\nthis study, we investigate whether ideas from deep learning loss design can be\napplied to improve the robustness of decision trees. In particular, we show\nthat loss correction and symmetric losses, both standard approaches, are not\neffective. We argue that other directions need to be explored to improve the\nrobustness of decision trees to label noise.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Lukasz Sztukiewicz",
            "Jack Henry Good",
            "Artur Dubrawski"
        ],
        "published": "2024-05-27T21:49:57Z"
    },
    {
        "title": "Deployment of NLP and LLM Techniques to Control Mobile Robots at the\n  Edge: A Case Study Using GPT-4-Turbo and LLaMA 2",
        "link": "http://arxiv.org/abs/2405.17670v1",
        "abstract": "This paper investigates the possibility of intuitive human-robot interaction\nthrough the application of Natural Language Processing (NLP) and Large Language\nModels (LLMs) in mobile robotics. We aim to explore the feasibility of using\nthese technologies for edge-based deployment, where traditional cloud\ndependencies are eliminated. The study specifically contrasts the performance\nof GPT-4-Turbo, which requires cloud connectivity, with an offline-capable,\nquantized version of LLaMA 2 (LLaMA 2-7B.Q5 K M). Our results show that\nGPT-4-Turbo delivers superior performance in interpreting and executing complex\ncommands accurately, whereas LLaMA 2 exhibits significant limitations in\nconsistency and reliability of command execution. Communication between the\ncontrol computer and the mobile robot is established via a Raspberry Pi Pico W,\nwhich wirelessly receives commands from the computer without internet\ndependency and transmits them through a wired connection to the robot's Arduino\ncontroller. This study highlights the potential and challenges of implementing\nLLMs and NLP at the edge, providing groundwork for future research into fully\nautonomous and network-independent robotic systems. For video demonstrations\nand source code, please refer to: https://tinyurl.com/RobocupSym2024.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Pascal Sikorski",
            "Leendert Schrader",
            "Kaleb Yu",
            "Lucy Billadeau",
            "Jinka Meenakshi",
            "Naveena Mutharasan",
            "Flavio Esposito",
            "Hadi AliAkbarpour",
            "Madi Babaiasl"
        ],
        "published": "2024-05-27T21:48:07Z"
    },
    {
        "title": "Hunting for Polluted White Dwarfs and Other Treasures with Gaia XP\n  Spectra and Unsupervised Machine Learning",
        "link": "http://arxiv.org/abs/2405.17667v1",
        "abstract": "White dwarfs (WDs) polluted by exoplanetary material provide the\nunprecedented opportunity to directly observe the interiors of exoplanets.\nHowever, spectroscopic surveys are often limited by brightness constraints, and\nWDs tend to be very faint, making detections of large populations of polluted\nWDs difficult. In this paper, we aim to increase considerably the number of WDs\nwith multiple metals in their atmospheres. Using 96,134 WDs with Gaia DR3 BP/RP\n(XP) spectra, we constructed a 2D map using an unsupervised machine learning\ntechnique called Uniform Manifold Approximation and Projection (UMAP) to\norganize the WDs into identifiable spectral regions. The polluted WDs are among\nthe distinct spectral groups identified in our map. We have shown that this\nselection method could potentially increase the number of known WDs with 5 or\nmore metal species in their atmospheres by an order of magnitude. Such systems\nare essential for characterizing exoplanet diversity and geology.",
        "subjects": [
            "astro-ph.SR",
            "astro-ph.EP",
            "cs.LG"
        ],
        "authors": [
            "Malia L. Kao",
            "Keith Hawkins",
            "Laura K. Rogers",
            "Amy Bonsor",
            "Bart H. Dunlap",
            "Jason L. Sanders",
            "M. H. Montgomery",
            "D. E. Winget"
        ],
        "published": "2024-05-27T21:44:14Z"
    },
    {
        "title": "Structured Partial Stochasticity in Bayesian Neural Networks",
        "link": "http://arxiv.org/abs/2405.17666v1",
        "abstract": "Bayesian neural network posterior distributions have a great number of modes\nthat correspond to the same network function. The abundance of such modes can\nmake it difficult for approximate inference methods to do their job. Recent\nwork has demonstrated the benefits of partial stochasticity for approximate\ninference in Bayesian neural networks; inference can be less costly and\nperformance can sometimes be improved. I propose a structured way to select the\ndeterministic subset of weights that removes neuron permutation symmetries, and\ntherefore the corresponding redundant posterior modes. With a drastically\nsimplified posterior distribution, the performance of existing approximate\ninference schemes is found to be greatly improved.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Tommy Rochussen"
        ],
        "published": "2024-05-27T21:40:31Z"
    },
    {
        "title": "Enhanced Robot Arm at the Edge with NLP and Vision Systems",
        "link": "http://arxiv.org/abs/2405.17665v1",
        "abstract": "This paper introduces a \"proof of concept\" for a new approach to assistive\nrobotics, integrating edge computing with Natural Language Processing (NLP) and\ncomputer vision to enhance the interaction between humans and robotic systems.\nOur \"proof of concept\" demonstrates the feasibility of using large language\nmodels (LLMs) and vision systems in tandem for interpreting and executing\ncomplex commands conveyed through natural language. This integration aims to\nimprove the intuitiveness and accessibility of assistive robotic systems,\nmaking them more adaptable to the nuanced needs of users with disabilities. By\nleveraging the capabilities of edge computing, our system has the potential to\nminimize latency and support offline capability, enhancing the autonomy and\nresponsiveness of assistive robots. Experimental results from our\nimplementation on a robotic arm show promising outcomes in terms of accurate\nintent interpretation and object manipulation based on verbal commands. This\nresearch lays the groundwork for future developments in assistive robotics,\nfocusing on creating highly responsive, user-centric systems that can\nsignificantly improve the quality of life for individuals with disabilities.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Pascal Sikorski",
            "Kaleb Yu",
            "Lucy Billadeau",
            "Flavio Esposito",
            "Hadi AliAkbarpour",
            "Madi Babaiasl"
        ],
        "published": "2024-05-27T21:33:56Z"
    },
    {
        "title": "Adaptive Device-Edge Collaboration on DNN Inference in AIoT: A Digital\n  Twin-Assisted Approach",
        "link": "http://dx.doi.org/10.1109/JIOT.2023.3336600",
        "abstract": "Device-edge collaboration on deep neural network (DNN) inference is a\npromising approach to efficiently utilizing network resources for supporting\nartificial intelligence of things (AIoT) applications. In this paper, we\npropose a novel digital twin (DT)-assisted approach to device-edge\ncollaboration on DNN inference that determines whether and when to stop local\ninference at a device and upload the intermediate results to complete the\ninference on an edge server. Instead of determining the collaboration for each\nDNN inference task only upon its generation, multi-step decision-making is\nperformed during the on-device inference to adapt to the dynamic computing\nworkload status at the device and the edge server. To enhance the adaptivity, a\nDT is constructed to evaluate all potential offloading decisions for each DNN\ninference task, which provides augmented training data for a machine\nlearning-assisted decision-making algorithm. Then, another DT is constructed to\nestimate the inference status at the device to avoid frequently fetching the\nstatus information from the device, thus reducing the signaling overhead. We\nalso derive necessary conditions for optimal offloading decisions to reduce the\noffloading decision space. Simulation results demon-strate the outstanding\nperformance of our DT-assisted approach in terms of balancing the tradeoff\namong inference accuracy, delay, and energy consumption.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Shisheng Hu",
            "Mushu Li",
            "Jie Gao",
            "Conghao Zhou",
            "Xuemin Shen"
        ],
        "published": "2024-05-27T21:30:52Z"
    },
    {
        "title": "What's the Opposite of a Face? Finding Shared Decodable Concepts and\n  their Negations in the Brain",
        "link": "http://arxiv.org/abs/2405.17663v1",
        "abstract": "Prior work has offered evidence for functional localization in the brain;\ndifferent anatomical regions preferentially activate for certain types of\nvisual input. For example, the fusiform face area preferentially activates for\nvisual stimuli that include a face. However, the spectrum of visual semantics\nis extensive, and only a few semantically-tuned patches of cortex have so far\nbeen identified in the human brain. Using a multimodal (natural language and\nimage) neural network architecture (CLIP) we train a highly accurate\ncontrastive model that maps brain responses during naturalistic image viewing\nto CLIP embeddings. We then use a novel adaptation of the DBSCAN clustering\nalgorithm to cluster the parameters of these participant-specific contrastive\nmodels. This reveals what we call Shared Decodable Concepts (SDCs): clusters in\nCLIP space that are decodable from common sets of voxels across multiple\nparticipants.\n  Examining the images most and least associated with each SDC cluster gives us\nadditional insight into the semantic properties of each SDC. We note SDCs for\npreviously reported visual features (e.g. orientation tuning in early visual\ncortex) as well as visual semantic concepts such as faces, places and bodies.\nIn cases where our method finds multiple clusters for a visuo-semantic concept,\nthe least associated images allow us to dissociate between confounding factors.\nFor example, we discovered two clusters of food images, one driven by color,\nthe other by shape. We also uncover previously unreported areas such as regions\nof extrastriate body area (EBA) tuned for legs/hands and sensitivity to\nnumerosity in right intraparietal sulcus, and more. Thus, our\ncontrastive-learning methodology better characterizes new and existing\nvisuo-semantic representations in the brain by leveraging multimodal neural\nnetwork representations and a novel adaptation of clustering algorithms.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Cory Efird",
            "Alex Murphy",
            "Joel Zylberberg",
            "Alona Fyshe"
        ],
        "published": "2024-05-27T21:28:26Z"
    },
    {
        "title": "RefDrop: Controllable Consistency in Image or Video Generation via\n  Reference Feature Guidance",
        "link": "http://arxiv.org/abs/2405.17661v1",
        "abstract": "There is a rapidly growing interest in controlling consistency across\nmultiple generated images using diffusion models. Among various methods, recent\nworks have found that simply manipulating attention modules by concatenating\nfeatures from multiple reference images provides an efficient approach to\nenhancing consistency without fine-tuning. Despite its popularity and success,\nfew studies have elucidated the underlying mechanisms that contribute to its\neffectiveness. In this work, we reveal that the popular approach is a linear\ninterpolation of image self-attention and cross-attention between synthesized\ncontent and reference features, with a constant rank-1 coefficient. Motivated\nby this observation, we find that a rank-1 coefficient is not necessary and\nsimplifies the controllable generation mechanism. The resulting algorithm,\nwhich we coin as RefDrop, allows users to control the influence of reference\ncontext in a direct and precise manner. Besides further enhancing consistency\nin single-subject image generation, our method also enables more interesting\napplications, such as the consistent generation of multiple subjects,\nsuppressing specific features to encourage more diverse content, and\nhigh-quality personalized video generation by boosting temporal consistency.\nEven compared with state-of-the-art image-prompt-based generators, such as\nIP-Adapter, RefDrop is competitive in terms of controllability and quality\nwhile avoiding the need to train a separate image encoder for feature injection\nfrom reference images, making it a versatile plug-and-play solution for any\nimage or video diffusion model.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jiaojiao Fan",
            "Haotian Xue",
            "Qinsheng Zhang",
            "Yongxin Chen"
        ],
        "published": "2024-05-27T21:23:20Z"
    },
    {
        "title": "LoReTrack: Efficient and Accurate Low-Resolution Transformer Tracking",
        "link": "http://arxiv.org/abs/2405.17660v1",
        "abstract": "High-performance Transformer trackers have shown excellent results, yet they\noften bear a heavy computational load. Observing that a smaller input can\nimmediately and conveniently reduce computations without changing the model, an\neasy solution is to adopt the low-resolution input for efficient Transformer\ntracking. Albeit faster, this hurts tracking accuracy much due to information\nloss in low resolution tracking. In this paper, we aim to mitigate such\ninformation loss to boost the performance of the low-resolution Transformer\ntracking via dual knowledge distillation from a frozen high-resolution (but not\na larger) Transformer tracker. The core lies in two simple yet effective\ndistillation modules, comprising query-key-value knowledge distillation\n(QKV-KD) and discrimination knowledge distillation (Disc-KD), across\nresolutions. The former, from the global view, allows the low-resolution\ntracker to inherit the features and interactions from the high-resolution\ntracker, while the later, from the target-aware view, enhances the\ntarget-background distinguishing capacity via imitating discriminative regions\nfrom its high-resolution counterpart. With the dual knowledge distillation, our\nLow-Resolution Transformer Tracker (LoReTrack) enjoys not only high efficiency\nowing to reduced computation but also enhanced accuracy by distilling knowledge\nfrom the high-resolution tracker. In extensive experiments, LoReTrack with a\n256x256 resolution consistently improves baseline with the same resolution, and\nshows competitive or even better results compared to 384x384 high-resolution\nTransformer tracker, while running 52% faster and saving 56% MACs. Moreover,\nLoReTrack is resolution-scalable. With a 128x128 resolution, it runs 25 fps on\na CPU with 64.9%/46.4% SUC scores on LaSOT/LaSOText, surpassing all other CPU\nreal-time trackers. Code will be released.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Shaohua Dong",
            "Yunhe Feng",
            "Qing Yang",
            "Yuewei Lin",
            "Heng Fan"
        ],
        "published": "2024-05-27T21:19:04Z"
    },
    {
        "title": "Enhancing Global Sensitivity and Uncertainty Quantification in Medical\n  Image Reconstruction with Monte Carlo Arbitrary-Masked Mamba",
        "link": "http://arxiv.org/abs/2405.17659v1",
        "abstract": "Deep learning has been extensively applied in medical image reconstruction,\nwhere Convolutional Neural Networks (CNNs) and Vision Transformers (ViTs)\nrepresent the predominant paradigms, each possessing distinct advantages and\ninherent limitations: CNNs exhibit linear complexity with local sensitivity,\nwhereas ViTs demonstrate quadratic complexity with global sensitivity. The\nemerging Mamba has shown superiority in learning visual representation, which\ncombines the advantages of linear scalability and global sensitivity. In this\nstudy, we introduce MambaMIR, an Arbitrary-Masked Mamba-based model with\nwavelet decomposition for joint medical image reconstruction and uncertainty\nestimation. A novel Arbitrary Scan Masking (ASM) mechanism ``masks out''\nredundant information to introduce randomness for further uncertainty\nestimation. Compared to the commonly used Monte Carlo (MC) dropout, our\nproposed MC-ASM provides an uncertainty map without the need for hyperparameter\ntuning and mitigates the performance drop typically observed when applying\ndropout to low-level tasks. For further texture preservation and better\nperceptual quality, we employ the wavelet transformation into MambaMIR and\nexplore its variant based on the Generative Adversarial Network, namely\nMambaMIR-GAN. Comprehensive experiments have been conducted for multiple\nrepresentative medical image reconstruction tasks, demonstrating that the\nproposed MambaMIR and MambaMIR-GAN outperform other baseline and\nstate-of-the-art methods in different reconstruction tasks, where MambaMIR\nachieves the best reconstruction fidelity and MambaMIR-GAN has the best\nperceptual quality. In addition, our MC-ASM provides uncertainty maps as an\nadditional tool for clinicians, while mitigating the typical performance drop\ncaused by the commonly used dropout.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Jiahao Huang",
            "Liutao Yang",
            "Fanwen Wang",
            "Yinzhe Wu",
            "Yang Nan",
            "Weiwen Wu",
            "Chengyan Wang",
            "Kuangyu Shi",
            "Angelica I. Aviles-Rivero",
            "Carola-Bibiane Schnlieb",
            "Daoqiang Zhang",
            "Guang Yang"
        ],
        "published": "2024-05-27T21:04:43Z"
    },
    {
        "title": "Generative Query Reformulation Using Ensemble Prompting, Document\n  Fusion, and Relevance Feedback",
        "link": "http://arxiv.org/abs/2405.17658v1",
        "abstract": "Query Reformulation (QR) is a set of techniques used to transform a user's\noriginal search query to a text that better aligns with the user's intent and\nimproves their search experience. Recently, zero-shot QR has been a promising\napproach due to its ability to exploit knowledge inherent in large language\nmodels. Inspired by the success of ensemble prompting strategies which have\nbenefited other tasks, we investigate if they can improve query reformulation.\nIn this context, we propose two ensemble-based prompting techniques,\nGenQREnsemble and GenQRFusion which leverage paraphrases of a zero-shot\ninstruction to generate multiple sets of keywords to improve retrieval\nperformance ultimately. We further introduce their post-retrieval variants to\nincorporate relevance feedback from a variety of sources, including an oracle\nsimulating a human user and a \"critic\" LLM. We demonstrate that an ensemble of\nquery reformulations can improve retrieval effectiveness by up to 18% on\nnDCG@10 in pre-retrieval settings and 9% on post-retrieval settings on multiple\nbenchmarks, outperforming all previously reported SOTA results. We perform\nsubsequent analyses to investigate the effects of feedback documents,\nincorporate domain-specific instructions, filter reformulations, and generate\nfluent reformulations that might be more beneficial to human searchers.\nTogether, the techniques and the results presented in this paper establish a\nnew state of the art in automated query reformulation for retrieval and suggest\npromising directions for future research.",
        "subjects": [
            "cs.IR",
            "cs.CL",
            "H.3.3; I.2.7"
        ],
        "authors": [
            "Kaustubh D. Dhole",
            "Ramraj Chandradevan",
            "Eugene Agichtein"
        ],
        "published": "2024-05-27T21:03:26Z"
    },
    {
        "title": "Robust Perception and Navigation of Autonomous Surface Vehicles in\n  Challenging Environments",
        "link": "http://arxiv.org/abs/2405.17657v1",
        "abstract": "Research on coastal regions traditionally involves methods like manual\nsampling, monitoring buoys, and remote sensing, but these methods face\nchallenges in spatially and temporally diverse regions of interest. Autonomous\nsurface vehicles (ASVs) with artificial intelligence (AI) are being explored,\nand recognized by the International Maritime Organization (IMO) as vital for\nfuture ecosystem understanding. However, there is not yet a mature technology\nfor autonomous environmental monitoring due to typically complex coastal\nsituations: (1) many static (e.g., buoy, dock) and dynamic (e.g., boats)\nobstacles not compliant with the rules of the road (COLREGs); (2) uncharted or\nuncertain information (e.g., non-updated nautical chart); and (3) high-cost\nASVs not accessible to the community and citizen science while resulting in\ntechnology illiteracy. To address the above challenges, my research involves\nboth system and algorithmic development: (1) a robotic boat system for stable\nand reliable in-water monitoring, (2) maritime perception to detect and track\nobstacles (such as buoys, and boats), and (3) navigational decision-making with\nmultiple-obstacle avoidance and multi-objective optimization.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Mingi Jeong"
        ],
        "published": "2024-05-27T20:59:47Z"
    },
    {
        "title": "Alignment is Key for Applying Diffusion Models to Retrosynthesis",
        "link": "http://arxiv.org/abs/2405.17656v1",
        "abstract": "Retrosynthesis, the task of identifying precursors for a given molecule, can\nbe naturally framed as a conditional graph generation task. Diffusion models\nare a particularly promising modelling approach, enabling post-hoc conditioning\nand trading off quality for speed during generation. We show mathematically\nthat permutation equivariant denoisers severely limit the expressiveness of\ngraph diffusion models and thus their adaptation to retrosynthesis. To address\nthis limitation, we relax the equivariance requirement such that it only\napplies to aligned permutations of the conditioning and the generated graphs\nobtained through atom mapping. Our new denoiser achieves the highest top-$1$\naccuracy ($54.7$\\%) across template-free and template-based methods on\nUSPTO-50k. We also demonstrate the ability for flexible post-training\nconditioning and good sample quality with small diffusion step counts,\nhighlighting the potential for interactive applications and additional controls\nfor multi-step planning.",
        "subjects": [
            "cs.LG",
            "q-bio.QM"
        ],
        "authors": [
            "Najwa Laabid",
            "Severi Rissanen",
            "Markus Heinonen",
            "Arno Solin",
            "Vikas Garg"
        ],
        "published": "2024-05-27T20:57:19Z"
    },
    {
        "title": "Data-Driven Personalized Energy Consumption Range Estimation for Plug-in\n  Hybrid Electric Vehicles in Urban Traffic",
        "link": "http://arxiv.org/abs/2405.17654v1",
        "abstract": "In urban traffic environments, driver behaviors exhibit considerable\ndiversity in vehicle operation, encompassing a range of acceleration and\nbraking maneuvers as well as adherence to traffic regulations, such as speed\nlimits. It is well-established that these intrinsic driving behaviors\nsignificantly influence vehicle energy consumption. Therefore, establishing a\nquantitative relationship between driver behavior and energy usage is essential\nfor identifying energy-efficient driving practices and optimizing routes within\nurban traffic. This study introduces a data-driven approach to predict the\nequivalent fuel consumption of a plug-in hybrid electric vehicle (PHEV) based\non an integrated model of driver behavior and vehicle energy consumption.\nUnlike traditional models that provide point predictions of fuel consumption,\nthis approach uses Conformalized Quantile Regression (CQR) to offer prediction\nintervals that capture the variability and uncertainty in fuel consumption.\nThese intervals reflect changes in fuel consumption, as well as variations in\ndriver behavior, and vehicle and route conditions. To develop this model,\ndriver-specific data were collected through a driver-in-the-loop simulator,\nwhich tested different human drivers responses. The CQR model was then trained\nand validated using the experimental data from the driver-in-the-loop\nsimulator, augmented by the synthetic data generated from Monte Carlo\nsimulations conducted using a calibrated microscopic driver behavior and\nvehicle energy model. The CQR model was evaluated by comparing its predictions\nof equivalent fuel consumption intervals with those of baseline prediction\ninterval methods that rely solely on conformal prediction.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Mehmet Fatih Ozkan",
            "James Farrell",
            "Marcello Telloni",
            "Luis Mendez",
            "Radu Pirvan",
            "Jeffrey P. Chrstos",
            "Marcello Canova",
            "Stephanie Stockar"
        ],
        "published": "2024-05-27T20:54:17Z"
    },
    {
        "title": "InversionView: A General-Purpose Method for Reading Information from\n  Neural Activations",
        "link": "http://arxiv.org/abs/2405.17653v1",
        "abstract": "The inner workings of neural networks can be better understood if we can\nfully decipher the information encoded in neural activations. In this paper, we\nargue that this information is embodied by the subset of inputs that give rise\nto similar activations. Computing such subsets is nontrivial as the input space\nis exponentially large. We propose InversionView, which allows us to\npractically inspect this subset by sampling from a trained decoder model\nconditioned on activations. This helps uncover the information content of\nactivation vectors, and facilitates understanding of the algorithms implemented\nby transformer models. We present three case studies where we investigate\nmodels ranging from small transformers to GPT-2. In these studies, we\ndemonstrate the characteristics of our method, show the distinctive advantages\nit offers, and provide causally verified circuits.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Xinting Huang",
            "Madhur Panwar",
            "Navin Goyal",
            "Michael Hahn"
        ],
        "published": "2024-05-27T20:53:22Z"
    },
    {
        "title": "Monotone two-scale methods for a class of integrodifferential operators\n  and applications",
        "link": "http://arxiv.org/abs/2405.17652v1",
        "abstract": "We develop a monotone, two-scale discretization for a class of\nintegrodifferential operators of order $2s$, $s \\in (0,1)$. We apply it to\ndevelop numerical schemes, and convergence rates, for linear and obstacle\nproblems governed by such operators. As applications of the monotonicity, we\nprovide error estimates for free boundaries and a convergent numerical scheme\nfor a concave fully nonlinear, nonlocal, problem.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Juan Pablo Borthagaray",
            "Ricardo H. Nochetto",
            "Abner J. Salgado",
            "Cline Torres"
        ],
        "published": "2024-05-27T20:53:06Z"
    },
    {
        "title": "An Analysis of Performance Bottlenecks in MRI Pre-Processing",
        "link": "http://arxiv.org/abs/2405.17650v1",
        "abstract": "Magnetic Resonance Image (MRI) pre-processing is a critical step for\nneuroimaging analysis. However, the computational cost of MRI pre-processing\npipelines is a major bottleneck for large cohort studies and some clinical\napplications. While High-Performance Computing (HPC) and, more recently, Deep\nLearning have been adopted to accelerate the computations, these techniques\nrequire costly hardware and are not accessible to all researchers. Therefore,\nit is important to understand the performance bottlenecks of MRI pre-processing\npipelines to improve their performance. Using Intel VTune profiler, we\ncharacterized the bottlenecks of several commonly used MRI-preprocessing\npipelines from the ANTs, FSL, and FreeSurfer toolboxes. We found that few\nfunctions contributed to most of the CPU time, and that linear interpolation\nwas the largest contributor. Data access was also a substantial bottleneck. We\nidentified a bug in the ITK library that impacts the performance of ANTs\npipeline in single-precision and a potential issue with the OpenMP scaling in\nFreeSurfer recon-all. Our results provide a reference for future efforts to\noptimize MRI pre-processing pipelines.",
        "subjects": [
            "cs.PF"
        ],
        "authors": [
            "Mathieu Dugr",
            "Yohan Chatelain",
            "Tristan Glatard"
        ],
        "published": "2024-05-27T20:48:33Z"
    },
    {
        "title": "Unifying Perspectives: Plausible Counterfactual Explanations on Global,\n  Group-wise, and Local Levels",
        "link": "http://arxiv.org/abs/2405.17642v1",
        "abstract": "Growing regulatory and societal pressures demand increased transparency in\nAI, particularly in understanding the decisions made by complex machine\nlearning models. Counterfactual Explanations (CFs) have emerged as a promising\ntechnique within Explainable AI (xAI), offering insights into individual model\npredictions. However, to understand the systemic biases and disparate impacts\nof AI models, it is crucial to move beyond local CFs and embrace global\nexplanations, which offer a~holistic view across diverse scenarios and\npopulations. Unfortunately, generating Global Counterfactual Explanations\n(GCEs) faces challenges in computational complexity, defining the scope of\n\"global,\" and ensuring the explanations are both globally representative and\nlocally plausible. We introduce a novel unified approach for generating Local,\nGroup-wise, and Global Counterfactual Explanations for differentiable\nclassification models via gradient-based optimization to address these\nchallenges. This framework aims to bridge the gap between individual and\nsystemic insights, enabling a deeper understanding of model decisions and their\npotential impact on diverse populations. Our approach further innovates by\nincorporating a probabilistic plausibility criterion, enhancing actionability\nand trustworthiness. By offering a cohesive solution to the optimization and\nplausibility challenges in GCEs, our work significantly advances the\ninterpretability and accountability of AI models, marking a step forward in the\npursuit of transparent AI.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ME"
        ],
        "authors": [
            "Patryk Wielopolski",
            "Oleksii Furman",
            "Jerzy Stefanowski",
            "Maciej Ziba"
        ],
        "published": "2024-05-27T20:32:09Z"
    },
    {
        "title": "Probabilistically Plausible Counterfactual Explanations with Normalizing\n  Flows",
        "link": "http://arxiv.org/abs/2405.17640v1",
        "abstract": "We present PPCEF, a novel method for generating probabilistically plausible\ncounterfactual explanations (CFs). PPCEF advances beyond existing methods by\ncombining a probabilistic formulation that leverages the data distribution with\nthe optimization of plausibility within a unified framework. Compared to\nreference approaches, our method enforces plausibility by directly optimizing\nthe explicit density function without assuming a particular family of\nparametrized distributions. This ensures CFs are not only valid (i.e., achieve\nclass change) but also align with the underlying data's probability density.\nFor that purpose, our approach leverages normalizing flows as powerful density\nestimators to capture the complex high-dimensional data distribution.\nFurthermore, we introduce a novel loss that balances the trade-off between\nachieving class change and maintaining closeness to the original instance while\nalso incorporating a probabilistic plausibility term. PPCEF's unconstrained\nformulation allows for efficient gradient-based optimization with batch\nprocessing, leading to orders of magnitude faster computation compared to prior\nmethods. Moreover, the unconstrained formulation of PPCEF allows for the\nseamless integration of future constraints tailored to specific counterfactual\nproperties. Finally, extensive evaluations demonstrate PPCEF's superiority in\ngenerating high-quality, probabilistically plausible counterfactual\nexplanations in high-dimensional tabular settings. This makes PPCEF a powerful\ntool for not only interpreting complex machine learning models but also for\nimproving fairness, accountability, and trust in AI systems.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ME"
        ],
        "authors": [
            "Patryk Wielopolski",
            "Oleksii Furman",
            "Jerzy Stefanowski",
            "Maciej Ziba"
        ],
        "published": "2024-05-27T20:24:03Z"
    },
    {
        "title": "The surprising efficiency of temporal difference learning for rare event\n  prediction",
        "link": "http://arxiv.org/abs/2405.17638v1",
        "abstract": "We quantify the efficiency of temporal difference (TD) learning over the\ndirect, or Monte Carlo (MC), estimator for policy evaluation in reinforcement\nlearning, with an emphasis on estimation of quantities related to rare events.\nPolicy evaluation is complicated in the rare event setting by the long\ntimescale of the event and by the need for \\emph{relative accuracy} in\nestimates of very small values. Specifically, we focus on least-squares TD\n(LSTD) prediction for finite state Markov chains, and show that LSTD can\nachieve relative accuracy far more efficiently than MC. We prove a central\nlimit theorem for the LSTD estimator and upper bound the \\emph{relative\nasymptotic variance} by simple quantities characterizing the connectivity of\nstates relative to the transition probabilities between them. Using this bound,\nwe show that, even when both the timescale of the rare event and the relative\naccuracy of the MC estimator are exponentially large in the number of states,\nLSTD maintains a fixed level of relative accuracy with a total number of\nobserved transitions of the Markov chain that is only \\emph{polynomially} large\nin the number of states.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Xiaoou Cheng",
            "Jonathan Weare"
        ],
        "published": "2024-05-27T20:18:20Z"
    },
    {
        "title": "The Economic Implications of Large Language Model Selection on Earnings\n  and Return on Investment: A Decision Theoretic Model",
        "link": "http://arxiv.org/abs/2405.17637v1",
        "abstract": "Selecting language models in business contexts requires a careful analysis of\nthe final financial benefits of the investment. However, the emphasis of\nacademia and industry analysis of LLM is solely on performance. This work\nintroduces a framework to evaluate LLMs, focusing on the earnings and return on\ninvestment aspects that should be taken into account in business decision\nmaking. We use a decision-theoretic approach to compare the financial impact of\ndifferent LLMs, considering variables such as the cost per token, the\nprobability of success in the specific task, and the gain and losses associated\nwith LLMs use. The study reveals how the superior accuracy of more expensive\nmodels can, under certain conditions, justify a greater investment through more\nsignificant earnings but not necessarily a larger RoI. This article provides a\nframework for companies looking to optimize their technology choices, ensuring\nthat investment in cutting-edge technology aligns with strategic financial\nobjectives. In addition, we discuss how changes in operational variables\ninfluence the economics of using LLMs, offering practical insights for\nenterprise settings, finding that the predicted gain and loss and the different\nprobabilities of success and failure are the variables that most impact the\nsensitivity of the models.",
        "subjects": [
            "cs.AI",
            "cs.CE",
            "I.2.m; K.6.1"
        ],
        "authors": [
            "Geraldo Xexo",
            "Filipe Braida",
            "Marcus Parreiras",
            "Paulo Xavier"
        ],
        "published": "2024-05-27T20:08:41Z"
    },
    {
        "title": "Single-Fiber Optical Frequency Domain Reflectometry Shape Sensing of\n  Continuum Manipulators with Planar Bending",
        "link": "http://arxiv.org/abs/2405.17636v1",
        "abstract": "To address the challenges associated with shape sensing of continuum\nmanipulators (CMs) using Fiber Bragg Grating (FBG) optical fibers, we feature a\nunique shape sensing assembly utilizing solely a single Optical Frequency\nDomain Reflectometry (OFDR) fiber attached to a flat nitinol wire (NiTi).\nIntegrating this easy-to-manufacture unique sensor with a long and soft CM with\n170 mm length, we performed different experiments to evaluate its shape\nreconstruction ability. Results demonstrate phenomenal shape reconstruction\naccuracy for both C-shape (< 2 mm tip error, < 1.2 mm shape error) and J-shape\n(< 3.4 mm tip error, < 2.3 mm shape error) experiments.",
        "subjects": [
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Mobina Tavangarifard",
            "Wendy Rodriguez Ovalle",
            "Farshid Alambeigi"
        ],
        "published": "2024-05-27T20:08:11Z"
    },
    {
        "title": "Enhancing Resiliency of Integrated Space-Air-Ground-Sea Networks with\n  Renewable Energies: A Use Case After the 2023 Trkiye Earthquake",
        "link": "http://arxiv.org/abs/2405.17635v1",
        "abstract": "Natural disasters can have catastrophic consequences, a poignant example is\nthe series of $7.7$ and $7.6$ magnitude earthquakes that devastated T\\\"urkiye\non February 6, 2023. To limit the damage, it is essential to maintain the\ncommunications infrastructure to ensure individuals impacted by the disaster\ncan receive critical information. The disastrous earthquakes in T\\\"urkiye have\nrevealed the importance of considering communications and energy solutions\ntogether to build resilient and sustainable infrastructure. Thus, this paper\nproposes an integrated space-air-ground-sea network architecture that utilizes\nvarious communications and energy-enabling technologies. This study aims to\ncontribute to the development of robust and sustainable disaster-response\nframeworks. In light of the T\\\"urkiye earthquakes, two methods for network\nmanagement are proposed: the first aims to ensure sustainability in the\npre-disaster phase and the second aims to maintain communications during the\nin-disaster phase. In these frameworks, communications technologies such as\nHigh Altitude Platform Station(s)(HAPS), which are among the key enablers to\nunlock the potential of 6G networks, and energy technologies such as Renewable\nEnergy Sources (RES), Battery Energy Storage Systems (BESSs), and Electric\nVehicles (EVs) have been used as the prominent technologies. By simulating a\ncase study, we demonstrate the performance of a proposed framework for\nproviding network resiliency. The paper concludes with potential challenges and\nfuture directions to achieve a disaster-resilient network architecture\nsolution.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Bilal Karaman",
            "Ilhan Basturk",
            "Sezai Taskin",
            "Ferdi Kara",
            "Engin Zeydan",
            "Halim Yanikomeroglu"
        ],
        "published": "2024-05-27T20:03:27Z"
    },
    {
        "title": "HEART-felt Narratives: Tracing Empathy and Narrative Style in Personal\n  Stories with LLMs",
        "link": "http://arxiv.org/abs/2405.17633v1",
        "abstract": "Empathy serves as a cornerstone in enabling prosocial behaviors, and can be\nevoked through sharing of personal experiences in stories. While empathy is\ninfluenced by narrative content, intuitively, people respond to the way a story\nis told as well, through narrative style. Yet the relationship between empathy\nand narrative style is not fully understood. In this work, we empirically\nexamine and quantify this relationship between style and empathy using LLMs and\nlarge-scale crowdsourcing studies. We introduce a novel, theory-based taxonomy,\nHEART (Human Empathy and Narrative Taxonomy) that delineates elements of\nnarrative style that can lead to empathy with the narrator of a story. We\nestablish the performance of LLMs in extracting narrative elements from HEART,\nshowing that prompting with our taxonomy leads to reasonable, human-level\nannotations beyond what prior lexicon-based methods can do. To show empirical\nuse of our taxonomy, we collect a dataset of empathy judgments of stories via a\nlarge-scale crowdsourcing study with N=2,624 participants. We show that\nnarrative elements extracted via LLMs, in particular, vividness of emotions and\nplot volume, can elucidate the pathways by which narrative style cultivates\nempathy towards personal stories. Our work suggests that such models can be\nused for narrative analyses that lead to human-centered social and behavioral\ninsights.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Jocelyn Shen",
            "Joel Mire",
            "Hae Won Park",
            "Cynthia Breazeal",
            "Maarten Sap"
        ],
        "published": "2024-05-27T20:00:38Z"
    },
    {
        "title": "BioDiscoveryAgent: An AI Agent for Designing Genetic Perturbation\n  Experiments",
        "link": "http://arxiv.org/abs/2405.17631v1",
        "abstract": "Agents based on large language models have shown great potential in\naccelerating scientific discovery by leveraging their rich background knowledge\nand reasoning capabilities. Here, we develop BioDiscoveryAgent, an agent that\ndesigns new experiments, reasons about their outcomes, and efficiently\nnavigates the hypothesis space to reach desired solutions. We demonstrate our\nagent on the problem of designing genetic perturbation experiments, where the\naim is to find a small subset out of many possible genes that, when perturbed,\nresult in a specific phenotype (e.g., cell growth). Utilizing its biological\nknowledge, BioDiscoveryAgent can uniquely design new experiments without the\nneed to train a machine learning model or explicitly design an acquisition\nfunction. Moreover, BioDiscoveryAgent achieves an average of 18% improvement in\ndetecting desired phenotypes across five datasets, compared to existing\nBayesian optimization baselines specifically trained for this task. Our\nevaluation includes one dataset that is unpublished, ensuring it is not part of\nthe language model's training data. Additionally, BioDiscoveryAgent predicts\ngene combinations to perturb twice as accurately as a random baseline, a task\nso far not explored in the context of closed-loop experiment design. The agent\nalso has access to tools for searching the biomedical literature, executing\ncode to analyze biological datasets, and prompting another agent to critically\nevaluate its predictions. Overall, BioDiscoveryAgent is interpretable at every\nstage, representing an accessible new paradigm in the computational design of\nbiological experiments with the potential to augment scientists' capabilities.",
        "subjects": [
            "cs.AI",
            "cs.CE",
            "cs.MA"
        ],
        "authors": [
            "Yusuf Roohani",
            "Jian Vora",
            "Qian Huang",
            "Zachary Steinhart",
            "Alexander Marson",
            "Percy Liang",
            "Jure Leskovec"
        ],
        "published": "2024-05-27T19:57:17Z"
    },
    {
        "title": "Lindenmayer graph languages, first-order theories and expanders",
        "link": "http://arxiv.org/abs/2405.17629v1",
        "abstract": "Combinatorial generation of expander families and Lindenmayer-style\ndevelopment models are both parallel in nature. Both can be handled within\nproposed parallel graph grammar formalism. Their first-order properties can\nthen be checked by encompassing the generated graph language into an\nappropriate automatic structure.",
        "subjects": [
            "cs.FL",
            "math.LO",
            "03D05 (Primary) 68Q42, 05C48, 92C15 (Secondary)",
            "F.4.1; F.4.2"
        ],
        "authors": [
            "Teodor Knapik"
        ],
        "published": "2024-05-27T19:52:11Z"
    },
    {
        "title": "Tensor Low-rank Approximation of Finite-horizon Value Functions",
        "link": "http://arxiv.org/abs/2405.17628v1",
        "abstract": "The goal of reinforcement learning is estimating a policy that maps states to\nactions and maximizes the cumulative reward of a Markov Decision Process (MDP).\nThis is oftentimes achieved by estimating first the optimal (reward) value\nfunction (VF) associated with each state-action pair. When the MDP has an\ninfinite horizon, the optimal VFs and policies are stationary under mild\nconditions. However, in finite-horizon MDPs, the VFs (hence, the policies) vary\nwith time. This poses a challenge since the number of VFs to estimate grows not\nonly with the size of the state-action space but also with the time horizon.\nThis paper proposes a non-parametric low-rank stochastic algorithm to\napproximate the VFs of finite-horizon MDPs. First, we represent the (unknown)\nVFs as a multi-dimensional array, or tensor, where time is one of the\ndimensions. Then, we use rewards sampled from the MDP to estimate the optimal\nVFs. More precisely, we use the (truncated) PARAFAC decomposition to design an\nonline low-rank algorithm that recovers the entries of the tensor of VFs. The\nsize of the low-rank PARAFAC model grows additively with respect to each of its\ndimensions, rendering our approach efficient, as demonstrated via numerical\nexperiments.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Sergio Rozada",
            "Antonio G. Marques"
        ],
        "published": "2024-05-27T19:52:00Z"
    },
    {
        "title": "Salutary Labeling with Zero Human Annotation",
        "link": "http://arxiv.org/abs/2405.17627v1",
        "abstract": "Active learning strategically selects informative unlabeled data points and\nqueries their ground truth labels for model training. The prevailing assumption\nunderlying this machine learning paradigm is that acquiring these ground truth\nlabels will optimally enhance model performance. However, this assumption may\nnot always hold true or maximize learning capacity, particularly considering\nthe costly labor annotations required for ground truth labels. In contrast to\ntraditional ground truth labeling, this paper proposes salutary labeling, which\nautomatically assigns the most beneficial labels to the most informative\nsamples without human annotation. Specifically, we utilize the influence\nfunction, a tool for estimating sample influence, to select newly added samples\nand assign their salutary labels by choosing the category that maximizes their\npositive influence. This process eliminates the need for human annotation.\nExtensive experiments conducted on nine benchmark datasets demonstrate the\nsuperior performance of our salutary labeling approach over traditional active\nlearning strategies. Additionally, we provide several in-depth explorations and\npractical applications of large language model (LLM) fine-tuning.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Wenxiao Xiao",
            "Hongfu Liu"
        ],
        "published": "2024-05-27T19:49:18Z"
    },
    {
        "title": "Matrix Low-Rank Approximation For Policy Gradient Methods",
        "link": "http://arxiv.org/abs/2405.17626v1",
        "abstract": "Estimating a policy that maps states to actions is a central problem in\nreinforcement learning. Traditionally, policies are inferred from the so called\nvalue functions (VFs), but exact VF computation suffers from the curse of\ndimensionality. Policy gradient (PG) methods bypass this by learning directly a\nparametric stochastic policy. Typically, the parameters of the policy are\nestimated using neural networks (NNs) tuned via stochastic gradient descent.\nHowever, finding adequate NN architectures can be challenging, and convergence\nissues are common as well. In this paper, we put forth low-rank matrix-based\nmodels to estimate efficiently the parameters of PG algorithms. We collect the\nparameters of the stochastic policy into a matrix, and then, we leverage\nmatrix-completion techniques to promote (enforce) low rank. We demonstrate via\nnumerical studies how low-rank matrix-based policy models reduce the\ncomputational and sample complexities relative to NN models, while achieving a\nsimilar aggregated reward.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Sergio Rozada",
            "Antonio G. Marques"
        ],
        "published": "2024-05-27T19:49:08Z"
    },
    {
        "title": "Matrix Low-Rank Trust Region Policy Optimization",
        "link": "http://arxiv.org/abs/2405.17625v1",
        "abstract": "Most methods in reinforcement learning use a Policy Gradient (PG) approach to\nlearn a parametric stochastic policy that maps states to actions. The standard\napproach is to implement such a mapping via a neural network (NN) whose\nparameters are optimized using stochastic gradient descent. However, PG methods\nare prone to large policy updates that can render learning inefficient. Trust\nregion algorithms, like Trust Region Policy Optimization (TRPO), constrain the\npolicy update step, ensuring monotonic improvements. This paper introduces\nlow-rank matrix-based models as an efficient alternative for estimating the\nparameters of TRPO algorithms. By gathering the stochastic policy's parameters\ninto a matrix and applying matrix-completion techniques, we promote and enforce\nlow rank. Our numerical studies demonstrate that low-rank matrix-based policy\nmodels effectively reduce both computational and sample complexities compared\nto NN models, while maintaining comparable aggregated rewards.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Sergio Rozada",
            "Antonio G. Marques"
        ],
        "published": "2024-05-27T19:46:31Z"
    },
    {
        "title": "Symmetric Reinforcement Learning Loss for Robust Learning on Diverse\n  Tasks and Model Scales",
        "link": "http://arxiv.org/abs/2405.17618v2",
        "abstract": "Reinforcement learning (RL) training is inherently unstable due to factors\nsuch as moving targets and high gradient variance. Reinforcement Learning from\nHuman Feedback (RLHF) and Reinforcement Learning from AI Feedback (RLAIF) can\nintroduce additional difficulty. Differing preferences can complicate the\nalignment process, and prediction errors in a trained reward model can become\nmore severe as the LLM generates unseen outputs. To enhance training\nrobustness, RL has adopted techniques from supervised learning, such as\nensembles and layer normalization. In this work, we improve the stability of RL\ntraining by adapting the reverse cross entropy (RCE) from supervised learning\nfor noisy data to define a symmetric RL loss. We demonstrate performance\nimprovements across various tasks and scales. We conduct experiments in\ndiscrete action tasks (Atari games) and continuous action space tasks (MuJoCo\nbenchmark and Box2D) using Symmetric A2C (SA2C) and Symmetric PPO (SPPO), with\nand without added noise with especially notable performance in SPPO across\ndifferent hyperparameters. Furthermore, we validate the benefits of the\nsymmetric RL loss when using SPPO for large language models through improved\nperformance in RLHF tasks, such as IMDB positive sentiment sentiment and TL;DR\nsummarization tasks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Ju-Seung Byun",
            "Andrew Perrault"
        ],
        "published": "2024-05-27T19:28:33Z"
    },
    {
        "title": "Design of a Rectangular Linear Microstrip Patch Antenna Array for 5G\n  Communication",
        "link": "http://arxiv.org/abs/2405.17616v1",
        "abstract": "This paper presents the design and characterization of a rectangular\nmicrostrip patch antenna array optimized for operation within the Ku-band\nfrequency range. The antenna array is impedance-matched to 50 Ohms and utilizes\na microstrip line feeding mechanism for excitation. The design maintains\ncompact dimensions, with the overall antenna occupying an area of 29.5x7 mm.\nThe antenna structure is modelled on an R03003 substrate material, featuring a\ndielectric constant of 3, a low-loss tangent of 0.0009, and a thickness of\n1.574 mm. The substrate is backed by a conducting ground plane, and the array\nconsists of six radiating patch elements positioned on top. Evaluation of the\ndesigned antenna array reveals a resonant frequency of 18GHz, with a -10 dB\nimpedance bandwidth extending over 700MHz. The antenna demonstrates a high gain\nof 7.51dBi, making it well-suited for applications in 5G and future\ncommunication systems. Its compact form factor, cost-effectiveness, and broad\nimpedance and radiation coverage further underscore its potential in these\ndomains.",
        "subjects": [
            "eess.SY",
            "cs.SY",
            "eess.SP",
            "physics.app-ph"
        ],
        "authors": [
            "Muhammad Asfar Saeed",
            "Augustine O. Nwajana"
        ],
        "published": "2024-05-27T19:25:55Z"
    },
    {
        "title": "Listenable Maps for Zero-Shot Audio Classifiers",
        "link": "http://arxiv.org/abs/2405.17615v1",
        "abstract": "Interpreting the decisions of deep learning models, including audio\nclassifiers, is crucial for ensuring the transparency and trustworthiness of\nthis technology. In this paper, we introduce LMAC-ZS (Listenable Maps for Audio\nClassifiers in the Zero-Shot context), which, to the best of our knowledge, is\nthe first decoder-based post-hoc interpretation method for explaining the\ndecisions of zero-shot audio classifiers. The proposed method utilizes a novel\nloss function that maximizes the faithfulness to the original similarity\nbetween a given text-and-audio pair. We provide an extensive evaluation using\nthe Contrastive Language-Audio Pretraining (CLAP) model to showcase that our\ninterpreter remains faithful to the decisions in a zero-shot classification\ncontext. Moreover, we qualitatively show that our method produces meaningful\nexplanations that correlate well with different text prompts.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS",
            "eess.SP"
        ],
        "authors": [
            "Francesco Paissan",
            "Luca Della Libera",
            "Mirco Ravanelli",
            "Cem Subakan"
        ],
        "published": "2024-05-27T19:25:42Z"
    },
    {
        "title": "A Framework for Multi-modal Learning: Jointly Modeling Inter- &\n  Intra-Modality Dependencies",
        "link": "http://arxiv.org/abs/2405.17613v1",
        "abstract": "Supervised multi-modal learning involves mapping multiple modalities to a\ntarget label. Previous studies in this field have concentrated on capturing in\nisolation either the inter-modality dependencies (the relationships between\ndifferent modalities and the label) or the intra-modality dependencies (the\nrelationships within a single modality and the label). We argue that these\nconventional approaches that rely solely on either inter- or intra-modality\ndependencies may not be optimal in general. We view the multi-modal learning\nproblem from the lens of generative models where we consider the target as a\nsource of multiple modalities and the interaction between them. Towards that\nend, we propose inter- & intra-modality modeling (I2M2) framework, which\ncaptures and integrates both the inter- and intra-modality dependencies,\nleading to more accurate predictions. We evaluate our approach using real-world\nhealthcare and vision-and-language datasets with state-of-the-art models,\ndemonstrating superior performance over traditional methods focusing only on\none type of modality dependency.",
        "subjects": [
            "cs.CV",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Divyam Madaan",
            "Taro Makino",
            "Sumit Chopra",
            "Kyunghyun Cho"
        ],
        "published": "2024-05-27T19:22:41Z"
    },
    {
        "title": "A note on the error analysis of data-driven closure models for large\n  eddy simulations of turbulence",
        "link": "http://arxiv.org/abs/2405.17612v2",
        "abstract": "In this work, we provide a mathematical formulation for error propagation in\nflow trajectory prediction using data-driven turbulence closure modeling. Under\nthe assumption that the predicted state of a large eddy simulation prediction\nmust be close to that of a subsampled direct numerical simulation, we retrieve\nan upper bound for the prediction error when utilizing a data-driven closure\nmodel. We also demonstrate that this error is significantly affected by the\ntime step size and the Jacobian which play a role in amplifying the initial\none-step error made by using the closure. Our analysis also shows that the\nerror propagates exponentially with rollout time and the upper bound of the\nsystem Jacobian which is itself influenced by the Jacobian of the closure\nformulation. These findings could enable the development of new regularization\ntechniques for ML models based on the identified error-bound terms, improving\ntheir robustness and reducing error propagation.",
        "subjects": [
            "physics.flu-dyn",
            "cs.LG",
            "physics.comp-ph"
        ],
        "authors": [
            "Dibyajyoti Chakraborty",
            "Shivam Barwey",
            "Hong Zhang",
            "Romit Maulik"
        ],
        "published": "2024-05-27T19:20:22Z"
    },
    {
        "title": "Explainable machine learning multi-label classification of Spanish legal\n  judgements",
        "link": "http://dx.doi.org/10.1016/j.jksuci.2022.10.015",
        "abstract": "Artificial Intelligence techniques such as Machine Learning (ML) have not\nbeen exploited to their maximum potential in the legal domain. This has been\npartially due to the insufficient explanations they provided about their\ndecisions. Automatic expert systems with explanatory capabilities can be\nspecially useful when legal practitioners search jurisprudence to gather\ncontextual knowledge for their cases. Therefore, we propose a hybrid system\nthat applies ML for multi-label classification of judgements (sentences) and\nvisual and natural language descriptions for explanation purposes, boosted by\nNatural Language Processing techniques and deep legal reasoning to identify the\nentities, such as the parties, involved. We are not aware of any prior work on\nautomatic multi-label classification of legal judgements also providing natural\nlanguage explanations to the end-users with comparable overall quality. Our\nsolution achieves over 85 % micro precision on a labelled data set annotated by\nlegal experts. This endorses its interest to relieve human experts from\nmonotonous labour-intensive legal classification tasks.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Francisco de Arriba-Prez",
            "Silvia Garca-Mndez",
            "Francisco J. Gonzlez-Castao",
            "Jaime Gonzlez-Gonzlez"
        ],
        "published": "2024-05-27T19:16:42Z"
    },
    {
        "title": "GarmentCodeData: A Dataset of 3D Made-to-Measure Garments With Sewing\n  Patterns",
        "link": "http://arxiv.org/abs/2405.17609v1",
        "abstract": "Recent research interest in the learning-based processing of garments, from\nvirtual fitting to generation and reconstruction, stumbles on a scarcity of\nhigh-quality public data in the domain. We contribute to resolving this need by\npresenting the first large-scale synthetic dataset of 3D made-to-measure\ngarments with sewing patterns, as well as its generation pipeline.\nGarmentCodeData contains 115,000 data points that cover a variety of designs in\nmany common garment categories: tops, shirts, dresses, jumpsuits, skirts,\npants, etc., fitted to a variety of body shapes sampled from a custom\nstatistical body model based on CAESAR, as well as a standard reference body\nshape, applying three different textile materials. To enable the creation of\ndatasets of such complexity, we introduce a set of algorithms for automatically\ntaking tailor's measures on sampled body shapes, sampling strategies for sewing\npattern design, and propose an automatic, open-source 3D garment draping\npipeline based on a fast XPBD simulator, while contributing several solutions\nfor collision resolution and drape correctness to enable scalability.\n  Dataset: http://hdl.handle.net/20.500.11850/673889",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "authors": [
            "Maria Korosteleva",
            "Timur Levent Kesdogan",
            "Fabian Kemper",
            "Stephan Wenninger",
            "Jasmin Koller",
            "Yuhan Zhang",
            "Mario Botsch",
            "Olga Sorkine-Hornung"
        ],
        "published": "2024-05-27T19:14:46Z"
    },
    {
        "title": "Advancing Cultural Inclusivity: Optimizing Embedding Spaces for Balanced\n  Music Recommendations",
        "link": "http://arxiv.org/abs/2405.17607v1",
        "abstract": "Popularity bias in music recommendation systems -- where artists and tracks\nwith the highest listen counts are recommended more often -- can also propagate\nbiases along demographic and cultural axes. In this work, we identify these\nbiases in recommendations for artists from underrepresented cultural groups in\nprototype-based matrix factorization methods. Unlike traditional matrix\nfactorization methods, prototype-based approaches are interpretable. This\nallows us to directly link the observed bias in recommendations for minority\nartists (the effect) to specific properties of the embedding space (the cause).\nWe mitigate popularity bias in music recommendation through capturing both\nusers' and songs' cultural nuances in the embedding space. To address these\nchallenges while maintaining recommendation quality, we propose two novel\nenhancements to the embedding space: i) we propose an approach to filter-out\nthe irrelevant prototypes used to represent each user and item to improve\ngeneralizability, and ii) we introduce regularization techniques to reinforce a\nmore uniform distribution of prototypes within the embedding space. Our results\ndemonstrate significant improvements in reducing popularity bias and enhancing\ndemographic and cultural fairness in music recommendations while achieving\ncompetitive -- if not better -- overall performance.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Armin Moradi",
            "Nicola Neophytou",
            "Golnoosh Farnadi"
        ],
        "published": "2024-05-27T19:12:53Z"
    },
    {
        "title": "A Patient-Specific Framework for Autonomous Spinal Fixation via a\n  Steerable Drilling Robot",
        "link": "http://arxiv.org/abs/2405.17606v1",
        "abstract": "In this paper, with the goal of enhancing the minimally invasive spinal\nfixation procedure in osteoporotic patients, we propose a first-of-its-kind\nimage-guided robotic framework for performing an autonomous and\npatient-specific procedure using a unique concentric tube steerable drilling\nrobot (CT-SDR). Particularly, leveraging a CT-SDR, we introduce the concept of\nJ-shape drilling based on a pre-operative trajectory planned in CT scan of a\npatient followed by appropriate calibration, registration, and navigation steps\nto safely execute this trajectory in real-time using our unique robotic setup.\nTo thoroughly evaluate the performance of our framework, we performed several\nexperiments on two different vertebral phantoms designed based on CT scan of\nreal patients.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Susheela Sharma",
            "Sarah Go",
            "Zeynep Yakay",
            "Yash Kulkarni",
            "Siddhartha Kapuria",
            "Jordan P. Amadio",
            "Reza Rajebi",
            "Mohsen Khadem",
            "Nassir Navab",
            "Farshid Alambeigi"
        ],
        "published": "2024-05-27T19:12:42Z"
    },
    {
        "title": "LoRA-XS: Low-Rank Adaptation with Extremely Small Number of Parameters",
        "link": "http://arxiv.org/abs/2405.17604v1",
        "abstract": "The recent trend in scaling language models has led to a growing demand for\nparameter-efficient tuning (PEFT) methods such as LoRA (Low-Rank Adaptation).\nLoRA consistently matches or surpasses the full fine-tuning baseline with fewer\nparameters. However, handling numerous task-specific or user-specific LoRA\nmodules on top of a base model still presents significant storage challenges.\nTo address this, we introduce LoRA-XS (Low-Rank Adaptation with eXtremely Small\nnumber of parameters), a novel approach leveraging Singular Value Decomposition\n(SVD) for parameter-efficient fine-tuning. LoRA-XS introduces a small r x r\nweight matrix between frozen LoRA matrices, which are constructed by SVD of the\noriginal weight matrix. Training only r x r weight matrices ensures\nindependence from model dimensions, enabling more parameter-efficient\nfine-tuning, especially for larger models. LoRA-XS achieves a remarkable\nreduction of trainable parameters by over 100x in 7B models compared to LoRA.\nOur benchmarking across various scales, including GLUE, GSM8k, and MATH\nbenchmarks, shows that our approach outperforms LoRA and recent\nstate-of-the-art approaches like VeRA in terms of parameter efficiency while\nmaintaining competitive performance.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Klaudia Baazy",
            "Mohammadreza Banaei",
            "Karl Aberer",
            "Jacek Tabor"
        ],
        "published": "2024-05-27T19:07:13Z"
    },
    {
        "title": "Towards Biomechanical Evaluation of a Transformative Additively\n  Manufactured Flexible Pedicle Screw for Robotic Spinal Fixation",
        "link": "http://arxiv.org/abs/2405.17603v1",
        "abstract": "Vital for spinal fracture treatment, pedicle screw fixation is the gold\nstandard for spinal fixation procedures. Nevertheless, due to the screw pullout\nand loosening issues, this surgery often fails to be effective for patients\nsuffering from osteoporosis (i.e., having low bone mineral density). These\nfailures can be attributed to the rigidity of existing drilling instruments and\npedicle screws forcing clinicians to place these implants into the osteoporotic\nregions of the vertebral body. To address this critical issue, we have\ndeveloped a steerable drilling robotic system and evaluated its performance in\ndrilling various J- and U-shape trajectories. Complementary to this robotic\nsystem, in this paper, we propose design, additive manufacturing, and\nbiomechanical evaluation of a transformative flexible pedicle screw (FPS) that\ncan be placed in pre-drilled straight and curved trajectories. To evaluate the\nperformance of the proposed flexible implant, we designed and fabricated two\ndifferent types of FPSs using the direct metal laser sintering (DMLS) process.\nUtilizing our unique experimental setup and ASTM standards, we then performed\nvarious pullout experiments on these FPSs to evaluate and analyze their\nbiomechanical performance implanted in straight trajectories.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Yash Kulkarni",
            "Susheela Sharma",
            "Jordan P. Amadio",
            "Farshid Alambeigi"
        ],
        "published": "2024-05-27T19:02:24Z"
    },
    {
        "title": "Augmenting Textual Generation via Topology Aware Retrieval",
        "link": "http://arxiv.org/abs/2405.17602v1",
        "abstract": "Despite the impressive advancements of Large Language Models (LLMs) in\ngenerating text, they are often limited by the knowledge contained in the input\nand prone to producing inaccurate or hallucinated content. To tackle these\nissues, Retrieval-augmented Generation (RAG) is employed as an effective\nstrategy to enhance the available knowledge base and anchor the responses in\nreality by pulling additional texts from external databases. In real-world\napplications, texts are often linked through entities within a graph, such as\ncitations in academic papers or comments in social networks. This paper\nexploits these topological relationships to guide the retrieval process in RAG.\nSpecifically, we explore two kinds of topological connections: proximity-based,\nfocusing on closely connected nodes, and role-based, which looks at nodes\nsharing similar subgraph structures. Our empirical research confirms their\nrelevance to text relationships, leading us to develop a Topology-aware\nRetrieval-augmented Generation framework. This framework includes a retrieval\nmodule that selects texts based on their topological relationships and an\naggregation module that integrates these texts into prompts to stimulate LLMs\nfor text generation. We have curated established text-attributed networks and\nconducted comprehensive experiments to validate the effectiveness of this\nframework, demonstrating its potential to enhance RAG with topological\nawareness.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Yu Wang",
            "Nedim Lipka",
            "Ruiyi Zhang",
            "Alexa Siu",
            "Yuying Zhao",
            "Bo Ni",
            "Xin Wang",
            "Ryan Rossi",
            "Tyler Derr"
        ],
        "published": "2024-05-27T19:02:18Z"
    },
    {
        "title": "GDSW preconditioners for composite Discontinuous Galerkin\n  discretizations of multicompartment reaction-diffusion problems",
        "link": "http://arxiv.org/abs/2405.17601v1",
        "abstract": "The aim of the present work is to design, analyze theoretically, and test\nnumerically, a generalized Dryja-Smith-Widlund (GDSW) preconditioner for\ncomposite Discontinuous Galerkin discretizations of multicompartment parabolic\nreaction-diffusion equations, where the solution can exhibit natural\ndiscontinuities across the domain. We prove that the resulting preconditioned\noperator for the solution of the discrete system arising at each time step\nconverges with a scalable and quasi-optimal upper bound for the condition\nnumber. The GDSW preconditioner is then applied to the EMI (Extracellular -\nMembrane - Intracellular) reaction-diffusion system, recently proposed to model\nmicroscopically the spatiotemporal evolution of cardiac bioelectrical\npotentials. Numerical tests validate the scalability and quasi-optimality of\nthe EMI-GDSW preconditioner, and investigate its robustness with respect to the\ntime step size as well as jumps in the diffusion coefficients.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "65N55, 65M55, 65F10, 92C30"
        ],
        "authors": [
            "Ngoc Mai Monica Huynh",
            "Luca Franco Pavarino",
            "Simone Scacchi"
        ],
        "published": "2024-05-27T19:01:05Z"
    },
    {
        "title": "Spatial Spinal Fixation: A Transformative Approach Using a Unique\n  Robot-Assisted Steerable Drilling System and Flexible Pedicle Screw",
        "link": "http://arxiv.org/abs/2405.17600v1",
        "abstract": "Spinal fixation procedures are currently limited by the rigidity of the\nexisting instruments and pedicle screws leading to fixation failures and rigid\npedicle screw pull out. Leveraging our recently developed Concentric Tube\nSteerable Drilling Robot (CT-SDR) in integration with a robotic manipulator, to\naddress the aforementioned issue, here we introduce the transformative concept\nof Spatial Spinal Fixation (SSF) using a unique Flexible Pedicle Screw (FPS).\nThe proposed SSF procedure enables planar and out-of-plane placement of the FPS\nthroughout the full volume of the vertebral body. In other words, not only does\nour fixation system provide the option of drilling in-plane and out-of-plane\ntrajectories, it also enables implanting the FPS inside linear (represented by\nan I-shape) and/or non-linear (represented by J-shape) trajectories. To\nthoroughly evaluate the functionality of our proposed robotic system and the\nSSF procedure, we have performed various experiments by drilling different I-J\nand J-J drilling trajectory pairs into our custom-designed L3 vertebral\nphantoms and analyzed the accuracy of the procedure using various metrics.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Susheela Sharma",
            "Yash Kulkarni",
            "Sarah Go",
            "Jeff Bonyun",
            "Jordan P. Amadio",
            "Reza Rajebi",
            "Maryam Tilton",
            "Mohsen Khadem",
            "Farshid Alambeigi"
        ],
        "published": "2024-05-27T19:01:03Z"
    },
    {
        "title": "A Mobility Equity Metric for Multi-Modal Intelligent Transportation\n  Systems",
        "link": "http://arxiv.org/abs/2405.17599v1",
        "abstract": "In this paper, we introduce a metric to evaluate the equity in mobility and a\nrouting framework to enhance the metric within multi-modal intelligent\ntransportation systems. The mobility equity metric (MEM) simultaneously\naccounts for service accessibility and transportation costs to quantify the\nequity and fairness in a transportation network. Finally, we develop a system\nplanner integrated with MEM that aims to distribute travel demand for the\ntransportation network, resulting in a socially optimal mobility system. Our\nframework results in a transportation network that is efficient in terms of\ntravel time, improves accessibility, and ensures equity in transportation.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Heeseung Bang",
            "Aditya Dave",
            "Filippos N. Tzortzoglou",
            "Andreas A. Malikopoulos"
        ],
        "published": "2024-05-27T19:00:57Z"
    },
    {
        "title": "GOI: Find 3D Gaussians of Interest with an Optimizable Open-vocabulary\n  Semantic-space Hyperplane",
        "link": "http://arxiv.org/abs/2405.17596v1",
        "abstract": "3D open-vocabulary scene understanding, crucial for advancing augmented\nreality and robotic applications, involves interpreting and locating specific\nregions within a 3D space as directed by natural language instructions. To this\nend, we introduce GOI, a framework that integrates semantic features from 2D\nvision-language foundation models into 3D Gaussian Splatting (3DGS) and\nidentifies 3D Gaussians of Interest using an Optimizable Semantic-space\nHyperplane. Our approach includes an efficient compression method that utilizes\nscene priors to condense noisy high-dimensional semantic features into compact\nlow-dimensional vectors, which are subsequently embedded in 3DGS. During the\nopen-vocabulary querying process, we adopt a distinct approach compared to\nexisting methods, which depend on a manually set fixed empirical threshold to\nselect regions based on their semantic feature distance to the query text\nembedding. This traditional approach often lacks universal accuracy, leading to\nchallenges in precisely identifying specific target areas. Instead, our method\ntreats the feature selection process as a hyperplane division within the\nfeature space, retaining only those features that are highly relevant to the\nquery. We leverage off-the-shelf 2D Referring Expression Segmentation (RES)\nmodels to fine-tune the semantic-space hyperplane, enabling a more precise\ndistinction between target regions and others. This fine-tuning substantially\nimproves the accuracy of open-vocabulary queries, ensuring the precise\nlocalization of pertinent 3D Gaussians. Extensive experiments demonstrate GOI's\nsuperiority over previous state-of-the-art methods. Our project page is\navailable at https://goi-hyperplane.github.io/ .",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yansong Qu",
            "Shaohui Dai",
            "Xinyang Li",
            "Jianghang Lin",
            "Liujuan Cao",
            "Shengchuan Zhang",
            "Rongrong Ji"
        ],
        "published": "2024-05-27T18:57:18Z"
    },
    {
        "title": "Element-Free Probability Distributions and Random Partitions",
        "link": "http://arxiv.org/abs/2405.17595v1",
        "abstract": "An \"element-free\" probability distribution is what remains of a probability\ndistribution after we forget the elements to which the probabilities were\nassigned. These objects naturally arise in Bayesian statistics, in situations\nwhere elements are used as labels and their specific identity is not important.\n  This paper develops the structural theory of element-free distributions,\nusing multisets and category theory. We give operations for moving between\nelement-free and ordinary distributions, and we show that these operations\ncommute with multinomial sampling. We then exploit this theory to prove two\nrepresentation theorems. These theorems show that element-free distributions\nprovide a natural representation for key random structures in Bayesian\nnonparametric clustering: exchangeable random partitions, and random\ndistributions parametrized by a base measure.",
        "subjects": [
            "cs.LO",
            "math.CT",
            "math.PR",
            "math.ST",
            "stat.TH"
        ],
        "authors": [
            "Victor Blanchi",
            "Hugo Paquet"
        ],
        "published": "2024-05-27T18:55:52Z"
    },
    {
        "title": "Towards Achieving Cooperation Compliance of Human Drivers in Mixed\n  Traffic",
        "link": "http://arxiv.org/abs/2405.17594v1",
        "abstract": "We consider a mixed-traffic environment in transportation systems, where\nConnected and Automated Vehicles (CAVs) coexist with potentially\nnon-cooperative Human-Driven Vehicles (HDVs). We develop a cooperation\ncompliance control framework to incentivize HDVs to align their behavior with\nsocially optimal objectives using a ``refundable toll'' scheme so as to achieve\na desired compliance probability for all non-compliant HDVs through a feedback\ncontrol mechanism combining global with local (individual) components. We apply\nthis scheme to the lane-changing problem, where a ``Social Planner'' provides\nreferences to the HDVs, measures their state errors, and induces cooperation\ncompliance for safe lane-changing through a refundable toll approach.\nSimulation results are included to show the effectiveness of our cooperation\ncompliance controller in terms of improved compliance and lane-changing\nmaneuver safety and efficiency when non-cooperative HDVs are present.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Anni Li",
            "Christos G. Cassandras"
        ],
        "published": "2024-05-27T18:55:09Z"
    },
    {
        "title": "Optimizing Layout of Recursive Datatypes with Marmoset",
        "link": "http://arxiv.org/abs/2405.17590v1",
        "abstract": "While programmers know that the low-level memory representation of data\nstructures can have significant effects on performance, compiler support to\noptimize the layout of those structures is an under-explored field. Prior work\nhas optimized the layout of individual, non-recursive structures without\nconsidering how collections of those objects in linked or recursive data\nstructures are laid out. This work introduces Marmoset, a compiler that\noptimizes the layouts of algebraic datatypes, with a special focus on producing\nhighly optimized, packed data layouts where recursive structures can be\ntraversed with minimal pointer chasing. Marmoset performs an analysis of how a\nrecursive ADT is used across functions to choose a global layout that promotes\nsimple, strided access for that ADT in memory. It does so by building and\nsolving a constraint system to minimize an abstract cost model, yielding a\npredicted efficient layout for the ADT. Marmoset then builds on top of Gibbon,\na prior compiler for packed, mostly-serial representations, to synthesize\noptimized ADTs. We show experimentally that Marmoset is able to choose optimal\nlayouts across a series of microbenchmarks and case studies, outperforming both\nGibbons baseline approach, as well as MLton, a Standard ML compiler that uses\ntraditional pointer-heavy representations.",
        "subjects": [
            "cs.PL",
            "cs.PF"
        ],
        "authors": [
            "Vidush Singhal",
            "Chaitanya Koparkar",
            "Joseph Zullo",
            "Artem Pelenitsyn",
            "Michael Vollmer",
            "Mike Rainey",
            "Ryan Newton",
            "Milind Kulkarni"
        ],
        "published": "2024-05-27T18:48:06Z"
    },
    {
        "title": "RAGSys: Item-Cold-Start Recommender as RAG System",
        "link": "http://arxiv.org/abs/2405.17587v1",
        "abstract": "Large Language Models (LLM) hold immense promise for real-world applications,\nbut their generic knowledge often falls short of domain-specific needs.\nFine-tuning, a common approach, can suffer from catastrophic forgetting and\nhinder generalizability. In-Context Learning (ICL) offers an alternative, which\ncan leverage Retrieval-Augmented Generation (RAG) to provide LLMs with relevant\ndemonstrations for few-shot learning tasks. This paper explores the desired\nqualities of a demonstration retrieval system for ICL. We argue that ICL\nretrieval in this context resembles item-cold-start recommender systems,\nprioritizing discovery and maximizing information gain over strict relevance.\nWe propose a novel evaluation method that measures the LLM's subsequent\nperformance on NLP tasks, eliminating the need for subjective diversity scores.\nOur findings demonstrate the critical role of diversity and quality bias in\nretrieved demonstrations for effective ICL, and highlight the potential of\nrecommender system techniques in this domain.",
        "subjects": [
            "cs.IR",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Emile Contal",
            "Garrin McGoldrick"
        ],
        "published": "2024-05-27T18:40:49Z"
    },
    {
        "title": "Understanding Forgetting in Continual Learning with Linear Regression",
        "link": "http://arxiv.org/abs/2405.17583v1",
        "abstract": "Continual learning, focused on sequentially learning multiple tasks, has\ngained significant attention recently. Despite the tremendous progress made in\nthe past, the theoretical understanding, especially factors contributing to\ncatastrophic forgetting, remains relatively unexplored. In this paper, we\nprovide a general theoretical analysis of forgetting in the linear regression\nmodel via Stochastic Gradient Descent (SGD) applicable to both\nunderparameterized and overparameterized regimes. Our theoretical framework\nreveals some interesting insights into the intricate relationship between task\nsequence and algorithmic parameters, an aspect not fully captured in previous\nstudies due to their restrictive assumptions. Specifically, we demonstrate\nthat, given a sufficiently large data size, the arrangement of tasks in a\nsequence, where tasks with larger eigenvalues in their population data\ncovariance matrices are trained later, tends to result in increased forgetting.\nAdditionally, our findings highlight that an appropriate choice of step size\nwill help mitigate forgetting in both underparameterized and overparameterized\nsettings. To validate our theoretical analysis, we conducted simulation\nexperiments on both linear regression models and Deep Neural Networks (DNNs).\nResults from these simulations substantiate our theoretical findings.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Meng Ding",
            "Kaiyi Ji",
            "Di Wang",
            "Jinhui Xu"
        ],
        "published": "2024-05-27T18:33:37Z"
    },
    {
        "title": "Building a temperature forecasting model for the city with the\n  regression neural network (RNN)",
        "link": "http://dx.doi.org/10.5281/zenodo.6190227",
        "abstract": "In recent years, a study by environmental organizations in the world and\nVietnam shows that weather change is quite complex. global warming has become a\nserious problem in the modern world, which is a concern for scientists. last\ncentury, it was difficult to forecast the weather due to missing weather\nmonitoring stations and technological limitations. this made it hard to collect\ndata for building predictive models to make accurate simulations. in Vietnam,\nresearch on weather forecast models is a recent development, having only begun\naround 2000. along with advancements in computer science, mathematical models\nare being built and applied with machine learning techniques to create more\naccurate and reliable predictive models. this article will summarize the\nresearch and solutions for applying recurrent neural networks to forecast urban\ntemperatures.",
        "subjects": [
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Nguyen Phuc Tran",
            "Duy Thanh Tran",
            "Thi Thuy Nga Duong"
        ],
        "published": "2024-05-27T18:32:36Z"
    },
    {
        "title": "Mixed Dynamics In Linear Networks: Unifying the Lazy and Active Regimes",
        "link": "http://arxiv.org/abs/2405.17580v1",
        "abstract": "The training dynamics of linear networks are well studied in two distinct\nsetups: the lazy regime and balanced/active regime, depending on the\ninitialization and width of the network. We provide a surprisingly simple\nunyfing formula for the evolution of the learned matrix that contains as\nspecial cases both lazy and balanced regimes but also a mixed regime in between\nthe two. In the mixed regime, a part of the network is lazy while the other is\nbalanced. More precisely the network is lazy along singular values that are\nbelow a certain threshold and balanced along those that are above the same\nthreshold. At initialization, all singular values are lazy, allowing for the\nnetwork to align itself with the task, so that later in time, when some of the\nsingular value cross the threshold and become active they will converge rapidly\n(convergence in the balanced regime is notoriously difficult in the absence of\nalignment). The mixed regime is the `best of both worlds': it converges from\nany random initialization (in contrast to balanced dynamics which require\nspecial initialization), and has a low rank bias (absent in the lazy dynamics).\nThis allows us to prove an almost complete phase diagram of training behavior\nas a function of the variance at initialization and the width, for a MSE\ntraining task.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Zhenfeng Tu",
            "Santiago Aranguri",
            "Arthur Jacot"
        ],
        "published": "2024-05-27T18:29:23Z"
    },
    {
        "title": "Harnessing Natural Oscillations for High-Speed, Efficient Asymmetrical\n  Locomotion in Quadrupedal Robots",
        "link": "http://arxiv.org/abs/2405.17579v1",
        "abstract": "This study explores the dynamics of asymmetrical bounding gaits in\nquadrupedal robots, focusing on the integration of torso pitching and hip\nmotion to enhance speed and stability. Traditional control strategies often\nenforce a fixed posture, minimizing natural body movements to simplify the\ncontrol problem. However, this approach may overlook the inherent dynamical\nadvantages found in natural locomotion. By considering the robot as two\ninterconnected segments, we concentrate on stance leg motion while allowing\npassive torso oscillation, drawing inspiration from natural dynamics and\nunderactuated robotics principles. Our control scheme employs Linear Inverted\nPendulum (LIP) and Spring-Loaded Inverted Pendulum (SLIP) models to govern\nfront and rear leg movements independently. This approach has been validated\nthrough extensive simulations and hardware experiments, demonstrating\nsuccessful high-speed locomotion with top speeds nearing 4 m/s and reduced\nground reaction forces, indicating a more efficient gait. Furthermore, unlike\nconventional methods, our strategy leverages natural torso oscillations to aid\nleg circulation and stride length, aligning robot dynamics more closely with\nbiological counterparts. Our findings suggest that embracing the natural\ndynamics of quadrupedal movement, particularly in asymmetrical gaits like\nbounding, can lead to more stable, efficient, and high-speed robotic\nlocomotion. This investigation lays the groundwork for future studies on\nversatile and dynamic quadrupedal gaits and their potential applications in\nscenarios demanding rapid and effective locomotion.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Jing Cheng",
            "Yasser G. Alqaham",
            "Zhenyu Gan"
        ],
        "published": "2024-05-27T18:28:22Z"
    },
    {
        "title": "Container pre-marshalling problem minimizing CV@R under uncertainty of\n  ship arrival times",
        "link": "http://arxiv.org/abs/2405.17576v1",
        "abstract": "This paper is concerned with the container pre-marshalling problem, which\ninvolves relocating containers in the storage area so that they can be\nefficiently loaded onto ships without reshuffles. In reality, however, ship\narrival times are affected by various external factors, which can cause the\norder of container retrieval to be different from the initial plan. To\nrepresent such uncertainty, we generate multiple scenarios from a multivariate\nprobability distribution of ship arrival times. We derive a mixed-integer\nlinear optimization model to find an optimal container layout such that the\nconditional value-at-risk is minimized for the number of misplaced containers\nresponsible for reshuffles. Moreover, we devise an exact algorithm based on the\ncutting-plane method to handle large-scale problems. Numerical experiments\nusing synthetic datasets demonstrate that our method can produce high-quality\ncontainer layouts compared with the conventional robust optimization model.\nAdditionally, our algorithm can speed up the computation of solving large-scale\nproblems.",
        "subjects": [
            "math.OC",
            "cs.AI"
        ],
        "authors": [
            "Daiki Ikuma",
            "Shunnosuke Ikeda",
            "Noriyoshi Sukegawa",
            "Yuichi Takano"
        ],
        "published": "2024-05-27T18:19:09Z"
    },
    {
        "title": "Interpretable Prognostics with Concept Bottleneck Models",
        "link": "http://arxiv.org/abs/2405.17575v1",
        "abstract": "Deep learning approaches have recently been extensively explored for the\nprognostics of industrial assets. However, they still suffer from a lack of\ninterpretability, which hinders their adoption in safety-critical applications.\nTo improve their trustworthiness, explainable AI (XAI) techniques have been\napplied in prognostics, primarily to quantify the importance of input variables\nfor predicting the remaining useful life (RUL) using post-hoc attribution\nmethods. In this work, we propose the application of Concept Bottleneck Models\n(CBMs), a family of inherently interpretable neural network architectures based\non concept explanations, to the task of RUL prediction. Unlike attribution\nmethods, which explain decisions in terms of low-level input features, concepts\nrepresent high-level information that is easily understandable by users.\nMoreover, once verified in actual applications, CBMs enable domain experts to\nintervene on the concept activations at test-time. We propose using the\ndifferent degradation modes of an asset as intermediate concepts. Our case\nstudies on the New Commercial Modular AeroPropulsion System Simulation\n(N-CMAPSS) aircraft engine dataset for RUL prediction demonstrate that the\nperformance of CBMs can be on par or superior to black-box models, while being\nmore interpretable, even when the available labeled concepts are limited. Code\navailable at\n\\href{https://github.com/EPFL-IMOS/concept-prognostics/}{\\url{github.com/EPFL-IMOS/concept-prognostics/}}.",
        "subjects": [
            "cs.LG",
            "eess.SP",
            "stat.ML"
        ],
        "authors": [
            "Florent Forest",
            "Katharina Rombach",
            "Olga Fink"
        ],
        "published": "2024-05-27T18:15:40Z"
    },
    {
        "title": "Hamiltonian Mechanics of Feature Learning: Bottleneck Structure in Leaky\n  ResNets",
        "link": "http://arxiv.org/abs/2405.17573v1",
        "abstract": "We study Leaky ResNets, which interpolate between ResNets ($\\tilde{L}=0$) and\nFully-Connected nets ($\\tilde{L}\\to\\infty$) depending on an 'effective depth'\nhyper-parameter $\\tilde{L}$. In the infinite depth limit, we study\n'representation geodesics' $A_{p}$: continuous paths in representation space\n(similar to NeuralODEs) from input $p=0$ to output $p=1$ that minimize the\nparameter norm of the network. We give a Lagrangian and Hamiltonian\nreformulation, which highlight the importance of two terms: a kinetic energy\nwhich favors small layer derivatives $\\partial_{p}A_{p}$ and a potential energy\nthat favors low-dimensional representations, as measured by the 'Cost of\nIdentity'. The balance between these two forces offers an intuitive\nunderstanding of feature learning in ResNets. We leverage this intuition to\nexplain the emergence of a bottleneck structure, as observed in previous work:\nfor large $\\tilde{L}$ the potential energy dominates and leads to a separation\nof timescales, where the representation jumps rapidly from the high dimensional\ninputs to a low-dimensional representation, move slowly inside the space of\nlow-dimensional representations, before jumping back to the potentially\nhigh-dimensional outputs. Inspired by this phenomenon, we train with an\nadaptive layer step-size to adapt to the separation of timescales.",
        "subjects": [
            "stat.ML",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Arthur Jacot",
            "Alexandre Kaiser"
        ],
        "published": "2024-05-27T18:15:05Z"
    },
    {
        "title": "Bluesky: Network Topology, Polarisation, and Algorithmic Curation",
        "link": "http://arxiv.org/abs/2405.17571v1",
        "abstract": "Bluesky is a nascent ``Twitter-like'' and decentralized social media network\nwith novel features and unprecedented data access. This paper provides a\ncharacterization of the network, studying the political leaning, polarization,\nnetwork structure, and algorithmic curation mechanisms of five million users.\nThe dataset spans from the website's first release in February of 2023. Users\nof the new social media site are predominantly left-center leaning and share\nlittle to no links associated with questionable sources. In contrast to the\nhomogeneous political stance, we find significant issues-based divergence by\nstudying opinions related to the Israel-Palestine conflict. Two clear\nhomophilic clusters emerge: Pro-Palestinian voices make up the plurality of\nmessages related to the conflict and the proportion has increased with a\nlessening of interest. We investigate multiple layers of the multi-scale\nBluesky network based on replies, likes, reposts, and follows, highlighting\ndifferences and similarities between the layers. We differentiate between\npersistent and non-persistent interactions and measure metrics of network\ntopology over time. All networks are heavy-tailed, clustered, and connected by\nshort paths. We showcase all feeds - algorithmic content recommenders - created\nfor and by users. A large number of custom feeds have been created but their\nuptake by users is limited. Multiple popular feeds aim to provide similar feeds\nthat are neither topical nor chronological. We conclude by claiming that\nBluesky - for all its novel features - is very similar in terms of its network\nstructure to existing and larger social media sites and provides unprecedented\nresearch opportunities for social scientists, network scientists, and political\nscientists alike.",
        "subjects": [
            "cs.SI"
        ],
        "authors": [
            "Dorian Quelle",
            "Alexandre Bovet"
        ],
        "published": "2024-05-27T18:10:55Z"
    },
    {
        "title": "Discriminant audio properties in deep learning based respiratory\n  insufficiency detection in Brazilian Portuguese",
        "link": "http://dx.doi.org/10.1007/978-3-031-34344-5_32",
        "abstract": "This work investigates Artificial Intelligence (AI) systems that detect\nrespiratory insufficiency (RI) by analyzing speech audios, thus treating speech\nas a RI biomarker. Previous works collected RI data (P1) from COVID-19 patients\nduring the first phase of the pandemic and trained modern AI models, such as\nCNNs and Transformers, which achieved $96.5\\%$ accuracy, showing the\nfeasibility of RI detection via AI. Here, we collect RI patient data (P2) with\nseveral causes besides COVID-19, aiming at extending AI-based RI detection. We\nalso collected control data from hospital patients without RI. We show that the\nconsidered models, when trained on P1, do not generalize to P2, indicating that\nCOVID-19 RI has features that may not be found in all RI types.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Marcelo Matheus Gauy",
            "Larissa Cristina Berti",
            "Arnaldo Cndido Jr",
            "Augusto Camargo Neto",
            "Alfredo Goldman",
            "Anna Sara Shafferman Levin",
            "Marcus Martins",
            "Beatriz Raposo de Medeiros",
            "Marcelo Queiroz",
            "Ester Cerdeira Sabino",
            "Flaviane Romani Fernandes Svartman",
            "Marcelo Finger"
        ],
        "published": "2024-05-27T18:04:49Z"
    },
    {
        "title": "ExtremeMETA: High-speed Lightweight Image Segmentation Model by\n  Remodeling Multi-channel Metamaterial Imagers",
        "link": "http://arxiv.org/abs/2405.17568v1",
        "abstract": "Deep neural networks (DNNs) have heavily relied on traditional computational\nunits like CPUs and GPUs. However, this conventional approach brings\nsignificant computational burdens, latency issues, and high power consumption,\nlimiting their effectiveness. This has sparked the need for lightweight\nnetworks like ExtremeC3Net. On the other hand, there have been notable\nadvancements in optical computational units, particularly with metamaterials,\noffering the exciting prospect of energy-efficient neural networks operating at\nthe speed of light. Yet, the digital design of metamaterial neural networks\n(MNNs) faces challenges such as precision, noise, and bandwidth, limiting their\napplication to intuitive tasks and low-resolution images. In this paper, we\npropose a large kernel lightweight segmentation model, ExtremeMETA. Based on\nthe ExtremeC3Net, the ExtremeMETA maximizes the ability of the first\nconvolution layer by exploring a larger convolution kernel and multiple\nprocessing paths. With the proposed large kernel convolution model, we extend\nthe optic neural network application boundary to the segmentation task. To\nfurther lighten the computation burden of the digital processing part, a set of\nmodel compression methods is applied to improve model efficiency in the\ninference stage. The experimental results on three publicly available datasets\ndemonstrate that the optimized efficient design improved segmentation\nperformance from 92.45 to 95.97 on mIoU while reducing computational FLOPs from\n461.07 MMacs to 166.03 MMacs. The proposed the large kernel lightweight model\nExtremeMETA showcases the hybrid design's ability on complex tasks.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Quan Liu",
            "Brandon T. Swartz",
            "Ivan Kravchenko",
            "Jason G. Valentine",
            "Yuankai Huo"
        ],
        "published": "2024-05-27T18:03:37Z"
    },
    {
        "title": "A deep-learning algorithm to disentangle self-interacting dark matter\n  and AGN feedback models",
        "link": "http://arxiv.org/abs/2405.17566v1",
        "abstract": "Different models of dark matter can alter the distribution of mass in galaxy\nclusters in a variety of ways. However, so can uncertain astrophysical feedback\nmechanisms. Here we present a Machine Learning method that ''learns'' how the\nimpact of dark matter self-interactions differs from that of astrophysical\nfeedback in order to break this degeneracy and make inferences on dark matter.\nWe train a Convolutional Neural Network on images of galaxy clusters from\nhydro-dynamic simulations. In the idealised case our algorithm is 80% accurate\nat identifying if a galaxy cluster harbours collisionless dark matter, dark\nmatter with ${\\sigma}_{\\rm DM}/m = 0.1$cm$^2/$g or with ${\\sigma}_{DM}/m =\n1$cm$^2$/g. Whilst we find adding X-ray emissivity maps does not improve the\nperformance in differentiating collisional dark matter, it does improve the\nability to disentangle different models of astrophysical feedback. We include\nnoise to resemble data expected from Euclid and Chandra and find our model has\na statistical error of < 0.01cm$^2$/g and that our algorithm is insensitive to\nshape measurement bias and photometric redshift errors. This method represents\na new way to analyse data from upcoming telescopes that is an order of\nmagnitude more precise and many orders faster, enabling us to explore the dark\nmatter parameter space like never before.",
        "subjects": [
            "astro-ph.CO",
            "cs.LG",
            "physics.comp-ph"
        ],
        "authors": [
            "David Harvey"
        ],
        "published": "2024-05-27T18:00:49Z"
    },
    {
        "title": "Probabilistic Verification of Neural Networks using Branch and Bound",
        "link": "http://arxiv.org/abs/2405.17556v1",
        "abstract": "Probabilistic verification of neural networks is concerned with formally\nanalysing the output distribution of a neural network under a probability\ndistribution of the inputs. Examples of probabilistic verification include\nverifying the demographic parity fairness notion or quantifying the safety of a\nneural network. We present a new algorithm for the probabilistic verification\nof neural networks based on an algorithm for computing and iteratively refining\nlower and upper bounds on probabilities over the outputs of a neural network.\nBy applying state-of-the-art bound propagation and branch and bound techniques\nfrom non-probabilistic neural network verification, our algorithm significantly\noutpaces existing probabilistic verification algorithms, reducing solving times\nfor various benchmarks from the literature from tens of minutes to tens of\nseconds. Furthermore, our algorithm compares favourably even to dedicated\nalgorithms for restricted subsets of probabilistic verification. We complement\nour empirical evaluation with a theoretical analysis, proving that our\nalgorithm is sound and, under mildly restrictive conditions, also complete when\nusing a suitable set of heuristics.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "David Boetius",
            "Stefan Leue",
            "Tobias Sutter"
        ],
        "published": "2024-05-27T18:00:03Z"
    },
    {
        "title": "Bayesian RG Flow in Neural Network Field Theories",
        "link": "http://arxiv.org/abs/2405.17538v1",
        "abstract": "The Neural Network Field Theory correspondence (NNFT) is a mapping from\nneural network (NN) architectures into the space of statistical field theories\n(SFTs). The Bayesian renormalization group (BRG) is an information-theoretic\ncoarse graining scheme that generalizes the principles of the Exact\nRenormalization Group (ERG) to arbitrarily parameterized probability\ndistributions, including those of NNs. In BRG, coarse graining is performed in\nparameter space with respect to an information-theoretic distinguishability\nscale set by the Fisher information metric. In this paper, we unify NNFT and\nBRG to form a powerful new framework for exploring the space of NNs and SFTs,\nwhich we coin BRG-NNFT. With BRG-NNFT, NN training dynamics can be interpreted\nas inducing a flow in the space of SFTs from the information-theoretic `IR'\n$\\rightarrow$ `UV'. Conversely, applying an information-shell coarse graining\nto the trained network's parameters induces a flow in the space of SFTs from\nthe information-theoretic `UV' $\\rightarrow$ `IR'. When the\ninformation-theoretic cutoff scale coincides with a standard momentum scale,\nBRG is equivalent to ERG. We demonstrate the BRG-NNFT correspondence on two\nanalytically tractable examples. First, we construct BRG flows for trained,\ninfinite-width NNs, of arbitrary depth, with generic activation functions. As a\nspecial case, we then restrict to architectures with a single infinitely-wide\nlayer, scalar outputs, and generalized cos-net activations. In this case, we\nshow that BRG coarse-graining corresponds exactly to the momentum-shell ERG\nflow of a free scalar SFT. Our analytic results are corroborated by a numerical\nexperiment in which an ensemble of asymptotically wide NNs are trained and\nsubsequently renormalized using an information-shell BRG scheme.",
        "subjects": [
            "hep-th",
            "cond-mat.dis-nn",
            "cs.LG"
        ],
        "authors": [
            "Jessica N. Howard",
            "Marc S. Klinger",
            "Anindita Maiti",
            "Alexander G. Stapleton"
        ],
        "published": "2024-05-27T18:00:00Z"
    },
    {
        "title": "Approximately-symmetric neural networks for quantum spin liquids",
        "link": "http://arxiv.org/abs/2405.17541v1",
        "abstract": "We propose and analyze a family of approximately-symmetric neural networks\nfor quantum spin liquid problems. These tailored architectures are\nparameter-efficient, scalable, and significantly out-perform existing\nsymmetry-unaware neural network architectures. Utilizing the mixed-field toric\ncode model, we demonstrate that our approach is competitive with the\nstate-of-the-art tensor network and quantum Monte Carlo methods. Moreover, at\nthe largest system sizes (N=480), our method allows us to explore Hamiltonians\nwith sign problems beyond the reach of both quantum Monte Carlo and finite-size\nmatrix-product states. The network comprises an exactly symmetric block\nfollowing a non-symmetric block, which we argue learns a transformation of the\nground state analogous to quasiadiabatic continuation. Our work paves the way\ntoward investigating quantum spin liquid problems within interpretable neural\nnetwork architectures",
        "subjects": [
            "quant-ph",
            "cond-mat.dis-nn",
            "cond-mat.str-el",
            "cs.LG"
        ],
        "authors": [
            "Dominik S. Kufel",
            "Jack Kemp",
            "Simon M. Linsel",
            "Chris R. Laumann",
            "Norman Y. Yao"
        ],
        "published": "2024-05-27T18:00:00Z"
    },
    {
        "title": "The MQT Handbook: A Summary of Design Automation Tools and Software for\n  Quantum Computing",
        "link": "http://arxiv.org/abs/2405.17543v1",
        "abstract": "Quantum computers are becoming a reality and numerous quantum computing\napplications with a near-term perspective (e.g., for finance, chemistry,\nmachine learning, and optimization) and with a long-term perspective (e.g., for\ncryptography or unstructured search) are currently being investigated. However,\ndesigning and realizing potential applications for these devices in a scalable\nfashion requires automated, efficient, and user-friendly software tools that\ncater to the needs of end users, engineers, and physicists at every level of\nthe entire quantum software stack. Many of the problems to be tackled in that\nregard are similar to design problems from the classical realm for which\nsophisticated design automation tools have been developed in the previous\ndecades.\n  The Munich Quantum Toolkit (MQT) is a collection of software tools for\nquantum computing developed by the Chair for Design Automation at the Technical\nUniversity of Munich which explicitly utilizes this design automation\nexpertise. Our overarching objective is to provide solutions for design tasks\nacross the entire quantum software stack. This entails high-level support for\nend users in realizing their applications, efficient methods for the classical\nsimulation, compilation, and verification of quantum circuits, tools for\nquantum error correction, support for physical design, and more. These methods\nare supported by corresponding data structures (such as decision diagrams) and\ncore methods (such as SAT encodings/solvers). All of the developed tools are\navailable as open-source implementations and are hosted on\nhttps://github.com/cda-tum.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "authors": [
            "Robert Wille",
            "Lucas Berent",
            "Tobias Forster",
            "Jagatheesan Kunasaikaran",
            "Kevin Mato",
            "Tom Peham",
            "Nils Quetschlich",
            "Damian Rovara",
            "Aaron Sander",
            "Ludwig Schmid",
            "Daniel Schnberger",
            "Yannick Stade",
            "Lukas Burgholzer"
        ],
        "published": "2024-05-27T18:00:00Z"
    },
    {
        "title": "Towards Human-AI Complementarity with Predictions Sets",
        "link": "http://arxiv.org/abs/2405.17544v1",
        "abstract": "Decision support systems based on prediction sets have proven to be effective\nat helping human experts solve classification tasks. Rather than providing\nsingle-label predictions, these systems provide sets of label predictions\nconstructed using conformal prediction, namely prediction sets, and ask human\nexperts to predict label values from these sets. In this paper, we first show\nthat the prediction sets constructed using conformal prediction are, in\ngeneral, suboptimal in terms of average accuracy. Then, we show that the\nproblem of finding the optimal prediction sets under which the human experts\nachieve the highest average accuracy is NP-hard. More strongly, unless P = NP,\nwe show that the problem is hard to approximate to any factor less than the\nsize of the label set. However, we introduce a simple and efficient greedy\nalgorithm that, for a large class of expert models and non-conformity scores,\nis guaranteed to find prediction sets that provably offer equal or greater\nperformance than those constructed using conformal prediction. Further, using a\nsimulation study with both synthetic and real expert predictions, we\ndemonstrate that, in practice, our greedy algorithm finds near-optimal\nprediction sets offering greater performance than conformal prediction.",
        "subjects": [
            "cs.LG",
            "cs.CY",
            "cs.HC"
        ],
        "authors": [
            "Giovanni De Toni",
            "Nastaran Okati",
            "Suhas Thejaswi",
            "Eleni Straitouri",
            "Manuel Gomez-Rodriguez"
        ],
        "published": "2024-05-27T18:00:00Z"
    },
    {
        "title": "Matryoshka Multimodal Models",
        "link": "http://arxiv.org/abs/2405.17430v1",
        "abstract": "Large Multimodal Models (LMMs) such as LLaVA have shown strong performance in\nvisual-linguistic reasoning. These models first embed images into a fixed large\nnumber of visual tokens and then feed them into a Large Language Model (LLM).\nHowever, this design causes an excessive number of tokens for dense visual\nscenarios such as high-resolution images and videos, leading to great\ninefficiency. While token pruning/merging methods do exist, they produce a\nsingle length output for each image and do not afford flexibility in trading\noff information density v.s. efficiency. Inspired by the concept of Matryoshka\nDolls, we propose M3: Matryoshka Multimodal Models, which learns to represent\nvisual content as nested sets of visual tokens that capture information across\nmultiple coarse-to-fine granularities. Our approach offers several unique\nbenefits for LMMs: (1) One can explicitly control the visual granularity per\ntest instance during inference, e.g. , adjusting the number of tokens used to\nrepresent an image based on the anticipated complexity or simplicity of the\ncontent; (2) M3 provides a framework for analyzing the granularity needed for\nexisting datasets, where we find that COCO-style benchmarks only need around ~9\nvisual tokens to obtain accuracy similar to that of using all 576 tokens; (3)\nOur approach provides a foundation to explore the best trade-off between\nperformance and visual token length at sample level, where our investigation\nreveals that a large gap exists between the oracle upper bound and current\nfixed-scale representations.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Mu Cai",
            "Jianwei Yang",
            "Jianfeng Gao",
            "Yong Jae Lee"
        ],
        "published": "2024-05-27T17:59:56Z"
    },
    {
        "title": "GaussianFormer: Scene as Gaussians for Vision-Based 3D Semantic\n  Occupancy Prediction",
        "link": "http://arxiv.org/abs/2405.17429v1",
        "abstract": "3D semantic occupancy prediction aims to obtain 3D fine-grained geometry and\nsemantics of the surrounding scene and is an important task for the robustness\nof vision-centric autonomous driving. Most existing methods employ dense grids\nsuch as voxels as scene representations, which ignore the sparsity of occupancy\nand the diversity of object scales and thus lead to unbalanced allocation of\nresources. To address this, we propose an object-centric representation to\ndescribe 3D scenes with sparse 3D semantic Gaussians where each Gaussian\nrepresents a flexible region of interest and its semantic features. We\naggregate information from images through the attention mechanism and\niteratively refine the properties of 3D Gaussians including position,\ncovariance, and semantics. We then propose an efficient Gaussian-to-voxel\nsplatting method to generate 3D occupancy predictions, which only aggregates\nthe neighboring Gaussians for a certain position. We conduct extensive\nexperiments on the widely adopted nuScenes and KITTI-360 datasets. Experimental\nresults demonstrate that GaussianFormer achieves comparable performance with\nstate-of-the-art methods with only 17.8% - 24.8% of their memory consumption.\nCode is available at: https://github.com/huang-yh/GaussianFormer.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Yuanhui Huang",
            "Wenzhao Zheng",
            "Yunpeng Zhang",
            "Jie Zhou",
            "Jiwen Lu"
        ],
        "published": "2024-05-27T17:59:51Z"
    },
    {
        "title": "NV-Embed: Improved Techniques for Training LLMs as Generalist Embedding\n  Models",
        "link": "http://arxiv.org/abs/2405.17428v1",
        "abstract": "Decoder-only large language model (LLM)-based embedding models are beginning\nto outperform BERT or T5-based embedding models in general-purpose text\nembedding tasks, including dense vector-based retrieval. In this work, we\nintroduce the NV-Embed model with a variety of architectural designs and\ntraining procedures to significantly enhance the performance of LLM as a\nversatile embedding model, while maintaining its simplicity and\nreproducibility. For model architecture, we propose a latent attention layer to\nobtain pooled embeddings, which consistently improves retrieval and downstream\ntask accuracy compared to mean pooling or using the last <EOS> token embedding\nfrom LLMs. To enhance representation learning, we remove the causal attention\nmask of LLMs during contrastive training. For model training, we introduce a\ntwo-stage contrastive instruction-tuning method. It first applies contrastive\ntraining with instructions on retrieval datasets, utilizing in-batch negatives\nand curated hard negative examples. At stage-2, it blends various non-retrieval\ndatasets into instruction tuning, which not only enhances non-retrieval task\naccuracy but also improves retrieval performance. Combining these techniques,\nour NV-Embed model, using only publicly available data, has achieved a\nrecord-high score of 69.32, ranking No. 1 on the Massive Text Embedding\nBenchmark (MTEB) (as of May 24, 2024), with 56 tasks, encompassing retrieval,\nreranking, classification, clustering, and semantic textual similarity tasks.\nNotably, our model also attains the highest score of 59.36 on 15 retrieval\ntasks in the MTEB benchmark (also known as BEIR). We will open-source the model\nat: https://huggingface.co/nvidia/NV-Embed-v1.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR",
            "cs.LG"
        ],
        "authors": [
            "Chankyu Lee",
            "Rajarshi Roy",
            "Mengyao Xu",
            "Jonathan Raiman",
            "Mohammad Shoeybi",
            "Bryan Catanzaro",
            "Wei Ping"
        ],
        "published": "2024-05-27T17:59:45Z"
    },
    {
        "title": "Reason3D: Searching and Reasoning 3D Segmentation via Large Language\n  Model",
        "link": "http://arxiv.org/abs/2405.17427v1",
        "abstract": "Recent advancements in multimodal large language models (LLMs) have shown\ntheir potential in various domains, especially concept reasoning. Despite these\ndevelopments, applications in understanding 3D environments remain limited.\nThis paper introduces Reason3D, a novel LLM designed for comprehensive 3D\nunderstanding. Reason3D takes point cloud data and text prompts as input to\nproduce textual responses and segmentation masks, facilitating advanced tasks\nlike 3D reasoning segmentation, hierarchical searching, express referring, and\nquestion answering with detailed mask outputs. Specifically, we propose a\nhierarchical mask decoder to locate small objects within expansive scenes. This\ndecoder initially generates a coarse location estimate covering the object's\ngeneral area. This foundational estimation facilitates a detailed,\ncoarse-to-fine segmentation strategy that significantly enhances the precision\nof object identification and segmentation. Experiments validate that Reason3D\nachieves remarkable results on large-scale ScanNet and Matterport3D datasets\nfor 3D express referring, 3D question answering, and 3D reasoning segmentation\ntasks. Code and models are available at:\nhttps://github.com/KuanchihHuang/Reason3D.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Kuan-Chih Huang",
            "Xiangtai Li",
            "Lu Qi",
            "Shuicheng Yan",
            "Ming-Hsuan Yang"
        ],
        "published": "2024-05-27T17:59:41Z"
    },
    {
        "title": "Benchmarking and Improving Bird's Eye View Perception Robustness in\n  Autonomous Driving",
        "link": "http://arxiv.org/abs/2405.17426v1",
        "abstract": "Recent advancements in bird's eye view (BEV) representations have shown\nremarkable promise for in-vehicle 3D perception. However, while these methods\nhave achieved impressive results on standard benchmarks, their robustness in\nvaried conditions remains insufficiently assessed. In this study, we present\nRoboBEV, an extensive benchmark suite designed to evaluate the resilience of\nBEV algorithms. This suite incorporates a diverse set of camera corruption\ntypes, each examined over three severity levels. Our benchmarks also consider\nthe impact of complete sensor failures that occur when using multi-modal\nmodels. Through RoboBEV, we assess 33 state-of-the-art BEV-based perception\nmodels spanning tasks like detection, map segmentation, depth estimation, and\noccupancy prediction. Our analyses reveal a noticeable correlation between the\nmodel's performance on in-distribution datasets and its resilience to\nout-of-distribution challenges. Our experimental results also underline the\nefficacy of strategies like pre-training and depth-free BEV transformations in\nenhancing robustness against out-of-distribution data. Furthermore, we observe\nthat leveraging extensive temporal information significantly improves the\nmodel's robustness. Based on our observations, we design an effective\nrobustness enhancement strategy based on the CLIP model. The insights from this\nstudy pave the way for the development of future BEV models that seamlessly\ncombine accuracy with real-world robustness.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Shaoyuan Xie",
            "Lingdong Kong",
            "Wenwei Zhang",
            "Jiawei Ren",
            "Liang Pan",
            "Kai Chen",
            "Ziwei Liu"
        ],
        "published": "2024-05-27T17:59:39Z"
    },
    {
        "title": "From Neurons to Neutrons: A Case Study in Interpretability",
        "link": "http://arxiv.org/abs/2405.17425v1",
        "abstract": "Mechanistic Interpretability (MI) promises a path toward fully understanding\nhow neural networks make their predictions. Prior work demonstrates that even\nwhen trained to perform simple arithmetic, models can implement a variety of\nalgorithms (sometimes concurrently) depending on initialization and\nhyperparameters. Does this mean neuron-level interpretability techniques have\nlimited applicability? We argue that high-dimensional neural networks can learn\nlow-dimensional representations of their training data that are useful beyond\nsimply making good predictions. Such representations can be understood through\nthe mechanistic interpretability lens and provide insights that are\nsurprisingly faithful to human-derived domain knowledge. This indicates that\nsuch approaches to interpretability can be useful for deriving a new\nunderstanding of a problem from models trained to solve it. As a case study, we\nextract nuclear physics concepts by studying models trained to reproduce\nnuclear data.",
        "subjects": [
            "cs.LG",
            "nucl-th"
        ],
        "authors": [
            "Ouail Kitouni",
            "Niklas Nolte",
            "Vctor Samuel Prez-Daz",
            "Sokratis Trifinopoulos",
            "Mike Williams"
        ],
        "published": "2024-05-27T17:59:35Z"
    },
    {
        "title": "LARM: Large Auto-Regressive Model for Long-Horizon Embodied Intelligence",
        "link": "http://arxiv.org/abs/2405.17424v1",
        "abstract": "Due to the need to interact with the real world, embodied agents are required\nto possess comprehensive prior knowledge, long-horizon planning capability, and\na swift response speed. Despite recent large language model (LLM) based agents\nachieving promising performance, they still exhibit several limitations. For\ninstance, the output of LLMs is a descriptive sentence, which is ambiguous when\ndetermining specific actions. To address these limitations, we introduce the\nlarge auto-regressive model (LARM). LARM leverages both text and multi-view\nimages as input and predicts subsequent actions in an auto-regressive manner.\nTo train LARM, we develop a novel data format named auto-regressive node\ntransmission structure and assemble a corresponding dataset. Adopting a\ntwo-phase training regimen, LARM successfully harvests enchanted equipment in\nMinecraft, which demands significantly more complex decision-making chains than\nthe highest achievements of prior best methods. Besides, the speed of LARM is\n6.8x faster.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhuoling Li",
            "Xiaogang Xu",
            "Zhenhua Xu",
            "SerNam Lim",
            "Hengshuang Zhao"
        ],
        "published": "2024-05-27T17:59:32Z"
    },
    {
        "title": "Privacy-Aware Visual Language Models",
        "link": "http://arxiv.org/abs/2405.17423v1",
        "abstract": "This paper aims to advance our understanding of how Visual Language Models\n(VLMs) handle privacy-sensitive information, a crucial concern as these\ntechnologies become integral to everyday life. To this end, we introduce a new\nbenchmark PrivBench, which contains images from 8 sensitive categories such as\npassports, or fingerprints. We evaluate 10 state-of-the-art VLMs on this\nbenchmark and observe a generally limited understanding of privacy,\nhighlighting a significant area for model improvement. Based on this we\nintroduce PrivTune, a new instruction-tuning dataset aimed at equipping VLMs\nwith knowledge about visual privacy. By tuning two pretrained VLMs, TinyLLaVa\nand MiniGPT-v2, on this small dataset, we achieve strong gains in their ability\nto recognize sensitive content, outperforming even GPT4-V. At the same time, we\nshow that privacy-tuning only minimally affects the VLMs performance on\nstandard benchmarks such as VQA. Overall, this paper lays out a crucial\nchallenge for making VLMs effective in handling real-world data safely and\nprovides a simple recipe that takes the first step towards building\nprivacy-aware VLMs.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "authors": [
            "Laurens Samson",
            "Nimrod Barazani",
            "Sennay Ghebreab",
            "Yuki M. Asano"
        ],
        "published": "2024-05-27T17:59:25Z"
    },
    {
        "title": "Hardness-Aware Scene Synthesis for Semi-Supervised 3D Object Detection",
        "link": "http://arxiv.org/abs/2405.17422v1",
        "abstract": "3D object detection aims to recover the 3D information of concerning objects\nand serves as the fundamental task of autonomous driving perception. Its\nperformance greatly depends on the scale of labeled training data, yet it is\ncostly to obtain high-quality annotations for point cloud data. While\nconventional methods focus on generating pseudo-labels for unlabeled samples as\nsupplements for training, the structural nature of 3D point cloud data\nfacilitates the composition of objects and backgrounds to synthesize realistic\nscenes. Motivated by this, we propose a hardness-aware scene synthesis (HASS)\nmethod to generate adaptive synthetic scenes to improve the generalization of\nthe detection models. We obtain pseudo-labels for unlabeled objects and\ngenerate diverse scenes with different compositions of objects and backgrounds.\nAs the scene synthesis is sensitive to the quality of pseudo-labels, we further\npropose a hardness-aware strategy to reduce the effect of low-quality\npseudo-labels and maintain a dynamic pseudo-database to ensure the diversity\nand quality of synthetic scenes. Extensive experimental results on the widely\nused KITTI and Waymo datasets demonstrate the superiority of the proposed HASS\nmethod, which outperforms existing semi-supervised learning methods on 3D\nobject detection. Code: https://github.com/wzzheng/HASS.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Shuai Zeng",
            "Wenzhao Zheng",
            "Jiwen Lu",
            "Haibin Yan"
        ],
        "published": "2024-05-27T17:59:23Z"
    },
    {
        "title": "MoSca: Dynamic Gaussian Fusion from Casual Videos via 4D Motion\n  Scaffolds",
        "link": "http://arxiv.org/abs/2405.17421v1",
        "abstract": "We introduce 4D Motion Scaffolds (MoSca), a neural information processing\nsystem designed to reconstruct and synthesize novel views of dynamic scenes\nfrom monocular videos captured casually in the wild. To address such a\nchallenging and ill-posed inverse problem, we leverage prior knowledge from\nfoundational vision models, lift the video data to a novel Motion Scaffold\n(MoSca) representation, which compactly and smoothly encodes the underlying\nmotions / deformations. The scene geometry and appearance are then disentangled\nfrom the deformation field, and are encoded by globally fusing the Gaussians\nanchored onto the MoSca and optimized via Gaussian Splatting. Additionally,\ncamera poses can be seamlessly initialized and refined during the dynamic\nrendering process, without the need for other pose estimation tools.\nExperiments demonstrate state-of-the-art performance on dynamic rendering\nbenchmarks.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "authors": [
            "Jiahui Lei",
            "Yijia Weng",
            "Adam Harley",
            "Leonidas Guibas",
            "Kostas Daniilidis"
        ],
        "published": "2024-05-27T17:59:07Z"
    },
    {
        "title": "Survival of the Fittest Representation: A Case Study with Modular\n  Addition",
        "link": "http://arxiv.org/abs/2405.17420v1",
        "abstract": "When a neural network can learn multiple distinct algorithms to solve a task,\nhow does it \"choose\" between them during training? To approach this question,\nwe take inspiration from ecology: when multiple species coexist, they\neventually reach an equilibrium where some survive while others die out.\nAnalogously, we suggest that a neural network at initialization contains many\nsolutions (representations and algorithms), which compete with each other under\npressure from resource constraints, with the \"fittest\" ultimately prevailing.\nTo investigate this Survival of the Fittest hypothesis, we conduct a case study\non neural networks performing modular addition, and find that these networks'\nmultiple circular representations at different Fourier frequencies undergo such\ncompetitive dynamics, with only a few circles surviving at the end. We find\nthat the frequencies with high initial signals and gradients, the \"fittest,\"\nare more likely to survive. By increasing the embedding dimension, we also\nobserve more surviving frequencies. Inspired by the Lotka-Volterra equations\ndescribing the dynamics between species, we find that the dynamics of the\ncircles can be nicely characterized by a set of linear differential equations.\nOur results with modular addition show that it is possible to decompose\ncomplicated representations into simpler components, along with their basic\ninteractions, to offer insight on the training dynamics of representations.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Xiaoman Delores Ding",
            "Zifan Carl Guo",
            "Eric J. Michaud",
            "Ziming Liu",
            "Max Tegmark"
        ],
        "published": "2024-05-27T17:59:04Z"
    },
    {
        "title": "MultiOOD: Scaling Out-of-Distribution Detection for Multiple Modalities",
        "link": "http://arxiv.org/abs/2405.17419v1",
        "abstract": "Detecting out-of-distribution (OOD) samples is important for deploying\nmachine learning models in safety-critical applications such as autonomous\ndriving and robot-assisted surgery. Existing research has mainly focused on\nunimodal scenarios on image data. However, real-world applications are\ninherently multimodal, which makes it essential to leverage information from\nmultiple modalities to enhance the efficacy of OOD detection. To establish a\nfoundation for more realistic Multimodal OOD Detection, we introduce the\nfirst-of-its-kind benchmark, MultiOOD, characterized by diverse dataset sizes\nand varying modality combinations. We first evaluate existing unimodal OOD\ndetection algorithms on MultiOOD, observing that the mere inclusion of\nadditional modalities yields substantial improvements. This underscores the\nimportance of utilizing multiple modalities for OOD detection. Based on the\nobservation of Modality Prediction Discrepancy between in-distribution (ID) and\nOOD data, and its strong correlation with OOD performance, we propose the\nAgree-to-Disagree (A2D) algorithm to encourage such discrepancy during\ntraining. Moreover, we introduce a novel outlier synthesis method, NP-Mix,\nwhich explores broader feature spaces by leveraging the information from\nnearest neighbor classes and complements A2D to strengthen OOD detection\nperformance. Extensive experiments on MultiOOD demonstrate that training with\nA2D and NP-Mix improves existing OOD detection algorithms by a large margin.\nOur source code and MultiOOD benchmark are available at\nhttps://github.com/donghao51/MultiOOD.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Hao Dong",
            "Yue Zhao",
            "Eleni Chatzi",
            "Olga Fink"
        ],
        "published": "2024-05-27T17:59:02Z"
    },
    {
        "title": "Self-Corrected Multimodal Large Language Model for End-to-End Robot\n  Manipulation",
        "link": "http://arxiv.org/abs/2405.17418v1",
        "abstract": "Robot manipulation policies have shown unsatisfactory action performance when\nconfronted with novel task or object instances. Hence, the capability to\nautomatically detect and self-correct failure action is essential for a\npractical robotic system. Recently, Multimodal Large Language Models (MLLMs)\nhave shown promise in visual instruction following and demonstrated strong\nreasoning abilities in various tasks. To unleash general MLLMs as an end-to-end\nrobotic agent, we introduce a Self-Corrected (SC)-MLLM, equipping our model not\nonly to predict end-effector poses but also to autonomously recognize and\ncorrect failure actions. Specifically, we first conduct parameter-efficient\nfine-tuning to empower MLLM with pose prediction ability, which is reframed as\na language modeling problem. When facing execution failures, our model learns\nto identify low-level action error causes (i.e., position and rotation errors)\nand adaptively seeks prompt feedback from experts. Based on the feedback,\nSC-MLLM rethinks the current failure scene and generates the corrected actions.\nFurthermore, we design a continuous policy learning method for successfully\ncorrected samples, enhancing the model's adaptability to the current scene\nconfiguration and reducing the frequency of expert intervention. To evaluate\nour SC-MLLM, we conduct extensive experiments in both simulation and real-world\nsettings. SC-MLLM agent significantly improve manipulation accuracy compared to\nprevious state-of-the-art robotic MLLM (ManipLLM), increasing from 57\\% to 79\\%\non seen object categories and from 47\\% to 69\\% on unseen novel categories.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jiaming Liu",
            "Chenxuan Li",
            "Guanqun Wang",
            "Lily Lee",
            "Kaichen Zhou",
            "Sixiang Chen",
            "Chuyan Xiong",
            "Jiaxin Ge",
            "Renrui Zhang",
            "Shanghang Zhang"
        ],
        "published": "2024-05-27T17:58:48Z"
    },
    {
        "title": "A Recipe for Unbounded Data Augmentation in Visual Reinforcement\n  Learning",
        "link": "http://arxiv.org/abs/2405.17416v1",
        "abstract": "$Q$-learning algorithms are appealing for real-world applications due to\ntheir data-efficiency, but they are very prone to overfitting and training\ninstabilities when trained from visual observations. Prior work, namely SVEA,\nfinds that selective application of data augmentation can improve the visual\ngeneralization of RL agents without destabilizing training. We revisit its\nrecipe for data augmentation, and find an assumption that limits its\neffectiveness to augmentations of a photometric nature. Addressing these\nlimitations, we propose a generalized recipe, SADA, that works with wider\nvarieties of augmentations. We benchmark its effectiveness on DMC-GB2 -- our\nproposed extension of the popular DMControl Generalization Benchmark -- as well\nas tasks from Meta-World and the Distracting Control Suite, and find that our\nmethod, SADA, greatly improves training stability and generalization of RL\nagents across a diverse set of augmentations. Visualizations, code, and\nbenchmark: see https://aalmuzairee.github.io/SADA/",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Abdulaziz Almuzairee",
            "Nicklas Hansen",
            "Henrik I. Christensen"
        ],
        "published": "2024-05-27T17:58:23Z"
    },
    {
        "title": "Collaborative Video Diffusion: Consistent Multi-video Generation with\n  Camera Control",
        "link": "http://arxiv.org/abs/2405.17414v1",
        "abstract": "Research on video generation has recently made tremendous progress, enabling\nhigh-quality videos to be generated from text prompts or images. Adding control\nto the video generation process is an important goal moving forward and recent\napproaches that condition video generation models on camera trajectories make\nstrides towards it. Yet, it remains challenging to generate a video of the same\nscene from multiple different camera trajectories. Solutions to this\nmulti-video generation problem could enable large-scale 3D scene generation\nwith editable camera trajectories, among other applications. We introduce\ncollaborative video diffusion (CVD) as an important step towards this vision.\nThe CVD framework includes a novel cross-video synchronization module that\npromotes consistency between corresponding frames of the same video rendered\nfrom different camera poses using an epipolar attention mechanism. Trained on\ntop of a state-of-the-art camera-control module for video generation, CVD\ngenerates multiple videos rendered from different camera trajectories with\nsignificantly better consistency than baselines, as shown in extensive\nexperiments. Project page: https://collaborativevideodiffusion.github.io/.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "authors": [
            "Zhengfei Kuang",
            "Shengqu Cai",
            "Hao He",
            "Yinghao Xu",
            "Hongsheng Li",
            "Leonidas Guibas",
            "Gordon Wetzstein"
        ],
        "published": "2024-05-27T17:58:01Z"
    },
    {
        "title": "BIOSCAN-CLIP: Bridging Vision and Genomics for Biodiversity Monitoring\n  at Scale",
        "link": "http://arxiv.org/abs/2405.17537v1",
        "abstract": "Measuring biodiversity is crucial for understanding ecosystem health. While\nprior works have developed machine learning models for the taxonomic\nclassification of photographic images and DNA separately, in this work, we\nintroduce a multimodal approach combining both, using CLIP-style contrastive\nlearning to align images, DNA barcodes, and textual data in a unified embedding\nspace. This allows for accurate classification of both known and unknown insect\nspecies without task-specific fine-tuning, leveraging contrastive learning for\nthe first time to fuse DNA and image data. Our method surpasses previous\nsingle-modality approaches in accuracy by over 11% on zero-shot learning tasks,\nshowcasing its effectiveness in biodiversity studies.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "authors": [
            "ZeMing Gong",
            "Austin T. Wang",
            "Joakim Bruslund Haurum",
            "Scott C. Lowe",
            "Graham W. Taylor",
            "Angel X. Chang"
        ],
        "published": "2024-05-27T17:57:48Z"
    },
    {
        "title": "Enhancing Music Genre Classification through Multi-Algorithm Analysis\n  and User-Friendly Visualization",
        "link": "http://dx.doi.org/10.52783/jes.3178",
        "abstract": "The aim of this study is to teach an algorithm how to recognize different\ntypes of music. Users will submit songs for analysis. Since the algorithm\nhasn't heard these songs before, it needs to figure out what makes each song\nunique. It does this by breaking down the songs into different parts and\nstudying things like rhythm, melody, and tone via supervised learning because\nthe program learns from examples that are already labelled. One important thing\nto consider when classifying music is its genre, which can be quite complex. To\nensure accuracy, we use five different algorithms, each working independently,\nto analyze the songs. This helps us get a more complete understanding of each\nsong's characteristics. Therefore, our goal is to correctly identify the genre\nof each submitted song. Once the analysis is done, the results are presented\nusing a graphing tool, making it easy for users to understand and provide\nfeedback.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "authors": [
            "Navin Kamuni",
            "Dheerendra Panwar"
        ],
        "published": "2024-05-27T17:57:20Z"
    },
    {
        "title": "Towards One Model for Classical Dimensionality Reduction: A\n  Probabilistic Perspective on UMAP and t-SNE",
        "link": "http://arxiv.org/abs/2405.17412v1",
        "abstract": "This paper shows that the dimensionality reduction methods, UMAP and t-SNE,\ncan be approximately recast as MAP inference methods corresponding to a\ngeneralized Wishart-based model introduced in ProbDR. This interpretation\noffers deeper theoretical insights into these algorithms, while introducing\ntools with which similar dimensionality reduction methods can be studied.",
        "subjects": [
            "stat.ML",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Aditya Ravuri",
            "Neil D. Lawrence"
        ],
        "published": "2024-05-27T17:57:12Z"
    },
    {
        "title": "The Peripatetic Hater: Predicting Movement Among Hate Subreddits",
        "link": "http://arxiv.org/abs/2405.17410v1",
        "abstract": "Many online hate groups exist to disparage others based on race, gender\nidentity, sex, or other characteristics. The accessibility of these communities\nallows users to join multiple types of hate groups (e.g., a racist community\nand misogynistic community), which calls into question whether these\nperipatetic users could be further radicalized compared to users that stay in\none type of hate group. However, little is known about the dynamics of joining\nmultiple types of hate groups, nor the effect of these groups on peripatetic\nusers. In this paper, we develop a new method to classify hate subreddits, and\nthe identities they disparage, which we use to better understand how users\nbecome peripatetic (join different types of hate subreddits). The hate\nclassification technique utilizes human-validated LLMs to extract the protected\nidentities attacked, if any, across 168 subreddits. We then cluster\nidentity-attacking subreddits to discover three broad categories of hate:\nracist, anti-LGBTQ, and misogynistic. We show that becoming active in a user's\nfirst hate subreddit can cause them to become active in additional hate\nsubreddits of a different category. We also find that users who join additional\nhate subreddits, especially of a different category, become more active in hate\nsubreddits as a whole and develop a wider hate group lexicon. We are therefore\nmotivated to train an AI model that we find usefully predicts the hate\ncategories users will become active in based on post text read and written. The\naccuracy of this model may be partly driven by peripatetic users often using\nthe language of hate subreddits they eventually join. Overall, these results\nhighlight the unique risks associated with hate communities on a social media\nplatform, as discussion of alternative targets of hate may lead users to target\nmore protected identities.",
        "subjects": [
            "cs.SI",
            "cs.CY",
            "cs.HC"
        ],
        "authors": [
            "Daniel Hickey",
            "Daniel M. T. Fessler",
            "Kristina Lerman",
            "Keith Burghardt"
        ],
        "published": "2024-05-27T17:57:05Z"
    },
    {
        "title": "Deep Learning Calabi-Yau four folds with hybrid and recurrent neural\n  network architectures",
        "link": "http://arxiv.org/abs/2405.17406v1",
        "abstract": "In this work, we report the results of applying deep learning based on hybrid\nconvolutional-recurrent and purely recurrent neural network architectures to\nthe dataset of almost one million complete intersection Calabi-Yau four-folds\n(CICY4) to machine-learn their four Hodge numbers $h^{1,1}, h^{2,1}, h^{3,1},\nh^{2,2}$. In particular, we explored and experimented with twelve different\nneural network models, nine of which are convolutional-recurrent (CNN-RNN)\nhybrids with the RNN unit being either GRU (Gated Recurrent Unit) or Long Short\nTerm Memory (LSTM). The remaining four models are purely recurrent neural\nnetworks based on LSTM. In terms of the $h^{1,1}, h^{2,1}, h^{3,1}, h^{2,2}$\nprediction accuracies, at 72% training ratio, our best performing individual\nmodel is CNN-LSTM-400, a hybrid CNN-LSTM with the LSTM hidden size of 400,\nwhich obtained 99.74%, 98.07%, 95.19%, 81.01%, our second best performing\nindividual model is LSTM-448, an LSTM-based model with the hidden size of 448,\nwhich obtained 99.74%, 97.51%, 94.24%, and 78.63%. These results were improved\nby forming ensembles of the top two, three or even four models. Our best\nensemble, consisting of the top three models, achieved the accuracies of\n99.80%, 98.40%, 95.80%, 83.02%. At 80% training ratio, the top two performing\nmodels LSTM-448 and LSTM-424 are both LSTM-based with the hidden sizes of 448\nand 424. Compared with the 72% training ratio, there is a significant\nimprovement of accuracies, which reached 99.85%, 98.66%, 96.26%, 84.77% for the\nbest individual model and 99.88%, 98.91%, 96.96%, 86.78% for the best ensemble.",
        "subjects": [
            "hep-th",
            "cs.LG",
            "math.AG"
        ],
        "authors": [
            "H. L. Dao"
        ],
        "published": "2024-05-27T17:55:05Z"
    },
    {
        "title": "Calibrated Dataset Condensation for Faster Hyperparameter Search",
        "link": "http://arxiv.org/abs/2405.17535v1",
        "abstract": "Dataset condensation can be used to reduce the computational cost of training\nmultiple models on a large dataset by condensing the training dataset into a\nsmall synthetic set. State-of-the-art approaches rely on matching the model\ngradients between the real and synthetic data. However, there is no theoretical\nguarantee of the generalizability of the condensed data: data condensation\noften generalizes poorly across hyperparameters/architectures in practice. This\npaper considers a different condensation objective specifically geared toward\nhyperparameter search. We aim to generate a synthetic validation dataset so\nthat the validation-performance rankings of the models, with different\nhyperparameters, on the condensed and original datasets are comparable. We\npropose a novel hyperparameter-calibrated dataset condensation (HCDC)\nalgorithm, which obtains the synthetic validation dataset by matching the\nhyperparameter gradients computed via implicit differentiation and efficient\ninverse Hessian approximation. Experiments demonstrate that the proposed\nframework effectively maintains the validation-performance rankings of models\nand speeds up hyperparameter/architecture search for tasks on both images and\ngraphs.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Mucong Ding",
            "Yuancheng Xu",
            "Tahseen Rabbani",
            "Xiaoyu Liu",
            "Brian Gravelle",
            "Teresa Ranadive",
            "Tai-Ching Tuan",
            "Furong Huang"
        ],
        "published": "2024-05-27T17:55:01Z"
    },
    {
        "title": "SMR: State Memory Replay for Long Sequence Modeling",
        "link": "http://arxiv.org/abs/2405.17534v1",
        "abstract": "Despite the promising performance of state space models (SSMs) in long\nsequence modeling, limitations still exist. Advanced SSMs like S5 and S6\n(Mamba) in addressing non-uniform sampling, their recursive structures impede\nefficient SSM computation via convolution. To overcome compatibility\nlimitations in parallel convolutional computation, this paper proposes a novel\nnon-recursive non-uniform sample processing strategy. Theoretical analysis of\nSSMs through the lens of Event-Triggered Control (ETC) theory reveals the\nNon-Stable State (NSS) problem, where deviations from sampling point\nrequirements lead to error transmission and accumulation, causing the\ndivergence of the SSM's hidden state. Our analysis further reveals that\nadjustments of input sequences with early memories can mitigate the NSS\nproblem, achieving Sampling Step Adaptation (SSA). Building on this insight, we\nintroduce a simple yet effective plug-and-play mechanism, State Memory Replay\n(SMR), which utilizes learnable memories to adjust the current state with\nmulti-step information for generalization at sampling points different from\nthose in the training data. This enables SSMs to stably model varying sampling\npoints. Experiments on long-range modeling tasks in autoregressive language\nmodeling and Long Range Arena demonstrate the general effectiveness of the SMR\nmechanism for a series of SSM models.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Biqing Qi",
            "Junqi Gao",
            "Kaiyan Zhang",
            "Dong Li",
            "Jianxing Liu",
            "Ligang Wu",
            "Bowen Zhou"
        ],
        "published": "2024-05-27T17:53:32Z"
    },
    {
        "title": "Human4DiT: Free-view Human Video Generation with 4D Diffusion\n  Transformer",
        "link": "http://arxiv.org/abs/2405.17405v1",
        "abstract": "We present a novel approach for generating high-quality, spatio-temporally\ncoherent human videos from a single image under arbitrary viewpoints. Our\nframework combines the strengths of U-Nets for accurate condition injection and\ndiffusion transformers for capturing global correlations across viewpoints and\ntime. The core is a cascaded 4D transformer architecture that factorizes\nattention across views, time, and spatial dimensions, enabling efficient\nmodeling of the 4D space. Precise conditioning is achieved by injecting human\nidentity, camera parameters, and temporal signals into the respective\ntransformers. To train this model, we curate a multi-dimensional dataset\nspanning images, videos, multi-view data and 3D/4D scans, along with a\nmulti-dimensional training strategy. Our approach overcomes the limitations of\nprevious methods based on GAN or UNet-based diffusion models, which struggle\nwith complex motions and viewpoint changes. Through extensive experiments, we\ndemonstrate our method's ability to synthesize realistic, coherent and\nfree-view human videos, paving the way for advanced multimedia applications in\nareas such as virtual reality and animation. Our project website is\nhttps://human4dit.github.io.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ruizhi Shao",
            "Youxin Pang",
            "Zerong Zheng",
            "Jingxiang Sun",
            "Yebin Liu"
        ],
        "published": "2024-05-27T17:53:29Z"
    },
    {
        "title": "Spectral Greedy Coresets for Graph Neural Networks",
        "link": "http://arxiv.org/abs/2405.17404v1",
        "abstract": "The ubiquity of large-scale graphs in node-classification tasks significantly\nhinders the real-world applications of Graph Neural Networks (GNNs). Node\nsampling, graph coarsening, and dataset condensation are effective strategies\nfor enhancing data efficiency. However, owing to the interdependence of graph\nnodes, coreset selection, which selects subsets of the data examples, has not\nbeen successfully applied to speed up GNN training on large graphs, warranting\nspecial treatment. This paper studies graph coresets for GNNs and avoids the\ninterdependence issue by selecting ego-graphs (i.e., neighborhood subgraphs\naround a node) based on their spectral embeddings. We decompose the coreset\nselection problem for GNNs into two phases: a coarse selection of widely spread\nego graphs and a refined selection to diversify their topologies. We design a\ngreedy algorithm that approximately optimizes both objectives. Our spectral\ngreedy graph coreset (SGGC) scales to graphs with millions of nodes, obviates\nthe need for model pre-training, and applies to low-homophily graphs. Extensive\nexperiments on ten datasets demonstrate that SGGC outperforms other coreset\nmethods by a wide margin, generalizes well across GNN architectures, and is\nmuch faster than graph condensation.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Mucong Ding",
            "Yinhan He",
            "Jundong Li",
            "Furong Huang"
        ],
        "published": "2024-05-27T17:52:12Z"
    },
    {
        "title": "A Closer Look at Time Steps is Worthy of Triple Speed-Up for Diffusion\n  Model Training",
        "link": "http://arxiv.org/abs/2405.17403v1",
        "abstract": "Training diffusion models is always a computation-intensive task. In this\npaper, we introduce a novel speed-up method for diffusion model training,\ncalled, which is based on a closer look at time steps. Our key findings are: i)\nTime steps can be empirically divided into acceleration, deceleration, and\nconvergence areas based on the process increment. ii) These time steps are\nimbalanced, with many concentrated in the convergence area. iii) The\nconcentrated steps provide limited benefits for diffusion training. To address\nthis, we design an asymmetric sampling strategy that reduces the frequency of\nsteps from the convergence area while increasing the sampling probability for\nsteps from other areas. Additionally, we propose a weighting strategy to\nemphasize the importance of time steps with rapid-change process increments. As\na plug-and-play and architecture-agnostic approach, SpeeD consistently achieves\n3-times acceleration across various diffusion architectures, datasets, and\ntasks. Notably, due to its simple design, our approach significantly reduces\nthe cost of diffusion model training with minimal overhead. Our research\nenables more researchers to train diffusion models at a lower cost.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "I.2"
        ],
        "authors": [
            "Kai Wang",
            "Yukun Zhou",
            "Mingjia Shi",
            "Zhihang Yuan",
            "Yuzhang Shang",
            "Xiaojiang Peng",
            "Hanwang Zhang",
            "Yang You"
        ],
        "published": "2024-05-27T17:51:36Z"
    },
    {
        "title": "THREAD: Thinking Deeper with Recursive Spawning",
        "link": "http://arxiv.org/abs/2405.17402v1",
        "abstract": "Large language models (LLMs) have shown impressive capabilities across\ndiverse settings, but still struggle as the length and complexity of the\ncontext increases. To address this challenge, we propose Thinking Recursively\nand Dynamically (ThReaD). THREAD frames model generation as a thread of\nexecution that, based on the context, can run to completion or dynamically\nspawn new threads. By spawning, threads can offload work (e.g., thinking,\nretrieving information) to child threads, which only return tokens needed for\nthe parent thread to do its work. In effect, this enables the model to adapt,\nas needed, the amount of intermediate work used to produce tokens. We apply\nTHREAD in the settings of LLM task solving and question answering, where the\ndynamic threading allows the model to recursively decompose the given task or\nquestion into progressively simpler sub-problems that can be solved by separate\nchild threads. We test THREAD, implemented using a few-shot learning approach,\non diverse benchmarks for agent tasks and data-grounded question answering.\nTHREAD achieves state-of-the-art performance with GPT-4 and GPT-3.5 on these\nbenchmarks, including ALFWorld, TextCraft, and WebShop, along with two new\nbenchmarks, DataCommons QA and MIMIC-III ICU QA. In addition, THREAD\noutperforms existing frameworks by 10% to 50% absolute points with smaller\nmodels, including Llama-3-8b and CodeLlama-7b.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Philip Schroeder",
            "Nathaniel Morgan",
            "Hongyin Luo",
            "James Glass"
        ],
        "published": "2024-05-27T17:51:24Z"
    },
    {
        "title": "RB-Modulation: Training-Free Personalization of Diffusion Models using\n  Stochastic Optimal Control",
        "link": "http://arxiv.org/abs/2405.17401v1",
        "abstract": "We propose Reference-Based Modulation (RB-Modulation), a new plug-and-play\nsolution for training-free personalization of diffusion models. Existing\ntraining-free approaches exhibit difficulties in (a) style extraction from\nreference images in the absence of additional style or content text\ndescriptions, (b) unwanted content leakage from reference style images, and (c)\neffective composition of style and content. RB-Modulation is built on a novel\nstochastic optimal controller where a style descriptor encodes the desired\nattributes through a terminal cost. The resulting drift not only overcomes the\ndifficulties above, but also ensures high fidelity to the reference style and\nadheres to the given text prompt. We also introduce a cross-attention-based\nfeature aggregation scheme that allows RB-Modulation to decouple content and\nstyle from the reference image. With theoretical justification and empirical\nevidence, our framework demonstrates precise extraction and control of content\nand style in a training-free manner. Further, our method allows a seamless\ncomposition of content and style, which marks a departure from the dependency\non external adapters or ControlNets.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "stat.ML"
        ],
        "authors": [
            "Litu Rout",
            "Yujia Chen",
            "Nataniel Ruiz",
            "Abhishek Kumar",
            "Constantine Caramanis",
            "Sanjay Shakkottai",
            "Wen-Sheng Chu"
        ],
        "published": "2024-05-27T17:51:08Z"
    },
    {
        "title": "PAE: LLM-based Product Attribute Extraction for E-Commerce Fashion\n  Trends",
        "link": "http://arxiv.org/abs/2405.17533v1",
        "abstract": "Product attribute extraction is an growing field in e-commerce business, with\nseveral applications including product ranking, product recommendation, future\nassortment planning and improving online shopping customer experiences.\nUnderstanding the customer needs is critical part of online business,\nspecifically fashion products. Retailers uses assortment planning to determine\nthe mix of products to offer in each store and channel, stay responsive to\nmarket dynamics and to manage inventory and catalogs. The goal is to offer the\nright styles, in the right sizes and colors, through the right channels. When\nshoppers find products that meet their needs and desires, they are more likely\nto return for future purchases, fostering customer loyalty. Product attributes\nare a key factor in assortment planning. In this paper we present PAE, a\nproduct attribute extraction algorithm for future trend reports consisting text\nand images in PDF format. Most existing methods focus on attribute extraction\nfrom titles or product descriptions or utilize visual information from existing\nproduct images. Compared to the prior works, our work focuses on attribute\nextraction from PDF files where upcoming fashion trends are explained. This\nwork proposes a more comprehensive framework that fully utilizes the different\nmodalities for attribute extraction and help retailers to plan the assortment\nin advance. Our contributions are three-fold: (a) We develop PAE, an efficient\nframework to extract attributes from unstructured data (text and images); (b)\nWe provide catalog matching methodology based on BERT representations to\ndiscover the existing attributes using upcoming attribute values; (c) We\nconduct extensive experiments with several baselines and show that PAE is an\neffective, flexible and on par or superior (avg 92.5% F1-Score) framework to\nexisting state-of-the-art for attribute value extraction task.",
        "subjects": [
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Apurva Sinha",
            "Ekta Gujral"
        ],
        "published": "2024-05-27T17:50:25Z"
    },
    {
        "title": "ClassDiffusion: More Aligned Personalization Tuning with Explicit Class\n  Guidance",
        "link": "http://arxiv.org/abs/2405.17532v1",
        "abstract": "Recent text-to-image customization works have been proven successful in\ngenerating images of given concepts by fine-tuning the diffusion models on a\nfew examples. However, these methods tend to overfit the concepts, resulting in\nfailure to create the concept under multiple conditions (e.g. headphone is\nmissing when generating a <sks> dog wearing a headphone'). Interestingly, we\nnotice that the base model before fine-tuning exhibits the capability to\ncompose the base concept with other elements (e.g. a dog wearing a headphone)\nimplying that the compositional ability only disappears after personalization\ntuning. Inspired by this observation, we present ClassDiffusion, a simple\ntechnique that leverages a semantic preservation loss to explicitly regulate\nthe concept space when learning the new concept. Despite its simplicity, this\nhelps avoid semantic drift when fine-tuning on the target concepts. Extensive\nqualitative and quantitative experiments demonstrate that the use of semantic\npreservation loss effectively improves the compositional abilities of the\nfine-tune models. In response to the ineffective evaluation of CLIP-T metrics,\nwe introduce BLIP2-T metric, a more equitable and effective evaluation metric\nfor this particular domain. We also provide in-depth empirical study and\ntheoretical analysis to better understand the role of the proposed loss.\nLastly, we also extend our ClassDiffusion to personalized video generation,\ndemonstrating its flexibility.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jiannan Huang",
            "Jun Hao Liew",
            "Hanshu Yan",
            "Yuyang Yin",
            "Yao Zhao",
            "Yunchao Wei"
        ],
        "published": "2024-05-27T17:50:10Z"
    },
    {
        "title": "Transformers Can Do Arithmetic with the Right Embeddings",
        "link": "http://arxiv.org/abs/2405.17399v1",
        "abstract": "The poor performance of transformers on arithmetic tasks seems to stem in\nlarge part from their inability to keep track of the exact position of each\ndigit inside of a large span of digits. We mend this problem by adding an\nembedding to each digit that encodes its position relative to the start of the\nnumber. In addition to the boost these embeddings provide on their own, we show\nthat this fix enables architectural modifications such as input injection and\nrecurrent layers to improve performance even further.\n  With positions resolved, we can study the logical extrapolation ability of\ntransformers. Can they solve arithmetic problems that are larger and more\ncomplex than those in their training data? We find that training on only 20\ndigit numbers with a single GPU for one day, we can reach state-of-the-art\nperformance, achieving up to 99% accuracy on 100 digit addition problems.\nFinally, we show that these gains in numeracy also unlock improvements on other\nmulti-step reasoning tasks including sorting and multiplication.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Sean McLeish",
            "Arpit Bansal",
            "Alex Stein",
            "Neel Jain",
            "John Kirchenbauer",
            "Brian R. Bartoldson",
            "Bhavya Kailkhura",
            "Abhinav Bhatele",
            "Jonas Geiping",
            "Avi Schwarzschild",
            "Tom Goldstein"
        ],
        "published": "2024-05-27T17:49:18Z"
    },
    {
        "title": "Vista: A Generalizable Driving World Model with High Fidelity and\n  Versatile Controllability",
        "link": "http://arxiv.org/abs/2405.17398v1",
        "abstract": "World models can foresee the outcomes of different actions, which is of\nparamount importance for autonomous driving. Nevertheless, existing driving\nworld models still have limitations in generalization to unseen environments,\nprediction fidelity of critical details, and action controllability for\nflexible application. In this paper, we present Vista, a generalizable driving\nworld model with high fidelity and versatile controllability. Based on a\nsystematic diagnosis of existing methods, we introduce several key ingredients\nto address these limitations. To accurately predict real-world dynamics at high\nresolution, we propose two novel losses to promote the learning of moving\ninstances and structural information. We also devise an effective latent\nreplacement approach to inject historical frames as priors for coherent\nlong-horizon rollouts. For action controllability, we incorporate a versatile\nset of controls from high-level intentions (command, goal point) to low-level\nmaneuvers (trajectory, angle, and speed) through an efficient learning\nstrategy. After large-scale training, the capabilities of Vista can seamlessly\ngeneralize to different scenarios. Extensive experiments on multiple datasets\nshow that Vista outperforms the most advanced general-purpose video generator\nin over 70% of comparisons and surpasses the best-performing driving world\nmodel by 55% in FID and 27% in FVD. Moreover, for the first time, we utilize\nthe capacity of Vista itself to establish a generalizable reward for real-world\naction evaluation without accessing the ground truth actions.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Shenyuan Gao",
            "Jiazhi Yang",
            "Li Chen",
            "Kashyap Chitta",
            "Yihang Qiu",
            "Andreas Geiger",
            "Jun Zhang",
            "Hongyang Li"
        ],
        "published": "2024-05-27T17:49:15Z"
    },
    {
        "title": "Occlusion Handling in 3D Human Pose Estimation with Perturbed Positional\n  Encoding",
        "link": "http://arxiv.org/abs/2405.17397v1",
        "abstract": "Understanding human behavior fundamentally relies on accurate 3D human pose\nestimation. Graph Convolutional Networks (GCNs) have recently shown promising\nadvancements, delivering state-of-the-art performance with rather lightweight\narchitectures. In the context of graph-structured data, leveraging the\neigenvectors of the graph Laplacian matrix for positional encoding is\neffective. Yet, the approach does not specify how to handle scenarios where\nedges in the input graph are missing. To this end, we propose a novel\npositional encoding technique, PerturbPE, that extracts consistent and regular\ncomponents from the eigenbasis. Our method involves applying multiple\nperturbations and taking their average to extract the consistent and regular\ncomponent from the eigenbasis. PerturbPE leverages the Rayleigh-Schrodinger\nPerturbation Theorem (RSPT) for calculating the perturbed eigenvectors.\nEmploying this labeling technique enhances the robustness and generalizability\nof the model. Our results support our theoretical findings, e.g. our\nexperimental analysis observed a performance enhancement of up to $12\\%$ on the\nHuman3.6M dataset in instances where occlusion resulted in the absence of one\nedge. Furthermore, our novel approach significantly enhances performance in\nscenarios where two edges are missing, setting a new benchmark for\nstate-of-the-art.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Niloofar Azizi",
            "Mohsen Fayyaz",
            "Horst Bischof"
        ],
        "published": "2024-05-27T17:48:54Z"
    },
    {
        "title": "The Expressive Capacity of State Space Models: A Formal Language\n  Perspective",
        "link": "http://arxiv.org/abs/2405.17394v1",
        "abstract": "Recently, recurrent models based on linear state space models (SSMs) have\nshown promising performance in language modeling (LM), competititve with\ntransformers. However, there is little understanding of the in-principle\nabilities of such models, which could provide useful guidance to the search for\nbetter LM architectures. We present a comprehensive theoretical study of the\ncapacity of such SSMs as it compares to that of transformers and traditional\nRNNs. We find that SSMs and transformers have overlapping but distinct\nstrengths. In star-free state tracking, SSMs implement straightforward and\nexact solutions to problems that transformers struggle to represent exactly.\nThey can also model bounded hierarchical structure with optimal memory even\nwithout simulating a stack. On the other hand, we identify a design choice in\ncurrent SSMs that limits their expressive power. We discuss implications for\nSSM and LM research, and verify results empirically on a recent SSM, Mamba.",
        "subjects": [
            "cs.CL",
            "cs.FL",
            "cs.LG"
        ],
        "authors": [
            "Yash Sarrof",
            "Yana Veitsman",
            "Michael Hahn"
        ],
        "published": "2024-05-27T17:46:57Z"
    },
    {
        "title": "EASI-Tex: Edge-Aware Mesh Texturing from Single Image",
        "link": "http://arxiv.org/abs/2405.17393v1",
        "abstract": "We present a novel approach for single-image mesh texturing, which employs a\ndiffusion model with judicious conditioning to seamlessly transfer an object's\ntexture from a single RGB image to a given 3D mesh object. We do not assume\nthat the two objects belong to the same category, and even if they do, there\ncan be significant discrepancies in their geometry and part proportions. Our\nmethod aims to rectify the discrepancies by conditioning a pre-trained Stable\nDiffusion generator with edges describing the mesh through ControlNet, and\nfeatures extracted from the input image using IP-Adapter to generate textures\nthat respect the underlying geometry of the mesh and the input texture without\nany optimization or training. We also introduce Image Inversion, a novel\ntechnique to quickly personalize the diffusion model for a single concept using\na single image, for cases where the pre-trained IP-Adapter falls short in\ncapturing all the details from the input image faithfully. Experimental results\ndemonstrate the efficiency and effectiveness of our edge-aware single-image\nmesh texturing approach, coined EASI-Tex, in preserving the details of the\ninput texture on diverse 3D objects, while respecting their geometry.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Sai Raj Kishore Perla",
            "Yizhi Wang",
            "Ali Mahdavi-Amiri",
            "Hao Zhang"
        ],
        "published": "2024-05-27T17:46:22Z"
    },
    {
        "title": "Dataset-learning duality and emergent criticality",
        "link": "http://arxiv.org/abs/2405.17391v1",
        "abstract": "In artificial neural networks, the activation dynamics of non-trainable\nvariables is strongly coupled to the learning dynamics of trainable variables.\nDuring the activation pass, the boundary neurons (e.g., input neurons) are\nmapped to the bulk neurons (e.g., hidden neurons), and during the learning\npass, both bulk and boundary neurons are mapped to changes in trainable\nvariables (e.g., weights and biases). For example, in feed-forward neural\nnetworks, forward propagation is the activation pass and backward propagation\nis the learning pass. We show that a composition of the two maps establishes a\nduality map between a subspace of non-trainable boundary variables (e.g.,\ndataset) and a tangent subspace of trainable variables (i.e., learning). In\ngeneral, the dataset-learning duality is a complex non-linear map between\nhigh-dimensional spaces, but in a learning equilibrium, the problem can be\nlinearized and reduced to many weakly coupled one-dimensional problems. We use\nthe duality to study the emergence of criticality, or the power-law\ndistributions of fluctuations of the trainable variables. In particular, we\nshow that criticality can emerge in the learning system even from the dataset\nin a non-critical state, and that the power-law distribution can be modified by\nchanging either the activation function or the loss function.",
        "subjects": [
            "cs.LG",
            "cond-mat.dis-nn",
            "cond-mat.stat-mech",
            "cs.NE"
        ],
        "authors": [
            "Ekaterina Kukleva",
            "Vitaly Vanchurin"
        ],
        "published": "2024-05-27T17:44:33Z"
    },
    {
        "title": "KSW: Khmer Stop Word based Dictionary for Keyword Extraction",
        "link": "http://arxiv.org/abs/2405.17390v1",
        "abstract": "This paper introduces KSW, a Khmer-specific approach to keyword extraction\nthat leverages a specialized stop word dictionary. Due to the limited\navailability of natural language processing resources for the Khmer language,\neffective keyword extraction has been a significant challenge. KSW addresses\nthis by developing a tailored stop word dictionary and implementing a\npreprocessing methodology to remove stop words, thereby enhancing the\nextraction of meaningful keywords. Our experiments demonstrate that KSW\nachieves substantial improvements in accuracy and relevance compared to\nprevious methods, highlighting its potential to advance Khmer text processing\nand information retrieval. The KSW resources, including the stop word\ndictionary, are available at the following GitHub repository:\n(https://github.com/back-kh/KSWv2-Khmer-Stop-Word-based-Dictionary-for-Keyword-Extraction.git).",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "authors": [
            "Nimol Thuon",
            "Wangrui Zhang",
            "Sada Thuon"
        ],
        "published": "2024-05-27T17:42:54Z"
    },
    {
        "title": "MindMerger: Efficient Boosting LLM Reasoning in non-English Languages",
        "link": "http://arxiv.org/abs/2405.17386v1",
        "abstract": "Reasoning capabilities are crucial for Large Language Models (LLMs), yet a\nnotable gap exists between English and non-English languages. To bridge this\ndisparity, some works fine-tune LLMs to relearn reasoning capabilities in\nnon-English languages, while others replace non-English inputs with an external\nmodel's outputs such as English translation text to circumvent the challenge of\nLLM understanding non-English. Unfortunately, these methods often underutilize\nthe built-in skilled reasoning and useful language understanding capabilities\nof LLMs. In order to better utilize the minds of reasoning and language\nunderstanding in LLMs, we propose a new method, namely MindMerger, which merges\nLLMs with the external language understanding capabilities from multilingual\nmodels to boost the multilingual reasoning performance. Furthermore, a two-step\ntraining scheme is introduced to first train to embeded the external\ncapabilities into LLMs and then train the collaborative utilization of the\nexternal capabilities and the built-in capabilities in LLMs. Experiments on\nthree multilingual reasoning datasets and a language understanding dataset\ndemonstrate that MindMerger consistently outperforms all baselines, especially\nin low-resource languages. Without updating the parameters of LLMs, the average\naccuracy improved by 6.7% and 8.0% across all languages and low-resource\nlanguages on the MGSM dataset, respectively.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Zixian Huang",
            "Wenhao Zhu",
            "Gong Cheng",
            "Lei Li",
            "Fei Yuan"
        ],
        "published": "2024-05-27T17:41:54Z"
    },
    {
        "title": "Evolutive Rendering Models",
        "link": "http://arxiv.org/abs/2405.17531v1",
        "abstract": "The landscape of computer graphics has undergone significant transformations\nwith the recent advances of differentiable rendering models. These rendering\nmodels often rely on heuristic designs that may not fully align with the final\nrendering objectives. We address this gap by pioneering \\textit{evolutive\nrendering models}, a methodology where rendering models possess the ability to\nevolve and adapt dynamically throughout the rendering process. In particular,\nwe present a comprehensive learning framework that enables the optimization of\nthree principal rendering elements, including the gauge transformations, the\nray sampling mechanisms, and the primitive organization. Central to this\nframework is the development of differentiable versions of these rendering\nelements, allowing for effective gradient backpropagation from the final\nrendering objectives. A detailed analysis of gradient characteristics is\nperformed to facilitate a stable and goal-oriented elements evolution. Our\nextensive experiments demonstrate the large potential of evolutive rendering\nmodels for enhancing the rendering performance across various domains,\nincluding static and dynamic scene representations, generative modeling, and\ntexture mapping.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Fangneng Zhan",
            "Hanxue Liang",
            "Yifan Wang",
            "Michael Niemeyer",
            "Michael Oechsle",
            "Adam Kortylewski",
            "Cengiz Oztireli",
            "Gordon Wetzstein",
            "Christian Theobalt"
        ],
        "published": "2024-05-27T17:40:00Z"
    },
    {
        "title": "Unlocking the Secrets of Linear Complexity Sequence Model from A Unified\n  Perspective",
        "link": "http://arxiv.org/abs/2405.17383v1",
        "abstract": "We present the Linear Complexity Sequence Model (LCSM), a comprehensive\nsolution that unites various sequence modeling techniques with linear\ncomplexity, including linear attention, state space model, long convolution,\nand linear RNN, within a single framework. The goal is to enhance comprehension\nof these models by analyzing the impact of each component from a cohesive and\nstreamlined viewpoint. Specifically, we segment the modeling processes of these\nmodels into three distinct stages: Expand, Oscillation, and Shrink (EOS), with\neach model having its own specific settings. The Expand stage involves\nprojecting the input signal onto a high-dimensional memory state. This is\nfollowed by recursive operations performed on the memory state in the\nOscillation stage. Finally, the memory state is projected back to a\nlow-dimensional space in the Shrink stage. We perform comprehensive experiments\nto analyze the impact of different stage settings on language modeling and\nretrieval tasks. Our results show that data-driven methods are crucial for the\neffectiveness of the three stages in language modeling, whereas hand-crafted\nmethods yield better performance in retrieval tasks.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Zhen Qin",
            "Xuyang Shen",
            "Dong Li",
            "Weigao Sun",
            "Stan Birchfield",
            "Richard Hartley",
            "Yiran Zhong"
        ],
        "published": "2024-05-27T17:38:55Z"
    },
    {
        "title": "ReMoDetect: Reward Models Recognize Aligned LLM's Generations",
        "link": "http://arxiv.org/abs/2405.17382v1",
        "abstract": "The remarkable capabilities and easy accessibility of large language models\n(LLMs) have significantly increased societal risks (e.g., fake news\ngeneration), necessitating the development of LLM-generated text (LGT)\ndetection methods for safe usage. However, detecting LGTs is challenging due to\nthe vast number of LLMs, making it impractical to account for each LLM\nindividually; hence, it is crucial to identify the common characteristics\nshared by these models. In this paper, we draw attention to a common feature of\nrecent powerful LLMs, namely the alignment training, i.e., training LLMs to\ngenerate human-preferable texts. Our key finding is that as these aligned LLMs\nare trained to maximize the human preferences, they generate texts with higher\nestimated preferences even than human-written texts; thus, such texts are\neasily detected by using the reward model (i.e., an LLM trained to model human\npreference distribution). Based on this finding, we propose two training\nschemes to further improve the detection ability of the reward model, namely\n(i) continual preference fine-tuning to make the reward model prefer aligned\nLGTs even further and (ii) reward modeling of Human/LLM mixed texts (a\nrephrased texts from human-written texts using aligned LLMs), which serves as a\nmedian preference text corpus between LGTs and human-written texts to learn the\ndecision boundary better. We provide an extensive evaluation by considering six\ntext domains across twelve aligned LLMs, where our method demonstrates\nstate-of-the-art results. Code is available at\nhttps://github.com/hyunseoklee-ai/reward_llm_detect.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "authors": [
            "Hyunseok Lee",
            "Jihoon Tack",
            "Jinwoo Shin"
        ],
        "published": "2024-05-27T17:38:33Z"
    },
    {
        "title": "Various Lengths, Constant Speed: Efficient Language Modeling with\n  Lightning Attention",
        "link": "http://arxiv.org/abs/2405.17381v1",
        "abstract": "We present Lightning Attention, the first linear attention implementation\nthat maintains a constant training speed for various sequence lengths under\nfixed memory consumption. Due to the issue with cumulative summation operations\n(cumsum), previous linear attention implementations cannot achieve their\ntheoretical advantage in a casual setting. However, this issue can be\neffectively solved by utilizing different attention calculation strategies to\ncompute the different parts of attention. Specifically, we split the attention\ncalculation into intra-blocks and inter-blocks and use conventional attention\ncomputation for intra-blocks and linear attention kernel tricks for\ninter-blocks. This eliminates the need for cumsum in the linear attention\ncalculation. Furthermore, a tiling technique is adopted through both forward\nand backward procedures to take full advantage of the GPU hardware. To enhance\naccuracy while preserving efficacy, we introduce TransNormerLLM (TNL), a new\narchitecture that is tailored to our lightning attention. We conduct rigorous\ntesting on standard and self-collected datasets with varying model sizes and\nsequence lengths. TNL is notably more efficient than other language models. In\naddition, benchmark results indicate that TNL performs on par with\nstate-of-the-art LLMs utilizing conventional transformer structures. The source\ncode is released at github.com/OpenNLPLab/TransnormerLLM.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Zhen Qin",
            "Weigao Sun",
            "Dong Li",
            "Xuyang Shen",
            "Weixuan Sun",
            "Yiran Zhong"
        ],
        "published": "2024-05-27T17:38:13Z"
    },
    {
        "title": "RTL-Repo: A Benchmark for Evaluating LLMs on Large-Scale RTL Design\n  Projects",
        "link": "http://arxiv.org/abs/2405.17378v1",
        "abstract": "Large Language Models (LLMs) have demonstrated potential in assisting with\nRegister Transfer Level (RTL) design tasks. Nevertheless, there remains to be a\nsignificant gap in benchmarks that accurately reflect the complexity of\nreal-world RTL projects. To address this, this paper presents RTL-Repo, a\nbenchmark specifically designed to evaluate LLMs on large-scale RTL design\nprojects. RTL-Repo includes a comprehensive dataset of more than 4000 Verilog\ncode samples extracted from public GitHub repositories, with each sample\nproviding the full context of the corresponding repository. We evaluate several\nstate-of-the-art models on the RTL-Repo benchmark, including GPT-4, GPT-3.5,\nStarcoder2, alongside Verilog-specific models like VeriGen and RTLCoder, and\ncompare their performance in generating Verilog code for complex projects. The\nRTL-Repo benchmark provides a valuable resource for the hardware design\ncommunity to assess and compare LLMs' performance in real-world RTL design\nscenarios and train LLMs specifically for Verilog code generation in complex,\nmulti-file RTL projects. RTL-Repo is open-source and publicly available on\nGithub.",
        "subjects": [
            "cs.LG",
            "cs.AR"
        ],
        "authors": [
            "Ahmed Allam",
            "Mohamed Shalan"
        ],
        "published": "2024-05-27T17:36:01Z"
    },
    {
        "title": "How Does Perfect Fitting Affect Representation Learning? On the Training\n  Dynamics of Representations in Deep Neural Networks",
        "link": "http://arxiv.org/abs/2405.17377v1",
        "abstract": "In this paper, we elucidate how representations in deep neural networks\n(DNNs) evolve during training. We focus on overparameterized learning settings\nwhere the training continues much after the trained DNN starts to perfectly fit\nits training data. We examine the evolution of learned representations along\nthe entire training process, including its perfect fitting regime, and with\nrespect to the epoch-wise double descent phenomenon. We explore the\nrepresentational similarity of DNN layers, each layer with respect to its own\nrepresentations throughout the training process. For this, we use two\nsimilarity metrics: (1) The centered kernel alignment (CKA) similarity; (2)\nSimilarity of decision regions of linear classifier probes that we train for\nthe DNN layers. Our extensive experiments discover training dynamics patterns\nthat can emerge in layers depending on the relative layer-depth, DNN width, and\narchitecture. We show that representations at the deeper layers evolve much\nmore in the training when an epoch-wise double descent occurs. For Vision\nTransformer, we show that the perfect fitting threshold creates a transition in\nthe evolution of representations across all the encoder blocks.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yuval Sharon",
            "Yehuda Dar"
        ],
        "published": "2024-05-27T17:33:03Z"
    },
    {
        "title": "Federating Dynamic Models using Early-Exit Architectures for Automatic\n  Speech Recognition on Heterogeneous Clients",
        "link": "http://arxiv.org/abs/2405.17376v1",
        "abstract": "Automatic speech recognition models require large amounts of speech\nrecordings for training. However, the collection of such data often is\ncumbersome and leads to privacy concerns. Federated learning has been widely\nused as an effective decentralized technique that collaboratively learns a\nshared prediction model while keeping the data local on different clients.\nUnfortunately, client devices often feature limited computation and\ncommunication resources leading to practical difficulties for large models. In\naddition, the heterogeneity that characterizes edge devices makes it\nsub-optimal to generate a single model that fits all of them. Differently from\nthe recent literature, where multiple models with different architectures are\nused, in this work, we propose using dynamical architectures which, employing\nearly-exit solutions, can adapt their processing (i.e. traversed layers)\ndepending on the input and on the operation conditions. This solution falls in\nthe realm of partial training methods and brings two benefits: a single model\nis used on a variety of devices; federating the models after local training is\nstraightforward. Experiments on public datasets show that our proposed approach\nis effective and can be combined with basic federated learning strategies.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Mohamed Nabih Ali",
            "Alessio Brutti",
            "Daniele Falavigna"
        ],
        "published": "2024-05-27T17:32:37Z"
    },
    {
        "title": "Navigating the Safety Landscape: Measuring Risks in Finetuning Large\n  Language Models",
        "link": "http://arxiv.org/abs/2405.17374v2",
        "abstract": "Safety alignment is the key to guiding the behaviors of large language models\n(LLMs) that are in line with human preferences and restrict harmful behaviors\nat inference time, but recent studies show that it can be easily compromised by\nfinetuning with only a few adversarially designed training examples. We aim to\nmeasure the risks in finetuning LLMs through navigating the LLM safety\nlandscape. We discover a new phenomenon observed universally in the model\nparameter space of popular open-source LLMs, termed as \"safety basin\": randomly\nperturbing model weights maintains the safety level of the original aligned\nmodel in its local neighborhood. Our discovery inspires us to propose the new\nVISAGE safety metric that measures the safety in LLM finetuning by probing its\nsafety landscape. Visualizing the safety landscape of the aligned model enables\nus to understand how finetuning compromises safety by dragging the model away\nfrom the safety basin. LLM safety landscape also highlights the system prompt's\ncritical role in protecting a model, and that such protection transfers to its\nperturbed variants within the safety basin. These observations from our safety\nlandscape research provide new insights for future work on LLM safety\ncommunity.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "ShengYun Peng",
            "Pin-Yu Chen",
            "Matthew Hull",
            "Duen Horng Chau"
        ],
        "published": "2024-05-27T17:31:56Z"
    },
    {
        "title": "BehaviorGPT: Smart Agent Simulation for Autonomous Driving with\n  Next-Patch Prediction",
        "link": "http://arxiv.org/abs/2405.17372v1",
        "abstract": "Simulating realistic interactions among traffic agents is crucial for\nefficiently validating the safety of autonomous driving systems. Existing\nleading simulators primarily use an encoder-decoder structure to encode the\nhistorical trajectories for future simulation. However, such a paradigm\ncomplicates the model architecture, and the manual separation of history and\nfuture trajectories leads to low data utilization. To address these challenges,\nwe propose Behavior Generative Pre-trained Transformers (BehaviorGPT), a\ndecoder-only, autoregressive architecture designed to simulate the sequential\nmotion of multiple agents. Crucially, our approach discards the traditional\nseparation between \"history\" and \"future,\" treating each time step as the\n\"current\" one, resulting in a simpler, more parameter- and data-efficient\ndesign that scales seamlessly with data and computation. Additionally, we\nintroduce the Next-Patch Prediction Paradigm (NP3), which enables models to\nreason at the patch level of trajectories and capture long-range\nspatial-temporal interactions. BehaviorGPT ranks first across several metrics\non the Waymo Sim Agents Benchmark, demonstrating its exceptional performance in\nmulti-agent and agent-map interactions. We outperformed state-of-the-art models\nwith a realism score of 0.741 and improved the minADE metric to 1.540, with an\napproximately 91.6% reduction in model parameters.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ],
        "authors": [
            "Zikang Zhou",
            "Haibo Hu",
            "Xinhong Chen",
            "Jianping Wang",
            "Nan Guan",
            "Kui Wu",
            "Yung-Hui Li",
            "Yu-Kai Huang",
            "Chun Jason Xue"
        ],
        "published": "2024-05-27T17:28:25Z"
    },
    {
        "title": "Model-Agnostic Zeroth-Order Policy Optimization for Meta-Learning of\n  Ergodic Linear Quadratic Regulators",
        "link": "http://arxiv.org/abs/2405.17370v1",
        "abstract": "Meta-learning has been proposed as a promising machine learning topic in\nrecent years, with important applications to image classification, robotics,\ncomputer games, and control systems. In this paper, we study the problem of\nusing meta-learning to deal with uncertainty and heterogeneity in ergodic\nlinear quadratic regulators. We integrate the zeroth-order optimization\ntechnique with a typical meta-learning method, proposing an algorithm that\nomits the estimation of policy Hessian, which applies to tasks of learning a\nset of heterogeneous but similar linear dynamic systems. The induced\nmeta-objective function inherits important properties of the original cost\nfunction when the set of linear dynamic systems are meta-learnable, allowing\nthe algorithm to optimize over a learnable landscape without projection onto\nthe feasible set. We provide a convergence result for the exact gradient\ndescent process by analyzing the boundedness and smoothness of the gradient for\nthe meta-objective, which justify the proposed algorithm with gradient\nestimation error being small. We also provide a numerical example to\ncorroborate this perspective.",
        "subjects": [
            "eess.SY",
            "cs.LG",
            "cs.SY"
        ],
        "authors": [
            "Yunian Pan",
            "Quanyan Zhu"
        ],
        "published": "2024-05-27T17:26:36Z"
    },
    {
        "title": "Predict joint angle of body parts based on sequence pattern recognition",
        "link": "http://dx.doi.org/10.1109/IMCOM53663.2022.9721801",
        "abstract": "The way organs are positioned and moved in the workplace can cause pain and\nphysical harm. Therefore, ergonomists use ergonomic risk assessments based on\nvisual observation of the workplace, or review pictures and videos taken in the\nworkplace. Sometimes the workers in the photos are not in perfect condition.\nSome parts of the workers' bodies may not be in the camera's field of view,\ncould be obscured by objects, or by self-occlusion, this is the main problem in\n2D human posture recognition. It is difficult to predict the position of body\nparts when they are not visible in the image, and geometric mathematical\nmethods are not entirely suitable for this purpose. Therefore, we created a\ndataset with artificial images of a 3D human model, specifically for painful\npostures, and real human photos from different viewpoints. Each image we\ncaptured was based on a predefined joint angle for each 3D model or human\nmodel. We created various images, including images where some body parts are\nnot visible. Nevertheless, the joint angle is estimated beforehand, so we could\nstudy the case by converting the input images into the sequence of joint\nconnections between predefined body parts and extracting the desired joint\nangle with a convolutional neural network. In the end, we obtained root mean\nsquare error (RMSE) of 12.89 and mean absolute error (MAE) of 4.7 on the test\ndataset.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Amin Ahmadi Kasani",
            "Hedieh Sajedi"
        ],
        "published": "2024-05-27T17:24:11Z"
    },
    {
        "title": "Fusing uncalibrated IMUs and handheld smartphone video to reconstruct\n  knee kinematics",
        "link": "http://arxiv.org/abs/2405.17368v1",
        "abstract": "Video and wearable sensor data provide complementary information about human\nmovement. Video provides a holistic understanding of the entire body in the\nworld while wearable sensors provide high-resolution measurements of specific\nbody segments. A robust method to fuse these modalities and obtain\nbiomechanically accurate kinematics would have substantial utility for clinical\nassessment and monitoring. While multiple video-sensor fusion methods exist,\nmost assume that a time-intensive, and often brittle, sensor-body calibration\nprocess has already been performed. In this work, we present a method to\ncombine handheld smartphone video and uncalibrated wearable sensor data at\ntheir full temporal resolution. Our monocular, video-only, biomechanical\nreconstruction already performs well, with only several degrees of error at the\nknee during walking compared to markerless motion capture. Reconstructing from\na fusion of video and wearable sensor data further reduces this error. We\nvalidate this in a mixture of people with no gait impairments, lower limb\nprosthesis users, and individuals with a history of stroke. We also show that\nsensor data allows tracking through periods of visual occlusion.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "J. D. Peiffer",
            "Kunal Shah",
            "Shawana Anarwala",
            "Kayan Abdou",
            "R. James Cotton"
        ],
        "published": "2024-05-27T17:23:16Z"
    },
    {
        "title": "EM-GANSim: Real-time and Accurate EM Simulation Using Conditional GANs\n  for 3D Indoor Scenes",
        "link": "http://arxiv.org/abs/2405.17366v1",
        "abstract": "We present a novel machine-learning (ML) approach (EM-GANSim) for real-time\nelectromagnetic (EM) propagation that is used for wireless communication\nsimulation in 3D indoor environments. Our approach uses a modified conditional\nGenerative Adversarial Network (GAN) that incorporates encoded geometry and\ntransmitter location while adhering to the electromagnetic propagation theory.\nThe overall physically-inspired learning is able to predict the power\ndistribution in 3D scenes, which is represented using heatmaps. Our overall\naccuracy is comparable to ray tracing-based EM simulation, as evidenced by\nlower mean squared error values. Furthermore, our GAN-based method drastically\nreduces the computation time, achieving a 5X speedup on complex benchmarks. In\npractice, it can compute the signal strength in a few milliseconds on any\nlocation in 3D indoor environments. We also present a large dataset of 3D\nmodels and EM ray tracing-simulated heatmaps. To the best of our knowledge,\nEM-GANSim is the first real-time algorithm for EM simulation in complex 3D\nindoor environments. We plan to release the code and the dataset.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "authors": [
            "Ruichen Wang",
            "Dinesh Manocha"
        ],
        "published": "2024-05-27T17:19:02Z"
    },
    {
        "title": "DR-CGRA: Supporting Loop-Carried Dependencies in CGRAs Without Spilling\n  Intermediate Values",
        "link": "http://arxiv.org/abs/2405.17365v1",
        "abstract": "Coarse-grain reconfigurable architectures (CGRAs) are gaining traction thanks\nto their performance and power efficiency. Utilizing CGRAs to accelerate the\nexecution of tight loops holds great potential for achieving significant\noverall performance gains, as a substantial portion of program execution time\nis dedicated to tight loops. But loop parallelization using CGRAs is\nchallenging because of loop-carried data dependencies. Traditionally,\nloop-carried dependencies are handled by spilling dependent values out of the\nreconfigurable array to a memory medium and then feeding them back to the grid.\nSpilling the values and feeding them back into the grid imposes additional\nlatencies and logic that impede performance and limit parallelism.\n  In this paper, we present the Dependency Resolved CGRA (DR-CGRA) architecture\nthat is designed to accelerate the execution of tight loops. DR-CGRA, which is\nbased on a massively-multithreaded CGRA, runs each iteration as a separate CGRA\nthread and maps loop-carried data dependencies to inter-thread communication\ninside the grid. This design ensures the passage of data-dependent values\nacross loop iterations without spilling them out of the grid.\n  The proposed DR-CGRA architecture was evaluated on various SPEC CPU 2017\nbenchmarks. The results demonstrated significant performance improvements, with\nan average speedup ranging from 2.1 to 4.5 and an overall average of 3.1 when\ncompared to state-of-the-art CGRA architecture.",
        "subjects": [
            "cs.AR"
        ],
        "authors": [
            "Elad Hadar",
            "Yoav Etsion"
        ],
        "published": "2024-05-27T17:15:58Z"
    },
    {
        "title": "Optimized thread-block arrangement in a GPU implementation of a linear\n  solver for atmospheric chemistry mechanisms",
        "link": "http://dx.doi.org/10.1016/j.cpc.2024.109240",
        "abstract": "Earth system models (ESM) demand significant hardware resources and energy\nconsumption to solve atmospheric chemistry processes. Recent studies have shown\nimproved performance from running these models on GPU accelerators.\nNonetheless, there is room for improvement in exploiting even more GPU\nresources.\n  This study proposes an optimized distribution of the chemical solver's\ncomputational load on the GPU, named Block-cells. Additionally, we evaluate\ndifferent configurations for distributing the computational load in an NVIDIA\nGPU.\n  We use the linear solver from the Chemistry Across Multiple Phases (CAMP)\nframework as our test bed. An intermediate-complexity chemical mechanism under\ntypical atmospheric conditions is used. Results demonstrate a 35x speedup\ncompared to the single-CPU thread reference case. Even using the full resources\nof the node (40 physical cores) on the reference case, the Block-cells version\noutperforms them by 50%. The Block-cells approach shows promise in alleviating\nthe computational burden of chemical solvers on GPU architectures.",
        "subjects": [
            "cs.AR",
            "cs.DC",
            "cs.PF",
            "cs.SE"
        ],
        "authors": [
            "Christian Guzman Ruiz",
            "Mario Acosta",
            "Oriol Jorba",
            "Eduardo Cesar Galobardes",
            "Matthew Dawson",
            "Guillermo Oyarzun",
            "Carlos Prez Garca-Pando",
            "Kim Serradell"
        ],
        "published": "2024-05-27T17:12:59Z"
    },
    {
        "title": "A One-Layer Decoder-Only Transformer is a Two-Layer RNN: With an\n  Application to Certified Robustness",
        "link": "http://arxiv.org/abs/2405.17361v1",
        "abstract": "This paper reveals a key insight that a one-layer decoder-only Transformer is\nequivalent to a two-layer Recurrent Neural Network (RNN). Building on this\ninsight, we propose ARC-Tran, a novel approach for verifying the robustness of\ndecoder-only Transformers against arbitrary perturbation spaces. Compared to\nARC-Tran, current robustness verification techniques are limited either to\nspecific and length-preserving perturbations like word substitutions or to\nrecursive models like LSTMs. ARC-Tran addresses these limitations by\nmeticulously managing position encoding to prevent mismatches and by utilizing\nour key insight to achieve precise and scalable verification. Our evaluation\nshows that ARC-Tran (1) trains models more robust to arbitrary perturbation\nspaces than those produced by existing techniques and (2) shows high\ncertification accuracy of the resulting models.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yuhao Zhang",
            "Aws Albarghouthi",
            "Loris D'Antoni"
        ],
        "published": "2024-05-27T17:10:04Z"
    },
    {
        "title": "Rethinking Transformers in Solving POMDPs",
        "link": "http://arxiv.org/abs/2405.17358v3",
        "abstract": "Sequential decision-making algorithms such as reinforcement learning (RL) in\nreal-world scenarios inevitably face environments with partial observability.\nThis paper scrutinizes the effectiveness of a popular architecture, namely\nTransformers, in Partially Observable Markov Decision Processes (POMDPs) and\nreveals its theoretical limitations. We establish that regular languages, which\nTransformers struggle to model, are reducible to POMDPs. This poses a\nsignificant challenge for Transformers in learning POMDP-specific inductive\nbiases, due to their lack of inherent recurrence found in other models like\nRNNs. This paper casts doubt on the prevalent belief in Transformers as\nsequence models for RL and proposes to introduce a point-wise recurrent\nstructure. The Deep Linear Recurrent Unit (LRU) emerges as a well-suited\nalternative for Partially Observable RL, with empirical results highlighting\nthe sub-optimal performance of the Transformer and considerable strength of\nLRU.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Chenhao Lu",
            "Ruizhe Shi",
            "Yuyao Liu",
            "Kaizhe Hu",
            "Simon S. Du",
            "Huazhe Xu"
        ],
        "published": "2024-05-27T17:02:35Z"
    },
    {
        "title": "DoRA: Enhancing Parameter-Efficient Fine-Tuning with Dynamic Rank\n  Distribution",
        "link": "http://arxiv.org/abs/2405.17357v2",
        "abstract": "Fine-tuning large-scale pre-trained models is inherently a resource-intensive\ntask. While it can enhance the capabilities of the model, it also incurs\nsubstantial computational costs, posing challenges to the practical application\nof downstream tasks. Existing parameter-efficient fine-tuning (PEFT) methods\nsuch as Low-Rank Adaptation (LoRA) rely on a bypass framework that ignores the\ndifferential parameter budget requirements across weight matrices, which may\nlead to suboptimal fine-tuning outcomes. To address this issue, we introduce\nthe Dynamic Low-Rank Adaptation (DoRA) method. DoRA decomposes high-rank LoRA\nlayers into structured single-rank components, allowing for dynamic pruning of\nparameter budget based on their importance to specific tasks during training,\nwhich makes the most of the limited parameter budget. Experimental results\ndemonstrate that DoRA can achieve competitive performance compared with LoRA\nand full model fine-tuning, and outperform various strong baselines with the\nsame storage parameter budget. Our code is available at\nhttps://github.com/MIkumikumi0116/DoRA",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yulong Mao",
            "Kaiyu Huang",
            "Changhao Guan",
            "Ganglin Bao",
            "Fengran Mo",
            "Jinan Xu"
        ],
        "published": "2024-05-27T17:02:27Z"
    },
    {
        "title": "Assessing the significance of longitudinal data in Alzheimer's Disease\n  forecasting",
        "link": "http://arxiv.org/abs/2405.17352v1",
        "abstract": "In this study, we employ a transformer encoder model to characterize the\nsignificance of longitudinal patient data for forecasting the progression of\nAlzheimer's Disease (AD). Our model, Longitudinal Forecasting Model for\nAlzheimer's Disease (LongForMAD), harnesses the comprehensive temporal\ninformation embedded in sequences of patient visits that incorporate multimodal\ndata, providing a deeper understanding of disease progression than can be drawn\nfrom single-visit data alone. We present an empirical analysis across two\npatient groups-Cognitively Normal (CN) and Mild Cognitive Impairment (MCI)-over\na span of five follow-up years. Our findings reveal that models incorporating\nmore extended patient histories can outperform those relying solely on present\ninformation, suggesting a deeper historical context is critical in enhancing\npredictive accuracy for future AD progression. Our results support the\nincorporation of longitudinal data in clinical settings to enhance the early\ndetection and monitoring of AD. Our code is available at\n\\url{https://github.com/batuhankmkaraman/LongForMAD}.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Batuhan K. Karaman",
            "Mert R. Sabuncu"
        ],
        "published": "2024-05-27T16:55:48Z"
    },
    {
        "title": "DOF-GS: Adjustable Depth-of-Field 3D Gaussian Splatting for\n  Refocusing,Defocus Rendering and Blur Removal",
        "link": "http://arxiv.org/abs/2405.17351v1",
        "abstract": "3D Gaussian Splatting-based techniques have recently advanced 3D scene\nreconstruction and novel view synthesis, achieving high-quality real-time\nrendering. However, these approaches are inherently limited by the underlying\npinhole camera assumption in modeling the images and hence only work for\nAll-in-Focus (AiF) sharp image inputs. This severely affects their\napplicability in real-world scenarios where images often exhibit defocus blur\ndue to the limited depth-of-field (DOF) of imaging devices. Additionally,\nexisting 3D Gaussian Splatting (3DGS) methods also do not support rendering of\nDOF effects.\n  To address these challenges, we introduce DOF-GS that allows for rendering\nadjustable DOF effects, removing defocus blur as well as refocusing of 3D\nscenes, all from multi-view images degraded by defocus blur. To this end, we\nre-imagine the traditional Gaussian Splatting pipeline by employing a finite\naperture camera model coupled with explicit, differentiable defocus rendering\nguided by the Circle-of-Confusion (CoC). The proposed framework provides for\ndynamic adjustment of DOF effects by changing the aperture and focal distance\nof the underlying camera model on-demand. It also enables rendering varying DOF\neffects of 3D scenes post-optimization, and generating AiF images from\ndefocused training images. Furthermore, we devise a joint optimization strategy\nto further enhance details in the reconstructed scenes by jointly optimizing\nrendered defocused and AiF images. Our experimental results indicate that\nDOF-GS produces high-quality sharp all-in-focus renderings conditioned on\ninputs compromised by defocus blur, with the training process incurring only a\nmodest increase in GPU memory consumption. We further demonstrate the\napplications of the proposed method for adjustable defocus rendering and\nrefocusing of the 3D scene from input images degraded by defocus blur.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yujie Wang",
            "Praneeth Chakravarthula",
            "Baoquan Chen"
        ],
        "published": "2024-05-27T16:54:49Z"
    },
    {
        "title": "Prompt Optimization with Human Feedback",
        "link": "http://arxiv.org/abs/2405.17346v1",
        "abstract": "Large language models (LLMs) have demonstrated remarkable performances in\nvarious tasks. However, the performance of LLMs heavily depends on the input\nprompt, which has given rise to a number of recent works on prompt\noptimization. However, previous works often require the availability of a\nnumeric score to assess the quality of every prompt. Unfortunately, when a\nhuman user interacts with a black-box LLM, attaining such a score is often\ninfeasible and unreliable. Instead, it is usually significantly easier and more\nreliable to obtain preference feedback from a human user, i.e., showing the\nuser the responses generated from a pair of prompts and asking the user which\none is preferred. Therefore, in this paper, we study the problem of prompt\noptimization with human feedback (POHF), in which we aim to optimize the prompt\nfor a black-box LLM using only human preference feedback. Drawing inspiration\nfrom dueling bandits, we design a theoretically principled strategy to select a\npair of prompts to query for preference feedback in every iteration, and hence\nintroduce our algorithm named automated POHF (APOHF). We apply our APOHF\nalgorithm to various tasks, including optimizing user instructions, prompt\noptimization for text-to-image generative models, and response optimization\nwith human feedback (i.e., further refining the response using a variant of our\nAPOHF). The results demonstrate that our APOHF can efficiently find a good\nprompt using a small number of preference feedback instances. Our code can be\nfound at \\url{https://github.com/xqlin98/APOHF}.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Xiaoqiang Lin",
            "Zhongxiang Dai",
            "Arun Verma",
            "See-Kiong Ng",
            "Patrick Jaillet",
            "Bryan Kian Hsiang Low"
        ],
        "published": "2024-05-27T16:49:29Z"
    },
    {
        "title": "Exploring and steering the moral compass of Large Language Models",
        "link": "http://arxiv.org/abs/2405.17345v1",
        "abstract": "Large Language Models (LLMs) have become central to advancing automation and\ndecision-making across various sectors, raising significant ethical questions.\nThis study proposes a comprehensive comparative analysis of the most advanced\nLLMs to assess their moral profiles. We subjected several state-of-the-art\nmodels to a selection of ethical dilemmas and found that all the proprietary\nones are mostly utilitarian and all of the open-weights ones align mostly with\nvalues-based ethics. Furthermore, when using the Moral Foundations\nQuestionnaire, all models we probed - except for Llama 2- displayed a strong\nliberal bias. Lastly, in order to causally intervene in one of the studied\nmodels, we propose a novel similarity-specific activation steering technique.\nUsing this method, we were able to reliably steer the model's moral compass to\ndifferent ethical schools. All of these results showcase that there is an\nethical dimension in already deployed LLMs, an aspect that is generally\noverlooked.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Alejandro Tlaie"
        ],
        "published": "2024-05-27T16:49:22Z"
    },
    {
        "title": "Measuring Exploration: Review and Systematic Evaluation of Modelling to\n  Generate Alternatives Methods in Macro-Energy Systems Planning Models",
        "link": "http://dx.doi.org/10.5281/zenodo.11088681",
        "abstract": "As decarbonization agendas mature, macro-energy systems modelling studies\nhave increasingly focused on enhanced decision support methods that move beyond\nleast-cost modelling to improve consideration of additional objectives and\ntradeoffs. One candidate is Modeling to Generate Alternatives (MGA), which\nsystematically explores new objectives without explicit stakeholder\nelicitation. Previous literature lacks both a comprehensive review of MGA\nvector selection methods in large-scale energy system models and comparative\ntesting of their relative efficacies in this setting. To fill this gap, this\npaper provides a comprehensive review of the MGA literature, identifying at\nleast seven MGA vector selection methodologies and carrying out a systematic\nevaluation of four: Hop-Skip-Jump, Random Vector, Variable Min/Max, and\nModelling All Alternatives. We examine each method's runtime,\nparallelizability, new solution discovery efficiency, and spatial exploration\nin lower dimensional (N <= 100) spaces, as well as spatial exploration in a\nthree-zone, 8760-hour capacity expansion model case. Through these tests, we\nfind Random Vector provides the broadest exploration of the near-optimal\nfeasible region and Variable Min/Max provides the most extreme results, while\nthe two tie on computational speed. We thus propose a new Hybrid vector\nselection approach combining the two methods to take advantage of the strengths\nof each. Additional analysis is provided on MGA variable selection, in which we\ndemonstrate MGA problems formulated over generation variables fail to retain\ncost-optimal dispatch and are thus not reflective of real operations of\nequivalent hypothetical capacity choices. As such, we recommend future studies\nutilize a parallelized combined vector approach over the set of capacity\nvariables for best results in computational speed and spatial exploration while\nretaining optimal dispatch.",
        "subjects": [
            "math.OC",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Michael Lau",
            "Neha Patankar",
            "Jesse D. Jenkins"
        ],
        "published": "2024-05-27T16:48:42Z"
    },
    {
        "title": "Physics-Informed Real NVP for Satellite Power System Fault Detection",
        "link": "http://arxiv.org/abs/2405.17339v1",
        "abstract": "The unique challenges posed by the space environment, characterized by\nextreme conditions and limited accessibility, raise the need for robust and\nreliable techniques to identify and prevent satellite faults. Fault detection\nmethods in the space sector are required to ensure mission success and to\nprotect valuable assets. In this context, this paper proposes an Artificial\nIntelligence (AI) based fault detection methodology and evaluates its\nperformance on ADAPT (Advanced Diagnostics and Prognostics Testbed), an\nElectrical Power System (EPS) dataset, crafted in laboratory by NASA.\n  Our study focuses on the application of a physics-informed (PI) real-valued\nnon-volume preserving (Real NVP) model for fault detection in space systems.\nThe efficacy of this method is systematically compared against other AI\napproaches such as Gated Recurrent Unit (GRU) and Autoencoder-based techniques.\n  Results show that our physics-informed approach outperforms existing methods\nof fault detection, demonstrating its suitability for addressing the unique\nchallenges of satellite EPS sub-system faults. Furthermore, we unveil the\ncompetitive advantage of physics-informed loss in AI models to address specific\nspace needs, namely robustness, reliability, and power constraints, crucial for\nspace exploration and satellite missions.",
        "subjects": [
            "cs.LG",
            "cs.RO"
        ],
        "authors": [
            "Carlo Cena",
            "Umberto Albertin",
            "Mauro Martini",
            "Silvia Bucci",
            "Marcello Chiaberge"
        ],
        "published": "2024-05-27T16:42:51Z"
    },
    {
        "title": "Cost-efficient Knowledge-based Question Answering with Large Language\n  Models",
        "link": "http://arxiv.org/abs/2405.17337v1",
        "abstract": "Knowledge-based question answering (KBQA) is widely used in many scenarios\nthat necessitate domain knowledge. Large language models (LLMs) bring\nopportunities to KBQA, while their costs are significantly higher and absence\nof domain-specific knowledge during pre-training. We are motivated to combine\nLLMs and prior small models on knowledge graphs (KGMs) for both inferential\naccuracy and cost saving. However, it remains challenging since accuracy and\ncost are not readily combined in the optimization as two distinct metrics. It\nis also laborious for model selection since different models excel in diverse\nknowledge. To this end, we propose Coke, a novel cost-efficient strategy for\nKBQA with LLMs, modeled as a tailored multi-armed bandit problem to minimize\ncalls to LLMs within limited budgets. We first formulate the accuracy\nexpectation with a cluster-level Thompson Sampling for either KGMs or LLMs. A\ncontext-aware policy is optimized to further distinguish the expert model\nsubject to the question semantics. The overall decision is bounded by the cost\nregret according to historical expenditure on failures. Extensive experiments\nshowcase the superior performance of Coke, which moves the Pareto frontier with\nup to 20.89% saving of GPT-4 fees while achieving a 2.74% higher accuracy on\nthe benchmark datasets.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Junnan Dong",
            "Qinggang Zhang",
            "Chuang Zhou",
            "Hao Chen",
            "Daochen Zha",
            "Xiao Huang"
        ],
        "published": "2024-05-27T16:37:34Z"
    },
    {
        "title": "XFormParser: A Simple and Effective Multimodal Multilingual\n  Semi-structured Form Parser",
        "link": "http://arxiv.org/abs/2405.17336v1",
        "abstract": "In the domain of document AI, semi-structured form parsing plays a crucial\nrole. This task leverages techniques from key information extraction (KIE),\ndealing with inputs that range from plain text to intricate modal data\ncomprising images and structural layouts. The advent of pre-trained multimodal\nmodels has driven the extraction of key information from form documents in\ndifferent formats such as PDFs and images. Nonetheless, the endeavor of form\nparsing is still encumbered by notable challenges like subpar capabilities in\nmulti-lingual parsing and diminished recall in contexts rich in text and\nvisuals. In this work, we introduce a simple but effective \\textbf{M}ultimodal\nand \\textbf{M}ultilingual semi-structured \\textbf{FORM} \\textbf{PARSER}\n(\\textbf{XFormParser}), which is anchored on a comprehensive pre-trained\nlanguage model and innovatively amalgamates semantic entity recognition (SER)\nand relation extraction (RE) into a unified framework, enhanced by a novel\nstaged warm-up training approach that employs soft labels to significantly\nrefine form parsing accuracy without amplifying inference overhead.\nFurthermore, we have developed a groundbreaking benchmark dataset, named\nInDFormBench, catering specifically to the parsing requirements of multilingual\nforms in various industrial contexts. Through rigorous testing on established\nmultilingual benchmarks and InDFormBench, XFormParser has demonstrated its\nunparalleled efficacy, notably surpassing the state-of-the-art (SOTA) models in\nRE tasks within language-specific setups by achieving an F1 score improvement\nof up to 1.79\\%. Our framework exhibits exceptionally improved performance\nacross tasks in both multi-language and zero-shot contexts when compared to\nexisting SOTA benchmarks. The code is publicly available at\nhttps://github.com/zhbuaa0/layoutlmft.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Xianfu Cheng",
            "Hang Zhang",
            "Jian Yang",
            "Xiang Li",
            "Weixiao Zhou",
            "Kui Wu",
            "Fei Liu",
            "Wei Zhang",
            "Tao Sun",
            "Tongliang Li",
            "Zhoujun Li"
        ],
        "published": "2024-05-27T16:37:17Z"
    },
    {
        "title": "Serial Monopoly on Blockchains with Quasi-patient Users",
        "link": "http://arxiv.org/abs/2405.17334v1",
        "abstract": "This paper introduces and investigates an extension of the price dynamics in\nserial monopoly blockchain described in Nisan [Nis23], tailored to accommodate\nquasi-patient users. Our model reflects users' diminishing interest in having\ntheir transactions added to the ledger over time, resulting in only a fraction\n$\\delta$ of the current demand persisting in the subsequent round. The\nframework presented by Lavi et al. [LSZ22], where users are impatient and\nderive utility only from immediate transaction inclusion in the next block,\ncorresponds to $\\delta=0$. Fully patient users who wait forever as in [Nis23],\ncorrespond to $\\delta=1$ in our model. This work provides new bounds on the\nprice dynamics for the more interesting case $\\delta\\in(0,1)$, showing somewhat\nunexpected effects on the dynamics itself. While the dynamics for the fully\npatient case is essentially \"oblivious\" of the structure of the daily demand\ncurve, this is no longer true for finite $\\delta < 1$. Moreover, the dynamics\nundergoes a \"transition phase\" where for some $\\delta$ it behaves as in the\nfully patient setting ($\\delta=1$), and for some smaller values\n$\\delta'<\\delta$ it stops \"oscillating\" and stays at the highest (\"monopolist\")\nprice. We provide quantitative bounds and analytical results that apply to\ndifferent demand functions showing that the bounds for $\\delta=1$ are not tight\nin general, for $\\delta<1$. These provide guarantees on the minimum\n(\"admission\") price such that transaction willing to pay that price are\neventually included (and those who do not want are never included).",
        "subjects": [
            "cs.GT"
        ],
        "authors": [
            "Paolo Penna",
            "Manvir Schneider"
        ],
        "published": "2024-05-27T16:35:00Z"
    },
    {
        "title": "Conditioning on Time is All You Need for Synthetic Survival Data\n  Generation",
        "link": "http://arxiv.org/abs/2405.17333v1",
        "abstract": "Synthetic data generation holds considerable promise, offering avenues to\nenhance privacy, fairness, and data accessibility. Despite the availability of\nvarious methods for generating synthetic tabular data, challenges persist,\nparticularly in specialized applications such as survival analysis. One\nsignificant obstacle in survival data generation is censoring, which manifests\nas not knowing the precise timing of observed (target) events for certain\ninstances. Existing methods face difficulties in accurately reproducing the\nreal distribution of event times for both observed (uncensored) events and\ncensored events, i.e., the generated event-time distributions do not accurately\nmatch the underlying distributions of the real data. So motivated, we propose a\nsimple paradigm to produce synthetic survival data by generating covariates\nconditioned on event times (and censoring indicators), thus allowing one to\nreuse existing conditional generative models for tabular data without\nsignificant computational overhead, and without making assumptions about the\n(usually unknown) generation mechanism underlying censoring. We evaluate this\nmethod via extensive experiments on real-world datasets. Our methodology\noutperforms multiple competitive baselines at generating survival data, while\nimproving the performance of downstream survival models trained on it and\ntested on real data.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Mohd Ashhad",
            "Ricardo Henao"
        ],
        "published": "2024-05-27T16:34:18Z"
    },
    {
        "title": "Clip Body and Tail Separately: High Probability Guarantees for DPSGD\n  with Heavy Tails",
        "link": "http://arxiv.org/abs/2405.17529v1",
        "abstract": "Differentially Private Stochastic Gradient Descent (DPSGD) is widely utilized\nto preserve training data privacy in deep learning, which first clips the\ngradients to a predefined norm and then injects calibrated noise into the\ntraining procedure. Existing DPSGD works typically assume the gradients follow\nsub-Gaussian distributions and design various clipping mechanisms to optimize\ntraining performance. However, recent studies have shown that the gradients in\ndeep learning exhibit a heavy-tail phenomenon, that is, the tails of the\ngradient have infinite variance, which may lead to excessive clipping loss to\nthe gradients with existing DPSGD mechanisms. To address this problem, we\npropose a novel approach, Discriminative Clipping~(DC)-DPSGD, with two key\ndesigns. First, we introduce a subspace identification technique to distinguish\nbetween body and tail gradients. Second, we present a discriminative clipping\nmechanism that applies different clipping thresholds for body and tail\ngradients to reduce the clipping loss. Under the non-convex condition,\n\\ourtech{} reduces the empirical gradient norm from\n{${\\mathbb{O}\\left(\\log^{\\max(0,\\theta-1)}(T/\\delta)\\log^{2\\theta}(\\sqrt{T})\\right)}$}\nto {${\\mathbb{O}\\left(\\log(\\sqrt{T})\\right)}$} with heavy-tailed index\n$\\theta\\geq 1/2$, iterations $T$, and arbitrary probability $\\delta$. Extensive\nexperiments on four real-world datasets demonstrate that our approach\noutperforms three baselines by up to 9.72\\% in terms of accuracy.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "authors": [
            "Haichao Sha",
            "Yang Cao",
            "Yong Liu",
            "Yuncheng Wu",
            "Ruixuan Liu",
            "Hong Chen"
        ],
        "published": "2024-05-27T16:30:11Z"
    },
    {
        "title": "Joint MIMO Transceiver and Reflector Design for Reconfigurable\n  Intelligent Surface-Assisted Communication",
        "link": "http://arxiv.org/abs/2405.17329v1",
        "abstract": "In this paper, we consider a reconfigurable intelligent surface\n(RIS)-assisted multiple-input multiple-output communication system with\nmultiple antennas at both the base station (BS) and the user. We plan to\nmaximize the achievable rate through jointly optimizing the transmit precoding\nmatrix, the receive combining matrix, and the RIS reflection matrix under the\nconstraints of the transmit power at the BS and the unit-modulus reflection at\nthe RIS. Regarding the non-trivial problem form, we initially reformulate it\ninto an considerable problem to make it tractable by utilizing the relationship\nbetween the achievable rate and the weighted minimum mean squared error. Next,\nthe transmit precoding matrix, the receive combining matrix, and the RIS\nreflection matrix are alternately optimized. In particular, the optimal\ntransmit precoding matrix and receive combining matrix are obtained in closed\nforms. Furthermore, a pair of computationally efficient methods are proposed\nfor the RIS reflection matrix, namely the semi-definite relaxation (SDR) method\nand the successive closed form (SCF) method. We theoretically prove that both\nmethods are ensured to converge, and the SCF-based algorithm is able to\nconverges to a Karush-Kuhn-Tucker point of the problem.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Yaqiong Zhao",
            "Jindan Xu",
            "Wei Xu",
            "Kezhi Wang",
            "Xinquan Ye",
            "Chau Yuen",
            "Xiaohu You"
        ],
        "published": "2024-05-27T16:28:37Z"
    },
    {
        "title": "Novel Approaches for ML-Assisted Particle Track Reconstruction and Hit\n  Clustering",
        "link": "http://arxiv.org/abs/2405.17325v1",
        "abstract": "Track reconstruction is a vital aspect of High-Energy Physics (HEP) and plays\na critical role in major experiments. In this study, we delve into unexplored\navenues for particle track reconstruction and hit clustering. Firstly, we\nenhance the algorithmic design effort by utilising a simplified simulator\n(REDVID) to generate training data that is specifically composed for\nsimplicity. We demonstrate the effectiveness of this data in guiding the\ndevelopment of optimal network architectures. Additionally, we investigate the\napplication of image segmentation networks for this task, exploring their\npotential for accurate track reconstruction. Moreover, we approach the task\nfrom a different perspective by treating it as a hit sequence to track sequence\ntranslation problem. Specifically, we explore the utilisation of Transformer\narchitectures for tracking purposes. Our preliminary findings are covered in\ndetail. By considering this novel approach, we aim to uncover new insights and\npotential advancements in track reconstruction. This research sheds light on\npreviously unexplored methods and provides valuable insights for the field of\nparticle track reconstruction and hit clustering in HEP.",
        "subjects": [
            "hep-ex",
            "cs.LG"
        ],
        "authors": [
            "Uraz Odyurt",
            "Nadezhda Dobreva",
            "Zef Wolffs",
            "Yue Zhao",
            "Antonio Ferrer Snchez",
            "Roberto Ruiz de Austri Bazan",
            "Jos D. Martn-Guerrero",
            "Ana-Lucia Varbanescu",
            "Sascha Caron"
        ],
        "published": "2024-05-27T16:23:50Z"
    },
    {
        "title": "Leveraging Offline Data in Linear Latent Bandits",
        "link": "http://arxiv.org/abs/2405.17324v1",
        "abstract": "Sequential decision-making domains such as recommender systems, healthcare\nand education often have unobserved heterogeneity in the population that can be\nmodeled using latent bandits $-$ a framework where an unobserved latent state\ndetermines the model for a trajectory. While the latent bandit framework is\ncompelling, the extent of its generality is unclear. We first address this by\nestablishing a de Finetti theorem for decision processes, and show that\n$\\textit{every}$ exchangeable and coherent stateless decision process is a\nlatent bandit. The latent bandit framework lends itself particularly well to\nonline learning with offline datasets, a problem of growing interest in\nsequential decision-making. One can leverage offline latent bandit data to\nlearn a complex model for each latent state, so that an agent can simply learn\nthe latent state online to act optimally. We focus on a linear model for a\nlatent bandit with $d_A$-dimensional actions, where the latent states lie in an\nunknown $d_K$-dimensional subspace for $d_K \\ll d_A$. We present SOLD, a novel\nprincipled method to learn this subspace from short offline trajectories with\nguarantees. We then provide two methods to leverage this subspace online:\nLOCAL-UCB and ProBALL-UCB. We demonstrate that LOCAL-UCB enjoys $\\tilde\nO(\\min(d_A\\sqrt{T}, d_K\\sqrt{T}(1+\\sqrt{d_AT/d_KN})))$ regret guarantees, where\nthe effective dimension is lower when the size $N$ of the offline dataset is\nlarger. ProBALL-UCB enjoys a slightly weaker guarantee, but is more practical\nand computationally efficient. Finally, we establish the efficacy of our\nmethods using experiments on both synthetic data and real-life movie\nrecommendation data from MovieLens.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Chinmaya Kausik",
            "Kevin Tan",
            "Ambuj Tewari"
        ],
        "published": "2024-05-27T16:23:34Z"
    },
    {
        "title": "Tracking Small Birds by Detection Candidate Region Filtering and\n  Detection History-aware Association",
        "link": "http://arxiv.org/abs/2405.17323v1",
        "abstract": "This paper focuses on tracking birds that appear small in a panoramic video.\nWhen the size of the tracked object is small in the image (small object\ntracking) and move quickly, object detection and association suffers. To\naddress these problems, we propose Adaptive Slicing Aided Hyper Inference\n(Adaptive SAHI), which reduces the candidate regions to apply detection, and\nDetection History-aware Similarity Criterion (DHSC), which accurately\nassociates objects in consecutive frames based on the detection history.\nExperiments on the NUBird2022 dataset verifies the effectiveness of the\nproposed method by showing improvements in both accuracy and speed.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Tingwei Liu",
            "Yasutomo Kawanishi",
            "Takahiro Komamizu",
            "Ichiro Ide"
        ],
        "published": "2024-05-27T16:22:38Z"
    },
    {
        "title": "Evaluation of computational and energy performance in matrix\n  multiplication algorithms on CPU and GPU using MKL, cuBLAS and SYCL",
        "link": "http://arxiv.org/abs/2405.17322v1",
        "abstract": "Matrix multiplication is fundamental in the backpropagation algorithm used to\ntrain deep neural network models. Libraries like Intel's MKL or NVIDIA's cuBLAS\nimplemented new and optimized matrix multiplication techniques that increase\nperformance and reduce computational costs. These techniques can also be\nimplemented in CUDA and SYCL and functions with AVX2 and AVX512 instructions,\nwhich have lower performance but better precision. The study compares execution\ntimes and power consumption using PAPI and PERF and compares accuracy for\ndifferent matrix sizes. Comparisons were made on architectures such as third\nand fourth-generation Intel CPUs and NVIDIA V100 and A100 GPUs. The MKL library\nshowed the best performance with a slight loss of precision, while OpenMP and\nSYCL on the CPU implementation showed the best accuracy but a loss of\nperformance. On the other hand, the results on GPU showed that cuBLAS with\ntensor cores had the best performance; however, it had a cost in accuracy. The\ncuBLAS library without these specialized cores shows minimal performance loss\nand much higher accuracy. The data obtained on different architectures showed\nthat the CPU could achieve performance close to that obtained on the GPU with\nincreased power consumption. These results are conditional on certain hardware\nspecifications, such as the number of cores, clock frequency, processor\ngeneration for the CPU, and the speed and bandwidth of the PCI bus and device\narchitecture (compute capability) for the GPU.",
        "subjects": [
            "cs.DC",
            "cs.AR"
        ],
        "authors": [
            "L. A. Torres",
            "Carlos J. Barrios H",
            "Yves Denneulin"
        ],
        "published": "2024-05-27T16:21:41Z"
    },
    {
        "title": "All-day Depth Completion",
        "link": "http://arxiv.org/abs/2405.17315v1",
        "abstract": "We propose a method for depth estimation under different illumination\nconditions, i.e., day and night time. As photometry is uninformative in regions\nunder low-illumination, we tackle the problem through a multi-sensor fusion\napproach, where we take as input an additional synchronized sparse point cloud\n(i.e., from a LiDAR) projected onto the image plane as a sparse depth map,\nalong with a camera image. The crux of our method lies in the use of the\nabundantly available synthetic data to first approximate the 3D scene structure\nby learning a mapping from sparse to (coarse) dense depth maps along with their\npredictive uncertainty - we term this, SpaDe. In poorly illuminated regions\nwhere photometric intensities do not afford the inference of local shape, the\ncoarse approximation of scene depth serves as a prior; the uncertainty map is\nthen used with the image to guide refinement through an uncertainty-driven\nresidual learning (URL) scheme. The resulting depth completion network\nleverages complementary strengths from both modalities - depth is sparse but\ninsensitive to illumination and in metric scale, and image is dense but\nsensitive with scale ambiguity. SpaDe can be used in a plug-and-play fashion,\nwhich allows for 25% improvement when augmented onto existing methods to\npreprocess sparse depth. We demonstrate URL on the nuScenes dataset where we\nimprove over all baselines by an average 11.65% in all-day scenarios, 11.23%\nwhen tested specifically for daytime, and 13.12% for nighttime scenes.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Vadim Ezhov",
            "Hyoungseob Park",
            "Zhaoyang Zhang",
            "Rishi Upadhyay",
            "Howard Zhang",
            "Chethan Chinder Chandrappa",
            "Achuta Kadambi",
            "Yunhao Ba",
            "Julie Dorsey",
            "Alex Wong"
        ],
        "published": "2024-05-27T16:16:53Z"
    },
    {
        "title": "Maximizing Phylogenetic Diversity under Ecological Constraints: A\n  Parameterized Complexity Study",
        "link": "http://arxiv.org/abs/2405.17314v1",
        "abstract": "In the NP-hard Optimizing PD with Dependencies (PDD) problem, the input\nconsists of a phylogenetic tree $T$ over a set of taxa $X$, a food-web that\ndescribes the prey-predator relationships in $X$, and integers $k$ and $D$. The\ntask is to find a set $S$ of $k$ species that is viable in the food-web such\nthat the subtree of $T$ obtained by retaining only the vertices of $S$ has\ntotal edge weight at least $D$. Herein, viable means that for every predator\ntaxon of $S$, the set $S$ contains at least one prey taxon. We provide the\nfirst systematic analysis of PDD and its special case s-PDD from a\nparameterized complexity perspective. For solution-size related parameters, we\nshow that PDD is FPT with respect to $D$ and with respect to $k$ plus the\nheight of the phylogenetic tree. Moreover, we consider structural\nparameterizations of the food-web. For example, we show an FPT-algorithm for\nthe parameter that measures the vertex deletion distance to graphs where every\nconnected component is a complete graph. Finally, we show that s-PDD admits an\nFPT-algorithm for the treewidth of the food-web. This disproves a conjecture of\nFaller et al. [Annals of Combinatorics, 2011] who conjectured that s-PDD is\nNP-hard even when the food-web is a tree.",
        "subjects": [
            "cs.CC"
        ],
        "authors": [
            "Christian Komusiewicz",
            "Jannik Schestag"
        ],
        "published": "2024-05-27T16:16:50Z"
    },
    {
        "title": "Probabilistic Graph Rewiring via Virtual Nodes",
        "link": "http://arxiv.org/abs/2405.17311v1",
        "abstract": "Message-passing graph neural networks (MPNNs) have emerged as a powerful\nparadigm for graph-based machine learning. Despite their effectiveness, MPNNs\nface challenges such as under-reaching and over-squashing, where limited\nreceptive fields and structural bottlenecks hinder information flow in the\ngraph. While graph transformers hold promise in addressing these issues, their\nscalability is limited due to quadratic complexity regarding the number of\nnodes, rendering them impractical for larger graphs. Here, we propose\n\\emph{implicitly rewired message-passing neural networks} (IPR-MPNNs), a novel\napproach that integrates \\emph{implicit} probabilistic graph rewiring into\nMPNNs. By introducing a small number of virtual nodes, i.e., adding additional\nnodes to a given graph and connecting them to existing nodes, in a\ndifferentiable, end-to-end manner, IPR-MPNNs enable long-distance message\npropagation, circumventing quadratic complexity. Theoretically, we demonstrate\nthat IPR-MPNNs surpass the expressiveness of traditional MPNNs. Empirically, we\nvalidate our approach by showcasing its ability to mitigate under-reaching and\nover-squashing effects, achieving state-of-the-art performance across multiple\ngraph datasets. Notably, IPR-MPNNs outperform graph transformers while\nmaintaining significantly faster computational efficiency.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Chendi Qian",
            "Andrei Manolache",
            "Christopher Morris",
            "Mathias Niepert"
        ],
        "published": "2024-05-27T16:11:49Z"
    },
    {
        "title": "Survey of Graph Neural Network for Internet of Things and NextG Networks",
        "link": "http://arxiv.org/abs/2405.17309v1",
        "abstract": "The exponential increase in Internet of Things (IoT) devices coupled with 6G\npushing towards higher data rates and connected devices has sparked a surge in\ndata. Consequently, harnessing the full potential of data-driven machine\nlearning has become one of the important thrusts. In addition to the\nadvancement in wireless technology, it is important to efficiently use the\nresources available and meet the users' requirements. Graph Neural Networks\n(GNNs) have emerged as a promising paradigm for effectively modeling and\nextracting insights which inherently exhibit complex network structures due to\nits high performance and accuracy, scalability, adaptability, and resource\nefficiency. There is a lack of a comprehensive survey that focuses on the\napplications and advances GNN has made in the context of IoT and Next\nGeneration (NextG) networks. To bridge that gap, this survey starts by\nproviding a detailed description of GNN's terminologies, architecture, and the\ndifferent types of GNNs. Then we provide a comprehensive survey of the\nadvancements in applying GNNs for IoT from the perspective of data fusion and\nintrusion detection. Thereafter, we survey the impact GNN has made in improving\nspectrum awareness. Next, we provide a detailed account of how GNN has been\nleveraged for networking and tactical systems. Through this survey, we aim to\nprovide a comprehensive resource for researchers to learn more about GNN in the\ncontext of wireless networks, and understand its state-of-the-art use cases\nwhile contrasting to other machine learning approaches. Finally, we also\ndiscussed the challenges and wide range of future research directions to\nfurther motivate the use of GNN for IoT and NextG Networks.",
        "subjects": [
            "cs.LG",
            "cs.NI"
        ],
        "authors": [
            "Sabarish Krishna Moorthy",
            "Jithin Jagannath"
        ],
        "published": "2024-05-27T16:10:49Z"
    },
    {
        "title": "Peer2PIR: Private Queries for IPFS",
        "link": "http://arxiv.org/abs/2405.17307v1",
        "abstract": "The InterPlanetary File System (IPFS) is a peer-to-peer network for storing\ndata in a distributed file system, hosting over 190,000 peers spanning 152\ncountries. Despite its prominence, the privacy properties that IPFS offers to\npeers are severely limited. Any query within the network leaks to other peers\nthe content for which a peer is querying. We address IPFS' privacy leakage\nacross three functionalities (peer routing, provider advertisements, and\ncontent retrieval), ultimately empowering peers to privately navigate and\nretrieve content in the network. We argue that private information retrieval\n(PIR) is the most suitable tool for our task. Our work highlights and addresses\nnovel challenges inherent to integrating PIR into distributed systems. We\npresent our new, private protocols and demonstrate that they incur minimal\noverheads compared to IPFS today. We also include a systematic comparison of\nstate-of-art PIR protocols in the context of distributed systems which may be\nof independent interest.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Miti Mazmudar",
            "Shannon Veitch",
            "Rasoul Akhavan Mahdavi"
        ],
        "published": "2024-05-27T16:09:25Z"
    },
    {
        "title": "Controllable Longer Image Animation with Diffusion Models",
        "link": "http://arxiv.org/abs/2405.17306v2",
        "abstract": "Generating realistic animated videos from static images is an important area\nof research in computer vision. Methods based on physical simulation and motion\nprediction have achieved notable advances, but they are often limited to\nspecific object textures and motion trajectories, failing to exhibit highly\ncomplex environments and physical dynamics. In this paper, we introduce an\nopen-domain controllable image animation method using motion priors with video\ndiffusion models. Our method achieves precise control over the direction and\nspeed of motion in the movable region by extracting the motion field\ninformation from videos and learning moving trajectories and strengths. Current\npretrained video generation models are typically limited to producing very\nshort videos, typically less than 30 frames. In contrast, we propose an\nefficient long-duration video generation method based on noise reschedule\nspecifically tailored for image animation tasks, facilitating the creation of\nvideos over 100 frames in length while maintaining consistency in content\nscenery and motion coordination. Specifically, we decompose the denoise process\ninto two distinct phases: the shaping of scene contours and the refining of\nmotion details. Then we reschedule the noise to control the generated frame\nsequences maintaining long-distance noise correlation. We conducted extensive\nexperiments with 10 baselines, encompassing both commercial tools and academic\nmethodologies, which demonstrate the superiority of our method. Our project\npage: https://wangqiang9.github.io/Controllable.github.io/",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Qiang Wang",
            "Minghua Liu",
            "Junjun Hu",
            "Fan Jiang",
            "Mu Xu"
        ],
        "published": "2024-05-27T16:08:00Z"
    },
    {
        "title": "Stochastic Omega-Regular Verification and Control with Supermartingales",
        "link": "http://arxiv.org/abs/2405.17304v1",
        "abstract": "We present for the first time a supermartingale certificate for\n$\\omega$-regular specifications. We leverage the Robbins & Siegmund convergence\ntheorem to characterize supermartingale certificates for the almost-sure\nacceptance of Streett conditions on general stochastic processes, which we call\nStreett supermartingales. This enables effective verification and control of\ndiscrete-time stochastic dynamical models with infinite state space under\n$\\omega$-regular and linear temporal logic specifications. Our result\ngeneralises reachability, safety, reach-avoid, persistence and recurrence\nspecifications; our contribution applies to discrete-time stochastic dynamical\nmodels and probabilistic programs with discrete and continuous state spaces and\ndistributions, and carries over to deterministic models and programs. We\nprovide a synthesis algorithm for control policies and Streett supermartingales\nas proof certificates for $\\omega$-regular objectives, which is sound and\ncomplete for supermartingales and control policies with polynomial templates\nand any stochastic dynamical model whose post-expectation is expressible as a\npolynomial. We additionally provide an optimisation of our algorithm that\nreduces the problem to satisfiability modulo theories, under the assumption\nthat templates and post-expectation are in piecewise linear form. We have built\na prototype and have demonstrated the efficacy of our approach on several\nexemplar $\\omega$-regular verification and control synthesis problems.",
        "subjects": [
            "cs.LO",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Alessandro Abate",
            "Mirco Giacobbe",
            "Diptarko Roy"
        ],
        "published": "2024-05-27T16:07:03Z"
    },
    {
        "title": "Simplicity Bias of Two-Layer Networks beyond Linearly Separable Data",
        "link": "http://arxiv.org/abs/2405.17299v1",
        "abstract": "Simplicity bias, the propensity of deep models to over-rely on simple\nfeatures, has been identified as a potential reason for limited\nout-of-distribution generalization of neural networks (Shah et al., 2020).\nDespite the important implications, this phenomenon has been theoretically\nconfirmed and characterized only under strong dataset assumptions, such as\nlinear separability (Lyu et al., 2021). In this work, we characterize\nsimplicity bias for general datasets in the context of two-layer neural\nnetworks initialized with small weights and trained with gradient flow.\nSpecifically, we prove that in the early training phases, network features\ncluster around a few directions that do not depend on the size of the hidden\nlayer. Furthermore, for datasets with an XOR-like pattern, we precisely\nidentify the learned features and demonstrate that simplicity bias intensifies\nduring later training stages. These results indicate that features learned in\nthe middle stages of training may be more useful for OOD transfer. We support\nthis hypothesis with experiments on image data.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Nikita Tsoy",
            "Nikola Konstantinov"
        ],
        "published": "2024-05-27T16:00:45Z"
    },
    {
        "title": "Coupling Light with Matter for Identifying Dominant Subnetworks",
        "link": "http://arxiv.org/abs/2405.17296v1",
        "abstract": "We present a novel light-matter platform that uses complex-valued oscillator\nnetworks, a form of physical neural networks, to identify dominant subnetworks\nand uncover indirect correlations within larger networks. This approach offers\nsignificant advantages, including low energy consumption, high processing\nspeed, and the immediate identification of co- and counter-regulated nodes\nwithout post-processing. The effectiveness of this approach is demonstrated\nthrough its application to biological networks, and we also propose its\napplicability to a wide range of other network types.",
        "subjects": [
            "cond-mat.dis-nn",
            "cond-mat.other",
            "cs.ET",
            "physics.optics",
            "quant-ph"
        ],
        "authors": [
            "Airat Kamaletdinov",
            "Natalia G. Berloff"
        ],
        "published": "2024-05-27T16:00:21Z"
    },
    {
        "title": "Efficient Ensembles Improve Training Data Attribution",
        "link": "http://arxiv.org/abs/2405.17293v1",
        "abstract": "Training data attribution (TDA) methods aim to quantify the influence of\nindividual training data points on the model predictions, with broad\napplications in data-centric AI, such as mislabel detection, data selection,\nand copyright compensation. However, existing methods in this field, which can\nbe categorized as retraining-based and gradient-based, have struggled with the\ntrade-off between computational efficiency and attribution efficacy.\nRetraining-based methods can accurately attribute complex non-convex models but\nare computationally prohibitive, while gradient-based methods are efficient but\noften fail for non-convex models. Recent research has shown that augmenting\ngradient-based methods with ensembles of multiple independently trained models\ncan achieve significantly better attribution efficacy. However, this approach\nremains impractical for very large-scale applications.\n  In this work, we discover that expensive, fully independent training is\nunnecessary for ensembling the gradient-based methods, and we propose two\nefficient ensemble strategies, DROPOUT ENSEMBLE and LORA ENSEMBLE, alternative\nto naive independent ensemble. These strategies significantly reduce training\ntime (up to 80%), serving time (up to 60%), and space cost (up to 80%) while\nmaintaining similar attribution efficacy to the naive independent ensemble. Our\nextensive experimental results demonstrate that the proposed strategies are\neffective across multiple TDA methods on diverse datasets and models, including\ngenerative settings, significantly advancing the Pareto frontier of TDA methods\nwith better computational efficiency and attribution efficacy.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Junwei Deng",
            "Ting-Wei Li",
            "Shichang Zhang",
            "Jiaqi Ma"
        ],
        "published": "2024-05-27T15:58:34Z"
    },
    {
        "title": "The logistic queue model: theoretical properties and performance\n  evaluation",
        "link": "http://arxiv.org/abs/2405.17528v1",
        "abstract": "The advent of digital twins (DT) for the control and management of\ncommunication networks requires accurate and fast methods to estimate key\nperformance indicators (KPI) needed for autonomous decision-making. Among\nseveral alternatives, queuing theory can be applied to model a real network as\na queue system that propagates entities representing network traffic. By using\nfluid flow queue simulation and numerical methods, a good trade-off between\naccuracy and execution time can be obtained. In this work, we present the\nformal derivation and mathematical properties of a continuous fluid flow\nqueuing model called the logistic queue model. We give novel proofs showing\nthat this queue model has all the theoretical properties one should expect such\nas positivity of the queue and first-in first-out (FIFO) property. Moreover,\nextensions are presented in order to model different characteristics of\ntelecommunication networks, including finite buffer sizes and propagation of\nflows with different priorities. Numerical results are presented to validate\nthe accuracy and improved performance of our approach in contrast to\ntraditional discrete event simulation, using synthetic traffic generated with\nthe characteristics of real captured network traffic. Finally, we evaluate a DT\nbuilt using a queue system based on the logistic queue model and demonstrate\nits applicability to estimate KPIs of an emulated real network under different\ntraffic conditions.",
        "subjects": [
            "cs.NI",
            "cs.CE"
        ],
        "authors": [
            "Franco Coltraro",
            "Marc Ruiz",
            "Luis Velasco"
        ],
        "published": "2024-05-27T15:56:49Z"
    },
    {
        "title": "Revised Optimal design of power electronic transformer based on hybrid\n  MMC under over-modulation operation",
        "link": "http://arxiv.org/abs/2405.17291v1",
        "abstract": "The bridge arm of the hybrid modular multilevel converter (MMC) is composed\nof half-bridge and full-bridge sub-modules cascaded together. Compared with the\nhalf-bridge MMC, it can operate in the boost-AC mode, where the modulation\nindex can be higher than 1, and the DC voltage and the AC voltage level are no\nlonger mutually constrained; compared with the full-bridge MMC, it has lower\nswitching device costs and losses. When the hybrid MMC boost-AC mode is used in\nthe power electronic transformer, the degree of freedom in system design is\nimproved, and the cost and volume of the power electronic transformer system\ncan be further reduced. This paper analyzes how to make full use of the newly\nadded modulation index of freedom introduced by the boost-AC hybrid MMC to\noptimize the power electronic transformer system, and finally gives the optimal\nmodulation index selection scheme of the hybrid MMC for different optimization\nobjectives.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Yaqian Zhang",
            "Xudong Zhang",
            "Jianzhong Zhang",
            "Fujin Deng"
        ],
        "published": "2024-05-27T15:55:33Z"
    },
    {
        "title": "Opinion-Guided Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.17287v1",
        "abstract": "Human guidance is often desired in reinforcement learning to improve the\nperformance of the learning agent. However, human insights are often mere\nopinions and educated guesses rather than well-formulated arguments. While\nopinions are subject to uncertainty, e.g., due to partial informedness or\nignorance about a problem, they also emerge earlier than hard evidence could be\nproduced. Thus, guiding reinforcement learning agents through opinions offers\nthe potential for more performant learning processes, but comes with the\nchallenge of modeling and managing opinions in a formal way. In this article,\nwe present a method to guide reinforcement learning agents through opinions. To\nthis end, we provide an end-to-end method to model and manage advisors'\nopinions. To assess the utility of the approach, we evaluate it with synthetic\nand human advisors, at different levels of uncertainty, and under multiple\nadvise strategies. Our results indicate that opinions, even if uncertain,\nimprove the performance of reinforcement learning agents, resulting in higher\nrewards, more efficient exploration, and a better reinforced policy. Although\nwe demonstrate our approach in a simplified topological running example, our\napproach is applicable to complex problems with higher dimensions as well.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Kyanna Dagenais",
            "Istvan David"
        ],
        "published": "2024-05-27T15:52:27Z"
    },
    {
        "title": "An NLP Crosswalk Between the Common Core State Standards and NAEP Item\n  Specifications",
        "link": "http://arxiv.org/abs/2405.17284v1",
        "abstract": "Natural language processing (NLP) is rapidly developing for applications in\neducational assessment. In this paper, I describe an NLP-based procedure that\ncan be used to support subject matter experts in establishing a crosswalk\nbetween item specifications and content standards. This paper extends recent\nwork by proposing and demonstrating the use of multivariate similarity based on\nembedding vectors for sentences or texts. In particular, a hybrid regression\nprocedure is demonstrated for establishing the match of each content standard\nto multiple item specifications. The procedure is used to evaluate the match of\nthe Common Core State Standards (CCSS) for mathematics at grade 4 to the\ncorresponding item specifications for the 2026 National Assessment of\nEducational Progress (NAEP).",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Gregory Camilli"
        ],
        "published": "2024-05-27T15:47:46Z"
    },
    {
        "title": "Recurrent Complex-Weighted Autoencoders for Unsupervised Object\n  Discovery",
        "link": "http://arxiv.org/abs/2405.17283v2",
        "abstract": "Current state-of-the-art synchrony-based models encode object bindings with\ncomplex-valued activations and compute with real-valued weights in feedforward\narchitectures. We argue for the computational advantages of a recurrent\narchitecture with complex-valued weights. We propose a fully convolutional\nautoencoder, SynCx, that performs iterative constraint satisfaction: at each\niteration, a hidden layer bottleneck encodes statistically regular\nconfigurations of features in particular phase relationships; over iterations,\nlocal constraints propagate and the model converges to a globally consistent\nconfiguration of phase assignments. Binding is achieved simply by the\nmatrix-vector product operation between complex-valued weights and activations,\nwithout the need for additional mechanisms that have been incorporated into\ncurrent synchrony-based models. SynCx outperforms or is strongly competitive\nwith current models for unsupervised object discovery. SynCx also avoids\ncertain systematic grouping errors of current models, such as the inability to\nseparate similarly colored objects without additional supervision.",
        "subjects": [
            "cs.LG",
            "cs.NE"
        ],
        "authors": [
            "Anand Gopalakrishnan",
            "Aleksandar Stani",
            "Jrgen Schmidhuber",
            "Michael Curtis Mozer"
        ],
        "published": "2024-05-27T15:47:03Z"
    },
    {
        "title": "R-ODE: Ricci Curvature Tells When You Will be Informed",
        "link": "http://arxiv.org/abs/2405.17282v1",
        "abstract": "Information diffusion prediction is fundamental to understand the structure\nand organization of the online social networks, and plays a crucial role to\nblocking rumor spread, influence maximization, political propaganda, etc. So\nfar, most existing solutions primarily predict the next user who will be\ninformed with historical cascades, but ignore an important factor in the\ndiffusion process - the time. Such limitation motivates us to pose the problem\nof the time-aware personalized information diffusion prediction for the first\ntime, telling the time when the target user will be informed. In this paper, we\naddress this problem from a fresh geometric perspective of Ricci curvature, and\npropose a novel Ricci-curvature regulated Ordinary Differential Equation\n(R-ODE). In the diffusion process, R-ODE considers that the inter-correlated\nusers are organized in a dynamic system in the representation space, and the\ncascades give the observations sampled from the continuous realm. At each\ninfection time, the message diffuses along the largest Ricci curvature,\nsignifying less transportation effort. In the continuous realm, the message\ntriggers users' movement, whose trajectory in the space is parameterized by an\nODE with graph neural network. Consequently, R-ODE predicts the infection time\nof a target user by the movement trajectory learnt from the observations.\nExtensive experiments evaluate the personalized time prediction ability of\nR-ODE, and show R-ODE outperforms the state-of-the-art baselines.",
        "subjects": [
            "cs.SI",
            "cs.LG"
        ],
        "authors": [
            "Li Sun",
            "Jingbin Hu",
            "Mengjie Li",
            "Hao Peng"
        ],
        "published": "2024-05-27T15:46:52Z"
    },
    {
        "title": "A Library for Automatic Natural Language Generation of Spanish Texts",
        "link": "http://dx.doi.org/10.1016/j.eswa.2018.11.036",
        "abstract": "In this article we present a novel system for natural language generation\n(NLG) of Spanish sentences from a minimum set of meaningful words (such as\nnouns, verbs and adjectives) which, unlike other state-of-the-art solutions,\nperforms the NLG task in a fully automatic way, exploiting both knowledge-based\nand statistical approaches. Relying on its linguistic knowledge of vocabulary\nand grammar, the system is able to generate complete, coherent and correctly\nspelled sentences from the main word sets presented by the user. The system,\nwhich was designed to be integrable, portable and efficient, can be easily\nadapted to other languages by design and can feasibly be integrated in a wide\nrange of digital devices. During its development we also created a\nsupplementary lexicon for Spanish, aLexiS, with wide coverage and high\nprecision, as well as syntactic trees from a freely available definite-clause\ngrammar. The resulting NLG library has been evaluated both automatically and\nmanually (annotation). The system can potentially be used in different\napplication domains such as augmentative communication and automatic generation\nof administrative reports or news.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Silvia Garca-Mndez",
            "Milagros Fernndez-Gavilanes",
            "Enrique Costa-Montenegro",
            "Jonathan Juncal-Martnez",
            "F. Javier Gonzlez-Castao"
        ],
        "published": "2024-05-27T15:44:06Z"
    },
    {
        "title": "Socially-Aware Shared Control Navigation for Assistive Mobile Robots in\n  the Built Environment",
        "link": "http://arxiv.org/abs/2405.17279v1",
        "abstract": "As the number of Persons with Disabilities (PWD), particularly those with one\nor more physical impairments, increases, there is an increasing demand for\nassistive robotic technologies that can support independent mobility in the\nbuilt environment and reduce the burden on caregivers. Current assistive\nmobility platforms (e.g., robotic wheelchairs) often fail to incorporate user\npreferences and control, leading to reduced trust and efficiency. Existing\nshared control algorithms do not allow the incorporation of the user control\npreferences inside the navigation framework or the path planning algorithm. In\naddition, existing dynamic local planner algorithms for robotic wheelchairs do\nnot take into account the social spaces of people, potentially leading such\nplatforms to infringe upon these areas and cause discomfort. To address these\nconcerns, this work introduces a novel socially-aware shared autonomy-based\nnavigation system for assistive mobile robotic platforms.\n  Our navigation framework comprises a Global Planner and a Local Planner. To\nimplement the Global Planner, the proposed approach introduces a novel User\nPreference Field (UPF) theory within its global planning framework, explicitly\nacknowledging user preferences to adeptly navigate away from congested areas.\nFor the Local Planner, we propose a Socially-aware Shared Control-based Model\nPredictive Control with Dynamic Control Barrier Function (SS-MPC-DCBF) to\nadjust movements in real-time, integrating user preferences for safer, more\nautonomous navigation. Evaluation results show that our Global Planner aligns\nclosely with user preferences compared to baselines, and our Local Planner\ndemonstrates enhanced safety and efficiency in dynamic and static scenarios.\nThis integrated approach fosters trust and autonomy, crucial for the acceptance\nof assistive mobility technologies in the built environment.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.HC"
        ],
        "authors": [
            "Yifan Xu",
            "Qianwei Wang",
            "Vineet Kamat",
            "Carol Menassa"
        ],
        "published": "2024-05-27T15:40:34Z"
    },
    {
        "title": "EF-Calib: Spatiotemporal Calibration of Event- and Frame-Based Cameras\n  Using Continuous-Time Trajectories",
        "link": "http://arxiv.org/abs/2405.17278v1",
        "abstract": "Event camera, a bio-inspired asynchronous triggered camera, offers promising\nprospects for fusion with frame-based cameras owing to its low latency and high\ndynamic range. However, calibrating stereo vision systems that incorporate both\nevent and frame-based cameras remains a significant challenge. In this letter,\nwe present EF-Calib, a spatiotemporal calibration framework for event- and\nframe-based cameras using continuous-time trajectories. A novel calibration\npattern applicable to both camera types and the corresponding event recognition\nalgorithm is proposed. Leveraging the asynchronous nature of events, a\nderivable piece-wise B-spline to represent camera pose continuously is\nintroduced, enabling calibration for intrinsic parameters, extrinsic\nparameters, and time offset, with analytical Jacobians provided. Various\nexperiments are carried out to evaluate the calibration performance of\nEF-Calib, including calibration experiments for intrinsic parameters, extrinsic\nparameters, and time offset. Experimental results show that EF-Calib achieves\nthe most accurate intrinsic parameters compared to current SOTA, the close\naccuracy of the extrinsic parameters compared to the frame-based results, and\naccurate time offset estimation. EF-Calib provides a convenient and accurate\ntoolbox for calibrating the system that fuses events and frames. The code of\nthis paper will also be open-sourced at: https://github.com/wsakobe/EF-Calib.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "authors": [
            "Shaoan Wang",
            "Zhanhua Xin",
            "Yaoqing Hu",
            "Dongyue Li",
            "Mingzhu Zhu",
            "Junzhi Yu"
        ],
        "published": "2024-05-27T15:40:24Z"
    },
    {
        "title": "Gradients of Functions of Large Matrices",
        "link": "http://arxiv.org/abs/2405.17277v1",
        "abstract": "Tuning scientific and probabilistic machine learning models -- for example,\npartial differential equations, Gaussian processes, or Bayesian neural networks\n-- often relies on evaluating functions of matrices whose size grows with the\ndata set or the number of parameters. While the state-of-the-art for evaluating\nthese quantities is almost always based on Lanczos and Arnoldi iterations, the\npresent work is the first to explain how to differentiate these workhorses of\nnumerical linear algebra efficiently. To get there, we derive previously\nunknown adjoint systems for Lanczos and Arnoldi iterations, implement them in\nJAX, and show that the resulting code can compete with Diffrax when it comes to\ndifferentiating PDEs, GPyTorch for selecting Gaussian process models and beats\nstandard factorisation methods for calibrating Bayesian neural networks. All\nthis is achieved without any problem-specific code optimisation. Find the code\nat https://github.com/pnkraemer/experiments-lanczos-adjoints and install the\nlibrary with pip install matfree.",
        "subjects": [
            "cs.LG",
            "cs.NA",
            "math.NA",
            "stat.ML"
        ],
        "authors": [
            "Nicholas Krmer",
            "Pablo Moreno-Muoz",
            "Hrittik Roy",
            "Sren Hauberg"
        ],
        "published": "2024-05-27T15:39:45Z"
    },
    {
        "title": "Unisolver: PDE-Conditional Transformers Are Universal PDE Solvers",
        "link": "http://arxiv.org/abs/2405.17527v1",
        "abstract": "Deep models have recently emerged as a promising tool to solve partial\ndifferential equations (PDEs), known as neural PDE solvers. While neural\nsolvers trained from either simulation data or physics-informed loss can solve\nthe PDEs reasonably well, they are mainly restricted to a specific set of PDEs,\ne.g. a certain equation or a finite set of coefficients. This bottleneck limits\nthe generalizability of neural solvers, which is widely recognized as its major\nadvantage over numerical solvers. In this paper, we present the Universal PDE\nsolver (Unisolver) capable of solving a wide scope of PDEs by leveraging a\nTransformer pre-trained on diverse data and conditioned on diverse PDEs.\nInstead of simply scaling up data and parameters, Unisolver stems from the\ntheoretical analysis of the PDE-solving process. Our key finding is that a PDE\nsolution is fundamentally under the control of a series of PDE components, e.g.\nequation symbols, coefficients, and initial and boundary conditions. Inspired\nby the mathematical structure of PDEs, we define a complete set of PDE\ncomponents and correspondingly embed them as domain-wise (e.g. equation\nsymbols) and point-wise (e.g. boundaries) conditions for Transformer PDE\nsolvers. Integrating physical insights with recent Transformer advances,\nUnisolver achieves consistent state-of-the-art results on three challenging\nlarge-scale benchmarks, showing impressive gains and endowing favorable\ngeneralizability and scalability.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Zhou Hang",
            "Yuezhou Ma",
            "Haixu Wu",
            "Haowen Wang",
            "Mingsheng Long"
        ],
        "published": "2024-05-27T15:34:35Z"
    },
    {
        "title": "DPN: Decoupling Partition and Navigation for Neural Solvers of Min-max\n  Vehicle Routing Problems",
        "link": "http://arxiv.org/abs/2405.17272v1",
        "abstract": "The min-max vehicle routing problem (min-max VRP) traverses all given\ncustomers by assigning several routes and aims to minimize the length of the\nlongest route. Recently, reinforcement learning (RL)-based sequential planning\nmethods have exhibited advantages in solving efficiency and optimality.\nHowever, these methods fail to exploit the problem-specific properties in\nlearning representations, resulting in less effective features for decoding\noptimal routes. This paper considers the sequential planning process of min-max\nVRPs as two coupled optimization tasks: customer partition for different routes\nand customer navigation in each route (i.e., partition and navigation). To\neffectively process min-max VRP instances, we present a novel attention-based\nPartition-and-Navigation encoder (P&N Encoder) that learns distinct embeddings\nfor partition and navigation. Furthermore, we utilize an inherent symmetry in\ndecoding routes and develop an effective agent-permutation-symmetric (APS) loss\nfunction. Experimental results demonstrate that the proposed\nDecoupling-Partition-Navigation (DPN) method significantly surpasses existing\nlearning-based methods in both single-depot and multi-depot min-max VRPs. Our\ncode is available at",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Zhi Zheng",
            "Shunyu Yao",
            "Zhenkun Wang",
            "Xialiang Tong",
            "Mingxuan Yuan",
            "Ke Tang"
        ],
        "published": "2024-05-27T15:33:16Z"
    },
    {
        "title": "FedHPL: Efficient Heterogeneous Federated Learning with Prompt Tuning\n  and Logit Distillation",
        "link": "http://arxiv.org/abs/2405.17267v1",
        "abstract": "Federated learning (FL) is a popular privacy-preserving paradigm that enables\ndistributed clients to collaboratively train models with a central server while\nkeeping raw data locally. In practice, distinct model architectures, varying\ndata distributions, and limited resources across local clients inevitably cause\nmodel performance degradation and a slowdown in convergence speed. However,\nexisting FL methods can only solve some of the above heterogeneous challenges\nand have obvious performance limitations. Notably, a unified framework has not\nyet been explored to overcome these challenges. Accordingly, we propose FedHPL,\na parameter-efficient unified $\\textbf{Fed}$erated learning framework for\n$\\textbf{H}$eterogeneous settings based on $\\textbf{P}$rompt tuning and\n$\\textbf{L}$ogit distillation. Specifically, we employ a local prompt tuning\nscheme that leverages a few learnable visual prompts to efficiently fine-tune\nthe frozen pre-trained foundation model for downstream tasks, thereby\naccelerating training and improving model performance under limited local\nresources and data heterogeneity. Moreover, we design a global logit\ndistillation scheme to handle the model heterogeneity and guide the local\ntraining. In detail, we leverage logits to implicitly capture local knowledge\nand design a weighted knowledge aggregation mechanism to generate global\nclient-specific logits. We provide a theoretical guarantee on the\ngeneralization error bound for FedHPL. The experiments on various benchmark\ndatasets under diverse settings of models and data demonstrate that our\nframework outperforms state-of-the-art FL approaches, with less computation\noverhead and training rounds.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Yuting Ma",
            "Lechao Cheng",
            "Yaxiong Wang",
            "Zhun Zhong",
            "Xiaohua Xu",
            "Meng Wang"
        ],
        "published": "2024-05-27T15:25:32Z"
    },
    {
        "title": "On the Noise Robustness of In-Context Learning for Text Generation",
        "link": "http://arxiv.org/abs/2405.17264v1",
        "abstract": "Large language models (LLMs) have shown impressive performance on downstream\ntasks by in-context learning (ICL), which heavily relies on the quality of\ndemonstrations selected from a large set of annotated examples. Recent works\nclaim that in-context learning is robust to noisy demonstrations in text\nclassification. In this work, we show that, on text generation tasks, noisy\nannotations significantly hurt the performance of in-context learning. To\ncircumvent the issue, we propose a simple and effective approach called Local\nPerplexity Ranking (LPR), which replaces the \"noisy\" candidates with their\nnearest neighbors that are more likely to be clean. Our method is motivated by\nanalyzing the perplexity deviation caused by noisy labels and decomposing\nperplexity into inherent perplexity and matching perplexity. Our key idea\nbehind LPR is thus to decouple the matching perplexity by performing the\nranking among the neighbors in semantic space. Our approach can prevent the\nselected demonstrations from including mismatched input-label pairs while\npreserving the effectiveness of the original selection methods. Extensive\nexperiments demonstrate the effectiveness of LPR, improving the EM score by up\nto 18.75 on common benchmarks with noisy annotations.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Hongfu Gao",
            "Feipeng Zhang",
            "Wenyu Jiang",
            "Jun Shu",
            "Feng Zheng",
            "Hongxin Wei"
        ],
        "published": "2024-05-27T15:22:58Z"
    },
    {
        "title": "ReStorEdge: An edge computing system with reuse semantics",
        "link": "http://arxiv.org/abs/2405.17263v2",
        "abstract": "This paper investigates an edge computing system where requests are processed\nby a set of replicated edge servers. We investigate a class of applications\nwhere similar queries produce identical results. To reduce processing overhead\non the edge servers we store the results of previous computations and return\nthem when new queries are sufficiently similar to earlier ones that produced\nthe results, avoiding the necessity of processing every new query. We implement\na similarity-based data classification system, which we evaluate based on\nreal-world datasets of images and voice queries. We evaluate a range of\norchestration strategies to distribute queries and cached results between edge\nnodes and show that the throughput of queries over a system of distributed edge\nnodes can be increased by 25-33%, increasing its capacity for higher workloads.",
        "subjects": [
            "cs.ET",
            "cs.DB",
            "cs.DC",
            "cs.NI"
        ],
        "authors": [
            "Adrian-Cristian Nicolaescu",
            "Spyridon Mastorakis",
            "Md Washik Al Azad",
            "David Griffin",
            "Miguel Rio"
        ],
        "published": "2024-05-27T15:22:22Z"
    },
    {
        "title": "Deep Feature Gaussian Processes for Single-Scene Aerosol Optical Depth\n  Reconstruction",
        "link": "http://dx.doi.org/10.1109/LGRS.2024.3398689",
        "abstract": "Remote sensing data provide a low-cost solution for large-scale monitoring of\nair pollution via the retrieval of aerosol optical depth (AOD), but is often\nlimited by cloud contamination. Existing methods for AOD reconstruction rely on\ntemporal information. However, for remote sensing data at high spatial\nresolution, multi-temporal observations are often unavailable. In this letter,\nwe take advantage of deep representation learning from convolutional neural\nnetworks and propose Deep Feature Gaussian Processes (DFGP) for single-scene\nAOD reconstruction. By using deep learning, we transform the variables to a\nfeature space with better explainable power. By using Gaussian processes, we\nexplicitly consider the correlation between observed AOD and missing AOD in\nspatial and feature domains. Experiments on two AOD datasets with real-world\ncloud patterns showed that the proposed method outperformed deep CNN and random\nforest, achieving R$^2$ of 0.7431 on MODIS AOD and R$^2$ of 0.9211 on EMIT AOD,\ncompared to deep CNN's R$^2$ of 0.6507 and R$^2$ of 0.8619. The proposed\nmethods increased R$^2$ by over 0.35 compared to the popular random forest in\nAOD reconstruction. The data and code used in this study are available at\n\\url{https://skrisliu.com/dfgp}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Shengjie Liu",
            "Lu Zhang"
        ],
        "published": "2024-05-27T15:20:40Z"
    },
    {
        "title": "Does Diffusion Beat GAN in Image Super Resolution?",
        "link": "http://arxiv.org/abs/2405.17261v1",
        "abstract": "There is a prevalent opinion in the recent literature that Diffusion-based\nmodels outperform GAN-based counterparts on the Image Super Resolution (ISR)\nproblem. However, in most studies, Diffusion-based ISR models were trained\nlonger and utilized larger networks than the GAN baselines. This raises the\nquestion of whether the superiority of Diffusion models is due to the Diffusion\nparadigm being better suited for the ISR task or if it is a consequence of the\nincreased scale and computational resources used in contemporary studies. In\nour work, we compare Diffusion-based and GAN-based Super Resolution under\ncontrolled settings, where both approaches are matched in terms of\narchitecture, model and dataset size, and computational budget. We show that a\nGAN-based model can achieve results comparable to a Diffusion-based model.\nAdditionally, we explore the impact of design choices such as text conditioning\nand augmentation on the performance of ISR models, showcasing their effect on\nseveral downstream tasks. We will release the inference code and weights of our\nscaled GAN.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Denis Kuznedelev",
            "Valerii Startsev",
            "Daniil Shlenskii",
            "Sergey Kastryulin"
        ],
        "published": "2024-05-27T15:19:59Z"
    },
    {
        "title": "Accelerating Simulation of Two-Phase Flows with Neural PDE Surrogates",
        "link": "http://arxiv.org/abs/2405.17260v1",
        "abstract": "Simulation is a powerful tool to better understand physical systems, but\ngenerally requires computationally expensive numerical methods. Downstream\napplications of such simulations can become computationally infeasible if they\nrequire many forward solves, for example in the case of inverse design with\nmany degrees of freedom. In this work, we investigate and extend neural PDE\nsolvers as a tool to aid in scaling simulations for two-phase flow problems,\nand simulations of oil expulsion from a pore specifically. We extend existing\nnumerical methods for this problem to a more complex setting involving varying\ngeometries of the domain to generate a challenging dataset. Further, we\ninvestigate three prominent neural PDE solver methods, namely the UNet, DRN and\nU-FNO, and extend them for characteristics of the oil-expulsion problem: (1)\nspatial conditioning on the geometry; (2) periodicity in the boundary; (3)\napproximate mass conservation. We scale all methods and benchmark their\nspeed-accuracy trade-off, evaluate qualitative properties, and perform an\nablation study. We find that the investigated methods can accurately model the\ndroplet dynamics with up to three orders of magnitude speed-up, that our\nextensions improve performance over the baselines, and that the introduced\nvarying geometries constitute a significantly more challenging setting over the\npreviously considered oil expulsion problem.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "physics.flu-dyn"
        ],
        "authors": [
            "Yoeri Poels",
            "Koen Minartz",
            "Harshit Bansal",
            "Vlado Menkovski"
        ],
        "published": "2024-05-27T15:18:12Z"
    },
    {
        "title": "$\\textit{Trans-LoRA}$: towards data-free Transferable Parameter\n  Efficient Finetuning",
        "link": "http://arxiv.org/abs/2405.17258v1",
        "abstract": "Low-rank adapters (LoRA) and their variants are popular parameter-efficient\nfine-tuning (PEFT) techniques that closely match full model fine-tune\nperformance while requiring only a small number of additional parameters. These\nadditional LoRA parameters are specific to the base model being adapted. When\nthe base model needs to be deprecated and replaced with a new one, all the\nassociated LoRA modules need to be re-trained. Such re-training requires access\nto the data used to train the LoRA for the original base model. This is\nespecially problematic for commercial cloud applications where the LoRA modules\nand the base models are hosted by service providers who may not be allowed to\nhost proprietary client task data. To address this challenge, we propose\n$\\textit{Trans-LoRA}$ -- a novel method for lossless, nearly data-free transfer\nof LoRAs across base models. Our approach relies on synthetic data to transfer\nLoRA modules. Using large language models, we design a synthetic data generator\nto approximate the data-generating process of the $\\textit{observed}$ task data\nsubset. Training on the resulting synthetic dataset transfers LoRA modules to\nnew models. We show the effectiveness of our approach using both LLama and\nGemma model families. Our approach achieves lossless (mostly improved) LoRA\ntransfer between models within and across different base model families, and\neven between different PEFT methods, on a wide variety of tasks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Runqian Wang",
            "Soumya Ghosh",
            "David Cox",
            "Diego Antognini",
            "Aude Oliva",
            "Rogerio Feris",
            "Leonid Karlinsky"
        ],
        "published": "2024-05-27T15:15:08Z"
    },
    {
        "title": "Surface reconstruction of sampled textiles via Morse theory",
        "link": "http://arxiv.org/abs/2405.17257v1",
        "abstract": "In this work, we study the perception problem for garments using tools from\ncomputational topology: the identification of their geometry and position in\nspace from point-cloud samples, as obtained e.g. with 3D scanners. We present a\nreconstruction algorithm based on a direct topological study of the sampled\ntextile surface that allows us to obtain a cellular decomposition of it via a\nMorse function. No intermediate triangulation or local implicit equations are\nused, avoiding reconstruction-induced artifices. No a priori knowledge of the\nsurface topology, density or regularity of the point-sample is required to run\nthe algorithm. The results are a piecewise decomposition of the surface as a\nunion of Morse cells (i.e. topological disks), suitable for tasks such as\nnoise-filtering or mesh-independent reparametrization, and a cell complex of\nsmall rank determining the surface topology. This algorithm can be applied to\nsmooth surfaces with or without boundary, embedded in an ambient space of any\ndimension.",
        "subjects": [
            "cs.CG",
            "cs.CV",
            "math.AT"
        ],
        "authors": [
            "Franco Coltraro",
            "Jaume Amors",
            "Maria Alberich-Carramiana",
            "Carme Torras"
        ],
        "published": "2024-05-27T15:14:47Z"
    },
    {
        "title": "Gaussian Embedding of Temporal Networks",
        "link": "http://dx.doi.org/10.1109/ACCESS.2023.3324213",
        "abstract": "Representing the nodes of continuous-time temporal graphs in a\nlow-dimensional latent space has wide-ranging applications, from prediction to\nvisualization. Yet, analyzing continuous-time relational data with timestamped\ninteractions introduces unique challenges due to its sparsity. Merely embedding\nnodes as trajectories in the latent space overlooks this sparsity, emphasizing\nthe need to quantify uncertainty around the latent positions. In this paper, we\npropose TGNE (\\textbf{T}emporal \\textbf{G}aussian \\textbf{N}etwork\n\\textbf{E}mbedding), an innovative method that bridges two distinct strands of\nliterature: the statistical analysis of networks via Latent Space Models\n(LSM)\\cite{Hoff2002} and temporal graph machine learning. TGNE embeds nodes as\npiece-wise linear trajectories of Gaussian distributions in the latent space,\ncapturing both structural information and uncertainty around the trajectories.\nWe evaluate TGNE's effectiveness in reconstructing the original graph and\nmodelling uncertainty. The results demonstrate that TGNE generates competitive\ntime-varying embedding locations compared to common baselines for\nreconstructing unobserved edge interactions based on observed edges.\nFurthermore, the uncertainty estimates align with the time-varying degree\ndistribution in the network, providing valuable insights into the temporal\ndynamics of the graph. To facilitate reproducibility, we provide an open-source\nimplementation of TGNE at \\url{https://github.com/aida-ugent/tgne}.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Raphal Romero",
            "Jefrey Lijffijt",
            "Riccardo Rastelli",
            "Marco Corneli",
            "Tijl De Bie"
        ],
        "published": "2024-05-27T15:07:57Z"
    },
    {
        "title": "GenWarp: Single Image to Novel Views with Semantic-Preserving Generative\n  Warping",
        "link": "http://arxiv.org/abs/2405.17251v1",
        "abstract": "Generating novel views from a single image remains a challenging task due to\nthe complexity of 3D scenes and the limited diversity in the existing\nmulti-view datasets to train a model on. Recent research combining large-scale\ntext-to-image (T2I) models with monocular depth estimation (MDE) has shown\npromise in handling in-the-wild images. In these methods, an input view is\ngeometrically warped to novel views with estimated depth maps, then the warped\nimage is inpainted by T2I models. However, they struggle with noisy depth maps\nand loss of semantic details when warping an input view to novel viewpoints. In\nthis paper, we propose a novel approach for single-shot novel view synthesis, a\nsemantic-preserving generative warping framework that enables T2I generative\nmodels to learn where to warp and where to generate, through augmenting\ncross-view attention with self-attention. Our approach addresses the\nlimitations of existing methods by conditioning the generative model on source\nview images and incorporating geometric warping signals. Qualitative and\nquantitative evaluations demonstrate that our model outperforms existing\nmethods in both in-domain and out-of-domain scenarios. Project page is\navailable at https://GenWarp-NVS.github.io/.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Junyoung Seo",
            "Kazumi Fukuda",
            "Takashi Shibuya",
            "Takuya Narihira",
            "Naoki Murata",
            "Shoukang Hu",
            "Chieh-Hsin Lai",
            "Seungryong Kim",
            "Yuki Mitsufuji"
        ],
        "published": "2024-05-27T15:07:04Z"
    },
    {
        "title": "\"Pass the butter\": A study on desktop-classic multitasking robotic arm\n  based on advanced YOLOv7 and BERT",
        "link": "http://arxiv.org/abs/2405.17250v1",
        "abstract": "In recent years, various intelligent autonomous robots have begun to appear\nin daily life and production. Desktop-level robots are characterized by their\nflexible deployment, rapid response, and suitability for light workload\nenvironments. In order to meet the current societal demand for service robot\ntechnology, this study proposes using a miniaturized desktop-level robot (by\nROS) as a carrier, locally deploying a natural language model (NLP-BERT), and\nintegrating visual recognition (CV-YOLO) and speech recognition technology\n(ASR-Whisper) as inputs to achieve autonomous decision-making and rational\naction by the desktop robot. Three comprehensive experiments were designed to\nvalidate the robotic arm, and the results demonstrate excellent performance\nusing this approach across all three experiments. In Task 1, the execution\nrates for speech recognition and action performance were 92.6% and 84.3%,\nrespectively. In Task 2, the highest execution rates under the given conditions\nreached 92.1% and 84.6%, while in Task 3, the highest execution rates were\n95.2% and 80.8%, respectively. Therefore, it can be concluded that the proposed\nsolution integrating ASR, NLP, and other technologies on edge devices is\nfeasible and provides a technical and engineering foundation for realizing\nmultimodal desktop-level robots.",
        "subjects": [
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Haohua Que",
            "Wenbin Pan",
            "Jie Xu",
            "Hao Luo",
            "Pei Wang",
            "Li Zhang"
        ],
        "published": "2024-05-27T15:06:03Z"
    },
    {
        "title": "Assessing LLMs Suitability for Knowledge Graph Completion",
        "link": "http://arxiv.org/abs/2405.17249v1",
        "abstract": "Recent work shown the capability of Large Language Models (LLMs) to solve\ntasks related to Knowledge Graphs, such as Knowledge Graph Completion, even in\nZero- or Few-Shot paradigms. However, they are known to hallucinate answers, or\noutput results in a non-deterministic manner, thus leading to wrongly reasoned\nresponses, even if they satisfy the user's demands. To highlight opportunities\nand challenges in knowledge graphs-related tasks, we experiment with two\ndistinguished LLMs, namely Mixtral-8x7B-Instruct-v0.1, and gpt-3.5-turbo-0125,\non Knowledge Graph Completion for static knowledge graphs, using prompts\nconstructed following the TELeR taxonomy, in Zero- and One-Shot contexts, on a\nTask-Oriented Dialogue system use case. When evaluated using both strict and\nflexible metrics measurement manners, our results show that LLMs could be fit\nfor such a task if prompts encapsulate sufficient information and relevant\nexamples.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Vasile Ionut Remus Iga",
            "Gheorghe Cosmin Silaghi"
        ],
        "published": "2024-05-27T15:04:50Z"
    },
    {
        "title": "Transformer In-Context Learning for Categorical Data",
        "link": "http://arxiv.org/abs/2405.17248v1",
        "abstract": "Recent research has sought to understand Transformers through the lens of\nin-context learning with functional data. We extend that line of work with the\ngoal of moving closer to language models, considering categorical outcomes,\nnonlinear underlying models, and nonlinear attention. The contextual data are\nof the form $\\textsf{C}=(x_1,c_1,\\dots,x_N,c_{N})$ where each\n$c_i\\in\\{0,\\dots,C-1\\}$ is drawn from a categorical distribution that depends\non covariates $x_i\\in\\mathbb{R}^d$. Contextual outcomes in the $m$th set of\ncontextual data, $\\textsf{C}_m$, are modeled in terms of latent function\n$f_m(x)\\in\\textsf{F}$, where $\\textsf{F}$ is a functional class with\n$(C-1)$-dimensional vector output. The probability of observing class\n$c\\in\\{0,\\dots,C-1\\}$ is modeled in terms of the output components of $f_m(x)$\nvia the softmax. The Transformer parameters may be trained with $M$ contextual\nexamples, $\\{\\textsf{C}_m\\}_{m=1,M}$, and the trained model is then applied to\nnew contextual data $\\textsf{C}_{M+1}$ for new $f_{M+1}(x)\\in\\textsf{F}$. The\ngoal is for the Transformer to constitute the probability of each category\n$c\\in\\{0,\\dots,C-1\\}$ for a new query $x_{N_{M+1}+1}$. We assume each component\nof $f_m(x)$ resides in a reproducing kernel Hilbert space (RKHS), specifying\n$\\textsf{F}$. Analysis and an extensive set of experiments suggest that on its\nforward pass the Transformer (with attention defined by the RKHS kernel)\nimplements a form of gradient descent of the underlying function, connected to\nthe latent vector function associated with the softmax. We present what is\nbelieved to be the first real-world demonstration of this few-shot-learning\nmethodology, using the ImageNet dataset.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Aaron T. Wang",
            "Ricardo Henao",
            "Lawrence Carin"
        ],
        "published": "2024-05-27T15:03:21Z"
    },
    {
        "title": "An Introduction to Vision-Language Modeling",
        "link": "http://arxiv.org/abs/2405.17247v1",
        "abstract": "Following the recent popularity of Large Language Models (LLMs), several\nattempts have been made to extend them to the visual domain. From having a\nvisual assistant that could guide us through unfamiliar environments to\ngenerative models that produce images using only a high-level text description,\nthe vision-language model (VLM) applications will significantly impact our\nrelationship with technology. However, there are many challenges that need to\nbe addressed to improve the reliability of those models. While language is\ndiscrete, vision evolves in a much higher dimensional space in which concepts\ncannot always be easily discretized. To better understand the mechanics behind\nmapping vision to language, we present this introduction to VLMs which we hope\nwill help anyone who would like to enter the field. First, we introduce what\nVLMs are, how they work, and how to train them. Then, we present and discuss\napproaches to evaluate VLMs. Although this work primarily focuses on mapping\nimages to language, we also discuss extending VLMs to videos.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Florian Bordes",
            "Richard Yuanzhe Pang",
            "Anurag Ajay",
            "Alexander C. Li",
            "Adrien Bardes",
            "Suzanne Petryk",
            "Oscar Maas",
            "Zhiqiu Lin",
            "Anas Mahmoud",
            "Bargav Jayaraman",
            "Mark Ibrahim",
            "Melissa Hall",
            "Yunyang Xiong",
            "Jonathan Lebensold",
            "Candace Ross",
            "Srihari Jayakumar",
            "Chuan Guo",
            "Diane Bouchacourt",
            "Haider Al-Tahan",
            "Karthik Padthe",
            "Vasu Sharma",
            "Hu Xu",
            "Xiaoqing Ellen Tan",
            "Megan Richards",
            "Samuel Lavoie",
            "Pietro Astolfi",
            "Reyhane Askari Hemmat",
            "Jun Chen",
            "Kushal Tirumala",
            "Rim Assouel",
            "Mazda Moayeri",
            "Arjang Talattof",
            "Kamalika Chaudhuri",
            "Zechun Liu",
            "Xilun Chen",
            "Quentin Garrido",
            "Karen Ullrich",
            "Aishwarya Agrawal",
            "Kate Saenko",
            "Asli Celikyilmaz",
            "Vikas Chandra"
        ],
        "published": "2024-05-27T15:01:23Z"
    },
    {
        "title": "Galaxy: A Resource-Efficient Collaborative Edge AI System for In-situ\n  Transformer Inference",
        "link": "http://arxiv.org/abs/2405.17245v1",
        "abstract": "Transformer-based models have unlocked a plethora of powerful intelligent\napplications at the edge, such as voice assistant in smart home. Traditional\ndeployment approaches offload the inference workloads to the remote cloud\nserver, which would induce substantial pressure on the backbone network as well\nas raise users' privacy concerns. To address that, in-situ inference has been\nrecently recognized for edge intelligence, but it still confronts significant\nchallenges stemming from the conflict between intensive workloads and limited\non-device computing resources. In this paper, we leverage our observation that\nmany edge environments usually comprise a rich set of accompanying trusted edge\ndevices with idle resources and propose Galaxy, a collaborative edge AI system\nthat breaks the resource walls across heterogeneous edge devices for efficient\nTransformer inference acceleration. Galaxy introduces a novel hybrid model\nparallelism to orchestrate collaborative inference, along with a\nheterogeneity-aware parallelism planning for fully exploiting the resource\npotential. Furthermore, Galaxy devises a tile-based fine-grained overlapping of\ncommunication and computation to mitigate the impact of tensor synchronizations\non inference latency under bandwidth-constrained edge environments. Extensive\nevaluation based on prototype implementation demonstrates that Galaxy\nremarkably outperforms state-of-the-art approaches under various edge\nenvironment setups, achieving up to 2.5x end-to-end latency reduction.",
        "subjects": [
            "cs.DC",
            "cs.AI",
            "cs.LG",
            "cs.NI"
        ],
        "authors": [
            "Shengyuan Ye",
            "Jiangsu Du",
            "Liekang Zeng",
            "Wenzhong Ou",
            "Xiaowen Chu",
            "Yutong Lu",
            "Xu Chen"
        ],
        "published": "2024-05-27T15:01:04Z"
    },
    {
        "title": "Surprise-Adaptive Intrinsic Motivation for Unsupervised Reinforcement\n  Learning",
        "link": "http://arxiv.org/abs/2405.17243v1",
        "abstract": "Both entropy-minimizing and entropy-maximizing (curiosity) objectives for\nunsupervised reinforcement learning (RL) have been shown to be effective in\ndifferent environments, depending on the environment's level of natural\nentropy. However, neither method alone results in an agent that will\nconsistently learn intelligent behavior across environments. In an effort to\nfind a single entropy-based method that will encourage emergent behaviors in\nany environment, we propose an agent that can adapt its objective online,\ndepending on the entropy conditions by framing the choice as a multi-armed\nbandit problem. We devise a novel intrinsic feedback signal for the bandit,\nwhich captures the agent's ability to control the entropy in its environment.\nWe demonstrate that such agents can learn to control entropy and exhibit\nemergent behaviors in both high- and low-entropy regimes and can learn skillful\nbehaviors in benchmark tasks. Videos of the trained agents and summarized\nfindings can be found on our project page\nhttps://sites.google.com/view/surprise-adaptive-agents",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Adriana Hugessen",
            "Roger Creus Castanyer",
            "Faisal Mohamed",
            "Glen Berseth"
        ],
        "published": "2024-05-27T14:58:24Z"
    },
    {
        "title": "NeurTV: Total Variation on the Neural Domain",
        "link": "http://arxiv.org/abs/2405.17241v1",
        "abstract": "Recently, we have witnessed the success of total variation (TV) for many\nimaging applications. However, traditional TV is defined on the original pixel\ndomain, which limits its potential. In this work, we suggest a new TV\nregularization defined on the neural domain. Concretely, the discrete data is\ncontinuously and implicitly represented by a deep neural network (DNN), and we\nuse the derivatives of DNN outputs w.r.t. input coordinates to capture local\ncorrelations of data. As compared with classical TV on the original domain, the\nproposed TV on the neural domain (termed NeurTV) enjoys two advantages. First,\nNeurTV is not limited to meshgrid but is suitable for both meshgrid and\nnon-meshgrid data. Second, NeurTV can more exactly capture local correlations\nacross data for any direction and any order of derivatives attributed to the\nimplicit and continuous nature of neural domain. We theoretically reinterpret\nNeurTV under the variational approximation framework, which allows us to build\nthe connection between classical TV and NeurTV and inspires us to develop\nvariants (e.g., NeurTV with arbitrary resolution and space-variant NeurTV).\nExtensive numerical experiments with meshgrid data (e.g., color and\nhyperspectral images) and non-meshgrid data (e.g., point clouds and spatial\ntranscriptomics) showcase the effectiveness of the proposed methods.",
        "subjects": [
            "cs.CV",
            "eess.IV",
            "94A08, 68U10, 68T45"
        ],
        "authors": [
            "Yisi Luo",
            "Xile Zhao",
            "Kai Ye",
            "Deyu Meng"
        ],
        "published": "2024-05-27T14:57:58Z"
    },
    {
        "title": "Content-Style Decoupling for Unsupervised Makeup Transfer without\n  Generating Pseudo Ground Truth",
        "link": "http://arxiv.org/abs/2405.17240v1",
        "abstract": "The absence of real targets to guide the model training is one of the main\nproblems with the makeup transfer task. Most existing methods tackle this\nproblem by synthesizing pseudo ground truths (PGTs). However, the generated\nPGTs are often sub-optimal and their imprecision will eventually lead to\nperformance degradation. To alleviate this issue, in this paper, we propose a\nnovel Content-Style Decoupled Makeup Transfer (CSD-MT) method, which works in a\npurely unsupervised manner and thus eliminates the negative effects of\ngenerating PGTs. Specifically, based on the frequency characteristics analysis,\nwe assume that the low-frequency (LF) component of a face image is more\nassociated with its makeup style information, while the high-frequency (HF)\ncomponent is more related to its content details. This assumption allows CSD-MT\nto decouple the content and makeup style information in each face image through\nthe frequency decomposition. After that, CSD-MT realizes makeup transfer by\nmaximizing the consistency of these two types of information between the\ntransferred result and input images, respectively. Two newly designed loss\nfunctions are also introduced to further improve the transfer performance.\nExtensive quantitative and qualitative analyses show the effectiveness of our\nCSD-MT method. Our code is available at\nhttps://github.com/Snowfallingplum/CSD-MT.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhaoyang Sun",
            "Shengwu Xiong",
            "Yaxiong Chen",
            "Yi Rong"
        ],
        "published": "2024-05-27T14:57:40Z"
    },
    {
        "title": "LLM-Assisted Static Analysis for Detecting Security Vulnerabilities",
        "link": "http://arxiv.org/abs/2405.17238v1",
        "abstract": "Software is prone to security vulnerabilities. Program analysis tools to\ndetect them have limited effectiveness in practice. While large language models\n(or LLMs) have shown impressive code generation capabilities, they cannot do\ncomplex reasoning over code to detect such vulnerabilities, especially because\nthis task requires whole-repository analysis. In this work, we propose IRIS,\nthe first approach that systematically combines LLMs with static analysis to\nperform whole-repository reasoning to detect security vulnerabilities. We\ncurate a new dataset, CWE-Bench-Java, comprising 120 manually validated\nsecurity vulnerabilities in real-world Java projects. These projects are\ncomplex, with an average of 300,000 lines of code and a maximum of up to 7\nmillion. Out of 120 vulnerabilities in CWE-Bench-Java, IRIS detects 69 using\nGPT-4, while the state-of-the-art static analysis tool only detects 27.\nFurther, IRIS also significantly reduces the number of false alarms (by more\nthan 80% in the best case).",
        "subjects": [
            "cs.CR",
            "cs.PL",
            "cs.SE"
        ],
        "authors": [
            "Ziyang Li",
            "Saikat Dutta",
            "Mayur Naik"
        ],
        "published": "2024-05-27T14:53:35Z"
    },
    {
        "title": "From Text to Blueprint: Leveraging Text-to-Image Tools for Floor Plan\n  Creation",
        "link": "http://arxiv.org/abs/2405.17236v1",
        "abstract": "Artificial intelligence is revolutionizing architecture through text-to-image\nsynthesis, converting textual descriptions into detailed visual\nrepresentations. We explore AI-assisted floor plan design, focusing on\ntechnical background, practical methods, and future directions. Using tools\nlike, Stable Diffusion, AI leverages models such as Generative Adversarial\nNetworks and Variational Autoencoders to generate complex and functional\nfloorplans designs. We evaluates these AI models' effectiveness in generating\nresidential floor plans from text prompts. Through experiments with reference\nimages, text prompts, and sketches, we assess the strengths and limitations of\ncurrent text-to-image technology in architectural visualization. Architects can\nuse these AI tools to streamline design processes, create multiple design\noptions, and enhance creativity and collaboration. We highlight AI's potential\nto drive smarter, more efficient floorplan design, contributing to ongoing\ndiscussions on AI integration in the design profession and its future impact.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Xiaoyu Li",
            "Jonathan Benjamin",
            "Xin Zhang"
        ],
        "published": "2024-05-27T14:51:33Z"
    },
    {
        "title": "Benchmarking General Purpose In-Context Learning",
        "link": "http://arxiv.org/abs/2405.17234v2",
        "abstract": "In-context learning (ICL) capabilities are becoming increasingly appealing\nfor building general intelligence due to their sample efficiency and\nindependence from artificial optimization skills. To enhance generalization,\nbiological neural systems primarily inherit learning capabilities and\nsubsequently refine their memory, acquiring diverse skills and knowledge\nthrough extensive lifelong experiences. This process gives rise to the concept\nof general-purpose in-context learning (GPICL). Compared to standard ICL, GPICL\naddresses a broader range of tasks, extends learning horizons, and starts at a\nlower zero-shot baseline. We introduce two lightweight but insightful\nbenchmarks specifically crafted to train and evaluate GPICL functionalities.\nEach benchmark includes a vast number of tasks characterized by significant\ntask variance and minimal transferable knowledge among tasks, facilitating\nlifelong in-context learning through continuous generation and interaction.\nThese features pose significant challenges for models that rely on context or\ninteractions to improve their proficiency, including language models, decision\nmodels, and world models. Our experiments reveal that parameter scale alone may\nnot be crucial for ICL or GPICL, suggesting alternative approaches such as\nincreasing the scale of contexts and memory states.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Fan Wang",
            "Chuan Lin",
            "Yang Cao",
            "Yu Kang"
        ],
        "published": "2024-05-27T14:50:42Z"
    },
    {
        "title": "CLAQ: Pushing the Limits of Low-Bit Post-Training Quantization for LLMs",
        "link": "http://arxiv.org/abs/2405.17233v1",
        "abstract": "Parameter quantization for Large Language Models (LLMs) has attracted\nincreasing attentions recently in reducing memory costs and improving\ncomputational efficiency. Early approaches have been widely adopted. However,\nthe existing methods suffer from poor performance in low-bit (such as 2 to 3\nbits) scenarios. In this paper, we present a novel and effective Column-Level\nAdaptive weight Quantization (CLAQ) framework by introducing three different\ntypes of adaptive strategies for LLM quantization. Firstly, a K-Means\nclustering based algorithm is proposed that allows dynamic generation of\nquantization centroids for each column of a parameter matrix. Secondly, we\ndesign an outlier-guided adaptive precision search strategy which can\ndynamically assign varying bit-widths to different columns. Finally, a dynamic\noutlier reservation scheme is developed to retain some parameters in their\noriginal float point precision, in trade off of boosted model performance.\nExperiments on various mainstream open source LLMs including LLaMA-1, LLaMA-2\nand Yi demonstrate that our methods achieve the state-of-the-art results across\ndifferent bit settings, especially in extremely low-bit scenarios. Code will be\nreleased soon.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Haoyu Wang",
            "Bei Liu",
            "Hang Shao",
            "Bo Xiao",
            "Ke Zeng",
            "Guanglu Wan",
            "Yanmin Qian"
        ],
        "published": "2024-05-27T14:49:39Z"
    },
    {
        "title": "InsigHTable: Insight-driven Hierarchical Table Visualization with\n  Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.17229v1",
        "abstract": "Embedding visual representations within original hierarchical tables can\nmitigate additional cognitive load stemming from the division of users'\nattention. The created hierarchical table visualizations can help users\nunderstand and explore complex data with multi-level attributes. However,\nbecause of many options available for transforming hierarchical tables and\nselecting subsets for embedding, the design space of hierarchical table\nvisualizations becomes vast, and the construction process turns out to be\ntedious, hindering users from constructing hierarchical table visualizations\nwith many data insights efficiently. We propose InsigHTable, a mixed-initiative\nand insight-driven hierarchical table transformation and visualization system.\nWe first define data insights within hierarchical tables, which consider the\nhierarchical structure in the table headers. Since hierarchical table\nvisualization construction is a sequential decision-making process, InsigHTable\nintegrates a deep reinforcement learning framework incorporating an auxiliary\nrewards mechanism. This mechanism addresses the challenge of sparse rewards in\nconstructing hierarchical table visualizations. Within the deep reinforcement\nlearning framework, the agent continuously optimizes its decision-making\nprocess to create hierarchical table visualizations to uncover more insights by\ncollaborating with analysts. We demonstrate the usability and effectiveness of\nInsigHTable through two case studies and sets of experiments. The results\nvalidate the effectiveness of the deep reinforcement learning framework and\nshow that InsigHTable can facilitate users to construct hierarchical table\nvisualizations and understand underlying data insights.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Guozheng Li",
            "Peng He",
            "Xinyu Wang",
            "Runfei Li",
            "Chi Harold Liu",
            "Chuangxin Ou",
            "Dong He",
            "Guoren Wang"
        ],
        "published": "2024-05-27T14:47:00Z"
    },
    {
        "title": "Learning Generic and Dynamic Locomotion of Humanoids Across Discrete\n  Terrains",
        "link": "http://arxiv.org/abs/2405.17227v1",
        "abstract": "This paper addresses the challenge of terrain-adaptive dynamic locomotion in\nhumanoid robots, a problem traditionally tackled by optimization-based methods\nor reinforcement learning (RL). Optimization-based methods, such as\nmodel-predictive control, excel in finding optimal reaction forces and\nachieving agile locomotion, especially in quadruped, but struggle with the\nnonlinear hybrid dynamics of legged systems and the real-time computation of\nstep location, timing, and reaction forces. Conversely, RL-based methods show\npromise in navigating dynamic and rough terrains but are limited by their\nextensive data requirements. We introduce a novel locomotion architecture that\nintegrates a neural network policy, trained through RL in simplified\nenvironments, with a state-of-the-art motion controller combining\nmodel-predictive control (MPC) and whole-body impulse control (WBIC). The\npolicy efficiently learns high-level locomotion strategies, such as gait\nselection and step positioning, without the need for full dynamics simulations.\nThis control architecture enables humanoid robots to dynamically navigate\ndiscrete terrains, making strategic locomotion decisions (e.g., walking,\njumping, and leaping) based on ground height maps. Our results demonstrate that\nthis integrated control architecture achieves dynamic locomotion with\nsignificantly fewer training samples than conventional RL-based methods and can\nbe transferred to different humanoid platforms without additional training. The\ncontrol architecture has been extensively tested in dynamic simulations,\naccomplishing terrain height-based dynamic locomotion for three different\nrobots.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Shangqun Yu",
            "Nisal Perera",
            "Daniel Marew",
            "Donghyun Kim"
        ],
        "published": "2024-05-27T14:44:07Z"
    },
    {
        "title": "A Retrospective of the Tutorial on Opportunities and Challenges of\n  Online Deep Learning",
        "link": "http://arxiv.org/abs/2405.17222v2",
        "abstract": "Machine learning algorithms have become indispensable in today's world. They\nsupport and accelerate the way we make decisions based on the data at hand.\nThis acceleration means that data structures that were valid at one moment\ncould no longer be valid in the future. With these changing data structures, it\nis necessary to adapt machine learning (ML) systems incrementally to the new\ndata. This is done with the use of online learning or continuous ML\ntechnologies. While deep learning technologies have shown exceptional\nperformance on predefined datasets, they have not been widely applied to\nonline, streaming, and continuous learning. In this retrospective of our\ntutorial titled Opportunities and Challenges of Online Deep Learning held at\nECML PKDD 2023, we provide a brief overview of the opportunities but also the\npotential pitfalls for the application of neural networks in online learning\nenvironments using the frameworks River and Deep-River.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Cedric Kulbach",
            "Lucas Cazzonelli",
            "Hoang-Anh Ngo",
            "Minh-Huong Le-Nguyen",
            "Albert Bifet"
        ],
        "published": "2024-05-27T14:40:03Z"
    },
    {
        "title": "RLAIF-V: Aligning MLLMs through Open-Source AI Feedback for Super GPT-4V\n  Trustworthiness",
        "link": "http://arxiv.org/abs/2405.17220v1",
        "abstract": "Learning from feedback reduces the hallucination of multimodal large language\nmodels (MLLMs) by aligning them with human preferences. While traditional\nmethods rely on labor-intensive and time-consuming manual labeling, recent\napproaches employing models as automatic labelers have shown promising results\nwithout human intervention. However, these methods heavily rely on costly\nproprietary models like GPT-4V, resulting in scalability issues. Moreover, this\nparadigm essentially distills the proprietary models to provide a temporary\nsolution to quickly bridge the performance gap. As this gap continues to\nshrink, the community is soon facing the essential challenge of aligning MLLMs\nusing labeler models of comparable capability. In this work, we introduce\nRLAIF-V, a novel framework that aligns MLLMs in a fully open-source paradigm\nfor super GPT-4V trustworthiness. RLAIF-V maximally exploits the open-source\nfeedback from two perspectives, including high-quality feedback data and online\nfeedback learning algorithm. Extensive experiments on seven benchmarks in both\nautomatic and human evaluation show that RLAIF-V substantially enhances the\ntrustworthiness of models without sacrificing performance on other tasks. Using\na 34B model as labeler, RLAIF-V 7B model reduces object hallucination by 82.9\\%\nand overall hallucination by 42.1\\%, outperforming the labeler model.\nRemarkably, RLAIF-V also reveals the self-alignment potential of open-source\nMLLMs, where a 12B model can learn from the feedback of itself to achieve less\nthan 29.5\\% overall hallucination rate, surpassing GPT-4V (45.9\\%) by a large\nmargin. The results shed light on a promising route to enhance the efficacy of\nleading-edge MLLMs.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Tianyu Yu",
            "Haoye Zhang",
            "Yuan Yao",
            "Yunkai Dang",
            "Da Chen",
            "Xiaoman Lu",
            "Ganqu Cui",
            "Taiwen He",
            "Zhiyuan Liu",
            "Tat-Seng Chua",
            "Maosong Sun"
        ],
        "published": "2024-05-27T14:37:01Z"
    },
    {
        "title": "Collage is the New Writing: Exploring the Fragmentation of Text and User\n  Interfaces in AI Tools",
        "link": "http://dx.doi.org/10.1145/3643834.3660681",
        "abstract": "This essay proposes and explores the concept of Collage for the design of AI\nwriting tools, transferred from avant-garde literature with four facets: 1)\nfragmenting text in writing interfaces, 2) juxtaposing voices (content vs\ncommand), 3) integrating material from multiple sources (e.g. text\nsuggestions), and 4) shifting from manual writing to editorial and\ncompositional decision-making, such as selecting and arranging snippets. The\nessay then employs Collage as an analytical lens to analyse the user interface\ndesign of recent AI writing tools, and as a constructive lens to inspire new\ndesign directions. Finally, a critical perspective relates the concerns that\nwriters historically expressed through literary collage to AI writing tools. In\na broad view, this essay explores how literary concepts can help advance design\ntheory around AI writing tools. It encourages creators of future writing tools\nto engage not only with new technological possibilities, but also with past\nwriting innovations.",
        "subjects": [
            "cs.HC",
            "cs.CL",
            "H.5.2; I.2.7"
        ],
        "authors": [
            "Daniel Buschek"
        ],
        "published": "2024-05-27T14:35:17Z"
    },
    {
        "title": "Autoformalizing Euclidean Geometry",
        "link": "http://arxiv.org/abs/2405.17216v1",
        "abstract": "Autoformalization involves automatically translating informal math into\nformal theorems and proofs that are machine-verifiable. Euclidean geometry\nprovides an interesting and controllable domain for studying autoformalization.\nIn this paper, we introduce a neuro-symbolic framework for autoformalizing\nEuclidean geometry, which combines domain knowledge, SMT solvers, and large\nlanguage models (LLMs). One challenge in Euclidean geometry is that informal\nproofs rely on diagrams, leaving gaps in texts that are hard to formalize. To\naddress this issue, we use theorem provers to fill in such diagrammatic\ninformation automatically, so that the LLM only needs to autoformalize the\nexplicit textual steps, making it easier for the model. We also provide\nautomatic semantic evaluation for autoformalized theorem statements. We\nconstruct LeanEuclid, an autoformalization benchmark consisting of problems\nfrom Euclid's Elements and the UniGeo dataset formalized in the Lean proof\nassistant. Experiments with GPT-4 and GPT-4V show the capability and\nlimitations of state-of-the-art LLMs on autoformalizing geometry problems. The\ndata and code are available at https://github.com/loganrjmurphy/LeanEuclid.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.LO",
            "stat.ML"
        ],
        "authors": [
            "Logan Murphy",
            "Kaiyu Yang",
            "Jialiang Sun",
            "Zhaoyu Li",
            "Anima Anandkumar",
            "Xujie Si"
        ],
        "published": "2024-05-27T14:35:10Z"
    },
    {
        "title": "Spectral-Refiner: Fine-Tuning of Accurate Spatiotemporal Neural Operator\n  for Turbulent Flows",
        "link": "http://arxiv.org/abs/2405.17211v1",
        "abstract": "Recent advancements in operator-type neural networks have shown promising\nresults in approximating the solutions of spatiotemporal Partial Differential\nEquations (PDEs). However, these neural networks often entail considerable\ntraining expenses, and may not always achieve the desired accuracy required in\nmany scientific and engineering disciplines. In this paper, we propose a new\nSpatiotemporal Fourier Neural Operator (SFNO) that learns maps between Bochner\nspaces, and a new learning framework to address these issues. This new paradigm\nleverages wisdom from traditional numerical PDE theory and techniques to refine\nthe pipeline of commonly adopted end-to-end neural operator training and\nevaluations. Specifically, in the learning problems for the turbulent flow\nmodeling by the Navier-Stokes Equations (NSE), the proposed architecture\ninitiates the training with a few epochs for SFNO, concluding with the freezing\nof most model parameters. Then, the last linear spectral convolution layer is\nfine-tuned without the frequency truncation. The optimization uses a negative\nSobolev norm for the first time as the loss in operator learning, defined\nthrough a reliable functional-type \\emph{a posteriori} error estimator whose\nevaluation is almost exact thanks to the Parseval identity. This design allows\nthe neural operators to effectively tackle low-frequency errors while the\nrelief of the de-aliasing filter addresses high-frequency errors. Numerical\nexperiments on commonly used benchmarks for the 2D NSE demonstrate significant\nimprovements in both computational efficiency and accuracy, compared to\nend-to-end evaluation and traditional numerical PDE solvers.",
        "subjects": [
            "cs.LG",
            "cs.NA",
            "math.NA",
            "physics.flu-dyn",
            "65M70 (Primary), 35Q30, 76M22, 65M50, 68T07 (Secondary)"
        ],
        "authors": [
            "Shuhao Cao",
            "Francesco Brarda",
            "Ruipeng Li",
            "Yuanzhe Xi"
        ],
        "published": "2024-05-27T14:33:06Z"
    },
    {
        "title": "Sublinear Cuts are the Exception in BDF-GIRGs",
        "link": "http://arxiv.org/abs/2405.19369v1",
        "abstract": "The introduction of geometry has proven instrumental in the efforts towards\nmore realistic models for real-world networks. In Geometric Inhomogeneous\nRandom Graphs (GIRGs), Euclidean Geometry induces clustering of the vertices,\nwhich is widely observed in networks in the wild. Euclidean Geometry in\nmultiple dimensions however restricts proximity of vertices to those cases\nwhere vertices are close in each coordinate. We introduce a large class of GIRG\nextensions, called BDF-GIRGs, which capture arbitrary hierarchies of the\ncoordinates within the distance function of the vertex feature space. These\ndistance functions have the potential to allow more realistic modeling of the\ncomplex formation of social ties in real-world networks, where similarities\nbetween people lead to connections. Here, similarity with respect to certain\nfeatures, such as familial kinship or a shared workplace, suffices for the\nformation of ties. It is known that - while many key properties of GIRGs, such\nas log-log average distance and sparsity, are independent of the distance\nfunction - the Euclidean metric induces small separators, i.e. sublinear cuts\nof the unique giant component in GIRGs, whereas no such sublinear separators\nexist under the component-wise minimum distance. Building on work of Lengler\nand Todorovi\\'{c}, we give a complete classification for the existence of small\nseparators in BDF-GIRGs. We further show that BDF-GIRGs all fulfill a\nstochastic triangle inequality and thus also exhibit clustering.",
        "subjects": [
            "cs.SI",
            "math.CO",
            "math.MG"
        ],
        "authors": [
            "Marc Kaufmann",
            "Raghu Raman Ravi",
            "Ulysse Schaller"
        ],
        "published": "2024-05-27T14:32:05Z"
    },
    {
        "title": "Numerical solution of the boundary value problem of elliptic equation by\n  Levi function scheme",
        "link": "http://arxiv.org/abs/2405.17204v1",
        "abstract": "For boundary value problem of an elliptic equation with variable coefficients\ndescribing the physical field distribution in inhomogeneous media, the Levi\nfunction can represent the solution in terms of volume and surface potentials,\nwith the drawback that the volume potential involving in the solution\nexpression requires heavy computational costs as well as the solvability of the\nintegral equations with respect to the density pair. We introduce an modified\nintegral expression for the solution to an elliptic equation in divergence form\nunder the Levi function framework. The well-posedness of the linear integral\nsystem with respect to the density functions to be determined is rigorously\nproved. Based on the singularity decomposition for the Levi function, we\npropose two schemes to deal with the volume integrals so that the density\nfunctions can be solved efficiently. One method is an adaptive discretization\nscheme (ADS) for computing the integrals with continuous integrands, leading to\nthe uniform accuracy of the integrals in the whole domain, and consequently the\nefficient computations for the density functions. The other method is the dual\nreciprocity method (DRM) which is a meshless approach converting the volume\nintegrals into boundary integrals equivalently by expressing the volume density\nas the combination of the radial basis functions determined by the interior\ngrids. The proposed schemes are justified numerically to be of satisfactory\ncomputation costs. Numerical examples in 2-dimensional and 3-dimensional cases\nare presented to show the validity of the proposed schemes.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "math-ph",
            "math.MP"
        ],
        "authors": [
            "Jinchao Pan",
            "Jijun Liu"
        ],
        "published": "2024-05-27T14:25:05Z"
    },
    {
        "title": "Efficient multi-prompt evaluation of LLMs",
        "link": "http://arxiv.org/abs/2405.17202v1",
        "abstract": "Most popular benchmarks for comparing LLMs rely on a limited set of prompt\ntemplates, which may not fully capture the LLMs' abilities and can affect the\nreproducibility of results on leaderboards. Many recent works empirically\nverify prompt sensitivity and advocate for changes in LLM evaluation. In this\npaper, we consider the problem of estimating the performance distribution\nacross many prompt variants instead of finding a single prompt to evaluate\nwith. We introduce PromptEval, a method for estimating performance across a\nlarge set of prompts borrowing strength across prompts and examples to produce\naccurate estimates under practical evaluation budgets. The resulting\ndistribution can be used to obtain performance quantiles to construct various\nrobust performance metrics (e.g., top 95% quantile or median). We prove that\nPromptEval consistently estimates the performance distribution and demonstrate\nits efficacy empirically on three prominent LLM benchmarks: MMLU, BIG-bench\nHard, and LMentry. For example, PromptEval can accurately estimate performance\nquantiles across 100 prompt templates on MMLU with a budget equivalent to two\nsingle-prompt evaluations. Our code and data can be found at\nhttps://github.com/felipemaiapolo/prompt-eval.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Felipe Maia Polo",
            "Ronald Xu",
            "Lucas Weber",
            "Mrian Silva",
            "Onkar Bhardwaj",
            "Leshem Choshen",
            "Allysson Flavio Melo de Oliveira",
            "Yuekai Sun",
            "Mikhail Yurochkin"
        ],
        "published": "2024-05-27T14:24:47Z"
    },
    {
        "title": "SmoothGNN: Smoothing-based GNN for Unsupervised Node Anomaly Detection",
        "link": "http://arxiv.org/abs/2405.17525v1",
        "abstract": "The smoothing issue leads to indistinguishable node representations, which\nposes a significant challenge in the field of graph learning. However, this\nissue also presents an opportunity to reveal underlying properties behind\ndifferent types of nodes, which have been overlooked in previous studies.\nThrough empirical and theoretical analysis of real-world node anomaly detection\n(NAD) datasets, we observe that anomalous and normal nodes show different\npatterns in the smoothing process, which can be leveraged to enhance NAD tasks.\nMotivated by these findings, in this paper, we propose a novel unsupervised NAD\nframework. Specifically, according to our theoretical analysis, we design a\nSmoothing Learning Component. Subsequently, we introduce a Smoothing-aware\nSpectral Graph Neural Network, which establishes the connection between the\nspectral space of graphs and the smoothing process. Additionally, we\ndemonstrate that the Dirichlet Energy, which reflects the smoothness of a\ngraph, can serve as coefficients for node representations across different\ndimensions of the spectral space. Building upon these observations and\nanalyses, we devise a novel anomaly measure for the NAD task. Extensive\nexperiments on 9 real-world datasets show that SmoothGNN outperforms the best\nrival by an average of 14.66% in AUC and 7.28% in Precision, with 75x running\ntime speed-up, which validates the effectiveness and efficiency of our\nframework.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Xiangyu Dong",
            "Xingyi Zhang",
            "Yanni Sun",
            "Lei Chen",
            "Mingxuan Yuan",
            "Sibo Wang"
        ],
        "published": "2024-05-27T14:23:30Z"
    },
    {
        "title": "Diagnosing the Compositional Knowledge of Vision Language Models from a\n  Game-Theoretic View",
        "link": "http://arxiv.org/abs/2405.17201v1",
        "abstract": "Compositional reasoning capabilities are usually considered as fundamental\nskills to characterize human perception. Recent studies show that current\nVision Language Models (VLMs) surprisingly lack sufficient knowledge with\nrespect to such capabilities. To this end, we propose to thoroughly diagnose\nthe composition representations encoded by VLMs, systematically revealing the\npotential cause for this weakness. Specifically, we propose evaluation methods\nfrom a novel game-theoretic view to assess the vulnerability of VLMs on\ndifferent aspects of compositional understanding, e.g., relations and\nattributes. Extensive experimental results demonstrate and validate several\ninsights to understand the incapabilities of VLMs on compositional reasoning,\nwhich provide useful and reliable guidance for future studies. The deliverables\nwill be updated at https://vlms-compositionality-gametheory.github.io/.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jin Wang",
            "Shichao Dong",
            "Yapeng Zhu",
            "Kelu Yao",
            "Weidong Zhao",
            "Chao Li",
            "Ping Luo"
        ],
        "published": "2024-05-27T14:22:03Z"
    },
    {
        "title": "Physically Consistent Modeling & Identification of Nonlinear Friction\n  with Dissipative Gaussian Processes",
        "link": "http://arxiv.org/abs/2405.17199v1",
        "abstract": "Friction modeling has always been a challenging problem due to the complexity\nof real physical systems. Although a few state-of-the-art structured\ndata-driven methods show their efficiency in nonlinear system modeling,\ndeterministic passivity as one of the significant characteristics of friction\nis rarely considered in these methods. To address this issue, we propose a\nGaussian Process based model that preserves the inherent structural properties\nsuch as passivity. A matrix-vector physical structure is considered in our\napproaches to ensure physical consistency, in particular, enabling a guarantee\nof positive semi-definiteness of the damping matrix. An aircraft benchmark\nsimulation is employed to demonstrate the efficacy of our methodology.\nEstimation accuracy and data efficiency are increased substantially by\nconsidering and enforcing more structured physical knowledge. Also, the\nfulfillment of the dissipative nature of the aerodynamics is validated\nnumerically.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Rui Dai",
            "Giulio Evangelisti",
            "Sandra Hirche"
        ],
        "published": "2024-05-27T14:20:37Z"
    },
    {
        "title": "Convex Relaxation for Solving Large-Margin Classifiers in Hyperbolic\n  Space",
        "link": "http://arxiv.org/abs/2405.17198v1",
        "abstract": "Hyperbolic spaces have increasingly been recognized for their outstanding\nperformance in handling data with inherent hierarchical structures compared to\ntheir Euclidean counterparts. However, learning in hyperbolic spaces poses\nsignificant challenges. In particular, extending support vector machines to\nhyperbolic spaces is in general a constrained non-convex optimization problem.\nPrevious and popular attempts to solve hyperbolic SVMs, primarily using\nprojected gradient descent, are generally sensitive to hyperparameters and\ninitializations, often leading to suboptimal solutions. In this work, by first\nrewriting the problem into a polynomial optimization, we apply semidefinite\nrelaxation and sparse moment-sum-of-squares relaxation to effectively\napproximate the optima. From extensive empirical experiments, these methods are\nshown to perform better than the projected gradient descent approach.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Sheng Yang",
            "Peihan Liu",
            "Cengiz Pehlevan"
        ],
        "published": "2024-05-27T14:19:53Z"
    },
    {
        "title": "Instability and Efficiency of Non-cooperative Games",
        "link": "http://arxiv.org/abs/2405.17196v1",
        "abstract": "It is well known that a non-cooperative game may have multiple equilibria. In\nthis paper we consider the efficiency of games, measured by the ratio between\nthe aggregate payoff over all Nash equilibria and that over all admissible\ncontrols. Such efficiency operator is typically unstable with respect to small\nperturbation of the game. This seemingly bad property can actually be a good\nnews in practice: it is possible that a small change of the game mechanism may\nimprove the efficiency of the game dramatically. We shall introduce a game\nmediator with limited resources and investigate the mechanism designs aiming to\nimprove the efficiency.",
        "subjects": [
            "cs.GT",
            "math.OC",
            "91A10, 91B03, 91B32"
        ],
        "authors": [
            "Jianfeng Zhang"
        ],
        "published": "2024-05-27T14:19:08Z"
    },
    {
        "title": "Anisotropic Gauss Reconstruction for Unoriented Point Clouds",
        "link": "http://arxiv.org/abs/2405.17193v1",
        "abstract": "Unoriented surface reconstructions based on the Gauss formula have attracted\nmuch attention due to their elegant mathematical formulation and excellent\nperformance. However, the isotropic characteristics of the formulation limit\ntheir capacity to leverage the anisotropic information within the point cloud.\nIn this work, we propose a novel anisotropic formulation by introducing a\nconvection term in the original Laplace operator. By choosing different\nvelocity vectors, the anisotropic feature can be exploited to construct more\neffective linear equations. Moreover, an adaptive selection strategy is\nintroduced for the velocity vector to further enhance the orientation and\nreconstruction performance of thin structures. Extensive experiments\ndemonstrate that our method achieves state-of-the-art performance and manages\nvarious challenging situations, especially for models with thin structures or\nsmall holes. The source code will be released on GitHub.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Yueji Ma",
            "Dong Xiao",
            "Zuoqiang Shi",
            "Bin Wang"
        ],
        "published": "2024-05-27T14:17:36Z"
    },
    {
        "title": "MCGAN: Enhancing GAN Training with Regression-Based Generator Loss",
        "link": "http://arxiv.org/abs/2405.17191v1",
        "abstract": "Generative adversarial networks (GANs) have emerged as a powerful tool for\ngenerating high-fidelity data. However, the main bottleneck of existing\napproaches is the lack of supervision on the generator training, which often\nresults in undamped oscillation and unsatisfactory performance. To address this\nissue, we propose an algorithm called Monte Carlo GAN (MCGAN). This approach,\nutilizing an innovative generative loss function, termly the regression loss,\nreformulates the generator training as a regression task and enables the\ngenerator training by minimizing the mean squared error between the\ndiscriminator's output of real data and the expected discriminator of fake\ndata. We demonstrate the desirable analytic properties of the regression loss,\nincluding discriminability and optimality, and show that our method requires a\nweaker condition on the discriminator for effective generator training. These\nproperties justify the strength of this approach to improve the training\nstability while retaining the optimality of GAN by leveraging strong\nsupervision of the regression loss. Numerical results on CIFAR-10 and CIFAR-100\ndatasets demonstrate that the proposed MCGAN significantly and consistently\nimproves the existing state-of-the-art GAN models in terms of quality,\naccuracy, training stability, and learned latent space. Furthermore, the\nproposed algorithm exhibits great flexibility for integrating with a variety of\nbackbone models to generate spatial images, temporal time-series, and\nspatio-temporal video data.",
        "subjects": [
            "cs.CV",
            "math.PR"
        ],
        "authors": [
            "Baoren Xiao",
            "Hao Ni",
            "Weixin Yang"
        ],
        "published": "2024-05-27T14:15:52Z"
    },
    {
        "title": "SoK: Leveraging Transformers for Malware Analysis",
        "link": "http://arxiv.org/abs/2405.17190v1",
        "abstract": "The introduction of transformers has been an important breakthrough for AI\nresearch and application as transformers are the foundation behind Generative\nAI. A promising application domain for transformers is cybersecurity, in\nparticular the malware domain analysis. The reason is the flexibility of the\ntransformer models in handling long sequential features and understanding\ncontextual relationships. However, as the use of transformers for malware\nanalysis is still in the infancy stage, it is critical to evaluate,\nsystematize, and contextualize existing literature to foster future research.\nThis Systematization of Knowledge (SoK) paper aims to provide a comprehensive\nanalysis of transformer-based approaches designed for malware analysis. Based\non our systematic analysis of existing knowledge, we structure and propose\ntaxonomies based on: (a) how different transformers are adapted, organized, and\nmodified across various use cases; and (b) how diverse feature types and their\nrepresentation capabilities are reflected. We also provide an inventory of\ndatasets used to explore multiple research avenues in the use of transformers\nfor malware analysis and discuss open challenges with future research\ndirections. We believe that this SoK paper will assist the research community\nin gaining detailed insights from existing work and will serve as a\nfoundational resource for implementing novel research using transformers for\nmalware analysis.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Pradip Kunwar",
            "Kshitiz Aryal",
            "Maanak Gupta",
            "Mahmoud Abdelsalam",
            "Elisa Bertino"
        ],
        "published": "2024-05-27T14:14:07Z"
    },
    {
        "title": "The SkatingVerse Workshop & Challenge: Methods and Results",
        "link": "http://arxiv.org/abs/2405.17188v1",
        "abstract": "The SkatingVerse Workshop & Challenge aims to encourage research in\ndeveloping novel and accurate methods for human action understanding. The\nSkatingVerse dataset used for the SkatingVerse Challenge has been publicly\nreleased. There are two subsets in the dataset, i.e., the training subset and\ntesting subset. The training subsets consists of 19,993 RGB video sequences,\nand the testing subsets consists of 8,586 RGB video sequences. Around 10\nparticipating teams from the globe competed in the SkatingVerse Challenge. In\nthis paper, we provide a brief summary of the SkatingVerse Workshop & Challenge\nincluding brief introductions to the top three methods. The submission\nleaderboard will be reopened for researchers that are interested in the human\naction understanding challenge. The benchmark dataset and other information can\nbe found at: https://skatingverse.github.io/.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jian Zhao",
            "Lei Jin",
            "Jianshu Li",
            "Zheng Zhu",
            "Yinglei Teng",
            "Jiaojiao Zhao",
            "Sadaf Gulshad",
            "Zheng Wang",
            "Bo Zhao",
            "Xiangbo Shu",
            "Yunchao Wei",
            "Xuecheng Nie",
            "Xiaojie Jin",
            "Xiaodan Liang",
            "Shin'ichi Satoh",
            "Yandong Guo",
            "Cewu Lu",
            "Junliang Xing",
            "Jane Shen Shengmei"
        ],
        "published": "2024-05-27T14:12:07Z"
    },
    {
        "title": "Memorize What Matters: Emergent Scene Decomposition from Multitraverse",
        "link": "http://arxiv.org/abs/2405.17187v2",
        "abstract": "Humans naturally retain memories of permanent elements, while ephemeral\nmoments often slip through the cracks of memory. This selective retention is\ncrucial for robotic perception, localization, and mapping. To endow robots with\nthis capability, we introduce 3D Gaussian Mapping (3DGM), a self-supervised,\ncamera-only offline mapping framework grounded in 3D Gaussian Splatting. 3DGM\nconverts multitraverse RGB videos from the same region into a Gaussian-based\nenvironmental map while concurrently performing 2D ephemeral object\nsegmentation. Our key observation is that the environment remains consistent\nacross traversals, while objects frequently change. This allows us to exploit\nself-supervision from repeated traversals to achieve environment-object\ndecomposition. More specifically, 3DGM formulates multitraverse environmental\nmapping as a robust differentiable rendering problem, treating pixels of the\nenvironment and objects as inliers and outliers, respectively. Using robust\nfeature distillation, feature residuals mining, and robust optimization, 3DGM\njointly performs 2D segmentation and 3D mapping without human intervention. We\nbuild the Mapverse benchmark, sourced from the Ithaca365 and nuPlan datasets,\nto evaluate our method in unsupervised 2D segmentation, 3D reconstruction, and\nneural rendering. Extensive results verify the effectiveness and potential of\nour method for self-driving and robotics.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "authors": [
            "Yiming Li",
            "Zehong Wang",
            "Yue Wang",
            "Zhiding Yu",
            "Zan Gojcic",
            "Marco Pavone",
            "Chen Feng",
            "Jose M. Alvarez"
        ],
        "published": "2024-05-27T14:11:17Z"
    },
    {
        "title": "A Pioneering Roadmap for ML-Driven Algorithmic Advancements in\n  Electrical Networks",
        "link": "http://arxiv.org/abs/2405.17184v2",
        "abstract": "To advance control, operation and planning tools of electrical networks with\nML is not straightforward. 110 experts were surveyed showing where and how ML\nalgorithmis could advance. This paper assesses this survey and research\nenvironment. Then it develops an innovation roadmap that helps align our\nresearch community towards a goal-oriented realisation of the opportunities\nthat AI upholds. This paper finds that the R\\&D environment of system operators\n(and the surrounding research ecosystem) needs adaptation to enable faster\ndevelopments with AI while maintaining high testing quality and safety. This\nroadmap may interest research centre managers in system operators, academics,\nand labs dedicated to advancing the next generation of tooling for electrical\nnetworks.",
        "subjects": [
            "eess.SY",
            "cs.SY",
            "eess.SP"
        ],
        "authors": [
            "Jochen L. Cremer",
            "Adrian Kelly",
            "Ricardo J. Bessa",
            "Milos Subasic",
            "Panagiotis N. Papadopoulos",
            "Samuel Young",
            "Amar Sagar",
            "Antoine Marot"
        ],
        "published": "2024-05-27T14:05:51Z"
    },
    {
        "title": "Exploring the Performance of Continuous-Time Dynamic Link Prediction\n  Algorithms",
        "link": "http://dx.doi.org/10.3390/app14083516",
        "abstract": "Dynamic Link Prediction (DLP) addresses the prediction of future links in\nevolving networks. However, accurately portraying the performance of DLP\nalgorithms poses challenges that might impede progress in the field.\nImportantly, common evaluation pipelines usually calculate ranking or binary\nclassification metrics, where the scores of observed interactions (positives)\nare compared with those of randomly generated ones (negatives). However, a\nsingle metric is not sufficient to fully capture the differences between DLP\nalgorithms, and is prone to overly optimistic performance evaluation. Instead,\nan in-depth evaluation should reflect performance variations across different\nnodes, edges, and time segments. In this work, we contribute tools to perform\nsuch a comprehensive evaluation. (1) We propose Birth-Death diagrams, a simple\nbut powerful visualization technique that illustrates the effect of time-based\ntrain-test splitting on the difficulty of DLP on a given dataset. (2) We\ndescribe an exhaustive taxonomy of negative sampling methods that can be used\nat evaluation time. (3) We carry out an empirical study of the effect of the\ndifferent negative sampling strategies. Our comparison between heuristics and\nstate-of-the-art memory-based methods on various real-world datasets confirms a\nstrong effect of using different negative sampling strategies on the test Area\nUnder the Curve (AUC). Moreover, we conduct a visual exploration of the\nprediction, with additional insights on which different types of errors are\nprominent over time.",
        "subjects": [
            "cs.SI",
            "cs.AI"
        ],
        "authors": [
            "Raphal Romero",
            "Maarten Buyl",
            "Tijl De Bie",
            "Jefrey Lijffijt"
        ],
        "published": "2024-05-27T14:03:28Z"
    },
    {
        "title": "Spectral regularization for adversarially-robust representation learning",
        "link": "http://arxiv.org/abs/2405.17181v1",
        "abstract": "The vulnerability of neural network classifiers to adversarial attacks is a\nmajor obstacle to their deployment in safety-critical applications.\nRegularization of network parameters during training can be used to improve\nadversarial robustness and generalization performance. Usually, the network is\nregularized end-to-end, with parameters at all layers affected by\nregularization. However, in settings where learning representations is key,\nsuch as self-supervised learning (SSL), layers after the feature representation\nwill be discarded when performing inference. For these models, regularizing up\nto the feature space is more suitable. To this end, we propose a new spectral\nregularizer for representation learning that encourages black-box adversarial\nrobustness in downstream classification tasks. In supervised classification\nsettings, we show empirically that this method is more effective in boosting\ntest accuracy and robustness than previously-proposed methods that regularize\nall layers of the network. We then show that this method improves the\nadversarial robustness of classifiers using representations learned with\nself-supervised training or transferred from another classification task. In\nall, our work begins to unveil how representational structure affects\nadversarial robustness.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Sheng Yang",
            "Jacob A. Zavatone-Veth",
            "Cengiz Pehlevan"
        ],
        "published": "2024-05-27T14:01:42Z"
    },
    {
        "title": "Boolean Gates Based on Liquid Marbles",
        "link": "http://arxiv.org/abs/2405.17180v1",
        "abstract": "Liquid Marbles are liquid droplets encapsulated by hydrophobic powder\nparticles. They offer an efficient approach to handling liquids due to their\nnon-wetting nature. In this work, starting from the interaction gate proposed\nin the literature, we describe how the logic gates AND, XOR, OR, NOT, NAND, and\nNOR could be realized. Given the irreversibility and non-conservativeness of\nclassical gates, we also discuss a possible implementation of the Toffoli gate,\na reversible gate, and of the Fredkin gate, a reversible and conservative gate.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Luca Cavenaghi",
            "Sandro Erba",
            "Claudio Zandron"
        ],
        "published": "2024-05-27T14:01:31Z"
    },
    {
        "title": "DreamMat: High-quality PBR Material Generation with Geometry- and\n  Light-aware Diffusion Models",
        "link": "http://arxiv.org/abs/2405.17176v1",
        "abstract": "2D diffusion model, which often contains unwanted baked-in shading effects\nand results in unrealistic rendering effects in the downstream applications.\nGenerating Physically Based Rendering (PBR) materials instead of just RGB\ntextures would be a promising solution. However, directly distilling the PBR\nmaterial parameters from 2D diffusion models still suffers from incorrect\nmaterial decomposition, such as baked-in shading effects in albedo. We\nintroduce DreamMat, an innovative approach to resolve the aforementioned\nproblem, to generate high-quality PBR materials from text descriptions. We find\nout that the main reason for the incorrect material distillation is that\nlarge-scale 2D diffusion models are only trained to generate final shading\ncolors, resulting in insufficient constraints on material decomposition during\ndistillation. To tackle this problem, we first finetune a new light-aware 2D\ndiffusion model to condition on a given lighting environment and generate the\nshading results on this specific lighting condition. Then, by applying the same\nenvironment lights in the material distillation, DreamMat can generate\nhigh-quality PBR materials that are not only consistent with the given geometry\nbut also free from any baked-in shading effects in albedo. Extensive\nexperiments demonstrate that the materials produced through our methods exhibit\ngreater visual appeal to users and achieve significantly superior rendering\nquality compared to baseline methods, which are preferable for downstream tasks\nsuch as game and film production.",
        "subjects": [
            "cs.GR",
            "cs.AI"
        ],
        "authors": [
            "Yuqing Zhang",
            "Yuan Liu",
            "Zhiyu Xie",
            "Lei Yang",
            "Zhongyuan Liu",
            "Mengzhou Yang",
            "Runze Zhang",
            "Qilong Kou",
            "Cheng Lin",
            "Wenping Wang",
            "Xiaogang Jin"
        ],
        "published": "2024-05-27T13:55:08Z"
    },
    {
        "title": "Partitioning complete geometric graphs into plane subgraphs",
        "link": "http://arxiv.org/abs/2405.17172v1",
        "abstract": "A \\emph{complete geometric graph} consists of a set $P$ of $n$ points in the\nplane, in general position, and all segments (edges) connecting them. It is a\nwell known question of Bose, Hurtado, Rivera-Campo, and Wood, whether there\nexists a positive constant $c<1$, such that every complete geometric graph on\n$n$ points can be partitioned into at most $cn$ plane graphs (that is,\nnoncrossing subgraphs). We answer this question in the affirmative in the\nspecial case where the underlying point set $P$ is \\emph{dense}, which means\nthat the ratio between the maximum and the minimum distances in $P$ is of the\norder of $\\Theta(\\sqrt{n})$.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "authors": [
            "Adrian Dumitrescu",
            "Jnos Pach"
        ],
        "published": "2024-05-27T13:51:21Z"
    },
    {
        "title": "Coordinating robotized construction using advanced robotic simulation:\n  The case of collaborative brick wall assembly",
        "link": "http://arxiv.org/abs/2405.17171v1",
        "abstract": "Utilizing robotic systems in the construction industry is gaining popularity\ndue to their build time, precision, and efficiency. In this paper, we introduce\na system that allows the coordination of multiple manipulator robots for\nconstruction activities. As a case study, we chose robotic brick wall assembly.\nBy utilizing a multi robot system where arm manipulators collaborate with each\nother, the entirety of a potentially long wall can be assembled simultaneously.\nHowever, the reduction of overall bricklaying time is dependent on the\nminimization of time required for each individual manipulator. In this paper,\nwe execute the simulation with various placements of material and the robots\nbase, as well as different robot configurations, to determine the optimal\nposition of the robot and material and the best configuration for the robot.\nThe simulation results provide users with insights into how to find the best\nplacement of robots and raw materials for brick wall assembly.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Mohammad Reza Kolani",
            "Stavros Nousias",
            "Andr Borrmann"
        ],
        "published": "2024-05-27T13:50:17Z"
    },
    {
        "title": "Forecasting Four Business Cycle Phases Using Machine Learning: A Case\n  Study of US and EuroZone",
        "link": "http://arxiv.org/abs/2405.17170v1",
        "abstract": "Understanding the business cycle is crucial for building economic stability,\nguiding business planning, and informing investment decisions. The business\ncycle refers to the recurring pattern of expansion and contraction in economic\nactivity over time. Economic analysis is inherently complex, incorporating a\nmyriad of factors (such as macroeconomic indicators, political decisions). This\ncomplexity makes it challenging to fully account for all variables when\ndetermining the current state of the economy and predicting its future\ntrajectory in the upcoming months. The objective of this study is to\ninvestigate the capacity of machine learning models in automatically analyzing\nthe state of the economic, with the goal of forecasting business phases\n(expansion, slowdown, recession and recovery) in the United States and the\nEuroZone. We compared three different machine learning approaches to classify\nthe phases of the business cycle, and among them, the Multinomial Logistic\nRegression (MLR) achieved the best results. Specifically, MLR got the best\nresults by achieving the accuracy of 65.25% (Top1) and 84.74% (Top2) for the\nEuroZone and 75% (Top1) and 92.14% (Top2) for the United States. These results\ndemonstrate the potential of machine learning techniques to predict business\ncycles accurately, which can aid in making informed decisions in the fields of\neconomics and finance.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Elvys Linhares Pontes",
            "Mohamed Benjannet",
            "Raymond Yung"
        ],
        "published": "2024-05-27T13:49:24Z"
    },
    {
        "title": "Partitioned Hankel-based Diffusion Models for Few-shot Low-dose CT\n  Reconstruction",
        "link": "http://arxiv.org/abs/2405.17167v1",
        "abstract": "Low-dose computed tomography (LDCT) plays a vital role in clinical\napplications by mitigating radiation risks. Nevertheless, reducing radiation\ndoses significantly degrades image quality. Concurrently, common deep learning\nmethods demand extensive data, posing concerns about privacy, cost, and time\nconstraints. Consequently, we propose a few-shot low-dose CT reconstruction\nmethod using Partitioned Hankel-based Diffusion (PHD) models. During the prior\nlearning stage, the projection data is first transformed into multiple\npartitioned Hankel matrices. Structured tensors are then extracted from these\nmatrices to facilitate prior learning through multiple diffusion models. In the\niterative reconstruction stage, an iterative stochastic differential equation\nsolver is employed along with data consistency constraints to update the\nacquired projection data. Furthermore, penalized weighted least-squares and\ntotal variation techniques are introduced to enhance the resulting image\nquality. The results approximate those of normal-dose counterparts, validating\nPHD model as an effective and practical model for reducing artifacts and noise\nwhile preserving image quality.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Wenhao Zhang",
            "Bin Huang",
            "Shuyue Chen",
            "Xiaoling Xu",
            "Weiwen Wu",
            "Qiegen Liu"
        ],
        "published": "2024-05-27T13:44:53Z"
    },
    {
        "title": "WeiPer: OOD Detection using Weight Perturbations of Class Projections",
        "link": "http://arxiv.org/abs/2405.17164v2",
        "abstract": "Recent advances in out-of-distribution (OOD) detection on image data show\nthat pre-trained neural network classifiers can separate in-distribution (ID)\nfrom OOD data well, leveraging the class-discriminative ability of the model\nitself. Methods have been proposed that either use logit information directly\nor that process the model's penultimate layer activations. With \"WeiPer\", we\nintroduce perturbations of the class projections in the final fully connected\nlayer which creates a richer representation of the input. We show that this\nsimple trick can improve the OOD detection performance of a variety of methods\nand additionally propose a distance-based method that leverages the properties\nof the augmented WeiPer space. We achieve state-of-the-art OOD detection\nresults across multiple benchmarks of the OpenOOD framework, especially\npronounced in difficult settings in which OOD samples are positioned close to\nthe training set distribution. We support our findings with theoretical\nmotivations and empirical observations, and run extensive ablations to provide\ninsights into why WeiPer works.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Maximilian Granz",
            "Manuel Heurich",
            "Tim Landgraf"
        ],
        "published": "2024-05-27T13:38:28Z"
    },
    {
        "title": "Injecting Hamiltonian Architectural Bias into Deep Graph Networks for\n  Long-Range Propagation",
        "link": "http://arxiv.org/abs/2405.17163v1",
        "abstract": "The dynamics of information diffusion within graphs is a critical open issue\nthat heavily influences graph representation learning, especially when\nconsidering long-range propagation. This calls for principled approaches that\ncontrol and regulate the degree of propagation and dissipation of information\nthroughout the neural flow. Motivated by this, we introduce (port-)Hamiltonian\nDeep Graph Networks, a novel framework that models neural information flow in\ngraphs by building on the laws of conservation of Hamiltonian dynamical\nsystems. We reconcile under a single theoretical and practical framework both\nnon-dissipative long-range propagation and non-conservative behaviors,\nintroducing tools from mechanical systems to gauge the equilibrium between the\ntwo components. Our approach can be applied to general message-passing\narchitectures, and it provides theoretical guarantees on information\nconservation in time. Empirical results prove the effectiveness of our\nport-Hamiltonian scheme in pushing simple graph convolutional architectures to\nstate-of-the-art performance in long-range benchmarks.",
        "subjects": [
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Simon Heilig",
            "Alessio Gravina",
            "Alessandro Trenta",
            "Claudio Gallicchio",
            "Davide Bacciu"
        ],
        "published": "2024-05-27T13:36:50Z"
    },
    {
        "title": "Stop! In the Name of Flaws: Disentangling Personal Names and\n  Sociodemographic Attributes in NLP",
        "link": "http://arxiv.org/abs/2405.17159v1",
        "abstract": "Personal names simultaneously differentiate individuals and categorize them\nin ways that are important in a given society. While the natural language\nprocessing community has thus associated personal names with sociodemographic\ncharacteristics in a variety of tasks, researchers have engaged to varying\ndegrees with the established methodological problems in doing so. To guide\nfuture work, we present an interdisciplinary background on names and naming. We\nthen survey the issues inherent to associating names with sociodemographic\nattributes, covering problems of validity (e.g., systematic error, construct\nvalidity), as well as ethical concerns (e.g., harms, differential impact,\ncultural insensitivity). Finally, we provide guiding questions along with\nnormative recommendations to avoid validity and ethical pitfalls when dealing\nwith names and sociodemographic characteristics in natural language processing.",
        "subjects": [
            "cs.CL",
            "cs.CY",
            "cs.HC"
        ],
        "authors": [
            "Vagrant Gautam",
            "Arjun Subramonian",
            "Anne Lauscher",
            "Os Keyes"
        ],
        "published": "2024-05-27T13:33:29Z"
    },
    {
        "title": "PatchScaler: An Efficient Patch-independent Diffusion Model for\n  Super-Resolution",
        "link": "http://arxiv.org/abs/2405.17158v1",
        "abstract": "Diffusion models significantly improve the quality of super-resolved images\nwith their impressive content generation capabilities. However, the huge\ncomputational costs limit the applications of these methods.Recent efforts have\nexplored reasonable inference acceleration to reduce the number of sampling\nsteps, but the computational cost remains high as each step is performed on the\nentire image.This paper introduces PatchScaler, a patch-independent\ndiffusion-based single image super-resolution (SR) method, designed to enhance\nthe efficiency of the inference process.The proposed method is motivated by the\nobservation that not all the image patches within an image need the same\nsampling steps for reconstructing high-resolution images.Based on this\nobservation, we thus develop a Patch-adaptive Group Sampling (PGS) to divide\nfeature patches into different groups according to the patch-level\nreconstruction difficulty and dynamically assign an appropriate sampling\nconfiguration for each group so that the inference speed can be better\naccelerated.In addition, to improve the denoising ability at each step of the\nsampling, we develop a texture prompt to guide the estimations of the diffusion\nmodel by retrieving high-quality texture priors from a patch-independent\nreference texture memory.Experiments show that our PatchScaler achieves\nfavorable performance in both quantitative and qualitative evaluations with\nfast inference speed.Our code and model are available at\n\\url{https://github.com/yongliuy/PatchScaler}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yong Liu",
            "Hang Dong",
            "Jinshan Pan",
            "Qingji Dong",
            "Kai Chen",
            "Rongxiang Zhang",
            "Xing Mei",
            "Lean Fu",
            "Fei Wang"
        ],
        "published": "2024-05-27T13:31:46Z"
    },
    {
        "title": "The Scaling Law in Stellar Light Curves",
        "link": "http://arxiv.org/abs/2405.17156v1",
        "abstract": "Analyzing time series of fluxes from stars, known as stellar light curves,\ncan reveal valuable information about stellar properties. However, most current\nmethods rely on extracting summary statistics, and studies using deep learning\nhave been limited to supervised approaches. In this research, we investigate\nthe scaling law properties that emerge when learning from astronomical time\nseries data using self-supervised techniques. By employing the GPT-2\narchitecture, we show the learned representation improves as the number of\nparameters increases from $10^4$ to $10^9$, with no signs of performance\nplateauing. We demonstrate that a self-supervised Transformer model achieves\n3-10 times the sample efficiency compared to the state-of-the-art supervised\nlearning model when inferring the surface gravity of stars as a downstream\ntask. Our research lays the groundwork for analyzing stellar light curves by\nexamining them through large-scale auto-regressive generative models.",
        "subjects": [
            "astro-ph.IM",
            "astro-ph.SR",
            "cs.LG"
        ],
        "authors": [
            "Jia-Shu Pan",
            "Yuan-Sen Ting",
            "Yang Huang",
            "Jie Yu",
            "Ji-Feng Liu"
        ],
        "published": "2024-05-27T13:31:03Z"
    },
    {
        "title": "CoSLight: Co-optimizing Collaborator Selection and Decision-making to\n  Enhance Traffic Signal Control",
        "link": "http://arxiv.org/abs/2405.17152v1",
        "abstract": "Effective multi-intersection collaboration is pivotal for\nreinforcement-learning-based traffic signal control to alleviate congestion.\nExisting work mainly chooses neighboring intersections as collaborators.\nHowever, quite an amount of congestion, even some wide-range congestion, is\ncaused by non-neighbors failing to collaborate. To address these issues, we\npropose to separate the collaborator selection as a second policy to be\nlearned, concurrently being updated with the original signal-controlling\npolicy. Specifically, the selection policy in real-time adaptively selects the\nbest teammates according to phase- and intersection-level features. Empirical\nresults on both synthetic and real-world datasets provide robust validation for\nthe superiority of our approach, offering significant improvements over\nexisting state-of-the-art methods. The code is available at\nhttps://github.com/AnonymousAccountss/CoSLight.",
        "subjects": [
            "cs.MA",
            "cs.AI"
        ],
        "authors": [
            "Jingqing Ruan",
            "Ziyue Li",
            "Hua Wei",
            "Haoyuan Jiang",
            "Jiaming Lu",
            "Xuantang Xiong",
            "Hangyu Mao",
            "Rui Zhao"
        ],
        "published": "2024-05-27T13:26:59Z"
    },
    {
        "title": "Smoke and Mirrors in Causal Downstream Tasks",
        "link": "http://arxiv.org/abs/2405.17151v1",
        "abstract": "Machine Learning and AI have the potential to transform data-driven\nscientific discovery, enabling accurate predictions for several scientific\nphenomena. As many scientific questions are inherently causal, this paper looks\nat the causal inference task of treatment effect estimation, where we assume\nbinary effects that are recorded as high-dimensional images in a Randomized\nControlled Trial (RCT). Despite being the simplest possible setting and a\nperfect fit for deep learning, we theoretically find that many common choices\nin the literature may lead to biased estimates. To test the practical impact of\nthese considerations, we recorded the first real-world benchmark for causal\ninference downstream tasks on high-dimensional observations as an RCT studying\nhow garden ants (Lasius neglectus) respond to microparticles applied onto their\ncolony members by hygienic grooming. Comparing 6 480 models fine-tuned from\nstate-of-the-art visual backbones, we find that the sampling and modeling\nchoices significantly affect the accuracy of the causal estimate, and that\nclassification accuracy is not a proxy thereof. We further validated the\nanalysis, repeating it on a synthetically generated visual data set controlling\nthe causal model. Our results suggest that future benchmarks should carefully\nconsider real downstream scientific questions, especially causal ones. Further,\nwe highlight guidelines for representation learning methods to help answer\ncausal questions in the sciences. All code and data will be released.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Riccardo Cadei",
            "Lukas Lindorfer",
            "Sylvia Cremer",
            "Cordelia Schmid",
            "Francesco Locatello"
        ],
        "published": "2024-05-27T13:26:34Z"
    },
    {
        "title": "Deep Learning-based Joint Channel Prediction and Multibeam Precoding for\n  LEO Satellite Internet of Things",
        "link": "http://arxiv.org/abs/2405.17150v1",
        "abstract": "Low earth orbit (LEO) satellite internet of things (IoT) is a promising way\nachieving global Internet of Everything, and thus has been widely recognized as\nan important component of sixth-generation (6G) wireless networks. Yet, due to\nhigh-speed movement of the LEO satellite, it is challenging to acquire timely\nchannel state information (CSI) and design effective multibeam precoding for\nvarious IoT applications. To this end, this paper provides a deep learning\n(DL)-based joint channel prediction and multibeam precoding scheme under\nadverse environments, e.g., high Doppler shift, long propagation delay, and low\nsatellite payload. {Specifically, this paper first designs a DL-based channel\nprediction scheme by using convolutional neural networks (CNN) and long short\nterm memory (LSTM), which predicts the CSI of current time slot according to\nthat of previous time slots. With the predicted CSI, this paper designs a\nDL-based robust multibeam precoding scheme by using a channel augmentation\nmethod based on variational auto-encoder (VAE).} Finally, extensive simulation\nresults confirm the effectiveness and robustness of the proposed scheme in LEO\nsatellite IoT.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Ming Ying",
            "Xiaoming Chen",
            "Qiao Qi",
            "Wolfgang Gerstacker"
        ],
        "published": "2024-05-27T13:23:23Z"
    },
    {
        "title": "LCM: Locally Constrained Compact Point Cloud Model for Masked Point\n  Modeling",
        "link": "http://arxiv.org/abs/2405.17149v1",
        "abstract": "The pre-trained point cloud model based on Masked Point Modeling (MPM) has\nexhibited substantial improvements across various tasks. However, these models\nheavily rely on the Transformer, leading to quadratic complexity and limited\ndecoder, hindering their practice application. To address this limitation, we\nfirst conduct a comprehensive analysis of existing Transformer-based MPM,\nemphasizing the idea that redundancy reduction is crucial for point cloud\nanalysis. To this end, we propose a Locally constrained Compact point cloud\nModel (LCM) consisting of a locally constrained compact encoder and a locally\nconstrained Mamba-based decoder. Our encoder replaces self-attention with our\nlocal aggregation layers to achieve an elegant balance between performance and\nefficiency. Considering the varying information density between masked and\nunmasked patches in the decoder inputs of MPM, we introduce a locally\nconstrained Mamba-based decoder. This decoder ensures linear complexity while\nmaximizing the perception of point cloud geometry information from unmasked\npatches with higher information density. Extensive experimental results show\nthat our compact model significantly surpasses existing Transformer-based\nmodels in both performance and efficiency, especially our LCM-based Point-MAE\nmodel, compared to the Transformer-based model, achieved an improvement of\n2.24%, 0.87%, and 0.94% in performance on the three variants of ScanObjectNN\nwhile reducing parameters by 88% and computation by 73%.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yaohua Zha",
            "Naiqi Li",
            "Yanzi Wang",
            "Tao Dai",
            "Hang Guo",
            "Bin Chen",
            "Zhi Wang",
            "Zhihao Ouyang",
            "Shu-Tao Xia"
        ],
        "published": "2024-05-27T13:19:23Z"
    },
    {
        "title": "Large Language Models (LLMs): Deployment, Tokenomics and Sustainability",
        "link": "http://arxiv.org/abs/2405.17147v1",
        "abstract": "The rapid advancement of Large Language Models (LLMs) has significantly\nimpacted human-computer interaction, epitomized by the release of GPT-4o, which\nintroduced comprehensive multi-modality capabilities. In this paper, we first\nexplored the deployment strategies, economic considerations, and sustainability\nchallenges associated with the state-of-the-art LLMs. More specifically, we\ndiscussed the deployment debate between Retrieval-Augmented Generation (RAG)\nand fine-tuning, highlighting their respective advantages and limitations.\nAfter that, we quantitatively analyzed the requirement of xPUs in training and\ninference. Additionally, for the tokenomics of LLM services, we examined the\nbalance between performance and cost from the quality of experience (QoE)'s\nperspective of end users. Lastly, we envisioned the future hybrid architecture\nof LLM processing and its corresponding sustainability concerns, particularly\nin the environmental carbon footprint impact. Through these discussions, we\nprovided a comprehensive overview of the operational and strategic\nconsiderations essential for the responsible development and deployment of\nLLMs.",
        "subjects": [
            "cs.MM"
        ],
        "authors": [
            "Haiwei Dong",
            "Shuang Xie"
        ],
        "published": "2024-05-27T13:16:29Z"
    },
    {
        "title": "Compressed-Language Models for Understanding Compressed File Formats: a\n  JPEG Exploration",
        "link": "http://arxiv.org/abs/2405.17146v1",
        "abstract": "This study investigates whether Compressed-Language Models (CLMs), i.e.\nlanguage models operating on raw byte streams from Compressed File\nFormats~(CFFs), can understand files compressed by CFFs. We focus on the JPEG\nformat as a representative CFF, given its commonality and its\nrepresentativeness of key concepts in compression, such as entropy coding and\nrun-length encoding. We test if CLMs understand the JPEG format by probing\ntheir capabilities to perform along three axes: recognition of inherent file\nproperties, handling of files with anomalies, and generation of new files. Our\nfindings demonstrate that CLMs can effectively perform these tasks. These\nresults suggest that CLMs can understand the semantics of compressed data when\ndirectly operating on the byte streams of files produced by CFFs. The\npossibility to directly operate on raw compressed files offers the promise to\nleverage some of their remarkable characteristics, such as their ubiquity,\ncompactness, multi-modality and segment-nature.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Juan C. Prez",
            "Alejandro Pardo",
            "Mattia Soldan",
            "Hani Itani",
            "Juan Leon-Alcazar",
            "Bernard Ghanem"
        ],
        "published": "2024-05-27T13:09:23Z"
    },
    {
        "title": "MVMS-RCN: A Dual-Domain Unfolding CT Reconstruction with\n  Multi-sparse-view and Multi-scale Refinement-correction",
        "link": "http://arxiv.org/abs/2405.17141v1",
        "abstract": "X-ray Computed Tomography (CT) is one of the most important diagnostic\nimaging techniques in clinical applications. Sparse-view CT imaging reduces the\nnumber of projection views to a lower radiation dose and alleviates the\npotential risk of radiation exposure. Most existing deep learning (DL) and deep\nunfolding sparse-view CT reconstruction methods: 1) do not fully use the\nprojection data; 2) do not always link their architecture designs to a\nmathematical theory; 3) do not flexibly deal with multi-sparse-view\nreconstruction assignments. This paper aims to use mathematical ideas and\ndesign optimal DL imaging algorithms for sparse-view tomography\nreconstructions. We propose a novel dual-domain deep unfolding unified\nframework that offers a great deal of flexibility for multi-sparse-view CT\nreconstruction with different sampling views through a single model. This\nframework combines the theoretical advantages of model-based methods with the\nsuperior reconstruction performance of DL-based methods, resulting in the\nexpected generalizability of DL. We propose a refinement module that utilizes\nunfolding projection domain to refine full-sparse-view projection errors, as\nwell as an image domain correction module that distills multi-scale geometric\nerror corrections to reconstruct sparse-view CT. This provides us with a new\nway to explore the potential of projection information and a new perspective on\ndesigning network architectures. All parameters of our proposed framework are\nlearnable end to end, and our method possesses the potential to be applied to\nplug-and-play reconstruction. Extensive experiments demonstrate that our\nframework is superior to other existing state-of-the-art methods. Our source\ncodes are available at https://github.com/fanxiaohong/MVMS-RCN.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Xiaohong Fan",
            "Ke Chen",
            "Huaming Yi",
            "Yin Yang",
            "Jianping Zhang"
        ],
        "published": "2024-05-27T13:01:25Z"
    },
    {
        "title": "SDL-MVS: View Space and Depth Deformable Learning Paradigm for\n  Multi-View Stereo Reconstruction in Remote Sensing",
        "link": "http://arxiv.org/abs/2405.17140v1",
        "abstract": "Research on multi-view stereo based on remote sensing images has promoted the\ndevelopment of large-scale urban 3D reconstruction. However, remote sensing\nmulti-view image data suffers from the problems of occlusion and uneven\nbrightness between views during acquisition, which leads to the problem of\nblurred details in depth estimation. To solve the above problem, we re-examine\nthe deformable learning method in the Multi-View Stereo task and propose a\nnovel paradigm based on view Space and Depth deformable Learning (SDL-MVS),\naiming to learn deformable interactions of features in different view spaces\nand deformably model the depth ranges and intervals to enable high accurate\ndepth estimation. Specifically, to solve the problem of view noise caused by\nocclusion and uneven brightness, we propose a Progressive Space deformable\nSampling (PSS) mechanism, which performs deformable learning of sampling points\nin the 3D frustum space and the 2D image space in a progressive manner to embed\nsource features to the reference feature adaptively. To further optimize the\ndepth, we introduce Depth Hypothesis deformable Discretization (DHD), which\nachieves precise positioning of the depth prior by adaptively adjusting the\ndepth range hypothesis and performing deformable discretization of the depth\ninterval hypothesis. Finally, our SDL-MVS achieves explicit modeling of\nocclusion and uneven brightness faced in multi-view stereo through the\ndeformable learning paradigm of view space and depth, achieving accurate\nmulti-view depth estimation. Extensive experiments on LuoJia-MVS and WHU\ndatasets show that our SDL-MVS reaches state-of-the-art performance. It is\nworth noting that our SDL-MVS achieves an MAE error of 0.086, an accuracy of\n98.9% for <0.6m, and 98.9% for <3-interval on the LuoJia-MVS dataset under the\npremise of three views as input.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yong-Qiang Mao",
            "Hanbo Bi",
            "Liangyu Xu",
            "Kaiqiang Chen",
            "Zhirui Wang",
            "Xian Sun",
            "Kun Fu"
        ],
        "published": "2024-05-27T12:59:46Z"
    },
    {
        "title": "Synergy and Diversity in CLIP: Enhancing Performance Through Adaptive\n  Backbone Ensembling",
        "link": "http://arxiv.org/abs/2405.17139v1",
        "abstract": "Contrastive Language-Image Pretraining (CLIP) stands out as a prominent\nmethod for image representation learning. Various architectures, from vision\ntransformers (ViTs) to convolutional networks (ResNets) have been trained with\nCLIP to serve as general solutions to diverse vision tasks. This paper explores\nthe differences across various CLIP-trained vision backbones. Despite using the\nsame data and training objective, we find that these architectures have notably\ndifferent representations, different classification performance across\ndatasets, and different robustness properties to certain types of image\nperturbations. Our findings indicate a remarkable possible synergy across\nbackbones by leveraging their respective strengths. In principle,\nclassification accuracy could be improved by over 40 percentage with an\ninformed selection of the optimal backbone per test example.Using this insight,\nwe develop a straightforward yet powerful approach to adaptively ensemble\nmultiple backbones. The approach uses as few as one labeled example per class\nto tune the adaptive combination of backbones. On a large collection of\ndatasets, the method achieves a remarkable increase in accuracy of up to 39.1%\nover the best single backbone, well beyond traditional ensembles",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Cristian Rodriguez-Opazo",
            "Ehsan Abbasnejad",
            "Damien Teney",
            "Edison Marrese-Taylor",
            "Hamed Damirchi",
            "Anton van den Hengel"
        ],
        "published": "2024-05-27T12:59:35Z"
    },
    {
        "title": "CMOSS: A Reliable, Motif-based Columnar Molecular Storage System",
        "link": "http://arxiv.org/abs/2405.17138v1",
        "abstract": "The surge in demand for cost-effective, durable long-term archival media,\ncoupled with density limitations of contemporary magnetic media, has resulted\nin synthetic DNA emerging as a promising new alternative. Despite its benefits,\nstoring data on DNA poses several challenges as the technology used for\nreading/writing data and achieving random access on DNA are highly error prone.\nIn order to deal with such errors, it is important to design efficient\npipelines that can carefully use redundancy to mask errors without amplifying\noverall cost. In this work, we present Columnar MOlecular Storage System\n(CMOSS), a novel, end-to-end DNA storage pipeline that can provide\nerror-tolerant data storage at low read/write costs. CMOSS differs from SOTA on\nthree fronts (i) a motif-based, vertical layout in contrast to nucleotide-based\nhorizontal layout used by SOTA, (ii) merged consensus calling and decoding\nenabled by the vertical layout, and (iii) a flexible, fixed-size, block-based\ndata organization for random access over DNA storage in contrast to the\nvariable-sized, object-based access used by SOTA. Using an in-depth evaluation\nvia simulation studies and real wet-lab experiments, we demonstrate the\nbenefits of various CMOSS design choices. We make the entire pipeline together\nwith the read datasets openly available to the community for faithful\nreproduction and furthering research.",
        "subjects": [
            "cs.DB"
        ],
        "authors": [
            "Eugenio Marinelli",
            "Yiqing Yan",
            "Virginie Magnone",
            "Pascal Barbry",
            "Raja Appuswamy"
        ],
        "published": "2024-05-27T12:56:12Z"
    },
    {
        "title": "Jump-teaching: Ultra Efficient and Robust Learning with Noisy Label",
        "link": "http://arxiv.org/abs/2405.17137v2",
        "abstract": "Sample selection is the most straightforward technique to combat label noise,\naiming to distinguish mislabeled samples during training and avoid the\ndegradation of the robustness of the model. In the workflow, $\\textit{selecting\npossibly clean data}$ and $\\textit{model update}$ are iterative. However, their\ninterplay and intrinsic characteristics hinder the robustness and efficiency of\nlearning with noisy labels: 1) The model chooses clean data with selection\nbias, leading to the accumulated error in the model update. 2) Most selection\nstrategies leverage partner networks or supplementary information to mitigate\nlabel corruption, albeit with increased computation resources and lower\nthroughput speed. Therefore, we employ only one network with the jump manner\nupdate to decouple the interplay and mine more semantic information from the\nloss for a more precise selection. Specifically, the selection of clean data\nfor each model update is based on one of the prior models, excluding the last\niteration. The strategy of model update exhibits a jump behavior in the form.\nMoreover, we map the outputs of the network and labels into the same semantic\nfeature space, respectively. In this space, a detailed and simple loss\ndistribution is generated to distinguish clean samples more effectively. Our\nproposed approach achieves almost up to $2.53\\times$ speedup, $0.46\\times$ peak\nmemory footprint, and superior robustness over state-of-the-art works with\nvarious noise settings.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Kangye Ji",
            "Fei Cheng",
            "Zeqing Wang",
            "Bohu Huang"
        ],
        "published": "2024-05-27T12:54:09Z"
    },
    {
        "title": "PanoTree: Autonomous Photo-Spot Explorer in Virtual Reality Scenes",
        "link": "http://arxiv.org/abs/2405.17136v1",
        "abstract": "Social VR platforms enable social, economic, and creative activities by\nallowing users to create and share their own virtual spaces. In social VR,\nphotography within a VR scene is an important indicator of visitors'\nactivities. Although automatic identification of photo spots within a VR scene\ncan facilitate the process of creating a VR scene and enhance the visitor\nexperience, there are challenges in quantitatively evaluating photos taken in\nthe VR scene and efficiently exploring the large VR scene. We propose PanoTree,\nan automated photo-spot explorer in VR scenes. To assess the aesthetics of\nimages captured in VR scenes, a deep scoring network is trained on a large\ndataset of photos collected by a social VR platform to determine whether humans\nare likely to take similar photos. Furthermore, we propose a Hierarchical\nOptimistic Optimization (HOO)-based search algorithm to efficiently explore 3D\nVR spaces with the reward from the scoring network. Our user study shows that\nthe scoring network achieves human-level performance in distinguishing randomly\ntaken images from those taken by humans. In addition, we show applications\nusing the explored photo spots, such as automatic thumbnail generation, support\nfor VR world creation, and visitor flow planning within a VR scene.",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "I.3; I.4"
        ],
        "authors": [
            "Tomohiro Hayase",
            "Braun Sacha",
            "Hikari Yanagawa",
            "Itsuki Orito",
            "Yuichi Hiroi"
        ],
        "published": "2024-05-27T12:54:05Z"
    },
    {
        "title": "Locally Testing Model Detections for Semantic Global Concepts",
        "link": "http://arxiv.org/abs/2405.17523v2",
        "abstract": "Ensuring the quality of black-box Deep Neural Networks (DNNs) has become ever\nmore significant, especially in safety-critical domains such as automated\ndriving. While global concept encodings generally enable a user to test a model\nfor a specific concept, linking global concept encodings to the local\nprocessing of single network inputs reveals their strengths and limitations.\nOur proposed framework global-to-local Concept Attribution (glCA) uses\napproaches from local (why a specific prediction originates) and global (how a\nmodel works generally) eXplainable Artificial Intelligence (xAI) to test DNNs\nfor a predefined semantical concept locally. The approach allows for\nconditioning local, post-hoc explanations on predefined semantic concepts\nencoded as linear directions in the model's latent space. Pixel-exact scoring\nconcerning the global concept usage assists the tester in further understanding\nthe model processing of single data points for the selected concept. Our\napproach has the advantage of fully covering the model-internal encoding of the\nsemantic concept and allowing the localization of relevant concept-related\ninformation. The results show major differences in the local perception and\nusage of individual global concept encodings and demand for further\ninvestigations regarding obtaining thorough semantic concept encodings.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Franz Motzkus",
            "Georgii Mikriukov",
            "Christian Hellert",
            "Ute Schmid"
        ],
        "published": "2024-05-27T12:52:45Z"
    },
    {
        "title": "Your decision path does matter in pre-training industrial recommenders\n  with multi-source behaviors",
        "link": "http://arxiv.org/abs/2405.17132v1",
        "abstract": "Online service platforms offering a wide range of services through miniapps\nhave become crucial for users who visit these platforms with clear intentions\nto find services they are interested in. Aiming at effective content delivery,\ncross-domain recommendation are introduced to learn high-quality\nrepresentations by transferring behaviors from data-rich scenarios. However,\nthese methods overlook the impact of the decision path that users take when\nconduct behaviors, that is, users ultimately exhibit different behaviors based\non various intents. To this end, we propose HIER, a novel Hierarchical decIsion\npath Enhanced Representation learning for cross-domain recommendation. With the\nhelp of graph neural networks for high-order topological information of the\nknowledge graph between multi-source behaviors, we further adaptively learn\ndecision paths through well-designed exemplar-level and information bottleneck\nbased contrastive learning. Extensive experiments in online and offline\nenvironments show the superiority of HIER.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Chunjing Gan",
            "Binbin Hu",
            "Bo Huang",
            "Ziqi Liu",
            "Jian Ma",
            "Zhiqiang Zhang",
            "Wenliang Zhong",
            "Jun Zhou"
        ],
        "published": "2024-05-27T12:49:07Z"
    },
    {
        "title": "Exploiting the Layered Intrinsic Dimensionality of Deep Models for\n  Practical Adversarial Training",
        "link": "http://arxiv.org/abs/2405.17130v1",
        "abstract": "Despite being a heavily researched topic, Adversarial Training (AT) is\nrarely, if ever, deployed in practical AI systems for two primary reasons: (i)\nthe gained robustness is frequently accompanied by a drop in generalization and\n(ii) generating adversarial examples (AEs) is computationally prohibitively\nexpensive. To address these limitations, we propose SMAAT, a new AT algorithm\nthat leverages the manifold conjecture, stating that off-manifold AEs lead to\nbetter robustness while on-manifold AEs result in better generalization.\nSpecifically, SMAAT aims at generating a higher proportion of off-manifold AEs\nby perturbing the intermediate deepnet layer with the lowest intrinsic\ndimension. This systematically results in better scalability compared to\nclassical AT as it reduces the PGD chains length required for generating the\nAEs. Additionally, our study provides, to the best of our knowledge, the first\nexplanation for the difference in the generalization and robustness trends\nbetween vision and language models, ie., AT results in a drop in generalization\nin vision models whereas, in encoder-based language models, generalization\neither improves or remains unchanged. We show that vision transformers and\ndecoder-based models tend to have low intrinsic dimensionality in the earlier\nlayers of the network (more off-manifold AEs), while encoder-based models have\nlow intrinsic dimensionality in the later layers. We demonstrate the efficacy\nof SMAAT; on several tasks, including robustifying (i) sentiment classifiers,\n(ii) safety filters in decoder-based models, and (iii) retrievers in RAG\nsetups. SMAAT requires only 25-33% of the GPU time compared to standard AT,\nwhile significantly improving robustness across all applications and\nmaintaining comparable generalization.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "authors": [
            "Enes Altinisik",
            "Safa Messaoud",
            "Husrev Taha Sencar",
            "Hassan Sajjad",
            "Sanjay Chawla"
        ],
        "published": "2024-05-27T12:48:30Z"
    },
    {
        "title": "TEII: Think, Explain, Interact and Iterate with Large Language Models to\n  Solve Cross-lingual Emotion Detection",
        "link": "http://arxiv.org/abs/2405.17129v1",
        "abstract": "Cross-lingual emotion detection allows us to analyze global trends, public\nopinion, and social phenomena at scale. We participated in the Explainability\nof Cross-lingual Emotion Detection (EXALT) shared task, achieving an F1-score\nof 0.6046 on the evaluation set for the emotion detection sub-task. Our system\noutperformed the baseline by more than 0.16 F1-score absolute, and ranked\nsecond amongst competing systems. We conducted experiments using fine-tuning,\nzero-shot learning, and few-shot learning for Large Language Model (LLM)-based\nmodels as well as embedding-based BiLSTM and KNN for non-LLM-based techniques.\nAdditionally, we introduced two novel methods: the Multi-Iteration Agentic\nWorkflow and the Multi-Binary-Classifier Agentic Workflow. We found that\nLLM-based approaches provided good performance on multilingual emotion\ndetection. Furthermore, ensembles combining all our experimented models yielded\nhigher F1-scores than any single approach alone.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Long Cheng",
            "Qihao Shao",
            "Christine Zhao",
            "Sheng Bi",
            "Gina-Anne Levow"
        ],
        "published": "2024-05-27T12:47:40Z"
    },
    {
        "title": "Motion Primitives Planning For Center-Articulated Vehicles",
        "link": "http://arxiv.org/abs/2405.17127v1",
        "abstract": "Autonomous navigation across unstructured terrains, including forests and\nconstruction areas, faces unique challenges due to intricate obstacles and the\nelement of the unknown. Lacking pre-existing maps, these scenarios necessitate\na motion planning approach that combines agility with efficiency. Critically,\nit must also incorporate the robot's kinematic constraints to navigate more\neffectively through complex environments. This work introduces a novel planning\nmethod for center-articulated vehicles (CAV), leveraging motion primitives\nwithin a receding horizon planning framework using onboard sensing. The\napproach commences with the offline creation of motion primitives, generated\nthrough forward simulations that reflect the distinct kinematic model of\ncenter-articulated vehicles. These primitives undergo evaluation through a\nheuristic-based scoring function, facilitating the selection of the most\nsuitable path for real-time navigation. To augment this planning process, we\ndevelop a pose-stabilizing controller, tailored to the kinematic specifications\nof center-articulated vehicles. During experiments, our method demonstrates a\n$67\\%$ improvement in SPL (Success Rate weighted by Path Length) performance\nover existing strategies. Furthermore, its efficacy was validated through\nreal-world experiments conducted with a tree harvester vehicle - SAHA.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Jiangpeng Hu",
            "Fan Yang",
            "Fang Nan",
            "Marco Hutter"
        ],
        "published": "2024-05-27T12:45:37Z"
    },
    {
        "title": "Dual VC Dimension Obstructs Sample Compression by Embeddings",
        "link": "http://arxiv.org/abs/2405.17120v1",
        "abstract": "This work studies embedding of arbitrary VC classes in well-behaved VC\nclasses, focusing particularly on extremal classes. Our main result expresses\nan impossibility: such embeddings necessarily require a significant increase in\ndimension. In particular, we prove that for every $d$ there is a class with VC\ndimension $d$ that cannot be embedded in any extremal class of VC dimension\nsmaller than exponential in $d$.\n  In addition to its independent interest, this result has an important\nimplication in learning theory, as it reveals a fundamental limitation of one\nof the most extensively studied approaches to tackling the long-standing sample\ncompression conjecture. Concretely, the approach proposed by Floyd and Warmuth\nentails embedding any given VC class into an extremal class of a comparable\ndimension, and then applying an optimal sample compression scheme for extremal\nclasses. However, our results imply that this strategy would in some cases\nresult in a sample compression scheme at least exponentially larger than what\nis predicted by the sample compression conjecture.\n  The above implications follow from a general result we prove: any extremal\nclass with VC dimension $d$ has dual VC dimension at most $2d+1$. This bound is\nexponentially smaller than the classical bound $2^{d+1}-1$ of Assouad, which\napplies to general concept classes (and is known to be unimprovable for some\nclasses). We in fact prove a stronger result, establishing that $2d+1$ upper\nbounds the dual Radon number of extremal classes. This theorem represents an\nabstraction of the classical Radon theorem for convex sets, extending its\napplicability to a wider combinatorial framework, without relying on the\nspecifics of Euclidean convexity. The proof utilizes the topological method and\nis primarily based on variants of the Topological Radon Theorem.",
        "subjects": [
            "cs.DM",
            "cs.LG",
            "I.2.6; G.2.1"
        ],
        "authors": [
            "Zachary Chase",
            "Bogdan Chornomaz",
            "Steve Hanneke",
            "Shay Moran",
            "Amir Yehudayoff"
        ],
        "published": "2024-05-27T12:38:25Z"
    },
    {
        "title": "Mixtures of Unsupervised Lexicon Classification",
        "link": "http://arxiv.org/abs/2405.17116v1",
        "abstract": "This paper presents a mixture version of the method-of-moment unsupervised\nlexicon classification by an incorporation of a Dirichlet process.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Peratham Wiriyathammabhum"
        ],
        "published": "2024-05-27T12:33:47Z"
    },
    {
        "title": "Holographic MIMO Systems, Their Channel Estimation and Performance",
        "link": "http://arxiv.org/abs/2405.17114v1",
        "abstract": "Holographic multiple-input multiple-output (MIMO) systems constitute a\npromising technology in support of next-generation wireless communications,\nthus paving the way for a smart programmable radio environment. However,\ndespite its significant potential, further fundamental issues remain to be\naddressed, such as the acquisition of accurate channel information. Indeed, the\nconventional angular-domain channel representation is no longer adequate for\ncharacterizing the sparsity inherent in holographic MIMO channels. To fill this\nknowledge gap, in this article, we conceive a decomposition and reconstruction\n(DeRe)-based framework for facilitating the estimation of sparse channels in\nholographic MIMOs. In particular, the channel parameters involved in the\nsteering vector, namely the azimuth and elevation angles plus the distance\n(AED), are decomposed for independently constructing their own covariance\nmatrices. Then, the acquisition of each parameter can be formulated as a\ncompressive sensing (CS) problem by harnessing the covariance matrix associated\nwith each individual parameter. We demonstrate that our solution exhibits an\nimproved performance and imposes a reduced pilot overhead, despite its reduced\ncomplexity. Finally, promising open research topics are highlighted to bridge\nthe gap between the theory and the practical employment of holographic MIMO\nschemes.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Yuanbin Chen",
            "Ying Wang",
            "Zhaocheng Wang",
            "Ping Zhang"
        ],
        "published": "2024-05-27T12:33:03Z"
    },
    {
        "title": "Using continuation methods to analyse the difficulty of problems solved\n  by Ising machines",
        "link": "http://arxiv.org/abs/2405.17112v1",
        "abstract": "Ising machines are dedicated hardware solvers of NP-hard optimization\nproblems. However, they do not always find the most optimal solution. The\nprobability of finding this optimal solution depends on the problem at hand.\nUsing continuation methods, we show that this is closely linked to the\nbifurcation sequence of the optimal solution. From this bifurcation analysis,\nwe can determine the effectiveness of solution schemes. Moreover, we find that\nthe proper choice of implementation of the Ising machine can drastically change\nthis bifurcation sequence and therefore vastly increase the probability of\nfinding the optimal solution.",
        "subjects": [
            "cond-mat.dis-nn",
            "cond-mat.stat-mech",
            "cs.CC"
        ],
        "authors": [
            "Jacob Lamers",
            "Guy Verschaffelt",
            "Guy Van der Sande"
        ],
        "published": "2024-05-27T12:29:04Z"
    },
    {
        "title": "Diffusion Bridge AutoEncoders for Unsupervised Representation Learning",
        "link": "http://arxiv.org/abs/2405.17111v1",
        "abstract": "Diffusion-based representation learning has achieved substantial attention\ndue to its promising capabilities in latent representation and sample\ngeneration. Recent studies have employed an auxiliary encoder to identify a\ncorresponding representation from a sample and to adjust the dimensionality of\na latent variable z. Meanwhile, this auxiliary structure invokes information\nsplit problem because the diffusion and the auxiliary encoder would divide the\ninformation from the sample into two representations for each model.\nParticularly, the information modeled by the diffusion becomes over-regularized\nbecause of the static prior distribution on xT. To address this problem, we\nintroduce Diffusion Bridge AuteEncoders (DBAE), which enable z-dependent\nendpoint xT inference through a feed-forward architecture. This structure\ncreates an information bottleneck at z, so xT becomes dependent on z in its\ngeneration. This results in two consequences: 1) z holds the full information\nof samples, and 2) xT becomes a learnable distribution, not static any further.\nWe propose an objective function for DBAE to enable both reconstruction and\ngenerative modeling, with their theoretical justification. Empirical evidence\nsupports the effectiveness of the intended design in DBAE, which notably\nenhances downstream inference quality, reconstruction, and disentanglement.\nAdditionally, DBAE generates high-fidelity samples in the unconditional\ngeneration.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yeongmin Kim",
            "Kwanghyeon Lee",
            "Minsang Park",
            "Byeonghu Na",
            "Il-Chul Moon"
        ],
        "published": "2024-05-27T12:28:17Z"
    },
    {
        "title": "Superpixelwise Low-rank Approximation based Partial Label Learning for\n  Hyperspectral Image Classification",
        "link": "http://dx.doi.org/10.1109/LGRS.2023.3279985",
        "abstract": "Insufficient prior knowledge of a captured hyperspectral image (HSI) scene\nmay lead the experts or the automatic labeling systems to offer incorrect\nlabels or ambiguous labels (i.e., assigning each training sample to a group of\ncandidate labels, among which only one of them is valid; this is also known as\npartial label learning) during the labeling process. Accordingly, how to learn\nfrom such data with ambiguous labels is a problem of great practical\nimportance. In this paper, we propose a novel superpixelwise low-rank\napproximation (LRA)-based partial label learning method, namely SLAP, which is\nthe first to take into account partial label learning in HSI classification.\nSLAP is mainly composed of two phases: disambiguating the training labels and\nacquiring the predictive model. Specifically, in the first phase, we propose a\nsuperpixelwise LRA-based model, preparing the affinity graph for the subsequent\nlabel propagation process while extracting the discriminative representation to\nenhance the following classification task of the second phase. Then to\ndisambiguate the training labels, label propagation propagates the labeling\ninformation via the affinity graph of training pixels. In the second phase, we\ntake advantage of the resulting disambiguated training labels and the\ndiscriminative representations to enhance the classification performance. The\nextensive experiments validate the advantage of the proposed SLAP method over\nstate-of-the-art methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Shujun Yang",
            "Yu Zhang",
            "Yao Ding",
            "Danfeng Hong"
        ],
        "published": "2024-05-27T12:26:49Z"
    },
    {
        "title": "Left-Linear Completion with AC Axioms",
        "link": "http://arxiv.org/abs/2405.17109v1",
        "abstract": "We revisit completion modulo equational theories for left-linear term rewrite\nsystems where unification modulo the theory is avoided and the normal rewrite\nrelation can be used in order to decide validity questions. To that end, we\ngive a new correctness proof for finite runs and establish a simulation result\nbetween the two inference systems known from the literature. Given a concrete\nreduction order, novel canonicity results show that the resulting complete\nsystems are unique up to the representation of their rules' right-hand sides.\nFurthermore, we show how left-linear AC completion can be simulated by general\nAC completion. In particular, this result allows us to switch from the former\nto the latter at any point during a completion process.",
        "subjects": [
            "cs.LO"
        ],
        "authors": [
            "Johannes Niederhauser",
            "Nao Hirokawa",
            "Aart Middeldorp"
        ],
        "published": "2024-05-27T12:25:34Z"
    },
    {
        "title": "Finding good policies in average-reward Markov Decision Processes\n  without prior knowledge",
        "link": "http://arxiv.org/abs/2405.17108v1",
        "abstract": "We revisit the identification of an $\\varepsilon$-optimal policy in\naverage-reward Markov Decision Processes (MDP). In such MDPs, two measures of\ncomplexity have appeared in the literature: the diameter, $D$, and the optimal\nbias span, $H$, which satisfy $H\\leq D$. Prior work have studied the complexity\nof $\\varepsilon$-optimal policy identification only when a generative model is\navailable. In this case, it is known that there exists an MDP with $D \\simeq H$\nfor which the sample complexity to output an $\\varepsilon$-optimal policy is\n$\\Omega(SAD/\\varepsilon^2)$ where $S$ and $A$ are the sizes of the state and\naction spaces. Recently, an algorithm with a sample complexity of order\n$SAH/\\varepsilon^2$ has been proposed, but it requires the knowledge of $H$. We\nfirst show that the sample complexity required to estimate $H$ is not bounded\nby any function of $S,A$ and $H$, ruling out the possibility to easily make the\nprevious algorithm agnostic to $H$. By relying instead on a diameter estimation\nprocedure, we propose the first algorithm for $(\\varepsilon,\\delta)$-PAC policy\nidentification that does not need any form of prior knowledge on the MDP. Its\nsample complexity scales in $SAD/\\varepsilon^2$ in the regime of small\n$\\varepsilon$, which is near-optimal. In the online setting, our first\ncontribution is a lower bound which implies that a sample complexity polynomial\nin $H$ cannot be achieved in this setting. Then, we propose an online algorithm\nwith a sample complexity in $SAD^2/\\varepsilon^2$, as well as a novel approach\nbased on a data-dependent stopping rule that we believe is promising to further\nreduce this bound.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Adrienne Tuynman",
            "Rmy Degenne",
            "Emilie Kaufmann"
        ],
        "published": "2024-05-27T12:24:14Z"
    },
    {
        "title": "LLM-Optic: Unveiling the Capabilities of Large Language Models for\n  Universal Visual Grounding",
        "link": "http://arxiv.org/abs/2405.17104v2",
        "abstract": "Visual grounding is an essential tool that links user-provided text queries\nwith query-specific regions within an image. Despite advancements in visual\ngrounding models, their ability to comprehend complex queries remains limited.\nTo overcome this limitation, we introduce LLM-Optic, an innovative method that\nutilizes Large Language Models (LLMs) as an optical lens to enhance existing\nvisual grounding models in comprehending complex text queries involving\nintricate text structures, multiple objects, or object spatial relationships,\nsituations that current models struggle with. LLM-Optic first employs an LLM as\na Text Grounder to interpret complex text queries and accurately identify\nobjects the user intends to locate. Then a pre-trained visual grounding model\nis used to generate candidate bounding boxes given the refined query by the\nText Grounder. After that, LLM-Optic annotates the candidate bounding boxes\nwith numerical marks to establish a connection between text and specific image\nregions, thereby linking two distinct modalities. Finally, it employs a Large\nMultimodal Model (LMM) as a Visual Grounder to select the marked candidate\nobjects that best correspond to the original text query. Through LLM-Optic, we\nhave achieved universal visual grounding, which allows for the detection of\narbitrary objects specified by arbitrary human language input. Importantly, our\nmethod achieves this enhancement without requiring additional training or\nfine-tuning. Extensive experiments across various challenging benchmarks\ndemonstrate that LLM-Optic achieves state-of-the-art zero-shot visual grounding\ncapabilities. Project Page: https://haoyu-zhao.github.io/LLM-Optic.github.io/.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Haoyu Zhao",
            "Wenhang Ge",
            "Ying-cong Chen"
        ],
        "published": "2024-05-27T12:23:08Z"
    },
    {
        "title": "Empowering Character-level Text Infilling by Eliminating Sub-Tokens",
        "link": "http://arxiv.org/abs/2405.17103v1",
        "abstract": "In infilling tasks, sub-tokens, representing instances where a complete token\nis segmented into two parts, often emerge at the boundaries of prefixes,\nmiddles, and suffixes. Traditional methods focused on training models at the\ntoken level, leading to sub-optimal performance in character-level infilling\ntasks during the inference stage. Alternately, some approaches considered\ncharacter-level infilling, but they relied on predicting sub-tokens in\ninference, yet this strategy diminished ability in character-level infilling\ntasks due to the large perplexity of the model on sub-tokens. In this paper, we\nintroduce FIM-SE, which stands for Fill-In-the-Middle with both Starting and\nEnding character constraints. The proposed method addresses character-level\ninfilling tasks by utilizing a line-level format to avoid predicting any\nsub-token in inference. In addition, we incorporate two special tokens to\nsignify the rest of the incomplete lines, thereby enhancing generation\nguidance. Extensive experiments demonstrate that our proposed approach\nsurpasses previous methods, offering a significant advantage. Code is available\nat https://github.com/SenseLLM/FIM-SE.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Houxing Ren",
            "Mingjie Zhan",
            "Zhongyuan Wu",
            "Hongsheng Li"
        ],
        "published": "2024-05-27T12:21:48Z"
    },
    {
        "title": "DINO-SD: Champion Solution for ICRA 2024 RoboDepth Challenge",
        "link": "http://arxiv.org/abs/2405.17102v1",
        "abstract": "Surround-view depth estimation is a crucial task aims to acquire the depth\nmaps of the surrounding views. It has many applications in real world scenarios\nsuch as autonomous driving, AR/VR and 3D reconstruction, etc. However, given\nthat most of the data in the autonomous driving dataset is collected in daytime\nscenarios, this leads to poor depth model performance in the face of\nout-of-distribution(OoD) data. While some works try to improve the robustness\nof depth model under OoD data, these methods either require additional training\ndata or lake generalizability. In this report, we introduce the DINO-SD, a\nnovel surround-view depth estimation model. Our DINO-SD does not need\nadditional data and has strong robustness. Our DINO-SD get the best performance\nin the track4 of ICRA 2024 RoboDepth Challenge.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Yifan Mao",
            "Ming Li",
            "Jian Liu",
            "Jiayang Liu",
            "Zihan Qin",
            "Chunxi Chu",
            "Jialei Xu",
            "Wenbo Zhao",
            "Junjun Jiang",
            "Xianming Liu"
        ],
        "published": "2024-05-27T12:21:31Z"
    },
    {
        "title": "Sok: Comprehensive Security Overview, Challenges, and Future Directions\n  of Voice-Controlled Systems",
        "link": "http://arxiv.org/abs/2405.17100v1",
        "abstract": "The integration of Voice Control Systems (VCS) into smart devices and their\ngrowing presence in daily life accentuate the importance of their security.\nCurrent research has uncovered numerous vulnerabilities in VCS, presenting\nsignificant risks to user privacy and security. However, a cohesive and\nsystematic examination of these vulnerabilities and the corresponding solutions\nis still absent. This lack of comprehensive analysis presents a challenge for\nVCS designers in fully understanding and mitigating the security issues within\nthese systems.\n  Addressing this gap, our study introduces a hierarchical model structure for\nVCS, providing a novel lens for categorizing and analyzing existing literature\nin a systematic manner. We classify attacks based on their technical principles\nand thoroughly evaluate various attributes, such as their methods, targets,\nvectors, and behaviors. Furthermore, we consolidate and assess the defense\nmechanisms proposed in current research, offering actionable recommendations\nfor enhancing VCS security. Our work makes a significant contribution by\nsimplifying the complexity inherent in VCS security, aiding designers in\neffectively identifying and countering potential threats, and setting a\nfoundation for future advancements in VCS security research.",
        "subjects": [
            "cs.CR",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Haozhe Xu",
            "Cong Wu",
            "Yangyang Gu",
            "Xingcan Shang",
            "Jing Chen",
            "Kun He",
            "Ruiying Du"
        ],
        "published": "2024-05-27T12:18:46Z"
    },
    {
        "title": "Efficient Model Compression for Hierarchical Federated Learning",
        "link": "http://arxiv.org/abs/2405.17522v1",
        "abstract": "Federated learning (FL), as an emerging collaborative learning paradigm, has\ngarnered significant attention due to its capacity to preserve privacy within\ndistributed learning systems. In these systems, clients collaboratively train a\nunified neural network model using their local datasets and share model\nparameters rather than raw data, enhancing privacy. Predominantly, FL systems\nare designed for mobile and edge computing environments where training\ntypically occurs over wireless networks. Consequently, as model sizes increase,\nthe conventional FL frameworks increasingly consume substantial communication\nresources. To address this challenge and improve communication efficiency, this\npaper introduces a novel hierarchical FL framework that integrates the benefits\nof clustered FL and model compression. We present an adaptive clustering\nalgorithm that identifies a core client and dynamically organizes clients into\nclusters. Furthermore, to enhance transmission efficiency, each core client\nimplements a local aggregation with compression (LC aggregation) algorithm\nafter collecting compressed models from other clients within the same cluster.\nSimulation results affirm that our proposed algorithms not only maintain\ncomparable predictive accuracy but also significantly reduce energy consumption\nrelative to existing FL mechanisms.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "authors": [
            "Xi Zhu",
            "Songcan Yu",
            "Junbo Wang",
            "Qinglin Yang"
        ],
        "published": "2024-05-27T12:17:47Z"
    },
    {
        "title": "Q-value Regularized Transformer for Offline Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.17098v1",
        "abstract": "Recent advancements in offline reinforcement learning (RL) have underscored\nthe capabilities of Conditional Sequence Modeling (CSM), a paradigm that learns\nthe action distribution based on history trajectory and target returns for each\nstate. However, these methods often struggle with stitching together optimal\ntrajectories from sub-optimal ones due to the inconsistency between the sampled\nreturns within individual trajectories and the optimal returns across multiple\ntrajectories. Fortunately, Dynamic Programming (DP) methods offer a solution by\nleveraging a value function to approximate optimal future returns for each\nstate, while these techniques are prone to unstable learning behaviors,\nparticularly in long-horizon and sparse-reward scenarios. Building upon these\ninsights, we propose the Q-value regularized Transformer (QT), which combines\nthe trajectory modeling ability of the Transformer with the predictability of\noptimal future returns from DP methods. QT learns an action-value function and\nintegrates a term maximizing action-values into the training loss of CSM, which\naims to seek optimal actions that align closely with the behavior policy.\nEmpirical evaluations on D4RL benchmark datasets demonstrate the superiority of\nQT over traditional DP and CSM methods, highlighting the potential of QT to\nenhance the state-of-the-art in offline RL.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Shengchao Hu",
            "Ziqing Fan",
            "Chaoqin Huang",
            "Li Shen",
            "Ya Zhang",
            "Yanfeng Wang",
            "Dacheng Tao"
        ],
        "published": "2024-05-27T12:12:39Z"
    },
    {
        "title": "Evaluation of Multi-task Uncertainties in Joint Semantic Segmentation\n  and Monocular Depth Estimation",
        "link": "http://arxiv.org/abs/2405.17097v1",
        "abstract": "While a number of promising uncertainty quantification methods have been\nproposed to address the prevailing shortcomings of deep neural networks like\noverconfidence and lack of explainability, quantifying predictive uncertainties\nin the context of joint semantic segmentation and monocular depth estimation\nhas not been explored yet. Since many real-world applications are multi-modal\nin nature and, hence, have the potential to benefit from multi-task learning,\nthis is a substantial gap in current literature. To this end, we conduct a\ncomprehensive series of experiments to study how multi-task learning influences\nthe quality of uncertainty estimates in comparison to solving both tasks\nseparately.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Steven Landgraf",
            "Markus Hillemann",
            "Theodor Kapler",
            "Markus Ulrich"
        ],
        "published": "2024-05-27T12:12:26Z"
    },
    {
        "title": "Dual feature reduction for the sparse-group lasso and its adaptive\n  variant",
        "link": "http://arxiv.org/abs/2405.17094v1",
        "abstract": "The sparse-group lasso performs both variable and group selection, making\nsimultaneous use of the strengths of the lasso and group lasso. It has found\nwidespread use in genetics, a field that regularly involves the analysis of\nhigh-dimensional data, due to its sparse-group penalty, which allows it to\nutilize grouping information. However, the sparse-group lasso can be\ncomputationally more expensive than both the lasso and group lasso, due to the\nadded shrinkage complexity, and its additional hyper-parameter that needs\ntuning. In this paper a novel dual feature reduction method, Dual Feature\nReduction (DFR), is presented that uses strong screening rules for the\nsparse-group lasso and the adaptive sparse-group lasso to reduce their input\nspace before optimization. DFR applies two layers of screening and is based on\nthe dual norms of the sparse-group lasso and adaptive sparse-group lasso.\nThrough synthetic and real numerical studies, it is shown that the proposed\nfeature reduction approach is able to drastically reduce the computational cost\nin many different scenarios.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Fabio Feser",
            "Marina Evangelou"
        ],
        "published": "2024-05-27T12:10:07Z"
    },
    {
        "title": "DeeperImpact: Optimizing Sparse Learned Index Structures",
        "link": "http://arxiv.org/abs/2405.17093v1",
        "abstract": "A lot of recent work has focused on sparse learned indexes that use deep\nneural architectures to significantly improve retrieval quality while keeping\nthe efficiency benefits of the inverted index. While such sparse learned\nstructures achieve effectiveness far beyond those of traditional inverted\nindex-based rankers, there is still a gap in effectiveness to the best dense\nretrievers, or even to sparse methods that leverage more expensive\noptimizations such as query expansion and query term weighting. We focus on\nnarrowing this gap by revisiting and optimizing DeepImpact, a sparse retrieval\napproach that uses DocT5Query for document expansion followed by a BERT\nlanguage model to learn impact scores for document terms. We first\nreinvestigate the expansion process and find that the recently proposed\nDoc2Query query filtration does not enhance retrieval quality when used with\nDeepImpact. Instead, substituting T5 with a fine-tuned Llama 2 model for query\nprediction results in a considerable improvement. Subsequently, we study\ntraining strategies that have proven effective for other models, in particular\nthe use of hard negatives, distillation, and pre-trained CoCondenser model\ninitialization. Our results significantly narrow the effectiveness gap with the\nmost effective versions of SPLADE.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Soyuj Basnet",
            "Jerry Gou",
            "Antonio Mallia",
            "Torsten Suel"
        ],
        "published": "2024-05-27T12:08:59Z"
    },
    {
        "title": "Positivity preserving finite element method for the Gross-Pitaevskii\n  ground state: discrete uniqueness and global convergence",
        "link": "http://arxiv.org/abs/2405.17090v1",
        "abstract": "We propose a positivity preserving finite element discretization for the\nnonlinear Gross-Pitaevskii eigenvalue problem. The method employs mass lumping\ntechniques, which allow to transfer the uniqueness up to sign and positivity\nproperties of the continuous ground state to the discrete setting. We further\nprove that every non-negative discrete excited state up to sign coincides with\nthe discrete ground state. This allows one to identify the limit of fully\ndiscretized gradient flows, which are typically used to compute the discrete\nground state, and thereby establish their global convergence. Furthermore, we\nperform a rigorous a priori error analysis of the proposed non-standard finite\nelement discretization, showing optimal orders of convergence for all unknowns.\nNumerical experiments illustrate the theoretical results of this paper.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "35Q55, 65N12, 65N15, 65N25, 65N30"
        ],
        "authors": [
            "Moritz Hauck",
            "Yizhou Liang",
            "Daniel Peterseim"
        ],
        "published": "2024-05-27T12:07:21Z"
    },
    {
        "title": "Phase Transitions in the Output Distribution of Large Language Models",
        "link": "http://arxiv.org/abs/2405.17088v1",
        "abstract": "In a physical system, changing parameters such as temperature can induce a\nphase transition: an abrupt change from one state of matter to another.\nAnalogous phenomena have recently been observed in large language models.\nTypically, the task of identifying phase transitions requires human analysis\nand some prior understanding of the system to narrow down which low-dimensional\nproperties to monitor and analyze. Statistical methods for the automated\ndetection of phase transitions from data have recently been proposed within the\nphysics community. These methods are largely system agnostic and, as shown\nhere, can be adapted to study the behavior of large language models. In\nparticular, we quantify distributional changes in the generated output via\nstatistical distances, which can be efficiently estimated with access to the\nprobability distribution over next-tokens. This versatile approach is capable\nof discovering new phases of behavior and unexplored transitions -- an ability\nthat is particularly exciting in light of the rapid development of language\nmodels and their emergent capabilities.",
        "subjects": [
            "cs.LG",
            "cond-mat.stat-mech",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Julian Arnold",
            "Flemming Holtorf",
            "Frank Schfer",
            "Niels Lrch"
        ],
        "published": "2024-05-27T12:04:36Z"
    },
    {
        "title": "Symbolic dynamics for the Kuramoto-Sivashinsky PDE on the line II",
        "link": "http://arxiv.org/abs/2405.17087v1",
        "abstract": "We present a new algorithm for the rigorous integration of the variational\nequation (i.e. producing $\\mathcal C^1$ estimates) for a class of dissipative\nPDEs on the torus. As an application for some parameter value for the\nKuramoto-Sivashinsky PDE on the line with odd and periodic boundary conditions\nwe prove the existence of infinite number of homo- and heteroclinic orbits to\ntwo periodic orbits. The proof is computer assisted.",
        "subjects": [
            "math.DS",
            "cs.NA",
            "math.AP",
            "math.NA",
            "35B40, 35B45, 65G30, 65N30"
        ],
        "authors": [
            "Daniel Wilczak",
            "Piotr Zgliczyski"
        ],
        "published": "2024-05-27T12:04:01Z"
    },
    {
        "title": "F-3DGS: Factorized Coordinates and Representations for 3D Gaussian\n  Splatting",
        "link": "http://arxiv.org/abs/2405.17083v2",
        "abstract": "The neural radiance field (NeRF) has made significant strides in representing\n3D scenes and synthesizing novel views. Despite its advancements, the high\ncomputational costs of NeRF have posed challenges for its deployment in\nresource-constrained environments and real-time applications. As an alternative\nto NeRF-like neural rendering methods, 3D Gaussian Splatting (3DGS) offers\nrapid rendering speeds while maintaining excellent image quality. However, as\nit represents objects and scenes using a myriad of Gaussians, it requires\nsubstantial storage to achieve high-quality representation. To mitigate the\nstorage overhead, we propose Factorized 3D Gaussian Splatting (F-3DGS), a novel\napproach that drastically reduces storage requirements while preserving image\nquality. Inspired by classical matrix and tensor factorization techniques, our\nmethod represents and approximates dense clusters of Gaussians with\nsignificantly fewer Gaussians through efficient factorization. We aim to\nefficiently represent dense 3D Gaussians by approximating them with a limited\namount of information for each axis and their combinations. This method allows\nus to encode a substantially large number of Gaussians along with their\nessential attributes -- such as color, scale, and rotation -- necessary for\nrendering using a relatively small number of elements. Extensive experimental\nresults demonstrate that F-3DGS achieves a significant reduction in storage\ncosts while maintaining comparable quality in rendered images.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xiangyu Sun",
            "Joo Chan Lee",
            "Daniel Rho",
            "Jong Hwan Ko",
            "Usman Ali",
            "Eunbyung Park"
        ],
        "published": "2024-05-27T11:55:49Z"
    },
    {
        "title": "Ensembling Diffusion Models via Adaptive Feature Aggregation",
        "link": "http://arxiv.org/abs/2405.17082v1",
        "abstract": "The success of the text-guided diffusion model has inspired the development\nand release of numerous powerful diffusion models within the open-source\ncommunity. These models are typically fine-tuned on various expert datasets,\nshowcasing diverse denoising capabilities. Leveraging multiple high-quality\nmodels to produce stronger generation ability is valuable, but has not been\nextensively studied. Existing methods primarily adopt parameter merging\nstrategies to produce a new static model. However, they overlook the fact that\nthe divergent denoising capabilities of the models may dynamically change\nacross different states, such as when experiencing different prompts, initial\nnoises, denoising steps, and spatial locations. In this paper, we propose a\nnovel ensembling method, Adaptive Feature Aggregation (AFA), which dynamically\nadjusts the contributions of multiple models at the feature level according to\nvarious states (i.e., prompts, initial noises, denoising steps, and spatial\nlocations), thereby keeping the advantages of multiple diffusion models, while\nsuppressing their disadvantages. Specifically, we design a lightweight\nSpatial-Aware Block-Wise (SABW) feature aggregator that adaptive aggregates the\nblock-wise intermediate features from multiple U-Net denoisers into a unified\none. The core idea lies in dynamically producing an individual attention map\nfor each model's features by comprehensively considering various states. It is\nworth noting that only SABW is trainable with about 50 million parameters,\nwhile other models are frozen. Both the quantitative and qualitative\nexperiments demonstrate the effectiveness of our proposed Adaptive Feature\nAggregation method. The code is available at https://github.com/tenvence/afa/.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Cong Wang",
            "Kuan Tian",
            "Yonghang Guan",
            "Jun Zhang",
            "Zhiwei Jiang",
            "Fei Shen",
            "Xiao Han",
            "Qing Gu",
            "Wei Yang"
        ],
        "published": "2024-05-27T11:55:35Z"
    },
    {
        "title": "Effective Layer Pruning Through Similarity Metric Perspective",
        "link": "http://arxiv.org/abs/2405.17081v1",
        "abstract": "Deep neural networks have been the predominant paradigm in machine learning\nfor solving cognitive tasks. Such models, however, are restricted by a high\ncomputational overhead, limiting their applicability and hindering advancements\nin the field. Extensive research demonstrated that pruning structures from\nthese models is a straightforward approach to reducing network complexity. In\nthis direction, most efforts focus on removing weights or filters. Studies have\nalso been devoted to layer pruning as it promotes superior computational gains.\nHowever, layer pruning often hurts the network predictive ability (i.e.,\naccuracy) at high compression rates. This work introduces an effective\nlayer-pruning strategy that meets all underlying properties pursued by pruning\nmethods. Our method estimates the relative importance of a layer using the\nCentered Kernel Alignment (CKA) metric, employed to measure the similarity\nbetween the representations of the unpruned model and a candidate layer for\npruning. We confirm the effectiveness of our method on standard architectures\nand benchmarks, in which it outperforms existing layer-pruning strategies and\nother state-of-the-art pruning techniques. Particularly, we remove more than\n75% of computation while improving predictive ability. At higher compression\nregimes, our method exhibits negligible accuracy drop, while other methods\nnotably deteriorate model accuracy. Apart from these benefits, our pruned\nmodels exhibit robustness to adversarial and out-of-distribution samples.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ian Pons",
            "Bruno Yamamoto",
            "Anna H. Reali Costa",
            "Artur Jordao"
        ],
        "published": "2024-05-27T11:54:51Z"
    },
    {
        "title": "A Two-Level Stochastic Model for the Lateral Movement of Vehicles Within\n  Their Lane Under Homogeneous Traffic Conditions",
        "link": "http://dx.doi.org/10.1109/ITSC57777.2023.10421975",
        "abstract": "The lateral position of vehicles within their lane is a decisive factor for\nthe range of vision of vehicle sensors. This, in turn, is crucial for a\nvehicle's ability to perceive its environment and gain a high situational\nawareness by processing the collected information. When aiming for increasing\nlevels of vehicle autonomy, this situational awareness becomes more and more\nimportant. Thus, when validating an autonomous driving function the\nrepresentativeness of the submicroscopic behavior such as the lateral offset\nhas to be ensured. With simulations being an essential part of the validation\nof autonomous driving functions, models describing these phenomena are\nrequired. Possible applications are the enhancement of microscopic traffic\nsimulations and the maneuver-based approach for scenario-based testing. This\npaper presents a two-level stochastic approach to model the lateral movement of\nvehicles within their lane during road-following maneuvers under homogeneous\ntraffic conditions. A Markov model generates the coarse lateral offset profile.\nIt is superposed with a noise model for the fine movements. Both models are set\nup using real-world data. The evaluation of the model shows promising\nqualitative and quantitative results, the potential for enhancements and\nextreme low computation times (10000 times faster than real time).",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Nicole Neis",
            "Juergen Beyerer"
        ],
        "published": "2024-05-27T11:53:47Z"
    },
    {
        "title": "Learning with User-Level Local Differential Privacy",
        "link": "http://arxiv.org/abs/2405.17079v1",
        "abstract": "User-level privacy is important in distributed systems. Previous research\nprimarily focuses on the central model, while the local models have received\nmuch less attention. Under the central model, user-level DP is strictly\nstronger than the item-level one. However, under the local model, the\nrelationship between user-level and item-level LDP becomes more complex, thus\nthe analysis is crucially different. In this paper, we first analyze the mean\nestimation problem and then apply it to stochastic optimization,\nclassification, and regression. In particular, we propose adaptive strategies\nto achieve optimal performance at all privacy levels. Moreover, we also obtain\ninformation-theoretic lower bounds, which show that the proposed methods are\nminimax optimal up to logarithmic factors. Unlike the central DP model, where\nuser-level DP always leads to slower convergence, our result shows that under\nthe local model, the convergence rates are nearly the same between user-level\nand item-level cases for distributions with bounded support. For heavy-tailed\ndistributions, the user-level rate is even faster than the item-level one.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Puning Zhao",
            "Li Shen",
            "Rongfei Fan",
            "Qingming Li",
            "Huiwen Wu",
            "Jiafei Wu",
            "Zhe Liu"
        ],
        "published": "2024-05-27T11:52:24Z"
    },
    {
        "title": "Leveraging small language models for Text2SPARQL tasks to improve the\n  resilience of AI assistance",
        "link": "http://arxiv.org/abs/2405.17076v1",
        "abstract": "In this work we will show that language models with less than one billion\nparameters can be used to translate natural language to SPARQL queries after\nfine-tuning. Using three different datasets ranging from academic to real\nworld, we identify prerequisites that the training data must fulfill in order\nfor the training to be successful. The goal is to empower users of semantic web\ntechnology to use AI assistance with affordable commodity hardware, making them\nmore resilient against external factors.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.IR"
        ],
        "authors": [
            "Felix Brei",
            "Johannes Frey",
            "Lars-Peter Meyer"
        ],
        "published": "2024-05-27T11:47:21Z"
    },
    {
        "title": "Interaction-Force Transport Gradient Flows",
        "link": "http://arxiv.org/abs/2405.17075v1",
        "abstract": "This paper presents a new type of gradient flow geometries over non-negative\nand probability measures motivated via a principled construction that combines\nthe optimal transport and interaction forces modeled by reproducing kernels.\nConcretely, we propose the interaction-force transport (IFT) gradient flows and\nits spherical variant via an infimal convolution of the Wasserstein and\nspherical MMD Riemannian metric tensors. We then develop a particle-based\noptimization algorithm based on the JKO-splitting scheme of the mass-preserving\nspherical IFT gradient flows. Finally, we provide both theoretical global\nexponential convergence guarantees and empirical simulation results for\napplying the IFT gradient flows to the sampling task of MMD-minimization\nstudied by Arbel et al. [2019]. Furthermore, we prove that the spherical IFT\ngradient flow enjoys the best of both worlds by providing the global\nexponential convergence guarantee for both the MMD and KL energy.",
        "subjects": [
            "cs.LG",
            "math.AP",
            "stat.ML"
        ],
        "authors": [
            "Egor Gladin",
            "Pavel Dvurechensky",
            "Alexander Mielke",
            "Jia-Jie Zhu"
        ],
        "published": "2024-05-27T11:46:14Z"
    },
    {
        "title": "Towards Ultra-High-Definition Image Deraining: A Benchmark and An\n  Efficient Method",
        "link": "http://arxiv.org/abs/2405.17074v1",
        "abstract": "Despite significant progress has been made in image deraining, existing\napproaches are mostly carried out on low-resolution images. The effectiveness\nof these methods on high-resolution images is still unknown, especially for\nultra-high-definition (UHD) images, given the continuous advancement of imaging\ndevices. In this paper, we focus on the task of UHD image deraining, and\ncontribute the first large-scale UHD image deraining dataset, 4K-Rain13k, that\ncontains 13,000 image pairs at 4K resolution. Based on this dataset, we conduct\na benchmark study on existing methods for processing UHD images. Furthermore,\nwe develop an effective and efficient vision MLP-based architecture (UDR-Mixer)\nto better solve this task. Specifically, our method contains two building\ncomponents: a spatial feature rearrangement layer that captures long-range\ninformation of UHD images, and a frequency feature modulation layer that\nfacilitates high-quality UHD image reconstruction. Extensive experimental\nresults demonstrate that our method performs favorably against the\nstate-of-the-art approaches while maintaining a lower model complexity. The\ncode and dataset will be available at https://github.com/cschenxiang/UDR-Mixer.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hongming Chen",
            "Xiang Chen",
            "Chen Wu",
            "Zhuoran Zheng",
            "Jinshan Pan",
            "Xianping Fu"
        ],
        "published": "2024-05-27T11:45:08Z"
    },
    {
        "title": "Soft Two-degree-of-freedom Dielectric Elastomer Position Sensor\n  Exhibiting Linear Behavior",
        "link": "http://dx.doi.org/10.1109/TMECH.2014.2307006",
        "abstract": "Soft robots could bring robotic systems to new horizons, by enabling safe\nhuman-machine interaction. For precise control, these soft structures require\nhigh level position feedback that is not easily achieved through conventional\none-degree-of-freedom (DOF) sensing apparatus. In this paper, a soft two-DOF\ndielectric elastomer (DE) sensor is specifically designed to provide accurate\nposition feedback for a soft polymer robotic manipulator. The technology is\nexemplified on a soft robot intended for MRI-guided prostate interventions. DEs\nare chosen for their major advantages of softness, high strains, low cost and\nembedded multiple-DOF sensing capability, providing excellent system\nintegration. A geometrical model of the proposed DE sensor is developed and\ncompared to experimental results in order to understand sensor mechanics. Using\na differential measurement approach, a handmade prototype provided linear\nsensory behavior and 0.2 mm accuracy on two-DOF. This correlates to a 0.7\\%\nerror over the sensor's 30 mm x 30 mm planar range, demonstrating the\noutstanding potential of DE technology for accurate multi-DOF position sensing.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Alexandre Girard",
            "Jean-Philippe Lucking Bigu",
            "Benjamin M. O'Brien",
            "Todd A. Gisby",
            "Iain A. Anderson",
            "Jean-Sbastien Plante"
        ],
        "published": "2024-05-27T11:43:05Z"
    },
    {
        "title": "A novel framework for systematic propositional formula simplification\n  based on existential graphs",
        "link": "http://arxiv.org/abs/2405.17072v1",
        "abstract": "This paper presents a novel simplification calculus for propositional logic\nderived from Peirce's existential graphs' rules of inference and implication\ngraphs. Our rules can be applied to propositional logic formulae in nested\nform, are equivalence-preserving, guarantee a monotonically decreasing number\nof variables, clauses and literals, and maximise the preservation of structural\nproblem information. Our techniques can also be seen as higher-level SAT\npreprocessing, and we show how one of our rules (TWSR) generalises and\nstreamlines most of the known equivalence-preserving SAT preprocessing methods.\nIn addition, we propose a simplification procedure based on the systematic\napplication of two of our rules (EPR and TWSR) which is solver-agnostic and can\nbe used to simplify large Boolean satisfiability problems and propositional\nformulae in arbitrary form, and we provide a formal analysis of its algorithmic\ncomplexity in terms of space and time. Finally, we show how our rules can be\nfurther extended with a novel n-ary implication graph to capture all known\nequivalence-preserving preprocessing procedures.",
        "subjects": [
            "cs.LO",
            "cs.AI",
            "math.LO",
            "03B35, 03B70, 68N17, 68T27",
            "F.4.1; I.2.2; I.2.3; I.2.4"
        ],
        "authors": [
            "Jordina Francs de Mas",
            "Juliana Bowles"
        ],
        "published": "2024-05-27T11:42:46Z"
    },
    {
        "title": "Advancing Medical Image Segmentation with Mini-Net: A Lightweight\n  Solution Tailored for Efficient Segmentation of Medical Images",
        "link": "http://arxiv.org/abs/2405.17520v1",
        "abstract": "Accurate segmentation of anatomical structures and abnormalities in medical\nimages is crucial for computer-aided diagnosis and analysis. While deep\nlearning techniques excel at this task, their computational demands pose\nchallenges. Additionally, some cutting-edge segmentation methods, though\neffective for general object segmentation, may not be optimised for medical\nimages. To address these issues, we propose Mini-Net, a lightweight\nsegmentation network specifically designed for medical images. With fewer than\n38,000 parameters, Mini-Net efficiently captures both high- and low-frequency\nfeatures, enabling real-time applications in various medical imaging scenarios.\nWe evaluate Mini-Net on various datasets, including DRIVE, STARE, ISIC-2016,\nISIC-2018, and MoNuSeg, demonstrating its robustness and good performance\ncompared to state-of-the-art methods.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Syed Javed",
            "Tariq M. Khan",
            "Abdul Qayyum",
            "Arcot Sowmya",
            "Imran Razzak"
        ],
        "published": "2024-05-27T11:41:48Z"
    },
    {
        "title": "Efficient mid-term forecasting of hourly electricity load using\n  generalized additive models",
        "link": "http://arxiv.org/abs/2405.17070v1",
        "abstract": "Accurate mid-term (weeks to one year) hourly electricity load forecasts are\nessential for strategic decision-making in power plant operation, ensuring\nsupply security and grid stability, and energy trading. While numerous models\neffectively predict short-term (hours to a few days) hourly load, mid-term\nforecasting solutions remain scarce. In mid-term load forecasting, besides\ndaily, weekly, and annual seasonal and autoregressive effects, capturing\nweather and holiday effects, as well as socio-economic non-stationarities in\nthe data, poses significant modeling challenges. To address these challenges,\nwe propose a novel forecasting method using Generalized Additive Models (GAMs)\nbuilt from interpretable P-splines and enhanced with autoregressive\npost-processing. This model uses smoothed temperatures, Error-Trend-Seasonal\n(ETS) modeled non-stationary states, a nuanced representation of holiday\neffects with weekday variations, and seasonal information as input. The\nproposed model is evaluated on load data from 24 European countries. This\nanalysis demonstrates that the model not only has significantly enhanced\nforecasting accuracy compared to state-of-the-art methods but also offers\nvaluable insights into the influence of individual components on predicted\nload, given its full interpretability. Achieving performance akin to day-ahead\nTSO forecasts in fast computation times of a few seconds for several years of\nhourly data underscores the model's potential for practical application in the\npower system industry.",
        "subjects": [
            "stat.AP",
            "cs.LG",
            "econ.GN",
            "q-fin.EC",
            "q-fin.ST"
        ],
        "authors": [
            "Monika Zimmermann",
            "Florian Ziel"
        ],
        "published": "2024-05-27T11:41:41Z"
    },
    {
        "title": "Training-free Editioning of Text-to-Image Models",
        "link": "http://arxiv.org/abs/2405.17069v1",
        "abstract": "Inspired by the software industry's practice of offering different editions\nor versions of a product tailored to specific user groups or use cases, we\npropose a novel task, namely, training-free editioning, for text-to-image\nmodels. Specifically, we aim to create variations of a base text-to-image model\nwithout retraining, enabling the model to cater to the diverse needs of\ndifferent user groups or to offer distinct features and functionalities. To\nachieve this, we propose that different editions of a given text-to-image model\ncan be formulated as concept subspaces in the latent space of its text encoder\n(e.g., CLIP). In such a concept subspace, all points satisfy a specific user\nneed (e.g., generating images of a cat lying on the grass/ground/falling\nleaves). Technically, we apply Principal Component Analysis (PCA) to obtain the\ndesired concept subspaces from representative text embedding that correspond to\na specific user need or requirement. Projecting the text embedding of a given\nprompt into these low-dimensional subspaces enables efficient model editioning\nwithout retraining. Intuitively, our proposed editioning paradigm enables a\nservice provider to customize the base model into its \"cat edition\" (or other\neditions) that restricts image generation to cats, regardless of the user's\nprompt (e.g., dogs, people, etc.). This introduces a new dimension for product\ndifferentiation, targeted functionality, and pricing strategies, unlocking\nnovel business models for text-to-image generators. Extensive experimental\nresults demonstrate the validity of our approach and its potential to enable a\nwide range of customized text-to-image model editions across various domains\nand applications.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Jinqi Wang",
            "Yunfei Fu",
            "Zhangcan Ding",
            "Bailin Deng",
            "Yu-Kun Lai",
            "Yipeng Qin"
        ],
        "published": "2024-05-27T11:40:50Z"
    },
    {
        "title": "The Poisson Midpoint Method for Langevin Dynamics: Provably Efficient\n  Discretization for Diffusion Models",
        "link": "http://arxiv.org/abs/2405.17068v1",
        "abstract": "Langevin Dynamics is a Stochastic Differential Equation (SDE) central to\nsampling and generative modeling and is implemented via time discretization.\nLangevin Monte Carlo (LMC), based on the Euler-Maruyama discretization, is the\nsimplest and most studied algorithm. LMC can suffer from slow convergence -\nrequiring a large number of steps of small step-size to obtain good quality\nsamples. This becomes stark in the case of diffusion models where a large\nnumber of steps gives the best samples, but the quality degrades rapidly with\nsmaller number of steps. Randomized Midpoint Method has been recently proposed\nas a better discretization of Langevin dynamics for sampling from strongly\nlog-concave distributions. However, important applications such as diffusion\nmodels involve non-log concave densities and contain time varying drift. We\npropose its variant, the Poisson Midpoint Method, which approximates a small\nstep-size LMC with large step-sizes. We prove that this can obtain a quadratic\nspeed up of LMC under very weak assumptions. We apply our method to diffusion\nmodels for image generation and show that it maintains the quality of DDPM with\n1000 neural network calls with just 50-80 neural network calls and outperforms\nODE based methods with similar compute.",
        "subjects": [
            "cs.LG",
            "cs.NA",
            "math.NA",
            "stat.ML"
        ],
        "authors": [
            "Saravanan Kandasamy",
            "Dheeraj Nagaraj"
        ],
        "published": "2024-05-27T11:40:42Z"
    },
    {
        "title": "Tokenization Matters! Degrading Large Language Models through\n  Challenging Their Tokenization",
        "link": "http://arxiv.org/abs/2405.17067v1",
        "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in language\nunderstanding and generation. Nonetheless, it was also witnessed that LLMs tend\nto produce inaccurate responses to specific queries. This deficiency can be\ntraced to the tokenization step LLMs must undergo, which is an inevitable\nlimitation inherent to all LLMs. In fact, incorrect tokenization is the\ncritical point that hinders LLMs in understanding the input precisely, thus\nleading to unsatisfactory output. To demonstrate this flaw of LLMs, we\nconstruct an adversarial dataset, named as $\\textbf{ADT (Adversarial Dataset\nfor Tokenizer)}$, which draws upon the vocabularies of various open-source LLMs\nto challenge LLMs' tokenization. ADT consists of two subsets: the manually\nconstructed ADT-Human and the automatically generated ADT-Auto. Our empirical\nresults reveal that our ADT is highly effective on challenging the tokenization\nof leading LLMs, including GPT-4o, Llama-3, Qwen2.5-max and so on, thus\ndegrading these LLMs' capabilities. Moreover, our method of automatic data\ngeneration has been proven efficient and robust, which can be applied to any\nopen-source LLMs. To the best of our knowledge, our study is the first to\ninvestigating LLMs' vulnerability in terms of challenging their token\nsegmentation, which will shed light on the subsequent research of improving\nLLMs' capabilities through optimizing their tokenization process and\nalgorithms.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Dixuan Wang",
            "Yanda Li",
            "Junyuan Jiang",
            "Zepeng Ding",
            "Guochao Jiang",
            "Jiaqing Liang",
            "Deqing Yang"
        ],
        "published": "2024-05-27T11:39:59Z"
    },
    {
        "title": "Saturn: Sample-efficient Generative Molecular Design using Memory\n  Manipulation",
        "link": "http://arxiv.org/abs/2405.17066v1",
        "abstract": "Generative molecular design for drug discovery has very recently achieved a\nwave of experimental validation, with language-based backbones being the most\ncommon architectures employed. The most important factor for downstream success\nis whether an in silico oracle is well correlated with the desired end-point.\nTo this end, current methods use cheaper proxy oracles with higher throughput\nbefore evaluating the most promising subset with high-fidelity oracles. The\nability to directly optimize high-fidelity oracles would greatly enhance\ngenerative design and be expected to improve hit rates. However, current models\nare not efficient enough to consider such a prospect, exemplifying the sample\nefficiency problem. In this work, we introduce Saturn, which leverages the\nAugmented Memory algorithm and demonstrates the first application of the Mamba\narchitecture for generative molecular design. We elucidate how experience\nreplay with data augmentation improves sample efficiency and how Mamba\nsynergistically exploits this mechanism. Saturn outperforms 22 models on\nmulti-parameter optimization tasks relevant to drug discovery and may possess\nsufficient sample efficiency to consider the prospect of directly optimizing\nhigh-fidelity oracles.",
        "subjects": [
            "q-bio.BM",
            "cs.LG"
        ],
        "authors": [
            "Jeff Guo",
            "Philippe Schwaller"
        ],
        "published": "2024-05-27T11:37:36Z"
    },
    {
        "title": "Model-Driven Engineering for Quantum Programming: A Case Study on Ground\n  State Energy Calculation",
        "link": "http://arxiv.org/abs/2405.17065v1",
        "abstract": "This study introduces a novel framework that brings together two main Quantum\nProgramming methodologies, gate-based Quantum Computing and Quantum Annealing,\nby applying the Model-Driven Engineering principles. This aims to enhance the\nadaptability, design and scalability of quantum programs, facilitating their\ndesign and operation across diverse computing platforms. A notable achievement\nof this research is the development of a mapping method for programs between\ngate-based quantum computers and quantum annealers which can lead to the\nautomatic transformation of these programs. Specifically, this method is\napplied to the Variational Quantum Eigensolver Algorithm and Quantum Anneling\nIsing Model, targeting ground state solutions. Finding ground-state solutions\nis crucial for a wide range of scientific applications, ranging from simulating\nchemistry lab experiments to medical applications, such as vaccine development.\nThe success of this application demonstrates Model-Driven Engineering for\nQuantum Programming frameworks's practical viability and sets a clear path for\nquantum Computing's broader use in solving intricate problems.",
        "subjects": [
            "quant-ph",
            "cs.PL",
            "cs.SE"
        ],
        "authors": [
            "Furkan Polat",
            "Hasan Tuncer",
            "Armin Moin",
            "Moharram Challenger"
        ],
        "published": "2024-05-27T11:37:20Z"
    },
    {
        "title": "Unifying Demonstration Selection and Compression for In-Context Learning",
        "link": "http://arxiv.org/abs/2405.17062v1",
        "abstract": "In-context learning (ICL) facilitates large language models (LLMs) exhibiting\nspectacular emergent capabilities in various scenarios. Unfortunately,\nintroducing demonstrations easily makes the prompt length explode, bringing a\nsignificant burden to hardware. In addition, random demonstrations usually\nachieve limited improvements in ICL, necessitating demonstration selection\namong accessible candidates. Previous studies introduce extra modules to\nperform demonstration compression or selection independently. In this paper, we\npropose an ICL framework UniICL, which Unifies demonstration selection and\ncompression, and final response generation via a single frozen LLM.\nSpecifically, UniICL first projects actual demonstrations and inference text\ninputs into short virtual tokens, respectively. Then, virtual tokens are\napplied to select suitable demonstrations by measuring semantic similarity\nwithin latent space among candidate demonstrations and inference input.\nFinally, inference text inputs together with selected virtual demonstrations\nare fed into the same frozen LLM for response generation. Notably, UniICL is a\nparameter-efficient framework that only contains 17M trainable parameters\noriginating from the projection layer. We conduct experiments and analysis over\nin- and out-domain datasets of both generative and understanding tasks,\nencompassing ICL scenarios with plentiful and limited demonstration candidates.\nResults show that UniICL effectively unifies $12 \\times$ compression,\ndemonstration selection, and response generation, efficiently scaling up the\nbaseline from 4-shot to 64-shot ICL in IMDb with 24 GB CUDA allocation",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Jun Gao"
        ],
        "published": "2024-05-27T11:31:58Z"
    },
    {
        "title": "Provably Efficient Reinforcement Learning with Multinomial Logit\n  Function Approximation",
        "link": "http://arxiv.org/abs/2405.17061v1",
        "abstract": "We study a new class of MDPs that employs multinomial logit (MNL) function\napproximation to ensure valid probability distributions over the state space.\nDespite its benefits, introducing non-linear function approximation raises\nsignificant challenges in both computational and statistical efficiency. The\nbest-known method of Hwang and Oh [2023] has achieved an\n$\\widetilde{\\mathcal{O}}(\\kappa^{-1}dH^2\\sqrt{K})$ regret, where $\\kappa$ is a\nproblem-dependent quantity, $d$ is the feature space dimension, $H$ is the\nepisode length, and $K$ is the number of episodes. While this result attains\nthe same rate in $K$ as the linear cases, the method requires storing all\nhistorical data and suffers from an $\\mathcal{O}(K)$ computation cost per\nepisode. Moreover, the quantity $\\kappa$ can be exponentially small, leading to\na significant gap for the regret compared to the linear cases. In this work, we\nfirst address the computational concerns by proposing an online algorithm that\nachieves the same regret with only $\\mathcal{O}(1)$ computation cost. Then, we\ndesign two algorithms that leverage local information to enhance statistical\nefficiency. They not only maintain an $\\mathcal{O}(1)$ computation cost per\nepisode but achieve improved regrets of\n$\\widetilde{\\mathcal{O}}(\\kappa^{-1/2}dH^2\\sqrt{K})$ and\n$\\widetilde{\\mathcal{O}}(dH^2\\sqrt{K} + \\kappa^{-1}d^2H^2)$ respectively.\nFinally, we establish a lower bound, justifying the optimality of our results\nin $d$ and $K$. To the best of our knowledge, this is the first work that\nachieves almost the same computational and statistical efficiency as linear\nfunction approximation while employing non-linear function approximation for\nreinforcement learning.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Long-Fei Li",
            "Yu-Jie Zhang",
            "Peng Zhao",
            "Zhi-Hua Zhou"
        ],
        "published": "2024-05-27T11:31:54Z"
    },
    {
        "title": "Graph Neural Networks on Quantum Computers",
        "link": "http://arxiv.org/abs/2405.17060v1",
        "abstract": "Graph Neural Networks (GNNs) are powerful machine learning models that excel\nat analyzing structured data represented as graphs, demonstrating remarkable\nperformance in applications like social network analysis and recommendation\nsystems. However, classical GNNs face scalability challenges when dealing with\nlarge-scale graphs. This paper proposes frameworks for implementing GNNs on\nquantum computers to potentially address the challenges. We devise quantum\nalgorithms corresponding to the three fundamental types of classical GNNs:\nGraph Convolutional Networks, Graph Attention Networks, and Message-Passing\nGNNs. A complexity analysis of our quantum implementation of the Simplified\nGraph Convolutional (SGC) Network shows potential quantum advantages over its\nclassical counterpart, with significant improvements in time and space\ncomplexities. Our complexities can have trade-offs between the two: when\noptimizing for minimal circuit depth, our quantum SGC achieves logarithmic time\ncomplexity in the input sizes (albeit at the cost of linear space complexity).\nWhen optimizing for minimal qubit usage, the quantum SGC exhibits space\ncomplexity logarithmic in the input sizes, offering an exponential reduction\ncompared to classical SGCs, while still maintaining better time complexity.\nThese results suggest our Quantum GNN frameworks could efficiently process\nlarge-scale graphs. This work paves the way for implementing more advanced\nGraph Neural Network models on quantum computers, opening new possibilities in\nquantum machine learning for analyzing graph-structured data.",
        "subjects": [
            "quant-ph",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Yidong Liao",
            "Xiao-Ming Zhang",
            "Chris Ferrie"
        ],
        "published": "2024-05-27T11:31:08Z"
    },
    {
        "title": "Comparative Study of Machine Learning Algorithms in Detecting\n  Cardiovascular Diseases",
        "link": "http://arxiv.org/abs/2405.17059v1",
        "abstract": "The detection of cardiovascular diseases (CVD) using machine learning\ntechniques represents a significant advancement in medical diagnostics, aiming\nto enhance early detection, accuracy, and efficiency. This study explores a\ncomparative analysis of various machine learning algorithms, including Logistic\nRegression, Decision Tree, Random Forest, Gradient Boosting, Support Vector\nMachine (SVM), K-Nearest Neighbors (KNN), and XGBoost. By utilising a\nstructured workflow encompassing data collection, preprocessing, model\nselection and hyperparameter tuning, training, evaluation, and choice of the\noptimal model, this research addresses the critical need for improved\ndiagnostic tools. The findings highlight the efficacy of ensemble methods and\nadvanced algorithms in providing reliable predictions, thereby offering a\ncomprehensive framework for CVD detection that can be readily implemented and\nadapted in clinical settings.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Dayana K",
            "S. Nandini",
            "Sanjjushri Varshini R"
        ],
        "published": "2024-05-27T11:29:54Z"
    },
    {
        "title": "ReflectionCoder: Learning from Reflection Sequence for Enhanced One-off\n  Code Generation",
        "link": "http://arxiv.org/abs/2405.17057v1",
        "abstract": "Code generation plays a crucial role in various tasks, such as code\nauto-completion and mathematical reasoning. Previous work has proposed numerous\nmethods to enhance code generation performance, including integrating feedback\nfrom the compiler. Inspired by this, we present ReflectionCoder, a novel\napproach that effectively leverages reflection sequences constructed by\nintegrating compiler feedback to improve one-off code generation performance.\nFurthermore, we propose reflection self-distillation and dynamically masked\ndistillation to effectively utilize these reflection sequences. Extensive\nexperiments on three benchmarks, i.e., HumanEval (+), MBPP (+), and MultiPl-E,\ndemonstrate that models fine-tuned with our method achieve state-of-the-art\nperformance. Notably, ReflectionCoder-DeepSeek-Coder-33B reaches pass@1 of 82.9\n(76.8) on HumanEval (+) and 84.1 (72.0) on MBPP (+), on par with GPT-3.5-Turbo\nand Claude-3-opus, and surpasses early GPT-4. Beyond the code domain, we\nbelieve this approach can benefit other domains that focus on final results and\nrequire long reasoning paths. Code and data are available at\nhttps://github.com/SenseLLM/ReflectionCoder.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Houxing Ren",
            "Mingjie Zhan",
            "Zhongyuan Wu",
            "Aojun Zhou",
            "Junting Pan",
            "Hongsheng Li"
        ],
        "published": "2024-05-27T11:27:00Z"
    },
    {
        "title": "Improving Data-aware and Parameter-aware Robustness for Continual\n  Learning",
        "link": "http://arxiv.org/abs/2405.17054v1",
        "abstract": "The goal of Continual Learning (CL) task is to continuously learn multiple\nnew tasks sequentially while achieving a balance between the plasticity and\nstability of new and old knowledge. This paper analyzes that this insufficiency\narises from the ineffective handling of outliers, leading to abnormal gradients\nand unexpected model updates. To address this issue, we enhance the data-aware\nand parameter-aware robustness of CL, proposing a Robust Continual Learning\n(RCL) method. From the data perspective, we develop a contrastive loss based on\nthe concepts of uniformity and alignment, forming a feature distribution that\nis more applicable to outliers. From the parameter perspective, we present a\nforward strategy for worst-case perturbation and apply robust gradient\nprojection to the parameters. The experimental results on three benchmarks show\nthat the proposed method effectively maintains robustness and achieves new\nstate-of-the-art (SOTA) results. The code is available at:\nhttps://github.com/HanxiXiao/RCL",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Hanxi Xiao",
            "Fan Lyu"
        ],
        "published": "2024-05-27T11:21:26Z"
    },
    {
        "title": "WirelessLLM: Empowering Large Language Models Towards Wireless\n  Intelligence",
        "link": "http://arxiv.org/abs/2405.17053v1",
        "abstract": "The rapid evolution of wireless technologies and the growing complexity of\nnetwork infrastructures necessitate a paradigm shift in how communication\nnetworks are designed, configured, and managed. Recent advancements in Large\nLanguage Models (LLMs) have sparked interest in their potential to\nrevolutionize wireless communication systems. However, existing studies on LLMs\nfor wireless systems are limited to a direct application for telecom language\nunderstanding. To empower LLMs with knowledge and expertise in the wireless\ndomain, this paper proposes WirelessLLM, a comprehensive framework for adapting\nand enhancing LLMs to address the unique challenges and requirements of\nwireless communication networks. We first identify three foundational\nprinciples that underpin WirelessLLM: knowledge alignment, knowledge fusion,\nand knowledge evolution. Then, we investigate the enabling technologies to\nbuild WirelessLLM, including prompt engineering, retrieval augmented\ngeneration, tool usage, multi-modal pre-training, and domain-specific\nfine-tuning. Moreover, we present three case studies to demonstrate the\npractical applicability and benefits of WirelessLLM for solving typical\nproblems in wireless networks. Finally, we conclude this paper by highlighting\nkey challenges and outlining potential avenues for future research.",
        "subjects": [
            "cs.NI",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Jiawei Shao",
            "Jingwen Tong",
            "Qiong Wu",
            "Wei Guo",
            "Zijian Li",
            "Zehong Lin",
            "Jun Zhang"
        ],
        "published": "2024-05-27T11:18:25Z"
    },
    {
        "title": "SelfCP: Compressing Long Prompt to 1/12 Using the Frozen Large Language\n  Model Itself",
        "link": "http://arxiv.org/abs/2405.17052v1",
        "abstract": "Long prompt leads to huge hardware costs when using Large Language Models\n(LLMs). Unfortunately, many tasks, such as summarization, inevitably introduce\nlong task-inputs, and the wide application of in-context learning easily makes\nthe prompt length explode. Inspired by the language understanding ability of\nLLMs, this paper proposes SelfCP, which uses the LLM \\textbf{itself} to\n\\textbf{C}ompress long \\textbf{P}rompt into compact virtual tokens. SelfCP\napplies a general frozen LLM twice, first as an encoder to compress the prompt\nand then as a decoder to generate responses. Specifically, given a long prompt,\nwe place special tokens within the lengthy segment for compression and signal\nthe LLM to generate $k$ virtual tokens. Afterward, the virtual tokens\nconcatenate with the uncompressed prompt and are fed into the same LLM to\ngenerate the response. In general, SelfCP facilitates the unconditional and\nconditional compression of prompts, fitting both standard tasks and those with\nspecific objectives. Since the encoder and decoder are frozen, SelfCP only\ncontains 17M trainable parameters and allows for convenient adaptation across\nvarious backbones. We implement SelfCP with two LLM backbones and evaluate it\nin both in- and out-domain tasks. Results show that the compressed virtual\ntokens can substitute $12 \\times$ larger original prompts effectively",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Jun Gao"
        ],
        "published": "2024-05-27T11:14:55Z"
    },
    {
        "title": "BeamVQ: Aligning Space-Time Forecasting Model via Self-training on\n  Physics-aware Metrics",
        "link": "http://arxiv.org/abs/2405.17051v1",
        "abstract": "Data-driven deep learning has emerged as the new paradigm to model complex\nphysical space-time systems. These data-driven methods learn patterns by\noptimizing statistical metrics and tend to overlook the adherence to physical\nlaws, unlike traditional model-driven numerical methods. Thus, they often\ngenerate predictions that are not physically realistic. On the other hand, by\nsampling a large amount of high quality predictions from a data-driven model,\nsome predictions will be more physically plausible than the others and closer\nto what will happen in the future. Based on this observation, we propose\n\\emph{Beam search by Vector Quantization} (BeamVQ) to enhance the physical\nalignment of data-driven space-time forecasting models. The key of BeamVQ is to\ntrain model on self-generated samples filtered with physics-aware metrics. To\nbe flexibly support different backbone architectures, BeamVQ leverages a code\nbank to transform any encoder-decoder model to the continuous state space into\ndiscrete codes. Afterwards, it iteratively employs beam search to sample\nhigh-quality sequences, retains those with the highest physics-aware scores,\nand trains model on the new dataset. Comprehensive experiments show that BeamVQ\nnot only gave an average statistical skill score boost for more than 32% for\nten backbones on five datasets, but also significantly enhances physics-aware\nmetrics.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Hao Wu",
            "Xingjian Shi",
            "Ziyue Huang",
            "Penghao Zhao",
            "Wei Xiong",
            "Jinbao Xue",
            "Yangyu Tao",
            "Xiaomeng Huang",
            "Weiyan Wang"
        ],
        "published": "2024-05-27T11:07:47Z"
    },
    {
        "title": "HeNCler: Node Clustering in Heterophilous Graphs through Learned\n  Asymmetric Similarity",
        "link": "http://arxiv.org/abs/2405.17050v1",
        "abstract": "Clustering nodes in heterophilous graphs presents unique challenges due to\nthe asymmetric relationships often overlooked by traditional methods, which\nmoreover assume that good clustering corresponds to high intra-cluster and low\ninter-cluster connectivity. To address these issues, we introduce HeNCler - a\nnovel approach for Heterophilous Node Clustering. Our method begins by defining\na weighted kernel singular value decomposition to create an asymmetric\nsimilarity graph, applicable to both directed and undirected graphs. We further\nestablish that the dual problem of this formulation aligns with asymmetric\nkernel spectral clustering, interpreting learned graph similarities without\nrelying on homophily. We demonstrate the ability to solve the primal problem\ndirectly, circumventing the computational difficulties of the dual approach.\nExperimental evidence confirms that HeNCler significantly enhances performance\nin node clustering tasks within heterophilous graph contexts.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Sonny Achten",
            "Francesco Tonin",
            "Volkan Cevher",
            "Johan A. K. Suykens"
        ],
        "published": "2024-05-27T11:04:05Z"
    },
    {
        "title": "Verifying Properties of Binary Neural Networks Using Sparse Polynomial\n  Optimization",
        "link": "http://arxiv.org/abs/2405.17049v1",
        "abstract": "This paper explores methods for verifying the properties of Binary Neural\nNetworks (BNNs), focusing on robustness against adversarial attacks. Despite\ntheir lower computational and memory needs, BNNs, like their full-precision\ncounterparts, are also sensitive to input perturbations. Established methods\nfor solving this problem are predominantly based on Satisfiability Modulo\nTheories and Mixed-Integer Linear Programming techniques, which are\ncharacterized by NP complexity and often face scalability issues.\n  We introduce an alternative approach using Semidefinite Programming\nrelaxations derived from sparse Polynomial Optimization. Our approach,\ncompatible with continuous input space, not only mitigates numerical issues\nassociated with floating-point calculations but also enhances verification\nscalability through the strategic use of tighter first-order semidefinite\nrelaxations. We demonstrate the effectiveness of our method in verifying\nrobustness against both $\\|.\\|_\\infty$ and $\\|.\\|_2$-based adversarial attacks.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Jianting Yang",
            "Sreko urainovi",
            "Jean-Bernard Lasserre",
            "Victor Magron",
            "Jun Zhao"
        ],
        "published": "2024-05-27T11:03:48Z"
    },
    {
        "title": "Interpretable Robotic Manipulation from Language",
        "link": "http://arxiv.org/abs/2405.17047v1",
        "abstract": "Humans naturally employ linguistic instructions to convey knowledge, a\nprocess that proves significantly more complex for machines, especially within\nthe context of multitask robotic manipulation environments. Natural language,\nmoreover, serves as the primary medium through which humans acquire new\nknowledge, presenting a potentially intuitive bridge for translating concepts\nunderstandable by humans into formats that can be learned by machines. In\npursuit of facilitating this integration, we introduce an explainable behavior\ncloning agent, named Ex-PERACT, specifically designed for manipulation tasks.\nThis agent is distinguished by its hierarchical structure, which incorporates\nnatural language to enhance the learning process. At the top level, the model\nis tasked with learning a discrete skill code, while at the bottom level, the\npolicy network translates the problem into a voxelized grid and maps the\ndiscretized actions to voxel grids. We evaluate our method across eight\nchallenging manipulation tasks utilizing the RLBench benchmark, demonstrating\nthat Ex-PERACT not only achieves competitive policy performance but also\neffectively bridges the gap between human instructions and machine execution in\ncomplex environments.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "authors": [
            "Boyuan Zheng",
            "Jianlong Zhou",
            "Fang Chen"
        ],
        "published": "2024-05-27T11:02:21Z"
    },
    {
        "title": "Generation and human-expert evaluation of interesting research ideas\n  using knowledge graphs and large language models",
        "link": "http://arxiv.org/abs/2405.17044v1",
        "abstract": "Advanced artificial intelligence (AI) systems with access to millions of\nresearch papers could inspire new research ideas that may not be conceived by\nhumans alone. However, how interesting are these AI-generated ideas, and how\ncan we improve their quality? Here, we introduce SciMuse, a system that uses an\nevolving knowledge graph built from more than 58 million scientific papers to\ngenerate personalized research ideas via an interface to GPT-4. We conducted a\nlarge-scale human evaluation with over 100 research group leaders from the Max\nPlanck Society, who ranked more than 4,000 personalized research ideas based on\ntheir level of interest. This evaluation allows us to understand the\nrelationships between scientific interest and the core properties of the\nknowledge graph. We find that data-efficient machine learning can predict\nresearch interest with high precision, allowing us to optimize the\ninterest-level of generated research ideas. This work represents a step towards\nan artificial scientific muse that could catalyze unforeseen collaborations and\nsuggest interesting avenues for scientists.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.DL",
            "cs.LG"
        ],
        "authors": [
            "Xuemei Gu",
            "Mario Krenn"
        ],
        "published": "2024-05-27T11:00:51Z"
    },
    {
        "title": "LabObf: A Label Protection Scheme for Vertical Federated Learning\n  Through Label Obfuscation",
        "link": "http://arxiv.org/abs/2405.17042v1",
        "abstract": "Split learning, as one of the most common architectures in vertical federated\nlearning, has gained widespread use in industry due to its privacy-preserving\ncharacteristics. In this architecture, the party holding the labels seeks\ncooperation from other parties to improve model performance due to insufficient\nfeature data. Each of these participants has a self-defined bottom model to\nlearn hidden representations from its own feature data and uploads the\nembedding vectors to the top model held by the label holder for final\npredictions. This design allows participants to conduct joint training without\ndirectly exchanging data. However, existing research points out that malicious\nparticipants may still infer label information from the uploaded embeddings,\nleading to privacy leakage. In this paper, we first propose an embedding\nextension attack that manually modifies embeddings to undermine existing\ndefense strategies, which rely on constraining the correlation between the\nembeddings uploaded by participants and the labels. Subsequently, we propose a\nnew label obfuscation defense strategy, called `LabObf', which randomly maps\neach original one-hot vector label to multiple numerical soft labels with\nvalues intertwined, significantly increasing the difficulty for attackers to\ninfer the labels. We conduct experiments on four different types of datasets,\nand the results show that LabObf can reduce the attacker's success rate to near\nrandom guessing while maintaining an acceptable model accuracy.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "authors": [
            "Ying He",
            "Mingyang Niu",
            "Jingyu Hua",
            "Yunlong Mao",
            "Xu Huang",
            "Chen Li",
            "Sheng Zhong"
        ],
        "published": "2024-05-27T10:54:42Z"
    },
    {
        "title": "BWArea Model: Learning World Model, Inverse Dynamics, and Policy for\n  Controllable Language Generation",
        "link": "http://arxiv.org/abs/2405.17039v1",
        "abstract": "Large language models (LLMs) have catalyzed a paradigm shift in natural\nlanguage processing, yet their limited controllability poses a significant\nchallenge for downstream applications. We aim to address this by drawing\ninspiration from the neural mechanisms of the human brain, specifically Broca's\nand Wernicke's areas, which are crucial for language generation and\ncomprehension, respectively. In particular, Broca's area receives cognitive\ndecision signals from Wernicke's area, treating the language generation as an\nintricate decision-making process, which differs from the fully auto-regressive\nlanguage generation of existing LLMs. In a similar vein, our proposed system,\nthe BWArea model, conceptualizes language generation as a decision-making task.\nThis model has three components: a language world model, an inverse dynamics\nmodel, and a cognitive policy. Like Wernicke's area, the inverse dynamics model\nis designed to deduce the underlying cognitive intentions, or latent actions,\nbehind each token. The BWArea model is amenable to both pre-training and\nfine-tuning like existing LLMs. With 30B clean pre-training tokens, we have\ntrained a BWArea model, which achieves competitive performance with LLMs of\nequal size (1B parameters). Unlike fully auto-regressive LLMs, its pre-training\nperformance does not degenerate if dirty data unintentionally appears. This\nshows the advantage of a decomposed structure of BWArea model in reducing\nefforts in laborious data selection and labeling. Finally, we reveal that the\nBWArea model offers enhanced controllability via fine-tuning the cognitive\npolicy with downstream reward metrics, thereby facilitating alignment with\ngreater simplicity. On 9 out of 10 tasks from two suites, TextWorld and\nBigBench Hard, our method shows superior performance to auto-regressive LLMs.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Chengxing Jia",
            "Pengyuan Wang",
            "Ziniu Li",
            "Yi-Chen Li",
            "Zhilong Zhang",
            "Nan Tang",
            "Yang Yu"
        ],
        "published": "2024-05-27T10:45:49Z"
    },
    {
        "title": "Advancements in Tactile Hand Gesture Recognition for Enhanced\n  Human-Machine Interaction",
        "link": "http://arxiv.org/abs/2405.17038v1",
        "abstract": "Motivated by the growing interest in enhancing intuitive physical\nHuman-Machine Interaction (HRI/HVI), this study aims to propose a robust\ntactile hand gesture recognition system. We performed a comprehensive\nevaluation of different hand gesture recognition approaches for a large area\ntactile sensing interface (touch interface) constructed from conductive\ntextiles. Our evaluation encompassed traditional feature engineering methods,\nas well as contemporary deep learning techniques capable of real-time\ninterpretation of a range of hand gestures, accommodating variations in hand\nsizes, movement velocities, applied pressure levels, and interaction points.\nOur extensive analysis of the various methods makes a significant contribution\nto tactile-based gesture recognition in the field of human-machine interaction.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Chiara Fumelli",
            "Anirvan Dutta",
            "Mohsen Kaboli"
        ],
        "published": "2024-05-27T10:44:27Z"
    },
    {
        "title": "BDC-Occ: Binarized Deep Convolution Unit For Binarized Occupancy Network",
        "link": "http://arxiv.org/abs/2405.17037v1",
        "abstract": "Existing 3D occupancy networks demand significant hardware resources,\nhindering the deployment of edge devices. Binarized Neural Networks (BNN) offer\nsubstantially reduced computational and memory requirements. However, their\nperformance decreases notably compared to full-precision networks. Moreover, it\nis challenging to enhance the performance of binarized models by increasing the\nnumber of binarized convolutional layers, which limits their practicability for\n3D occupancy prediction. To bridge these gaps, we propose a novel binarized\ndeep convolution (BDC) unit that effectively enhances performance while\nincreasing the number of binarized convolutional layers. Firstly, through\ntheoretical analysis, we demonstrate that 1 \\times 1 binarized convolutions\nintroduce minimal binarization errors. Therefore, additional binarized\nconvolutional layers are constrained to 1 \\times 1 in the BDC unit. Secondly,\nwe introduce the per-channel weight branch to mitigate the impact of\nbinarization errors from unimportant channel features on the performance of\nbinarized models, thereby improving performance while increasing the number of\nbinarized convolutional layers. Furthermore, we decompose the 3D occupancy\nnetwork into four convolutional modules and utilize the proposed BDC unit to\nbinarize these modules. Our BDC-Occ model is created by applying the proposed\nBDC unit to binarize the existing 3D occupancy networks. Comprehensive\nquantitative and qualitative experiments demonstrate that the proposed BDC-Occ\nis the state-of-the-art binarized 3D occupancy network algorithm.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zongkai Zhang",
            "Zidong Xu",
            "Wenming Yang",
            "Qingmin Liao",
            "Jing-Hao Xue"
        ],
        "published": "2024-05-27T10:44:05Z"
    },
    {
        "title": "Glauber Generative Model: Discrete Diffusion Models via Binary\n  Classification",
        "link": "http://arxiv.org/abs/2405.17035v1",
        "abstract": "We introduce the Glauber Generative Model (GGM), a new class of discrete\ndiffusion models, to obtain new samples from a distribution given samples from\na discrete space. GGM deploys a discrete Markov chain called the heat bath\ndynamics (or the Glauber dynamics) to denoise a sequence of noisy tokens to a\nsample from a joint distribution of discrete tokens. Our novel conceptual\nframework provides an exact reduction of the task of learning the denoising\nMarkov chain to solving a class of binary classification tasks. More\nspecifically, the model learns to classify a given token in a noisy sequence as\nsignal or noise. In contrast, prior works on discrete diffusion models either\nsolve regression problems to learn importance ratios, or minimize loss\nfunctions given by variational approximations. We apply GGM to language\nmodeling and image generation, where images are discretized using image\ntokenizers like VQGANs. We show that it outperforms existing discrete diffusion\nmodels in language generation, and demonstrates strong performance for image\ngeneration without using dataset-specific image tokenizers. We also show that\nour model is capable of performing well in zero-shot control settings like text\nand image infilling.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Harshit Varma",
            "Dheeraj Nagaraj",
            "Karthikeyan Shanmugam"
        ],
        "published": "2024-05-27T10:42:13Z"
    },
    {
        "title": "FUGNN: Harmonizing Fairness and Utility in Graph Neural Networks",
        "link": "http://arxiv.org/abs/2405.17034v1",
        "abstract": "Fairness-aware Graph Neural Networks (GNNs) often face a challenging\ntrade-off, where prioritizing fairness may require compromising utility. In\nthis work, we re-examine fairness through the lens of spectral graph theory,\naiming to reconcile fairness and utility within the framework of spectral graph\nlearning. We explore the correlation between sensitive features and spectrum in\nGNNs, using theoretical analysis to delineate the similarity between original\nsensitive features and those after convolution under different spectrum. Our\nanalysis reveals a reduction in the impact of similarity when the eigenvectors\nassociated with the largest magnitude eigenvalue exhibit directional\nsimilarity. Based on these theoretical insights, we propose FUGNN, a novel\nspectral graph learning approach that harmonizes the conflict between fairness\nand utility. FUGNN ensures algorithmic fairness and utility by truncating the\nspectrum and optimizing eigenvector distribution during the encoding process.\nThe fairness-aware eigenvector selection reduces the impact of convolution on\nsensitive features while concurrently minimizing the sacrifice of utility.\nFUGNN further optimizes the distribution of eigenvectors through a transformer\narchitecture. By incorporating the optimized spectrum into the graph\nconvolution network, FUGNN effectively learns node representations. Experiments\non six real-world datasets demonstrate the superiority of FUGNN over baseline\nmethods. The codes are available at https://github.com/yushuowiki/FUGNN.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Renqiang Luo",
            "Huafei Huang",
            "Shuo Yu",
            "Zhuoyang Han",
            "Estrid He",
            "Xiuzhen Zhang",
            "Feng Xia"
        ],
        "published": "2024-05-27T10:40:21Z"
    },
    {
        "title": "Any-step Dynamics Model Improves Future Predictions for Online and\n  Offline Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.17031v1",
        "abstract": "Model-based methods in reinforcement learning offer a promising approach to\nenhance data efficiency by facilitating policy exploration within a dynamics\nmodel. However, accurately predicting sequential steps in the dynamics model\nremains a challenge due to the bootstrapping prediction, which attributes the\nnext state to the prediction of the current state. This leads to accumulated\nerrors during model roll-out. In this paper, we propose the Any-step Dynamics\nModel (ADM) to mitigate the compounding error by reducing bootstrapping\nprediction to direct prediction. ADM allows for the use of variable-length\nplans as inputs for predicting future states without frequent bootstrapping. We\ndesign two algorithms, ADMPO-ON and ADMPO-OFF, which apply ADM in online and\noffline model-based frameworks, respectively. In the online setting, ADMPO-ON\ndemonstrates improved sample efficiency compared to previous state-of-the-art\nmethods. In the offline setting, ADMPO-OFF not only demonstrates superior\nperformance compared to recent state-of-the-art offline approaches but also\noffers better quantification of model uncertainty using only a single ADM.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Haoxin Lin",
            "Yu-Yan Xu",
            "Yihao Sun",
            "Zhilong Zhang",
            "Yi-Chen Li",
            "Chengxing Jia",
            "Junyin Ye",
            "Jiaji Zhang",
            "Yang Yu"
        ],
        "published": "2024-05-27T10:33:53Z"
    },
    {
        "title": "SCaRL- A Synthetic Multi-Modal Dataset for Autonomous Driving",
        "link": "http://arxiv.org/abs/2405.17030v1",
        "abstract": "We present a novel synthetically generated multi-modal dataset, SCaRL, to\nenable the training and validation of autonomous driving solutions. Multi-modal\ndatasets are essential to attain the robustness and high accuracy required by\nautonomous systems in applications such as autonomous driving. As deep\nlearning-based solutions are becoming more prevalent for object detection,\nclassification, and tracking tasks, there is great demand for datasets\ncombining camera, lidar, and radar sensors. Existing real/synthetic datasets\nfor autonomous driving lack synchronized data collection from a complete sensor\nsuite. SCaRL provides synchronized Synthetic data from RGB, semantic/instance,\nand depth Cameras; Range-Doppler-Azimuth/Elevation maps and raw data from\nRadar; and 3D point clouds/2D maps of semantic, depth and Doppler data from\ncoherent Lidar. SCaRL is a large dataset based on the CARLA Simulator, which\nprovides data for diverse, dynamic scenarios and traffic conditions. SCaRL is\nthe first dataset to include synthetic synchronized data from coherent Lidar\nand MIMO radar sensors.\n  The dataset can be accessed here:\nhttps://fhr-ihs-sva.pages.fraunhofer.de/asp/scarl/",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Avinash Nittur Ramesh",
            "Aitor Correas-Serrano",
            "Mara Gonzlez-Huici"
        ],
        "published": "2024-05-27T10:31:26Z"
    },
    {
        "title": "Multi-view Disparity Estimation Using a Novel Gradient Consistency Model",
        "link": "http://arxiv.org/abs/2405.17029v1",
        "abstract": "Variational approaches to disparity estimation typically use a linearised\nbrightness constancy constraint, which only applies in smooth regions and over\nsmall distances. Accordingly, current variational approaches rely on a schedule\nto progressively include image data. This paper proposes the use of Gradient\nConsistency information to assess the validity of the linearisation; this\ninformation is used to determine the weights applied to the data term as part\nof an analytically inspired Gradient Consistency Model. The Gradient\nConsistency Model penalises the data term for view pairs that have a mismatch\nbetween the spatial gradients in the source view and the spatial gradients in\nthe target view. Instead of relying on a tuned or learned schedule, the\nGradient Consistency Model is self-scheduling, since the weights evolve as the\nalgorithm progresses. We show that the Gradient Consistency Model outperforms\nstandard coarse-to-fine schemes and the recently proposed progressive inclusion\nof views approach in both rate of convergence and accuracy.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "James L. Gray",
            "Aous T. Naman",
            "David S. Taubman"
        ],
        "published": "2024-05-27T10:30:59Z"
    },
    {
        "title": "RSET: Remapping-based Sorting Method for Emotion Transfer Speech\n  Synthesis",
        "link": "http://arxiv.org/abs/2405.17028v1",
        "abstract": "Although current Text-To-Speech (TTS) models are able to generate\nhigh-quality speech samples, there are still challenges in developing emotion\nintensity controllable TTS. Most existing TTS models achieve emotion intensity\ncontrol by extracting intensity information from reference speeches.\nUnfortunately, limited by the lack of modeling for intra-class emotion\nintensity and the model's information decoupling capability, the generated\nspeech cannot achieve fine-grained emotion intensity control and suffers from\ninformation leakage issues. In this paper, we propose an emotion transfer TTS\nmodel, which defines a remapping-based sorting method to model intra-class\nrelative intensity information, combined with Mutual Information (MI) to\ndecouple speaker and emotion information, and synthesizes expressive speeches\nwith perceptible intensity differences. Experiments show that our model\nachieves fine-grained emotion control while preserving speaker information.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Haoxiang Shi",
            "Jianzong Wang",
            "Xulong Zhang",
            "Ning Cheng",
            "Jun Yu",
            "Jing Xiao"
        ],
        "published": "2024-05-27T10:30:54Z"
    },
    {
        "title": "Supervised Batch Normalization",
        "link": "http://arxiv.org/abs/2405.17027v1",
        "abstract": "Batch Normalization (BN), a widely-used technique in neural networks,\nenhances generalization and expedites training by normalizing each mini-batch\nto the same mean and variance. However, its effectiveness diminishes when\nconfronted with diverse data distributions. To address this challenge, we\npropose Supervised Batch Normalization (SBN), a pioneering approach. We expand\nnormalization beyond traditional single mean and variance parameters, enabling\nthe identification of data modes prior to training. This ensures effective\nnormalization for samples sharing common features. We define contexts as modes,\ncategorizing data with similar characteristics. These contexts are explicitly\ndefined, such as domains in domain adaptation or modalities in multimodal\nsystems, or implicitly defined through clustering algorithms based on data\nsimilarity. We illustrate the superiority of our approach over BN and other\ncommonly employed normalization techniques through various experiments on both\nsingle and multi-task datasets. Integrating SBN with Vision Transformer results\nin a remarkable \\textit{15.13}\\% accuracy enhancement on CIFAR-100.\nAdditionally, in domain adaptation scenarios, employing AdaMatch demonstrates\nan impressive \\textit{22.25}\\% accuracy improvement on MNIST and SVHN compared\nto BN.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Bilal Faye",
            "Mustapha Lebbah",
            "Hanane Azzag"
        ],
        "published": "2024-05-27T10:30:21Z"
    },
    {
        "title": "SWAT: Scalable and Efficient Window Attention-based Transformers\n  Acceleration on FPGAs",
        "link": "http://arxiv.org/abs/2405.17025v1",
        "abstract": "Efficiently supporting long context length is crucial for Transformer models.\nThe quadratic complexity of the self-attention computation plagues traditional\nTransformers. Sliding window-based static sparse attention mitigates the\nproblem by limiting the attention scope of the input tokens, reducing the\ntheoretical complexity from quadratic to linear. Although the sparsity induced\nby window attention is highly structured, it does not align perfectly with the\nmicroarchitecture of the conventional accelerators, leading to suboptimal\nimplementation. In response, we propose a dataflow-aware FPGA-based accelerator\ndesign, SWAT, that efficiently leverages the sparsity to achieve scalable\nperformance for long input. The proposed microarchitecture is based on a design\nthat maximizes data reuse by using a combination of row-wise dataflow, kernel\nfusion optimization, and an input-stationary design considering the distributed\nmemory and computation resources of FPGA. Consequently, it achieves up to\n22$\\times$ and 5.7$\\times$ improvement in latency and energy efficiency\ncompared to the baseline FPGA-based accelerator and 15$\\times$ energy\nefficiency compared to GPU-based solution.",
        "subjects": [
            "cs.AR",
            "cs.AI"
        ],
        "authors": [
            "Zhenyu Bai",
            "Pranav Dangi",
            "Huize Li",
            "Tulika Mitra"
        ],
        "published": "2024-05-27T10:25:08Z"
    },
    {
        "title": "Compositional Few-Shot Class-Incremental Learning",
        "link": "http://arxiv.org/abs/2405.17022v1",
        "abstract": "Few-shot class-incremental learning (FSCIL) is proposed to continually learn\nfrom novel classes with only a few samples after the (pre-)training on base\nclasses with sufficient data. However, this remains a challenge. In contrast,\nhumans can easily recognize novel classes with a few samples. Cognitive science\ndemonstrates that an important component of such human capability is\ncompositional learning. This involves identifying visual primitives from\nlearned knowledge and then composing new concepts using these transferred\nprimitives, making incremental learning both effective and interpretable. To\nimitate human compositional learning, we propose a cognitive-inspired method\nfor the FSCIL task. We define and build a compositional model based on set\nsimilarities, and then equip it with a primitive composition module and a\nprimitive reuse module. In the primitive composition module, we propose to\nutilize the Centered Kernel Alignment (CKA) similarity to approximate the\nsimilarity between primitive sets, allowing the training and evaluation based\non primitive compositions. In the primitive reuse module, we enhance primitive\nreusability by classifying inputs based on primitives replaced with the closest\nprimitives from other classes. Experiments on three datasets validate our\nmethod, showing it outperforms current state-of-the-art methods with improved\ninterpretability. Our code is available at\nhttps://github.com/Zoilsen/Comp-FSCIL.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Yixiong Zou",
            "Shanghang Zhang",
            "Haichen Zhou",
            "Yuhua Li",
            "Ruixuan Li"
        ],
        "published": "2024-05-27T10:21:38Z"
    },
    {
        "title": "From Compliant to Rigid Contact Simulation: a Unified and Efficient\n  Approach",
        "link": "http://arxiv.org/abs/2405.17020v1",
        "abstract": "Whether rigid or compliant, contact interactions are inherent to robot\nmotions, enabling them to move or manipulate things. Contact interactions\nresult from complex physical phenomena, that can be mathematically cast as\nNonlinear Complementarity Problems (NCPs) in the context of rigid or compliant\npoint contact interactions. Such a class of complementarity problems is, in\ngeneral, difficult to solve both from an optimization and numerical\nperspective. Over the past decades, dedicated and specialized contact solvers,\nimplemented in modern robotics simulators (e.g., Bullet, Drake, MuJoCo, DART,\nRaisim) have emerged. Yet, most of these solvers tend either to solve a relaxed\nformulation of the original contact problems (at the price of physical\ninconsistencies) or to scale poorly with the problem dimension or its numerical\nconditioning (e.g., a robotic hand manipulating a paper sheet). In this paper,\nwe introduce a unified and efficient approach to solving NCPs in the context of\ncontact simulation. It relies on a sound combination of the Alternating\nDirection Method of Multipliers (ADMM) and proximal algorithms to account for\nboth compliant and rigid contact interfaces in a unified way. To handle\nill-conditioned problems and accelerate the convergence rate, we also propose\nan efficient update strategy to adapt the ADMM hyperparameters automatically.\nBy leveraging proximal methods, we also propose new algorithmic solutions to\nefficiently evaluate the inverse dynamics involving rigid and compliant contact\ninteractions, extending the approach developed in MuJoCo. We validate the\nefficiency and robustness of our contact solver against several alternative\ncontact methods of the literature and benchmark them on various robotics and\ngranular mechanics scenarios. Our code is made open-source at\nhttps://github.com/Simple-Robotics/Simple.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Justin Carpentier",
            "Louis Montaut",
            "Quentin Le Lidec"
        ],
        "published": "2024-05-27T10:15:35Z"
    },
    {
        "title": "Bounding Random Test Set Size with Computational Learning Theory",
        "link": "http://dx.doi.org/10.1145/3660819",
        "abstract": "Random testing approaches work by generating inputs at random, or by\nselecting inputs randomly from some pre-defined operational profile. One\nlong-standing question that arises in this and other testing contexts is as\nfollows: When can we stop testing? At what point can we be certain that\nexecuting further tests in this manner will not explore previously untested\n(and potentially buggy) software behaviors? This is analogous to the question\nin Machine Learning, of how many training examples are required in order to\ninfer an accurate model. In this paper we show how probabilistic approaches to\nanswer this question in Machine Learning (arising from Computational Learning\nTheory) can be applied in our testing context. This enables us to produce an\nupper bound on the number of tests that are required to achieve a given level\nof adequacy. We are the first to enable this from only knowing the number of\ncoverage targets (e.g. lines of code) in the source code, without needing to\nobserve a sample test executions. We validate this bound on a large set of Java\nunits, and an autonomous driving system.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Neil Walkinshaw",
            "Michael Foster",
            "Jose Miguel Rojas",
            "Robert M Hierons"
        ],
        "published": "2024-05-27T10:15:16Z"
    },
    {
        "title": "Structural cohesive element for the modelling of delamination in\n  composite laminates without the cohesive zone limit",
        "link": "http://arxiv.org/abs/2405.17018v1",
        "abstract": "Delamination is a critical mode of failure that occurs between plies in a\ncomposite laminate. The cohesive element, developed based on the cohesive zone\nmodel, is widely used for modeling delamination. However, standard cohesive\nelements suffer from a well-known limit on the mesh density-the element size\nmust be much smaller than the cohesive zone size. This work develops a new set\nof elements for modelling composite plies and their interfaces in 3D. A\ntriangular Kirchhoff-Love shell element is developed for orthotropic materials\nto model the plies. A structural cohesive element, conforming to the shell\nelements of the plies, is developed to model the interface delamination. The\nproposed method is verified and validated on the classical benchmark problems\nof Mode I, Mode II, and mixed-mode delamination of unidirectional laminates, as\nwell as on the single-leg bending problem of a multi-directional laminate. All\nthe results show that the element size in the proposed models can be ten times\nlarger than that in the standard cohesive element models, with more than 90%\nreduction in CPU time, while retaining prediction accuracy. This would then\nallow more effective and efficient modeling of delamination in composites\nwithout worrying about the cohesive zone limit on the mesh density.",
        "subjects": [
            "cs.CE",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Xiaopeng Ai",
            "Boyang Chen",
            "Christos Kassapoglou"
        ],
        "published": "2024-05-27T10:05:50Z"
    },
    {
        "title": "Analysis of Multiscale Reinforcement Q-Learning Algorithms for Mean\n  Field Control Games",
        "link": "http://arxiv.org/abs/2405.17017v2",
        "abstract": "Mean Field Control Games (MFCG), introduced in [Angiuli et al., 2022a],\nrepresent competitive games between a large number of large collaborative\ngroups of agents in the infinite limit of number and size of groups. In this\npaper, we prove the convergence of a three-timescale Reinforcement Q-Learning\n(RL) algorithm to solve MFCG in a model-free approach from the point of view of\nrepresentative agents. Our analysis uses a Q-table for finite state and action\nspaces updated at each discrete time-step over an infinite horizon. In [Angiuli\net al., 2023], we proved convergence of two-timescale algorithms for MFG and\nMFC separately highlighting the need to follow multiple population\ndistributions in the MFC case. Here, we integrate this feature for MFCG as well\nas three rates of update decreasing to zero in the proper ratios. Our technique\nof proof uses a generalization to three timescales of the two-timescale\nanalysis in [Borkar, 1997]. We give a simple example satisfying the various\nhypothesis made in the proof of convergence and illustrating the performance of\nthe algorithm.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "cs.MA"
        ],
        "authors": [
            "Andrea Angiuli",
            "Jean-Pierre Fouque",
            "Mathieu Laurire",
            "Mengrui Zhang"
        ],
        "published": "2024-05-27T10:01:52Z"
    },
    {
        "title": "$\\text{Di}^2\\text{Pose}$: Discrete Diffusion Model for Occluded 3D Human\n  Pose Estimation",
        "link": "http://arxiv.org/abs/2405.17016v1",
        "abstract": "Continuous diffusion models have demonstrated their effectiveness in\naddressing the inherent uncertainty and indeterminacy in monocular 3D human\npose estimation (HPE). Despite their strengths, the need for large search\nspaces and the corresponding demand for substantial training data make these\nmodels prone to generating biomechanically unrealistic poses. This challenge is\nparticularly noticeable in occlusion scenarios, where the complexity of\ninferring 3D structures from 2D images intensifies. In response to these\nlimitations, we introduce the Discrete Diffusion Pose\n($\\text{Di}^2\\text{Pose}$), a novel framework designed for occluded 3D HPE that\ncapitalizes on the benefits of a discrete diffusion model. Specifically,\n$\\text{Di}^2\\text{Pose}$ employs a two-stage process: it first converts 3D\nposes into a discrete representation through a \\emph{pose quantization step},\nwhich is subsequently modeled in latent space through a \\emph{discrete\ndiffusion process}. This methodological innovation restrictively confines the\nsearch space towards physically viable configurations and enhances the model's\ncapability to comprehend how occlusions affect human pose within the latent\nspace. Extensive evaluations conducted on various benchmarks (e.g., Human3.6M,\n3DPW, and 3DPW-Occ) have demonstrated its effectiveness.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Weiquan Wang",
            "Jun Xiao",
            "Chunping Wang",
            "Wei Liu",
            "Zhao Wang",
            "Long Chen"
        ],
        "published": "2024-05-27T10:01:36Z"
    },
    {
        "title": "MotionLLM: Multimodal Motion-Language Learning with Large Language\n  Models",
        "link": "http://arxiv.org/abs/2405.17013v2",
        "abstract": "Recent advancements in Multimodal Large Language Models (MM-LLMs) have\ndemonstrated promising potential in terms of generalization and robustness when\napplied to different modalities. While previous works have already achieved 3D\nhuman motion generation using various approaches including language modeling,\nthey mostly % are mostly carefully designed use specialized architecture and\nare restricted to single-human motion generation. Inspired by the success of\nMM-LLMs, we propose MotionLLM, a simple and general framework that can achieve\nsingle-human, multi-human motion generation, and motion captioning by\nfine-tuning pre-trained LLMs. Specifically, we encode and quantize motions into\ndiscrete LLM-understandable tokens, which results in a unified vocabulary\nconsisting of both motion and text tokens. With only 1--3% parameters of the\nLLMs trained by using adapters, our single-human motion generation achieves\ncomparable results to those diffusion models and other trained-from-scratch\ntransformer-based models. Additionally, we show that our approach is scalable\nand flexible, allowing easy extension to multi-human motion generation through\nautoregressive generation of single-human motions. Project page:\nhttps://knoxzhao.github.io/MotionLLM",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Qi Wu",
            "Yubo Zhao",
            "Yifan Wang",
            "Yu-Wing Tai",
            "Chi-Keung Tang"
        ],
        "published": "2024-05-27T09:57:51Z"
    },
    {
        "title": "Position: Foundation Agents as the Paradigm Shift for Decision Making",
        "link": "http://arxiv.org/abs/2405.17009v3",
        "abstract": "Decision making demands intricate interplay between perception, memory, and\nreasoning to discern optimal policies. Conventional approaches to decision\nmaking face challenges related to low sample efficiency and poor\ngeneralization. In contrast, foundation models in language and vision have\nshowcased rapid adaptation to diverse new tasks. Therefore, we advocate for the\nconstruction of foundation agents as a transformative shift in the learning\nparadigm of agents. This proposal is underpinned by the formulation of\nfoundation agents with their fundamental characteristics and challenges\nmotivated by the success of large language models (LLMs). Moreover, we specify\nthe roadmap of foundation agents from large interactive data collection or\ngeneration, to self-supervised pretraining and adaptation, and knowledge and\nvalue alignment with LLMs. Lastly, we pinpoint critical research questions\nderived from the formulation and delineate trends for foundation agents\nsupported by real-world use cases, addressing both technical and theoretical\naspects to propel the field towards a more comprehensive and impactful future.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Xiaoqian Liu",
            "Xingzhou Lou",
            "Jianbin Jiao",
            "Junge Zhang"
        ],
        "published": "2024-05-27T09:54:50Z"
    },
    {
        "title": "Quantum-safe Edge Applications: How to Secure Computation in Distributed\n  Computing Systems",
        "link": "http://arxiv.org/abs/2405.17008v1",
        "abstract": "The advent of distributed computing systems will offer great flexibility for\napplication workloads, while also imposing more attention to security, where\nthe future advent and adoption of quantum technology can introduce new security\nthreats. For this reason, the Multi-access Edge Computing (MEC) working group\nat ETSI has recently started delving into security aspects, especially\nmotivated by the upcoming reality of the MEC federation, which involves\nservices made of application instances belonging to different systems (thus,\ndifferent trust domains). On the other side, Quantum Key Distribution (QKD) can\nhelp strengthen the level of security by enabling the exchange of secure keys\nthrough an unconditionally secure protocol, e.g., to secure communication\nbetween REST clients and servers in distributed computing systems at the edge.\nIn this paper, we propose a technical solution to achieve this goal, building\non standard specifications, namely ETSI MEC and ETSI QKD, and discussing the\ngaps and limitations of current technology, which hamper full-fledged in-field\ndeployment and mass adoption. Furthermore, we provide our look-ahead view on\nthe future of secure distributed computing through the enticing option of\nfederating edge computing domains.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Claudio Cicconetti",
            "Dario Sabella",
            "Pietro Noviello",
            "Gennaro Davide Paduanelli"
        ],
        "published": "2024-05-27T09:53:59Z"
    },
    {
        "title": "Efficient Visual Fault Detection for Freight Train via Neural\n  Architecture Search with Data Volume Robustness",
        "link": "http://arxiv.org/abs/2405.17004v1",
        "abstract": "Deep learning-based fault detection methods have achieved significant\nsuccess. In visual fault detection of freight trains, there exists a large\ncharacteristic difference between inter-class components (scale variance) but\nintra-class on the contrary, which entails scale-awareness for detectors.\nMoreover, the design of task-specific networks heavily relies on human\nexpertise. As a consequence, neural architecture search (NAS) that automates\nthe model design process gains considerable attention because of its promising\nperformance. However, NAS is computationally intensive due to the large search\nspace and huge data volume. In this work, we propose an efficient NAS-based\nframework for visual fault detection of freight trains to search for the\ntask-specific detection head with capacities of multi-scale representation.\nFirst, we design a scale-aware search space for discovering an effective\nreceptive field in the head. Second, we explore the robustness of data volume\nto reduce search costs based on the specifically designed search space, and a\nnovel sharing strategy is proposed to reduce memory and further improve search\nefficiency. Extensive experimental results demonstrate the effectiveness of our\nmethod with data volume robustness, which achieves 46.8 and 47.9 mAP on the\nBottom View and Side View datasets, respectively. Our framework outperforms the\nstate-of-the-art approaches and linearly decreases the search costs with\nreduced data volumes.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Yang Zhang",
            "Mingying Li",
            "Huilin Pan",
            "Moyun Liu",
            "Yang Zhou"
        ],
        "published": "2024-05-27T09:47:49Z"
    },
    {
        "title": "Graph Condensation for Open-World Graph Learning",
        "link": "http://arxiv.org/abs/2405.17003v1",
        "abstract": "The burgeoning volume of graph data presents significant computational\nchallenges in training graph neural networks (GNNs), critically impeding their\nefficiency in various applications. To tackle this challenge, graph\ncondensation (GC) has emerged as a promising acceleration solution, focusing on\nthe synthesis of a compact yet representative graph for efficiently training\nGNNs while retaining performance. Despite the potential to promote scalable use\nof GNNs, existing GC methods are limited to aligning the condensed graph with\nmerely the observed static graph distribution. This limitation significantly\nrestricts the generalization capacity of condensed graphs, particularly in\nadapting to dynamic distribution changes. In real-world scenarios, however,\ngraphs are dynamic and constantly evolving, with new nodes and edges being\ncontinually integrated. Consequently, due to the limited generalization\ncapacity of condensed graphs, applications that employ GC for efficient GNN\ntraining end up with sub-optimal GNNs when confronted with evolving graph\nstructures and distributions in dynamic real-world situations. To overcome this\nissue, we propose open-world graph condensation (OpenGC), a robust GC framework\nthat integrates structure-aware distribution shift to simulate evolving graph\npatterns and exploit the temporal environments for invariance condensation.\nThis approach is designed to extract temporal invariant patterns from the\noriginal graph, thereby enhancing the generalization capabilities of the\ncondensed graph and, subsequently, the GNNs trained on it. Extensive\nexperiments on both real-world and synthetic evolving graphs demonstrate that\nOpenGC outperforms state-of-the-art (SOTA) GC methods in adapting to dynamic\nchanges in open-world graph environments.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Xinyi Gao",
            "Tong Chen",
            "Wentao Zhang",
            "Yayong Li",
            "Xiangguo Sun",
            "Hongzhi Yin"
        ],
        "published": "2024-05-27T09:47:09Z"
    },
    {
        "title": "UIT-DarkCow team at ImageCLEFmedical Caption 2024: Diagnostic Captioning\n  for Radiology Images Efficiency with Transformer Models",
        "link": "http://arxiv.org/abs/2405.17002v2",
        "abstract": "Purpose: This study focuses on the development of automated text generation\nfrom radiology images, termed diagnostic captioning, to assist medical\nprofessionals in reducing clinical errors and improving productivity. The aim\nis to provide tools that enhance report quality and efficiency, which can\nsignificantly impact both clinical practice and deep learning research in the\nbiomedical field. Methods: In our participation in the ImageCLEFmedical2024\nCaption evaluation campaign, we explored caption prediction tasks using\nadvanced Transformer-based models. We developed methods incorporating\nTransformer encoder-decoder and Query Transformer architectures. These models\nwere trained and evaluated to generate diagnostic captions from radiology\nimages. Results: Experimental evaluations demonstrated the effectiveness of our\nmodels, with the VisionDiagnostor-BioBART model achieving the highest BERTScore\nof 0.6267. This performance contributed to our team, DarkCow, achieving third\nplace on the leaderboard. Conclusion: Our diagnostic captioning models show\ngreat promise in aiding medical professionals by generating high-quality\nreports efficiently. This approach can facilitate better data processing and\nperformance optimization in medical imaging departments, ultimately benefiting\nhealthcare delivery.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Quan Van Nguyen",
            "Huy Quang Pham",
            "Dan Quang Tran",
            "Thang Kien-Bao Nguyen",
            "Nhat-Hao Nguyen-Dang",
            "Bao-Thien Nguyen-Tat"
        ],
        "published": "2024-05-27T09:46:09Z"
    },
    {
        "title": "Delta-modular ILP Problems of Bounded Co-dimension, Discrepancy, and\n  Convolution",
        "link": "http://arxiv.org/abs/2405.17001v1",
        "abstract": "For $k, n \\geq 0$, and $c \\in Z^n$, we consider ILP problems \\begin{gather*}\n  \\max\\bigl\\{ c^\\top x \\colon A x = b,\\, x \\in Z^n_{\\geq 0} \\bigr\\}\\text{ with\n$A \\in Z^{k \\times n}$, $rank(A) = k$, $b \\in Z^{k}$ and}\n  \\max\\bigl\\{ c^\\top x \\colon A x \\leq b,\\, x \\in Z^n \\bigr\\} \\text{ with $A\n\\in Z^{(n+k) \\times n}$, $rank(A) = n$, $b \\in Z^{n+k}$.} \\end{gather*} The\nfirst problem is called an \\emph{ILP problem in the standard form of the\ncodimension $k$}, and the second problem is called an \\emph{ILP problem in the\ncanonical form with $n+k$ constraints.} We show that, for any sufficiently\nlarge $\\Delta$, both problems can be solved with $$ 2^{O(k)} \\cdot (f_{k,d}\n\\cdot \\Delta)^2 / 2^{\\Omega\\bigl(\\sqrt{\\log(f_{k,d} \\cdot \\Delta)}\\bigr)} $$\noperations, where $\n  f_{k,d} = \\min \\Bigl\\{ k^{k/2},\n  \\bigl(\\log k \\cdot \\log (d + k)\\bigr)^{k/2}\n  \\Bigr\\} $, $d$ is the dimension of a corresponding polyhedron and $\\Delta$ is\nthe maximum absolute value of $rank(A) \\times rank(A)$ sub-determinants of $A$.\n  As our second main result, we show that the feasibility variants of both\nproblems can be solved with $$ 2^{O(k)} \\cdot f_{k,d} \\cdot \\Delta \\cdot\n\\log^3(f_{k,d} \\cdot \\Delta) $$ operations. The constant $f_{k,d}$ can be\nreplaced by other constant $g_{k,\\Delta} = \\bigl(\\log k \\cdot \\log (k\n\\Delta)\\bigr)^{k/2}$ that depends only on $k$ and $\\Delta$. Additionally, we\nconsider different partial cases with $k=0$ and $k=1$, which have interesting\napplications.\n  As a result of independent interest, we propose an\n$n^2/2^{\\Omega\\bigl(\\sqrt{\\log n}\\bigr)}$-time algorithm for the tropical\nconvolution problem on sequences, indexed by elements of a finite Abelian group\nof the order $n$. This result is obtained, reducing the above problem to the\nmatrix multiplication problem on a tropical semiring and using seminal\nalgorithm by R. Williams.",
        "subjects": [
            "cs.CC",
            "cs.DS",
            "math.AC",
            "math.OC"
        ],
        "authors": [
            "D. Gribanov",
            "D. Malyshev",
            "P. M. Pardalos"
        ],
        "published": "2024-05-27T09:45:06Z"
    },
    {
        "title": "Program Synthesis is $_3^0$-Complete",
        "link": "http://arxiv.org/abs/2405.16997v1",
        "abstract": "This paper considers program synthesis in the context of computational\nhardness, asking the question: How hard is it to determine whether a given\nsynthesis problem has a solution or not?\n  To answer this question, this paper studies program synthesis for a basic\nimperative, Turing-complete language IMP, for which this paper proves that\nprogram synthesis is $\\Sigma_3^0$-\\emph{complete} in the arithmetical\nhierarchy. The proof of this fact relies on a fully constructive encoding of\nprogram synthesis (which is typically formulated as a second-order query) as a\nfirst-order formula in the standard model of arithmetic (i.e., Peano\narithmetic). Constructing such a formula then allows us to reduce the decision\nproblem for COF (the set of functions which diverge only on a finite set of\ninputs), which is well-known to be a $\\Sigma_3^0$-complete problem, into the\nconstructed first-order representation of synthesis.\n  In addition to this main result, we also consider the hardness of variants of\nsynthesis problems, such as those introduced in previous work to make program\nsynthesis more tractable (e.g., synthesis over finite examples). To the best of\nour knowledge, this paper is the first to give a first-order characterization\nof program synthesis in general, and precisely define the computability of\nsynthesis problems and their variants.",
        "subjects": [
            "cs.LO",
            "cs.CC",
            "cs.PL"
        ],
        "authors": [
            "Jinwoo Kim"
        ],
        "published": "2024-05-27T09:43:10Z"
    },
    {
        "title": "Mitigating Noisy Correspondence by Geometrical Structure Consistency\n  Learning",
        "link": "http://arxiv.org/abs/2405.16996v1",
        "abstract": "Noisy correspondence that refers to mismatches in cross-modal data pairs, is\nprevalent on human-annotated or web-crawled datasets. Prior approaches to\nleverage such data mainly consider the application of uni-modal noisy label\nlearning without amending the impact on both cross-modal and intra-modal\ngeometrical structures in multimodal learning. Actually, we find that both\nstructures are effective to discriminate noisy correspondence through\nstructural differences when being well-established. Inspired by this\nobservation, we introduce a Geometrical Structure Consistency (GSC) method to\ninfer the true correspondence. Specifically, GSC ensures the preservation of\ngeometrical structures within and between modalities, allowing for the accurate\ndiscrimination of noisy samples based on structural differences. Utilizing\nthese inferred true correspondence labels, GSC refines the learning of\ngeometrical structures by filtering out the noisy samples. Experiments across\nfour cross-modal datasets confirm that GSC effectively identifies noisy samples\nand significantly outperforms the current leading methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zihua Zhao",
            "Mengxi Chen",
            "Tianjie Dai",
            "Jiangchao Yao",
            "Bo han",
            "Ya Zhang",
            "Yanfeng Wang"
        ],
        "published": "2024-05-27T09:42:52Z"
    },
    {
        "title": "Vision-and-Language Navigation Generative Pretrained Transformer",
        "link": "http://arxiv.org/abs/2405.16994v1",
        "abstract": "In the Vision-and-Language Navigation (VLN) field, agents are tasked with\nnavigating real-world scenes guided by linguistic instructions. Enabling the\nagent to adhere to instructions throughout the process of navigation represents\na significant challenge within the domain of VLN. To address this challenge,\ncommon approaches often rely on encoders to explicitly record past locations\nand actions, increasing model complexity and resource consumption. Our\nproposal, the Vision-and-Language Navigation Generative Pretrained Transformer\n(VLN-GPT), adopts a transformer decoder model (GPT2) to model trajectory\nsequence dependencies, bypassing the need for historical encoding modules. This\nmethod allows for direct historical information access through trajectory\nsequence, enhancing efficiency. Furthermore, our model separates the training\nprocess into offline pre-training with imitation learning and online\nfine-tuning with reinforcement learning. This distinction allows for more\nfocused training objectives and improved performance. Performance assessments\non the VLN dataset reveal that VLN-GPT surpasses complex state-of-the-art\nencoder-based models.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Wen Hanlin"
        ],
        "published": "2024-05-27T09:42:04Z"
    },
    {
        "title": "An experimental study of the response time in an edge-cloud continuum\n  with ClusterLink",
        "link": "http://arxiv.org/abs/2405.16988v1",
        "abstract": "In this paper, we conduct an experimental study to provide a general sense of\nthe application response time implications that inter-cluster communication\nexperiences at the edge at the example of a specific IoT-edge-cloud contiuum\nsolution from the EU Project ICOS called ClusterLink. We create an environment\nto emulate different networking topologies that include multiple cloud or edge\nsites scenarios, and conduct a set of tests to compare the application response\ntimes via ClusterLink to direct communications in relation to node distances\nand request/response payload size. Our results show that, in an edge context,\nClusterLink does not introduce a significant processing overhead to the\ncommunication for small payloads as compared to cloud. For higher payloads and\non comparably more aged consumer hardware, ClusterLink version 0.2 introduces\ncommunication overhead relative to the delay experienced on the link.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Marc Michalke",
            "Fin Gentzen",
            "Admela Jukan",
            "Kfir Toledo",
            "Etai Lev Ran"
        ],
        "published": "2024-05-27T09:33:25Z"
    },
    {
        "title": "Assessment of Left Atrium Motion Deformation Through Full Cardiac Cycle",
        "link": "http://arxiv.org/abs/2405.17518v1",
        "abstract": "Unlike Right Atrium (RA), Left Atrium (LA) presents distinctive challenges,\nincluding much thinner myocardial walls, complex and irregular morphology, as\nwell as diversity in individual's structure, making off-the-shelf methods\ndesigned for the Left Ventricle (LV) may not work in the context of the left\natrium. To overcome aforementioned challenges, we are the first to present\ncomprehensive technical workflow designed for 4D registration modeling to\nautomatically analyze LA motion using high-resolution 3D Cine MR images. We\nintegrate segmentation network and 4D registration process to precisely\ndelineate LA segmentation throughout the full cardiac cycle. Additionally, an\nimage 4D registration network is employed to extract LA displacement vector\nfields (DVFs). Our findings show the potential of proposed end to end framework\nin providing clinicians with novel regional biomarkers for left atrium motion\ntracking and deformation, carrying significant clinical implications.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Abdul Qayyum",
            "Moona Mazher",
            "Angela Lee",
            "Jose A Solis-Lemus",
            "Imran Razzak",
            "Steven A Niederer"
        ],
        "published": "2024-05-27T09:31:24Z"
    },
    {
        "title": "Optimal error bounds for the two point flux approximation finite volume\n  scheme",
        "link": "http://arxiv.org/abs/2405.16985v1",
        "abstract": "We consider a finite volume scheme with two-point flux approximation (TPFA)\nto approximate a Laplace problem when the solution exhibits no more regularity\nthan belonging to $H^1_0(\\Omega)$. We establish in this case some error bounds\nfor both the solution and the approximation of the gradient component\northogonal to the mesh faces. This estimate is optimal, in the sense that the\napproximation error has the same order as that of the sum of the interpolation\nerror and a conformity error. A numerical example illustrates the error\nestimate in the context of a solution with minimal regularity. This result is\nextended to evolution problems discretized via the implicit Euler scheme in an\nappendix.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Robert Eymard",
            "Thierry Gallout",
            "Raphaele Herbin"
        ],
        "published": "2024-05-27T09:31:15Z"
    },
    {
        "title": "Robust kernel-free quadratic surface twin support vector machine with\n  capped $L_1$-norm distance metric",
        "link": "http://arxiv.org/abs/2405.16982v1",
        "abstract": "Twin support vector machine (TSVM) is a very classical and practical\nclassifier for pattern classification. However, the traditional TSVM has two\nlimitations. Firstly, it uses the L_2-norm distance metric that leads to its\nsensitivity to outliers. Second, it needs to select the appropriate kernel\nfunction and the kernel parameters for nonlinear classification. To effectively\navoid these two problems, this paper proposes a robust capped L_1-norm\nkernel-free quadratic surface twin support vector machine (CL_1QTSVM). The\nstrengths of our model are briefly summarized as follows. 1) The robustness of\nour model is further improved by employing the capped L_1 norm distance metric.\n2) Our model is a kernel-free method that avoids the time-consuming process of\nselecting appropriate kernel functions and kernel parameters. 3) The\nintroduction of L_2-norm regularization term to improve the generalization\nability of the model. 4) To efficiently solve the proposed model, an iterative\nalgorithm is developed. 5) The convergence, time complexity and existence of\nlocally optimal solutions of the developed algorithms are further discussed.\nNumerical experiments on numerous types of datasets validate the classification\nperformance and robustness of the proposed model.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Qi Si",
            "Zhi Xia Yang"
        ],
        "published": "2024-05-27T09:23:52Z"
    },
    {
        "title": "Characterising Developer Sentiment in Software Components: An\n  Exploratory Study of Gentoo",
        "link": "http://arxiv.org/abs/2405.16981v1",
        "abstract": "Collaborative software development happens in teams, that cooperate on shared\nartefacts, and discuss development on online platforms. Due to the complexity\nof development and the variety of teams, software components often act as\neffective containers for parallel work and teams.\n  Past research has shown how communication between team members, especially in\nan open-source environment, can become extremely toxic, and lead to members\nleaving the development team. This has a direct effect on the evolution and\nmaintenance of the project in which the former members were active in.\n  The purpose of our study is two-fold: first, we propose an approach to\nevaluate, at a finer granularity, the positive and negative emotions in the\ncommunication between developers; and second, we aim to characterise a\nproject's development paths, or components, as more or less impacted by the\nemotions.\n  Our analysis evaluates single sentences rather than whole messages as the\nfinest granularity of communication. The previous study found that the high\npositivity or negativity at the sentence level may indirectly impact the writer\nhim/herself, or the reader. In this way, we could highlight specific paths of\nGentoo as the most affected by negative emotions, and show how negative\nemotions have evolved and changed along the same paths.\n  By joining the analysis of the mailing lists, from which we derive the\nsentiment of the developers, with the information derived from the development\nlogs, we obtained a longitudinal picture of how development paths have been\nhistorically affected by positive or negative emotions. Our study shows that,\nin recent years, negative emotions have generally decreased in the\ncommunication between Gentoo developers. We also show how file paths, as\ncollaborative software development artefacts, were more or less impacted by the\nemotions of the developers.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Tien Rahayu Tulili",
            "Ayushi Rastogi",
            "Andrea Capiluppi"
        ],
        "published": "2024-05-27T09:22:47Z"
    },
    {
        "title": "DSU-Net: Dynamic Snake U-Net for 2-D Seismic First Break Picking",
        "link": "http://arxiv.org/abs/2405.16980v1",
        "abstract": "In seismic exploration, identifying the first break (FB) is a critical\ncomponent in establishing subsurface velocity models. Various automatic picking\ntechniques based on deep neural networks have been developed to expedite this\nprocedure. The most popular class is using semantic segmentation networks to\npick on a shot gather called 2-dimensional (2-D) picking. Generally, 2-D\nsegmentation-based picking methods input an image of a shot gather, and output\na binary segmentation map, in which the maximum of each column is the location\nof FB. However, current designed segmentation networks is difficult to ensure\nthe horizontal continuity of the segmentation. Additionally, FB jumps also\nexist in some areas, and it is not easy for current networks to detect such\njumps. Therefore, it is important to pick as much as possible and ensure\nhorizontal continuity. To alleviate this problem, we propose a novel semantic\nsegmentation network for the 2-D seismic FB picking task, where we introduce\nthe dynamic snake convolution into U-Net and call the new segmentation network\ndynamic-snake U-Net (DSU-Net). Specifically, we develop original dynamic-snake\nconvolution (DSConv) in CV and propose a novel DSConv module, which can extract\nthe horizontal continuous feature in the shallow feature of the shot gather.\nMany experiments have shown that DSU-Net demonstrates higher accuracy and\nrobustness than the other 2-D segmentation-based models, achieving\nstate-of-the-art (SOTA) performance in 2-D seismic field surveys. Particularly,\nit can effectively detect FB jumps and better ensure the horizontal continuity\nof FB. In addition, the ablation experiment and the anti-noise experiment,\nrespectively, verify the optimal structure of the DSConv module and the\nrobustness of the picking.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Hongtao Wang",
            "Rongyu Feng",
            "Liangyi Wu",
            "Mutian Liu",
            "Yinuo Cui",
            "Chunxia Zhang",
            "Zhenbo Guo"
        ],
        "published": "2024-05-27T09:22:22Z"
    },
    {
        "title": "OSLO: One-Shot Label-Only Membership Inference Attacks",
        "link": "http://arxiv.org/abs/2405.16978v1",
        "abstract": "We introduce One-Shot Label-Only (OSLO) membership inference attacks (MIAs),\nwhich accurately infer a given sample's membership in a target model's training\nset with high precision using just \\emph{a single query}, where the target\nmodel only returns the predicted hard label. This is in contrast to\nstate-of-the-art label-only attacks which require $\\sim6000$ queries, yet get\nattack precisions lower than OSLO's. OSLO leverages transfer-based black-box\nadversarial attacks. The core idea is that a member sample exhibits more\nresistance to adversarial perturbations than a non-member. We compare OSLO\nagainst state-of-the-art label-only attacks and demonstrate that, despite\nrequiring only one query, our method significantly outperforms previous attacks\nin terms of precision and true positive rate (TPR) under the same false\npositive rates (FPR). For example, compared to previous label-only MIAs, OSLO\nachieves a TPR that is 7$\\times$ to 28$\\times$ stronger under a 0.1\\% FPR on\nCIFAR10 for a ResNet model. We evaluated multiple defense mechanisms against\nOSLO.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "authors": [
            "Yuefeng Peng",
            "Jaechul Roh",
            "Subhransu Maji",
            "Amir Houmansadr"
        ],
        "published": "2024-05-27T09:21:40Z"
    },
    {
        "title": "Collective Perception Datasets for Autonomous Driving: A Comprehensive\n  Review",
        "link": "http://arxiv.org/abs/2405.16973v1",
        "abstract": "To ensure safe operation of autonomous vehicles in complex urban\nenvironments, complete perception of the environment is necessary. However, due\nto environmental conditions, sensor limitations, and occlusions, this is not\nalways possible from a single point of view. To address this issue, collective\nperception is an effective method. Realistic and large-scale datasets are\nessential for training and evaluating collective perception methods. This paper\nprovides the first comprehensive technical review of collective perception\ndatasets in the context of autonomous driving. The survey analyzes existing V2V\nand V2X datasets, categorizing them based on different criteria such as sensor\nmodalities, environmental conditions, and scenario variety. The focus is on\ntheir applicability for the development of connected automated vehicles. This\nstudy aims to identify the key criteria of all datasets and to present their\nstrengths, weaknesses, and anomalies. Finally, this survey concludes by making\nrecommendations regarding which dataset is most suitable for collective 3D\nobject detection, tracking, and semantic segmentation.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Sven Teufel",
            "Jrg Gamerdinger",
            "Jan-Patrick Kirchner",
            "Georg Volk",
            "Oliver Bringmann"
        ],
        "published": "2024-05-27T09:08:55Z"
    },
    {
        "title": "A Correlation- and Mean-Aware Loss Function and Benchmarking Framework\n  to Improve GAN-based Tabular Data Synthesis",
        "link": "http://arxiv.org/abs/2405.16971v1",
        "abstract": "Advancements in science rely on data sharing. In medicine, where personal\ndata are often involved, synthetic tabular data generated by generative\nadversarial networks (GANs) offer a promising avenue. However, existing GANs\nstruggle to capture the complexities of real-world tabular data, which often\ncontain a mix of continuous and categorical variables with potential imbalances\nand dependencies. We propose a novel correlation- and mean-aware loss function\ndesigned to address these challenges as a regularizer for GANs. To ensure a\nrigorous evaluation, we establish a comprehensive benchmarking framework using\nten real-world datasets and eight established tabular GAN baselines. The\nproposed loss function demonstrates statistically significant improvements over\nexisting methods in capturing the true data distribution, significantly\nenhancing the quality of synthetic data generated with GANs. The benchmarking\nframework shows that the enhanced synthetic data quality leads to improved\nperformance in downstream machine learning (ML) tasks, ultimately paving the\nway for easier data sharing.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Minh H. Vu",
            "Daniel Edler",
            "Carl Wibom",
            "Tommy Lfstedt",
            "Beatrice Melin",
            "Martin Rosvall"
        ],
        "published": "2024-05-27T09:08:08Z"
    },
    {
        "title": "The Multi-Range Theory of Translation Quality Measurement: MQM scoring\n  models and Statistical Quality Control",
        "link": "http://arxiv.org/abs/2405.16969v2",
        "abstract": "The year 2024 marks the 10th anniversary of the Multidimensional Quality\nMetrics (MQM) framework for analytic translation quality evaluation. The MQM\nerror typology has been widely used by practitioners in the translation and\nlocalization industry and has served as the basis for many derivative projects.\nThe annual Conference on Machine Translation (WMT) shared tasks on both human\nand automatic translation quality evaluations used the MQM error typology.\n  The metric stands on two pillars: error typology and the scoring model. The\nscoring model calculates the quality score from annotation data, detailing how\nto convert error type and severity counts into numeric scores to determine if\nthe content meets specifications. Previously, only the raw scoring model had\nbeen published. This April, the MQM Council published the Linear Calibrated\nScoring Model, officially presented herein, along with the Non-Linear Scoring\nModel, which had not been published before.\n  This paper details the latest MQM developments and presents a universal\napproach to translation quality measurement across three sample size ranges. It\nalso explains why Statistical Quality Control should be used for very small\nsample sizes, starting from a single sentence.",
        "subjects": [
            "cs.CL",
            "stat.AP"
        ],
        "authors": [
            "Arle Lommel",
            "Serge Gladkoff",
            "Alan Melby",
            "Sue Ellen Wright",
            "Ingemar Strandvik",
            "Katerina Gasova",
            "Angelika Vaasa",
            "Andy Benzo",
            "Romina Marazzato Sparano",
            "Monica Foresi",
            "Johani Innis",
            "Lifeng Han",
            "Goran Nenadic"
        ],
        "published": "2024-05-27T09:06:24Z"
    },
    {
        "title": "Remote control system of a binary tree of switches -- II. balancing for\n  a perfect binary tree",
        "link": "http://arxiv.org/abs/2405.16968v1",
        "abstract": "We study a tree coloring model introduced by Guidon (2018), initially based\non an analogy with a remote control system of a rail yard, seen as switches on\na binary tree. For a given binary tree, we formalize the constraints on the\ncoloring, in particular the distribution of the nodes among colors. Following\nGuidon, we are interested in balanced colorings i.e. colorings which minimize\nthe maximum size of the subsets of the tree nodes distributed by color. With\nhis method, we present balanced colorings for trees of height up to 7. But his\nmethod seems difficult to apply for trees of greater height. Also we present\nanother method which gives solutions for arbitrarily large trees. We illustrate\nit with a balanced coloring for height 8. In the appendix, we give the exact\nformulas and the asymptotic behavior of the number of colorings as a function\nof the height of the tree.",
        "subjects": [
            "cs.DM"
        ],
        "authors": [
            "Olivier Golinelli"
        ],
        "published": "2024-05-27T09:06:17Z"
    },
    {
        "title": "WASH: Train your Ensemble with Communication-Efficient Weight Shuffling,\n  then Average",
        "link": "http://arxiv.org/abs/2405.17517v1",
        "abstract": "The performance of deep neural networks is enhanced by ensemble methods,\nwhich average the output of several models. However, this comes at an increased\ncost at inference. Weight averaging methods aim at balancing the generalization\nof ensembling and the inference speed of a single model by averaging the\nparameters of an ensemble of models. Yet, naive averaging results in poor\nperformance as models converge to different loss basins, and aligning the\nmodels to improve the performance of the average is challenging. Alternatively,\ninspired by distributed training, methods like DART and PAPA have been proposed\nto train several models in parallel such that they will end up in the same\nbasin, resulting in good averaging accuracy. However, these methods either\ncompromise ensembling accuracy or demand significant communication between\nmodels during training. In this paper, we introduce WASH, a novel distributed\nmethod for training model ensembles for weight averaging that achieves\nstate-of-the-art image classification accuracy. WASH maintains models within\nthe same basin by randomly shuffling a small percentage of weights during\ntraining, resulting in diverse models and lower communication costs compared to\nstandard parameter averaging methods.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "cs.NE",
            "stat.ML"
        ],
        "authors": [
            "Louis Fournier",
            "Adel Nabli",
            "Masih Aminbeidokhti",
            "Marco Pedersoli",
            "Eugene Belilovsky",
            "Edouard Oyallon"
        ],
        "published": "2024-05-27T09:02:57Z"
    },
    {
        "title": "Time Elastic Neural Networks",
        "link": "http://arxiv.org/abs/2405.17516v1",
        "abstract": "We introduce and detail an atypical neural network architecture, called time\nelastic neural network (teNN), for multivariate time series classification. The\nnovelty compared to classical neural network architecture is that it explicitly\nincorporates time warping ability, as well as a new way of considering\nattention. In addition, this architecture is capable of learning a dropout\nstrategy, thus optimizing its own architecture.Behind the design of this\narchitecture, our overall objective is threefold: firstly, we are aiming at\nimproving the accuracy of instance based classification approaches that shows\nquite good performances as far as enough training data is available. Secondly\nwe seek to reduce the computational complexity inherent to these methods to\nimprove their scalability. Ideally, we seek to find an acceptable balance\nbetween these first two criteria. And finally, we seek to enhance the\nexplainability of the decision provided by this kind of neural architecture.The\nexperiment demonstrates that the stochastic gradient descent implemented to\ntrain a teNN is quite effective. To the extent that the selection of some\ncritical meta-parameters is correct, convergence is generally smooth and\nfast.While maintaining good accuracy, we get a drastic gain in scalability by\nfirst reducing the required number of reference time series, i.e. the number of\nteNN cells required. Secondly, we demonstrate that, during the training\nprocess, the teNN succeeds in reducing the number of neurons required within\neach cell. Finally, we show that the analysis of the activation and attention\nmatrices as well as the reference time series after training provides relevant\ninformation to interpret and explain the classification results.The comparative\nstudy that we have carried out and which concerns around thirty diverse and\nmultivariate datasets shows that the teNN obtains results comparable to those\nof the state of the art, in particular similar to those of a network mixing\nLSTM and CNN architectures for example.",
        "subjects": [
            "cs.NE",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Pierre-Franois Marteau"
        ],
        "published": "2024-05-27T09:01:30Z"
    },
    {
        "title": "Dual-Delayed Asynchronous SGD for Arbitrarily Heterogeneous Data",
        "link": "http://arxiv.org/abs/2405.16966v1",
        "abstract": "We consider the distributed learning problem with data dispersed across\nmultiple workers under the orchestration of a central server. Asynchronous\nStochastic Gradient Descent (SGD) has been widely explored in such a setting to\nreduce the synchronization overhead associated with parallelization. However,\nthe performance of asynchronous SGD algorithms often depends on a bounded\ndissimilarity condition among the workers' local data, a condition that can\ndrastically affect their efficiency when the workers' data are highly\nheterogeneous. To overcome this limitation, we introduce the\n\\textit{dual-delayed asynchronous SGD (DuDe-ASGD)} algorithm designed to\nneutralize the adverse effects of data heterogeneity. DuDe-ASGD makes full use\nof stale stochastic gradients from all workers during asynchronous training,\nleading to two distinct time lags in the model parameters and data samples\nutilized in the server's iterations. Furthermore, by adopting an incremental\naggregation strategy, DuDe-ASGD maintains a per-iteration computational cost\nthat is on par with traditional asynchronous SGD algorithms. Our analysis\ndemonstrates that DuDe-ASGD achieves a near-minimax-optimal convergence rate\nfor smooth nonconvex problems, even when the data across workers are extremely\nheterogeneous. Numerical experiments indicate that DuDe-ASGD compares favorably\nwith existing asynchronous and synchronous SGD-based algorithms.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Xiaolu Wang",
            "Yuchang Sun",
            "Hoi-To Wai",
            "Jun Zhang"
        ],
        "published": "2024-05-27T09:00:30Z"
    },
    {
        "title": "Timeliness of Status Update System: The Effect of Parallel Transmission\n  Using Heterogeneous Updating Devices",
        "link": "http://arxiv.org/abs/2405.16965v1",
        "abstract": "Timely status updating is the premise of emerging interaction-based\napplications in the Internet of Things (IoT). Using redundant devices to update\nthe status of interest is a promising method to improve the timeliness of\ninformation. However, parallel status updating leads to out-of-order arrivals\nat the monitor, significantly challenging timeliness analysis. This work\nstudies the Age of Information (AoI) of a multi-queue status update system\nwhere multiple devices monitor the same physical process. Specifically, two\nsystems are considered: the Basic System, which only has type-1 devices that\nare ad hoc devices located close to the source, and the Hybrid System, which\ncontains additional type-2 devices that are infrastructure-based devices\nlocated in fixed points compared to the Basic System. Using the Stochastic\nHybrid Systems (SHS) framework, a mathematical model that combines discrete and\ncontinuous dynamics, we derive the expressions of the average AoI of the\nconsidered two systems in closed form. Numerical results verify the accuracy of\nthe analysis. It is shown that when the number and parameters of the type-1\ndevices/type-2 devices are fixed, the logarithm of average AoI will linearly\ndecrease with the logarithm of the total arrival rate of type-2 devices or that\nof the number of type-1 devices under specific condition. It has also been\ndemonstrated that the proposed systems can significantly outperform the FCFS\nM/M/N status update system.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Zhengchuan Chen",
            "Kang Lang",
            "Nikolaos Pappas",
            "Howard H. Yang",
            "Min Wang",
            "Zhong Tian",
            "Tony Q. S. Quek"
        ],
        "published": "2024-05-27T08:57:37Z"
    },
    {
        "title": "Exploring the LLM Journey from Cognition to Expression with Linear\n  Representations",
        "link": "http://arxiv.org/abs/2405.16964v1",
        "abstract": "This paper presents an in-depth examination of the evolution and interplay of\ncognitive and expressive capabilities in large language models (LLMs), with a\nspecific focus on Baichuan-7B and Baichuan-33B, an advanced bilingual (Chinese\nand English) LLM series. We define and explore the model's cognitive and\nexpressive capabilities through linear representations across three critical\nphases: Pretraining, Supervised Fine-Tuning (SFT), and Reinforcement Learning\nfrom Human Feedback (RLHF). Cognitive capability is defined as the quantity and\nquality of information conveyed by the neuron output vectors within the\nnetwork, similar to the neural signal processing in human cognition. Expressive\ncapability is defined as the model's capability to produce word-level output.\nOur findings unveil a sequential development pattern, where cognitive abilities\nare largely established during Pretraining, whereas expressive abilities\npredominantly advance during SFT and RLHF. Statistical analyses confirm a\nsignificant correlation between the two capabilities, suggesting that cognitive\ncapacity may limit expressive potential. The paper also explores the\ntheoretical underpinnings of these divergent developmental trajectories and\ntheir connection to the LLMs' architectural design. Moreover, we evaluate\nvarious optimization-independent strategies, such as few-shot learning and\nrepeated sampling, which bridge the gap between cognitive and expressive\ncapabilities. This research reveals the potential connection between the hidden\nspace and the output space, contributing valuable insights into the\ninterpretability and controllability of their training processes.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Yuzi Yan",
            "Jialian Li",
            "Yipin Zhang",
            "Dong Yan"
        ],
        "published": "2024-05-27T08:57:04Z"
    },
    {
        "title": "Blind Data Adaptation to tackle Covariate Shift in Operational\n  Steganalysis",
        "link": "http://arxiv.org/abs/2405.16961v2",
        "abstract": "The proliferation of image manipulation for unethical purposes poses\nsignificant challenges in social networks. One particularly concerning method\nis Image Steganography, allowing individuals to hide illegal information in\ndigital images without arousing suspicions. Such a technique pose severe\nsecurity risks, making it crucial to develop effective steganalysis methods\nenabling to detect manipulated images for clandestine communications. Although\nsignificant advancements have been achieved with machine learning models, a\ncritical issue remains: the disparity between the controlled datasets used to\ntrain steganalysis models against real-world datasets of forensic\npractitioners, undermining severely the practical effectiveness of standardized\nsteganalysis models. In this paper, we address this issue focusing on a\nrealistic scenario where practitioners lack crucial information about the\nlimited target set of images under analysis, including details about their\ndevelopment process and even whereas it contains manipulated images or not. By\nleveraging geometric alignment and distribution matching of source and target\nresiduals, we develop TADA (Target Alignment through Data Adaptation), a novel\nmethodology enabling to emulate sources aligned with specific targets in\nsteganalysis, which is also relevant for highly unbalanced targets. The\nemulator is represented by a light convolutional network trained to align\ndistributions of image residuals. Experimental validation demonstrates the\npotential of our strategy over traditional methods fighting covariate shift in\nsteganalysis.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CR",
            "cs.MM"
        ],
        "authors": [
            "Rony Abecidan",
            "Vincent Itier",
            "Jrmie Boulanger",
            "Patrick Bas",
            "Tom Pevn"
        ],
        "published": "2024-05-27T08:55:22Z"
    },
    {
        "title": "DCPI-Depth: Explicitly Infusing Dense Correspondence Prior to\n  Unsupervised Monocular Depth Estimation",
        "link": "http://arxiv.org/abs/2405.16960v1",
        "abstract": "There has been a recent surge of interest in learning to perceive depth from\nmonocular videos in an unsupervised fashion. A key challenge in this field is\nachieving robust and accurate depth estimation in challenging scenarios,\nparticularly in regions with weak textures or where dynamic objects are\npresent. This study makes three major contributions by delving deeply into\ndense correspondence priors to provide existing frameworks with explicit\ngeometric constraints. The first novelty is a contextual-geometric depth\nconsistency loss, which employs depth maps triangulated from dense\ncorrespondences based on estimated ego-motion to guide the learning of depth\nperception from contextual information, since explicitly triangulated depth\nmaps capture accurate relative distances among pixels. The second novelty\narises from the observation that there exists an explicit, deducible\nrelationship between optical flow divergence and depth gradient. A differential\nproperty correlation loss is, therefore, designed to refine depth estimation\nwith a specific emphasis on local variations. The third novelty is a\nbidirectional stream co-adjustment strategy that enhances the interaction\nbetween rigid and optical flows, encouraging the former towards more accurate\ncorrespondence and making the latter more adaptable across various scenarios\nunder the static scene hypotheses. DCPI-Depth, a framework that incorporates\nall these innovative components and couples two bidirectional and collaborative\nstreams, achieves state-of-the-art performance and generalizability across\nmultiple public datasets, outperforming all existing prior arts. Specifically,\nit demonstrates accurate depth estimation in texture-less and dynamic regions,\nand shows more reasonable smoothness.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Mengtan Zhang",
            "Yi Feng",
            "Qijun Chen",
            "Rui Fan"
        ],
        "published": "2024-05-27T08:55:17Z"
    },
    {
        "title": "A Machine Learning Approach to Analyze the Effects of Alzheimer's\n  Disease on Handwriting through Lognormal Features",
        "link": "http://dx.doi.org/10.1007/978-3-031-45461-5_8",
        "abstract": "Alzheimer's disease is one of the most incisive illnesses among the\nneurodegenerative ones, and it causes a progressive decline in cognitive\nabilities that, in the worst cases, becomes severe enough to interfere with\ndaily life. Currently, there is no cure, so an early diagnosis is strongly\nneeded to try and slow its progression through medical treatments. Handwriting\nanalysis is considered a potential tool for detecting and understanding certain\nneurological conditions, including Alzheimer's disease. While handwriting\nanalysis alone cannot provide a definitive diagnosis of Alzheimer's, it may\noffer some insights and be used for a comprehensive assessment. The\nSigma-lognormal model is conceived for movement analysis and can also be\napplied to handwriting. This model returns a set of lognormal parameters as\noutput, which forms the basis for the computation of novel and significant\nfeatures. This paper presents a machine learning approach applied to\nhandwriting features extracted through the sigma-lognormal model. The aim is to\ndevelop a support system to help doctors in the diagnosis and study of\nAlzheimer, evaluate the effectiveness of the extracted features and finally\nstudy the relation among them.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Tiziana D'Alessandro",
            "Cristina Carmona-Duarte",
            "Claudio De Stefano",
            "Moises Diaz",
            "Miguel A. Ferrer",
            "Francesco Fontanella"
        ],
        "published": "2024-05-27T08:54:11Z"
    },
    {
        "title": "Large Deviations of Gaussian Neural Networks with ReLU activation",
        "link": "http://arxiv.org/abs/2405.16958v1",
        "abstract": "We prove a large deviation principle for deep neural networks with Gaussian\nweights and (at most linearly growing) activation functions. This generalises\nearlier work, in which bounded and continuous activation functions were\nconsidered. In practice, linearly growing activation functions such as ReLU are\nmost commonly used. We furthermore simplify previous expressions for the rate\nfunction and a give power-series expansions for the ReLU case.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.PR",
            "60F10, 68T07"
        ],
        "authors": [
            "Quirin Vogel"
        ],
        "published": "2024-05-27T08:53:24Z"
    },
    {
        "title": "Functional Programming Paradigm of Python for Scientific Computation\n  Pipeline Integration",
        "link": "http://arxiv.org/abs/2405.16956v1",
        "abstract": "The advent of modern data processing has led to an increasing tendency\ntowards interdisciplinarity, which frequently involves the importation of\ndifferent technical approaches. Consequently, there is an urgent need for a\nunified data control system to facilitate the integration of varying libraries.\nThis integration is of profound significance in accelerating prototype\nverification, optimising algorithm performance and minimising maintenance\ncosts. This paper presents a novel functional programming (FP) paradigm based\non the Python architecture and associated suites in programming practice,\ndesigned for the integration of pipelines of different data mapping operations.\nIn particular, the solution is intended for the integration of scientific\ncomputation flows, which affords a robust yet flexible solution for the\naforementioned challenges.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CE",
            "cs.PL",
            "cs.SE"
        ],
        "authors": [
            "Chen Zhang",
            "Lecheng Jia",
            "Wei Zhang",
            "Ning Wen"
        ],
        "published": "2024-05-27T08:46:57Z"
    },
    {
        "title": "Convergence of SGD with momentum in the nonconvex case: A novel time\n  window-based analysis",
        "link": "http://arxiv.org/abs/2405.16954v1",
        "abstract": "We propose a novel time window-based analysis technique to investigate the\nconvergence behavior of the stochastic gradient descent method with momentum\n(SGDM) in nonconvex settings. Despite its popularity, the convergence behavior\nof SGDM remains less understood in nonconvex scenarios. This is primarily due\nto the absence of a sufficient descent property and challenges in controlling\nstochastic errors in an almost sure sense. To address these challenges, we\nstudy the behavior of SGDM over specific time windows, rather than examining\nthe descent of consecutive iterates as in traditional analyses. This time\nwindow-based approach simplifies the convergence analysis and enables us to\nestablish the first iterate convergence result for SGDM under the\nKurdyka-Lojasiewicz (KL) property. Based on the underlying KL exponent and the\nutilized step size scheme, we further characterize local convergence rates of\nSGDM.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "authors": [
            "Junwen Qiu",
            "Bohao Ma",
            "Andre Milzarek"
        ],
        "published": "2024-05-27T08:46:28Z"
    },
    {
        "title": "Evaluation of Resource-Efficient Crater Detectors on Embedded Systems",
        "link": "http://arxiv.org/abs/2405.16953v1",
        "abstract": "Real-time analysis of Martian craters is crucial for mission-critical\noperations, including safe landings and geological exploration. This work\nleverages the latest breakthroughs for on-the-edge crater detection aboard\nspacecraft. We rigorously benchmark several YOLO networks using a Mars craters\ndataset, analyzing their performance on embedded systems with a focus on\noptimization for low-power devices. We optimize this process for a new wave of\ncost-effective, commercial-off-the-shelf-based smaller satellites.\nImplementations on diverse platforms, including Google Coral Edge TPU, AMD\nVersal SoC VCK190, Nvidia Jetson Nano and Jetson AGX Orin, undergo a detailed\ntrade-off analysis. Our findings identify optimal network-device pairings,\nenhancing the feasibility of crater detection on resource-constrained hardware\nand setting a new precedent for efficient and resilient extraterrestrial\nimaging. Code at: https://github.com/billpsomas/mars_crater_detection.",
        "subjects": [
            "cs.CV",
            "cs.DC",
            "cs.PF"
        ],
        "authors": [
            "Simon Vellas",
            "Bill Psomas",
            "Kalliopi Karadima",
            "Dimitrios Danopoulos",
            "Alexandros Paterakis",
            "George Lentaris",
            "Dimitrios Soudris",
            "Konstantinos Karantzalos"
        ],
        "published": "2024-05-27T08:45:57Z"
    },
    {
        "title": "Fast ML-driven Analog Circuit Layout using Reinforcement Learning and\n  Steiner Trees",
        "link": "http://arxiv.org/abs/2405.16951v1",
        "abstract": "This paper presents an artificial intelligence driven methodology to reduce\nthe bottleneck often encountered in the analog ICs layout phase. We frame the\nfloorplanning problem as a Markov Decision Process and leverage reinforcement\nlearning for automatic placement generation under established topological\nconstraints. Consequently, we introduce Steiner tree-based methods for the\nglobal routing step and generate guiding paths to be used to connect every\ncircuit block. Finally, by integrating these solutions into a procedural\ngeneration framework, we present a unified pipeline that bridges the divide\nbetween circuit design and verification steps. Experimental results demonstrate\nthe efficacy in generating complete layouts, eventually reducing runtimes to\n1.5% compared to manual efforts.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Davide Basso",
            "Luca Bortolussi",
            "Mirjana Videnovic-Misic",
            "Husni Habal"
        ],
        "published": "2024-05-27T08:42:42Z"
    },
    {
        "title": "Zero-Shot Video Semantic Segmentation based on Pre-Trained Diffusion\n  Models",
        "link": "http://arxiv.org/abs/2405.16947v1",
        "abstract": "We introduce the first zero-shot approach for Video Semantic Segmentation\n(VSS) based on pre-trained diffusion models. A growing research direction\nattempts to employ diffusion models to perform downstream vision tasks by\nexploiting their deep understanding of image semantics. Yet, the majority of\nthese approaches have focused on image-related tasks like semantic\ncorrespondence and segmentation, with less emphasis on video tasks such as VSS.\nIdeally, diffusion-based image semantic segmentation approaches can be applied\nto videos in a frame-by-frame manner. However, we find their performance on\nvideos to be subpar due to the absence of any modeling of temporal information\ninherent in the video data. To this end, we tackle this problem and introduce a\nframework tailored for VSS based on pre-trained image and video diffusion\nmodels. We propose building a scene context model based on the diffusion\nfeatures, where the model is autoregressively updated to adapt to scene\nchanges. This context model predicts per-frame coarse segmentation maps that\nare temporally consistent. To refine these maps further, we propose a\ncorrespondence-based refinement strategy that aggregates predictions\ntemporally, resulting in more confident predictions. Finally, we introduce a\nmasked modulation approach to upsample the coarse maps to the full resolution\nat a high quality. Experiments show that our proposed approach outperforms\nexisting zero-shot image semantic segmentation approaches significantly on\nvarious VSS benchmarks without any training or fine-tuning. Moreover, it rivals\nsupervised VSS approaches on the VSPW dataset despite not being explicitly\ntrained for VSS.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Qian Wang",
            "Abdelrahman Eldesokey",
            "Mohit Mendiratta",
            "Fangneng Zhan",
            "Adam Kortylewski",
            "Christian Theobalt",
            "Peter Wonka"
        ],
        "published": "2024-05-27T08:39:38Z"
    },
    {
        "title": "Biological Neurons Compete with Deep Reinforcement Learning in Sample\n  Efficiency in a Simulated Gameworld",
        "link": "http://arxiv.org/abs/2405.16946v1",
        "abstract": "How do biological systems and machine learning algorithms compare in the\nnumber of samples required to show significant improvements in completing a\ntask? We compared the learning efficiency of in vitro biological neural\nnetworks to the state-of-the-art deep reinforcement learning (RL) algorithms in\na simplified simulation of the game `Pong'. Using DishBrain, a system that\nembodies in vitro neural networks with in silico computation using a\nhigh-density multi-electrode array, we contrasted the learning rate and the\nperformance of these biological systems against time-matched learning from\nthree state-of-the-art deep RL algorithms (i.e., DQN, A2C, and PPO) in the same\ngame environment. This allowed a meaningful comparison between biological\nneural systems and deep RL. We find that when samples are limited to a\nreal-world time course, even these very simple biological cultures outperformed\ndeep RL algorithms across various game performance characteristics, implying a\nhigher sample efficiency. Ultimately, even when tested across multiple types of\ninformation input to assess the impact of higher dimensional data input,\nbiological neurons showcased faster learning than all deep reinforcement\nlearning agents.",
        "subjects": [
            "q-bio.NC",
            "cs.AI"
        ],
        "authors": [
            "Moein Khajehnejad",
            "Forough Habibollahi",
            "Aswin Paul",
            "Adeel Razi",
            "Brett J. Kagan"
        ],
        "published": "2024-05-27T08:38:17Z"
    },
    {
        "title": "PASTA: Pathology-Aware MRI to PET Cross-Modal Translation with Diffusion\n  Models",
        "link": "http://arxiv.org/abs/2405.16942v1",
        "abstract": "Positron emission tomography (PET) is a well-established functional imaging\ntechnique for diagnosing brain disorders. However, PET's high costs and\nradiation exposure limit its widespread use. In contrast, magnetic resonance\nimaging (MRI) does not have these limitations. Although it also captures\nneurodegenerative changes, MRI is a less sensitive diagnostic tool than PET. To\nclose this gap, we aim to generate synthetic PET from MRI. Herewith, we\nintroduce PASTA, a novel pathology-aware image translation framework based on\nconditional diffusion models. Compared to the state-of-the-art methods, PASTA\nexcels in preserving both structural and pathological details in the target\nmodality, which is achieved through its highly interactive dual-arm\narchitecture and multi-modal condition integration. A cycle exchange\nconsistency and volumetric generation strategy elevate PASTA's capability to\nproduce high-quality 3D PET scans. Our qualitative and quantitative results\nconfirm that the synthesized PET scans from PASTA not only reach the best\nquantitative scores but also preserve the pathology correctly. For Alzheimer's\nclassification, the performance of synthesized scans improves over MRI by 4%,\nalmost reaching the performance of actual PET. Code is available at\nhttps://github.com/ai-med/PASTA.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Yitong Li",
            "Igor Yakushev",
            "Dennis M. Hedderich",
            "Christian Wachinger"
        ],
        "published": "2024-05-27T08:33:24Z"
    },
    {
        "title": "AbstractBeam: Enhancing Bottom-Up Program Synthesis using Library\n  Learning",
        "link": "http://arxiv.org/abs/2405.17514v1",
        "abstract": "LambdaBeam is a state-of-the-art execution-guided algorithm for program\nsynthesis that incorporates higher-order functions, lambda functions, and\niterative loops into the Domain-Specific Language (DSL). LambdaBeam generates\nevery program from the start. Yet, many program blocks or subprograms occur\nfrequently in a given domain, e.g., loops to traverse a list. Thus, repeating\nprograms can be used to enhance the synthesis algorithm. However, LambdaBeam\nfails to leverage this potential. For this purpose, we introduce AbstractBeam:\nA novel program synthesis framework that employs Library Learning to identify\nsuch program repetitions, integrates them into the DSL, and thus utilizes their\npotential to boost LambdaBeam's synthesis algorithm. Our experimental\nevaluations demonstrate that AbstractBeam significantly improves LambdaBeam's\nperformance in the LambdaBeam integer list manipulation domain. Additionally,\nAbstractBeam's program generation is more efficient compared to LambdaBeam's\nsynthesis. Finally, our findings indicate that Library Learning is effective in\ndomains not specifically crafted to highlight its benefits.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.PL"
        ],
        "authors": [
            "Janis Zenkner",
            "Lukas Dierkes",
            "Tobias Sesterhenn",
            "Chrisitan Bartelt"
        ],
        "published": "2024-05-27T08:31:12Z"
    },
    {
        "title": "Adversarial Attacks on Both Face Recognition and Face Anti-spoofing\n  Models",
        "link": "http://arxiv.org/abs/2405.16940v1",
        "abstract": "Adversarial attacks on Face Recognition (FR) systems have proven highly\neffective in compromising pure FR models, yet adversarial examples may be\nineffective to the complete FR systems as Face Anti-Spoofing (FAS) models are\noften incorporated and can detect a significant number of them. To address this\nunder-explored and essential problem, we propose a novel setting of\nadversarially attacking both FR and FAS models simultaneously, aiming to\nenhance the practicability of adversarial attacks on FR systems. In particular,\nwe introduce a new attack method, namely Style-aligned Distribution Biasing\n(SDB), to improve the capacity of black-box attacks on both FR and FAS models.\nSpecifically, our SDB framework consists of three key components. Firstly, to\nenhance the transferability of FAS models, we design a Distribution-aware Score\nBiasing module to optimize adversarial face examples away from the distribution\nof spoof images utilizing scores. Secondly, to mitigate the substantial style\ndifferences between live images and adversarial examples initialized with spoof\nimages, we introduce an Instance Style Alignment module that aligns the style\nof adversarial examples with live images. In addition, to alleviate the\nconflicts between the gradients of FR and FAS models, we propose a Gradient\nConsistency Maintenance module to minimize disparities between the gradients\nusing Hessian approximation. Extensive experiments showcase the superiority of\nour proposed attack method to state-of-the-art adversarial attacks.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Fengfan Zhou",
            "Qianyu Zhou",
            "Xiangtai Li",
            "Xuequan Lu",
            "Lizhuang Ma",
            "Hefei Ling"
        ],
        "published": "2024-05-27T08:30:29Z"
    },
    {
        "title": "Remote control system of a binary tree of switches -- I. constraints and\n  inequalities",
        "link": "http://arxiv.org/abs/2405.16938v1",
        "abstract": "We study a tree coloring model introduced by Guidon (2018), initially based\non an analogy with a remote control system of a rail yard, seen as a switch\ntree. For a given rooted tree, we formalize the constraints on the coloring, in\nparticular on the minimum number of colors, and on the distribution of the\nnodes among colors. We show that the sequence $(a_1,a_2,a_3,\\cdots)$, where\n$a_i$ denotes the number of nodes with color $i$, satisfies a set of\ninequalities which only involve the sequence $(n_0,n_1,n_2,\\cdots)$ where $n_i$\ndenotes the number of nodes with height $i$. By coloring the nodes according to\ntheir depth, we deduce that these inequalities also apply to the sequence\n$(d_0,d_1,d_2,\\cdots)$ where $d_i$ denotes the number of nodes with depth $i$.",
        "subjects": [
            "cs.DM"
        ],
        "authors": [
            "Olivier Golinelli"
        ],
        "published": "2024-05-27T08:29:07Z"
    },
    {
        "title": "Construction of birational trilinear volumes via tensor rank criteria",
        "link": "http://arxiv.org/abs/2405.16936v1",
        "abstract": "We provide effective methods to construct and manipulate trilinear birational\nmaps $\\phi:(\\mathbb{P}^1)^3\\dashrightarrow \\mathbb{P}^3$ by establishing a\nnovel connection between birationality and tensor rank. These yield four\nfamilies of nonlinear birational transformations between 3D spaces that can be\noperated with enough flexibility for applications in computer-aided geometric\ndesign. More precisely, we describe the geometric constraints on the defining\ncontrol points of the map that are necessary for birationality, and present\nconstructions for such configurations. For adequately constrained control\npoints, we prove that birationality is achieved if and only if a certain\n$2\\times 2\\times 2$ tensor has rank one. As a corollary, we prove that the\nlocus of weights that ensure birationality is\n$\\mathbb{P}^1\\times\\mathbb{P}^1\\times\\mathbb{P}^1$. Additionally, we provide\nformulas for the inverse $\\phi^{-1}$ as well as the explicit defining equations\nof the irreducible components of the base loci. Finally, we introduce a notion\nof \"distance to birationality\" for trilinear rational maps, and explain how to\ncontinuously deform birational maps.",
        "subjects": [
            "math.AG",
            "cs.SC",
            "14E05, 14Q99, 65D17",
            "G.0; I.1; I.6; J.6"
        ],
        "authors": [
            "Laurent Bus",
            "Pablo Mazn"
        ],
        "published": "2024-05-27T08:28:09Z"
    },
    {
        "title": "Do Vision-Language Transformers Exhibit Visual Commonsense? An Empirical\n  Study of VCR",
        "link": "http://arxiv.org/abs/2405.16934v1",
        "abstract": "Visual Commonsense Reasoning (VCR) calls for explanatory reasoning behind\nquestion answering over visual scenes. To achieve this goal, a model is\nrequired to provide an acceptable rationale as the reason for the predicted\nanswers. Progress on the benchmark dataset stems largely from the recent\nadvancement of Vision-Language Transformers (VL Transformers). These models are\nfirst pre-trained on some generic large-scale vision-text datasets, and then\nthe learned representations are transferred to the downstream VCR task. Despite\ntheir attractive performance, this paper posits that the VL Transformers do not\nexhibit visual commonsense, which is the key to VCR. In particular, our\nempirical results pinpoint several shortcomings of existing VL Transformers:\nsmall gains from pre-training, unexpected language bias, limited model\narchitecture for the two inseparable sub-tasks, and neglect of the important\nobject-tag correlation. With these findings, we tentatively suggest some future\ndirections from the aspect of dataset, evaluation metric, and training tricks.\nWe believe this work could make researchers revisit the intuition and goals of\nVCR, and thus help tackle the remaining challenges in visual reasoning.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhenyang Li",
            "Yangyang Guo",
            "Kejie Wang",
            "Xiaolin Chen",
            "Liqiang Nie",
            "Mohan Kankanhalli"
        ],
        "published": "2024-05-27T08:26:58Z"
    },
    {
        "title": "Empowering Large Language Models to Set up a Knowledge Retrieval Indexer\n  via Self-Learning",
        "link": "http://arxiv.org/abs/2405.16933v1",
        "abstract": "Retrieval-Augmented Generation (RAG) offers a cost-effective approach to\ninjecting real-time knowledge into large language models (LLMs). Nevertheless,\nconstructing and validating high-quality knowledge repositories require\nconsiderable effort. We propose a pre-retrieval framework named Pseudo-Graph\nRetrieval-Augmented Generation (PG-RAG), which conceptualizes LLMs as students\nby providing them with abundant raw reading materials and encouraging them to\nengage in autonomous reading to record factual information in their own words.\nThe resulting concise, well-organized mental indices are interconnected through\ncommon topics or complementary facts to form a pseudo-graph database. During\nthe retrieval phase, PG-RAG mimics the human behavior in flipping through\nnotes, identifying fact paths and subsequently exploring the related contexts.\nAdhering to the principle of the path taken by many is the best, it integrates\nhighly corroborated fact paths to provide a structured and refined sub-graph\nassisting LLMs. We validated PG-RAG on three specialized question-answering\ndatasets. In single-document tasks, PG-RAG significantly outperformed the\ncurrent best baseline, KGP-LLaMA, across all key evaluation metrics, with an\naverage overall performance improvement of 11.6%. Specifically, its BLEU score\nincreased by approximately 14.3%, and the QE-F1 metric improved by 23.7%. In\nmulti-document scenarios, the average metrics of PG-RAG were at least 2.35%\nhigher than the best baseline. Notably, the BLEU score and QE-F1 metric showed\nstable improvements of around 7.55% and 12.75%, respectively. Our code:\nhttps://github.com/IAAR-Shanghai/PGRAG.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "authors": [
            "Xun Liang",
            "Simin Niu",
            "Zhiyu li",
            "Sensen Zhang",
            "Shichao Song",
            "Hanyu Wang",
            "Jiawei Yang",
            "Feiyu Xiong",
            "Bo Tang",
            "Chenyang Xi"
        ],
        "published": "2024-05-27T08:26:45Z"
    },
    {
        "title": "CudaSIFT-SLAM: multiple-map visual SLAM for full procedure mapping in\n  real human endoscopy",
        "link": "http://arxiv.org/abs/2405.16932v1",
        "abstract": "Monocular visual simultaneous localization and mapping (V-SLAM) is nowadays\nan irreplaceable tool in mobile robotics and augmented reality, where it\nperforms robustly. However, human colonoscopies pose formidable challenges like\nocclusions, blur, light changes, lack of texture, deformation, water jets or\ntool interaction, which result in very frequent tracking losses. ORB-SLAM3, the\ntop performing multiple-map V-SLAM, is unable to recover from them by merging\nsub-maps or relocalizing the camera, due to the poor performance of its place\nrecognition algorithm based on ORB features and DBoW2 bag-of-words.\n  We present CudaSIFT-SLAM, the first V-SLAM system able to process complete\nhuman colonoscopies in real-time. To overcome the limitations of ORB-SLAM3, we\nuse SIFT instead of ORB features and replace the DBoW2 direct index with the\nmore computationally demanding brute-force matching, being able to successfully\nmatch images separated in time for relocation and map merging. Real-time\nperformance is achieved thanks to CudaSIFT, a GPU implementation for SIFT\nextraction and brute-force matching.\n  We benchmark our system in the C3VD phantom colon dataset, and in a full real\ncolonoscopy from the Endomapper dataset, demonstrating the capabilities to\nmerge sub-maps and relocate in them, obtaining significantly longer sub-maps.\nOur system successfully maps in real-time 88 % of the frames in the C3VD\ndataset. In a real screening colonoscopy, despite the much higher prevalence of\noccluded and blurred frames, the mapping coverage is 53 % in carefully explored\nareas and 38 % in the full sequence, a 70 % improvement over ORB-SLAM3.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "I.4.9"
        ],
        "authors": [
            "Richard Elvira",
            "Juan D. Tards",
            "Jos M. M. Montiel"
        ],
        "published": "2024-05-27T08:26:19Z"
    },
    {
        "title": "From Obstacle to Opportunity: Enhancing Semi-supervised Learning with\n  Synthetic Data",
        "link": "http://arxiv.org/abs/2405.16930v1",
        "abstract": "Semi-supervised learning (SSL) can utilize unlabeled data to enhance model\nperformance. In recent years, with increasingly powerful generative models\nbecoming available, a large number of synthetic images have been uploaded to\npublic image sets. Therefore, when collecting unlabeled data from these\nsources, the inclusion of synthetic images is inevitable. This prompts us to\nconsider the impact of unlabeled data mixed with real and synthetic images on\nSSL. In this paper, we set up a new task, Real and Synthetic hybrid SSL\n(RS-SSL), to investigate this problem. We discover that current SSL methods are\nunable to fully utilize synthetic data and are sometimes negatively affected.\nThen, by analyzing the issues caused by synthetic images, we propose a new SSL\nmethod, RSMatch, to tackle the RS-SSL problem. Extensive experimental results\nshow that RSMatch can better utilize the synthetic data in unlabeled images to\nimprove the SSL performance. The effectiveness is further verified through\nablation studies and visualization.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zerun Wang",
            "Jiafeng Mao",
            "Liuyu Xiang",
            "Toshihiko Yamasaki"
        ],
        "published": "2024-05-27T08:24:42Z"
    },
    {
        "title": "Uncertainty Management in the Construction of Knowledge Graphs: a Survey",
        "link": "http://arxiv.org/abs/2405.16929v1",
        "abstract": "Knowledge Graphs (KGs) are a major asset for companies thanks to their great\nflexibility in data representation and their numerous applications, e.g.,\nvocabulary sharing, Q/A or recommendation systems. To build a KG it is a common\npractice to rely on automatic methods for extracting knowledge from various\nheterogeneous sources. But in a noisy and uncertain world, knowledge may not be\nreliable and conflicts between data sources may occur. Integrating unreliable\ndata would directly impact the use of the KG, therefore such conflicts must be\nresolved. This could be done manually by selecting the best data to integrate.\nThis first approach is highly accurate, but costly and time-consuming. That is\nwhy recent efforts focus on automatic approaches, which represents a\nchallenging task since it requires handling the uncertainty of extracted\nknowledge throughout its integration into the KG. We survey state-of-the-art\napproaches in this direction and present constructions of both open and\nenterprise KGs and how their quality is maintained. We then describe different\nknowledge extraction methods, introducing additional uncertainty. We also\ndiscuss downstream tasks after knowledge acquisition, including KG completion\nusing embedding models, knowledge alignment, and knowledge fusion in order to\naddress the problem of knowledge uncertainty in KG construction. We conclude\nwith a discussion on the remaining challenges and perspectives when\nconstructing a KG taking into account uncertainty.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Lucas Jarnac",
            "Yoan Chabot",
            "Miguel Couceiro"
        ],
        "published": "2024-05-27T08:22:52Z"
    },
    {
        "title": "TopoLa: a novel embedding framework for understanding complex networks",
        "link": "http://arxiv.org/abs/2405.16928v1",
        "abstract": "Complex networks, which are the abstractions of many real-world systems,\npresent a persistent challenge across disciplines for people to decipher their\nunderlying information. Recently, hyperbolic geometry of latent spaces has\ngained traction in network analysis, due to its ability to preserve certain\nlocal intrinsic properties of the nodes. In this study, we explore the problem\nfrom a much broader perspective: understanding the impact of nodes' global\ntopological structures on latent space placements. Our investigations reveal a\ndirect correlation between the topological structure of nodes and their\npositioning within the latent space. Building on this deep and strong\nconnection between node distance and network topology, we propose a novel\nembedding framework called Topology-encoded Latent Hyperbolic Geometry (TopoLa)\nfor analyzing complex networks. With the encoded topological information in the\nlatent space, TopoLa is capable of enhancing both conventional and low-rank\nnetworks, using the singular value gap to clarify the mathematical principles\nbehind this enhancement. Meanwhile, we show that the equipped TopoLa distance\ncan also help augment pivotal deep learning models encompassing knowledge\ndistillation and contrastive learning.",
        "subjects": [
            "cs.SI",
            "cs.GT"
        ],
        "authors": [
            "Kai Zheng",
            "Qilong Feng",
            "Yaohang Li",
            "Qichang Zhao",
            "Jinhui Xu",
            "Jianxin Wang"
        ],
        "published": "2024-05-27T08:22:32Z"
    },
    {
        "title": "Is Cambodia the World's Largest Cashew Producer?",
        "link": "http://arxiv.org/abs/2405.16926v1",
        "abstract": "Cambodia's agricultural landscape is rapidly transforming, particularly in\nthe cashew sector. Despite the country's rapid emergence and ambition to become\nthe largest cashew producer, comprehensive data on plantation areas and the\nenvironmental impacts of this expansion are lacking. This study addresses the\ngap in detailed land use data for cashew plantations in Cambodia and assesses\nthe implications of agricultural advancements. We collected over 80,000\ntraining polygons across Cambodia to train a convolutional neural network using\nhigh-resolution optical and SAR satellite data for precise cashew plantation\nmapping. Our findings indicate that Cambodia ranks among the top five in terms\nof cultivated area and the top three in global cashew production, driven by\nhigh yields. Significant cultivated areas are located in Kampong Thom, Kratie,\nand Ratanak Kiri provinces. Balancing rapid agricultural expansion with\nenvironmental stewardship, particularly forest conservation, is crucial.\nCambodia's cashew production is poised for further growth, driven by\nhigh-yielding trees and premium nuts. However, sustainable expansion requires\nintegrating agricultural practices with economic and environmental strategies\nto enhance local value and protect forested areas. Advanced mapping\ntechnologies offer comprehensive tools to support these objectives and ensure\nthe sustainable development of Cambodia's cashew industry.",
        "subjects": [
            "cs.CY",
            "68T07",
            "I.2.6; I.5.1"
        ],
        "authors": [
            "Veasna Chaya",
            "Ate Poortinga",
            "Keo Nimol",
            "Se Sokleap",
            "Mon Sophorn",
            "Phy Chhin",
            "Andrea McMahon",
            "Andrea Puzzi Nicolau",
            "Karis Tenneson",
            "David Saah"
        ],
        "published": "2024-05-27T08:20:50Z"
    },
    {
        "title": "OED: Towards One-stage End-to-End Dynamic Scene Graph Generation",
        "link": "http://arxiv.org/abs/2405.16925v1",
        "abstract": "Dynamic Scene Graph Generation (DSGG) focuses on identifying visual\nrelationships within the spatial-temporal domain of videos. Conventional\napproaches often employ multi-stage pipelines, which typically consist of\nobject detection, temporal association, and multi-relation classification.\nHowever, these methods exhibit inherent limitations due to the separation of\nmultiple stages, and independent optimization of these sub-problems may yield\nsub-optimal solutions. To remedy these limitations, we propose a one-stage\nend-to-end framework, termed OED, which streamlines the DSGG pipeline. This\nframework reformulates the task as a set prediction problem and leverages\npair-wise features to represent each subject-object pair within the scene\ngraph. Moreover, another challenge of DSGG is capturing temporal dependencies,\nwe introduce a Progressively Refined Module (PRM) for aggregating temporal\ncontext without the constraints of additional trackers or handcrafted\ntrajectories, enabling end-to-end optimization of the network. Extensive\nexperiments conducted on the Action Genome benchmark demonstrate the\neffectiveness of our design. The code and models are available at\n\\url{https://github.com/guanw-pku/OED}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Guan Wang",
            "Zhimin Li",
            "Qingchao Chen",
            "Yang Liu"
        ],
        "published": "2024-05-27T08:18:41Z"
    },
    {
        "title": "Demystifying amortized causal discovery with transformers",
        "link": "http://arxiv.org/abs/2405.16924v1",
        "abstract": "Supervised learning approaches for causal discovery from observational data\noften achieve competitive performance despite seemingly avoiding explicit\nassumptions that traditional methods make for identifiability. In this work, we\ninvestigate CSIvA (Ke et al., 2023), a transformer-based model promising to\ntrain on synthetic data and transfer to real data. First, we bridge the gap\nwith existing identifiability theory and show that constraints on the training\ndata distribution implicitly define a prior on the test observations.\nConsistent with classical approaches, good performance is achieved when we have\na good prior on the test data, and the underlying model is identifiable. At the\nsame time, we find new trade-offs. Training on datasets generated from\ndifferent classes of causal models, unambiguously identifiable in isolation,\nimproves the test generalization. Performance is still guaranteed, as the\nambiguous cases resulting from the mixture of identifiable causal models are\nunlikely to occur (which we formally prove). Overall, our study finds that\namortized causal discovery still needs to obey identifiability theory, but it\nalso differs from classical methods in how the assumptions are formulated,\ntrading more reliance on assumptions on the noise type for fewer hypotheses on\nthe mechanisms.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Francesco Montagna",
            "Max Cairney-Leeming",
            "Dhanya Sridhar",
            "Francesco Locatello"
        ],
        "published": "2024-05-27T08:17:49Z"
    },
    {
        "title": "SA-GS: Semantic-Aware Gaussian Splatting for Large Scene Reconstruction\n  with Geometry Constrain",
        "link": "http://arxiv.org/abs/2405.16923v2",
        "abstract": "With the emergence of Gaussian Splats, recent efforts have focused on\nlarge-scale scene geometric reconstruction. However, most of these efforts\neither concentrate on memory reduction or spatial space division, neglecting\ninformation in the semantic space. In this paper, we propose a novel method,\nnamed SA-GS, for fine-grained 3D geometry reconstruction using semantic-aware\n3D Gaussian Splats. Specifically, we leverage prior information stored in large\nvision models such as SAM and DINO to generate semantic masks. We then\nintroduce a geometric complexity measurement function to serve as soft\nregularization, guiding the shape of each Gaussian Splat within specific\nsemantic areas. Additionally, we present a method that estimates the expected\nnumber of Gaussian Splats in different semantic areas, effectively providing a\nlower bound for Gaussian Splats in these areas. Subsequently, we extract the\npoint cloud using a novel probability density-based extraction method,\ntransforming Gaussian Splats into a point cloud crucial for downstream tasks.\nOur method also offers the potential for detailed semantic inquiries while\nmaintaining high image-based reconstruction results. We provide extensive\nexperiments on publicly available large-scale scene reconstruction datasets\nwith highly accurate point clouds as ground truth and our novel dataset. Our\nresults demonstrate the superiority of our method over current state-of-the-art\nGaussian Splats reconstruction methods by a significant margin in terms of\ngeometric-based measurement metrics. Code and additional results will soon be\navailable on our project page.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Butian Xiong",
            "Xiaoyu Ye",
            "Tze Ho Elden Tse",
            "Kai Han",
            "Shuguang Cui",
            "Zhen Li"
        ],
        "published": "2024-05-27T08:15:10Z"
    },
    {
        "title": "Theories of synaptic memory consolidation and intelligent plasticity for\n  continual learning",
        "link": "http://arxiv.org/abs/2405.16922v1",
        "abstract": "Humans and animals learn throughout life. Such continual learning is crucial\nfor intelligence. In this chapter, we examine the pivotal role plasticity\nmechanisms with complex internal synaptic dynamics could play in enabling this\nability in neural networks. By surveying theoretical research, we highlight two\nfundamental enablers for continual learning. First, synaptic plasticity\nmechanisms must maintain and evolve an internal state over several behaviorally\nrelevant timescales. Second, plasticity algorithms must leverage the internal\nstate to intelligently regulate plasticity at individual synapses to facilitate\nthe seamless integration of new memories while avoiding detrimental\ninterference with existing ones. Our chapter covers successful applications of\nthese principles to deep neural networks and underscores the significance of\nsynaptic metaplasticity in sustaining continual learning capabilities. Finally,\nwe outline avenues for further research to understand the brain's superb\ncontinual learning abilities and harness similar mechanisms for artificial\nintelligence systems.",
        "subjects": [
            "q-bio.NC",
            "cs.AI",
            "cs.LG",
            "cs.NE"
        ],
        "authors": [
            "Friedemann Zenke",
            "Axel Laborieux"
        ],
        "published": "2024-05-27T08:13:39Z"
    },
    {
        "title": "VoCoT: Unleashing Visually Grounded Multi-Step Reasoning in Large\n  Multi-Modal Models",
        "link": "http://arxiv.org/abs/2405.16919v2",
        "abstract": "While large multi-modal models (LMMs) have exhibited impressive capabilities\nacross diverse tasks, their effectiveness in handling complex tasks has been\nlimited by the prevailing single-step reasoning paradigm. To this end, this\npaper proposes VoCoT, a multi-step Visually grounded object-centric\nChain-of-Thought reasoning framework tailored for inference with LMMs. VoCoT is\ncharacterized by two key features: (1) object-centric reasoning paths that\nrevolve around cross-modal shared object-level information, and (2) visually\ngrounded representation of object concepts in a multi-modal interleaved and\naligned manner, which effectively bridges the modality gap within LMMs during\nlong-term generation. Additionally, we construct an instruction dataset to\nfacilitate LMMs in adapting to reasoning with VoCoT. By introducing VoCoT into\nthe prevalent open-source LMM architecture, we introduce VolCano. With only 7B\nparameters and limited input resolution, VolCano demonstrates excellent\nperformance across various scenarios, surpassing SOTA models, including GPT-4V,\nin tasks requiring complex reasoning. Our code, data and model will be\navailable at https://github.com/RupertLuo/VoCoT.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Zejun Li",
            "Ruipu Luo",
            "Jiwen Zhang",
            "Minghui Qiu",
            "Zhongyu Wei"
        ],
        "published": "2024-05-27T08:12:00Z"
    },
    {
        "title": "The Uncanny Valley: Exploring Adversarial Robustness from a Flatness\n  Perspective",
        "link": "http://arxiv.org/abs/2405.16918v1",
        "abstract": "Flatness of the loss surface not only correlates positively with\ngeneralization but is also related to adversarial robustness, since\nperturbations of inputs relate non-linearly to perturbations of weights. In\nthis paper, we empirically analyze the relation between adversarial examples\nand relative flatness with respect to the parameters of one layer. We observe a\npeculiar property of adversarial examples: during an iterative first-order\nwhite-box attack, the flatness of the loss surface measured around the\nadversarial example first becomes sharper until the label is flipped, but if we\nkeep the attack running it runs into a flat uncanny valley where the label\nremains flipped. We find this phenomenon across various model architectures and\ndatasets. Our results also extend to large language models (LLMs), but due to\nthe discrete nature of the input space and comparatively weak attacks, the\nadversarial examples rarely reach a truly flat region. Most importantly, this\nphenomenon shows that flatness alone cannot explain adversarial robustness\nunless we can also guarantee the behavior of the function around the examples.\nWe theoretically connect relative flatness to adversarial robustness by\nbounding the third derivative of the loss surface, underlining the need for\nflatness in combination with a low global Lipschitz constant for a robust\nmodel.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Nils Philipp Walter",
            "Linara Adilova",
            "Jilles Vreeken",
            "Michael Kamp"
        ],
        "published": "2024-05-27T08:10:46Z"
    },
    {
        "title": "LRAMM -- Low precision approximates GEMM via RSVD",
        "link": "http://arxiv.org/abs/2405.16917v1",
        "abstract": "Matrix multiplication computation acceleration has been a research hotspot\nacross various domains. Due to the characteristics of some applications,\napproximate matrix multiplication can achieve significant performance\nimprovements without losing much precision.\n  In this paper, we propose LRAMM - a high-performance matrix multiplication\napproximation algorithm that combines mixed-precision quantized matrix\nmultiplication with RSVD techniques, further enhancing efficiency within the\nerror range of low-precision matrix multiplication by utilizing matrix low-rank\ndecomposition technology.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "cs.PF"
        ],
        "authors": [
            "Hongyaoxing Gu"
        ],
        "published": "2024-05-27T08:09:07Z"
    },
    {
        "title": "Multilingual Diversity Improves Vision-Language Representations",
        "link": "http://arxiv.org/abs/2405.16915v1",
        "abstract": "Massive web-crawled image-text datasets lay the foundation for recent\nprogress in multimodal learning. These datasets are designed with the goal of\ntraining a model to do well on standard computer vision benchmarks, many of\nwhich, however, have been shown to be English-centric (e.g., ImageNet).\nConsequently, existing data curation techniques gravitate towards using\npredominantly English image-text pairs and discard many potentially useful\nnon-English samples. Our work questions this practice. Multilingual data is\ninherently enriching not only because it provides a gateway to learn about\nculturally salient concepts, but also because it depicts common concepts\ndifferently from monolingual data. We thus conduct a systematic study to\nexplore the performance benefits of using more samples of non-English origins\nwith respect to English vision tasks. By translating all multilingual\nimage-text pairs from a raw web crawl to English and re-filtering them, we\nincrease the prevalence of (translated) multilingual data in the resulting\ntraining set. Pre-training on this dataset outperforms using English-only or\nEnglish-dominated datasets on ImageNet, ImageNet distribution shifts,\nimage-English-text retrieval and on average across 38 tasks from the DataComp\nbenchmark. On a geographically diverse task like GeoDE, we also observe\nimprovements across all regions, with the biggest gain coming from Africa. In\naddition, we quantitatively show that English and non-English data are\nsignificantly different in both image and (translated) text space. We hope that\nour findings motivate future work to be more intentional about including\nmulticultural and multilingual data, not just when non-English or\ngeographically diverse tasks are involved, but to enhance model capabilities at\nlarge.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Thao Nguyen",
            "Matthew Wallingford",
            "Sebastin Santy",
            "Wei-Chiu Ma",
            "Sewoong Oh",
            "Ludwig Schmidt",
            "Pang Wei Koh",
            "Ranjay Krishna"
        ],
        "published": "2024-05-27T08:08:51Z"
    },
    {
        "title": "Rigorous Simulation-based Testing for Autonomous Driving Systems --\n  Targeting the Achilles' Heel of Four Open Autopilots",
        "link": "http://arxiv.org/abs/2405.16914v1",
        "abstract": "Simulation-based testing remains the main approach for validating Autonomous\nDriving Systems. We propose a rigorous test method based on breaking down\nscenarios into simple ones, taking into account the fact that autopilots make\ndecisions according to traffic rules whose application depends on local\nknowledge and context. This leads us to consider the autopilot as a dynamic\nsystem receiving three different types of vistas as input, each characterizing\na specific driving operation and a corresponding control policy.\n  The test method for the considered vista types generates test cases for\ncritical configurations that place the vehicle under test in critical\nsituations characterized by the transition from cautious behavior to\nprogression in order to clear an obstacle. The test cases thus generated are\nrealistic, i.e., they determine the initial conditions from which safe control\npolicies are possible, based on knowledge of the vehicle's dynamic\ncharacteristics. Constraint analysis identifies the most critical test cases,\nwhose success implies the validity of less critical ones. Test coverage can\ntherefore be greatly simplified. Critical test cases reveal major defects in\nApollo, Autoware, and the Carla and LGSVL autopilots. Defects include\naccidents, software failures, and traffic rule violations that would be\ndifficult to detect by random simulation, as the test cases lead to situations\ncharacterized by finely-tuned parameters of the vehicles involved, such as\ntheir relative position and speed.\n  Our results corroborate real-life observations and confirm that autonomous\ndriving systems still have a long way to go before offering acceptable safety\nguarantees.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Changwen Li",
            "Joseph Sifakis",
            "Rongjie Yan",
            "Jian Zhang"
        ],
        "published": "2024-05-27T08:06:21Z"
    },
    {
        "title": "A Cross-Dataset Study for Text-based 3D Human Motion Retrieval",
        "link": "http://arxiv.org/abs/2405.16909v1",
        "abstract": "We provide results of our study on text-based 3D human motion retrieval and\nparticularly focus on cross-dataset generalization. Due to practical reasons\nsuch as dataset-specific human body representations, existing works typically\nbenchmarkby training and testing on partitions from the same dataset. Here, we\nemploy a unified SMPL body format for all datasets, which allows us to perform\ntraining on one dataset, testing on the other, as well as training on a\ncombination of datasets. Our results suggest that there exist dataset biases in\nstandard text-motion benchmarks such as HumanML3D, KIT Motion-Language, and\nBABEL. We show that text augmentations help close the domain gap to some\nextent, but the gap remains. We further provide the first zero-shot action\nrecognition results on BABEL, without using categorical action labels during\ntraining, opening up a new avenue for future research.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Lore Bensabath",
            "Mathis Petrovich",
            "Gl Varol"
        ],
        "published": "2024-05-27T07:58:20Z"
    },
    {
        "title": "Can Large Language Models Faithfully Express Their Intrinsic Uncertainty\n  in Words?",
        "link": "http://arxiv.org/abs/2405.16908v1",
        "abstract": "We posit that large language models (LLMs) should be capable of expressing\ntheir intrinsic uncertainty in natural language. For example, if the LLM is\nequally likely to output two contradicting answers to the same question, then\nits generated response should reflect this uncertainty by hedging its answer\n(e.g., \"I'm not sure, but I think...\"). We formalize faithful response\nuncertainty based on the gap between the model's intrinsic confidence in the\nassertions it makes and the decisiveness by which they are conveyed. This\nexample-level metric reliably indicates whether the model reflects its\nuncertainty, as it penalizes both excessive and insufficient hedging. We\nevaluate a variety of aligned LLMs at faithfully communicating uncertainty on\nseveral knowledge-intensive question answering tasks. Our results provide\nstrong evidence that modern LLMs are poor at faithfully conveying their\nuncertainty, and that better alignment is necessary to improve their\ntrustworthiness.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Gal Yona",
            "Roee Aharoni",
            "Mor Geva"
        ],
        "published": "2024-05-27T07:56:23Z"
    },
    {
        "title": "GTA: Generative Trajectory Augmentation with Guidance for Offline\n  Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.16907v2",
        "abstract": "Offline Reinforcement Learning (Offline RL) presents challenges of learning\neffective decision-making policies from static datasets without any online\ninteractions. Data augmentation techniques, such as noise injection and data\nsynthesizing, aim to improve Q-function approximation by smoothing the learned\nstate-action region. However, these methods often fall short of directly\nimproving the quality of offline datasets, leading to suboptimal results. In\nresponse, we introduce \\textbf{GTA}, Generative Trajectory Augmentation, a\nnovel generative data augmentation approach designed to enrich offline data by\naugmenting trajectories to be both high-rewarding and dynamically plausible.\nGTA applies a diffusion model within the data augmentation framework. GTA\npartially noises original trajectories and then denoises them with\nclassifier-free guidance via conditioning on amplified return value. Our\nresults show that GTA, as a general data augmentation strategy, enhances the\nperformance of widely used offline RL algorithms in both dense and sparse\nreward settings. Furthermore, we conduct a quality analysis of data augmented\nby GTA and demonstrate that GTA improves the quality of the data. Our code is\navailable at https://github.com/Jaewoopudding/GTA",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Jaewoo Lee",
            "Sujin Yun",
            "Taeyoung Yun",
            "Jinkyoo Park"
        ],
        "published": "2024-05-27T07:55:45Z"
    },
    {
        "title": "Harnessing the Power of Vicinity-Informed Analysis for Classification\n  under Covariate Shift",
        "link": "http://arxiv.org/abs/2405.16906v1",
        "abstract": "Transfer learning enhances prediction accuracy on a target distribution by\nleveraging data from a source distribution, demonstrating significant benefits\nin various applications. This paper introduces a novel dissimilarity measure\nthat utilizes vicinity information, i.e., the local structure of data points,\nto analyze the excess error in classification under covariate shift, a transfer\nlearning setting where marginal feature distributions differ but conditional\nlabel distributions remain the same. We characterize the excess error using the\nproposed measure and demonstrate faster or competitive convergence rates\ncompared to previous techniques. Notably, our approach is effective in\nsituations where the non-absolute continuousness assumption, which often\nappears in real-world applications, holds. Our theoretical analysis bridges the\ngap between current theoretical findings and empirical observations in transfer\nlearning, particularly in scenarios with significant differences between source\nand target distributions.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Mitsuhiro Fujikawa",
            "Yohei Akimoto",
            "Jun Sakuma",
            "Kazuto Fukuchi"
        ],
        "published": "2024-05-27T07:55:27Z"
    },
    {
        "title": "Privacy and Security Trade-off in Interconnected Systems with Known or\n  Unknown Privacy Noise Covariance",
        "link": "http://arxiv.org/abs/2405.16905v1",
        "abstract": "This paper is concerned with the security problem for interconnected systems,\nwhere each subsystem is required to detect local attacks using locally\navailable information and the information received from its neighboring\nsubsystems. Moreover, we consider that there exists an additional eavesdropper\nbeing able to infer the private information by eavesdropping transmitted data\nbetween subsystems. Then, a privacy-preserving method is employed by adding\nprivacy noise to transmitted data, and the privacy level is measured by mutual\ninformation. Nevertheless, adding privacy noise to transmitted data may affect\nthe detection performance metrics such as detection probability and false alarm\nprobability. Thus, we theoretically analyze the trade-off between the privacy\nand the detection performance. An optimization problem with maximizing both the\ndegree of privacy preservation and the detection probability is established to\nobtain the covariance of the privacy noise. In addition, the attack detector of\neach subsystem may not obtain all information about the privacy noise. We\nfurther theoretically analyze the trade-off between the privacy and the false\nalarm probability when the attack detector has no knowledge of the privacy\nnoise covariance. An optimization problem with maximizing the degree of privacy\npreservation with guaranteeing a bound of false alarm distortion level is\nestablished to obtain {\\color{black}{the covariance of the privacy noise}}.\nMoreover, to analyze the effect of the privacy noise on the detection\nprobability, we consider that each subsystem can estimate the unknown privacy\nnoise covariance by the secondary data. Based on the estimated covariance, we\nconstruct another attack detector and analyze how the privacy noise affects its\ndetection performance. Finally, a numerical example is provided to verify the\neffectiveness of theoretical results.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Haojun Wang",
            "Kun Liu",
            "Baojia Li",
            "Emilia Fridman",
            "Yuanqing Xia"
        ],
        "published": "2024-05-27T07:53:51Z"
    },
    {
        "title": "Kaczmarz Projection Algorithms in Moving Window: Performance Improvement\n  via Extended Orthogonality & Forgetting",
        "link": "http://dx.doi.org/10.1007/s11265-024-01915-w",
        "abstract": "New Kaczmarz algorithms with rank two gain update, extended orthogonality\nproperty and forgetting mechanism which includes both exponential and\ninstantaneous forgetting (implemented via a proper choice of the forgetting\nfactor and the window size) are introduced and associated in this report with\nwell-known Kaczmarz algorithms with rank one update.",
        "subjects": [
            "math.OC",
            "cs.NA",
            "math.DS",
            "math.NA",
            "math.SP"
        ],
        "authors": [
            "Alexander Stotsky"
        ],
        "published": "2024-05-27T07:53:16Z"
    },
    {
        "title": "Predicting from a Different Perspective in Re-ranking Model for\n  Inductive Knowledge Graph Completion",
        "link": "http://arxiv.org/abs/2405.16902v1",
        "abstract": "Rule-induction models have been shown great power in the inductive setting of\nknowledge graph completion. In this setting, the models are tested on a\nknowledge graph entirely composed of unseen entities. These models learn\nrelation patterns as rules by utilizing subgraphs. The same input but different\nrules cause differences in the model's predictions. In this paper, we focus on\nthis behavior of the model. We propose a re-ranking-based model called ReDistLP\n(Re-ranking with a Distinct Model for Link Prediction). This model enhances the\neffectiveness of re-ranking by leveraging the difference in the predictions\nbetween the initial retriever and the re-ranker. ReDistLP outperforms the\nstate-of-the-art methods in 2 out of 3 datasets.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yuki Iwamoto",
            "Ken Kameiwa"
        ],
        "published": "2024-05-27T07:50:09Z"
    },
    {
        "title": "Recurrent and Convolutional Neural Networks in Classification of EEG\n  Signal for Guided Imagery and Mental Workload Detection",
        "link": "http://arxiv.org/abs/2405.16901v2",
        "abstract": "The Guided Imagery technique is reported to be used by therapists all over\nthe world in order to increase the comfort of patients suffering from a variety\nof disorders from mental to oncology ones and proved to be successful in\nnumerous of ways. Possible support for the therapists can be estimation of the\ntime at which subject goes into deep relaxation. This paper presents the\nresults of the investigations of a cohort of 26 students exposed to Guided\nImagery relaxation technique and mental task workloads conducted with the use\nof dense array electroencephalographic amplifier. The research reported herein\naimed at verification whether it is possible to detect differences between\nthose two states and to classify them using deep learning methods and recurrent\nneural networks such as EEGNet, Long Short-Term Memory-based classifier, 1D\nConvolutional Neural Network and hybrid model of 1D Convolutional Neural\nNetwork and Long Short-Term Memory. The data processing pipeline was presented\nfrom the data acquisition, through the initial data cleaning, preprocessing and\npostprocessing. The classification was based on two datasets: one of them using\n26 so-called cognitive electrodes and the other one using signal collected from\n256 channels. So far there have not been such comparisons in the application\nbeing discussed. The classification results are presented by the validation\nmetrics such as: accuracy, recall, precision, F1-score and loss for each case.\nIt turned out that it is not necessary to collect signals from all electrodes\nas classification of the cognitive ones gives the results similar to those\nobtained for the full signal and extending input to 256 channels does not add\nmuch value. In Disscussion there were proposed an optimal classifier as well as\nsome suggestions concerning the prospective development of the project.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Filip Postepski",
            "Grzegorz M. Wojcik",
            "Krzysztof Wrobel",
            "Andrzej Kawiak",
            "Katarzyna Zemla",
            "Grzegorz Sedek"
        ],
        "published": "2024-05-27T07:49:30Z"
    },
    {
        "title": "Partial Models for Building Adaptive Model-Based Reinforcement Learning\n  Agents",
        "link": "http://arxiv.org/abs/2405.16899v1",
        "abstract": "In neuroscience, one of the key behavioral tests for determining whether a\nsubject of study exhibits model-based behavior is to study its adaptiveness to\nlocal changes in the environment. In reinforcement learning, however, recent\nstudies have shown that modern model-based agents display poor adaptivity to\nsuch changes. The main reason for this is that modern agents are typically\ndesigned to improve sample efficiency in single task settings and thus do not\ntake into account the challenges that can arise in other settings. In local\nadaptation settings, one particularly important challenge is in quickly\nbuilding and maintaining a sufficiently accurate model after a local change.\nThis is challenging for deep model-based agents as their models and replay\nbuffers are monolithic structures lacking distribution shift handling\ncapabilities. In this study, we show that the conceptually simple idea of\npartial models can allow deep model-based agents to overcome this challenge and\nthus allow for building locally adaptive model-based agents. By modeling the\ndifferent parts of the state space through different models, the agent can not\nonly maintain a model that is accurate across the state space, but it can also\nquickly adapt it in the presence of a local change in the environment. We\ndemonstrate this by showing that the use of partial models in agents such as\ndeep Dyna-Q, PlaNet and Dreamer can allow for them to effectively adapt to the\nlocal changes in their environments.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Safa Alver",
            "Ali Rahimi-Kalahroudi",
            "Doina Precup"
        ],
        "published": "2024-05-27T07:46:36Z"
    },
    {
        "title": "Unconventional complexity classes in unconventional computing (extended\n  abstract)",
        "link": "http://arxiv.org/abs/2405.16896v1",
        "abstract": "Many unconventional computing models, including some that appear to be quite\ndifferent from traditional ones such as Turing machines, happen to characterise\neither the complexity class P or PSPACE when working in deterministic\npolynomial time (and in the maximally parallel way, where this applies). We\ndiscuss variants of cellular automata and membrane systems that escape this\ndichotomy and characterise intermediate complexity classes, usually defined in\nterms of Turing machines with oracles, as well as some possible reasons why\nthis happens.",
        "subjects": [
            "cs.CC"
        ],
        "authors": [
            "Antonio E. Porreca"
        ],
        "published": "2024-05-27T07:43:54Z"
    },
    {
        "title": "Anonymization Prompt Learning for Facial Privacy-Preserving\n  Text-to-Image Generation",
        "link": "http://arxiv.org/abs/2405.16895v1",
        "abstract": "Text-to-image diffusion models, such as Stable Diffusion, generate highly\nrealistic images from text descriptions. However, the generation of certain\ncontent at such high quality raises concerns. A prominent issue is the accurate\ndepiction of identifiable facial images, which could lead to malicious deepfake\ngeneration and privacy violations. In this paper, we propose Anonymization\nPrompt Learning (APL) to address this problem. Specifically, we train a\nlearnable prompt prefix for text-to-image diffusion models, which forces the\nmodel to generate anonymized facial identities, even when prompted to produce\nimages of specific individuals. Extensive quantitative and qualitative\nexperiments demonstrate the successful anonymization performance of APL, which\nanonymizes any specific individuals without compromising the quality of\nnon-identity-specific image generation. Furthermore, we reveal the\nplug-and-play property of the learned prompt prefix, enabling its effective\napplication across different pretrained text-to-image models for transferrable\nprivacy and security protection against the risks of deepfakes.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Liang Shi",
            "Jie Zhang",
            "Shiguang Shan"
        ],
        "published": "2024-05-27T07:38:26Z"
    },
    {
        "title": "On Fairness of Low-Rank Adaptation of Large Models",
        "link": "http://arxiv.org/abs/2405.17512v1",
        "abstract": "Low-rank adaptation of large models, particularly LoRA, has gained traction\ndue to its computational efficiency. This efficiency, contrasted with the\nprohibitive costs of full-model fine-tuning, means that practitioners often\nturn to LoRA and sometimes without a complete understanding of its\nramifications. In this study, we focus on fairness and ask whether LoRA has an\nunexamined impact on utility, calibration, and resistance to membership\ninference across different subgroups (e.g., genders, races, religions) compared\nto a full-model fine-tuning baseline. We present extensive experiments across\nvision and language domains and across classification and generation tasks\nusing ViT-Base, Swin-v2-Large, Llama-2 7B, and Mistral 7B. Intriguingly,\nexperiments suggest that while one can isolate cases where LoRA exacerbates\nmodel bias across subgroups, the pattern is inconsistent -- in many cases, LoRA\nhas equivalent or even improved fairness compared to the base model or its full\nfine-tuning baseline. We also examine the complications of evaluating\nfine-tuning fairness relating to task design and model token bias, calling for\nmore careful fairness evaluations in future work.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CY"
        ],
        "authors": [
            "Zhoujie Ding",
            "Ken Ziyu Liu",
            "Pura Peetathawatchai",
            "Berivan Isik",
            "Sanmi Koyejo"
        ],
        "published": "2024-05-27T07:37:43Z"
    },
    {
        "title": "An Unconstrained Formulation of Some Constrained Partial Differential\n  Equations and its Application to Finite Neuron Methods",
        "link": "http://arxiv.org/abs/2405.16894v1",
        "abstract": "In this paper, we present a new framework how a PDE with constraints can be\nformulated into a sequence of PDEs with no constraints, whose solutions are\nconvergent to the solution of the PDE with constraints. This framework is then\nused to build a novel finite neuron method to solve the 2nd order elliptic\nequations with the Dirichlet boundary condition. Our algorithm is the first\nalgorithm, proven to lead to shallow neural network solutions with an optimal\nH1 norm error. We show that a widely used penalized PDE, which imposes the\nDirichlet boundary condition weakly can be interpreted as the first element of\nthe sequence of PDEs within our framework. Furthermore, numerically, we show\nthat it may not lead to the solution with the optimal H1 norm error bound in\ngeneral. On the other hand, we theoretically demonstrate that the second and\nlater elements of a sequence of PDEs can lead to an adequate solution with the\noptimal H1 norm error bound. A number of sample tests are performed to confirm\nthe effectiveness of the proposed algorithm and the relevant theory.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Jiwei Jia",
            "Young Ju Lee",
            "Ruitong Shan"
        ],
        "published": "2024-05-27T07:35:53Z"
    },
    {
        "title": "Cross Far- and Near-Field Channel Measurement and Modeling in Extremely\n  Large-scale Antenna Array (ELAA) Systems",
        "link": "http://arxiv.org/abs/2405.16893v1",
        "abstract": "Technologies like ultra-massive multiple-input-multiple-output (UM-MIMO) and\nreconfigurable intelligent surfaces (RISs) are of special interest to meet the\nkey performance indicators of future wireless systems including ubiquitous\nconnectivity and lightning-fast data rates. One of their common features, the\nextremely large-scale antenna array (ELAA) systems with hundreds or thousands\nof antennas, give rise to near-field (NF) propagation and bring new challenges\nto channel modeling and characterization. In this paper, a cross-field channel\nmodel for ELAA systems is proposed, which improves the statistical model in\n3GPP TR 38.901 by refining the propagation path with its first and last bounces\nand differentiating the characterization of parameters like path loss, delay,\nand angles in near- and far-fields. A comprehensive analysis of cross-field\nboundaries and closed-form expressions of corresponding NF or FF parameters are\nprovided. Furthermore, cross-field experiments carried out in a typical indoor\nscenario at 300 GHz verify the variation of MPC parameters across the antenna\narray, and demonstrate the distinction of channels between different antenna\nelements. Finally, detailed generation procedures of the cross-field channel\nmodel are provided, based on which simulations and analysis on NF probabilities\nand channel coefficients are conducted for $4\\times4$, $8\\times8$,\n$16\\times16$, and $9\\times21$ uniform planar arrays at different frequency\nbands.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Yiqin Wang",
            "Chong Han",
            "Shu Sun",
            "Jianhua Zhang"
        ],
        "published": "2024-05-27T07:27:41Z"
    },
    {
        "title": "PivotMesh: Generic 3D Mesh Generation via Pivot Vertices Guidance",
        "link": "http://arxiv.org/abs/2405.16890v1",
        "abstract": "Generating compact and sharply detailed 3D meshes poses a significant\nchallenge for current 3D generative models. Different from extracting dense\nmeshes from neural representation, some recent works try to model the native\nmesh distribution (i.e., a set of triangles), which generates more compact\nresults as humans crafted. However, due to the complexity and variety of mesh\ntopology, these methods are typically limited to small datasets with specific\ncategories and are hard to extend. In this paper, we introduce a generic and\nscalable mesh generation framework PivotMesh, which makes an initial attempt to\nextend the native mesh generation to large-scale datasets. We employ a\ntransformer-based auto-encoder to encode meshes into discrete tokens and decode\nthem from face level to vertex level hierarchically. Subsequently, to model the\ncomplex typology, we first learn to generate pivot vertices as coarse mesh\nrepresentation and then generate the complete mesh tokens with the same\nauto-regressive Transformer. This reduces the difficulty compared with directly\nmodeling the mesh distribution and further improves the model controllability.\nPivotMesh demonstrates its versatility by effectively learning from both small\ndatasets like Shapenet, and large-scale datasets like Objaverse and\nObjaverse-xl. Extensive experiments indicate that PivotMesh can generate\ncompact and sharp 3D meshes across various categories, highlighting its great\npotential for native mesh modeling.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Haohan Weng",
            "Yikai Wang",
            "Tong Zhang",
            "C. L. Philip Chen",
            "Jun Zhu"
        ],
        "published": "2024-05-27T07:13:13Z"
    },
    {
        "title": "Part123: Part-aware 3D Reconstruction from a Single-view Image",
        "link": "http://arxiv.org/abs/2405.16888v1",
        "abstract": "Recently, the emergence of diffusion models has opened up new opportunities\nfor single-view reconstruction. However, all the existing methods represent the\ntarget object as a closed mesh devoid of any structural information, thus\nneglecting the part-based structure, which is crucial for many downstream\napplications, of the reconstructed shape. Moreover, the generated meshes\nusually suffer from large noises, unsmooth surfaces, and blurry textures,\nmaking it challenging to obtain satisfactory part segments using 3D\nsegmentation techniques. In this paper, we present Part123, a novel framework\nfor part-aware 3D reconstruction from a single-view image. We first use\ndiffusion models to generate multiview-consistent images from a given image,\nand then leverage Segment Anything Model (SAM), which demonstrates powerful\ngeneralization ability on arbitrary objects, to generate multiview segmentation\nmasks. To effectively incorporate 2D part-based information into 3D\nreconstruction and handle inconsistency, we introduce contrastive learning into\na neural rendering framework to learn a part-aware feature space based on the\nmultiview segmentation masks. A clustering-based algorithm is also developed to\nautomatically derive 3D part segmentation results from the reconstructed\nmodels. Experiments show that our method can generate 3D models with\nhigh-quality segmented parts on various objects. Compared to existing\nunstructured reconstruction methods, the part-aware 3D models from our method\nbenefit some important applications, including feature-preserving\nreconstruction, primitive fitting, and 3D shape editing.",
        "subjects": [
            "cs.GR",
            "cs.CV"
        ],
        "authors": [
            "Anran Liu",
            "Cheng Lin",
            "Yuan Liu",
            "Xiaoxiao Long",
            "Zhiyang Dou",
            "Hao-Xiang Guo",
            "Ping Luo",
            "Wenping Wang"
        ],
        "published": "2024-05-27T07:10:21Z"
    },
    {
        "title": "A Large Language Model-based multi-agent manufacturing system for\n  intelligent shopfloor",
        "link": "http://arxiv.org/abs/2405.16887v1",
        "abstract": "As productivity advances, the demand of customers for multi-variety and\nsmall-batch production is increasing, thereby putting forward higher\nrequirements for manufacturing systems. When production tasks frequent changes\ndue to this demand, traditional manufacturing systems often cannot response\npromptly. The multi-agent manufacturing system is proposed to address this\nproblem. However, because of technical limitations, the negotiation among\nagents in this kind of system is realized through predefined heuristic rules,\nwhich is not intelligent enough to deal with the multi-variety and small batch\nproduction. To this end, a Large Language Model-based (LLM-based) multi-agent\nmanufacturing system for intelligent shopfloor is proposed in the present\nstudy. This system delineates the diverse agents and defines their\ncollaborative methods. The roles of the agents encompass Machine Server Agent\n(MSA), Bid Inviter Agent (BIA), Bidder Agent (BA), Thinking Agent (TA), and\nDecision Agent (DA). Due to the support of LLMs, TA and DA acquire the ability\nof analyzing the shopfloor condition and choosing the most suitable machine, as\nopposed to executing a predefined program artificially. The negotiation between\nBAs and BIA is the most crucial step in connecting manufacturing resources.\nWith the support of TA and DA, BIA will finalize the distribution of orders,\nrelying on the information of each machine returned by BA. MSAs bears the\nresponsibility for connecting the agents with the physical shopfloor. This\nsystem aims to distribute and transmit workpieces through the collaboration of\nthe agents with these distinct roles, distinguishing it from other scheduling\napproaches. Comparative experiments were also conducted to validate the\nperformance of this system.",
        "subjects": [
            "cs.AI",
            "cs.MA",
            "cs.RO"
        ],
        "authors": [
            "Zhen Zhao",
            "Dunbing Tang",
            "Haihua Zhu",
            "Zequn Zhang",
            "Kai Chen",
            "Changchun Liu",
            "Yuchen Ji"
        ],
        "published": "2024-05-27T07:10:04Z"
    },
    {
        "title": "Hawk: Learning to Understand Open-World Video Anomalies",
        "link": "http://arxiv.org/abs/2405.16886v1",
        "abstract": "Video Anomaly Detection (VAD) systems can autonomously monitor and identify\ndisturbances, reducing the need for manual labor and associated costs. However,\ncurrent VAD systems are often limited by their superficial semantic\nunderstanding of scenes and minimal user interaction. Additionally, the\nprevalent data scarcity in existing datasets restricts their applicability in\nopen-world scenarios. In this paper, we introduce Hawk, a novel framework that\nleverages interactive large Visual Language Models (VLM) to interpret video\nanomalies precisely. Recognizing the difference in motion information between\nabnormal and normal videos, Hawk explicitly integrates motion modality to\nenhance anomaly identification. To reinforce motion attention, we construct an\nauxiliary consistency loss within the motion and video space, guiding the video\nbranch to focus on the motion modality. Moreover, to improve the interpretation\nof motion-to-language, we establish a clear supervisory relationship between\nmotion and its linguistic representation. Furthermore, we have annotated over\n8,000 anomaly videos with language descriptions, enabling effective training\nacross diverse open-world scenarios, and also created 8,000 question-answering\npairs for users' open-world questions. The final results demonstrate that Hawk\nachieves SOTA performance, surpassing existing baselines in both video\ndescription generation and question-answering. Our codes/dataset/demo will be\nreleased at https://github.com/jqtangust/hawk.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jiaqi Tang",
            "Hao Lu",
            "Ruizheng Wu",
            "Xiaogang Xu",
            "Ke Ma",
            "Cheng Fang",
            "Bin Guo",
            "Jiangbo Lu",
            "Qifeng Chen",
            "Ying-Cong Chen"
        ],
        "published": "2024-05-27T07:08:58Z"
    },
    {
        "title": "Match, Compare, or Select? An Investigation of Large Language Models for\n  Entity Matching",
        "link": "http://arxiv.org/abs/2405.16884v1",
        "abstract": "Entity matching (EM) is a critical step in entity resolution. Recently,\nentity matching based on large language models (LLMs) has shown great promise.\nHowever, current LLM-based entity matching approaches typically follow a binary\nmatching paradigm that ignores the global consistency between different\nrecords. In this paper, we investigate various methodologies for LLM-based\nentity matching that incorporate record interactions from different\nperspectives. Specifically, we comprehensively compare three representative\nstrategies: matching, comparing, and selecting, and analyze their respective\nadvantages and challenges in diverse scenarios. Based on our findings, we\nfurther design a compositional entity matching (ComEM) framework that leverages\nthe composition of multiple strategies and LLMs. In this way, ComEM can benefit\nfrom the advantages of different sides and achieve improvements in both\neffectiveness and efficiency. Experimental results show that ComEM not only\nachieves significant performance gains on various datasets but also reduces the\ncost of LLM-based entity matching in real-world application.",
        "subjects": [
            "cs.CL",
            "cs.DB"
        ],
        "authors": [
            "Tianshu Wang",
            "Hongyu Lin",
            "Xiaoyang Chen",
            "Xianpei Han",
            "Hao Wang",
            "Zhenyu Zeng",
            "Le Sun"
        ],
        "published": "2024-05-27T07:05:27Z"
    },
    {
        "title": "Scorch: A Library for Sparse Deep Learning",
        "link": "http://arxiv.org/abs/2405.16883v1",
        "abstract": "The rapid growth in the size of deep learning models strains the capabilities\nof traditional dense computation paradigms. Leveraging sparse computation has\nbecome increasingly popular for training and deploying large-scale models, but\nexisting deep learning frameworks lack extensive support for sparse operations.\nTo bridge this gap, we introduce Scorch, a library that seamlessly integrates\nefficient sparse tensor computation into the PyTorch ecosystem, with an initial\nfocus on inference workloads on CPUs. Scorch provides a flexible and intuitive\ninterface for sparse tensors, supporting diverse sparse data structures. Scorch\nintroduces a compiler stack that automates key optimizations, including\nautomatic loop ordering, tiling, and format inference. Combined with a runtime\nthat adapts its execution to both dense and sparse data, Scorch delivers\nsubstantial speedups over hand-written PyTorch Sparse (torch.sparse) operations\nwithout sacrificing usability. More importantly, Scorch enables efficient\ncomputation of complex sparse operations that lack hand-optimized PyTorch\nimplementations. This flexibility is crucial for exploring novel sparse\narchitectures. We demonstrate Scorch's ease of use and performance gains on\ndiverse deep learning models across multiple domains. With only minimal code\nchanges, Scorch achieves 1.05-5.78x speedups over PyTorch Sparse on end-to-end\ntasks. Scorch's seamless integration and performance gains make it a valuable\naddition to the PyTorch ecosystem. We believe Scorch will enable wider\nexploration of sparsity as a tool for scaling deep learning and inform the\ndevelopment of other sparse libraries.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.MS",
            "cs.PL"
        ],
        "authors": [
            "Bobby Yan",
            "Alexander J. Root",
            "Trevor Gale",
            "David Broman",
            "Fredrik Kjolstad"
        ],
        "published": "2024-05-27T06:59:20Z"
    },
    {
        "title": "Half-duplex communication complexity with adversary can be less than the\n  classical communication complexity",
        "link": "http://arxiv.org/abs/2405.16881v1",
        "abstract": "Half-duplex communication complexity with adversary was defined in [Hoover,\nK., Impagliazzo, R., Mihajlin, I., Smal, A. V. Half-Duplex Communication\nComplexity, ISAAC 2018.] Half-duplex communication protocols generalize\nclassical protocols defined by Andrew Yao in [Yao, A. C.-C. Some Complexity\nQuestions Related to Distributive Computing (Preliminary Report), STOC 1979].\nIt has been unknown so far whether the communication complexities defined by\nthese models are different or not. In the present paper we answer this\nquestion: we exhibit a function whose half-duplex communication complexity with\nadversary is strictly less than its classical communication complexity.",
        "subjects": [
            "cs.CC",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Mikhail Dektiarev",
            "Nikolay Vereshchagin"
        ],
        "published": "2024-05-27T06:53:46Z"
    },
    {
        "title": "Reference Neural Operators: Learning the Smooth Dependence of Solutions\n  of PDEs on Geometric Deformations",
        "link": "http://arxiv.org/abs/2405.17509v1",
        "abstract": "For partial differential equations on domains of arbitrary shapes, existing\nworks of neural operators attempt to learn a mapping from geometries to\nsolutions. It often requires a large dataset of geometry-solution pairs in\norder to obtain a sufficiently accurate neural operator. However, for many\nindustrial applications, e.g., engineering design optimization, it can be\nprohibitive to satisfy the requirement since even a single simulation may take\nhours or days of computation. To address this issue, we propose reference\nneural operators (RNO), a novel way of implementing neural operators, i.e., to\nlearn the smooth dependence of solutions on geometric deformations.\nSpecifically, given a reference solution, RNO can predict solutions\ncorresponding to arbitrary deformations of the referred geometry. This approach\nturns out to be much more data efficient. Through extensive experiments, we\nshow that RNO can learn the dependence across various types and different\nnumbers of geometry objects with relatively small datasets. RNO outperforms\nbaseline models in accuracy by a large lead and achieves up to 80% error\nreduction.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ze Cheng",
            "Zhongkai Hao",
            "Xiaoqiang Wang",
            "Jianing Huang",
            "Youjia Wu",
            "Xudan Liu",
            "Yiru Zhao",
            "Songming Liu",
            "Hang Su"
        ],
        "published": "2024-05-27T06:50:17Z"
    },
    {
        "title": "Systematic Literature Review of Commercial Participation in Open Source\n  Software",
        "link": "http://arxiv.org/abs/2405.16880v1",
        "abstract": "Open source software (OSS) has been playing a fundamental role in not only\ninformation technology but also our social lives. Attracted by various\nadvantages of OSS, increasing commercial companies take extensive participation\nin open source development and have had a broad impact. This paper provides a\ncomprehensive systematic literature review (SLR) of existing research on\ncompany participation in OSS. We collected 92 papers and organized them based\non their research topics, which cover three main directions, i.e.,\nparticipation motivation, contribution model, and impact on OSS development. We\nfound the explored motivations of companies are mainly from economic,\ntechnological, and social aspects. Existing studies categorize companies'\ncontribution models in OSS projects mainly through their objectives and how\nthey shape OSS communities. Researchers also explored how commercial\nparticipation affects OSS development. We conclude with research challenges and\npromising research directions on commercial participation in OSS. This study\ncontributes to a comprehensive understanding of commercial participation in OSS\ndevelopment.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Xuetao Li",
            "Yuxia Zhang",
            "Cailean Osborne",
            "Minghui Zhou",
            "Zhi Jin",
            "Hui Liu"
        ],
        "published": "2024-05-27T06:50:01Z"
    },
    {
        "title": "Unsupervised Generative Feature Transformation via Graph Contrastive\n  Pre-training and Multi-objective Fine-tuning",
        "link": "http://arxiv.org/abs/2405.16879v1",
        "abstract": "Feature transformation is to derive a new feature set from original features\nto augment the AI power of data. In many science domains such as material\nperformance screening, while feature transformation can model material formula\ninteractions and compositions and discover performance drivers, supervised\nlabels are collected from expensive and lengthy experiments. This issue\nmotivates an Unsupervised Feature Transformation Learning (UFTL) problem. Prior\nliterature, such as manual transformation, supervised feedback guided search,\nand PCA, either relies on domain knowledge or expensive supervised feedback, or\nsuffers from large search space, or overlooks non-linear feature-feature\ninteractions. UFTL imposes a major challenge on existing methods: how to design\na new unsupervised paradigm that captures complex feature interactions and\navoids large search space? To fill this gap, we connect graph, contrastive, and\ngenerative learning to develop a measurement-pretrain-finetune paradigm for\nUFTL. For unsupervised feature set utility measurement, we propose a feature\nvalue consistency preservation perspective and develop a mean discounted\ncumulative gain like unsupervised metric to evaluate feature set utility. For\nunsupervised feature set representation pretraining, we regard a feature set as\na feature-feature interaction graph, and develop an unsupervised graph\ncontrastive learning encoder to embed feature sets into vectors. For generative\ntransformation finetuning, we regard a feature set as a feature cross sequence\nand feature transformation as sequential generation. We develop a deep\ngenerative feature transformation model that coordinates the pretrained feature\nset encoder and the gradient information extracted from a feature set utility\nevaluator to optimize a transformed feature generator.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Wangyang Ying",
            "Dongjie Wang",
            "Xuanming Hu",
            "Yuanchun Zhou",
            "Charu C. Aggarwal",
            "Yanjie Fu"
        ],
        "published": "2024-05-27T06:50:00Z"
    },
    {
        "title": "Are Self-Attentions Effective for Time Series Forecasting?",
        "link": "http://arxiv.org/abs/2405.16877v1",
        "abstract": "Time series forecasting is crucial for applications across multiple domains\nand various scenarios. Although Transformer models have dramatically shifted\nthe landscape of forecasting, their effectiveness remains debated. Recent\nfindings have indicated that simpler linear models might outperform complex\nTransformer-based approaches, highlighting the potential for more streamlined\narchitectures. In this paper, we shift focus from the overall architecture of\nthe Transformer to the effectiveness of self-attentions for time series\nforecasting. To this end, we introduce a new architecture, Cross-Attention-only\nTime Series transformer (CATS), that rethinks the traditional Transformer\nframework by eliminating self-attention and leveraging cross-attention\nmechanisms instead. By establishing future horizon-dependent parameters as\nqueries and enhanced parameter sharing, our model not only improves long-term\nforecasting accuracy but also reduces the number of parameters and memory\nusage. Extensive experiment across various datasets demonstrates that our model\nachieves superior performance with the lowest mean squared error and uses fewer\nparameters compared to existing models.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Dongbin Kim",
            "Jinseong Park",
            "Jaewook Lee",
            "Hoki Kim"
        ],
        "published": "2024-05-27T06:49:39Z"
    },
    {
        "title": "Transfer Learning for Diffusion Models",
        "link": "http://arxiv.org/abs/2405.16876v2",
        "abstract": "Diffusion models, a specific type of generative model, have achieved\nunprecedented performance in recent years and consistently produce high-quality\nsynthetic samples. A critical prerequisite for their notable success lies in\nthe presence of a substantial number of training samples, which can be\nimpractical in real-world applications due to high collection costs or\nassociated risks. Consequently, various finetuning and regularization\napproaches have been proposed to transfer knowledge from existing pre-trained\nmodels to specific target domains with limited data. This paper introduces the\nTransfer Guided Diffusion Process (TGDP), a novel approach distinct from\nconventional finetuning and regularization methods. We prove that the optimal\ndiffusion model for the target domain integrates pre-trained diffusion models\non the source domain with additional guidance from a domain classifier. We\nfurther extend TGDP to a conditional version for modeling the joint\ndistribution of data and its corresponding labels, together with two additional\nregularization terms to enhance the model performance. We validate the\neffectiveness of TGDP on Gaussian mixture simulations and on real\nelectrocardiogram (ECG) datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Yidong Ouyang",
            "Liyan Xie",
            "Hongyuan Zha",
            "Guang Cheng"
        ],
        "published": "2024-05-27T06:48:58Z"
    },
    {
        "title": "Digitalization in Infrastructure Construction Projects: A PRISMA-Based\n  Review of Benefits and Obstacles",
        "link": "http://arxiv.org/abs/2405.16875v1",
        "abstract": "The current study presents a comprehensive review of the benefits and\nbarriers associated with the adoption of Building Information Modeling (BIM) in\ninfrastructure projects, focusing on the period from 2013 to 2023. The research\nexplores the manifold advantages offered by BIM, spanning the entire project\nlife cycle, including planning, design, construction, maintenance, and\nsustainability. Notably, BIM enhances collaboration, facilitates real-time\ndata-driven decision-making, and leads to substantial cost and time savings. In\nparallel, a systematic literature review was conducted to identify and\ncategorize the barriers hindering BIM adoption within the infrastructure\nindustry. Eleven studies were selected for in-depth analysis, revealing a total\nof 74 obstacles. Through synthetic analysis and thematic clustering, seven\nprimary impediments to BIM adoption were identified, encompassing challenges\nrelated to education/training, resistance to change, business value clarity,\nperceived cost, lack of standards and guidelines, lack of mandates, and lack of\ninitiatives. This review explores the benefits and barriers in the industry\nthat are facing BIM adoption in infrastructure projects, giving an important\nperspective toward improving effective BIM adoption strategies, policies, and\nstandards. Future directions for research and industry development are\noutlined, including efforts to enhance education and training, promote\nstandardization, advocate for policy and mandates, and integrate BIM with\nemerging technologies.",
        "subjects": [
            "cs.RO",
            "cs.CE",
            "cs.ET"
        ],
        "authors": [
            "Mohammed Abdulsalam Alsofiani"
        ],
        "published": "2024-05-27T06:48:21Z"
    },
    {
        "title": "CoCoGesture: Toward Coherent Co-speech 3D Gesture Generation in the Wild",
        "link": "http://arxiv.org/abs/2405.16874v1",
        "abstract": "Deriving co-speech 3D gestures has seen tremendous progress in virtual avatar\nanimation. Yet, the existing methods often produce stiff and unreasonable\ngestures with unseen human speech inputs due to the limited 3D speech-gesture\ndata. In this paper, we propose CoCoGesture, a novel framework enabling vivid\nand diverse gesture synthesis from unseen human speech prompts. Our key insight\nis built upon the custom-designed pretrain-fintune training paradigm. At the\npretraining stage, we aim to formulate a large generalizable gesture diffusion\nmodel by learning the abundant postures manifold. Therefore, to alleviate the\nscarcity of 3D data, we first construct a large-scale co-speech 3D gesture\ndataset containing more than 40M meshed posture instances across 4.3K speakers,\ndubbed GES-X. Then, we scale up the large unconditional diffusion model to 1B\nparameters and pre-train it to be our gesture experts. At the finetune stage,\nwe present the audio ControlNet that incorporates the human voice as condition\nprompts to guide the gesture generation. Here, we construct the audio\nControlNet through a trainable copy of our pre-trained diffusion model.\nMoreover, we design a novel Mixture-of-Gesture-Experts (MoGE) block to\nadaptively fuse the audio embedding from the human speech and the gesture\nfeatures from the pre-trained gesture experts with a routing mechanism. Such an\neffective manner ensures audio embedding is temporal coordinated with motion\nfeatures while preserving the vivid and diverse gesture generation. Extensive\nexperiments demonstrate that our proposed CoCoGesture outperforms the\nstate-of-the-art methods on the zero-shot speech-to-gesture generation. The\ndataset will be publicly available at: https://mattie-e.github.io/GES-X/",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xingqun Qi",
            "Hengyuan Zhang",
            "Yatian Wang",
            "Jiahao Pan",
            "Chen Liu",
            "Peng Li",
            "Xiaowei Chi",
            "Mengfei Li",
            "Qixun Zhang",
            "Wei Xue",
            "Shanghang Zhang",
            "Wenhan Luo",
            "Qifeng Liu",
            "Yike Guo"
        ],
        "published": "2024-05-27T06:47:14Z"
    },
    {
        "title": "ContrastAlign: Toward Robust BEV Feature Alignment via Contrastive\n  Learning for Multi-Modal 3D Object Detection",
        "link": "http://arxiv.org/abs/2405.16873v1",
        "abstract": "In the field of 3D object detection tasks, fusing heterogeneous features from\nLiDAR and camera sensors into a unified Bird's Eye View (BEV) representation is\na widely adopted paradigm. However, existing methods are often compromised by\nimprecise sensor calibration, resulting in feature misalignment in LiDAR-camera\nBEV fusion. Moreover, such inaccuracies result in errors in depth estimation\nfor the camera branch, ultimately causing misalignment between LiDAR and camera\nBEV features. In this work, we propose a novel ContrastAlign approach that\nutilizes contrastive learning to enhance the alignment of heterogeneous\nmodalities, thereby improving the robustness of the fusion process.\nSpecifically, our approach includes the L-Instance module, which directly\noutputs LiDAR instance features within LiDAR BEV features. Then, we introduce\nthe C-Instance module, which predicts camera instance features through RoI\n(Region of Interest) pooling on the camera BEV features. We propose the\nInstanceFusion module, which utilizes contrastive learning to generate similar\ninstance features across heterogeneous modalities. We then use graph matching\nto calculate the similarity between the neighboring camera instance features\nand the similarity instance features to complete the alignment of instance\nfeatures. Our method achieves state-of-the-art performance, with an mAP of\n70.3%, surpassing BEVFusion by 1.8% on the nuScenes validation set.\nImportantly, our method outperforms BEVFusion by 7.3% under conditions with\nmisalignment noise.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ziying Song",
            "Feiyang Jia",
            "Hongyu Pan",
            "Yadan Luo",
            "Caiyan Jia",
            "Guoxin Zhang",
            "Lin Liu",
            "Yang Ji",
            "Lei Yang",
            "Li Wang"
        ],
        "published": "2024-05-27T06:43:12Z"
    },
    {
        "title": "Multi-Behavior Generative Recommendation",
        "link": "http://arxiv.org/abs/2405.16871v1",
        "abstract": "Multi-behavior sequential recommendation (MBSR) aims to incorporate behavior\ntypes of interactions for better recommendations. Existing approaches focus on\nthe next-item prediction objective, neglecting the value of integrating the\ntarget behavior type into the learning objective. In this paper, we propose\nMBGen, a novel Multi-Behavior sequential Generative recommendation framework.\nWe formulate the MBSR task into a consecutive two-step process: (1) given item\nsequences, MBGen first predicts the next behavior type to frame the user\nintention, (2) given item sequences and a target behavior type, MBGen then\npredicts the next items. To model such a two-step process, we tokenize both\nbehaviors and items into tokens and construct one single token sequence with\nboth behaviors and items placed interleaved. Furthermore, MBGen learns to\nautoregressively generate the next behavior and item tokens in a unified\ngenerative recommendation paradigm, naturally enabling a multi-task capability.\nAdditionally, we exploit the heterogeneous nature of token sequences in the\ngenerative recommendation and propose a position-routed sparse architecture to\nefficiently and effectively scale up models. Extensive experiments on public\ndatasets demonstrate that MBGen significantly outperforms existing MBSR models\nacross multiple tasks.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Zihan Liu",
            "Yupeng Hou",
            "Julian McAuley"
        ],
        "published": "2024-05-27T06:39:36Z"
    },
    {
        "title": "Mixture of Modality Knowledge Experts for Robust Multi-modal Knowledge\n  Graph Completion",
        "link": "http://arxiv.org/abs/2405.16869v1",
        "abstract": "Multi-modal knowledge graph completion (MMKGC) aims to automatically discover\nnew knowledge triples in the given multi-modal knowledge graphs (MMKGs), which\nis achieved by collaborative modeling the structural information concealed in\nmassive triples and the multi-modal features of the entities. Existing methods\ntend to focus on crafting elegant entity-wise multi-modal fusion strategies,\nyet they overlook the utilization of multi-perspective features concealed\nwithin the modalities under diverse relational contexts. To address this issue,\nwe introduce a novel MMKGC framework with Mixture of Modality Knowledge experts\n(MoMoK for short) to learn adaptive multi-modal embedding under intricate\nrelational contexts. We design relation-guided modality knowledge experts to\nacquire relation-aware modality embeddings and integrate the predictions from\nmulti-modalities to achieve comprehensive decisions. Additionally, we\ndisentangle the experts by minimizing their mutual information. Experiments on\nfour public MMKG benchmarks demonstrate the outstanding performance of MoMoK\nunder complex scenarios.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Yichi Zhang",
            "Zhuo Chen",
            "Lingbing Guo",
            "Yajing Xu",
            "Binbin Hu",
            "Ziqi Liu",
            "Wen Zhang",
            "Huajun Chen"
        ],
        "published": "2024-05-27T06:36:17Z"
    },
    {
        "title": "RCDN: Towards Robust Camera-Insensitivity Collaborative Perception via\n  Dynamic Feature-based 3D Neural Modeling",
        "link": "http://arxiv.org/abs/2405.16868v1",
        "abstract": "Collaborative perception is dedicated to tackling the constraints of\nsingle-agent perception, such as occlusions, based on the multiple agents'\nmulti-view sensor inputs. However, most existing works assume an ideal\ncondition that all agents' multi-view cameras are continuously available. In\nreality, cameras may be highly noisy, obscured or even failed during the\ncollaboration. In this work, we introduce a new robust camera-insensitivity\nproblem: how to overcome the issues caused by the failed camera perspectives,\nwhile stabilizing high collaborative performance with low calibration cost? To\naddress above problems, we propose RCDN, a Robust Camera-insensitivity\ncollaborative perception with a novel Dynamic feature-based 3D Neural modeling\nmechanism. The key intuition of RCDN is to construct collaborative neural\nrendering field representations to recover failed perceptual messages sent by\nmultiple agents. To better model collaborative neural rendering field, RCDN\nfirst establishes a geometry BEV feature based time-invariant static field with\nother agents via fast hash grid modeling. Based on the static background field,\nthe proposed time-varying dynamic field can model corresponding motion vectors\nfor foregrounds with appropriate positions. To validate RCDN, we create\nOPV2V-N, a new large-scale dataset with manual labelling under different camera\nfailed scenarios. Extensive experiments conducted on OPV2V-N show that RCDN can\nbe ported to other baselines and improve their robustness in extreme\ncamera-insensitivity settings. Our code and datasets will be available soon.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Tianhang Wang",
            "Fan Lu",
            "Zehan Zheng",
            "Guang Chen",
            "Changjun Jiang"
        ],
        "published": "2024-05-27T06:35:55Z"
    },
    {
        "title": "Clustering-based Learning for UAV Tracking and Pose Estimation",
        "link": "http://arxiv.org/abs/2405.16867v1",
        "abstract": "UAV tracking and pose estimation plays an imperative role in various\nUAV-related missions, such as formation control and anti-UAV measures.\nAccurately detecting and tracking UAVs in a 3D space remains a particularly\nchallenging problem, as it requires extracting sparse features of micro UAVs\nfrom different flight environments and continuously matching correspondences,\nespecially during agile flight. Generally, cameras and LiDARs are the two main\ntypes of sensors used to capture UAV trajectories in flight. However, both\nsensors have limitations in UAV classification and pose estimation. This\ntechnical report briefly introduces the method proposed by our team \"NTU-ICG\"\nfor the CVPR 2024 UG2+ Challenge Track 5. This work develops a clustering-based\nlearning detection approach, CL-Det, for UAV tracking and pose estimation using\ntwo types of LiDARs, namely Livox Avia and LiDAR 360. We combine the\ninformation from the two data sources to locate drones in 3D. We first align\nthe timestamps of Livox Avia data and LiDAR 360 data and then separate the\npoint cloud of objects of interest (OOIs) from the environment. The point cloud\nof OOIs is clustered using the DBSCAN method, with the midpoint of the largest\ncluster assumed to be the UAV position. Furthermore, we utilize historical\nestimations to fill in missing data. The proposed method shows competitive pose\nestimation performance and ranks 5th on the final leaderboard of the CVPR 2024\nUG2+ Challenge.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "authors": [
            "Jiaping Xiao",
            "Phumrapee Pisutsin",
            "Cheng Wen Tsao",
            "Mir Feroskhan"
        ],
        "published": "2024-05-27T06:33:25Z"
    },
    {
        "title": "Hierarchical Rank-One Sequence Convexification for the Relaxation of\n  Variational Problems with Microstructures",
        "link": "http://arxiv.org/abs/2405.16866v1",
        "abstract": "This paper presents an efficient algorithm for the approximation of the\nrank-one convex hull in the context of nonlinear solid mechanics. It is based\non hierarchical rank-one sequences and simultaneously provides first and second\nderivative information essential for the calculation of mechanical stresses and\nthe computational minimization of discretized energies. For materials, whose\nmicrostructure can be well approximated in terms of laminates and where each\nlaminate stage achieves energetic optimality with respect to the current stage,\nthe approximate envelope coincides with the rank-one convex envelope. Although\nthe proposed method provides only an upper bound for the rank-one convex hull,\na careful examination of the resulting constraints shows a decent applicability\nin mechanical problems. Various aspects of the algorithm are discussed,\nincluding the restoration of rotational invariance, microstructure\nreconstruction, comparisons with other semi-convexification algorithms, and\nmesh independency. Overall, this paper demonstrates the efficiency of the\nalgorithm for both, well-established mathematical benchmark problems as well as\nnonconvex isotropic finite-strain continuum damage models in two and three\ndimensions. Thereby, for the first time, a feasible concurrent numerical\nrelaxation is established for an incremental, dissipative large-strain model\nwith relevant applications in engineering problems.",
        "subjects": [
            "cs.CE"
        ],
        "authors": [
            "Maximilian Khler",
            "Timo Neumeier",
            "Malte. A. Peter",
            "Daniel Peterseim",
            "Daniel Balzani"
        ],
        "published": "2024-05-27T06:32:36Z"
    },
    {
        "title": "An Investigation of Conformal Isometry Hypothesis for Grid Cells",
        "link": "http://arxiv.org/abs/2405.16865v1",
        "abstract": "This paper investigates the conformal isometry hypothesis as a potential\nexplanation for the emergence of hexagonal periodic patterns in the response\nmaps of grid cells. The hypothesis posits that the activities of the population\nof grid cells form a high-dimensional vector in the neural space, representing\nthe agent's self-position in 2D physical space. As the agent moves in the 2D\nphysical space, the vector rotates in a 2D manifold in the neural space, driven\nby a recurrent neural network. The conformal isometry hypothesis proposes that\nthis 2D manifold in the neural space is a conformally isometric embedding of\nthe 2D physical space, in the sense that local displacements of the vector in\nneural space are proportional to local displacements of the agent in the\nphysical space. Thus the 2D manifold forms an internal map of the 2D physical\nspace, equipped with an internal metric. In this paper, we conduct numerical\nexperiments to show that this hypothesis underlies the hexagon periodic\npatterns of grid cells. We also conduct theoretical analysis to further support\nthis hypothesis. In addition, we propose a conformal modulation of the input\nvelocity of the agent so that the recurrent neural network of grid cells\nsatisfies the conformal isometry hypothesis automatically. To summarize, our\nwork provides numerical and theoretical evidences for the conformal isometry\nhypothesis for grid cells and may serve as a foundation for further development\nof normative models of grid cells and beyond.",
        "subjects": [
            "q-bio.NC",
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Dehong Xu",
            "Ruiqi Gao",
            "Wen-Hao Zhang",
            "Xue-Xin Wei",
            "Ying Nian Wu"
        ],
        "published": "2024-05-27T06:31:39Z"
    },
    {
        "title": "Sparsity comparison of polytopal finite element methods",
        "link": "http://arxiv.org/abs/2405.16864v1",
        "abstract": "In this work we compare crucial parameters for efficiency of different finite\nelement methods for solving partial differential equations (PDEs) on polytopal\nmeshes. We consider the Virtual Element Method (VEM) and different\nDiscontinuous Galerkin (DG) methods, namely the Hybrid DG and Trefftz DG\nmethods. The VEM is a conforming method, that can be seen as a generalization\nof the classic finite element method to arbitrary polytopal meshes. DG methods\nare non-conforming methods that offer high flexibility, but also come with high\ncomputational costs. Hybridization reduces these costs by introducing\nadditional facet variables, onto which the computational costs can be\ntransfered to. Trefftz DG methods achieve a similar reduction in complexity by\nselecting a special and smaller set of basis functions on each element. The\nassociation of computational costs to different geometrical entities (elements\nor facets) leads to differences in the performance of these methods on\ndifferent grid types. This paper aims to compare the dependency of these\napproaches across different grid configurations.",
        "subjects": [
            "math.NA",
            "cs.CC",
            "cs.CE",
            "cs.NA"
        ],
        "authors": [
            "Christoph Lehrenfeld",
            "Paul Stocker",
            "Maximilian Zienecker"
        ],
        "published": "2024-05-27T06:31:07Z"
    },
    {
        "title": "NCIDiff: Non-covalent Interaction-generative Diffusion Model for\n  Improving Reliability of 3D Molecule Generation Inside Protein Pocket",
        "link": "http://arxiv.org/abs/2405.16861v1",
        "abstract": "Advancements in deep generative modeling have changed the paradigm of drug\ndiscovery. Among such approaches, target-aware methods that exploit 3D\nstructures of protein pockets were spotlighted for generating ligand molecules\nwith their plausible binding modes. While docking scores superficially assess\nthe quality of generated ligands, closer inspection of the binding structures\nreveals the inconsistency in local interactions between a pocket and generated\nligands. Here, we address the issue by explicitly generating non-covalent\ninteractions (NCIs), which are universal patterns throughout protein-ligand\ncomplexes. Our proposed model, NCIDiff, simultaneously denoises NCI types of\nprotein-ligand edges along with a 3D graph of a ligand molecule during the\nsampling. With the NCI-generating strategy, our model generates ligands with\nmore reliable NCIs, especially outperforming the baseline diffusion-based\nmodels. We further adopted inpainting techniques on NCIs to further improve the\nquality of the generated molecules. Finally, we showcase the applicability of\nNCIDiff on drug design tasks for real-world settings with specialized\nobjectives by guiding the generation process with desired NCI patterns.",
        "subjects": [
            "q-bio.BM",
            "cs.LG",
            "physics.bio-ph"
        ],
        "authors": [
            "Joongwon Lee",
            "Wonho Zhung",
            "Woo Youn Kim"
        ],
        "published": "2024-05-27T06:26:55Z"
    },
    {
        "title": "Think Before You Act: A Two-Stage Framework for Mitigating Gender Bias\n  Towards Vision-Language Tasks",
        "link": "http://arxiv.org/abs/2405.16860v1",
        "abstract": "Gender bias in vision-language models (VLMs) can reinforce harmful\nstereotypes and discrimination. In this paper, we focus on mitigating gender\nbias towards vision-language tasks. We identify object hallucination as the\nessence of gender bias in VLMs. Existing VLMs tend to focus on salient or\nfamiliar attributes in images but ignore contextualized nuances. Moreover, most\nVLMs rely on the co-occurrence between specific objects and gender attributes\nto infer the ignored features, ultimately resulting in gender bias. We propose\nGAMA, a task-agnostic generation framework to mitigate gender bias. GAMA\nconsists of two stages: narrative generation and answer inference. During\nnarrative generation, GAMA yields all-sided but gender-obfuscated narratives,\nwhich prevents premature concentration on localized image features, especially\ngender attributes. During answer inference, GAMA integrates the image,\ngenerated narrative, and a task-specific question prompt to infer answers for\ndifferent vision-language tasks. This approach allows the model to rethink\ngender attributes and answers. We conduct extensive experiments on GAMA,\ndemonstrating its debiasing and generalization ability.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Yunqi Zhang",
            "Songda Li",
            "Chunyuan Deng",
            "Luyi Wang",
            "Hui Zhao"
        ],
        "published": "2024-05-27T06:20:58Z"
    },
    {
        "title": "Estimating Depth of Monocular Panoramic Image with Teacher-Student Model\n  Fusing Equirectangular and Spherical Representations",
        "link": "http://arxiv.org/abs/2405.16858v1",
        "abstract": "Disconnectivity and distortion are the two problems which must be coped with\nwhen processing 360 degrees equirectangular images. In this paper, we propose a\nmethod of estimating the depth of monocular panoramic image with a\nteacher-student model fusing equirectangular and spherical representations. In\ncontrast with the existing methods fusing an equirectangular representation\nwith a cube map representation or tangent representation, a spherical\nrepresentation is a better choice because a sampling on a sphere is more\nuniform and can also cope with distortion more effectively. In this processing,\na novel spherical convolution kernel computing with sampling points on a sphere\nis developed to extract features from the spherical representation, and then, a\nSegmentation Feature Fusion(SFF) methodology is utilized to combine the\nfeatures with ones extracted from the equirectangular representation. In\ncontrast with the existing methods using a teacher-student model to obtain a\nlighter model of depth estimation, we use a teacher-student model to learn the\nlatent features of depth images. This results in a trained model which\nestimates the depth map of an equirectangular image using not only the feature\nmaps extracted from an input equirectangular image but also the distilled\nknowledge learnt from the ground truth of depth map of a training set. In\nexperiments, the proposed method is tested on several well-known 360 monocular\ndepth estimation benchmark datasets, and outperforms the existing methods for\nthe most evaluation indexes.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jingguo Liu",
            "Yijun Xu",
            "Shigang Li",
            "Jianfeng Li"
        ],
        "published": "2024-05-27T06:11:16Z"
    },
    {
        "title": "Can We Trust LLMs? Mitigate Overconfidence Bias in LLMs through\n  Knowledge Transfer",
        "link": "http://arxiv.org/abs/2405.16856v1",
        "abstract": "The study explores mitigating overconfidence bias in LLMs to improve their\nreliability. We introduce a knowledge transfer (KT) method utilizing chain of\nthoughts, where \"big\" LLMs impart knowledge to \"small\" LLMs via detailed,\nsequential reasoning paths. This method uses advanced reasoning of larger\nmodels to fine-tune smaller models, enabling them to produce more accurate\npredictions with calibrated confidence. Experimental evaluation using\nmultiple-choice questions and sentiment analysis across diverse datasets\ndemonstrated the KT method's superiority over the vanilla and question-answer\npair (QA) fine-tuning methods. The most significant improvement in three key\nmetrics, where the KT method outperformed the vanilla and QA methods by an\naverage of 55.3% and 43.1%, respectively. These findings underscore the KT\nmethod's potential in enhancing model trustworthiness and accuracy, offering\nprecise outputs with well-matched confidence levels across various contexts.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Haoyan Yang",
            "Yixuan Wang",
            "Xingyin Xu",
            "Hanyuan Zhang",
            "Yirong Bian"
        ],
        "published": "2024-05-27T06:06:36Z"
    },
    {
        "title": "Knowing What Not to Do: Leverage Language Model Insights for Action\n  Space Pruning in Multi-agent Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.16854v1",
        "abstract": "Multi-agent reinforcement learning (MARL) is employed to develop autonomous\nagents that can learn to adopt cooperative or competitive strategies within\ncomplex environments. However, the linear increase in the number of agents\nleads to a combinatorial explosion of the action space, which may result in\nalgorithmic instability, difficulty in convergence, or entrapment in local\noptima. While researchers have designed a variety of effective algorithms to\ncompress the action space, these methods also introduce new challenges, such as\nthe need for manually designed prior knowledge or reliance on the structure of\nthe problem, which diminishes the applicability of these techniques. In this\npaper, we introduce Evolutionary action SPAce Reduction with Knowledge\n(eSpark), an exploration function generation framework driven by large language\nmodels (LLMs) to boost exploration and prune unnecessary actions in MARL. Using\njust a basic prompt that outlines the overall task and setting, eSpark is\ncapable of generating exploration functions in a zero-shot manner, identifying\nand pruning redundant or irrelevant state-action pairs, and then achieving\nautonomous improvement from policy feedback. In reinforcement learning tasks\ninvolving inventory management and traffic light control encompassing a total\nof 15 scenarios, eSpark consistently outperforms the combined MARL algorithm in\nall scenarios, achieving an average performance gain of 34.4% and 9.9% in the\ntwo types of tasks respectively. Additionally, eSpark has proven to be capable\nof managing situations with a large number of agents, securing a 29.7%\nimprovement in scalability challenges that featured over 500 agents. The code\ncan be found in https://github.com/LiuZhihao2022/eSpark.git.",
        "subjects": [
            "cs.MA"
        ],
        "authors": [
            "Zhihao Liu",
            "Xianliang Yang",
            "Zichuan Liu",
            "Yifan Xia",
            "Wei Jiang",
            "Yuanyu Zhang",
            "Lijuan Li",
            "Guoliang Fan",
            "Lei Song",
            "Bian Jiang"
        ],
        "published": "2024-05-27T06:00:24Z"
    },
    {
        "title": "EM Distillation for One-step Diffusion Models",
        "link": "http://arxiv.org/abs/2405.16852v1",
        "abstract": "While diffusion models can learn complex distributions, sampling requires a\ncomputationally expensive iterative process. Existing distillation methods\nenable efficient sampling, but have notable limitations, such as performance\ndegradation with very few sampling steps, reliance on training data access, or\nmode-seeking optimization that may fail to capture the full distribution. We\npropose EM Distillation (EMD), a maximum likelihood-based approach that\ndistills a diffusion model to a one-step generator model with minimal loss of\nperceptual quality. Our approach is derived through the lens of\nExpectation-Maximization (EM), where the generator parameters are updated using\nsamples from the joint distribution of the diffusion teacher prior and inferred\ngenerator latents. We develop a reparametrized sampling scheme and a noise\ncancellation technique that together stabilizes the distillation process. We\nfurther reveal an interesting connection of our method with existing methods\nthat minimize mode-seeking KL. EMD outperforms existing one-step generative\nmethods in terms of FID scores on ImageNet-64 and ImageNet-128, and compares\nfavorably with prior work on distilling text-to-image diffusion models.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Sirui Xie",
            "Zhisheng Xiao",
            "Diederik P Kingma",
            "Tingbo Hou",
            "Ying Nian Wu",
            "Kevin Patrick Murphy",
            "Tim Salimans",
            "Ben Poole",
            "Ruiqi Gao"
        ],
        "published": "2024-05-27T05:55:22Z"
    },
    {
        "title": "Temporal Spiking Neural Networks with Synaptic Delay for Graph Reasoning",
        "link": "http://arxiv.org/abs/2405.16851v1",
        "abstract": "Spiking neural networks (SNNs) are investigated as biologically inspired\nmodels of neural computation, distinguished by their computational capability\nand energy efficiency due to precise spiking times and sparse spikes with\nevent-driven computation. A significant question is how SNNs can emulate\nhuman-like graph-based reasoning of concepts and relations, especially\nleveraging the temporal domain optimally. This paper reveals that SNNs, when\namalgamated with synaptic delay and temporal coding, are proficient in\nexecuting (knowledge) graph reasoning. It is elucidated that spiking time can\nfunction as an additional dimension to encode relation properties via a\nneural-generalized path formulation. Empirical results highlight the efficacy\nof temporal delay in relation processing and showcase exemplary performance in\ndiverse graph reasoning tasks. The spiking model is theoretically estimated to\nachieve $20\\times$ energy savings compared to non-spiking counterparts,\ndeepening insights into the capabilities and potential of biologically inspired\nSNNs for efficient reasoning. The code is available at\nhttps://github.com/pkuxmq/GRSNN.",
        "subjects": [
            "cs.NE",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Mingqing Xiao",
            "Yixin Zhu",
            "Di He",
            "Zhouchen Lin"
        ],
        "published": "2024-05-27T05:53:30Z"
    },
    {
        "title": "UniCompress: Enhancing Multi-Data Medical Image Compression with\n  Knowledge Distillation",
        "link": "http://arxiv.org/abs/2405.16850v1",
        "abstract": "In the field of medical image compression, Implicit Neural Representation\n(INR) networks have shown remarkable versatility due to their flexible\ncompression ratios, yet they are constrained by a one-to-one fitting approach\nthat results in lengthy encoding times. Our novel method,\n``\\textbf{UniCompress}'', innovatively extends the compression capabilities of\nINR by being the first to compress multiple medical data blocks using a single\nINR network. By employing wavelet transforms and quantization, we introduce a\ncodebook containing frequency domain information as a prior input to the INR\nnetwork. This enhances the representational power of INR and provides\ndistinctive conditioning for different image blocks. Furthermore, our research\nintroduces a new technique for the knowledge distillation of implicit\nrepresentations, simplifying complex model knowledge into more manageable\nformats to improve compression ratios. Extensive testing on CT and electron\nmicroscopy (EM) datasets has demonstrated that UniCompress outperforms\ntraditional INR methods and commercial compression solutions like HEVC,\nespecially in complex and high compression scenarios. Notably, compared to\nexisting INR techniques, UniCompress achieves a 4$\\sim$5 times increase in\ncompression speed, marking a significant advancement in the field of medical\nimage compression. Codes will be publicly available.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Runzhao Yang",
            "Yinda Chen",
            "Zhihong Zhang",
            "Xiaoyu Liu",
            "Zongren Li",
            "Kunlun He",
            "Zhiwei Xiong",
            "Jinli Suo",
            "Qionghai Dai"
        ],
        "published": "2024-05-27T05:52:13Z"
    },
    {
        "title": "Sync4D: Video Guided Controllable Dynamics for Physics-Based 4D\n  Generation",
        "link": "http://arxiv.org/abs/2405.16849v1",
        "abstract": "In this work, we introduce a novel approach for creating controllable\ndynamics in 3D-generated Gaussians using casually captured reference videos.\nOur method transfers the motion of objects from reference videos to a variety\nof generated 3D Gaussians across different categories, ensuring precise and\ncustomizable motion transfer. We achieve this by employing blend skinning-based\nnon-parametric shape reconstruction to extract the shape and motion of\nreference objects. This process involves segmenting the reference objects into\nmotion-related parts based on skinning weights and establishing shape\ncorrespondences with generated target shapes. To address shape and temporal\ninconsistencies prevalent in existing methods, we integrate physical\nsimulation, driving the target shapes with matched motion. This integration is\noptimized through a displacement loss to ensure reliable and genuine dynamics.\nOur approach supports diverse reference inputs, including humans, quadrupeds,\nand articulated objects, and can generate dynamics of arbitrary length,\nproviding enhanced fidelity and applicability. Unlike methods heavily reliant\non diffusion video generation models, our technique offers specific and\nhigh-quality motion transfer, maintaining both shape integrity and temporal\nconsistency.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhoujie Fu",
            "Jiacheng Wei",
            "Wenhao Shen",
            "Chaoyue Song",
            "Xiaofeng Yang",
            "Fayao Liu",
            "Xulei Yang",
            "Guosheng Lin"
        ],
        "published": "2024-05-27T05:49:12Z"
    },
    {
        "title": "A re-calibration method for object detection with multi-modal alignment\n  bias in autonomous driving",
        "link": "http://arxiv.org/abs/2405.16848v1",
        "abstract": "Multi-modal object detection in autonomous driving has achieved great\nbreakthroughs due to the usage of fusing complementary information from\ndifferent sensors. The calibration in fusion between sensors such as LiDAR and\ncamera is always supposed to be precise in previous work. However, in reality,\ncalibration matrices are fixed when the vehicles leave the factory, but\nvibration, bumps, and data lags may cause calibration bias. As the research on\nthe calibration influence on fusion detection performance is relatively few,\nflexible calibration dependency multi-sensor detection method has always been\nattractive. In this paper, we conducted experiments on SOTA detection method\nEPNet++ and proved slight bias on calibration can reduce the performance\nseriously. We also proposed a re-calibration model based on semantic\nsegmentation which can be combined with a detection algorithm to improve the\nperformance and robustness of multi-modal calibration bias.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhihang Song",
            "Lihui Peng",
            "Jianming Hu",
            "Danya Yao",
            "Yi Zhang"
        ],
        "published": "2024-05-27T05:46:37Z"
    },
    {
        "title": "TokenUnify: Scalable Autoregressive Visual Pre-training with Mixture\n  Token Prediction",
        "link": "http://arxiv.org/abs/2405.16847v1",
        "abstract": "Autoregressive next-token prediction is a standard pretraining method for\nlarge-scale language models, but its application to vision tasks is hindered by\nthe non-sequential nature of image data, leading to cumulative errors. Most\nvision models employ masked autoencoder (MAE) based pretraining, which faces\nscalability issues. To address these challenges, we introduce\n\\textbf{TokenUnify}, a novel pretraining method that integrates random token\nprediction, next-token prediction, and next-all token prediction. We provide\ntheoretical evidence demonstrating that TokenUnify mitigates cumulative errors\nin visual autoregression. Cooperated with TokenUnify, we have assembled a\nlarge-scale electron microscopy (EM) image dataset with ultra-high resolution,\nideal for creating spatially correlated long sequences. This dataset includes\nover 120 million annotated voxels, making it the largest neuron segmentation\ndataset to date and providing a unified benchmark for experimental validation.\nLeveraging the Mamba network inherently suited for long-sequence modeling on\nthis dataset, TokenUnify not only reduces the computational complexity but also\nleads to a significant 45\\% improvement in segmentation performance on\ndownstream EM neuron segmentation tasks compared to existing methods.\nFurthermore, TokenUnify demonstrates superior scalability over MAE and\ntraditional autoregressive methods, effectively bridging the gap between\npretraining strategies for language and vision models. Code is available at\n\\url{https://github.com/ydchen0806/TokenUnify}.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Yinda Chen",
            "Haoyuan Shi",
            "Xiaoyu Liu",
            "Te Shi",
            "Ruobing Zhang",
            "Dong Liu",
            "Zhiwei Xiong",
            "Feng Wu"
        ],
        "published": "2024-05-27T05:45:51Z"
    },
    {
        "title": "On Mesa-Optimization in Autoregressively Trained Transformers: Emergence\n  and Capability",
        "link": "http://arxiv.org/abs/2405.16845v1",
        "abstract": "Autoregressively trained transformers have brought a profound revolution to\nthe world, especially with their in-context learning (ICL) ability to address\ndownstream tasks. Recently, several studies suggest that transformers learn a\nmesa-optimizer during autoregressive (AR) pretraining to implement ICL. Namely,\nthe forward pass of the trained transformer is equivalent to optimizing an\ninner objective function in-context. However, whether the practical non-convex\ntraining dynamics will converge to the ideal mesa-optimizer is still unclear.\nTowards filling this gap, we investigate the non-convex dynamics of a one-layer\nlinear causal self-attention model autoregressively trained by gradient flow,\nwhere the sequences are generated by an AR process $x_{t+1} = W x_t$. First,\nunder a certain condition of data distribution, we prove that an\nautoregressively trained transformer learns $W$ by implementing one step of\ngradient descent to minimize an ordinary least squares (OLS) problem\nin-context. It then applies the learned $\\widehat{W}$ for next-token\nprediction, thereby verifying the mesa-optimization hypothesis. Next, under the\nsame data conditions, we explore the capability limitations of the obtained\nmesa-optimizer. We show that a stronger assumption related to the moments of\ndata is the sufficient and necessary condition that the learned mesa-optimizer\nrecovers the distribution. Besides, we conduct exploratory analyses beyond the\nfirst data condition and prove that generally, the trained transformer will not\nperform vanilla gradient descent for the OLS problem. Finally, our simulation\nresults verify the theoretical results.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "stat.ML"
        ],
        "authors": [
            "Chenyu Zheng",
            "Wei Huang",
            "Rongzhen Wang",
            "Guoqiang Wu",
            "Jun Zhu",
            "Chongxuan Li"
        ],
        "published": "2024-05-27T05:41:06Z"
    },
    {
        "title": "Non-stochastic Bandits With Evolving Observations",
        "link": "http://arxiv.org/abs/2405.16843v1",
        "abstract": "We introduce a novel online learning framework that unifies and generalizes\npre-established models, such as delayed and corrupted feedback, to encompass\nadversarial environments where action feedback evolves over time. In this\nsetting, the observed loss is arbitrary and may not correlate with the true\nloss incurred, with each round updating previous observations adversarially. We\npropose regret minimization algorithms for both the full-information and bandit\nsettings, with regret bounds quantified by the average feedback accuracy\nrelative to the true loss. Our algorithms match the known regret bounds across\nmany special cases, while also introducing previously unknown bounds.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yogev Bar-On",
            "Yishay Mansour"
        ],
        "published": "2024-05-27T05:32:46Z"
    },
    {
        "title": "Approximation of arbitrarily high-order PDEs by first-order hyperbolic\n  relaxation",
        "link": "http://arxiv.org/abs/2405.16841v1",
        "abstract": "We present a framework for constructing a first-order hyperbolic system whose\nsolution approximates that of a desired higher-order evolution equation.\nConstructions of this kind have received increasing interest in recent years,\nand are potentially useful as either analytical or computational tools for\nunderstanding the corresponding higher-order equation. We perform a systematic\nanalysis of a family of linear model equations and show that for each member of\nthis family there is a stable hyperbolic approximation whose solution converges\nto that of the model equation in a certain limit. We then show through several\nexamples that this approach can be applied successfully to a very wide range of\nnonlinear PDEs of practical interest.",
        "subjects": [
            "math.AP",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "David I. Ketcheson",
            "Abhijit Biswas"
        ],
        "published": "2024-05-27T05:28:40Z"
    },
    {
        "title": "Enhancing Accuracy in Generative Models via Knowledge Transfer",
        "link": "http://arxiv.org/abs/2405.16837v1",
        "abstract": "This paper investigates the accuracy of generative models and the impact of\nknowledge transfer on their generation precision. Specifically, we examine a\ngenerative model for a target task, fine-tuned using a pre-trained model from a\nsource task. Building on the \"Shared Embedding\" concept, which bridges the\nsource and target tasks, we introduce a novel framework for transfer learning\nunder distribution metrics such as the Kullback-Leibler divergence. This\nframework underscores the importance of leveraging inherent similarities\nbetween diverse tasks despite their distinct data distributions. Our theory\nsuggests that the shared structures can augment the generation accuracy for a\ntarget task, reliant on the capability of a source model to identify shared\nstructures and effective knowledge transfer from source to target learning. To\ndemonstrate the practical utility of this framework, we explore the theoretical\nimplications for two specific generative models: diffusion and normalizing\nflows. The results show enhanced performance in both models over their\nnon-transfer counterparts, indicating advancements for diffusion models and\nproviding fresh insights into normalizing flows in transfer and non-transfer\nsettings. These results highlight the significant contribution of knowledge\ntransfer in boosting the generation capabilities of these models.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Xinyu Tian",
            "Xiaotong Shen"
        ],
        "published": "2024-05-27T05:10:49Z"
    },
    {
        "title": "Enhancing Fast Feed Forward Networks with Load Balancing and a Master\n  Leaf Node",
        "link": "http://arxiv.org/abs/2405.16836v1",
        "abstract": "Fast feedforward networks (FFFs) are a class of neural networks that exploit\nthe observation that different regions of the input space activate distinct\nsubsets of neurons in wide networks. FFFs partition the input space into\nseparate sections using a differentiable binary tree of neurons and during\ninference descend the binary tree in order to improve computational efficiency.\nInspired by Mixture of Experts (MoE) research, we propose the incorporation of\nload balancing and Master Leaf techniques into the FFF architecture to improve\nperformance and simplify the training process. We reproduce experiments found\nin literature and present results on FFF models enhanced using these\ntechniques. The proposed architecture and training recipe achieves up to 16.3%\nand 3% absolute classification accuracy increase in training and test accuracy,\nrespectively, compared to the original FFF architecture. Additionally, we\nobserve a smaller variance in the results compared to those reported in prior\nresearch. These findings demonstrate the potential of integrating MoE-inspired\ntechniques into FFFs for developing more accurate and efficient models.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Andreas Charalampopoulos",
            "Nikolas Chatzis",
            "Foivos Ntoulas-Panagiotopoulos",
            "Charilaos Papaioannou",
            "Alexandros Potamianos"
        ],
        "published": "2024-05-27T05:06:24Z"
    },
    {
        "title": "Safe LoRA: the Silver Lining of Reducing Safety Risks when Fine-tuning\n  Large Language Models",
        "link": "http://arxiv.org/abs/2405.16833v1",
        "abstract": "While large language models (LLMs) such as Llama-2 or GPT-4 have shown\nimpressive zero-shot performance, fine-tuning is still necessary to enhance\ntheir performance for customized datasets, domain-specific tasks, or other\nprivate needs. However, fine-tuning all parameters of LLMs requires significant\nhardware resources, which can be impractical for typical users. Therefore,\nparameter-efficient fine-tuning such as LoRA have emerged, allowing users to\nfine-tune LLMs without the need for considerable computing resources, with\nlittle performance degradation compared to fine-tuning all parameters.\nUnfortunately, recent studies indicate that fine-tuning can increase the risk\nto the safety of LLMs, even when data does not contain malicious content. To\naddress this challenge, we propose Safe LoRA, a simple one-liner patch to the\noriginal LoRA implementation by introducing the projection of LoRA weights from\nselected layers to the safety-aligned subspace, effectively reducing the safety\nrisks in LLM fine-tuning while maintaining utility. It is worth noting that\nSafe LoRA is a training-free and data-free approach, as it only requires the\nknowledge of the weights from the base and aligned LLMs. Our extensive\nexperiments demonstrate that when fine-tuning on purely malicious data, Safe\nLoRA retains similar safety performance as the original aligned model.\nMoreover, when the fine-tuning dataset contains a mixture of both benign and\nmalicious data, Safe LoRA mitigates the negative effect made by malicious data\nwhile preserving performance on downstream tasks.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Chia-Yi Hsu",
            "Yu-Lin Tsai",
            "Chih-Hsun Lin",
            "Pin-Yu Chen",
            "Chia-Mu Yu",
            "Chun-Ying Huang"
        ],
        "published": "2024-05-27T05:04:05Z"
    },
    {
        "title": "Structured Graph Network for Constrained Robot Crowd Navigation with Low\n  Fidelity Simulation",
        "link": "http://arxiv.org/abs/2405.16830v2",
        "abstract": "We investigate the feasibility of deploying reinforcement learning (RL)\npolicies for constrained crowd navigation using a low-fidelity simulator. We\nintroduce a representation of the dynamic environment, separating human and\nobstacle representations. Humans are represented through detected states, while\nobstacles are represented as computed point clouds based on maps and robot\nlocalization. This representation enables RL policies trained in a low-fidelity\nsimulator to deploy in real world with a reduced sim2real gap. Additionally, we\npropose a spatio-temporal graph to model the interactions between agents and\nobstacles. Based on the graph, we use attention mechanisms to capture the\nrobot-human, human-human, and human-obstacle interactions. Our method\nsignificantly improves navigation performance in both simulated and real-world\nenvironments. Video demonstrations can be found at\nhttps://sites.google.com/view/constrained-crowdnav/home.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Shuijing Liu",
            "Kaiwen Hong",
            "Neeloy Chakraborty",
            "Katherine Driggs-Campbell"
        ],
        "published": "2024-05-27T04:53:09Z"
    },
    {
        "title": "PyGS: Large-scale Scene Representation with Pyramidal 3D Gaussian\n  Splatting",
        "link": "http://arxiv.org/abs/2405.16829v3",
        "abstract": "Neural Radiance Fields (NeRFs) have demonstrated remarkable proficiency in\nsynthesizing photorealistic images of large-scale scenes. However, they are\noften plagued by a loss of fine details and long rendering durations. 3D\nGaussian Splatting has recently been introduced as a potent alternative,\nachieving both high-fidelity visual results and accelerated rendering\nperformance. Nonetheless, scaling 3D Gaussian Splatting is fraught with\nchallenges. Specifically, large-scale scenes grapples with the integration of\nobjects across multiple scales and disparate viewpoints, which often leads to\ncompromised efficacy as the Gaussians need to balance between detail levels.\nFurthermore, the generation of initialization points via COLMAP from\nlarge-scale dataset is both computationally demanding and prone to incomplete\nreconstructions. To address these challenges, we present Pyramidal 3D Gaussian\nSplatting (PyGS) with NeRF Initialization. Our approach represent the scene\nwith a hierarchical assembly of Gaussians arranged in a pyramidal fashion. The\ntop level of the pyramid is composed of a few large Gaussians, while each\nsubsequent layer accommodates a denser collection of smaller Gaussians. We\neffectively initialize these pyramidal Gaussians through sampling a rapidly\ntrained grid-based NeRF at various frequencies. We group these pyramidal\nGaussians into clusters and use a compact weighting network to dynamically\ndetermine the influence of each pyramid level of each cluster considering\ncamera viewpoint during rendering. Our method achieves a significant\nperformance leap across multiple large-scale datasets and attains a rendering\ntime that is over 400 times faster than current state-of-the-art approaches.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zipeng Wang",
            "Dan Xu"
        ],
        "published": "2024-05-27T04:52:21Z"
    },
    {
        "title": "Kernel-based optimally weighted conformal prediction intervals",
        "link": "http://arxiv.org/abs/2405.16828v1",
        "abstract": "Conformal prediction has been a popular distribution-free framework for\nuncertainty quantification. In this paper, we present a novel conformal\nprediction method for time-series, which we call Kernel-based Optimally\nWeighted Conformal Prediction Intervals (KOWCPI). Specifically, KOWCPI adapts\nthe classic Reweighted Nadaraya-Watson (RNW) estimator for quantile regression\non dependent data and learns optimal data-adaptive weights. Theoretically, we\ntackle the challenge of establishing a conditional coverage guarantee for\nnon-exchangeable data under strong mixing conditions on the non-conformity\nscores. We demonstrate the superior performance of KOWCPI on real time-series\nagainst state-of-the-art methods, where KOWCPI achieves narrower confidence\nintervals without losing coverage.",
        "subjects": [
            "cs.LG",
            "math.ST",
            "stat.ML",
            "stat.TH"
        ],
        "authors": [
            "Jonghyeok Lee",
            "Chen Xu",
            "Yao Xie"
        ],
        "published": "2024-05-27T04:49:41Z"
    },
    {
        "title": "Structure-preserving finite element methods for computing dynamics of\n  rotating Bose-Einstein condensate",
        "link": "http://arxiv.org/abs/2405.16827v1",
        "abstract": "This work is concerned with the construction and analysis of\nstructure-preserving Galerkin methods for computing the dynamics of rotating\nBose-Einstein condensate (BEC) based on the Gross-Pitaevskii equation with\nangular momentum rotation. Due to the presence of the rotation term,\nconstructing finite element methods (FEMs) that preserve both mass and energy\nremains an unresolved issue, particularly in the context of nonconforming FEMs.\nFurthermore, in comparison to existing works, we provide a comprehensive\nconvergence analysis, offering a thorough demonstration of the methods' optimal\nand high-order convergence properties. Finally, extensive numerical results are\npresented to check the theoretical analysis of the structure-preserving\nnumerical method for rotating BEC, and the quantized vortex lattice's behavior\nis scrutinized through a series of numerical tests.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Meng Li",
            "Junjun Wang",
            "Zhen Guan",
            "Zhijie Du"
        ],
        "published": "2024-05-27T04:48:09Z"
    },
    {
        "title": "Unified Editing of Panorama, 3D Scenes, and Videos Through Disentangled\n  Self-Attention Injection",
        "link": "http://arxiv.org/abs/2405.16823v1",
        "abstract": "While text-to-image models have achieved impressive capabilities in image\ngeneration and editing, their application across various modalities often\nnecessitates training separate models. Inspired by existing method of single\nimage editing with self attention injection and video editing with shared\nattention, we propose a novel unified editing framework that combines the\nstrengths of both approaches by utilizing only a basic 2D image text-to-image\n(T2I) diffusion model. Specifically, we design a sampling method that\nfacilitates editing consecutive images while maintaining semantic consistency\nutilizing shared self-attention features during both reference and consecutive\nimage sampling processes. Experimental results confirm that our method enables\nediting across diverse modalities including 3D scenes, videos, and panorama\nimages.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Gihyun Kwon",
            "Jangho Park",
            "Jong Chul Ye"
        ],
        "published": "2024-05-27T04:44:36Z"
    },
    {
        "title": "Vidu4D: Single Generated Video to High-Fidelity 4D Reconstruction with\n  Dynamic Gaussian Surfels",
        "link": "http://arxiv.org/abs/2405.16822v1",
        "abstract": "Video generative models are receiving particular attention given their\nability to generate realistic and imaginative frames. Besides, these models are\nalso observed to exhibit strong 3D consistency, significantly enhancing their\npotential to act as world simulators. In this work, we present Vidu4D, a novel\nreconstruction model that excels in accurately reconstructing 4D (i.e.,\nsequential 3D) representations from single generated videos, addressing\nchallenges associated with non-rigidity and frame distortion. This capability\nis pivotal for creating high-fidelity virtual contents that maintain both\nspatial and temporal coherence. At the core of Vidu4D is our proposed Dynamic\nGaussian Surfels (DGS) technique. DGS optimizes time-varying warping functions\nto transform Gaussian surfels (surface elements) from a static state to a\ndynamically warped state. This transformation enables a precise depiction of\nmotion and deformation over time. To preserve the structural integrity of\nsurface-aligned Gaussian surfels, we design the warped-state geometric\nregularization based on continuous warping fields for estimating normals.\nAdditionally, we learn refinements on rotation and scaling parameters of\nGaussian surfels, which greatly alleviates texture flickering during the\nwarping process and enhances the capture of fine-grained appearance details.\nVidu4D also contains a novel initialization state that provides a proper start\nfor the warping fields in DGS. Equipping Vidu4D with an existing video\ngenerative model, the overall framework demonstrates high-fidelity text-to-4D\ngeneration in both appearance and geometry.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yikai Wang",
            "Xinzhou Wang",
            "Zilong Chen",
            "Zhengyi Wang",
            "Fuchun Sun",
            "Jun Zhu"
        ],
        "published": "2024-05-27T04:43:44Z"
    },
    {
        "title": "Perturbation-Restrained Sequential Model Editing",
        "link": "http://arxiv.org/abs/2405.16821v1",
        "abstract": "Model editing is an emerging field that focuses on updating the knowledge\nembedded within large language models (LLMs) without extensive retraining.\nHowever, current model editing methods significantly compromise the general\nabilities of LLMs as the number of edits increases, and this trade-off poses a\nsubstantial challenge to the continual learning of LLMs. In this paper, we\nfirst theoretically analyze that the factor affecting the general abilities in\nsequential model editing lies in the condition number of the edited matrix. The\ncondition number of a matrix represents its numerical sensitivity, and\ntherefore can be used to indicate the extent to which the original knowledge\nassociations stored in LLMs are perturbed after editing. Subsequently,\nstatistical findings demonstrate that the value of this factor becomes larger\nas the number of edits increases, thereby exacerbating the deterioration of\ngeneral abilities. To this end, a framework termed Perturbation Restraint on\nUpper bouNd for Editing (PRUNE) is proposed, which applies the condition number\nrestraints in sequential editing. These restraints can lower the upper bound on\nperturbation to edited models, thus preserving the general abilities.\nSystematically, we conduct experiments employing three popular editing methods\non three LLMs across four representative downstream tasks. Evaluation results\nshow that PRUNE can preserve considerable general abilities while maintaining\nthe editing performance effectively in sequential model editing. The code and\ndata are available at https://github.com/mjy1111/PRUNE.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Jun-Yu Ma",
            "Hong Wang",
            "Hao-Xiang Xu",
            "Zhen-Hua Ling",
            "Jia-Chen Gu"
        ],
        "published": "2024-05-27T04:40:56Z"
    },
    {
        "title": "Laboratory-Scale AI: Open-Weight Models are Competitive with ChatGPT\n  Even in Low-Resource Settings",
        "link": "http://dx.doi.org/10.1145/3630106.3658966",
        "abstract": "The rapid proliferation of generative AI has raised questions about the\ncompetitiveness of lower-parameter, locally tunable, open-weight models\nrelative to high-parameter, API-guarded, closed-weight models in terms of\nperformance, domain adaptation, cost, and generalization. Centering\nunder-resourced yet risk-intolerant settings in government, research, and\nhealthcare, we see for-profit closed-weight models as incompatible with\nrequirements for transparency, privacy, adaptability, and standards of\nevidence. Yet the performance penalty in using open-weight models, especially\nin low-data and low-resource settings, is unclear.\n  We assess the feasibility of using smaller, open-weight models to replace\nGPT-4-Turbo in zero-shot, few-shot, and fine-tuned regimes, assuming access to\nonly a single, low-cost GPU. We assess value-sensitive issues around bias,\nprivacy, and abstention on three additional tasks relevant to those topics. We\nfind that with relatively low effort, very low absolute monetary cost, and\nrelatively little data for fine-tuning, small open-weight models can achieve\ncompetitive performance in domain-adapted tasks without sacrificing generality.\nWe then run experiments considering practical issues in bias, privacy, and\nhallucination risk, finding that open models offer several benefits over closed\nmodels. We intend this work as a case study in understanding the opportunity\ncost of reproducibility and transparency over for-profit state-of-the-art zero\nshot performance, finding this cost to be marginal under realistic settings.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CY",
            "cs.HC"
        ],
        "authors": [
            "Robert Wolfe",
            "Isaac Slaughter",
            "Bin Han",
            "Bingbing Wen",
            "Yiwei Yang",
            "Lucas Rosenblatt",
            "Bernease Herman",
            "Eva Brown",
            "Zening Qu",
            "Nic Weber",
            "Bill Howe"
        ],
        "published": "2024-05-27T04:38:10Z"
    },
    {
        "title": "Automatic Domain Adaptation by Transformers in In-Context Learning",
        "link": "http://arxiv.org/abs/2405.16819v1",
        "abstract": "Selecting or designing an appropriate domain adaptation algorithm for a given\nproblem remains challenging. This paper presents a Transformer model that can\nprovably approximate and opt for domain adaptation methods for a given dataset\nin the in-context learning framework, where a foundation model performs new\ntasks without updating its parameters at test time. Specifically, we prove that\nTransformers can approximate instance-based and feature-based unsupervised\ndomain adaptation algorithms and automatically select an algorithm suited for a\ngiven dataset. Numerical results indicate that in-context learning demonstrates\nan adaptive domain adaptation surpassing existing methods.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Ryuichiro Hataya",
            "Kota Matsui",
            "Masaaki Imaizumi"
        ],
        "published": "2024-05-27T04:33:53Z"
    },
    {
        "title": "Advancing Behavior Generation in Mobile Robotics through High-Fidelity\n  Procedural Simulations",
        "link": "http://arxiv.org/abs/2405.16818v1",
        "abstract": "This paper introduces YamaS, a simulator integrating Unity3D Engine with\nRobotic Operating System for robot navigation research and aims to facilitate\nthe development of both Deep Reinforcement Learning (Deep-RL) and Natural\nLanguage Processing (NLP). It supports single and multi-agent configurations\nwith features like procedural environment generation, RGB vision, and dynamic\nobstacle navigation. Unique to YamaS is its ability to construct single and\nmulti-agent environments, as well as generating agent's behaviour through\ntextual descriptions. The simulator's fidelity is underscored by comparisons\nwith the real-world Yamabiko Beego robot, demonstrating high accuracy in sensor\nsimulations and spatial reasoning. Moreover, YamaS integrates Virtual Reality\n(VR) to augment Human-Robot Interaction (HRI) studies, providing an immersive\nplatform for developers and researchers. This fusion establishes YamaS as a\nversatile and valuable tool for the development and testing of autonomous\nsystems, contributing to the fields of robot simulation and AI-driven training\nmethodologies.",
        "subjects": [
            "cs.RO",
            "cs.HC"
        ],
        "authors": [
            "Victor A. Kich",
            "Jair A. Bottega",
            "Raul Steinmetz",
            "Ricardo B. Grando",
            "Ayanori Yorozu",
            "Akihisa Ohya"
        ],
        "published": "2024-05-27T04:31:55Z"
    },
    {
        "title": "Controlling Rate, Distortion, and Realism: Towards a Single\n  Comprehensive Neural Image Compression Model",
        "link": "http://dx.doi.org/10.1109/WACV57701.2024.00288",
        "abstract": "In recent years, neural network-driven image compression (NIC) has gained\nsignificant attention. Some works adopt deep generative models such as GANs and\ndiffusion models to enhance perceptual quality (realism). A critical obstacle\nof these generative NIC methods is that each model is optimized for a single\nbit rate. Consequently, multiple models are required to compress images to\ndifferent bit rates, which is impractical for real-world applications. To\ntackle this issue, we propose a variable-rate generative NIC model.\nSpecifically, we explore several discriminator designs tailored for the\nvariable-rate approach and introduce a novel adversarial loss. Moreover, by\nincorporating the newly proposed multi-realism technique, our method allows the\nusers to adjust the bit rate, distortion, and realism with a single model,\nachieving ultra-controllability. Unlike existing variable-rate generative NIC\nmodels, our method matches or surpasses the performance of state-of-the-art\nsingle-rate generative NIC models while covering a wide range of bit rates\nusing just one model. Code will be available at https://github.com/iwa-shi/CRDR",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Shoma Iwai",
            "Tomo Miyazaki",
            "Shinichiro Omachi"
        ],
        "published": "2024-05-27T04:22:25Z"
    },
    {
        "title": "Image-level Regression for Uncertainty-aware Retinal Image Segmentation",
        "link": "http://arxiv.org/abs/2405.16815v1",
        "abstract": "Accurate retinal vessel segmentation is a crucial step in the quantitative\nassessment of retinal vasculature, which is needed for the early detection of\nretinal diseases and other conditions. Numerous studies have been conducted to\ntackle the problem of segmenting vessels automatically using a pixel-wise\nclassification approach. The common practice of creating ground truth labels is\nto categorize pixels as foreground and background. This approach is, however,\nbiased, and it ignores the uncertainty of a human annotator when it comes to\nannotating e.g. thin vessels. In this work, we propose a simple and effective\nmethod that casts the retinal image segmentation task as an image-level\nregression. For this purpose, we first introduce a novel Segmentation\nAnnotation Uncertainty-Aware (SAUNA) transform, which adds pixel uncertainty to\nthe ground truth using the pixel's closeness to the annotation boundary and\nvessel thickness. To train our model with soft labels, we generalize the\nearlier proposed Jaccard metric loss to arbitrary hypercubes, which is a second\ncontribution of this work. The proposed SAUNA transform and the new theoretical\nresults allow us to directly train a standard U-Net-like architecture at the\nimage level, outperforming all recently published methods. We conduct thorough\nexperiments and compare our method to a diverse set of baselines across 5\nretinal image datasets. Our implementation is available at\n\\url{https://github.com/Oulu-IMEDS/SAUNA}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Trung Dang",
            "Huy Hoang Nguyen",
            "Aleksei Tiulpin"
        ],
        "published": "2024-05-27T04:17:10Z"
    },
    {
        "title": "SiNGR: Brain Tumor Segmentation via Signed Normalized Geodesic Transform\n  Regression",
        "link": "http://arxiv.org/abs/2405.16813v1",
        "abstract": "One of the primary challenges in brain tumor segmentation arises from the\nuncertainty of voxels close to tumor boundaries. However, the conventional\nprocess of generating ground truth segmentation masks fails to treat such\nuncertainties properly. Those ``hard labels'' with 0s and 1s conceptually\ninfluenced the majority of prior studies on brain image segmentation. As a\nresult, tumor segmentation is often solved through voxel classification. In\nthis work, we instead view this problem as a voxel-level regression, where the\nground truth represents a certainty mapping from any pixel based on the\ndistance to tumor border. We propose a novel ground truth label transformation,\nwhich is based on a signed geodesic transform, to capture the uncertainty in\nbrain tumors' vicinity, while maintaining a margin between positive and\nnegative samples. We combine this idea with a Focal-like regression L1-loss\nthat enables effective regression learning in high-dimensional output space by\nappropriately weighting voxels according to their difficulty. We thoroughly\nconduct an experimental evaluation to validate the components of our proposed\nmethod, compare it to a diverse array of state-of-the-art segmentation models,\nand show that it is architecture-agnostic. The code of our method is made\npublicly available (\\url{https://github.com/Oulu-IMEDS/SiNGR/}).",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Trung Dang",
            "Huy Hoang Nguyen",
            "Aleksei Tiulpin"
        ],
        "published": "2024-05-27T04:14:20Z"
    },
    {
        "title": "Performance evaluation of Reddit Comments using Machine Learning and\n  Natural Language Processing methods in Sentiment Analysis",
        "link": "http://arxiv.org/abs/2405.16810v2",
        "abstract": "Sentiment analysis, an increasingly vital field in both academia and\nindustry, plays a pivotal role in machine learning applications, particularly\non social media platforms like Reddit. However, the efficacy of sentiment\nanalysis models is hindered by the lack of expansive and fine-grained emotion\ndatasets. To address this gap, our study leverages the GoEmotions dataset,\ncomprising a diverse range of emotions, to evaluate sentiment analysis methods\nacross a substantial corpus of 58,000 comments. Distinguished from prior\nstudies by the Google team, which limited their analysis to only two models,\nour research expands the scope by evaluating a diverse array of models. We\ninvestigate the performance of traditional classifiers such as Naive Bayes and\nSupport Vector Machines (SVM), as well as state-of-the-art transformer-based\nmodels including BERT, RoBERTa, and GPT. Furthermore, our evaluation criteria\nextend beyond accuracy to encompass nuanced assessments, including hierarchical\nclassification based on varying levels of granularity in emotion\ncategorization. Additionally, considerations such as computational efficiency\nare incorporated to provide a comprehensive evaluation framework. Our findings\nreveal that the RoBERTa model consistently outperforms the baseline models,\ndemonstrating superior accuracy in fine-grained sentiment classification tasks.\nThis underscores the substantial potential and significance of the RoBERTa\nmodel in advancing sentiment analysis capabilities.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Xiaoxia Zhang",
            "Xiuyuan Qi",
            "Zixin Teng"
        ],
        "published": "2024-05-27T03:59:28Z"
    },
    {
        "title": "Trajectory Data Suffices for Statistically Efficient Learning in Offline\n  RL with Linear $q^$-Realizability and Concentrability",
        "link": "http://arxiv.org/abs/2405.16809v1",
        "abstract": "We consider offline reinforcement learning (RL) in $H$-horizon Markov\ndecision processes (MDPs) under the linear $q^\\pi$-realizability assumption,\nwhere the action-value function of every policy is linear with respect to a\ngiven $d$-dimensional feature function. The hope in this setting is that\nlearning a good policy will be possible without requiring a sample size that\nscales with the number of states in the MDP. Foster et al. [2021] have shown\nthis to be impossible even under $\\textit{concentrability}$, a data coverage\nassumption where a coefficient $C_\\text{conc}$ bounds the extent to which the\nstate-action distribution of any policy can veer off the data distribution.\nHowever, the data in this previous work was in the form of a sequence of\nindividual transitions. This leaves open the question of whether the negative\nresult mentioned could be overcome if the data was composed of sequences of\nfull trajectories. In this work we answer this question positively by proving\nthat with trajectory data, a dataset of size\n$\\text{poly}(d,H,C_\\text{conc})/\\epsilon^2$ is sufficient for deriving an\n$\\epsilon$-optimal policy, regardless of the size of the state space. The main\ntool that makes this result possible is due to Weisz et al. [2023], who\ndemonstrate that linear MDPs can be used to approximate linearly\n$q^\\pi$-realizable MDPs. The connection to trajectory data is that the linear\nMDP approximation relies on \"skipping\" over certain states. The associated\nestimation problems are thus easy when working with trajectory data, while they\nremain nontrivial when working with individual transitions. The question of\ncomputational efficiency under our assumptions remains open.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Volodymyr Tkachuk",
            "Gellrt Weisz",
            "Csaba Szepesvri"
        ],
        "published": "2024-05-27T03:59:13Z"
    },
    {
        "title": "Extreme Compression of Adaptive Neural Images",
        "link": "http://arxiv.org/abs/2405.16807v1",
        "abstract": "Implicit Neural Representations (INRs) and Neural Fields are a novel paradigm\nfor signal representation, from images and audio to 3D scenes and videos. The\nfundamental idea is to represent a signal as a continuous and differentiable\nneural network. This idea offers unprecedented benefits such as continuous\nresolution and memory efficiency, enabling new compression techniques. However,\nrepresenting data as neural networks poses new challenges. For instance, given\na 2D image as a neural network, how can we further compress such a neural\nimage?. In this work, we present a novel analysis on compressing neural fields,\nwith the focus on images. We also introduce Adaptive Neural Images (ANI), an\nefficient neural representation that enables adaptation to different inference\nor transmission requirements. Our proposed method allows to reduce the\nbits-per-pixel (bpp) of the neural image by 4x, without losing sensitive\ndetails or harming fidelity. We achieve this thanks to our successful\nimplementation of 4-bit neural representations. Our work offers a new framework\nfor developing compressed neural fields.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR",
            "cs.MM"
        ],
        "authors": [
            "Leo Hoshikawa",
            "Marcos V. Conde",
            "Takeshi Ohashi",
            "Atsushi Irie"
        ],
        "published": "2024-05-27T03:54:09Z"
    },
    {
        "title": "Entity Alignment with Noisy Annotations from Large Language Models",
        "link": "http://arxiv.org/abs/2405.16806v2",
        "abstract": "Entity alignment (EA) aims to merge two knowledge graphs (KGs) by identifying\nequivalent entity pairs. While existing methods heavily rely on human-generated\nlabels, it is prohibitively expensive to incorporate cross-domain experts for\nannotation in real-world scenarios. The advent of Large Language Models (LLMs)\npresents new avenues for automating EA with annotations, inspired by their\ncomprehensive capability to process semantic information. However, it is\nnontrivial to directly apply LLMs for EA since the annotation space in\nreal-world KGs is large. LLMs could also generate noisy labels that may mislead\nthe alignment. To this end, we propose a unified framework, LLM4EA, to\neffectively leverage LLMs for EA. Specifically, we design a novel active\nlearning policy to significantly reduce the annotation space by prioritizing\nthe most valuable entities based on the entire inter-KG and intra-KG structure.\nMoreover, we introduce an unsupervised label refiner to continuously enhance\nlabel accuracy through in-depth probabilistic reasoning. We iteratively\noptimize the policy based on the feedback from a base EA model. Extensive\nexperiments demonstrate the advantages of LLM4EA on four benchmark datasets in\nterms of effectiveness, robustness, and efficiency. Codes are available via\nhttps://github.com/chensyCN/llm4ea_official.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Shengyuan Chen",
            "Qinggang Zhang",
            "Junnan Dong",
            "Wen Hua",
            "Qing Li",
            "Xiao Huang"
        ],
        "published": "2024-05-27T03:52:55Z"
    },
    {
        "title": "Gradient Compressed Sensing: A Query-Efficient Gradient Estimator for\n  High-Dimensional Zeroth-Order Optimization",
        "link": "http://arxiv.org/abs/2405.16805v1",
        "abstract": "We study nonconvex zeroth-order optimization (ZOO) in a high-dimensional\nspace $\\mathbb R^d$ for functions with approximately $s$-sparse gradients. To\nreduce the dependence on the dimensionality $d$ in the query complexity,\nhigh-dimensional ZOO methods seek to leverage gradient sparsity to design\ngradient estimators. The previous best method needs $O\\big(s\\log\\frac ds\\big)$\nqueries per step to achieve $O\\big(\\frac1T\\big)$ rate of convergence w.r.t. the\nnumber T of steps. In this paper, we propose *Gradient Compressed Sensing*\n(GraCe), a query-efficient and accurate estimator for sparse gradients that\nuses only $O\\big(s\\log\\log\\frac ds\\big)$ queries per step and still achieves\n$O\\big(\\frac1T\\big)$ rate of convergence. To our best knowledge, we are the\nfirst to achieve a *double-logarithmic* dependence on $d$ in the query\ncomplexity under weaker assumptions. Our proposed GraCe generalizes the\nIndyk--Price--Woodruff (IPW) algorithm in compressed sensing from linear\nmeasurements to nonlinear functions. Furthermore, since the IPW algorithm is\npurely theoretical due to its impractically large constant, we improve the IPW\nalgorithm via our *dependent random partition* technique together with our\ncorresponding novel analysis and successfully reduce the constant by a factor\nof nearly 4300. Our GraCe is not only theoretically query-efficient but also\nachieves strong empirical performance. We benchmark our GraCe against 12\nexisting ZOO methods with 10000-dimensional functions and demonstrate that\nGraCe significantly outperforms existing methods.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ruizhong Qiu",
            "Hanghang Tong"
        ],
        "published": "2024-05-27T03:52:53Z"
    },
    {
        "title": "TIE: Revolutionizing Text-based Image Editing for Complex-Prompt\n  Following and High-Fidelity Editing",
        "link": "http://arxiv.org/abs/2405.16803v1",
        "abstract": "As the field of image generation rapidly advances, traditional diffusion\nmodels and those integrated with multimodal large language models (LLMs) still\nencounter limitations in interpreting complex prompts and preserving image\nconsistency pre and post-editing. To tackle these challenges, we present an\ninnovative image editing framework that employs the robust Chain-of-Thought\n(CoT) reasoning and localizing capabilities of multimodal LLMs to aid diffusion\nmodels in generating more refined images. We first meticulously design a CoT\nprocess comprising instruction decomposition, region localization, and detailed\ndescription. Subsequently, we fine-tune the LISA model, a lightweight\nmultimodal LLM, using the CoT process of Multimodal LLMs and the mask of the\nedited image. By providing the diffusion models with knowledge of the generated\nprompt and image mask, our models generate images with a superior understanding\nof instructions. Through extensive experiments, our model has demonstrated\nsuperior performance in image generation, surpassing existing state-of-the-art\nmodels. Notably, our model exhibits an enhanced ability to understand complex\nprompts and generate corresponding images, while maintaining high fidelity and\nconsistency in images before and after generation.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xinyu Zhang",
            "Mengxue Kang",
            "Fei Wei",
            "Shuang Xu",
            "Yuhe Liu",
            "Lin Ma"
        ],
        "published": "2024-05-27T03:50:37Z"
    },
    {
        "title": "AutoCV: Empowering Reasoning with Automated Process Labeling via\n  Confidence Variation",
        "link": "http://arxiv.org/abs/2405.16802v3",
        "abstract": "In this work, we propose a novel method named \\textbf{Auto}mated Process\nLabeling via \\textbf{C}onfidence \\textbf{V}ariation (\\textbf{\\textsc{AutoCV}})\nto enhance the reasoning capabilities of large language models (LLMs) by\nautomatically annotating the reasoning steps. Our approach begins by training a\nverification model on the correctness of final answers, enabling it to generate\nautomatic process annotations. This verification model assigns a confidence\nscore to each reasoning step, indicating the probability of arriving at the\ncorrect final answer from that point onward. We detect relative changes in the\nverification's confidence scores across reasoning steps to automatically\nannotate the reasoning process. This alleviates the need for numerous manual\nannotations or the high computational costs associated with model-induced\nannotation approaches. We experimentally validate that the confidence\nvariations learned by the verification model trained on the final answer\ncorrectness can effectively identify errors in the reasoning steps.\nSubsequently, we demonstrate that the process annotations generated by\n\\textsc{AutoCV} can improve the accuracy of the verification model in selecting\nthe correct answer from multiple outputs generated by LLMs. Notably, we achieve\nsubstantial improvements across five datasets in mathematics and commonsense\nreasoning. The source code of \\textsc{AutoCV} is available at\n\\url{https://github.com/rookie-joe/AUTOCV}.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Jianqiao Lu",
            "Zhiyang Dou",
            "Hongru Wang",
            "Zeyu Cao",
            "Jianbo Dai",
            "Yingjia Wan",
            "Yinya Huang",
            "Zhijiang Guo"
        ],
        "published": "2024-05-27T03:44:24Z"
    },
    {
        "title": "TAGA: Text-Attributed Graph Self-Supervised Learning by Synergizing\n  Graph and Text Mutual Transformations",
        "link": "http://arxiv.org/abs/2405.16800v1",
        "abstract": "Text-Attributed Graphs (TAGs) enhance graph structures with natural language\ndescriptions, enabling detailed representation of data and their relationships\nacross a broad spectrum of real-world scenarios. Despite the potential for\ndeeper insights, existing TAG representation learning primarily relies on\nsupervised methods, necessitating extensive labeled data and limiting\napplicability across diverse contexts. This paper introduces a new\nself-supervised learning framework, Text-And-Graph Multi-View Alignment (TAGA),\nwhich overcomes these constraints by integrating TAGs' structural and semantic\ndimensions. TAGA constructs two complementary views: Text-of-Graph view, which\norganizes node texts into structured documents based on graph topology, and the\nGraph-of-Text view, which converts textual nodes and connections into graph\ndata. By aligning representations from both views, TAGA captures joint textual\nand structural information. In addition, a novel structure-preserving random\nwalk algorithm is proposed for efficient training on large-sized TAGs. Our\nframework demonstrates strong performance in zero-shot and few-shot scenarios\nacross eight real-world datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Zheng Zhang",
            "Yuntong Hu",
            "Bo Pan",
            "Chen Ling",
            "Liang Zhao"
        ],
        "published": "2024-05-27T03:40:16Z"
    },
    {
        "title": "Dual-State Personalized Knowledge Tracing with Emotional Incorporation",
        "link": "http://arxiv.org/abs/2405.16799v1",
        "abstract": "Knowledge tracing has been widely used in online learning systems to guide\nthe students' future learning. However, most existing KT models primarily focus\non extracting abundant information from the question sets and explore the\nrelationships between them, but ignore the personalized student behavioral\ninformation in the learning process. This will limit the model's ability to\naccurately capture the personalized knowledge states of students and reasonably\npredict their performances. To alleviate this limitation, we explicitly models\nthe personalized learning process by incorporating the emotions, a\nrepresentative personalized behavior in the learning process, into KT\nframework. Specifically, we present a novel Dual-State Personalized Knowledge\nTracing with Emotional Incorporation model to achieve this goal: Firstly, we\nincorporate emotional information into the modeling process of knowledge state,\nresulting in the Knowledge State Boosting Module. Secondly, we design an\nEmotional State Tracing Module to monitor students' personalized emotional\nstates, and propose an emotion prediction method based on personalized\nemotional states. Finally, we apply the predicted emotions to enhance students'\nresponse prediction. Furthermore, to extend the generalization capability of\nour model across different datasets, we design a transferred version of DEKT,\nnamed Transfer Learning-based Self-loop model (T-DEKT). Extensive experiments\nshow our method achieves the state-of-the-art performance.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Shanshan Wang",
            "Fangzheng Yuan",
            "Keyang Wang",
            "Xun Yang",
            "Xingyi Zhang",
            "Meng Wang"
        ],
        "published": "2024-05-27T03:39:34Z"
    },
    {
        "title": "Exploring Fairness in Educational Data Mining in the Context of the\n  Right to be Forgotten",
        "link": "http://arxiv.org/abs/2405.16798v2",
        "abstract": "In education data mining (EDM) communities, machine learning has achieved\nremarkable success in discovering patterns and structures to tackle educational\nchallenges. Notably, fairness and algorithmic bias have gained attention in\nlearning analytics of EDM. With the increasing demand for the right to be\nforgotten, there is a growing need for machine learning models to forget\nsensitive data and its impact, particularly within the realm of EDM. The\nparadigm of selective forgetting, also known as machine unlearning, has been\nextensively studied to address this need by eliminating the influence of\nspecific data from a pre-trained model without complete retraining. However,\nexisting research assumes that interactive data removal operations are\nconducted in secure and reliable environments, neglecting potential malicious\nunlearning requests to undermine the fairness of machine learning systems. In\nthis paper, we introduce a novel class of selective forgetting attacks designed\nto compromise the fairness of learning models while maintaining their\npredictive accuracy, thereby preventing the model owner from detecting the\ndegradation in model performance. Additionally, we propose an innovative\noptimization framework for selective forgetting attacks, capable of generating\nmalicious unlearning requests across various attack scenarios. We validate the\neffectiveness of our proposed selective forgetting attacks on fairness through\nextensive experiments using diverse EDM datasets.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Wei Qian",
            "Aobo Chen",
            "Chenxu Zhao",
            "Yangyi Li",
            "Mengdi Huai"
        ],
        "published": "2024-05-27T03:35:50Z"
    },
    {
        "title": "A Real-Time Voice Activity Detection Based On Lightweight Neural",
        "link": "http://arxiv.org/abs/2405.16797v1",
        "abstract": "Voice activity detection (VAD) is the task of detecting speech in an audio\nstream, which is challenging due to numerous unseen noises and low\nsignal-to-noise ratios in real environments. Recently, neural network-based\nVADs have alleviated the degradation of performance to some extent. However,\nthe majority of existing studies have employed excessively large models and\nincorporated future context, while neglecting to evaluate the operational\nefficiency and latency of the models. In this paper, we propose a lightweight\nand real-time neural network called MagicNet, which utilizes casual and depth\nseparable 1-D convolutions and GRU. Without relying on future features as\ninput, our proposed model is compared with two state-of-the-art algorithms on\nsynthesized in-domain and out-domain test datasets. The evaluation results\ndemonstrate that MagicNet can achieve improved performance and robustness with\nfewer parameter costs.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "authors": [
            "Jidong Jia",
            "Pei Zhao",
            "Di Wang"
        ],
        "published": "2024-05-27T03:31:16Z"
    },
    {
        "title": "DualContrast: Unsupervised Disentangling of Content and Transformations\n  with Implicit Parameterization",
        "link": "http://arxiv.org/abs/2405.16796v1",
        "abstract": "Unsupervised disentanglement of content and transformation has recently drawn\nmuch research, given their efficacy in solving downstream unsupervised tasks\nlike clustering, alignment, and shape analysis. This problem is particularly\nimportant for analyzing shape-focused real-world scientific image datasets,\ngiven their significant relevance to downstream tasks. The existing works\naddress the problem by explicitly parameterizing the transformation factors,\nsignificantly reducing their expressiveness. Moreover, they are not applicable\nin cases where transformations can not be readily parametrized. An alternative\nto such explicit approaches is self-supervised methods with data augmentation,\nwhich implicitly disentangles transformations and content. We demonstrate that\nthe existing self-supervised methods with data augmentation result in the poor\ndisentanglement of content and transformations in real-world scenarios.\nTherefore, we developed a novel self-supervised method, DualContrast,\nspecifically for unsupervised disentanglement of content and transformations in\nshape-focused image datasets. Our extensive experiments showcase the\nsuperiority of DualContrast over existing self-supervised and explicit\nparameterization approaches. We leveraged DualContrast to disentangle protein\nidentities and protein conformations in cellular 3D protein images. Moreover,\nwe also disentangled transformations in MNIST, viewpoint in the Linemod Object\ndataset, and human movement deformation in the Starmen dataset as\ntransformations using DualContrast.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Mostofa Rafid Uddin",
            "Min Xu"
        ],
        "published": "2024-05-27T03:31:14Z"
    },
    {
        "title": "Laurel: Generating Dafny Assertions Using Large Language Models",
        "link": "http://arxiv.org/abs/2405.16792v1",
        "abstract": "Dafny is a popular verification language, which automates proofs by\noutsourcing them to an SMT solver. This automation is not perfect, however, and\nthe solver often requires guidance in the form of helper assertions creating a\nburden for the proof engineer. In this paper, we propose Laurel, a tool that\nuses large language models (LLMs) to automatically generate helper assertions\nfor Dafny programs. To improve the success rate of LLMs in this task, we design\ntwo domain-specific prompting techniques. First, we help the LLM determine the\nlocation of the missing assertion by analyzing the verifier's error message and\ninserting an assertion placeholder at that location. Second, we provide the LLM\nwith example assertions from the same codebase, which we select based on a new\nlemma similarity metric. We evaluate our techniques on a dataset of helper\nassertions we extracted from three real-world Dafny codebases. Our evaluation\nshows that Laurel is able to generate over 50% of the required helper\nassertions given only a few attempts, making LLMs a usable and affordable tool\nto further automate practical program verification.",
        "subjects": [
            "cs.LO",
            "cs.AI"
        ],
        "authors": [
            "Eric Mugnier",
            "Emmanuel Anaya Gonzalez",
            "Ranjit Jhala",
            "Nadia Polikarpova",
            "Yuanyuan Zhou"
        ],
        "published": "2024-05-27T03:26:01Z"
    },
    {
        "title": "Joint Node Selection and Resource Allocation Optimization for\n  Cooperative Sensing with a Shared Wireless Backhaul",
        "link": "http://arxiv.org/abs/2405.16791v1",
        "abstract": "In this paper, we consider a cooperative sensing framework in the context of\nfuture multi-functional network with both communication and sensing ability,\nwhere one base station (BS) serves as a sensing transmitter and several nearby\nBSs serve as sensing receivers. Each receiver receives the sensing signal\nreflected by the target and communicates with the fusion center (FC) through a\nwireless multiple access channel (MAC) for cooperative target localization. To\nimprove the localization performance, we present a hybrid information-signal\ndomain cooperative sensing (HISDCS) design, where each sensing receiver\ntransmits both the estimated time delay/effective reflecting coefficient and\nthe received sensing signal sampled around the estimated time delay to the FC.\nThen, we propose to minimize the number of channel uses by utilizing an\nefficient Karhunen-Lo\\'eve transformation (KLT) encoding scheme for signal\nquantization and proper node selection, under the Cram\\'er-Rao lower bound\n(CRLB) constraint and the capacity limits of MAC. A novel matrix-inequality\nconstrained successive convex approximation (MCSCA) algorithm is proposed to\noptimize the wireless backhaul resource allocation, together with a greedy\nstrategy for node selection. Despite the high non-convexness of the considered\nproblem, we prove that the proposed MCSCA algorithm is able to converge to the\nset of Karush-Kuhn-Tucker (KKT) solutions of a relaxed problem obtained by\nrelaxing the discrete variables. Besides, a low-complexity quantization bit\nreallocation algorithm is designed, which does not perform explicit node\nselection, and is able to harvest most of the performance gain brought by\nHISDCS. Finally, numerical simulations are presented to show that the proposed\nHISDCS design is able to significantly outperform the baseline schemes.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Mingxin Chen",
            "Ming-Min Zhao",
            "An Liu",
            "Min Li",
            "Qingjiang Shi"
        ],
        "published": "2024-05-27T03:24:53Z"
    },
    {
        "title": "SCSim: A Realistic Spike Cameras Simulator",
        "link": "http://arxiv.org/abs/2405.16790v1",
        "abstract": "Spike cameras, with their exceptional temporal resolution, are\nrevolutionizing high-speed visual applications. Large-scale synthetic datasets\nhave significantly accelerated the development of these cameras, particularly\nin reconstruction and optical flow. However, current synthetic datasets for\nspike cameras lack sophistication. Addressing this gap, we introduce SCSim, a\nnovel and more realistic spike camera simulator with a comprehensive noise\nmodel. SCSim is adept at autonomously generating driving scenarios and\nsynthesizing corresponding spike streams. To enhance the fidelity of these\nstreams, we've developed a comprehensive noise model tailored to the unique\ncircuitry of spike cameras. Our evaluations demonstrate that SCSim outperforms\nexisting simulation methods in generating authentic spike streams. Crucially,\nSCSim simplifies the creation of datasets, thereby greatly advancing\nspike-based visual tasks like reconstruction. Our project refers to\nhttps://github.com/Acnext/SCSim.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Liwen Hu",
            "Lei Ma",
            "Yijia Guo",
            "Tiejun Huang"
        ],
        "published": "2024-05-27T03:24:34Z"
    },
    {
        "title": "NoteLLM-2: Multimodal Large Representation Models for Recommendation",
        "link": "http://arxiv.org/abs/2405.16789v1",
        "abstract": "Large Language Models (LLMs) have demonstrated exceptional text\nunderstanding. Existing works explore their application in text embedding\ntasks. However, there are few works utilizing LLMs to assist multimodal\nrepresentation tasks. In this work, we investigate the potential of LLMs to\nenhance multimodal representation in multimodal item-to-item (I2I)\nrecommendations. One feasible method is the transfer of Multimodal Large\nLanguage Models (MLLMs) for representation tasks. However, pre-training MLLMs\nusually requires collecting high-quality, web-scale multimodal data, resulting\nin complex training procedures and high costs. This leads the community to rely\nheavily on open-source MLLMs, hindering customized training for representation\nscenarios. Therefore, we aim to design an end-to-end training method that\ncustomizes the integration of any existing LLMs and vision encoders to\nconstruct efficient multimodal representation models. Preliminary experiments\nshow that fine-tuned LLMs in this end-to-end method tend to overlook image\ncontent. To overcome this challenge, we propose a novel training framework,\nNoteLLM-2, specifically designed for multimodal representation. We propose two\nways to enhance the focus on visual information. The first method is based on\nthe prompt viewpoint, which separates multimodal content into visual content\nand textual content. NoteLLM-2 adopts the multimodal In-Content Learning method\nto teach LLMs to focus on both modalities and aggregate key information. The\nsecond method is from the model architecture, utilizing a late fusion mechanism\nto directly fuse visual information into textual information. Extensive\nexperiments have been conducted to validate the effectiveness of our method.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Chao Zhang",
            "Haoxin Zhang",
            "Shiwei Wu",
            "Di Wu",
            "Tong Xu",
            "Yan Gao",
            "Yao Hu",
            "Enhong Chen"
        ],
        "published": "2024-05-27T03:24:01Z"
    },
    {
        "title": "3D Reconstruction with Fast Dipole Sums",
        "link": "http://arxiv.org/abs/2405.16788v3",
        "abstract": "We introduce a technique for the reconstruction of high-fidelity surfaces\nfrom multi-view images. Our technique uses a new point-based representation,\nthe dipole sum, which generalizes the winding number to allow for interpolation\nof arbitrary per-point attributes in point clouds with noisy or outlier points.\nUsing dipole sums allows us to represent implicit geometry and radiance fields\nas per-point attributes of a point cloud, which we initialize directly from\nstructure from motion. We additionally derive Barnes-Hut fast summation schemes\nfor accelerated forward and reverse-mode dipole sum queries. These queries\nfacilitate the use of ray tracing to efficiently and differentiably render\nimages with our point-based representations, and thus update their point\nattributes to optimize scene geometry and appearance. We evaluate this inverse\nrendering framework against state-of-the-art alternatives, based on ray tracing\nof neural representations or rasterization of Gaussian point-based\nrepresentations. Our technique significantly improves reconstruction quality at\nequal runtimes, while also supporting more general rendering techniques such as\nshadow rays for direct illumination. In the supplement, we provide interactive\nvisualizations of our results.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hanyu Chen",
            "Bailey Miller",
            "Ioannis Gkioulekas"
        ],
        "published": "2024-05-27T03:23:25Z"
    },
    {
        "title": "PromptFix: You Prompt and We Fix the Photo",
        "link": "http://arxiv.org/abs/2405.16785v1",
        "abstract": "Diffusion models equipped with language models demonstrate excellent\ncontrollability in image generation tasks, allowing image processing to adhere\nto human instructions. However, the lack of diverse instruction-following data\nhampers the development of models that effectively recognize and execute\nuser-customized instructions, particularly in low-level tasks. Moreover, the\nstochastic nature of the diffusion process leads to deficiencies in image\ngeneration or editing tasks that require the detailed preservation of the\ngenerated images. To address these limitations, we propose PromptFix, a\ncomprehensive framework that enables diffusion models to follow human\ninstructions to perform a wide variety of image-processing tasks. First, we\nconstruct a large-scale instruction-following dataset that covers comprehensive\nimage-processing tasks, including low-level tasks, image editing, and object\ncreation. Next, we propose a high-frequency guidance sampling method to\nexplicitly control the denoising process and preserve high-frequency details in\nunprocessed areas. Finally, we design an auxiliary prompting adapter, utilizing\nVision-Language Models (VLMs) to enhance text prompts and improve the model's\ntask generalization. Experimental results show that PromptFix outperforms\nprevious methods in various image-processing tasks. Our proposed model also\nachieves comparable inference efficiency with these baseline models and\nexhibits superior zero-shot capabilities in blind restoration and combination\ntasks. The dataset and code will be aviliable at\nhttps://github.com/yeates/PromptFix.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yongsheng Yu",
            "Ziyun Zeng",
            "Hang Hua",
            "Jianlong Fu",
            "Jiebo Luo"
        ],
        "published": "2024-05-27T03:13:28Z"
    },
    {
        "title": "The second-order zero differential uniformity of the swapped inverse\n  functions over finite fields",
        "link": "http://arxiv.org/abs/2405.16784v1",
        "abstract": "The Feistel Boomerang Connectivity Table (FBCT) was proposed as the feistel\ncounterpart of the Boomerang Connectivity Table. The entries of the FBCT are\nactually related to the second-order zero differential spectrum. Recently,\nseveral results on the second-order zero differential uniformity of some\nfunctions were introduced. However, almost all of them were focused on power\nfunctions, and there are only few results on non-power functions. In this\npaper, we investigate the second-order zero differential uniformity of the\nswapped inverse functions, which are functions obtained from swapping two\npoints in the inverse function. We also present the second-order zero\ndifferential spectrum of the swapped inverse functions for certain cases. In\nparticular, this paper is the first result to characterize classes of non-power\nfunctions with the second-order zero differential uniformity equal to 4, in\neven characteristic.",
        "subjects": [
            "cs.IT",
            "cs.CR",
            "math.IT"
        ],
        "authors": [
            "Jaeseong Jeong",
            "Namhun Koo",
            "Soonhak Kwon"
        ],
        "published": "2024-05-27T03:11:57Z"
    },
    {
        "title": "TrojFM: Resource-efficient Backdoor Attacks against Very Large\n  Foundation Models",
        "link": "http://arxiv.org/abs/2405.16783v1",
        "abstract": "One key challenge in backdoor attacks against large foundation models is the\nresource limits. Backdoor attacks usually require retraining the target model,\nwhich is impractical for very large foundation models. Existing backdoor\nattacks are mainly designed for supervised classifiers or small foundation\nmodels (e.g., BERT). None of these attacks has successfully compromised a very\nlarge foundation model, such as Llama-3-70B, especially with limited\ncomputational resources. In this paper, we propose TrojFM, a novel backdoor\nattack tailored for very large foundation models. Our primary technical\ncontribution is the development of a novel backdoor injection method. This\nmethod forces a backdoored model to generate similar hidden representations for\npoisoned inputs regardless of their actual semantics. Our approach injects such\nbackdoors by fine-tuning only a very small proportion of model parameters. This\nenables TrojFM to efficiently launch downstream task-agnostic backdoor attacks\nagainst very large foundation models under limited computational resources.\nMoreover, we optimize the fine-tuning process with our customized QLoRA\ntechnique, enabling launching our attack via only~\\textit{one A100 GPU}.\nFurthermore, we design a new trigger injection method to ensure our attack\nstealthiness. Through extensive experiments, we first demonstrate that TrojFM\ncan launch effective backdoor attacks against widely used large GPT-style\nmodels without jeopardizing their normal functionalities (and outperforming\nexisting attacks on BERT-style models). Furthermore, we show that TrojFM is\nresilient to SOTA defenses and is insensitive to changes in key\nhyper-parameters. Finally, we conduct a resource analysis to quantify that our\nmethod can significantly save computational and memory costs compared to\nexisting backdoor attacks.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Yuzhou. Nie",
            "Yanting. Wang",
            "Jinyuan. Jia",
            "Michael J. De Lucia",
            "Nathaniel D. Bastian",
            "Wenbo. Guo",
            "Dawn. Song"
        ],
        "published": "2024-05-27T03:10:57Z"
    },
    {
        "title": "Probabilistic Height Grid Terrain Mapping for Mining Shovels using LiDAR",
        "link": "http://arxiv.org/abs/2405.16774v1",
        "abstract": "This paper explores the question of creating and maintaining terrain maps in\nenvironments where the terrain changes. The specific example explored is the\nconstruction of terrain maps from 3D LiDAR measurements on an electric rope\nshovel. The approach extends the height grid representation of terrain to\ninclude a Hidden Markov Model in each cell, enabling confidence-based mapping\nof constantly changing terrain. There are inherent difficulties in this\nproblem, including semantic labelling of the LiDAR measurements associated with\nmachinery and determining the pose of the sensor. Solutions to both of these\nproblems are explored. The significance of this work lies in the need for\naccurate terrain mapping to support autonomous machine operation.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Vedant Bhandari",
            "Jasmin James",
            "Tyson Phillips",
            "P. Ross McAree"
        ],
        "published": "2024-05-27T03:00:35Z"
    },
    {
        "title": "Balancing User Preferences by Social Networks: A Condition-Guided Social\n  Recommendation Model for Mitigating Popularity Bias",
        "link": "http://arxiv.org/abs/2405.16772v1",
        "abstract": "Social recommendation models weave social interactions into their design to\nprovide uniquely personalized recommendation results for users. However, social\nnetworks not only amplify the popularity bias in recommendation models,\nresulting in more frequent recommendation of hot items and fewer long-tail\nitems, but also include a substantial amount of redundant information that is\nessentially meaningless for the model's performance. Existing social\nrecommendation models fail to address the issues of popularity bias and the\nredundancy of social information, as they directly characterize social\ninfluence across the entire social network without making targeted adjustments.\nIn this paper, we propose a Condition-Guided Social Recommendation Model (named\nCGSoRec) to mitigate the model's popularity bias by denoising the social\nnetwork and adjusting the weights of user's social preferences. More\nspecifically, CGSoRec first includes a Condition-Guided Social Denoising Model\n(CSD) to remove redundant social relations in the social network for capturing\nusers' social preferences with items more precisely. Then, CGSoRec calculates\nusers' social preferences based on denoised social network and adjusts the\nweights in users' social preferences to make them can counteract the popularity\nbias present in the recommendation model. At last, CGSoRec includes a\nCondition-Guided Diffusion Recommendation Model (CGD) to introduce the adjusted\nsocial preferences as conditions to control the recommendation results for a\ndebiased direction. Comprehensive experiments on three real-world datasets\ndemonstrate the effectiveness of our proposed method. The code is in:\nhttps://github.com/hexin5515/CGSoRec.",
        "subjects": [
            "cs.SI",
            "cs.LG"
        ],
        "authors": [
            "Xin He",
            "Wenqi Fan",
            "Ruobing Wang",
            "Yili Wang",
            "Ying Wang",
            "Shirui Pan",
            "Xin Wang"
        ],
        "published": "2024-05-27T02:45:01Z"
    },
    {
        "title": "ARC: A Generalist Graph Anomaly Detector with In-Context Learning",
        "link": "http://arxiv.org/abs/2405.16771v1",
        "abstract": "Graph anomaly detection (GAD), which aims to identify abnormal nodes that\ndiffer from the majority within a graph, has garnered significant attention.\nHowever, current GAD methods necessitate training specific to each dataset,\nresulting in high training costs, substantial data requirements, and limited\ngeneralizability when being applied to new datasets and domains. To address\nthese limitations, this paper proposes ARC, a generalist GAD approach that\nenables a ``one-for-all'' GAD model to detect anomalies across various graph\ndatasets on-the-fly. Equipped with in-context learning, ARC can directly\nextract dataset-specific patterns from the target dataset using few-shot normal\nsamples at the inference stage, without the need for retraining or fine-tuning\non the target dataset. ARC comprises three components that are well-crafted for\ncapturing universal graph anomaly patterns: 1) smoothness-based feature\nAlignment module that unifies the features of different datasets into a common\nand anomaly-sensitive space; 2) ego-neighbor Residual graph encoder that learns\nabnormality-related node embeddings; and 3) cross-attentive in-Context anomaly\nscoring module that predicts node abnormality by leveraging few-shot normal\nsamples. Extensive experiments on multiple benchmark datasets from various\ndomains demonstrate the superior anomaly detection performance, efficiency, and\ngeneralizability of ARC.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yixin Liu",
            "Shiyuan Li",
            "Yu Zheng",
            "Qingfeng Chen",
            "Chengqi Zhang",
            "Shirui Pan"
        ],
        "published": "2024-05-27T02:42:33Z"
    },
    {
        "title": "Physics informed cell representations for variational formulation of\n  multiscale problems",
        "link": "http://arxiv.org/abs/2405.16770v1",
        "abstract": "With the rapid advancement of graphical processing units, Physics-Informed\nNeural Networks (PINNs) are emerging as a promising tool for solving partial\ndifferential equations (PDEs). However, PINNs are not well suited for solving\nPDEs with multiscale features, particularly suffering from slow convergence and\npoor accuracy. To address this limitation of PINNs, this article proposes\nphysics-informed cell representations for resolving multiscale Poisson problems\nusing a model architecture consisting of multilevel multiresolution grids\ncoupled with a multilayer perceptron (MLP). The grid parameters (i.e., the\nlevel-dependent feature vectors) and the MLP parameters (i.e., the weights and\nbiases) are determined using gradient-descent based optimization. The\nvariational (weak) form based loss function accelerates computation by allowing\nthe linear interpolation of feature vectors within grid cells. This cell-based\nMLP model also facilitates the use of a decoupled training scheme for Dirichlet\nboundary conditions and a parameter-sharing scheme for periodic boundary\nconditions, delivering superior accuracy compared to conventional PINNs.\nFurthermore, the numerical examples highlight improved speed and accuracy in\nsolving PDEs with nonlinear or high-frequency boundary conditions and provide\ninsights into hyperparameter selection. In essence, by cell-based MLP model\nalong with the parallel tiny-cuda-nn library, our implementation improves\nconvergence speed and numerical accuracy.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yuxiang Gao",
            "Soheil Kolouri",
            "Ravindra Duddu"
        ],
        "published": "2024-05-27T02:42:16Z"
    },
    {
        "title": "Time-dependent complex variable solution on quasi three-dimensional\n  shallow tunnelling in gravititational geomaterial with reasonable far-field\n  displacement",
        "link": "http://arxiv.org/abs/2405.16768v1",
        "abstract": "Three-dimensional effect of tunnel face and gravitational excavation\ngenerally occur in shallow tunnelling, which are nevertheless not adequately\nconsidered in present complex variable solutions. In this paper, a new\ntime-dependent complex variable solution on quasi three-dimensional shallow\ntunnelling in gravitational geomaterial is derived, and the far-field\ndisplacement singularity is eliminated by fixed far-field ground surface in the\nwhole excavation time span. With an equivalent coefficient of three-dimensional\neffect, the quasi three-dimensional shallow tunnelling is transformed into a\nplane strain problem with time-dependent virtual traction along tunnel\nperiphery. The mixed boundaries of fixed far-field ground surface and nearby\nfree segment form a homogenerous Riemann-Hilbert problem with extra constraints\nof the virtual traction along tunnel periphery, which is simultaneously solved\nusing an iterative linear system with good numerical stability. The mixed\nboundary conditions along the ground surface in the whole excavation time span\nare well satisified in a numerical case, which is further examined by comparing\nwith corresponding finite element solution. The results are in good agreements,\nand the proposed solution illustrates high efficiency. More discussions are\nmade on excavation rate, viscosity, and solution convergence. A latent paradox\nis disclosed for objectivity.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Luobin Lin",
            "Fuquan Chen",
            "Changjie Zheng"
        ],
        "published": "2024-05-27T02:32:34Z"
    },
    {
        "title": "Oblivious Monitoring for Discrete-Time STL via Fully Homomorphic\n  Encryption",
        "link": "http://arxiv.org/abs/2405.16767v1",
        "abstract": "When monitoring a cyber-physical system (CPS) from a remote server, keeping\nthe monitored data secret is crucial, particularly when they contain sensitive\ninformation, e.g., biological or location data. Recently, Banno et al. (CAV'22)\nproposed a protocol for online LTL monitoring that keeps data concealed from\nthe server using Fully Homomorphic Encryption (FHE). We build on this protocol\nto allow arithmetic operations over encrypted values, e.g., to compute a safety\nmeasurement combining distance, velocity, and so forth. Overall, our protocol\nenables oblivious online monitoring of discrete-time real-valued signals\nagainst signal temporal logic (STL) formulas. Our protocol combines two FHE\nschemes, CKKS and TFHE, leveraging their respective strengths. We employ CKKS\nto evaluate arithmetic predicates in STL formulas while utilizing TFHE to\nprocess them using a DFA derived from the STL formula. We conducted case\nstudies on monitoring blood glucose levels and vehicles' behavior against the\nResponsibility-Sensitive Safety (RSS) rules. Our results suggest the practical\nrelevance of our protocol.",
        "subjects": [
            "cs.CR",
            "cs.FL"
        ],
        "authors": [
            "Masaki Waga",
            "Kotaro Matsuoka",
            "Takashi Suwa",
            "Naoki Matsumoto",
            "Ryotaro Banno",
            "Song Bian",
            "Kohei Suenaga"
        ],
        "published": "2024-05-27T02:32:16Z"
    },
    {
        "title": "Reframing the Relationship in Out-of-Distribution Detection",
        "link": "http://arxiv.org/abs/2405.16766v1",
        "abstract": "The remarkable achievements of Large Language Models (LLMs) have captivated\nthe attention of both academia and industry, transcending their initial role in\ndialogue generation. The utilization of LLMs as intermediary agents in various\ntasks has yielded promising results, sparking a wave of innovation in\nartificial intelligence. Building on these breakthroughs, we introduce a novel\napproach that integrates the agent paradigm into the Out-of-distribution (OOD)\ndetection task, aiming to enhance its robustness and adaptability. Our proposed\nmethod, Concept Matching with Agent (CMA), employs neutral prompts as agents to\naugment the CLIP-based OOD detection process. These agents function as dynamic\nobservers and communication hubs, interacting with both In-distribution (ID)\nlabels and data inputs to form vector triangle relationships. This triangular\nframework offers a more nuanced approach than the traditional binary\nrelationship, allowing for better separation and identification of ID and OOD\ninputs. Our extensive experimental results showcase the superior performance of\nCMA over both zero-shot and training-required methods in a diverse array of\nreal-world scenarios.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "YuXiao Lee",
            "Xiaofeng Cao"
        ],
        "published": "2024-05-27T02:27:28Z"
    },
    {
        "title": "Study of Robust Direction Finding Based on Joint Sparse Representation",
        "link": "http://arxiv.org/abs/2405.16765v1",
        "abstract": "Standard Direction of Arrival (DOA) estimation methods are typically derived\nbased on the Gaussian noise assumption, making them highly sensitive to\noutliers. Therefore, in the presence of impulsive noise, the performance of\nthese methods may significantly deteriorate. In this paper, we model impulsive\nnoise as Gaussian noise mixed with sparse outliers. By exploiting their\nstatistical differences, we propose a novel DOA estimation method based on\nsparse signal recovery (SSR). Furthermore, to address the issue of grid\nmismatch, we utilize an alternating optimization approach that relies on the\nestimated outlier matrix and the on-grid DOA estimates to obtain the off-grid\nDOA estimates. Simulation results demonstrate that the proposed method exhibits\nrobustness against large outliers.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "authors": [
            "Y. Li",
            "W. Xiao",
            "L. Zhao",
            "Z. Huang",
            "Q. Li",
            "L. Li",
            "R. C. de Lamare"
        ],
        "published": "2024-05-27T02:26:37Z"
    },
    {
        "title": "Transport of Algebraic Structure to Latent Embeddings",
        "link": "http://arxiv.org/abs/2405.16763v1",
        "abstract": "Machine learning often aims to produce latent embeddings of inputs which lie\nin a larger, abstract mathematical space. For example, in the field of 3D\nmodeling, subsets of Euclidean space can be embedded as vectors using implicit\nneural representations. Such subsets also have a natural algebraic structure\nincluding operations (e.g., union) and corresponding laws (e.g.,\nassociativity). How can we learn to \"union\" two sets using only their latent\nembeddings while respecting associativity? We propose a general procedure for\nparameterizing latent space operations that are provably consistent with the\nlaws on the input space. This is achieved by learning a bijection from the\nlatent space to a carefully designed mirrored algebra which is constructed on\nEuclidean space in accordance with desired laws. We evaluate these structural\ntransport nets for a range of mirrored algebras against baselines that operate\ndirectly on the latent space. Our experiments provide strong evidence that\nrespecting the underlying algebraic structure of the input space is key for\nlearning accurate and self-consistent operations.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Samuel Pfrommer",
            "Brendon G. Anderson",
            "Somayeh Sojoudi"
        ],
        "published": "2024-05-27T02:24:57Z"
    },
    {
        "title": "Addressing Discretization-Induced Bias in Demographic Prediction",
        "link": "http://arxiv.org/abs/2405.16762v1",
        "abstract": "Racial and other demographic imputation is necessary for many applications,\nespecially in auditing disparities and outreach targeting in political\ncampaigns. The canonical approach is to construct continuous predictions --\ne.g., based on name and geography -- and then to $\\textit{discretize}$ the\npredictions by selecting the most likely class (argmax). We study how this\npractice produces $\\textit{discretization bias}$. In particular, we show that\nargmax labeling, as used by a prominent commercial voter file vendor to impute\nrace/ethnicity, results in a substantial under-count of African-American\nvoters, e.g., by 28.2% points in North Carolina. This bias can have substantial\nimplications in downstream tasks that use such labels.\n  We then introduce a $\\textit{joint optimization}$ approach -- and a tractable\n$\\textit{data-driven thresholding}$ heuristic -- that can eliminate this bias,\nwith negligible individual-level accuracy loss. Finally, we theoretically\nanalyze discretization bias, show that calibrated continuous models are\ninsufficient to eliminate it, and that an approach such as ours is necessary.\nBroadly, we warn researchers and practitioners against discretizing continuous\ndemographic predictions without considering downstream consequences.",
        "subjects": [
            "cs.CY",
            "cs.LG",
            "K.4.0"
        ],
        "authors": [
            "Evan Dong",
            "Aaron Schein",
            "Yixin Wang",
            "Nikhil Garg"
        ],
        "published": "2024-05-27T02:22:43Z"
    },
    {
        "title": "Masked Face Recognition with Generative-to-Discriminative\n  Representations",
        "link": "http://arxiv.org/abs/2405.16761v1",
        "abstract": "Masked face recognition is important for social good but challenged by\ndiverse occlusions that cause insufficient or inaccurate representations. In\nthis work, we propose a unified deep network to learn\ngenerative-to-discriminative representations for facilitating masked face\nrecognition. To this end, we split the network into three modules and learn\nthem on synthetic masked faces in a greedy module-wise pretraining manner.\nFirst, we leverage a generative encoder pretrained for face inpainting and\nfinetune it to represent masked faces into category-aware descriptors.\nAttribute to the generative encoder's ability in recovering context\ninformation, the resulting descriptors can provide occlusion-robust\nrepresentations for masked faces, mitigating the effect of diverse masks. Then,\nwe incorporate a multi-layer convolutional network as a discriminative reformer\nand learn it to convert the category-aware descriptors into identity-aware\nvectors, where the learning is effectively supervised by distilling relation\nknowledge from off-the-shelf face recognition model. In this way, the\ndiscriminative reformer together with the generative encoder serves as the\npretrained backbone, providing general and discriminative representations\ntowards masked faces. Finally, we cascade one fully-connected layer following\nby one softmax layer into a feature classifier and finetune it to identify the\nreformed identity-aware vectors. Extensive experiments on synthetic and\nrealistic datasets demonstrate the effectiveness of our approach in recognizing\nmasked faces.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Shiming Ge",
            "Weijia Guo",
            "Chenyu Li",
            "Junzheng Zhang",
            "Yong Li",
            "Dan Zeng"
        ],
        "published": "2024-05-27T02:20:55Z"
    },
    {
        "title": "Graphon Particle Systems, Part I: Spatio-Temporal Approximation and Law\n  of Large Numbers",
        "link": "http://arxiv.org/abs/2405.16760v1",
        "abstract": "We study a class of graphon particle systems with time-varying random\ncoefficients. In a graphon particle system, the interactions among particles\nare characterized by the coupled mean field terms through an underlying graphon\nand the randomness of the coefficients comes from the stochastic processes\nassociated with the particle labels. By constructing two-level approximated\nsequences converging in 2-Wasserstein distance, we prove the existence and\nuniqueness of the solution to the system. Besides, by constructing two-level\napproximated functions converging to the graphon mean field terms, we establish\nthe law of large numbers, which reveals that if the number of particles tends\nto infinity and the discretization step tends to zero, then the discrete-time\ninteracting particle system over the large-scale network converges to the\ngraphon particle system. As a byproduct, we discover that the graphon particle\nsystem can describe the dynamic evolution of the distributed stochastic\ngradient descent algorithm over the large-scale network and prove that if the\ngradients of the local cost functions are Lipschitz continuous, then the\ngraphon particle system can be regarded as the spatio-temporal approximation of\nthe discrete-time distributed stochastic gradient descent algorithm as the\nnumber of network nodes tends to infinity and the algorithm step size tends to\nzero.",
        "subjects": [
            "eess.SY",
            "cs.SY",
            "math.PR"
        ],
        "authors": [
            "Yan Chen",
            "Tao Li"
        ],
        "published": "2024-05-27T02:20:44Z"
    },
    {
        "title": "Greedy Growing Enables High-Resolution Pixel-Based Diffusion Models",
        "link": "http://arxiv.org/abs/2405.16759v1",
        "abstract": "We address the long-standing problem of how to learn effective pixel-based\nimage diffusion models at scale, introducing a remarkably simple greedy growing\nmethod for stable training of large-scale, high-resolution models. without the\nneeds for cascaded super-resolution components. The key insight stems from\ncareful pre-training of core components, namely, those responsible for\ntext-to-image alignment {\\it vs.} high-resolution rendering. We first\ndemonstrate the benefits of scaling a {\\it Shallow UNet}, with no\ndown(up)-sampling enc(dec)oder. Scaling its deep core layers is shown to\nimprove alignment, object structure, and composition. Building on this core\nmodel, we propose a greedy algorithm that grows the architecture into\nhigh-resolution end-to-end models, while preserving the integrity of the\npre-trained representation, stabilizing training, and reducing the need for\nlarge high-resolution datasets. This enables a single stage model capable of\ngenerating high-resolution images without the need of a super-resolution\ncascade. Our key results rely on public datasets and show that we are able to\ntrain non-cascaded models up to 8B parameters with no further regularization\nschemes. Vermeer, our full pipeline model trained with internal datasets to\nproduce 1024x1024 images, without cascades, is preferred by 44.0% vs. 21.4%\nhuman evaluators over SDXL.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Cristina N. Vasconcelos",
            "Abdullah Rashwan Austin Waters",
            "Trevor Walker",
            "Keyang Xu",
            "Jimmy Yan",
            "Rui Qian",
            "Shixin Luo",
            "Zarana Parekh",
            "Andrew Bunner",
            "Hongliang Fei",
            "Roopal Garg",
            "Mandy Guo",
            "Ivana Kajic",
            "Yeqing Li",
            "Henna Nandwani",
            "Jordi Pont-Tuset",
            "Yasumasa Onoe",
            "Sarah Rosston",
            "Su Wang",
            "Wenlei Zhou",
            "Kevin Swersky",
            "David J. Fleet",
            "Jason M. Baldridge",
            "Oliver Wang"
        ],
        "published": "2024-05-27T02:12:39Z"
    },
    {
        "title": "Symmetry-Informed Governing Equation Discovery",
        "link": "http://arxiv.org/abs/2405.16756v1",
        "abstract": "Despite the advancements in learning governing differential equations from\nobservations of dynamical systems, data-driven methods are often unaware of\nfundamental physical laws, such as frame invariance. As a result, these\nalgorithms may search an unnecessarily large space and discover equations that\nare less accurate or overly complex. In this paper, we propose to leverage\nsymmetry in automated equation discovery to compress the equation search space\nand improve the accuracy and simplicity of the learned equations. Specifically,\nwe derive equivariance constraints from the time-independent symmetries of\nODEs. Depending on the types of symmetries, we develop a pipeline for\nincorporating symmetry constraints into various equation discovery algorithms,\nincluding sparse regression and genetic programming. In experiments across a\ndiverse range of dynamical systems, our approach demonstrates better robustness\nagainst noise and recovers governing equations with significantly higher\nprobability than baselines without symmetry.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Jianke Yang",
            "Wang Rao",
            "Nima Dehmamy",
            "Robin Walters",
            "Rose Yu"
        ],
        "published": "2024-05-27T01:58:23Z"
    },
    {
        "title": "CHESS: Contextual Harnessing for Efficient SQL Synthesis",
        "link": "http://arxiv.org/abs/2405.16755v1",
        "abstract": "Utilizing large language models (LLMs) for transforming natural language\nquestions into SQL queries (text-to-SQL) is a promising yet challenging\napproach, particularly when applied to real-world databases with complex and\nextensive schemas. In particular, effectively incorporating data catalogs and\ndatabase values for SQL generation remains an obstacle, leading to suboptimal\nsolutions. We address this problem by proposing a new pipeline that effectively\nretrieves relevant data and context, selects an efficient schema, and\nsynthesizes correct and efficient SQL queries. To increase retrieval precision,\nour pipeline introduces a hierarchical retrieval method leveraging\nmodel-generated keywords, locality-sensitive hashing indexing, and vector\ndatabases. Additionally, we have developed an adaptive schema pruning technique\nthat adjusts based on the complexity of the problem and the model's context\nsize. Our approach generalizes to both frontier proprietary models like GPT-4\nand open-source models such as Llama-3-70B. Through a series of ablation\nstudies, we demonstrate the effectiveness of each component of our pipeline and\nits impact on the end-to-end performance. Our method achieves new\nstate-of-the-art performance on the cross-domain challenging BIRD dataset.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DB"
        ],
        "authors": [
            "Shayan Talaei",
            "Mohammadreza Pourreza",
            "Yu-Chen Chang",
            "Azalia Mirhoseini",
            "Amin Saberi"
        ],
        "published": "2024-05-27T01:54:16Z"
    },
    {
        "title": "Adaptive VIO: Deep Visual-Inertial Odometry with Online Continual\n  Learning",
        "link": "http://arxiv.org/abs/2405.16754v1",
        "abstract": "Visual-inertial odometry (VIO) has demonstrated remarkable success due to its\nlow-cost and complementary sensors. However, existing VIO methods lack the\ngeneralization ability to adjust to different environments and sensor\nattributes. In this paper, we propose Adaptive VIO, a new monocular\nvisual-inertial odometry that combines online continual learning with\ntraditional nonlinear optimization. Adaptive VIO comprises two networks to\npredict visual correspondence and IMU bias. Unlike end-to-end approaches that\nuse networks to fuse the features from two modalities (camera and IMU) and\npredict poses directly, we combine neural networks with visual-inertial bundle\nadjustment in our VIO system. The optimized estimates will be fed back to the\nvisual and IMU bias networks, refining the networks in a self-supervised\nmanner. Such a learning-optimization-combined framework and feedback mechanism\nenable the system to perform online continual learning. Experiments demonstrate\nthat our Adaptive VIO manifests adaptive capability on EuRoC and TUM-VI\ndatasets. The overall performance exceeds the currently known learning-based\nVIO methods and is comparable to the state-of-the-art optimization-based\nmethods.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Youqi Pan",
            "Wugen Zhou",
            "Yingdian Cao",
            "Hongbin Zha"
        ],
        "published": "2024-05-27T01:54:07Z"
    },
    {
        "title": "Multi-answer Constrained Optimal Querying: Maximum Information Gain\n  Coding",
        "link": "http://arxiv.org/abs/2405.16753v1",
        "abstract": "As the rapidly developments of artificial intelligence and machine learning,\nbehavior tree design in multiagent system or AI game become more important. The\nbehavior tree design problem is highly related to the source coding in\ninformation theory. \"Twenty Questions\" problem is a typical example for the\nbehavior tree design, usually used to explain the source coding application in\ninformation theory and can be solved by Huffman coding. In some realistic\nscenarios, there are some constraints on the asked questions. However, for\ngeneral question set, finding the minimum expected querying length is an open\nproblem, belongs to NP-hard. Recently, a new coding scheme has been proposed to\nprovide a near optimal solution for binary cases with some constraints, named\ngreedy binary separation coding (GBSC). In this work, we shall generalize it to\nD-ary cases and propose maximum information gain coding (MIGC) approach to\nsolve the multi-answer decision constrained querying problem. The optimality of\nthe proposed MIGC is discussed in theory. Later on, we also apply MIGC to\ndiscuss three practical scenarios and showcase that MIGC has better performance\nthan GBSC and Shannon Coding in terms of bits persymbol.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Zhefan Li",
            "Pingyi Fan"
        ],
        "published": "2024-05-27T01:53:53Z"
    },
    {
        "title": "Model Ensembling for Constrained Optimization",
        "link": "http://arxiv.org/abs/2405.16752v1",
        "abstract": "There is a long history in machine learning of model ensembling, beginning\nwith boosting and bagging and continuing to the present day. Much of this\nhistory has focused on combining models for classification and regression, but\nrecently there is interest in more complex settings such as ensembling policies\nin reinforcement learning. Strong connections have also emerged between\nensembling and multicalibration techniques. In this work, we further\ninvestigate these themes by considering a setting in which we wish to ensemble\nmodels for multidimensional output predictions that are in turn used for\ndownstream optimization. More precisely, we imagine we are given a number of\nmodels mapping a state space to multidimensional real-valued predictions. These\npredictions form the coefficients of a linear objective that we would like to\noptimize under specified constraints. The fundamental question we address is\nhow to improve and combine such models in a way that outperforms the best of\nthem in the downstream optimization problem. We apply multicalibration\ntechniques that lead to two provably efficient and convergent algorithms. The\nfirst of these (the white box approach) requires being given models that map\nstates to output predictions, while the second (the \\emph{black box} approach)\nrequires only policies (mappings from states to solutions to the optimization\nproblem). For both, we provide convergence and utility guarantees. We conclude\nby investigating the performance and behavior of the two algorithms in a\ncontrolled experimental setting.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Ira Globus-Harris",
            "Varun Gupta",
            "Michael Kearns",
            "Aaron Roth"
        ],
        "published": "2024-05-27T01:48:07Z"
    },
    {
        "title": "LLM-Based Cooperative Agents using Information Relevance and Plan\n  Validation",
        "link": "http://arxiv.org/abs/2405.16751v1",
        "abstract": "We address the challenge of multi-agent cooperation, where agents achieve a\ncommon goal by interacting with a 3D scene and cooperating with decentralized\nagents under complex partial observations. This involves managing communication\ncosts and optimizing interaction trajectories in dynamic environments. Our\nresearch focuses on three primary limitations of existing cooperative agent\nsystems. Firstly, current systems demonstrate inefficiency in managing acquired\ninformation through observation, resulting in declining planning performance as\nthe environment becomes more complex with additional objects or goals.\nSecondly, the neglect of false plans in partially observable settings leads to\nsuboptimal cooperative performance, as agents struggle to adapt to\nenvironmental changes influenced by the unseen actions of other agents. Lastly,\nthe failure to incorporate spatial data into decision-making processes\nrestricts the agent's ability to construct optimized trajectories. To overcome\nthese limitations, we propose the RElevance and Validation-Enhanced Cooperative\nLanguage Agent (REVECA), a novel cognitive architecture powered by GPT-3.5.\nREVECA leverages relevance assessment, plan validation, and spatial information\nto enhance the efficiency and robustness of agent cooperation in dynamic and\npartially observable environments while minimizing continuous communication\ncosts and effectively managing irrelevant dummy objects. Our extensive\nexperiments demonstrate the superiority of REVECA over previous approaches,\nincluding those driven by GPT-4.0. Additionally, a user study highlights\nREVECA's potential for achieving trustworthy human-AI cooperation. We expect\nthat REVECA will have significant applications in gaming, XR applications,\neducational tools, and humanoid robots, contributing to substantial economic,\ncommercial, and academic advancements.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "cs.MA"
        ],
        "authors": [
            "SeungWon Seo",
            "Junhyeok Lee",
            "SeongRae Noh",
            "HyeongYeop Kang"
        ],
        "published": "2024-05-27T01:47:14Z"
    },
    {
        "title": "DMPlug: A Plug-in Method for Solving Inverse Problems with Diffusion\n  Models",
        "link": "http://arxiv.org/abs/2405.16749v1",
        "abstract": "Pretrained diffusion models (DMs) have recently been popularly used in\nsolving inverse problems (IPs). The existing methods mostly interleave\niterative steps in the reverse diffusion process and iterative steps to bring\nthe iterates closer to satisfying the measurement constraint. However, such\ninterleaving methods struggle to produce final results that look like natural\nobjects of interest (i.e., manifold feasibility) and fit the measurement (i.e.,\nmeasurement feasibility), especially for nonlinear IPs. Moreover, their\ncapabilities to deal with noisy IPs with unknown types and levels of\nmeasurement noise are unknown. In this paper, we advocate viewing the reverse\nprocess in DMs as a function and propose a novel plug-in method for solving IPs\nusing pretrained DMs, dubbed DMPlug. DMPlug addresses the issues of manifold\nfeasibility and measurement feasibility in a principled manner, and also shows\ngreat potential for being robust to unknown types and levels of noise. Through\nextensive experiments across various IP tasks, including two linear and three\nnonlinear IPs, we demonstrate that DMPlug consistently outperforms\nstate-of-the-art methods, often by large margins especially for nonlinear IPs.\nThe code is available at https://github.com/sun-umn/DMPlug.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Hengkang Wang",
            "Xu Zhang",
            "Taihui Li",
            "Yuxiang Wan",
            "Tiancong Chen",
            "Ju Sun"
        ],
        "published": "2024-05-27T01:38:30Z"
    },
    {
        "title": "Hypergraph Laplacian Eigenmaps and Face Recognition Problems",
        "link": "http://arxiv.org/abs/2405.16748v1",
        "abstract": "Face recognition is a very important topic in data science and biometric\nsecurity research areas. It has multiple applications in military, finance, and\nretail, to name a few. In this paper, the novel hypergraph Laplacian Eigenmaps\nwill be proposed and combine with the k nearest-neighbor method and/or with the\nkernel ridge regression method to solve the face recognition problem.\nExperimental results illustrate that the accuracy of the combination of the\nnovel hypergraph Laplacian Eigenmaps and one specific classification system is\nsimilar to the accuracy of the combination of the old symmetric normalized\nhypergraph Laplacian Eigenmaps method and one specific classification system.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Loc Hoang Tran"
        ],
        "published": "2024-05-27T01:35:14Z"
    },
    {
        "title": "Understanding Linear Probing then Fine-tuning Language Models from NTK\n  Perspective",
        "link": "http://arxiv.org/abs/2405.16747v1",
        "abstract": "The two-stage fine-tuning (FT) method, linear probing then fine-tuning\n(LP-FT), consistently outperforms linear probing (LP) and FT alone in terms of\naccuracy for both in-distribution (ID) and out-of-distribution (OOD) data. This\nsuccess is largely attributed to the preservation of pre-trained features,\nachieved through a near-optimal linear head obtained during LP. However,\ndespite the widespread use of large language models, the exploration of complex\narchitectures such as Transformers remains limited. In this paper, we analyze\nthe training dynamics of LP-FT for classification models on the basis of the\nneural tangent kernel (NTK) theory. Our analysis decomposes the NTK matrix into\ntwo components, highlighting the importance of the linear head norm alongside\nthe prediction accuracy at the start of the FT stage. We also observe a\nsignificant increase in the linear head norm during LP, stemming from training\nwith the cross-entropy (CE) loss, which effectively minimizes feature changes.\nFurthermore, we find that this increased norm can adversely affect model\ncalibration, a challenge that can be addressed by temperature scaling.\nAdditionally, we extend our analysis with the NTK to the low-rank adaptation\n(LoRA) method and validate its effectiveness. Our experiments with a\nTransformer-based model on natural language processing tasks across multiple\nbenchmarks confirm our theoretical analysis and demonstrate the effectiveness\nof LP-FT in fine-tuning language models. Code is available at\nhttps://github.com/tom4649/lp-ft_ntk.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Akiyoshi Tomihari",
            "Issei Sato"
        ],
        "published": "2024-05-27T01:31:40Z"
    },
    {
        "title": "Ecosystem of Large Language Models for Code",
        "link": "http://arxiv.org/abs/2405.16746v1",
        "abstract": "The availability of vast amounts of publicly accessible data of source code\nand the advances in modern language models, coupled with increasing\ncomputational resources, have led to a remarkable surge in the development of\nlarge language models for code (LLM4Code, for short). The interaction between\ncode datasets and models gives rise to a complex ecosystem characterized by\nintricate dependencies that are worth studying. This paper introduces a\npioneering analysis of the code model ecosystem. Utilizing Hugging Face -- the\npremier hub for transformer-based models -- as our primary source, we curate a\nlist of datasets and models that are manually confirmed to be relevant to\nsoftware engineering. By analyzing the ecosystem, we first identify the popular\nand influential datasets, models, and contributors. The popularity is\nquantified by various metrics, including the number of downloads, the number of\nlikes, the number of reuses, etc. The ecosystem follows a power-law\ndistribution, indicating that users prefer widely recognized models and\ndatasets. Then, we manually categorize how models in the ecosystem are reused\ninto nine categories, analyzing prevalent model reuse practices. The top 3 most\npopular reuse types are fine-tuning, architecture sharing, and quantization. We\nalso explore the practices surrounding the publication of LLM4Code,\nspecifically focusing on documentation practice and license selection. We find\nthat the documentation in the ecosystem contains less information than that in\ngeneral artificial intelligence (AI)-related repositories hosted on GitHub.\nAdditionally, the license usage is also different from other software\nrepositories. Models in the ecosystem adopt some AI-specific licenses, e.g.,\nRAIL (Responsible AI Licenses) and AI model license agreement.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Zhou Yang",
            "Jieke Shi",
            "David Lo"
        ],
        "published": "2024-05-27T01:31:30Z"
    },
    {
        "title": "PP-SAM: Perturbed Prompts for Robust Adaptation of Segment Anything\n  Model for Polyp Segmentation",
        "link": "http://arxiv.org/abs/2405.16740v1",
        "abstract": "The Segment Anything Model (SAM), originally designed for general-purpose\nsegmentation tasks, has been used recently for polyp segmentation. Nonetheless,\nfine-tuning SAM with data from new imaging centers or clinics poses significant\nchallenges. This is because this necessitates the creation of an expensive and\ntime-intensive annotated dataset, along with the potential for variability in\nuser prompts during inference. To address these issues, we propose a robust\nfine-tuning technique, PP-SAM, that allows SAM to adapt to the polyp\nsegmentation task with limited images. To this end, we utilize variable\nperturbed bounding box prompts (BBP) to enrich the learning context and enhance\nthe model's robustness to BBP perturbations during inference. Rigorous\nexperiments on polyp segmentation benchmarks reveal that our variable BBP\nperturbation significantly improves model resilience. Notably, on Kvasir,\n1-shot fine-tuning boosts the DICE score by 20% and 37% with 50 and 100-pixel\nBBP perturbations during inference, respectively. Moreover, our experiments\nshow that 1-shot, 5-shot, and 10-shot PP-SAM with 50-pixel perturbations during\ninference outperform a recent state-of-the-art (SOTA) polyp segmentation method\nby 26%, 7%, and 5% DICE scores, respectively. Our results motivate the broader\napplicability of our PP-SAM for other medical imaging tasks with limited\nsamples. Our implementation is available at https://github.com/SLDGroup/PP-SAM.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Md Mostafijur Rahman",
            "Mustafa Munir",
            "Debesh Jha",
            "Ulas Bagci",
            "Radu Marculescu"
        ],
        "published": "2024-05-27T01:13:01Z"
    },
    {
        "title": "Oracle-Efficient Reinforcement Learning for Max Value Ensembles",
        "link": "http://arxiv.org/abs/2405.16739v1",
        "abstract": "Reinforcement learning (RL) in large or infinite state spaces is notoriously\nchallenging, both theoretically (where worst-case sample and computational\ncomplexities must scale with state space cardinality) and experimentally (where\nfunction approximation and policy gradient techniques often scale poorly and\nsuffer from instability and high variance). One line of research attempting to\naddress these difficulties makes the natural assumption that we are given a\ncollection of heuristic base or $\\textit{constituent}$ policies upon which we\nwould like to improve in a scalable manner. In this work we aim to compete with\nthe $\\textit{max-following policy}$, which at each state follows the action of\nwhichever constituent policy has the highest value. The max-following policy is\nalways at least as good as the best constituent policy, and may be considerably\nbetter. Our main result is an efficient algorithm that learns to compete with\nthe max-following policy, given only access to the constituent policies (but\nnot their value functions). In contrast to prior work in similar settings, our\ntheoretical results require only the minimal assumption of an ERM oracle for\nvalue function approximation for the constituent policies (and not the global\noptimal policy or the max-following policy itself) on samplable distributions.\nWe illustrate our algorithm's experimental effectiveness and behavior on\nseveral robotic simulation testbeds.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Marcel Hussing",
            "Michael Kearns",
            "Aaron Roth",
            "Sikata Bela Sengupta",
            "Jessica Sorrell"
        ],
        "published": "2024-05-27T01:08:23Z"
    },
    {
        "title": "CARL: A Framework for Equivariant Image Registration",
        "link": "http://arxiv.org/abs/2405.16738v2",
        "abstract": "Image registration estimates spatial correspondences between a pair of\nimages. These estimates are typically obtained via numerical optimization or\nregression by a deep network. A desirable property of such estimators is that a\ncorrespondence estimate (e.g., the true oracle correspondence) for an image\npair is maintained under deformations of the input images. Formally, the\nestimator should be equivariant to a desired class of image transformations. In\nthis work, we present careful analyses of the desired equivariance properties\nin the context of multi-step deep registration networks. Based on these\nanalyses we 1) introduce the notions of $[U,U]$ equivariance (network\nequivariance to the same deformations of the input images) and $[W,U]$\nequivariance (where input images can undergo different deformations); we 2)\nshow that in a suitable multi-step registration setup it is sufficient for\noverall $[W,U]$ equivariance if the first step has $[W,U]$ equivariance and all\nothers have $[U,U]$ equivariance; we 3) show that common\ndisplacement-predicting networks only exhibit $[U,U]$ equivariance to\ntranslations instead of the more powerful $[W,U]$ equivariance; and we 4) show\nhow to achieve multi-step $[W,U]$ equivariance via a coordinate-attention\nmechanism combined with displacement-predicting refinement layers (CARL).\nOverall, our approach obtains excellent practical registration performance on\nseveral 3D medical image registration tasks and outperforms existing\nunsupervised approaches for the challenging problem of abdomen registration.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hastings Greer",
            "Lin Tian",
            "Francois-Xavier Vialard",
            "Roland Kwitt",
            "Raul San Jose Estepar",
            "Marc Niethammer"
        ],
        "published": "2024-05-27T01:06:58Z"
    },
    {
        "title": "Limited-perception games",
        "link": "http://arxiv.org/abs/2405.16735v1",
        "abstract": "We study rational agents with different perception capabilities in strategic\ngames. We focus on a class of one-shot limited-perception games. These games\nextend simultaneous-move normal-form games by presenting each player with an\nindividualized perception of all players' payoff functions. The accuracy of a\nplayer's perception is determined by the player's capability level. Capability\nlevels are countable and totally ordered, with a higher level corresponding to\na more accurate perception. We study the rational behavior of players in these\ngames and formalize relevant equilibria conditions. In contrast to equilibria\nin conventional bimatrix games, which can be represented by a pair of mixed\nstrategies, in our limited perception games a higher-order response function\ncaptures how the lower-capability player uses their (less accurate) perception\nof the payoff function to reason about the (more accurate) possible perceptions\nof the higher-capability opponent. This response function characterizes, for\neach possible perception of the higher-capability player (from the perspective\nof the lower-capability player), the best response of the higher capability\nplayer for that perception. Since the domain of the response function can be\nexponentially large or even infinite, finding one equilibrium may be\ncomputationally intractable or even undecidable. Nevertheless, we show that for\nany $\\epsilon$, there exists an $\\epsilon$-equilibrium with a compact,\ntractable representation whose size is independent of the size of the response\nfunction's domain. We further identify classes of zero-sum limited-perception\ngames in which finding an equilibrium becomes a (typically tractable) nonsmooth\nconvex optimization problem.",
        "subjects": [
            "cs.GT"
        ],
        "authors": [
            "Kai Jia",
            "Martin Rinard"
        ],
        "published": "2024-05-27T00:56:21Z"
    },
    {
        "title": "Faster Sampling via Stochastic Gradient Proximal Sampler",
        "link": "http://arxiv.org/abs/2405.16734v1",
        "abstract": "Stochastic gradients have been widely integrated into Langevin-based methods\nto improve their scalability and efficiency in solving large-scale sampling\nproblems. However, the proximal sampler, which exhibits much faster convergence\nthan Langevin-based algorithms in the deterministic setting Lee et al. (2021),\nhas yet to be explored in its stochastic variants. In this paper, we study the\nStochastic Proximal Samplers (SPS) for sampling from non-log-concave\ndistributions. We first establish a general framework for implementing\nstochastic proximal samplers and establish the convergence theory accordingly.\nWe show that the convergence to the target distribution can be guaranteed as\nlong as the second moment of the algorithm trajectory is bounded and restricted\nGaussian oracles can be well approximated. We then provide two implementable\nvariants based on Stochastic gradient Langevin dynamics (SGLD) and\nMetropolis-adjusted Langevin algorithm (MALA), giving rise to SPS-SGLD and\nSPS-MALA. We further show that SPS-SGLD and SPS-MALA can achieve\n$\\epsilon$-sampling error in total variation (TV) distance within\n$\\tilde{\\mathcal{O}}(d\\epsilon^{-2})$ and\n$\\tilde{\\mathcal{O}}(d^{1/2}\\epsilon^{-2})$ gradient complexities, which\noutperform the best-known result by at least an $\\tilde{\\mathcal{O}}(d^{1/3})$\nfactor. This enhancement in performance is corroborated by our empirical\nstudies on synthetic data with various dimensions, demonstrating the efficiency\nof our proposed algorithm.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Xunpeng Huang",
            "Difan Zou",
            "Yi-An Ma",
            "Hanze Dong",
            "Tong Zhang"
        ],
        "published": "2024-05-27T00:53:18Z"
    },
    {
        "title": "The Collusion of Memory and Nonlinearity in Stochastic Approximation\n  With Constant Stepsize",
        "link": "http://arxiv.org/abs/2405.16732v1",
        "abstract": "In this work, we investigate stochastic approximation (SA) with Markovian\ndata and nonlinear updates under constant stepsize $\\alpha>0$. Existing work\nhas primarily focused on either i.i.d. data or linear update rules. We take a\nnew perspective and carefully examine the simultaneous presence of Markovian\ndependency of data and nonlinear update rules, delineating how the interplay\nbetween these two structures leads to complications that are not captured by\nprior techniques. By leveraging the smoothness and recurrence properties of the\nSA updates, we develop a fine-grained analysis of the correlation between the\nSA iterates $\\theta_k$ and Markovian data $x_k$. This enables us to overcome\nthe obstacles in existing analysis and establish for the first time the weak\nconvergence of the joint process $(x_k, \\theta_k)_{k\\geq0}$. Furthermore, we\npresent a precise characterization of the asymptotic bias of the SA iterates,\ngiven by\n$\\mathbb{E}[\\theta_\\infty]-\\theta^\\ast=\\alpha(b_\\text{m}+b_\\text{n}+b_\\text{c})+O(\\alpha^{3/2})$.\nHere, $b_\\text{m}$ is associated with the Markovian noise, $b_\\text{n}$ is tied\nto the nonlinearity, and notably, $b_\\text{c}$ represents a multiplicative\ninteraction between the Markovian noise and nonlinearity, which is absent in\nprevious works. As a by-product of our analysis, we derive finite-time bounds\non higher moment $\\mathbb{E}[\\|\\theta_k-\\theta^\\ast\\|^{2p}]$ and present\nnon-asymptotic geometric convergence rates for the iterates, along with a\nCentral Limit Theorem.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.OC",
            "math.ST",
            "stat.TH"
        ],
        "authors": [
            "Dongyan Huo",
            "Yixuan Zhang",
            "Yudong Chen",
            "Qiaomin Xie"
        ],
        "published": "2024-05-27T00:23:42Z"
    },
    {
        "title": "Pretraining with Random Noise for Fast and Robust Learning without\n  Weight Transport",
        "link": "http://arxiv.org/abs/2405.16731v1",
        "abstract": "The brain prepares for learning even before interacting with the environment,\nby refining and optimizing its structures through spontaneous neural activity\nthat resembles random noise. However, the mechanism of such a process has yet\nto be thoroughly understood, and it is unclear whether this process can benefit\nthe algorithm of machine learning. Here, we study this issue using a neural\nnetwork with a feedback alignment algorithm, demonstrating that pretraining\nneural networks with random noise increases the learning efficiency as well as\ngeneralization abilities without weight transport. First, we found that random\nnoise training modifies forward weights to match backward synaptic feedback,\nwhich is necessary for teaching errors by feedback alignment. As a result, a\nnetwork with pre-aligned weights learns notably faster than a network without\nrandom noise training, even reaching a convergence speed comparable to that of\na backpropagation algorithm. Sequential training with both random noise and\ndata brings weights closer to synaptic feedback than training solely with data,\nenabling more precise credit assignment and faster learning. We also found that\neach readout probability approaches the chance level and that the effective\ndimensionality of weights decreases in a network pretrained with random noise.\nThis pre-regularization allows the network to learn simple solutions of a low\nrank, reducing the generalization loss during subsequent training. This also\nenables the network robustly to generalize a novel, out-of-distribution\ndataset. Lastly, we confirmed that random noise pretraining reduces the amount\nof meta-loss, enhancing the network ability to adapt to various tasks. Overall,\nour results suggest that random noise training with feedback alignment offers a\nstraightforward yet effective method of pretraining that facilitates quick and\nreliable learning without weight transport.",
        "subjects": [
            "cs.LG",
            "cs.NE"
        ],
        "authors": [
            "Jeonghwan Cheon",
            "Sang Wan Lee",
            "Se-Bum Paik"
        ],
        "published": "2024-05-27T00:12:51Z"
    },
    {
        "title": "Latent Energy-Based Odyssey: Black-Box Optimization via Expanded\n  Exploration in the Energy-Based Latent Space",
        "link": "http://arxiv.org/abs/2405.16730v1",
        "abstract": "Offline Black-Box Optimization (BBO) aims at optimizing a black-box function\nusing the knowledge from a pre-collected offline dataset of function values and\ncorresponding input designs. However, the high-dimensional and\nhighly-multimodal input design space of black-box function pose inherent\nchallenges for most existing methods that model and operate directly upon input\ndesigns. These issues include but are not limited to high sample complexity,\nwhich relates to inaccurate approximation of black-box function; and\ninsufficient coverage and exploration of input design modes, which leads to\nsuboptimal proposal of new input designs. In this work, we consider finding a\nlatent space that serves as a compressed yet accurate representation of the\ndesign-value joint space, enabling effective latent exploration of high-value\ninput design modes. To this end, we formulate an learnable energy-based latent\nspace, and propose Noise-intensified Telescoping density-Ratio Estimation\n(NTRE) scheme for variational learning of an accurate latent space model\nwithout costly Markov Chain Monte Carlo. The optimization process is then\nexploration of high-value designs guided by the learned energy-based model in\nthe latent space, formulated as gradient-based sampling from a\nlatent-variable-parameterized inverse model. We show that our particular\nparameterization encourages expanded exploration around high-value design\nmodes, motivated by inversion thinking of a fundamental result of conditional\ncovariance matrix typically used for variance reduction. We observe that our\nmethod, backed by an accurately learned informative latent space and an\nexpanding-exploration model design, yields significant improvements over strong\nprevious methods on both synthetic and real world datasets such as the\ndesign-bench suite.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.AP"
        ],
        "authors": [
            "Peiyu Yu",
            "Dinghuai Zhang",
            "Hengzhi He",
            "Xiaojian Ma",
            "Ruiyao Miao",
            "Yifan Lu",
            "Yasi Zhang",
            "Deqian Kong",
            "Ruiqi Gao",
            "Jianwen Xie",
            "Guang Cheng",
            "Ying Nian Wu"
        ],
        "published": "2024-05-27T00:11:53Z"
    },
    {
        "title": "Free-Space Optical Channel Turbulence Prediction: A Machine Learning\n  Approach",
        "link": "http://arxiv.org/abs/2405.16729v1",
        "abstract": "Channel turbulence presents a formidable obstacle for free-space optical\n(FSO) communication. Anticipation of turbulence levels is highly important for\nmitigating disruptions. We study the application of machine learning (ML) to\nFSO data streams to rapidly predict channel turbulence levels with no\nadditional sensing hardware. An optical bit stream was transmitted through a\ncontrolled channel in the lab under six distinct turbulence levels, and the\nefficacy of using ML to classify turbulence levels was examined. ML-based\nturbulence level classification was found to be >98% accurate with multiple ML\ntraining parameters, but highly dependent upon the timescale of changes between\nturbulence levels.",
        "subjects": [
            "eess.SY",
            "cs.LG",
            "cs.SY"
        ],
        "authors": [
            "Md Zobaer Islam",
            "Ethan Abele",
            "Fahim Ferdous Hossain",
            "Arsalan Ahmad",
            "Sabit Ekin",
            "John F. O'Hara"
        ],
        "published": "2024-05-27T00:08:36Z"
    }
]