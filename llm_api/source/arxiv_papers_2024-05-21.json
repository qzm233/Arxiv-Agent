[
    {
        "title": "Low-Complexity PSCL Decoding of Polar Codes",
        "link": "http://arxiv.org/abs/2405.13255v1",
        "abstract": "Successive cancellation list (SCL) decoding enables polar codes and their\ngeneralizations to deliver satisfactory performance in finite-length scenarios\nbut it comes with high latency and complexity. To reduce latency, a partitioned\nSCL (PSCL) decoding algorithm, implemented over a PSCL decoding tree, can be\nutilized. In this work, we aim to lower down the complexity of the PSCL\ndecoding, resulting in an efficient decoding algorithm with low latency and\ncomplexity for polar-like codes. To achieve this, we define two metrics at each\nlevel of the PSCL decoding tree. One is for evaluating the reliability of a\npath and the other is for estimating the probability of the correct path being\nincluded in a list of paths. Then, we propose a double-threshold strategy in\nthe PSCL decoding process where unreliable valid paths are pruned based on the\nfirst metric, and then a list of surviving paths is selected based on the\nsecond metric. Simulation results demonstrate that when polar/CRC-polar/PAC\ncodes are decoded using the proposed low-complexity PSCL decoder, both the\nsorting complexity and the computational complexity are reduced and\nsignificantly decrease as the signal-to-noise ratio (SNR) increases.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Xinyuanmeng Yao",
            "Xiao Ma"
        ],
        "published": "2024-05-21T23:54:09Z"
    },
    {
        "title": "System Safety Monitoring of Learned Components Using Temporal Metric\n  Forecasting",
        "link": "http://arxiv.org/abs/2405.13254v1",
        "abstract": "In learning-enabled autonomous systems, safety monitoring of learned\ncomponents is crucial to ensure their outputs do not lead to system safety\nviolations, given the operational context of the system. However, developing a\nsafety monitor for practical deployment in real-world applications is\nchallenging. This is due to limited access to internal workings and training\ndata of the learned component. Furthermore, safety monitors should predict\nsafety violations with low latency, while consuming a reasonable amount of\ncomputation.\n  To address the challenges, we propose a safety monitoring method based on\nprobabilistic time series forecasting. Given the learned component outputs and\nan operational context, we empirically investigate different Deep Learning\n(DL)-based probabilistic forecasting to predict the objective measure capturing\nthe satisfaction or violation of a safety requirement (safety metric). We\nempirically evaluate safety metric and violation prediction accuracy, and\ninference latency and resource usage of four state-of-the-art models, with\nvarying horizons, using an autonomous aviation case study. Our results suggest\nthat probabilistic forecasting of safety metrics, given learned component\noutputs and scenarios, is effective for safety monitoring. Furthermore, for the\nautonomous aviation case study, Temporal Fusion Transformer (TFT) was the most\naccurate model for predicting imminent safety violations, with acceptable\nlatency and resource consumption.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.RO",
            "cs.SE"
        ],
        "authors": [
            "Sepehr Sharifi",
            "Andrea Stocco",
            "Lionel C. Briand"
        ],
        "published": "2024-05-21T23:48:26Z"
    },
    {
        "title": "Improving Earth-like planet detection in radial velocity using deep\n  learning",
        "link": "http://arxiv.org/abs/2405.13247v1",
        "abstract": "Many novel methods have been proposed to mitigate stellar activity for\nexoplanet detection as the presence of stellar activity in radial velocity (RV)\nmeasurements is the current major limitation. Unlike traditional methods that\nmodel stellar activity in the RV domain, more methods are moving in the\ndirection of disentangling stellar activity at the spectral level. The goal of\nthis paper is to present a novel convolutional neural network-based algorithm\nthat efficiently models stellar activity signals at the spectral level,\nenhancing the detection of Earth-like planets. We trained a convolutional\nneural network to build the correlation between the change in the spectral line\nprofile and the corresponding RV, full width at half maximum (FWHM) and\nbisector span (BIS) values derived from the classical cross-correlation\nfunction. This algorithm has been tested on three intensively observed stars:\nAlpha Centauri B (HD128621), Tau ceti (HD10700), and the Sun. By injecting\nsimulated planetary signals at the spectral level, we demonstrate that our\nmachine learning algorithm can achieve, for HD128621 and HD10700, a detection\nthreshold of 0.5 m/s in semi-amplitude for planets with periods ranging from 10\nto 300 days. This threshold would correspond to the detection of a\n$\\sim$4$\\mathrm{M}_{\\oplus}$ in the habitable zone of those stars. On the\nHARPS-N solar dataset, our algorithm is even more efficient at mitigating\nstellar activity signals and can reach a threshold of 0.2 m/s, which would\ncorrespond to a 2.2$\\mathrm{M}_{\\oplus}$ planet on the orbit of the Earth. To\nthe best of our knowledge, it is the first time that such low detection\nthresholds are reported for the Sun, but also for other stars, and therefore\nthis highlights the efficiency of our convolutional neural network-based\nalgorithm at mitigating stellar activity in RV measurements.",
        "subjects": [
            "astro-ph.EP",
            "astro-ph.IM",
            "cs.LG"
        ],
        "authors": [
            "Yinan Zhao",
            "Xavier Dumusque",
            "Michael Cretignier",
            "Andrew Collier Cameron",
            "David W. Latham",
            "Mercedes López-Morales",
            "Michel Mayor",
            "Alessandro Sozzetti",
            "Rosario Cosentino",
            "Isidro Gómez-Vargas",
            "Francesco Pepe",
            "Stephane Udry"
        ],
        "published": "2024-05-21T23:28:20Z"
    },
    {
        "title": "A Survey of Robotic Language Grounding: Tradeoffs Between Symbols and\n  Embeddings",
        "link": "http://arxiv.org/abs/2405.13245v1",
        "abstract": "With large language models, robots can understand language more flexibly and\nmore capable than ever before. This survey reviews recent literature and\nsituates it into a spectrum with two poles: 1) mapping between language and\nsome manually defined formal representation of meaning, and 2) mapping between\nlanguage and high-dimensional vector spaces that translate directly to\nlow-level robot policy. Using a formal representation allows the meaning of the\nlanguage to be precisely represented, limits the size of the learning problem,\nand leads to a framework for interpretability and formal safety guarantees.\nMethods that embed language and perceptual data into high-dimensional spaces\navoid this manually specified symbolic structure and thus have the potential to\nbe more general when fed enough data but require more data and computing to\ntrain. We discuss the benefits and tradeoffs of each approach and finish by\nproviding directions for future work that achieves the best of both worlds.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Vanya Cohen",
            "Jason Xinyu Liu",
            "Raymond Mooney",
            "Stefanie Tellex",
            "David Watkins"
        ],
        "published": "2024-05-21T23:12:03Z"
    },
    {
        "title": "A Novel Approach to Evaluating Battery Charger Controller Design with\n  Nonlinear PID Controller in an Extendable CHIL Setup",
        "link": "http://arxiv.org/abs/2405.13243v1",
        "abstract": "The design and development of power electronics converters pose a multitude\nof challenges. The evaluation of power electronics converters, particularly\nwhen operating at high power levels, presents a significant task, offering\ndesigners a deeper understanding of the functionality. Several methodologies\nhave been devised to conduct hardware-in-the-loop (HIL) tests, which are\nclassified into two main categories: controller hardware-in-the-loop (CHIL) and\npower hardware-in-the-loop (PHIL) tests. This paper explores the advantages and\ndrawbacks of these two approaches and introduces a straightforward and\ncost-effective CHIL method for initial proof of concept and risk-free\ncontroller training. This method is based on the interaction between\nMATLAB/Simulink and Python. To assess the operation of the proposed system, a\nmodeled battery pack (96S1P) is charged using a modeled battery charger\nconverter, employing a non-linear PID controller. In this scenario, the\ncontroller benefits from the CC-CV technique for charging the battery pack. The\nresults are presented in the final section.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Shervin Salehi Rad",
            "Micheal Muhlbaier",
            "Oleg Fishman",
            "Javad Chevinly",
            "Elias Nadi",
            "Hua Zhang",
            "Fei Lu"
        ],
        "published": "2024-05-21T23:10:57Z"
    },
    {
        "title": "Goals as Reward-Producing Programs",
        "link": "http://arxiv.org/abs/2405.13242v1",
        "abstract": "People are remarkably capable of generating their own goals, beginning with\nchild's play and continuing into adulthood. Despite considerable empirical and\ncomputational work on goals and goal-oriented behavior, models are still far\nfrom capturing the richness of everyday human goals. Here, we bridge this gap\nby collecting a dataset of human-generated playful goals, modeling them as\nreward-producing programs, and generating novel human-like goals through\nprogram synthesis. Reward-producing programs capture the rich semantics of\ngoals through symbolic operations that compose, add temporal constraints, and\nallow for program execution on behavioral traces to evaluate progress. To build\na generative model of goals, we learn a fitness function over the infinite set\nof possible goal programs and sample novel goals with a quality-diversity\nalgorithm. Human evaluators found that model-generated goals, when sampled from\npartitions of program space occupied by human examples, were indistinguishable\nfrom human-created games. We also discovered that our model's internal fitness\nscores predict games that are evaluated as more fun to play and more\nhuman-like.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Guy Davidson",
            "Graham Todd",
            "Julian Togelius",
            "Todd M. Gureckis",
            "Brenden M. Lake"
        ],
        "published": "2024-05-21T23:09:12Z"
    },
    {
        "title": "Enhancing User Interest based on Stream Clustering and Memory Networks\n  in Large-Scale Recommender Systems",
        "link": "http://arxiv.org/abs/2405.13238v1",
        "abstract": "Recommender Systems (RSs) provide personalized recommendation service based\non user interest, which are widely used in various platforms. However, there\nare lots of users with sparse interest due to lacking consumption behaviors,\nwhich leads to poor recommendation results for them. This problem is widespread\nin large-scale RSs and is particularly difficult to address. To solve this\nproblem, we propose a novel solution named User Interest Enhancement (UIE)\nwhich enhances user interest including user profile and user history behavior\nsequences using the enhancement vectors and personalized enhancement vector\ngenerated based on stream clustering and memory networks from different\nperspectives. UIE not only remarkably improves model performance on the users\nwith sparse interest but also significantly enhance model performance on other\nusers. UIE is an end-to-end solution which is easy to be implemented based on\nranking model. Moreover, we expand our solution and apply similar methods to\nlong-tail items, which also achieves excellent improvement. Furthermore, we\nconduct extensive offline and online experiments in a large-scale industrial\nRS. The results demonstrate that our model outperforms other models remarkably,\nespecially for the users with sparse interest. Until now, UIE has been fully\ndeployed in multiple large-scale RSs and achieved remarkable improvements.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "authors": [
            "Peng Liu",
            "Nian Wang",
            "Cong Xu",
            "Ming Zhao",
            "Bin Wang",
            "Yi Ren"
        ],
        "published": "2024-05-21T22:53:00Z"
    },
    {
        "title": "Spatial Matching of 2D Mammography Images and Specimen Radiographs:\n  Towards Improved Characterization of Suspicious Microcalcifications",
        "link": "http://arxiv.org/abs/2405.13237v1",
        "abstract": "Accurate characterization of suspicious microcalcifications is critical to\ndetermine whether these calcifications are associated with invasive disease.\nOur overarching objective is to enable the joint characterization of\nmicrocalcifications and surrounding breast tissue using mammography images and\ndigital histopathology images. Towards this goal, we investigate a template\nmatching-based approach that utilizes microcalcifications as landmarks to match\nradiographs taken of biopsy core specimens to groups of calcifications that are\nvisible on mammography. Our approach achieved a high negative predictive value\n(0.98) but modest precision (0.66) and recall (0.58) in identifying the\nmammographic region where microcalcifications were taken during a core needle\nbiopsy.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Noor Nakhaei",
            "Chrysostomos Marasinou",
            "Akinyinka Omigbodun",
            "Nina Capiro",
            "Bo Li",
            "Anne Hoyt",
            "William Hsu"
        ],
        "published": "2024-05-21T22:51:06Z"
    },
    {
        "title": "Geometric Transformation Uncertainty for Improving 3D Fetal Brain Pose\n  Prediction from Freehand 2D Ultrasound Videos",
        "link": "http://arxiv.org/abs/2405.13235v1",
        "abstract": "Accurately localizing two-dimensional (2D) ultrasound (US) fetal brain images\nin the 3D brain, using minimal computational resources, is an important task\nfor automated US analysis of fetal growth and development. We propose an\nuncertainty-aware deep learning model for automated 3D plane localization in 2D\nfetal brain images. Specifically, a multi-head network is trained to jointly\nregress 3D plane pose from 2D images in terms of different geometric\ntransformations. The model explicitly learns to predict uncertainty to allocate\nhigher weight to inputs with low variances across different transformations to\nimprove performance. Our proposed method, QAERTS, demonstrates superior pose\nestimation accuracy than the state-of-the-art and most of the uncertainty-based\napproaches, leading to 9% improvement on plane angle (PA) for localization\naccuracy, and 8% on normalized cross-correlation (NCC) for sampled image\nquality. QAERTS also demonstrates efficiency, containing 5$\\times$ fewer\nparameters than ensemble-based approach, making it advantageous in\nresource-constrained settings. In addition, QAERTS proves to be more robust to\nnoise effects observed in freehand US scanning by leveraging rotational\ndiscontinuities and explicit output uncertainties.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Jayroop Ramesh",
            "Nicola K Dinsdale",
            "the INTERGROWTH-21st Consortium",
            "Pak-Hei Yeung",
            "Ana IL Namburete"
        ],
        "published": "2024-05-21T22:42:08Z"
    },
    {
        "title": "MELD-ST: An Emotion-aware Speech Translation Dataset",
        "link": "http://arxiv.org/abs/2405.13233v1",
        "abstract": "Emotion plays a crucial role in human conversation. This paper underscores\nthe significance of considering emotion in speech translation. We present the\nMELD-ST dataset for the emotion-aware speech translation task, comprising\nEnglish-to-Japanese and English-to-German language pairs. Each language pair\nincludes about 10,000 utterances annotated with emotion labels from the MELD\ndataset. Baseline experiments using the SeamlessM4T model on the dataset\nindicate that fine-tuning with emotion labels can enhance translation\nperformance in some settings, highlighting the need for further research in\nemotion-aware speech translation systems.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Sirou Chen",
            "Sakiko Yahata",
            "Shuichiro Shimizu",
            "Zhengdong Yang",
            "Yihang Li",
            "Chenhui Chu",
            "Sadao Kurohashi"
        ],
        "published": "2024-05-21T22:40:38Z"
    },
    {
        "title": "Multiple Realizability and the Rise of Deep Learning",
        "link": "http://arxiv.org/abs/2405.13231v1",
        "abstract": "The multiple realizability thesis holds that psychological states may be\nimplemented in a diversity of physical systems. The deep learning revolution\nseems to be bringing this possibility to life, offering the most plausible\nexamples of man-made realizations of sophisticated cognitive functions to date.\nThis paper explores the implications of deep learning models for the multiple\nrealizability thesis. Among other things, it challenges the widely held view\nthat multiple realizability entails that the study of the mind can and must be\npursued independently of the study of its implementation in the brain or in\nartificial analogues. Although its central contribution is philosophical, the\npaper has substantial methodological upshots for contemporary cognitive\nscience, suggesting that deep neural networks may play a crucial role in\nformulating and evaluating hypotheses about cognition, even if they are\ninterpreted as implementation-level models. In the age of deep learning,\nmultiple realizability possesses a renewed significance.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Sam Whitman McGrath",
            "Jacob Russin"
        ],
        "published": "2024-05-21T22:36:49Z"
    },
    {
        "title": "Transfer Learning Approach for Railway Technical Map (RTM) Component\n  Identification",
        "link": "http://dx.doi.org/10.1007/978-981-19-2397-5_44",
        "abstract": "The extreme popularity over the years for railway transportation urges the\nnecessity to maintain efficient railway management systems around the globe.\nEven though, at present, there exist a large collection of Computer Aided\nDesigned Railway Technical Maps (RTMs) but available only in the portable\ndocument format (PDF). Using Deep Learning and Optical Character Recognition\ntechniques, this research work proposes a generic system to digitize the\nrelevant map component data from a given input image and create a formatted\ntext file per image. Out of YOLOv3, SSD and Faster-RCNN object detection models\nused, Faster-RCNN yields the highest mean Average Precision (mAP) and the\nhighest F1 score values 0.68 and 0.76 respectively. Further it is proven from\nthe results obtained that, one can improve the results with OCR when the text\ncontaining image is being sent through a sophisticated pre-processing pipeline\nto remove distortions.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.DL"
        ],
        "authors": [
            "Obadage Rochana Rumalshan",
            "Pramuka Weerasinghe",
            "Mohamed Shaheer",
            "Prabhath Gunathilake",
            "Erunika Dayaratna"
        ],
        "published": "2024-05-21T22:35:08Z"
    },
    {
        "title": "A rapid approach to urban traffic noise mapping with a generative\n  adversarial network",
        "link": "http://arxiv.org/abs/2405.13227v1",
        "abstract": "With rapid urbanisation and the accompanying increase in traffic density,\ntraffic noise has become a major concern in urban planning. However,\ntraditional grid noise mapping methods have limitations in terms of time\nconsumption, software costs, and a lack of parameter integration interfaces.\nThese limitations hinder their ability to meet the need for iterative updates\nand rapid performance feedback in the early design stages of street-scale urban\nplanning. Herein, we developed a rapid urban traffic noise mapping technique\nthat leverages generative adversarial networks (GANs) as a surrogate model.\nThis approach enables the rapid assessment of urban traffic noise distribution\nby using urban elements such as roads and buildings as the input. The mean\nvalues for the mean squared error (MSE) and structural similarity index (SSIM)\nare 0.0949 and 0.8528, respectively, for the validation dataset. Hence, our\nprediction accuracy is on par with that of conventional prediction software.\nFurthermore, the trained model is integrated into Grasshopper as a tool,\nfacilitating the rapid generation of traffic noise maps. This integration\nallows urban designers and planners, even those without expertise in acoustics,\nto easily anticipate changes in acoustics impacts caused by design.",
        "subjects": [
            "cs.LG",
            "physics.app-ph"
        ],
        "authors": [
            "Xinhao Yang",
            "Zhen Han",
            "Xiaodong Lu",
            "Yuan Zhang"
        ],
        "published": "2024-05-21T22:28:41Z"
    },
    {
        "title": "Dataset Decomposition: Faster LLM Training with Variable Sequence Length\n  Curriculum",
        "link": "http://arxiv.org/abs/2405.13226v1",
        "abstract": "Large language models (LLMs) are commonly trained on datasets consisting of\nfixed-length token sequences. These datasets are created by randomly\nconcatenating documents of various lengths and then chunking them into\nsequences of a predetermined target length. However, this method of\nconcatenation can lead to cross-document attention within a sequence, which is\nneither a desirable learning signal nor computationally efficient.\nAdditionally, training on long sequences becomes computationally prohibitive\ndue to the quadratic cost of attention. In this study, we introduce dataset\ndecomposition, a novel variable sequence length training technique, to tackle\nthese challenges. We decompose a dataset into a union of buckets, each\ncontaining sequences of the same size extracted from a unique document. During\ntraining, we use variable sequence length and batch size, sampling\nsimultaneously from all buckets with a curriculum. In contrast to the\nconcat-and-chunk baseline, which incurs a fixed attention cost at every step of\ntraining, our proposed method incurs a penalty proportional to the actual\ndocument lengths at each step, resulting in significant savings in training\ntime. We train an 8k context-length 1B model at the same cost as a 2k\ncontext-length model trained with the baseline approach. Experiments on a\nweb-scale corpus demonstrate that our approach significantly enhances\nperformance on standard language evaluations and long-context benchmarks,\nreaching target accuracy 3x faster compared to the baseline. Our method not\nonly enables efficient pretraining on long sequences but also scales\neffectively with dataset size. Lastly, we shed light on a critical yet less\nstudied aspect of training large language models: the distribution and\ncurriculum of sequence lengths, which results in a non-negligible difference in\nperformance.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Hadi Pouransari",
            "Chun-Liang Li",
            "Jen-Hao Rick Chang",
            "Pavan Kumar Anasosalu Vasu",
            "Cem Koc",
            "Vaishaal Shankar",
            "Oncel Tuzel"
        ],
        "published": "2024-05-21T22:26:01Z"
    },
    {
        "title": "Integrating behavioral experimental findings into dynamical models to\n  inform social change interventions",
        "link": "http://arxiv.org/abs/2405.13224v1",
        "abstract": "Addressing global challenges -- from public health to climate change -- often\ninvolves stimulating the large-scale adoption of new products or behaviors.\nResearch traditions that focus on individual decision making suggest that\nachieving this objective requires better identifying the drivers of individual\nadoption choices. On the other hand, computational approaches rooted in\ncomplexity science focus on maximizing the propagation of a given product or\nbehavior throughout social networks of interconnected adopters. The integration\nof these two perspectives -- although advocated by several research communities\n-- has remained elusive so far. Here we show how achieving this integration\ncould inform seeding policies to facilitate the large-scale adoption of a given\nbehavior or product. Drawing on complex contagion and discrete choice theories,\nwe propose a method to estimate individual-level thresholds to adoption, and\nvalidate its predictive power in two choice experiments. By integrating the\nestimated thresholds into computational simulations, we show that\nstate-of-the-art seeding methods for social influence maximization might be\nsuboptimal if they neglect individual-level behavioral drivers, which can be\ncorrected through the proposed experimental method.",
        "subjects": [
            "physics.soc-ph",
            "cs.SI",
            "econ.EM"
        ],
        "authors": [
            "Radu Tanase",
            "René Algesheimer",
            "Manuel S. Mariani"
        ],
        "published": "2024-05-21T22:17:17Z"
    },
    {
        "title": "Paired Autoencoders for Inverse Problems",
        "link": "http://arxiv.org/abs/2405.13220v1",
        "abstract": "We consider the solution of nonlinear inverse problems where the forward\nproblem is a discretization of a partial differential equation. Such problems\nare notoriously difficult to solve in practice and require minimizing a\ncombination of a data-fit term and a regularization term. The main\ncomputational bottleneck of typical algorithms is the direct estimation of the\ndata misfit. Therefore, likelihood-free approaches have become appealing\nalternatives. Nonetheless, difficulties in generalization and limitations in\naccuracy have hindered their broader utility and applicability. In this work,\nwe use a paired autoencoder framework as a likelihood-free estimator for\ninverse problems. We show that the use of such an architecture allows us to\nconstruct a solution efficiently and to overcome some known open problems when\nusing likelihood-free estimators. In particular, our framework can assess the\nquality of the solution and improve on it if needed. We demonstrate the\nviability of our approach using examples from full waveform inversion and\ninverse electromagnetic imaging.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Matthias Chung",
            "Emma Hart",
            "Julianne Chung",
            "Bas Peters",
            "Eldad Haber"
        ],
        "published": "2024-05-21T22:00:34Z"
    },
    {
        "title": "How Reliable AI Chatbots are for Disease Prediction from Patient\n  Complaints?",
        "link": "http://arxiv.org/abs/2405.13219v1",
        "abstract": "Artificial Intelligence (AI) chatbots leveraging Large Language Models (LLMs)\nare gaining traction in healthcare for their potential to automate patient\ninteractions and aid clinical decision-making. This study examines the\nreliability of AI chatbots, specifically GPT 4.0, Claude 3 Opus, and Gemini\nUltra 1.0, in predicting diseases from patient complaints in the emergency\ndepartment. The methodology includes few-shot learning techniques to evaluate\nthe chatbots' effectiveness in disease prediction. We also fine-tune the\ntransformer-based model BERT and compare its performance with the AI chatbots.\nResults suggest that GPT 4.0 achieves high accuracy with increased few-shot\ndata, while Gemini Ultra 1.0 performs well with fewer examples, and Claude 3\nOpus maintains consistent performance. BERT's performance, however, is lower\nthan all the chatbots, indicating limitations due to limited labeled data.\nDespite the chatbots' varying accuracy, none of them are sufficiently reliable\nfor critical medical decision-making, underscoring the need for rigorous\nvalidation and human oversight. This study reflects that while AI chatbots have\npotential in healthcare, they should complement, not replace, human expertise\nto ensure patient safety. Further refinement and research are needed to improve\nAI-based healthcare applications' reliability for disease prediction.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Ayesha Siddika Nipu",
            "K M Sajjadul Islam",
            "Praveen Madiraju"
        ],
        "published": "2024-05-21T22:00:13Z"
    },
    {
        "title": "Study on spike-and-wave detection in epileptic signals using\n  t-location-scale distribution and the K-nearest neighbors classifier",
        "link": "http://dx.doi.org/10.1109/URUCON.2017.8171869",
        "abstract": "Pattern classification in electroencephalography (EEG) signals is an\nimportant problem in biomedical engineering since it enables the detection of\nbrain activity, particularly the early detection of epileptic seizures. In this\npaper, we propose a k-nearest neighbors classification for epileptic EEG\nsignals based on a t-location-scale statistical representation to detect\nspike-and-waves. The proposed approach is demonstrated on a real dataset\ncontaining both spike-and-wave events and normal brain function signals, where\nour performance is evaluated in terms of classification accuracy, sensitivity,\nand specificity.",
        "subjects": [
            "stat.AP",
            "cs.LG",
            "stat.CO",
            "stat.ML"
        ],
        "authors": [
            "Antonio Quintero-Rincón",
            "Jorge Prendes",
            "Valeria Muro",
            "Carlos D'Giano"
        ],
        "published": "2024-05-21T21:52:08Z"
    },
    {
        "title": "Computational Tradeoffs in Image Synthesis: Diffusion, Masked-Token, and\n  Next-Token Prediction",
        "link": "http://arxiv.org/abs/2405.13218v2",
        "abstract": "Nearly every recent image synthesis approach, including diffusion,\nmasked-token prediction, and next-token prediction, uses a Transformer network\narchitecture. Despite this common backbone, there has been no direct, compute\ncontrolled comparison of how these approaches affect performance and\nefficiency. We analyze the scalability of each approach through the lens of\ncompute budget measured in FLOPs. We find that token prediction methods, led by\nnext-token prediction, significantly outperform diffusion on prompt following.\nOn image quality, while next-token prediction initially performs better,\nscaling trends suggest it is eventually matched by diffusion. We compare the\ninference compute efficiency of each approach and find that next token\nprediction is by far the most efficient. Based on our findings we recommend\ndiffusion for applications targeting image quality and low latency; and\nnext-token prediction when prompt following or throughput is more important.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Maciej Kilian",
            "Varun Jampani",
            "Luke Zettlemoyer"
        ],
        "published": "2024-05-21T21:49:39Z"
    },
    {
        "title": "Interactive Simulations of Backdoors in Neural Networks",
        "link": "http://arxiv.org/abs/2405.13217v1",
        "abstract": "This work addresses the problem of planting and defending cryptographic-based\nbackdoors in artificial intelligence (AI) models. The motivation comes from our\nlack of understanding and the implications of using cryptographic techniques\nfor planting undetectable backdoors under theoretical assumptions in the large\nAI model systems deployed in practice. Our approach is based on designing a\nweb-based simulation playground that enables planting, activating, and\ndefending cryptographic backdoors in neural networks (NN). Simulations of\nplanting and activating backdoors are enabled for two scenarios: in the\nextension of NN model architecture to support digital signature verification\nand in the modified architectural block for non-linear operators. Simulations\nof backdoor defense against backdoors are available based on proximity analysis\nand provide a playground for a game of planting and defending against\nbackdoors. The simulations are available at\nhttps://pages.nist.gov/nn-calculator",
        "subjects": [
            "cs.LG",
            "cs.CR",
            "68",
            "I.2; I.6; E.3"
        ],
        "authors": [
            "Peter Bajcsy",
            "Maxime Bros"
        ],
        "published": "2024-05-21T21:42:49Z"
    },
    {
        "title": "Equipping Transformer with Random-Access Reading for Long-Context\n  Understanding",
        "link": "http://arxiv.org/abs/2405.13216v1",
        "abstract": "Long-context modeling presents a significant challenge for transformer-based\nlarge language models (LLMs) due to the quadratic complexity of the\nself-attention mechanism and issues with length extrapolation caused by\npretraining exclusively on short inputs. Existing methods address computational\ncomplexity through techniques such as text chunking, the kernel approach, and\nstructured attention, and tackle length extrapolation problems through\npositional encoding, continued pretraining, and data engineering. These\napproaches typically require $\\textbf{sequential access}$ to the document,\nnecessitating reading from the first to the last token. We contend that for\ngoal-oriented reading of long documents, such sequential access is not\nnecessary, and a proficiently trained model can learn to omit hundreds of less\npertinent tokens. Inspired by human reading behaviors and existing empirical\nobservations, we propose $\\textbf{random access}$, a novel reading strategy\nthat enables transformers to efficiently process long documents without\nexamining every token. Experimental results from pretraining, fine-tuning, and\ninference phases validate the efficacy of our method.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Chenghao Yang",
            "Zi Yang",
            "Nan Hua"
        ],
        "published": "2024-05-21T21:41:07Z"
    },
    {
        "title": "Investigating Symbolic Capabilities of Large Language Models",
        "link": "http://arxiv.org/abs/2405.13209v1",
        "abstract": "Prompting techniques have significantly enhanced the capabilities of Large\nLanguage Models (LLMs) across various complex tasks, including reasoning,\nplanning, and solving math word problems. However, most research has\npredominantly focused on language-based reasoning and word problems, often\noverlooking the potential of LLMs in handling symbol-based calculations and\nreasoning. This study aims to bridge this gap by rigorously evaluating LLMs on\na series of symbolic tasks, such as addition, multiplication, modulus\narithmetic, numerical precision, and symbolic counting. Our analysis\nencompasses eight LLMs, including four enterprise-grade and four open-source\nmodels, of which three have been pre-trained on mathematical tasks. The\nassessment framework is anchored in Chomsky's Hierarchy, providing a robust\nmeasure of the computational abilities of these models. The evaluation employs\nminimally explained prompts alongside the zero-shot Chain of Thoughts\ntechnique, allowing models to navigate the solution process autonomously. The\nfindings reveal a significant decline in LLMs' performance on context-free and\ncontext-sensitive symbolic tasks as the complexity, represented by the number\nof symbols, increases. Notably, even the fine-tuned GPT3.5 exhibits only\nmarginal improvements, mirroring the performance trends observed in other\nmodels. Across the board, all models demonstrated a limited generalization\nability on these symbol-intensive tasks. This research underscores LLMs'\nchallenges with increasing symbolic complexity and highlights the need for\nspecialized training, memory and architectural adjustments to enhance their\nproficiency in symbol-based reasoning tasks.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Neisarg Dave",
            "Daniel Kifer",
            "C. Lee Giles",
            "Ankur Mali"
        ],
        "published": "2024-05-21T21:24:34Z"
    },
    {
        "title": "Identity-free Artificial Emotional Intelligence via Micro-Gesture\n  Understanding",
        "link": "http://arxiv.org/abs/2405.13206v1",
        "abstract": "In this work, we focus on a special group of human body language -- the\nmicro-gesture (MG), which differs from the range of ordinary illustrative\ngestures in that they are not intentional behaviors performed to convey\ninformation to others, but rather unintentional behaviors driven by inner\nfeelings. This characteristic introduces two novel challenges regarding\nmicro-gestures that are worth rethinking. The first is whether strategies\ndesigned for other action recognition are entirely applicable to\nmicro-gestures. The second is whether micro-gestures, as supplementary data,\ncan provide additional insights for emotional understanding. In recognizing\nmicro-gestures, we explored various augmentation strategies that take into\naccount the subtle spatial and brief temporal characteristics of\nmicro-gestures, often accompanied by repetitiveness, to determine more suitable\naugmentation methods. Considering the significance of temporal domain\ninformation for micro-gestures, we introduce a simple and efficient\nplug-and-play spatiotemporal balancing fusion method. We not only studied our\nmethod on the considered micro-gesture dataset but also conducted experiments\non mainstream action datasets. The results show that our approach performs well\nin micro-gesture recognition and on other datasets, achieving state-of-the-art\nperformance compared to previous micro-gesture recognition methods. For\nemotional understanding based on micro-gestures, we construct complex emotional\nreasoning scenarios. Our evaluation, conducted with large language models,\nshows that micro-gestures play a significant and positive role in enhancing\ncomprehensive emotional understanding. The scenarios we developed can be\nextended to other micro-gesture-based tasks such as deception detection and\ninterviews. We confirm that our new insights contribute to advancing research\nin micro-gesture and emotional artificial intelligence.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Rong Gao",
            "Xin Liu",
            "Bohao Xing",
            "Zitong Yu",
            "Bjorn W. Schuller",
            "Heikki Kälviäinen"
        ],
        "published": "2024-05-21T21:16:55Z"
    },
    {
        "title": "Multi-Agent Reinforcement Learning with Hierarchical Coordination for\n  Emergency Responder Stationing",
        "link": "http://arxiv.org/abs/2405.13205v1",
        "abstract": "An emergency responder management (ERM) system dispatches responders, such as\nambulances, when it receives requests for medical aid. ERM systems can also\nproactively reposition responders between predesignated waiting locations to\ncover any gaps that arise due to the prior dispatch of responders or\nsignificant changes in the distribution of anticipated requests. Optimal\nrepositioning is computationally challenging due to the exponential number of\nways to allocate responders between locations and the uncertainty in future\nrequests. The state-of-the-art approach in proactive repositioning is a\nhierarchical approach based on spatial decomposition and online Monte Carlo\ntree search, which may require minutes of computation for each decision in a\ndomain where seconds can save lives. We address the issue of long decision\ntimes by introducing a novel reinforcement learning (RL) approach, based on the\nsame hierarchical decomposition, but replacing online search with learning. To\naddress the computational challenges posed by large, variable-dimensional, and\ndiscrete state and action spaces, we propose: (1) actor-critic based agents\nthat incorporate transformers to handle variable-dimensional states and\nactions, (2) projections to fixed-dimensional observations to handle complex\nstates, and (3) combinatorial techniques to map continuous actions to discrete\nallocations. We evaluate our approach using real-world data from two U.S.\ncities, Nashville, TN and Seattle, WA. Our experiments show that compared to\nthe state of the art, our approach reduces computation time per decision by\nthree orders of magnitude, while also slightly reducing average ambulance\nresponse time by 5 seconds.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Amutheezan Sivagnanam",
            "Ava Pettet",
            "Hunter Lee",
            "Ayan Mukhopadhyay",
            "Abhishek Dubey",
            "Aron Laszka"
        ],
        "published": "2024-05-21T21:15:45Z"
    },
    {
        "title": "BeadSight: An Inexpensive Tactile Sensor Using Hydro-Gel Beads",
        "link": "http://arxiv.org/abs/2405.13204v1",
        "abstract": "In robotic manipulation, tactile sensors are indispensable, especially when\ndealing with soft objects, objects of varying dimensions, or those out of the\nrobot's direct line of sight. Traditional tactile sensors often grapple with\nchallenges related to cost and durability. To address these issues, our study\nintroduces a novel approach to visuo-tactile sensing with an emphasis on\neconomy and replacablity. Our proposed sensor, BeadSight, uses hydro-gel beads\nencased in a vinyl bag as an economical, easily replaceable sensing medium.\nWhen the sensor makes contact with a surface, the deformation of the hydrogel\nbeads is observed using a rear camera. This observation is then passed through\na U-net Neural Network to predict the forces acting on the surface of the bead\nbag, in the form of a pressure map. Our results show that the sensor can\naccurately predict these pressure maps, detecting the location and magnitude of\nforces applied to the surface. These abilities make BeadSight an effective,\ninexpensive, and easily replaceable tactile sensor, ideal for many robotics\napplications.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Abraham George",
            "Yibo Chen",
            "Atharva Dikshit",
            "Peter Pak",
            "Amir Barati Farimani"
        ],
        "published": "2024-05-21T21:15:27Z"
    },
    {
        "title": "Modeling Real-Time Interactive Conversations as Timed Diarized\n  Transcripts",
        "link": "http://arxiv.org/abs/2405.13203v1",
        "abstract": "Chatbots built upon language models have exploded in popularity, but they\nhave largely been limited to synchronous, turn-by-turn dialogues. In this paper\nwe present a simple yet general method to simulate real-time interactive\nconversations using pretrained text-only language models, by modeling timed\ndiarized transcripts and decoding them with causal rejection sampling. We\ndemonstrate the promise of this method with two case studies: instant messenger\ndialogues and spoken conversations, which require generation at about 30 tok/s\nand 20 tok/s respectively to maintain real-time interactivity. These\ncapabilities can be added into language models using relatively little data and\nrun on commodity hardware.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "authors": [
            "Garrett Tanzer",
            "Gustaf Ahdritz",
            "Luke Melas-Kyriazi"
        ],
        "published": "2024-05-21T21:14:31Z"
    },
    {
        "title": "Empowering Urban Traffic Management: Elevated 3D LiDAR for Data\n  Collection and Advanced Object Detection Analysis",
        "link": "http://arxiv.org/abs/2405.13202v1",
        "abstract": "The 3D object detection capabilities in urban environments have been\nenormously improved by recent developments in Light Detection and Range (LiDAR)\ntechnology. This paper presents a novel framework that transforms the detection\nand analysis of 3D objects in traffic scenarios by utilizing the power of\nelevated LiDAR sensors. We are presenting our methodology's remarkable capacity\nto collect complex 3D point cloud data, which allows us to accurately and in\ndetail capture the dynamics of urban traffic. Due to the limitation in\nobtaining real-world traffic datasets, we utilize the simulator to generate 3D\npoint cloud for specific scenarios. To support our experimental analysis, we\nfirstly simulate various 3D point cloud traffic-related objects. Then, we use\nthis dataset as a basis for training and evaluating our 3D object detection\nmodels, in identifying and monitoring both vehicles and pedestrians in\nsimulated urban traffic environments. Next, we fine tune the Point\nVoxel-Region-based Convolutional Neural Network (PV-RCNN) architecture, making\nit more suited to handle and understand the massive volumes of point cloud data\ngenerated by our urban traffic simulations. Our results show the effectiveness\nof the proposed solution in accurately detecting objects in traffic scenes and\nhighlight the role of LiDAR in improving urban safety and advancing intelligent\ntransportation systems.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Nawfal Guefrachi",
            "Hakim Ghazzai",
            "Ahmad Alsharoa"
        ],
        "published": "2024-05-21T21:12:09Z"
    },
    {
        "title": "TauAD: MRI-free Tau Anomaly Detection in PET Imaging via Conditioned\n  Diffusion Models",
        "link": "http://arxiv.org/abs/2405.13199v1",
        "abstract": "The emergence of tau PET imaging over the last decade has enabled Alzheimer's\ndisease (AD) researchers to examine tau pathology in vivo and more effectively\ncharacterize the disease trajectories of AD. Current tau PET analysis methods,\nhowever, typically perform inferences on large cortical ROIs and are limited in\nthe detection of localized tau pathology that varies across subjects.\nFurthermore, a high-resolution MRI is required to carry out conventional tau\nPET analysis, which is not commonly acquired in clinical practices and may not\nbe acquired for many elderly patients with dementia due to strong motion\nartifacts, claustrophobia, or certain metal implants. In this work, we propose\na novel conditional diffusion model to perform MRI-free anomaly detection from\ntau PET imaging data. By including individualized conditions and two\ncomplementary loss maps from pseudo-healthy and pseudo-unhealthy\nreconstructions, our model computes an anomaly map across the entire brain area\nthat allows simply training a support vector machine (SVM) for classifying\ndisease severity. We train our model on ADNI subjects (n=534) and evaluate its\nperformance on a separate dataset from the preclinical subjects of the A4\nclinical trial (n=447). We demonstrate that our method outperforms baseline\ngenerative models and the conventional Z-score-based method in anomaly\nlocalization without mis-detecting off-target bindings in sub-cortical and\nout-of-brain areas. By classifying the A4 subjects according to their anomaly\nmap using the SVM trained on ADNI data, we show that our method can\nsuccessfully group preclinical subjects with significantly different cognitive\nfunctions, which further demonstrates the effectiveness of our method in\ncapturing biologically relevant anomaly in tau PET imaging.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Lujia Zhong",
            "Shuo Huang",
            "Jiaxin Yue",
            "Jianwei Zhang",
            "Zhiwei Deng",
            "Wenhao Chi",
            "Yonggang Shi"
        ],
        "published": "2024-05-21T21:02:53Z"
    },
    {
        "title": "Global-Local Detail Guided Transformer for Sea Ice Recognition in\n  Optical Remote Sensing Images",
        "link": "http://arxiv.org/abs/2405.13197v1",
        "abstract": "The recognition of sea ice is of great significance for reflecting climate\nchange and ensuring the safety of ship navigation. Recently, many deep learning\nbased methods have been proposed and applied to segment and recognize sea ice\nregions. However, the diverse scales of sea ice areas, the zigzag and fine edge\ncontours, and the difficulty in distinguishing different types of sea ice pose\nchallenges to existing sea ice recognition models. In this paper, a\nGlobal-Local Detail Guided Transformer (GDGT) method is proposed for sea ice\nrecognition in optical remote sensing images. In GDGT, a global-local feature\nfusiont mechanism is designed to fuse global structural correlation features\nand local spatial detail features. Furthermore, a detail-guided decoder is\ndeveloped to retain more high-resolution detail information during feature\nreconstruction for improving the performance of sea ice recognition.\nExperiments on the produced sea ice dataset demonstrated the effectiveness and\nadvancement of GDGT.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhanchao Huang",
            "Wenjun Hong",
            "Hua Su"
        ],
        "published": "2024-05-21T21:02:20Z"
    },
    {
        "title": "Practical and efficient quantum circuit synthesis and transpiling with\n  Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.13196v1",
        "abstract": "This paper demonstrates the integration of Reinforcement Learning (RL) into\nquantum transpiling workflows, significantly enhancing the synthesis and\nrouting of quantum circuits. By employing RL, we achieve near-optimal synthesis\nof Linear Function, Clifford, and Permutation circuits, up to 9, 11 and 65\nqubits respectively, while being compatible with native device instruction sets\nand connectivity constraints, and orders of magnitude faster than optimization\nmethods such as SAT solvers. We also achieve significant reductions in\ntwo-qubit gate depth and count for circuit routing up to 133 qubits with\nrespect to other routing heuristics such as SABRE. We find the method to be\nefficient enough to be useful in practice in typical quantum transpiling\npipelines. Our results set the stage for further AI-powered enhancements of\nquantum computing workflows.",
        "subjects": [
            "quant-ph",
            "cs.AI"
        ],
        "authors": [
            "David Kremer",
            "Victor Villar",
            "Hanhee Paik",
            "Ivan Duran",
            "Ismael Faro",
            "Juan Cruz-Benito"
        ],
        "published": "2024-05-21T20:59:12Z"
    },
    {
        "title": "CamViG: Camera Aware Image-to-Video Generation with Multimodal\n  Transformers",
        "link": "http://arxiv.org/abs/2405.13195v1",
        "abstract": "We extend multimodal transformers to include 3D camera motion as a\nconditioning signal for the task of video generation. Generative video models\nare becoming increasingly powerful, thus focusing research efforts on methods\nof controlling the output of such models. We propose to add virtual 3D camera\ncontrols to generative video methods by conditioning generated video on an\nencoding of three-dimensional camera movement over the course of the generated\nvideo. Results demonstrate that we are (1) able to successfully control the\ncamera during video generation, starting from a single frame and a camera\nsignal, and (2) we demonstrate the accuracy of the generated 3D camera paths\nusing traditional computer vision methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Andrew Marmon",
            "Grant Schindler",
            "José Lezama",
            "Dan Kondratyuk",
            "Bryan Seybold",
            "Irfan Essa"
        ],
        "published": "2024-05-21T20:54:27Z"
    },
    {
        "title": "KPConvX: Modernizing Kernel Point Convolution with Kernel Attention",
        "link": "http://arxiv.org/abs/2405.13194v1",
        "abstract": "In the field of deep point cloud understanding, KPConv is a unique\narchitecture that uses kernel points to locate convolutional weights in space,\ninstead of relying on Multi-Layer Perceptron (MLP) encodings. While it\ninitially achieved success, it has since been surpassed by recent MLP networks\nthat employ updated designs and training strategies. Building upon the kernel\npoint principle, we present two novel designs: KPConvD (depthwise KPConv), a\nlighter design that enables the use of deeper architectures, and KPConvX, an\ninnovative design that scales the depthwise convolutional weights of KPConvD\nwith kernel attention values. Using KPConvX with a modern architecture and\ntraining strategy, we are able to outperform current state-of-the-art\napproaches on the ScanObjectNN, Scannetv2, and S3DIS datasets. We validate our\ndesign choices through ablation studies and release our code and models.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hugues Thomas",
            "Yao-Hung Hubert Tsai",
            "Timothy D. Barfoot",
            "Jian Zhang"
        ],
        "published": "2024-05-21T20:53:49Z"
    },
    {
        "title": "Efficient Imitation Learning with Conservative World Models",
        "link": "http://arxiv.org/abs/2405.13193v1",
        "abstract": "We tackle the problem of policy learning from expert demonstrations without a\nreward function. A central challenge in this space is that these policies fail\nupon deployment due to issues of distributional shift, environment\nstochasticity, or compounding errors. Adversarial imitation learning alleviates\nthis issue but requires additional on-policy training samples for stability,\nwhich presents a challenge in realistic domains due to inefficient learning and\nhigh sample complexity. One approach to this issue is to learn a world model of\nthe environment, and use synthetic data for policy training. While successful\nin prior works, we argue that this is sub-optimal due to additional\ndistribution shifts between the learned model and the real environment.\nInstead, we re-frame imitation learning as a fine-tuning problem, rather than a\npure reinforcement learning one. Drawing theoretical connections to offline RL\nand fine-tuning algorithms, we argue that standard online world model\nalgorithms are not well suited to the imitation learning problem. We derive a\nprincipled conservative optimization bound and demonstrate empirically that it\nleads to improved performance on two very challenging manipulation environments\nfrom high-dimensional raw pixel observations. We set a new state-of-the-art\nperformance on the Franka Kitchen environment from images, requiring only 10\ndemos on no reward labels, as well as solving a complex dexterity manipulation\ntask.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Victor Kolev",
            "Rafael Rafailov",
            "Kyle Hatch",
            "Jiajun Wu",
            "Chelsea Finn"
        ],
        "published": "2024-05-21T20:53:18Z"
    },
    {
        "title": "Pragmatic auditing: a pilot-driven approach for auditing Machine\n  Learning systems",
        "link": "http://arxiv.org/abs/2405.13191v1",
        "abstract": "The growing adoption and deployment of Machine Learning (ML) systems came\nwith its share of ethical incidents and societal concerns. It also unveiled the\nnecessity to properly audit these systems in light of ethical principles. For\nsuch a novel type of algorithmic auditing to become standard practice, two main\nprerequisites need to be available: A lifecycle model that is tailored towards\ntransparency and accountability, and a principled risk assessment procedure\nthat allows the proper scoping of the audit. Aiming to make a pragmatic step\ntowards a wider adoption of ML auditing, we present a respective procedure that\nextends the AI-HLEG guidelines published by the European Commission. Our audit\nprocedure is based on an ML lifecycle model that explicitly focuses on\ndocumentation, accountability, and quality assurance; and serves as a common\nground for alignment between the auditors and the audited organisation. We\ndescribe two pilots conducted on real-world use cases from two different\norganisations and discuss the shortcomings of ML algorithmic auditing as well\nas future directions thereof.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Djalel Benbouzid",
            "Christiane Plociennik",
            "Laura Lucaj",
            "Mihai Maftei",
            "Iris Merget",
            "Aljoscha Burchardt",
            "Marc P. Hauer",
            "Abdeldjallil Naceri",
            "Patrick van der Smagt"
        ],
        "published": "2024-05-21T20:40:37Z"
    },
    {
        "title": "Interpretable Spatio-Temporal Embedding for Brain Structural-Effective\n  Network with Ordinary Differential Equation",
        "link": "http://arxiv.org/abs/2405.13190v1",
        "abstract": "The MRI-derived brain network serves as a pivotal instrument in elucidating\nboth the structural and functional aspects of the brain, encompassing the\nramifications of diseases and developmental processes. However, prevailing\nmethodologies, often focusing on synchronous BOLD signals from functional MRI\n(fMRI), may not capture directional influences among brain regions and rarely\ntackle temporal functional dynamics. In this study, we first construct the\nbrain-effective network via the dynamic causal model. Subsequently, we\nintroduce an interpretable graph learning framework termed Spatio-Temporal\nEmbedding ODE (STE-ODE). This framework incorporates specifically designed\ndirected node embedding layers, aiming at capturing the dynamic interplay\nbetween structural and effective networks via an ordinary differential equation\n(ODE) model, which characterizes spatial-temporal brain dynamics. Our framework\nis validated on several clinical phenotype prediction tasks using two\nindependent publicly available datasets (HCP and OASIS). The experimental\nresults clearly demonstrate the advantages of our model compared to several\nstate-of-the-art methods.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Haoteng Tang",
            "Guodong Liu",
            "Siyuan Dai",
            "Kai Ye",
            "Kun Zhao",
            "Wenlu Wang",
            "Carl Yang",
            "Lifang He",
            "Alex Leow",
            "Paul Thompson",
            "Heng Huang",
            "Liang Zhan"
        ],
        "published": "2024-05-21T20:37:07Z"
    },
    {
        "title": "A machine learning framework for interpretable predictions in patient\n  pathways: The case of predicting ICU admission for patients with symptoms of\n  sepsis",
        "link": "http://arxiv.org/abs/2405.13187v1",
        "abstract": "Proactive analysis of patient pathways helps healthcare providers anticipate\ntreatment-related risks, identify outcomes, and allocate resources. Machine\nlearning (ML) can leverage a patient's complete health history to make informed\ndecisions about future events. However, previous work has mostly relied on\nso-called black-box models, which are unintelligible to humans, making it\ndifficult for clinicians to apply such models. Our work introduces PatWay-Net,\nan ML framework designed for interpretable predictions of admission to the\nintensive care unit (ICU) for patients with symptoms of sepsis. We propose a\nnovel type of recurrent neural network and combine it with multi-layer\nperceptrons to process the patient pathways and produce predictive yet\ninterpretable results. We demonstrate its utility through a comprehensive\ndashboard that visualizes patient health trajectories, predictive outcomes, and\nassociated risks. Our evaluation includes both predictive performance - where\nPatWay-Net outperforms standard models such as decision trees, random forests,\nand gradient-boosted decision trees - and clinical utility, validated through\nstructured interviews with clinicians. By providing improved predictive\naccuracy along with interpretable and actionable insights, PatWay-Net serves as\na valuable tool for healthcare decision support in the critical case of\npatients with symptoms of sepsis.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Sandra Zilker",
            "Sven Weinzierl",
            "Mathias Kraus",
            "Patrick Zschech",
            "Martin Matzner"
        ],
        "published": "2024-05-21T20:31:42Z"
    },
    {
        "title": "Automated categorization of pre-trained models for software engineering:\n  A case study with a Hugging Face dataset",
        "link": "http://arxiv.org/abs/2405.13185v1",
        "abstract": "Software engineering (SE) activities have been revolutionized by the advent\nof pre-trained models (PTMs), defined as large machine learning (ML) models\nthat can be fine-tuned to perform specific SE tasks. However, users with\nlimited expertise may need help to select the appropriate model for their\ncurrent task. To tackle the issue, the Hugging Face (HF) platform simplifies\nthe use of PTMs by collecting, storing, and curating several models.\nNevertheless, the platform currently lacks a comprehensive categorization of\nPTMs designed specifically for SE, i.e., the existing tags are more suited to\ngeneric ML categories.\n  This paper introduces an approach to address this gap by enabling the\nautomatic classification of PTMs for SE tasks. First, we utilize a public dump\nof HF to extract PTMs information, including model documentation and associated\ntags. Then, we employ a semi-automated method to identify SE tasks and their\ncorresponding PTMs from existing literature. The approach involves creating an\ninitial mapping between HF tags and specific SE tasks, using a similarity-based\nstrategy to identify PTMs with relevant tags. The evaluation shows that model\ncards are informative enough to classify PTMs considering the pipeline tag.\nMoreover, we provide a mapping between SE tasks and stored PTMs by relying on\nmodel names.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Claudio Di Sipio",
            "Riccardo Rubei",
            "Juri Di Rocco",
            "Davide Di Ruscio",
            "Phuong T. Nguyen"
        ],
        "published": "2024-05-21T20:26:17Z"
    },
    {
        "title": "Comparative Analysis of Different Efficient Fine Tuning Methods of Large\n  Language Models (LLMs) in Low-Resource Setting",
        "link": "http://arxiv.org/abs/2405.13181v1",
        "abstract": "In the domain of large language models (LLMs), arXiv:2305.16938 showed that\nfew-shot full-model fine-tuning -- namely Vanilla Fine Tuning (FT) and\nPattern-Based Fine Tuning (PBFT) --, and In-Context Learning (ICL) generalize\nsimilarly on Out-Of-Domain (OOD) datasets, but vary in terms of task\nadaptation. However, they both pose challenges, especially in term of memory\nrequirements. In this paper, we further try to push the understanding of\ndifferent fine-tuning strategies for LLM and aim to bring a myriad of these on\nthe same pedestal for an elaborate comparison with full-model fine-tuning on\ntwo diverse datasets. To that end, we conducted a series of experiments,\nbeginning with state-of-the-art methods like vanilla fine-tuning and\nPattern-Based Fine-Tuning (PBFT) on pre-trained models across two datasets,\nCOLA and MNLI. We then investigate adaptive fine-tuning and the efficiency of\nLoRA adapters in a few-shot setting. Finally, we also compare an alternative\napproach that has gained recent popularity -- context distillation -- with the\nvanilla FT and PBFT with and without few-shot setup.\n  Our findings suggest that these alternative strategies that we explored can\nexhibit out-of-domain generalization comparable to that of vanilla FT and PBFT.\nPBFT under-performs Vanilla FT on out-of-domain (OOD) data, emphasizing the\nneed for effective prompts. Further, our adaptive-fine tuning and LoRA\nexperiments perform comparable or slightly worse than the standard fine-tunings\nas anticipated, since standard fine-tunings involve tuning the entire model.\nFinally, our context distillation experiments out-perform the standard\nfine-tuning methods. These findings underscore that eventually the choice of an\nappropriate fine-tuning method depends on the available resources (memory,\ncompute, data) and task adaptability.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Krishna Prasad Varadarajan Srinivasan",
            "Prasanth Gumpena",
            "Madhusudhana Yattapu",
            "Vishal H. Brahmbhatt"
        ],
        "published": "2024-05-21T20:08:52Z"
    },
    {
        "title": "Data Assimilation with Machine Learning Surrogate Models: A Case Study\n  with FourCastNet",
        "link": "http://arxiv.org/abs/2405.13180v1",
        "abstract": "Modern data-driven surrogate models for weather forecasting provide accurate\nshort-term predictions but inaccurate and nonphysical long-term forecasts. This\npaper investigates online weather prediction using machine learning surrogates\nsupplemented with partial and noisy observations. We empirically demonstrate\nand theoretically justify that, despite the long-time instability of the\nsurrogates and the sparsity of the observations, filtering estimates can remain\naccurate in the long-time horizon. As a case study, we integrate FourCastNet, a\nstate-of-the-art weather surrogate model, within a variational data\nassimilation framework using partial, noisy ERA5 data. Our results show that\nfiltering estimates remain accurate over a year-long assimilation window and\nprovide effective initial conditions for forecasting tasks, including extreme\nevent prediction.",
        "subjects": [
            "eess.SP",
            "cs.LG",
            "nlin.CD",
            "physics.ao-ph",
            "stat.AP"
        ],
        "authors": [
            "Melissa Adrian",
            "Daniel Sanz-Alonso",
            "Rebecca Willett"
        ],
        "published": "2024-05-21T20:06:12Z"
    },
    {
        "title": "RAG-RLRC-LaySum at BioLaySumm: Integrating Retrieval-Augmented\n  Generation and Readability Control for Layman Summarization of Biomedical\n  Texts",
        "link": "http://arxiv.org/abs/2405.13179v1",
        "abstract": "This paper introduces the RAG-RLRC-LaySum framework, designed to make complex\nbiomedical research understandable to laymen through advanced Natural Language\nProcessing (NLP) techniques. Our Retrieval Augmented Generation (RAG) solution,\nenhanced by a reranking method, utilizes multiple knowledge sources to ensure\nthe precision and pertinence of lay summaries. Additionally, our Reinforcement\nLearning for Readability Control (RLRC) strategy improves readability, making\nscientific content comprehensible to non-specialists. Evaluations using the\npublicly accessible PLOS and eLife datasets show that our methods surpass Plain\nGemini model, demonstrating a 20% increase in readability scores, a 15%\nimprovement in ROUGE-2 relevance scores, and a 10% enhancement in factual\naccuracy. The RAG-RLRC-LaySum framework effectively democratizes scientific\nknowledge, enhancing public engagement with biomedical discoveries.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yuelyu Ji",
            "Zhuochun Li",
            "Rui Meng",
            "Sonish Sivarajkumar",
            "Yanshan Wang",
            "Zeshui Yu",
            "Hui Ji",
            "Yushui Han",
            "Hanyu Zeng",
            "Daqing He"
        ],
        "published": "2024-05-21T20:03:40Z"
    },
    {
        "title": "One-Shot Imitation Learning with Invariance Matching for Robotic\n  Manipulation",
        "link": "http://arxiv.org/abs/2405.13178v1",
        "abstract": "Learning a single universal policy that can perform a diverse set of\nmanipulation tasks is a promising new direction in robotics. However, existing\ntechniques are limited to learning policies that can only perform tasks that\nare encountered during training, and require a large number of demonstrations\nto learn new tasks. Humans, on the other hand, often can learn a new task from\na single unannotated demonstration. In this work, we propose the\nInvariance-Matching One-shot Policy Learning (IMOP) algorithm. In contrast to\nthe standard practice of learning the end-effector's pose directly, IMOP first\nlearns invariant regions of the state space for a given task, and then computes\nthe end-effector's pose through matching the invariant regions between\ndemonstrations and test scenes. Trained on the 18 RLBench tasks, IMOP achieves\na success rate that outperforms the state-of-the-art consistently, by 4.5% on\naverage over the 18 tasks. More importantly, IMOP can learn a novel task from a\nsingle unannotated demonstration, and without any fine-tuning, and achieves an\naverage success rate improvement of $11.5\\%$ over the state-of-the-art on 22\nnovel tasks selected across nine categories. IMOP can also generalize to new\nshapes and learn to manipulate objects that are different from those in the\ndemonstration. Further, IMOP can perform one-shot sim-to-real transfer using a\nsingle real-robot demonstration.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Xinyu Zhang",
            "Abdeslam Boularias"
        ],
        "published": "2024-05-21T20:01:03Z"
    },
    {
        "title": "A Workbench for Autograding Retrieve/Generate Systems",
        "link": "http://arxiv.org/abs/2405.13177v1",
        "abstract": "This resource paper addresses the challenge of evaluating Information\nRetrieval (IR) systems in the era of autoregressive Large Language Models\n(LLMs). Traditional methods relying on passage-level judgments are no longer\neffective due to the diversity of responses generated by LLM-based systems. We\nprovide a workbench to explore several alternative evaluation approaches to\njudge the relevance of a system's response that incorporate LLMs: 1. Asking an\nLLM whether the response is relevant; 2. Asking the LLM which set of nuggets\n(i.e., relevant key facts) is covered in the response; 3. Asking the LLM to\nanswer a set of exam questions with the response.\n  This workbench aims to facilitate the development of new, reusable test\ncollections. Researchers can manually refine sets of nuggets and exam\nquestions, observing their impact on system evaluation and leaderboard\nrankings.\n  Resource available at https://github.com/TREMA-UNH/autograding-workbench",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Laura Dietz"
        ],
        "published": "2024-05-21T19:57:51Z"
    },
    {
        "title": "Almost Bipartite non-König-Egerváry Graphs Revisited",
        "link": "http://arxiv.org/abs/2405.13176v1",
        "abstract": "Let $\\alpha(G)$ denote the cardinality of a maximum independent set, while\n$\\mu(G)$ be the size of a maximum matching in $G=\\left( V,E\\right) $. It is\nknown that if $\\alpha(G)+\\mu(G)=\\left\\vert V\\right\\vert $, then $G$ is a\nK\\\"{o}nig-Egerv\\'{a}ry graph.\n  The critical difference $d(G)$ is $\\max\\{d(I):I\\in\\mathrm{Ind}(G)\\}$, where\n$\\mathrm{Ind}(G)$\\ denotes the family of all independent sets of $G$. If\n$A\\in\\mathrm{Ind}(G)$ with $d\\left( X\\right) =d(G)$, then $A$ is a critical\nindependent set. For a graph $G$, let $\\mathrm{diadem}(G)=\\bigcup\\{S:S$ is a\ncritical independent set in $G\\}$, and $\\varrho_{v}\\left( G\\right) $ denote the\nnumber of vertices $v\\in V\\left( G\\right) $, such that $G-v$ is a\nK\\\"{o}nig-Egerv\\'{a}ry graph. A graph is called almost bipartite if it has a\nunique odd cycle.\n  In this paper, we show that if $G$ is an almost bipartite\nnon-K\\\"{o}nig-Egerv\\'{a}ry graph with the unique odd cycle $C$, then the\nfollowing assertions are true:\n  1. every maximum matching of $G$ contains $\\left\\lfloor\n{V(C)}/{2}\\right\\rfloor $ edges belonging to $C$;\n  2. $V(C)\\cup N_{G}\\left[ \\mathrm{diadem}\\left( G\\right) \\right] =V$ and\n$V(C)\\cap N_{G}\\left[ \\mathrm{diadem}\\left( G\\right) \\right] =\\emptyset$;\n  3. $\\varrho_{v}\\left( G\\right) =\\left\\vert \\mathrm{corona}\\left( G\\right)\n\\right\\vert -\\left\\vert \\mathrm{diadem}\\left( G\\right) \\right\\vert $, where\n$\\mathrm{corona}\\left( G\\right) $ is the union of all maximum independent sets\nof $G$;\n  4. $\\varrho_{v}\\left( G\\right) =\\left\\vert V\\right\\vert $ if and only if\n$G=C_{2k+1}$ for some integer $k\\geq1$.",
        "subjects": [
            "math.CO",
            "cs.DM",
            "05C69 (Primary) 05C70 (Secondary)",
            "G.2.2"
        ],
        "authors": [
            "Vadim E. Levit",
            "Eugen Mandrescu"
        ],
        "published": "2024-05-21T19:55:35Z"
    },
    {
        "title": "FV8: A Forced Execution JavaScript Engine for Detecting Evasive\n  Techniques",
        "link": "http://arxiv.org/abs/2405.13175v1",
        "abstract": "Evasion techniques allow malicious code to never be observed. This impacts\nsignificantly the detection capabilities of tools that rely on either dynamic\nor static analysis, as they never get to process the malicious code. The\ndynamic nature of JavaScript, where code is often injected dynamically, makes\nevasions particularly effective. Yet, we lack tools that can detect evasive\ntechniques in a challenging environment such as JavaScript.\n  In this paper, we present FV8, a modified V8 JavaScript engine designed to\nidentify evasion techniques in JavaScript code. FV8 selectively enforces code\nexecution on APIs that conditionally inject dynamic code, thus enhancing code\ncoverage and consequently improving visibility into malicious code. We\nintegrate our tool in both the Node.js engine and the Chromium browser,\ncompelling code execution in npm packages and Chrome browser extensions. Our\ntool increases code coverage by 11% compared to default V8 and detects 28\nunique evasion categories, including five previously unreported techniques. In\ndata confirmed as malicious from both ecosystems, our tool identifies 1,443\n(14.6%) npm packages and 164 (82%) extensions containing at least one type of\nevasion. In previously unexamined extensions (39,592), our tool discovered\n16,471 injected third-party scripts, and a total of 8,732,120 lines of code\nexecuted due to our forced execution instrumentation. Furthermore, it tagged a\ntotal of 423 extensions as both evasive and malicious and we manually verify\n110 extensions (26%) to actually be malicious, impacting two million users. Our\ntool is open-source and serves both as an in-browser and standalone dynamic\nanalysis tool, capable of detecting evasive code, bypassing obfuscation in\ncertain cases, offering improved access to malicious code, and supporting\nrecursive analysis of dynamic code injections",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Nikolaos Pantelaios",
            "Alexandros Kapravelos"
        ],
        "published": "2024-05-21T19:54:19Z"
    },
    {
        "title": "Efficient and Interpretable Information Retrieval for Product Question\n  Answering with Heterogeneous Data",
        "link": "http://arxiv.org/abs/2405.13173v1",
        "abstract": "Expansion-enhanced sparse lexical representation improves information\nretrieval (IR) by minimizing vocabulary mismatch problems during lexical\nmatching. In this paper, we explore the potential of jointly learning dense\nsemantic representation and combining it with the lexical one for ranking\ncandidate information. We present a hybrid information retrieval mechanism that\nmaximizes lexical and semantic matching while minimizing their shortcomings.\nOur architecture consists of dual hybrid encoders that independently encode\nqueries and information elements. Each encoder jointly learns a dense semantic\nrepresentation and a sparse lexical representation augmented by a learnable\nterm expansion of the corresponding text through contrastive learning. We\ndemonstrate the efficacy of our model in single-stage ranking of a benchmark\nproduct question-answering dataset containing the typical heterogeneous\ninformation available on online product pages. Our evaluation demonstrates that\nour hybrid approach outperforms independently trained retrievers by 10.95%\n(sparse) and 2.7% (dense) in MRR@5 score. Moreover, our model offers better\ninterpretability and performs comparably to state-of-the-art cross encoders\nwhile reducing response time by 30% (latency) and cutting computational load by\napproximately 38% (FLOPs).",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Biplob Biswas",
            "Rajiv Ramnath"
        ],
        "published": "2024-05-21T19:46:35Z"
    },
    {
        "title": "Measuring Internet Routing from the Most Valuable Points",
        "link": "http://arxiv.org/abs/2405.13172v1",
        "abstract": "While the increasing number of Vantage Points (VPs) in RIPE RIS and\nRouteViews\n  improves our understanding of the Internet, the quadratically increasing\n  volume of collected data poses a challenge to the scientific and operational\n  use of the data. The design and implementation of BGP and BGP data\n  collection systems lead to data archives with enormous redundancy, as\n  there is substantial overlap in announced routes across many different VPs.\n  Researchers thus often resort to arbitrary sampling of the data,\n  which we demonstrate\n  comes at a cost to the accuracy and coverage of previous works. The continued\n  growth of the Internet, and of these collection systems, exacerbates\n  this cost. The community needs a better approach to managing\n  and using these data archives.\n  We propose MVP, a system that\n  scores VPs according to their level of redundancy with other VPs,\n  allowing more informed sampling of these data archives.\n  Our challenge is that the degree of redundancy between two updates depends\n  on how we define redundancy, which in turn depends on\n  the analysis objective. Our key contribution is\n  a general framework and associated algorithms to assess\n  redundancy between VP observations.\n  We quantify the benefit of our approach for four canonical BGP routing\nanalyses: AS relationship inference, AS rank computation, hijack detection, and\nrouting detour detection. MVP improves the coverage or accuracy (or both) of\nall these analyses while processing the same volume of data.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Thomas Alfroy",
            "Thomas Holterbach",
            "Thomas Krenc",
            "KC Claffy",
            "Cristel Pelsser"
        ],
        "published": "2024-05-21T19:46:15Z"
    },
    {
        "title": "Launching Your VR Neuroscience Laboratory",
        "link": "http://dx.doi.org/10.1007/7854_2023_420",
        "abstract": "The proliferation and refinement of affordable virtual reality (VR)\ntechnologies and wearable sensors have opened new frontiers in cognitive and\nbehavioral neuroscience. This chapter offers a broad overview of VR for anyone\ninterested in leveraging it as a research tool. In the first section, it\nexamines the fundamental functionalities of VR and outlines important\nconsiderations that inform the development of immersive content that stimulates\nthe senses. In the second section, the focus of the discussion shifts to the\nimplementation of VR in the context of the neuroscience lab. Practical advice\nis offered on adapting commercial, off-theshelf devices to specific research\npurposes. Further, methods are explored for recording, synchronizing, and\nfusing heterogeneous forms of data obtained through the VR system or add-on\nsensors, as well as for labeling events and capturing game play.",
        "subjects": [
            "cs.HC",
            "q-bio.NC"
        ],
        "authors": [
            "Ying Choon Wu",
            "Christopher Maymon",
            "Jonathon Paden",
            "Weichen Liu"
        ],
        "published": "2024-05-21T19:37:09Z"
    },
    {
        "title": "FEATHER: A Reconfigurable Accelerator with Data Reordering Support for\n  Low-Cost On-Chip Dataflow Switching",
        "link": "http://arxiv.org/abs/2405.13170v1",
        "abstract": "The inference of ML models composed of diverse structures, types, and sizes\nboils down to the execution of different dataflows (i.e. different tiling,\nordering, parallelism, and shapes). Using the optimal dataflow for every layer\nof workload can reduce latency by up to two orders of magnitude over a\nsuboptimal dataflow. Unfortunately, reconfiguring hardware for different\ndataflows involves on-chip data layout reordering and datapath\nreconfigurations, leading to non-trivial overhead that hinders ML accelerators\nfrom exploiting different dataflows, resulting in suboptimal performance. To\naddress this challenge, we propose FEATHER, an innovative accelerator that\nleverages a novel spatial array termed Nest and a novel multi-stage reduction\nnetwork called BIRRD for performing flexible data reduction with layout\nreordering under the hood, enabling seamless switching between optimal\ndataflows with negligible latency and resources overhead. For systematically\nevaluating the performance interaction between dataflows and layouts, we\nenhance Timeloop, a state-of-the-art dataflow cost modeling and search\nframework, with layout assessment capabilities, and term it as Layoutloop. We\nmodel FEATHER into Layoutloop and also deploy FEATHER end-to-end on the edge\nZCU104 FPGA. FEATHER delivers 1.27~2.89x inference latency speedup and\n1.3~6.43x energy efficiency improvement compared to various SoTAs like NVDLA,\nSIGMA and Eyeriss under ResNet-50 and MobiletNet-V3 in Layoutloop. On practical\nFPGA devices, FEATHER achieves 2.65/3.91x higher throughput than Xilinx\nDPU/Gemmini. Remarkably, such performance and energy efficiency enhancements\ncome at only 6% area over a fixed-dataflow Eyeriss-like accelerator. Our code\nis released at https://github.com/maeri-project/FEATHER.",
        "subjects": [
            "cs.AR"
        ],
        "authors": [
            "Jianming Tong",
            "Anirudh Itagi",
            "Prasanth Chatarasi",
            "Tushar Krishna"
        ],
        "published": "2024-05-21T19:37:00Z"
    },
    {
        "title": "FairLENS: Assessing Fairness in Law Enforcement Speech Recognition",
        "link": "http://arxiv.org/abs/2405.13166v1",
        "abstract": "Automatic speech recognition (ASR) techniques have become powerful tools,\nenhancing efficiency in law enforcement scenarios. To ensure fairness for\ndemographic groups in different acoustic environments, ASR engines must be\ntested across a variety of speakers in realistic settings. However, describing\nthe fairness discrepancies between models with confidence remains a challenge.\nMeanwhile, most public ASR datasets are insufficient to perform a satisfying\nfairness evaluation. To address the limitations, we built FairLENS - a\nsystematic fairness evaluation framework. We propose a novel and adaptable\nevaluation method to examine the fairness disparity between different models.\nWe also collected a fairness evaluation dataset covering multiple scenarios and\ndemographic dimensions. Leveraging this framework, we conducted fairness\nassessments on 1 open-source and 11 commercially available state-of-the-art ASR\nmodels. Our results reveal that certain models exhibit more biases than others,\nserving as a fairness guideline for users to make informed choices when\nselecting ASR models for a given real-world scenario. We further explored model\nbiases towards specific demographic groups and observed that shifts in the\nacoustic domain can lead to the emergence of new biases.",
        "subjects": [
            "eess.AS",
            "cs.AI",
            "cs.CY"
        ],
        "authors": [
            "Yicheng Wang",
            "Mark Cusick",
            "Mohamed Laila",
            "Kate Puech",
            "Zhengping Ji",
            "Xia Hu",
            "Michael Wilson",
            "Noah Spitzer-Williams",
            "Michael Wheeler",
            "Yasser Ibrahim"
        ],
        "published": "2024-05-21T19:23:40Z"
    },
    {
        "title": "Adaptive coupling of 3D and 2D fluid flow models",
        "link": "http://arxiv.org/abs/2405.13165v1",
        "abstract": "Similar to the notion of h-adaptivity, where the discretization resolution is\nadaptively changed, I propose the notion of model adaptivity, where the\nunderlying model (the governing equations) is adaptively changed in space and\ntime. Specifically, this work introduces a hybrid and adaptive coupling of a 3D\nbulk fluid flow model with a 2D thin film flow model. As a result, this work\nextends the applicability of existing thin film flow models to complex\nscenarios where, for example, bulk flow develops into thin films after striking\na surface. At each location in space and time, the proposed framework\nautomatically decides whether a 3D model or a 2D model must be applied. Using a\nmeshless approach for both 3D and 2D models, at each particle, the decision to\napply a 2D or 3D model is based on the user-prescribed resolution and a local\nprincipal component analysis. When a particle needs to be changed from a 3D\nmodel to 2D, or vice versa, the discretization is changed, and all relevant\ndata mapping is done on-the-fly. Appropriate two-way coupling conditions and\nmass conservation considerations between the 3D and 2D models are also\ndeveloped. Numerical results show that this model adaptive framework shows\nhigher flexibility and compares well against finely resolved 3D simulations. In\nan actual application scenario, a 3 factor speed up is obtained, while\nmaintaining the accuracy of the solution.",
        "subjects": [
            "physics.flu-dyn",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Pratik Suchde"
        ],
        "published": "2024-05-21T19:21:51Z"
    },
    {
        "title": "Non-autoregressive real-time Accent Conversion model with voice cloning",
        "link": "http://arxiv.org/abs/2405.13162v1",
        "abstract": "Currently, the development of Foreign Accent Conversion (FAC) models utilizes\ndeep neural network architectures, as well as ensembles of neural networks for\nspeech recognition and speech generation. The use of these models is limited by\narchitectural features, which does not allow flexible changes in the timbre of\nthe generated speech and requires the accumulation of context, leading to\nincreased delays in generation and makes these systems unsuitable for use in\nreal-time multi-user communication scenarios. We have developed the\nnon-autoregressive model for real-time accent conversion with voice cloning.\nThe model generates native-sounding L1 speech with minimal latency based on\ninput L2 accented speech. The model consists of interconnected modules for\nextracting accent, gender, and speaker embeddings, converting speech,\ngenerating spectrograms, and decoding the resulting spectrogram into an audio\nsignal. The model has the ability to save, clone and change the timbre, gender\nand accent of the speaker's voice in real time. The results of the objective\nassessment show that the model improves speech quality, leading to enhanced\nrecognition performance in existing ASR systems. The results of subjective\ntests show that the proposed accent and gender encoder improves the generation\nquality. The developed model demonstrates high-quality low-latency accent\nconversion, voice cloning, and speech enhancement capabilities, making it\nsuitable for real-time multi-user communication scenarios.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "authors": [
            "Vladimir Nechaev",
            "Sergey Kosyakov"
        ],
        "published": "2024-05-21T19:07:26Z"
    },
    {
        "title": "Borrowing Strength in Distributionally Robust Optimization via\n  Hierarchical Dirichlet Processes",
        "link": "http://arxiv.org/abs/2405.13160v1",
        "abstract": "This paper presents a novel optimization framework to address key challenges\npresented by modern machine learning applications: High dimensionality,\ndistributional uncertainty, and data heterogeneity. Our approach unifies\nregularized estimation, distributionally robust optimization (DRO), and\nhierarchical Bayesian modeling in a single data-driven criterion. By employing\na hierarchical Dirichlet process (HDP) prior, the method effectively handles\nmulti-source data, achieving regularization, distributional robustness, and\nborrowing strength across diverse yet related data-generating processes. We\ndemonstrate the method's advantages by establishing theoretical performance\nguarantees and tractable Monte Carlo approximations based on Dirichlet process\n(DP) theory. Numerical experiments validate the framework's efficacy in\nimproving and stabilizing both prediction and parameter estimation accuracy,\nshowcasing its potential for application in complex data environments.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Nicola Bariletto",
            "Khai Nguyen",
            "Nhat Ho"
        ],
        "published": "2024-05-21T19:03:09Z"
    },
    {
        "title": "A Privacy-Preserving DAO Model Using NFT Authentication for the\n  Punishment not Reward Blockchain Architecture",
        "link": "http://arxiv.org/abs/2405.13156v1",
        "abstract": "\\This paper presents a novel decentralized autonomous organization (DAO)\nmodel leveraging non-fungible tokens (NFTs) for advanced access control and\nprivacy-preserving interactions within a Punishment not Reward (PnR) blockchain\nframework. The proposed model introduces a dual NFT architecture: Membership\nNFTs (\\(NFT_{auth}\\)) for authentication and access control, and Interaction\nNFTs (\\(NFT_{priv}\\)) for enabling private, encrypted interactions among\nparticipants. Governance is enforced through smart contracts that manage\nreputation and administer punitive measures, such as conditional identity\ndisclosure. By prioritizing privacy, security, and deterrence over financial\nrewards, this model addresses key challenges in existing blockchain incentive\nstructures, paving the way for more sustainable and decentralized governance\nframeworks.",
        "subjects": [
            "cs.CR",
            "cs.SE"
        ],
        "authors": [
            "Talgar Bayan",
            "Richard Banach"
        ],
        "published": "2024-05-21T18:53:15Z"
    },
    {
        "title": "ReALLM: A general framework for LLM compression and fine-tuning",
        "link": "http://arxiv.org/abs/2405.13155v1",
        "abstract": "We introduce ReALLM, a novel approach for compression and memory-efficient\nadaptation of pre-trained language models that encompasses most of the\npost-training quantization and fine-tuning methods for a budget of <4 bits.\nPre-trained matrices are decomposed into a high-precision low-rank component\nand a vector-quantized latent representation (using an autoencoder). During the\nfine-tuning step, only the low-rank components are updated. Our results show\nthat pre-trained matrices exhibit different patterns. ReALLM adapts the shape\nof the encoder (small/large embedding, high/low bit VQ, etc.) to each matrix.\nReALLM proposes to represent each matrix with a small embedding on $b$ bits and\na neural decoder model $\\mathcal{D}_\\phi$ with its weights on $b_\\phi$ bits.\nThe decompression of a matrix requires only one embedding and a single forward\npass with the decoder. Our weight-only quantization algorithm yields the best\nresults on language generation tasks (C4 and WikiText-2) for a budget of $3$\nbits without any training. With a budget of $2$ bits, ReALLM achieves\nstate-of-the art performance after fine-tuning on a small calibration dataset.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Louis Leconte",
            "Lisa Bedin",
            "Van Minh Nguyen",
            "Eric Moulines"
        ],
        "published": "2024-05-21T18:50:51Z"
    },
    {
        "title": "Generating A Crowdsourced Conversation Dataset to Combat Cybergrooming",
        "link": "http://arxiv.org/abs/2405.13154v1",
        "abstract": "Cybergrooming emerges as a growing threat to adolescent safety and mental\nhealth. One way to combat cybergrooming is to leverage predictive artificial\nintelligence (AI) to detect predatory behaviors in social media. However, these\nmethods can encounter challenges like false positives and negative implications\nsuch as privacy concerns. Another complementary strategy involves using\ngenerative artificial intelligence to empower adolescents by educating them\nabout predatory behaviors. To this end, we envision developing state-of-the-art\nconversational agents to simulate the conversations between adolescents and\npredators for educational purposes. Yet, one key challenge is the lack of a\ndataset to train such conversational agents. In this position paper, we present\nour motivation for empowering adolescents to cope with cybergrooming. We\npropose to develop large-scale, authentic datasets through an online survey\ntargeting adolescents and parents. We discuss some initial background behind\nour motivation and proposed design of the survey, such as situating the\nparticipants in artificial cybergrooming scenarios, then allowing participants\nto respond to the survey to obtain their authentic responses. We also present\nseveral open questions related to our proposed approach and hope to discuss\nthem with the workshop attendees.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Xinyi Zhang",
            "Pamela J. Wisniewski",
            "Jin-hee Cho",
            "Lifu Huang",
            "Sang Won Lee"
        ],
        "published": "2024-05-21T18:49:02Z"
    },
    {
        "title": "Enhancing Interaction Modeling with Agent Selection and Physical Methods\n  for Trajectory Prediction",
        "link": "http://arxiv.org/abs/2405.13152v1",
        "abstract": "In this study, we address the limitations inherent in most existing vehicle\ntrajectory prediction methodologies that indiscriminately incorporate all\nagents within a predetermined proximity when accounting for inter-agent\ninteractions. These approaches commonly employ attention-based architecture or\ngraph neural networks for encoding interactions, which introduces three\nchallenges: (i) The indiscriminate selection of all nearby agents substantially\nescalates the computational demands of the model, particularly in those\ninteraction-rich scenarios. (ii) Moreover, the simplistic feature extraction of\ncurrent time agents falls short of adequately capturing the nuanced dynamics of\ninteractions. (iii) Compounded by the inherently low interpretability of\nattention mechanism and graph neural networks, there is a propensity for the\nmodel to allocate unreliable correlation coefficients to certain agents,\nadversely impacting the accuracy of trajectory predictions. To mitigate these\nissues, we introduce ASPILin, a novel approach that enhances the selection of\ninteracting agents by considering their current and future lanes, extending\nthis consideration across all historical frames. Utilizing the states of the\nagents, we estimate the nearest future distance between agents and the time\nneeded to reach this distance. Then, combine these with their current distances\nto derive a physical correlation coefficient to encode interactions.\nExperiments conducted on popular trajectory prediction datasets demonstrate\nthat our method is efficient and straightforward, outperforming other\nstate-of-the-art methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Shiji Huang",
            "Lei Ye",
            "Min Chen",
            "Wenhai Luo",
            "Chenqi Xu",
            "Deyuan Liang",
            "Dihong Wang"
        ],
        "published": "2024-05-21T18:45:18Z"
    },
    {
        "title": "Gaussian Measures Conditioned on Nonlinear Observations: Consistency,\n  MAP Estimators, and Simulation",
        "link": "http://arxiv.org/abs/2405.13149v1",
        "abstract": "The article presents a systematic study of the problem of conditioning a\nGaussian random variable $\\xi$ on nonlinear observations of the form $F \\circ\n\\phi(\\xi)$ where $\\phi: \\mathcal{X} \\to \\mathbb{R}^N$ is a bounded linear\noperator and $F$ is nonlinear. Such problems arise in the context of Bayesian\ninference and recent machine learning-inspired PDE solvers. We give a\nrepresenter theorem for the conditioned random variable $\\xi \\mid F\\circ\n\\phi(\\xi)$, stating that it decomposes as the sum of an infinite-dimensional\nGaussian (which is identified analytically) as well as a finite-dimensional\nnon-Gaussian measure. We also introduce a novel notion of the mode of a\nconditional measure by taking the limit of the natural relaxation of the\nproblem, to which we can apply the existing notion of maximum a posteriori\nestimators of posterior measures. Finally, we introduce a variant of the\nLaplace approximation for the efficient simulation of the aforementioned\nconditioned Gaussian random variables towards uncertainty quantification.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "cs.NA",
            "math.NA",
            "math.PR",
            "stat.CO"
        ],
        "authors": [
            "Yifan Chen",
            "Bamdad Hosseini",
            "Houman Owhadi",
            "Andrew M Stuart"
        ],
        "published": "2024-05-21T18:38:14Z"
    },
    {
        "title": "A novel reliability attack of Physical Unclonable Functions",
        "link": "http://arxiv.org/abs/2405.13147v1",
        "abstract": "Physical Unclonable Functions (PUFs) are emerging as promising security\nprimitives for IoT devices, providing device fingerprints based on physical\ncharacteristics. Despite their strengths, PUFs are vulnerable to machine\nlearning (ML) attacks, including conventional and reliability-based attacks.\nConventional ML attacks have been effective in revealing vulnerabilities of\nmany PUFs, and reliability-based ML attacks are more powerful tools that have\ndetected vulnerabilities of some PUFs that are resistant to conventional ML\nattacks. Since reliability-based ML attacks leverage information of PUFs'\nunreliability, we were tempted to examine the feasibility of building defense\nusing reliability enhancing techniques, and have discovered that majority\nvoting with reasonably high repeats provides effective defense against existing\nreliability-based ML attack methods. It is known that majority voting reduces\nbut does not eliminate unreliability, we are motivated to investigate if new\nattack methods exist that can capture the low unreliability of highly but\nnot-perfectly reliable PUFs, which led to the development of a new reliability\nrepresentation and the new representation-enabled attack method that has\nexperimentally cracked PUFs enhanced with majority voting of high repetitions.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "authors": [
            "Gaoxiang Li",
            "Yu Zhuang"
        ],
        "published": "2024-05-21T18:34:14Z"
    },
    {
        "title": "A lightweight PUF-based authentication protocol",
        "link": "http://arxiv.org/abs/2405.13146v1",
        "abstract": "Lightweight authentication is essential for resource-constrained\nInternet-of-Things (IoT). Implementable with low resource and operable with low\npower, Physical Unclonable Functions (PUFs) have the potential as hardware\nprimitives for implementing lightweight authentication protocols. The arbiter\nPUF (APUF) is probably the most lightweight strong PUF capable of generating\nexponentially many challenge-response pairs (CRPs), a desirable property for\nauthentication protocols, but APUF is severely weak against modeling attacks.\nEfforts on PUF design have led to many PUFs of higher resistance to modeling\nattacks and also higher area overhead. There are also substantial efforts on\nprotocol development, some leverage PUFs' strength in fighting modeling\nattacks, and some others employ carefully designed protocol techniques to\nobfuscate either the challenges or the responses with modest increase of area\noverhead for some or increased operations for some others. To attain both low\nresource footprint and high modeling attack resistance, in this paper we\npropose a co-design of PUF and protocol, where the PUF consists of an APUF and\na zero-transistor interface that obfuscates the true challenge bits fed to the\nPUF. The obfuscated PUF possesses rigorously proven potential and\nexperimentally supported performance against modeling attacks when a condition\nis met, and the protocol provides the condition required by the PUF and\nleverages the PUF's modeling resistance to arrive at low resource overhead and\nhigh operational simplicity, enabling lightweight authentications while\nresisting modeling attacks.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Yu Zhuang",
            "Gaoxiang Li"
        ],
        "published": "2024-05-21T18:32:13Z"
    },
    {
        "title": "Mamo: a Mathematical Modeling Benchmark with Solvers",
        "link": "http://arxiv.org/abs/2405.13144v1",
        "abstract": "Mathematical modeling involves representing real-world phenomena, systems, or\nproblems using mathematical expressions and equations to analyze, understand,\nand predict their behavior. Given that this process typically requires\nexperienced experts, there is an interest in exploring whether Large Language\nModels (LLMs) can undertake mathematical modeling to potentially decrease human\nlabor. To evaluate of LLMs in mathematical modeling, we introduce a new\nbenchmark, Mamo, that transcends traditional result-oriented assessments.\nUnlike conventional methods that primarily assess LLMs based on the accuracy of\nsolutions to mathematical problems, our approach offers deeper insight into the\nmodeling process itself. By focusing on the processes LLMs undertake rather\nthan the correctness of their final solutions, Mamo pioneers a novel evaluation\nparadigm. This shift underscores the importance of understanding the inherent\nmodeling capabilities of LLMs, paving the way for a more nuanced and\ncomprehensive analysis of their problem-solving strategies. Our work marks a\nsignificant advancement in the field, suggesting a new direction for future\nresearch by emphasizing the evaluation of LLMs' modeling processes over the\nmere correctness of answers. This benchmark not only facilitates a better\nunderstanding of LLMs' mathematical modeling capabilities but also sets a new\nstandard for evaluating their performance in complex problem-solving scenarios.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Xuhan Huang",
            "Qingning Shen",
            "Yan Hu",
            "Anningzhe Gao",
            "Benyou Wang"
        ],
        "published": "2024-05-21T18:29:54Z"
    },
    {
        "title": "Pseudorandomness, symmetry, smoothing: I",
        "link": "http://arxiv.org/abs/2405.13143v1",
        "abstract": "We prove several new results about bounded uniform and small-bias\ndistributions. A main message is that, small-bias, even perturbed with noise,\ndoes not fool several classes of tests better than bounded uniformity. We prove\nthis for threshold tests, small-space algorithms, and small-depth circuits. In\nparticular, we obtain small-bias distributions that\n  1) achieve an optimal lower bound on their statistical distance to any\nbounded-uniform distribution. This closes a line of research initiated by Alon,\nGoldreich, and Mansour in 2003, and improves on a result by O'Donnell and Zhao.\n  2) have heavier tail mass than the uniform distribution. This answers a\nquestion posed by several researchers including Bun and Steinke.\n  3) rule out a popular paradigm for constructing pseudorandom generators,\noriginating in a 1989 work by Ajtai and Wigderson. This again answers a\nquestion raised by several researchers. For branching programs, our result\nmatches a bound by Forbes and Kelley.\n  Our small-bias distributions above are symmetric. We show that the xor of any\ntwo symmetric small-bias distributions fools any bounded function. Hence our\nexamples cannot be extended to the xor of two small-bias distributions, another\npopular paradigm whose power remains unknown. We also generalize and simplify\nthe proof of a result of Bazzi.",
        "subjects": [
            "cs.CC"
        ],
        "authors": [
            "Harm Derksen",
            "Peter Ivanov",
            "Chin Ho Lee",
            "Emanuele Viola"
        ],
        "published": "2024-05-21T18:26:42Z"
    },
    {
        "title": "Offline robot programming assisted by task demonstration: an\n  AutomationML interoperable solution for glass adhesive application and\n  welding",
        "link": "http://dx.doi.org/10.1080/0951192X.2024.2358042",
        "abstract": "Robots have been successfully deployed in both traditional and novel\nmanufacturing processes. However, they are still difficult to program by\nnon-experts, which limits their accessibility to a wider range of potential\nusers. Programming robots requires expertise in both robotics and the specific\nmanufacturing process in which they are applied. Robot programs created offline\noften lack parameters that represent relevant manufacturing skills when\nexecuting a specific task. These skills encompass aspects like robot\norientation and velocity. This paper introduces an intuitive robot programming\nsystem designed to capture manufacturing skills from task demonstrations\nperformed by skilled workers. Demonstration data, including orientations and\nvelocities of the working paths, are acquired using a magnetic tracking system\nfixed to the tools used by the worker. Positional data are extracted from\nCAD/CAM. Robot path poses are transformed into Cartesian space and validated in\nsimulation, subsequently leading to the generation of robot programs. PathML,\nan AutomationML-based syntax, integrates robot and manufacturing data across\nthe heterogeneous elements and stages of the manufacturing systems considered.\nExperiments conducted on the glass adhesive application and welding processes\nshowcased the intuitive nature of the system, with path errors falling within\nthe functional tolerance range.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "M. Babcinschi",
            "F. Cruz",
            "N. Duarte",
            "S. Santos",
            "S. Alves",
            "P. Neto"
        ],
        "published": "2024-05-21T18:23:37Z"
    },
    {
        "title": "On Convergence of the Alternating Directions SGHMC Algorithm",
        "link": "http://arxiv.org/abs/2405.13140v1",
        "abstract": "We study convergence rates of Hamiltonian Monte Carlo (HMC) algorithms with\nleapfrog integration under mild conditions on stochastic gradient oracle for\nthe target distribution (SGHMC). Our method extends standard HMC by allowing\nthe use of general auxiliary distributions, which is achieved by a novel\nprocedure of Alternating Directions.\n  The convergence analysis is based on the investigations of the Dirichlet\nforms associated with the underlying Markov chain driving the algorithms. For\nthis purpose, we provide a detailed analysis on the error of the leapfrog\nintegrator for Hamiltonian motions with both the kinetic and potential energy\nfunctions in general form. We characterize the explicit dependence of the\nconvergence rates on key parameters such as the problem dimension, functional\nproperties of both the target and auxiliary distributions, and the quality of\nthe oracle.",
        "subjects": [
            "math.ST",
            "cs.LG",
            "math.PR",
            "stat.TH"
        ],
        "authors": [
            "Soumyadip Ghsoh",
            "Yingdong Lu",
            "Tomasz Nowicki"
        ],
        "published": "2024-05-21T18:22:44Z"
    },
    {
        "title": "Towards Principled, Practical Policy Gradient for Bandits and Tabular\n  MDPs",
        "link": "http://arxiv.org/abs/2405.13136v1",
        "abstract": "We consider (stochastic) softmax policy gradient (PG) methods for bandits and\ntabular Markov decision processes (MDPs). While the PG objective is\nnon-concave, recent research has used the objective's smoothness and gradient\ndomination properties to achieve convergence to an optimal policy. However,\nthese theoretical results require setting the algorithm parameters according to\nunknown problem-dependent quantities (e.g. the optimal action or the true\nreward vector in a bandit problem). To address this issue, we borrow ideas from\nthe optimization literature to design practical, principled PG methods in both\nthe exact and stochastic settings. In the exact setting, we employ an Armijo\nline-search to set the step-size for softmax PG and empirically demonstrate a\nlinear convergence rate. In the stochastic setting, we utilize exponentially\ndecreasing step-sizes, and characterize the convergence rate of the resulting\nalgorithm. We show that the proposed algorithm offers similar theoretical\nguarantees as the state-of-the art results, but does not require the knowledge\nof oracle-like quantities. For the multi-armed bandit setting, our techniques\nresult in a theoretically-principled PG algorithm that does not require\nexplicit exploration, the knowledge of the reward gap, the reward\ndistributions, or the noise. Finally, we empirically compare the proposed\nmethods to PG approaches that require oracle knowledge, and demonstrate\ncompetitive performance.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Michael Lu",
            "Matin Aghaei",
            "Anant Raj",
            "Sharan Vaswani"
        ],
        "published": "2024-05-21T18:12:39Z"
    },
    {
        "title": "Dataset Mention Extraction in Scientific Articles Using Bi-LSTM-CRF\n  Model",
        "link": "http://dx.doi.org/10.5281/zenodo.4402304",
        "abstract": "Datasets are critical for scientific research, playing an important role in\nreplication, reproducibility, and efficiency. Researchers have recently shown\nthat datasets are becoming more important for science to function properly,\neven serving as artifacts of study themselves. However, citing datasets is not\na common or standard practice in spite of recent efforts by data repositories\nand funding agencies. This greatly affects our ability to track their usage and\nimportance. A potential solution to this problem is to automatically extract\ndataset mentions from scientific articles. In this work, we propose to achieve\nsuch extraction by using a neural network based on a Bi-LSTM-CRF architecture.\nOur method achieves F1 = 0.885 in social science articles released as part of\nthe Rich Context Dataset. We discuss the limitations of the current datasets\nand propose modifications to the model to be done in the future.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Tong Zeng",
            "Daniel Acuna"
        ],
        "published": "2024-05-21T18:12:37Z"
    },
    {
        "title": "Atomic Self-Consistency for Better Long Form Generations",
        "link": "http://arxiv.org/abs/2405.13131v1",
        "abstract": "Recent work has aimed to improve LLM generations by filtering out\nhallucinations, thereby improving the precision of the information in\nresponses. Correctness of a long-form response, however, also depends on the\nrecall of multiple pieces of information relevant to the question. In this\npaper, we introduce Atomic Self-Consistency (ASC), a technique for improving\nthe recall of relevant information in an LLM response. ASC follows recent work,\nUniversal Self-Consistency (USC) in using multiple stochastic samples from an\nLLM to improve the long-form response. Unlike USC which only focuses on\nselecting the best single generation, ASC picks authentic subparts from the\nsamples and merges them into a superior composite answer. Through extensive\nexperiments and ablations, we show that merging relevant subparts of multiple\nsamples performs significantly better than picking a single sample. ASC\ndemonstrates significant gains over USC on multiple factoids and open-ended QA\ndatasets - ASQA, QAMPARI, QUEST, ELI5 with ChatGPT and Llama2. Our analysis\nalso reveals untapped potential for enhancing long-form generations using\napproach of merging multiple samples.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Raghuveer Thirukovalluru",
            "Yukun Huang",
            "Bhuwan Dhingra"
        ],
        "published": "2024-05-21T18:05:44Z"
    },
    {
        "title": "Pure Planning to Pure Policies and In Between with a Recursive Tree\n  Planner",
        "link": "http://arxiv.org/abs/2405.13130v1",
        "abstract": "A recursive tree planner (RTP) is designed to function as a pure planner\nwithout policies at one extreme and run a pure greedy policy at the other. In\nbetween, the RTP exploits policies to improve planning performance and improve\nzero-shot transfer from one class of planning problem to another. Policies are\nlearned through imitation of the planner. These are then used by the planner to\nimprove policies in a virtuous cycle. To improve planning performance and\nzero-shot transfer, the RTP incorporates previously learned tasks as\ngeneralized actions (GA) at any level of its hierarchy, and can refine those GA\nby adding primitive actions at any level too. For search, the RTP uses a\ngeneralized Dijkstra algorithm [Dijkstra 1959] which tries the greedy policy\nfirst and then searches over near-greedy paths and then farther away as\nnecessary. The RPT can return multiple sub-goals from lower levels as well as\nboundary states near obstacles, and can exploit policies with background and\nobject-number invariance. Policies at all levels of the hierarchy can be\nlearned simultaneously or in any order or come from outside the framework. The\nRTP is tested here on a variety of Box2d [Cato 2022] problems, including the\nclassic lunar lander [Farama 2022], and on the MuJoCo [Todorov et al 2012]\ninverted pendulum.",
        "subjects": [
            "cs.RO",
            "cs.LG",
            "I.2.9; I.2.6"
        ],
        "authors": [
            "A. Norman Redlich"
        ],
        "published": "2024-05-21T18:02:47Z"
    },
    {
        "title": "Rethinking the production and publication of machine-reusable\n  expressions of research findings",
        "link": "http://arxiv.org/abs/2405.13129v1",
        "abstract": "Literature is the primary expression of scientific knowledge and an important\nsource of research data. However, scientific knowledge expressed in narrative\ntext documents is not inherently machine reusable. To facilitate knowledge\nreuse, e.g. for synthesis research, scientific knowledge must be extracted from\narticles and organized into databases post-publication. The high time costs and\ninaccuracies associated with completing these activities manually has driven\nthe development of techniques that automate knowledge extraction. Tackling the\nproblem with a different mindset, we propose a pre-publication approach, known\nas reborn, that ensures scientific knowledge is born reusable, i.e. produced in\na machine-reusable format during knowledge production. We implement the\napproach using the Open Research Knowledge Graph infrastructure for FAIR\nscientific knowledge organization. We test the approach with three use cases,\nand discuss the role of publishers and editors in scaling the approach. Our\nresults suggest that the proposed approach is superior compared to classical\nmanual and semi-automated post-publication extraction techniques in terms of\nknowledge richness and accuracy as well as technological simplicity.",
        "subjects": [
            "cs.DL"
        ],
        "authors": [
            "Markus Stocker",
            "Lauren Snyder",
            "Matthew Anfuso",
            "Oliver Ludwig",
            "Freya Thießen",
            "Kheir Eddine Farfar",
            "Muhammad Haris",
            "Allard Oelen",
            "Mohamad Yaser Jaradeh"
        ],
        "published": "2024-05-21T18:02:40Z"
    },
    {
        "title": "Towards Retrieval-Augmented Architectures for Image Captioning",
        "link": "http://arxiv.org/abs/2405.13127v1",
        "abstract": "The objective of image captioning models is to bridge the gap between the\nvisual and linguistic modalities by generating natural language descriptions\nthat accurately reflect the content of input images. In recent years,\nresearchers have leveraged deep learning-based models and made advances in the\nextraction of visual features and the design of multimodal connections to\ntackle this task. This work presents a novel approach towards developing image\ncaptioning models that utilize an external kNN memory to improve the generation\nprocess. Specifically, we propose two model variants that incorporate a\nknowledge retriever component that is based on visual similarities, a\ndifferentiable encoder to represent input images, and a kNN-augmented language\nmodel to predict tokens based on contextual cues and text retrieved from the\nexternal memory. We experimentally validate our approach on COCO and nocaps\ndatasets and demonstrate that incorporating an explicit external memory can\nsignificantly enhance the quality of captions, especially with a larger\nretrieval corpus. This work provides valuable insights into retrieval-augmented\ncaptioning models and opens up new avenues for improving image captioning at a\nlarger scale.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.MM"
        ],
        "authors": [
            "Sara Sarto",
            "Marcella Cornia",
            "Lorenzo Baraldi",
            "Alessandro Nicolosi",
            "Rita Cucchiara"
        ],
        "published": "2024-05-21T18:02:07Z"
    },
    {
        "title": "Reducing Transformer Key-Value Cache Size with Cross-Layer Attention",
        "link": "http://arxiv.org/abs/2405.12981v1",
        "abstract": "Key-value (KV) caching plays an essential role in accelerating decoding for\ntransformer-based autoregressive large language models (LLMs). However, the\namount of memory required to store the KV cache can become prohibitive at long\nsequence lengths and large batch sizes. Since the invention of the transformer,\ntwo of the most effective interventions discovered for reducing the size of the\nKV cache have been Multi-Query Attention (MQA) and its generalization,\nGrouped-Query Attention (GQA). MQA and GQA both modify the design of the\nattention block so that multiple query heads can share a single key/value head,\nreducing the number of distinct key/value heads by a large factor while only\nminimally degrading accuracy. In this paper, we show that it is possible to\ntake Multi-Query Attention a step further by also sharing key and value heads\nbetween adjacent layers, yielding a new attention design we call Cross-Layer\nAttention (CLA). With CLA, we find that it is possible to reduce the size of\nthe KV cache by another 2x while maintaining nearly the same accuracy as\nunmodified MQA. In experiments training 1B- and 3B-parameter models from\nscratch, we demonstrate that CLA provides a Pareto improvement over the\nmemory/accuracy tradeoffs which are possible with traditional MQA, enabling\ninference with longer sequence lengths and larger batch sizes than would\notherwise be possible",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "authors": [
            "William Brandon",
            "Mayank Mishra",
            "Aniruddha Nrusimha",
            "Rameswar Panda",
            "Jonathan Ragan Kelly"
        ],
        "published": "2024-05-21T17:59:29Z"
    },
    {
        "title": "OmniGlue: Generalizable Feature Matching with Foundation Model Guidance",
        "link": "http://arxiv.org/abs/2405.12979v1",
        "abstract": "The image matching field has been witnessing a continuous emergence of novel\nlearnable feature matching techniques, with ever-improving performance on\nconventional benchmarks. However, our investigation shows that despite these\ngains, their potential for real-world applications is restricted by their\nlimited generalization capabilities to novel image domains. In this paper, we\nintroduce OmniGlue, the first learnable image matcher that is designed with\ngeneralization as a core principle. OmniGlue leverages broad knowledge from a\nvision foundation model to guide the feature matching process, boosting\ngeneralization to domains not seen at training time. Additionally, we propose a\nnovel keypoint position-guided attention mechanism which disentangles spatial\nand appearance information, leading to enhanced matching descriptors. We\nperform comprehensive experiments on a suite of $7$ datasets with varied image\ndomains, including scene-level, object-centric and aerial images. OmniGlue's\nnovel components lead to relative gains on unseen domains of $20.9\\%$ with\nrespect to a directly comparable reference model, while also outperforming the\nrecent LightGlue method by $9.5\\%$ relatively.Code and model can be found at\nhttps://hwjiang1510.github.io/OmniGlue",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hanwen Jiang",
            "Arjun Karpur",
            "Bingyi Cao",
            "Qixing Huang",
            "Andre Araujo"
        ],
        "published": "2024-05-21T17:59:22Z"
    },
    {
        "title": "Personalized Residuals for Concept-Driven Text-to-Image Generation",
        "link": "http://arxiv.org/abs/2405.12978v1",
        "abstract": "We present personalized residuals and localized attention-guided sampling for\nefficient concept-driven generation using text-to-image diffusion models. Our\nmethod first represents concepts by freezing the weights of a pretrained\ntext-conditioned diffusion model and learning low-rank residuals for a small\nsubset of the model's layers. The residual-based approach then directly enables\napplication of our proposed sampling technique, which applies the learned\nresiduals only in areas where the concept is localized via cross-attention and\napplies the original diffusion weights in all other regions. Localized sampling\ntherefore combines the learned identity of the concept with the existing\ngenerative prior of the underlying diffusion model. We show that personalized\nresiduals effectively capture the identity of a concept in ~3 minutes on a\nsingle GPU without the use of regularization images and with fewer parameters\nthan previous models, and localized sampling allows using the original model as\nstrong prior for large parts of the image.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Cusuh Ham",
            "Matthew Fisher",
            "James Hays",
            "Nicholas Kolkin",
            "Yuchen Liu",
            "Richard Zhang",
            "Tobias Hinz"
        ],
        "published": "2024-05-21T17:59:01Z"
    },
    {
        "title": "A Sound Type System for Secure Currency Flow",
        "link": "http://arxiv.org/abs/2405.12976v1",
        "abstract": "In this paper we focus on TinySol, a minimal calculus for Solidity smart\ncontracts, introduced by Bartoletti et al. We start by rephrasing its syntax\n(to emphasise its object-oriented flavour) and give a new big-step operational\nsemantics. We then use it to define two security properties, namely call\nintegrity and noninterference. These two properties have some similarities in\ntheir definition, in that they both require that some part of a program is not\ninfluenced by the other part. However, we show that the two properties are\nactually incomparable. Nevertheless, we provide a type system for\nnoninterference and show that well-typed programs satisfy call integrity as\nwell; hence, programs that are accepted by our type system satisfy both\nproperties. We finally discuss the practical usability of the type system and\nits limitations by means of some simple examples.",
        "subjects": [
            "cs.PL"
        ],
        "authors": [
            "Luca Aceto",
            "Daniele Gorla",
            "Stian Lybech"
        ],
        "published": "2024-05-21T17:57:33Z"
    },
    {
        "title": "BiomedParse: a biomedical foundation model for image parsing of\n  everything everywhere all at once",
        "link": "http://arxiv.org/abs/2405.12971v1",
        "abstract": "Biomedical image analysis is fundamental for biomedical discovery in cell\nbiology, pathology, radiology, and many other biomedical domains. Holistic\nimage analysis comprises interdependent subtasks such as segmentation,\ndetection, and recognition of relevant objects. Here, we propose BiomedParse, a\nbiomedical foundation model for imaging parsing that can jointly conduct\nsegmentation, detection, and recognition for 82 object types across 9 imaging\nmodalities. Through joint learning, we can improve accuracy for individual\ntasks and enable novel applications such as segmenting all relevant objects in\nan image through a text prompt, rather than requiring users to laboriously\nspecify the bounding box for each object. We leveraged readily available\nnatural-language labels or descriptions accompanying those datasets and use\nGPT-4 to harmonize the noisy, unstructured text information with established\nbiomedical object ontologies. We created a large dataset comprising over six\nmillion triples of image, segmentation mask, and textual description. On image\nsegmentation, we showed that BiomedParse is broadly applicable, outperforming\nstate-of-the-art methods on 102,855 test image-mask-label triples across 9\nimaging modalities (everything). On object detection, which aims to locate a\nspecific object of interest, BiomedParse again attained state-of-the-art\nperformance, especially on objects with irregular shapes (everywhere). On\nobject recognition, which aims to identify all objects in a given image along\nwith their semantic types, we showed that BiomedParse can simultaneously\nsegment and label all biomedical objects in an image (all at once). In summary,\nBiomedParse is an all-in-one tool for biomedical image analysis by jointly\nsolving segmentation, detection, and recognition for all major biomedical image\nmodalities, paving the path for efficient and accurate image-based biomedical\ndiscovery.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Theodore Zhao",
            "Yu Gu",
            "Jianwei Yang",
            "Naoto Usuyama",
            "Ho Hin Lee",
            "Tristan Naumann",
            "Jianfeng Gao",
            "Angela Crabtree",
            "Brian Piening",
            "Carlo Bifulco",
            "Mu Wei",
            "Hoifung Poon",
            "Sheng Wang"
        ],
        "published": "2024-05-21T17:54:06Z"
    },
    {
        "title": "Face Adapter for Pre-Trained Diffusion Models with Fine-Grained ID and\n  Attribute Control",
        "link": "http://arxiv.org/abs/2405.12970v1",
        "abstract": "Current face reenactment and swapping methods mainly rely on GAN frameworks,\nbut recent focus has shifted to pre-trained diffusion models for their superior\ngeneration capabilities. However, training these models is resource-intensive,\nand the results have not yet achieved satisfactory performance levels. To\naddress this issue, we introduce Face-Adapter, an efficient and effective\nadapter designed for high-precision and high-fidelity face editing for\npre-trained diffusion models. We observe that both face reenactment/swapping\ntasks essentially involve combinations of target structure, ID and attribute.\nWe aim to sufficiently decouple the control of these factors to achieve both\ntasks in one model. Specifically, our method contains: 1) A Spatial Condition\nGenerator that provides precise landmarks and background; 2) A Plug-and-play\nIdentity Encoder that transfers face embeddings to the text space by a\ntransformer decoder. 3) An Attribute Controller that integrates spatial\nconditions and detailed attributes. Face-Adapter achieves comparable or even\nsuperior performance in terms of motion control precision, ID retention\ncapability, and generation quality compared to fully fine-tuned face\nreenactment/swapping models. Additionally, Face-Adapter seamlessly integrates\nwith various StableDiffusion models.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yue Han",
            "Junwei Zhu",
            "Keke He",
            "Xu Chen",
            "Yanhao Ge",
            "Wei Li",
            "Xiangtai Li",
            "Jiangning Zhang",
            "Chengjie Wang",
            "Yong Liu"
        ],
        "published": "2024-05-21T17:50:12Z"
    },
    {
        "title": "Can We Treat Noisy Labels as Accurate?",
        "link": "http://arxiv.org/abs/2405.12969v1",
        "abstract": "Noisy labels significantly hinder the accuracy and generalization of machine\nlearning models, particularly due to ambiguous instance features. Traditional\ntechniques that attempt to correct noisy labels directly, such as those using\ntransition matrices, often fail to address the inherent complexities of the\nproblem sufficiently. In this paper, we introduce EchoAlign, a transformative\nparadigm shift in learning from noisy labels. Instead of focusing on label\ncorrection, EchoAlign treats noisy labels ($\\tilde{Y}$) as accurate and\nmodifies corresponding instance features ($X$) to achieve better alignment with\n$\\tilde{Y}$. EchoAlign's core components are (1) EchoMod: Employing\ncontrollable generative models, EchoMod precisely modifies instances while\nmaintaining their intrinsic characteristics and ensuring alignment with the\nnoisy labels. (2) EchoSelect: Instance modification inevitably introduces\ndistribution shifts between training and test sets. EchoSelect maintains a\nsignificant portion of clean original instances to mitigate these shifts. It\nleverages the distinct feature similarity distributions between original and\nmodified instances as a robust tool for accurate sample selection. This\nintegrated approach yields remarkable results. In environments with 30%\ninstance-dependent noise, even at 99% selection accuracy, EchoSelect retains\nnearly twice the number of samples compared to the previous best method.\nNotably, on three datasets, EchoAlign surpasses previous state-of-the-art\ntechniques with a substantial improvement.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yuxiang Zheng",
            "Zhongyi Han",
            "Yilong Yin",
            "Xin Gao",
            "Tongliang Liu"
        ],
        "published": "2024-05-21T17:49:10Z"
    },
    {
        "title": "The future of cosmological likelihood-based inference: accelerated\n  high-dimensional parameter estimation and model comparison",
        "link": "http://arxiv.org/abs/2405.12965v1",
        "abstract": "We advocate for a new paradigm of cosmological likelihood-based inference,\nleveraging recent developments in machine learning and its underlying\ntechnology, to accelerate Bayesian inference in high-dimensional settings.\nSpecifically, we combine (i) emulation, where a machine learning model is\ntrained to mimic cosmological observables, e.g. CosmoPower-JAX; (ii)\ndifferentiable and probabilistic programming, e.g. JAX and NumPyro,\nrespectively; (iii) scalable Markov chain Monte Carlo (MCMC) sampling\ntechniques that exploit gradients, e.g. Hamiltonian Monte Carlo; and (iv)\ndecoupled and scalable Bayesian model selection techniques that compute the\nBayesian evidence purely from posterior samples, e.g. the learned harmonic mean\nimplemented in harmonic. This paradigm allows us to carry out a complete\nBayesian analysis, including both parameter estimation and model selection, in\na fraction of the time of traditional approaches. First, we demonstrate the\napplication of this paradigm on a simulated cosmic shear analysis for a Stage\nIV survey in 37- and 39-dimensional parameter spaces, comparing $\\Lambda$CDM\nand a dynamical dark energy model ($w_0w_a$CDM). We recover posterior contours\nand evidence estimates that are in excellent agreement with those computed by\nthe traditional nested sampling approach while reducing the computational cost\nfrom 8 months on 48 CPU cores to 2 days on 12 GPUs. Second, we consider a joint\nanalysis between three simulated next-generation surveys, each performing a\n3x2pt analysis, resulting in 157- and 159-dimensional parameter spaces.\nStandard nested sampling techniques are simply not feasible in this\nhigh-dimensional setting, requiring a projected 12 years of compute time on 48\nCPU cores; on the other hand, the proposed approach only requires 8 days of\ncompute time on 24 GPUs. All packages used in our analyses are publicly\navailable.",
        "subjects": [
            "astro-ph.CO",
            "astro-ph.IM",
            "cs.LG"
        ],
        "authors": [
            "Davide Piras",
            "Alicja Polanska",
            "Alessio Spurio Mancini",
            "Matthew A. Price",
            "Jason D. McEwen"
        ],
        "published": "2024-05-21T17:45:36Z"
    },
    {
        "title": "Differential Walk on Spheres",
        "link": "http://arxiv.org/abs/2405.12964v1",
        "abstract": "We introduce a Monte Carlo method for evaluating derivatives of the solution\nto a partial differential equation (PDE) with respect to problem parameters\n(such as domain geometry or boundary conditions). Derivatives can be evaluated\nat arbitrary points without performing a global solve, or constructing a\nvolumetric grid or mesh. The method is hence well-suited to inverse problems\nwith complex geometry, such as PDE-constrained shape optimization. Like other\nwalk on spheres (WoS) algorithms, our method is trivial to parallelize, and is\nagnostic to boundary representation (meshes, splines, implicit surfaces etc.),\nsupporting large topological changes. We focus in particular on screened\nPoisson equations, which model diverse problems from scientific and geometric\ncomputing. As in differentiable rendering, we jointly estimate derivatives with\nrespect to all parameters -- hence, cost does not grow significantly with\nparameter count. In practice, even noisy derivative estimates exhibit fast,\nstable convergence for stochastic gradient-based optimization -- as we show via\nexamples from thermal design, shape from diffusion, and computer graphics.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Bailey Miller",
            "Rohan Sawhney",
            "Keenan Crane",
            "Ioannis Gkioulekas"
        ],
        "published": "2024-05-21T17:45:17Z"
    },
    {
        "title": "Comprehensive Multimodal Deep Learning Survival Prediction Enabled by a\n  Transformer Architecture: A Multicenter Study in Glioblastoma",
        "link": "http://arxiv.org/abs/2405.12963v1",
        "abstract": "Background: This research aims to improve glioblastoma survival prediction by\nintegrating MR images, clinical and molecular-pathologic data in a\ntransformer-based deep learning model, addressing data heterogeneity and\nperformance generalizability. Method: We propose and evaluate a\ntransformer-based non-linear and non-proportional survival prediction model.\nThe model employs self-supervised learning techniques to effectively encode the\nhigh-dimensional MRI input for integration with non-imaging data using\ncross-attention. To demonstrate model generalizability, the model is assessed\nwith the time-dependent concordance index (Cdt) in two training setups using\nthree independent public test sets: UPenn-GBM, UCSF-PDGM, and RHUH-GBM, each\ncomprising 378, 366, and 36 cases, respectively. Results: The proposed\ntransformer model achieved promising performance for imaging as well as\nnon-imaging data, effectively integrating both modalities for enhanced\nperformance (UPenn-GBM test-set, imaging Cdt 0.645, multimodal Cdt 0.707) while\noutperforming state-of-the-art late-fusion 3D-CNN-based models. Consistent\nperformance was observed across the three independent multicenter test sets\nwith Cdt values of 0.707 (UPenn-GBM, internal test set), 0.672 (UCSF-PDGM,\nfirst external test set) and 0.618 (RHUH-GBM, second external test set). The\nmodel achieved significant discrimination between patients with favorable and\nunfavorable survival for all three datasets (logrank p 1.9\\times{10}^{-8},\n9.7\\times{10}^{-3}, and 1.2\\times{10}^{-2}). Conclusions: The proposed\ntransformer-based survival prediction model integrates complementary\ninformation from diverse input modalities, contributing to improved\nglioblastoma survival prediction compared to state-of-the-art methods.\nConsistent performance was observed across institutions supporting model\ngeneralizability.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Ahmed Gomaa",
            "Yixing Huang",
            "Amr Hagag",
            "Charlotte Schmitter",
            "Daniel Höfler",
            "Thomas Weissmann",
            "Katharina Breininger",
            "Manuel Schmidt",
            "Jenny Stritzelberger",
            "Daniel Delev",
            "Roland Coras",
            "Arnd Dörfler",
            "Oliver Schnell",
            "Benjamin Frey",
            "Udo S. Gaipl",
            "Sabine Semrau",
            "Christoph Bert",
            "Rainer Fietkau",
            "Florian Putz"
        ],
        "published": "2024-05-21T17:44:48Z"
    },
    {
        "title": "Modeling for Non-exponential Production Systems Using Parts Flow Data:\n  Model Parameter Estimation and Performance Analysis",
        "link": "http://arxiv.org/abs/2405.12962v1",
        "abstract": "Mathematical modeling of production systems is the foundation of all\nmodel-based approaches for production system analysis, design, improvement, and\ncontrol. To construct such a model for the stochastic process of the production\nsystem more efficiently, a new modeling approach has been proposed that\nreversely identifies the model parameters using system performance metrics\n(e.g., production rate, work-in-process, etc.) derived from the parts flow\ndata. This paper extends this performance metrics-based modeling approach to\nnon-exponential serial production lines. Since no analytical expressions of\nperformance metrics are available for non-exponential systems, we use neural\nnetwork surrogate models to calculate those performance metrics as functions in\nterms of the system parameters. Then, based on the surrogate models and given\nperformance metrics, the machine parameters are estimated by solving a\nconstrained optimization problem that minimizes the mean square error of the\nperformance metrics resulting from the estimated parameters compared to the\ntrue ones. With the designed multi-start particle swarm optimization algorithm,\nwe find that multiple non-unique combinations of machine parameters can lead to\npractically the same system performance metrics and a linear relationship of\nthe reliability parameters from these obtained estimations is observed.\nBesides, model sensitivity analysis is implemented to verify the robustness of\nthe different combinations of machine parameters even under the potential\nimprovement scenarios.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Yuting Sun",
            "Liang Zhang"
        ],
        "published": "2024-05-21T17:40:48Z"
    },
    {
        "title": "Energy Rank Alignment: Using Preference Optimization to Search Chemical\n  Space at Scale",
        "link": "http://arxiv.org/abs/2405.12961v1",
        "abstract": "Searching through chemical space is an exceptionally challenging problem\nbecause the number of possible molecules grows combinatorially with the number\nof atoms. Large, autoregressive models trained on databases of chemical\ncompounds have yielded powerful generators, but we still lack robust strategies\nfor generating molecules with desired properties. This molecular search problem\nclosely resembles the \"alignment\" problem for large language models, though for\nmany chemical tasks we have a specific and easily evaluable reward function.\nHere, we introduce an algorithm called energy rank alignment (ERA) that\nleverages an explicit reward function to produce a gradient-based objective\nthat we use to optimize autoregressive policies. We show theoretically that\nthis algorithm is closely related to proximal policy optimization (PPO) and\ndirect preference optimization (DPO), but has a minimizer that converges to an\nideal Gibbs-Boltzmann distribution with the reward playing the role of an\nenergy function. Furthermore, this algorithm is highly scalable, does not\nrequire reinforcement learning, and performs well relative to DPO when the\nnumber of preference observations per pairing is small. We deploy this approach\nto align molecular transformers to generate molecules with externally specified\nproperties and find that it does so robustly, searching through diverse parts\nof chemical space. While our focus here is on chemical search, we also obtain\nexcellent results on an AI supervised task for LLM alignment, showing that the\nmethod is scalable and general.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "physics.chem-ph",
            "q-bio.QM"
        ],
        "authors": [
            "Shriram Chennakesavalu",
            "Frank Hu",
            "Sebastian Ibarraran",
            "Grant M. Rotskoff"
        ],
        "published": "2024-05-21T17:35:20Z"
    },
    {
        "title": "Soft Synergies: Model Order Reduction of Hybrid Soft-Rigid Robots via\n  Optimal Strain Parameterization",
        "link": "http://arxiv.org/abs/2405.12959v1",
        "abstract": "Soft robots offer remarkable adaptability and safety advantages over rigid\nrobots, but modeling their complex, nonlinear dynamics remains challenging.\nStrain-based models have recently emerged as a promising candidate to describe\nsuch systems, however, they tend to be high-dimensional and time consuming.\nThis paper presents a novel model order reduction approach for soft and hybrid\nrobots by combining strain-based modeling with Proper Orthogonal Decomposition\n(POD). The method identifies optimal coupled strain basis functions -- or\nmechanical synergies -- from simulation data, enabling the description of soft\nrobot configurations with a minimal number of generalized coordinates. The\nreduced order model (ROM) achieves substantial dimensionality reduction while\npreserving accuracy. Rigorous testing demonstrates the interpolation and\nextrapolation capabilities of the ROM for soft manipulators under static and\ndynamic conditions. The approach is further validated on a snake-like\nhyper-redundant rigid manipulator and a closed-chain system with soft and rigid\ncomponents, illustrating its broad applicability. Finally, the approach is\nleveraged for shape estimation of a real six-actuator soft manipulator using\nonly two position markers, showcasing its practical utility. This POD-based ROM\noffers significant computational speed-ups, paving the way for real-time\nsimulation and control of complex soft and hybrid robots.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Abdulaziz Y. Alkayas",
            "Anup Teejo Mathew",
            "Daniel Feliu-Talegon",
            "Ping Deng",
            "Thomas George Thuruthel",
            "Federico Renda"
        ],
        "published": "2024-05-21T17:32:04Z"
    },
    {
        "title": "Online Learning of Halfspaces with Massart Noise",
        "link": "http://arxiv.org/abs/2405.12958v1",
        "abstract": "We study the task of online learning in the presence of Massart noise.\nInstead of assuming that the online adversary chooses an arbitrary sequence of\nlabels, we assume that the context $\\mathbf{x}$ is selected adversarially but\nthe label $y$ presented to the learner disagrees with the ground-truth label of\n$\\mathbf{x}$ with unknown probability at most $\\eta$. We study the fundamental\nclass of $\\gamma$-margin linear classifiers and present a computationally\nefficient algorithm that achieves mistake bound $\\eta T + o(T)$. Our mistake\nbound is qualitatively tight for efficient algorithms: it is known that even in\nthe offline setting achieving classification error better than $\\eta$ requires\nsuper-polynomial time in the SQ model.\n  We extend our online learning model to a $k$-arm contextual bandit setting\nwhere the rewards -- instead of satisfying commonly used realizability\nassumptions -- are consistent (in expectation) with some linear ranking\nfunction with weight vector $\\mathbf{w}^\\ast$. Given a list of contexts\n$\\mathbf{x}_1,\\ldots \\mathbf{x}_k$, if $\\mathbf{w}^*\\cdot \\mathbf{x}_i >\n\\mathbf{w}^* \\cdot \\mathbf{x}_j$, the expected reward of action $i$ must be\nlarger than that of $j$ by at least $\\Delta$. We use our Massart online learner\nto design an efficient bandit algorithm that obtains expected reward at least\n$(1-1/k)~ \\Delta T - o(T)$ bigger than choosing a random action at every round.",
        "subjects": [
            "cs.LG",
            "cs.DS",
            "math.ST",
            "stat.ML",
            "stat.TH"
        ],
        "authors": [
            "Ilias Diakonikolas",
            "Vasilis Kontonis",
            "Christos Tzamos",
            "Nikos Zarifis"
        ],
        "published": "2024-05-21T17:31:10Z"
    },
    {
        "title": "Truncated Variance Reduced Value Iteration",
        "link": "http://arxiv.org/abs/2405.12952v1",
        "abstract": "We provide faster randomized algorithms for computing an $\\epsilon$-optimal\npolicy in a discounted Markov decision process with\n$A_{\\text{tot}}$-state-action pairs, bounded rewards, and discount factor\n$\\gamma$. We provide an $\\tilde{O}(A_{\\text{tot}}[(1 -\n\\gamma)^{-3}\\epsilon^{-2} + (1 - \\gamma)^{-2}])$-time algorithm in the sampling\nsetting, where the probability transition matrix is unknown but accessible\nthrough a generative model which can be queried in $\\tilde{O}(1)$-time, and an\n$\\tilde{O}(s + (1-\\gamma)^{-2})$-time algorithm in the offline setting where\nthe probability transition matrix is known and $s$-sparse. These results\nimprove upon the prior state-of-the-art which either ran in\n$\\tilde{O}(A_{\\text{tot}}[(1 - \\gamma)^{-3}\\epsilon^{-2} + (1 - \\gamma)^{-3}])$\ntime [Sidford, Wang, Wu, Ye 2018] in the sampling setting, $\\tilde{O}(s +\nA_{\\text{tot}} (1-\\gamma)^{-3})$ time [Sidford, Wang, Wu, Yang, Ye 2018] in the\noffline setting, or time at least quadratic in the number of states using\ninterior point methods for linear programming. We achieve our results by\nbuilding upon prior stochastic variance-reduced value iteration methods\n[Sidford, Wang, Wu, Yang, Ye 2018]. We provide a variant that carefully\ntruncates the progress of its iterates to improve the variance of new\nvariance-reduced sampling procedures that we introduce to implement the steps.\nOur method is essentially model-free and can be implemented in\n$\\tilde{O}(A_{\\text{tot}})$-space when given generative model access.\nConsequently, our results take a step in closing the sample-complexity gap\nbetween model-free and model-based methods.",
        "subjects": [
            "cs.LG",
            "cs.DS",
            "math.OC"
        ],
        "authors": [
            "Yujia Jin",
            "Ishani Karmarkar",
            "Aaron Sidford",
            "Jiayi Wang"
        ],
        "published": "2024-05-21T17:28:06Z"
    },
    {
        "title": "Strategic Deployment of Honeypots in Blockchain-based IoT Systems",
        "link": "http://arxiv.org/abs/2405.12951v1",
        "abstract": "This paper addresses the challenge of enhancing cybersecurity in\nBlockchain-based Internet of Things (BIoTs) systems, which are increasingly\nvulnerable to sophisticated cyberattacks. It introduces an AI-powered system\nmodel for the dynamic deployment of honeypots, utilizing an Intrusion Detection\nSystem (IDS) integrated with smart contract functionalities on IoT nodes. This\nmodel enables the transformation of regular nodes into decoys in response to\nsuspicious activities, thereby strengthening the security of BIoT networks. The\npaper analyses strategic interactions between potential attackers and the\nAI-enhanced IDS through a game-theoretic model, specifically Bayesian games.\nThe model focuses on understanding and predicting sophisticated attacks that\nmay initially appear normal, emphasizing strategic decision-making, optimized\nhoneypot deployment, and adaptive strategies in response to evolving attack\npatterns.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.NI"
        ],
        "authors": [
            "Daniel Commey",
            "Sena Hounsinou",
            "Garth V. Crosby"
        ],
        "published": "2024-05-21T17:27:00Z"
    },
    {
        "title": "Trading Volume Maximization with Online Learning",
        "link": "http://arxiv.org/abs/2405.13102v1",
        "abstract": "We explore brokerage between traders in an online learning framework. At any\nround $t$, two traders meet to exchange an asset, provided the exchange is\nmutually beneficial. The broker proposes a trading price, and each trader tries\nto sell their asset or buy the asset from the other party, depending on whether\nthe price is higher or lower than their private valuations. A trade happens if\none trader is willing to sell and the other is willing to buy at the proposed\nprice. Previous work provided guidance to a broker aiming at enhancing traders'\ntotal earnings by maximizing the gain from trade, defined as the sum of the\ntraders' net utilities after each interaction. In contrast, we investigate how\nthe broker should behave to maximize the trading volume, i.e., the total number\nof trades. We model the traders' valuations as an i.i.d. process with an\nunknown distribution. If the traders' valuations are revealed after each\ninteraction (full-feedback), and the traders' valuations cumulative\ndistribution function (cdf) is continuous, we provide an algorithm achieving\nlogarithmic regret and show its optimality up to constant factors. If only\ntheir willingness to sell or buy at the proposed price is revealed after each\ninteraction ($2$-bit feedback), we provide an algorithm achieving\npoly-logarithmic regret when the traders' valuations cdf is Lipschitz and show\nthat this rate is near-optimal. We complement our results by analyzing the\nimplications of dropping the regularity assumptions on the unknown traders'\nvaluations cdf. If we drop the continuous cdf assumption, the regret rate\ndegrades to $\\Theta(\\sqrt{T})$ in the full-feedback case, where $T$ is the time\nhorizon. If we drop the Lipschitz cdf assumption, learning becomes impossible\nin the $2$-bit feedback case.",
        "subjects": [
            "cs.GT",
            "cs.LG",
            "q-fin.CP"
        ],
        "authors": [
            "Tommaso Cesari",
            "Roberto Colomboni"
        ],
        "published": "2024-05-21T17:26:44Z"
    },
    {
        "title": "Exact predicates, exact constructions and combinatorics for mesh CSG",
        "link": "http://arxiv.org/abs/2405.12949v1",
        "abstract": "This article introduces a general mesh intersection algorithm that exactly\ncomputes the so-called Weiler model and that uses it to implement boolean\noperations with arbitrary multi-operand expressions, CSG (constructive solid\ngeometry) and some mesh repair operations. From an input polygon soup, the\nalgorithm first computes the co-refinement, with an exact representation of the\nintersection points. Then, the decomposition of 3D space into volumetric\nregions (Weiler model) is constructed, by sorting the facets around the\nnon-manifold intersection edges (radial sort), using specialized exact\npredicates. Finally, based on the input boolean expression, the triangular\nfacets that belong to the boundary of the result are classified. This is, to\nour knowledge, the first algorithm that computes an exact Weiler model. To\nimplement all the involved predicates and constructions, two geometric kernels\nare proposed, tested and discussed (arithmetic expansions and multi-precision\nfloating-point). As a guiding principle,the combinatorial information shared\nbetween each step is kept as simple as possible. It is made possible by\ntreating all the particular cases in the kernel. In particular, triangles with\nintersections are remeshed using the (uniquely defined) Constrained Delaunay\nTriangulation, with symbolic perturbations to disambiguate configurations with\nco-cyclic points. It makes it easy to discard the duplicated triangles that\nappear when remeshing overlapping facets. The method is tested and compared\nwith previous work, on the existing \"thingi10K\" dataset (to test co-refinement\nand mesh repair) and on a new \"thingiCSG\" dataset made publicly available (to\ntest the full CSG pipeline) on a variety of interesting examples featuring\ndifferent types of \"pathologies\"",
        "subjects": [
            "cs.CG"
        ],
        "authors": [
            "Bruno Lévy"
        ],
        "published": "2024-05-21T17:21:41Z"
    },
    {
        "title": "Tutorly: Turning Programming Videos Into Apprenticeship Learning\n  Environments with LLMs",
        "link": "http://arxiv.org/abs/2405.12946v1",
        "abstract": "Online programming videos, including tutorials and streamcasts, are widely\npopular and contain a wealth of expert knowledge. However, effectively\nutilizing these resources to achieve targeted learning goals can be\nchallenging. Unlike direct tutoring, video content lacks tailored guidance\nbased on individual learning paces, personalized feedback, and interactive\nengagement necessary for support and monitoring. Our work transforms\nprogramming videos into one-on-one tutoring experiences using the cognitive\napprenticeship framework. Tutorly, developed as a JupyterLab Plugin, allows\nlearners to (1) set personalized learning goals, (2) engage in\nlearning-by-doing through a conversational LLM-based mentor agent, (3) receive\nguidance and feedback based on a student model that steers the mentor moves. In\na within-subject study with 16 participants learning exploratory data analysis\nfrom a streamcast, Tutorly significantly improved their performance from 61.9%\nto 76.6% based on a post-test questionnaire. Tutorly demonstrates the potential\nfor enhancing programming video learning experiences with LLM and learner\nmodeling.",
        "subjects": [
            "cs.HC",
            "cs.LG"
        ],
        "authors": [
            "Wengxi Li",
            "Roy Pea",
            "Nick Haber",
            "Hari Subramonyam"
        ],
        "published": "2024-05-21T17:17:34Z"
    },
    {
        "title": "Improved upper bounds for the Heilbronn's Problem for $k$-gons",
        "link": "http://arxiv.org/abs/2405.12945v1",
        "abstract": "The Heilbronn triangle problem asks for the placement of $n$ points in a unit\nsquare that maximizes the smallest area of a triangle formed by any three of\nthose points. In $1972$, Schmidt considered a natural generalization of this\nproblem. He asked for the placement of $n$ points in a unit square that\nmaximizes the smallest area of the convex hull formed by any four of those\npoints. He showed a lower bound of $\\Omega(n^{-3/2})$, which was improved to\n$\\Omega(n^{-3/2}\\log{n})$ by Leffman.\n  A trivial upper bound of $3/n$ could be obtained, and Schmidt asked if this\ncould be improved asymptotically. However, despite several efforts, no\nasymptotic improvement over the trivial upper bound was known for the last $50$\nyears, and the problem started to get the tag of being notoriously hard.\nSzemer{\\'e}di posed the question of whether one can, at least, improve the\nconstant in this trivial upper bound. In this work, we answer this question by\nproving an upper bound of $2/n+o(1/n)$. We also extend our results to any\nconvex hulls formed by $k\\geq 4$ points.",
        "subjects": [
            "cs.DM",
            "cs.CG",
            "math.CO"
        ],
        "authors": [
            "Rishikesh Gajjala",
            "Jayanth Ravi"
        ],
        "published": "2024-05-21T17:17:25Z"
    },
    {
        "title": "AMFD: Distillation via Adaptive Multimodal Fusion for Multispectral\n  Pedestrian Detection",
        "link": "http://arxiv.org/abs/2405.12944v1",
        "abstract": "Multispectral pedestrian detection has been shown to be effective in\nimproving performance within complex illumination scenarios. However, prevalent\ndouble-stream networks in multispectral detection employ two separate feature\nextraction branches for multi-modal data, leading to nearly double the\ninference time compared to single-stream networks utilizing only one feature\nextraction branch. This increased inference time has hindered the widespread\nemployment of multispectral pedestrian detection in embedded devices for\nautonomous systems. To address this limitation, various knowledge distillation\nmethods have been proposed. However, traditional distillation methods focus\nonly on the fusion features and ignore the large amount of information in the\noriginal multi-modal features, thereby restricting the student network's\nperformance. To tackle the challenge, we introduce the Adaptive Modal Fusion\nDistillation (AMFD) framework, which can fully utilize the original modal\nfeatures of the teacher network. Specifically, a Modal Extraction Alignment\n(MEA) module is utilized to derive learning weights for student networks,\nintegrating focal and global attention mechanisms. This methodology enables the\nstudent network to acquire optimal fusion strategies independent from that of\nteacher network without necessitating an additional feature fusion module.\nFurthermore, we present the SMOD dataset, a well-aligned challenging\nmultispectral dataset for detection. Extensive experiments on the challenging\nKAIST, LLVIP and SMOD datasets are conducted to validate the effectiveness of\nAMFD. The results demonstrate that our method outperforms existing\nstate-of-the-art methods in both reducing log-average Miss Rate and improving\nmean Average Precision. The code is available at\nhttps://github.com/bigD233/AMFD.git.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zizhao Chen",
            "Yeqiang Qian",
            "Xiaoxiao Yang",
            "Chunxiang Wang",
            "Ming Yang"
        ],
        "published": "2024-05-21T17:17:17Z"
    },
    {
        "title": "Learning the Infinitesimal Generator of Stochastic Diffusion Processes",
        "link": "http://arxiv.org/abs/2405.12940v1",
        "abstract": "We address data-driven learning of the infinitesimal generator of stochastic\ndiffusion processes, essential for understanding numerical simulations of\nnatural and physical systems. The unbounded nature of the generator poses\nsignificant challenges, rendering conventional analysis techniques for\nHilbert-Schmidt operators ineffective. To overcome this, we introduce a novel\nframework based on the energy functional for these stochastic processes. Our\napproach integrates physical priors through an energy-based risk metric in both\nfull and partial knowledge settings. We evaluate the statistical performance of\na reduced-rank estimator in reproducing kernel Hilbert spaces (RKHS) in the\npartial knowledge setting. Notably, our approach provides learning bounds\nindependent of the state space dimension and ensures non-spurious spectral\nestimation. Additionally, we elucidate how the distortion between the intrinsic\nenergy-induced metric of the stochastic diffusion and the RKHS metric used for\ngenerator estimation impacts the spectral learning bounds.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.PR",
            "62M15"
        ],
        "authors": [
            "Vladimir R. Kostic",
            "Karim Lounici",
            "Helene Halconruy",
            "Timothee Devergne",
            "Massimiliano Pontil"
        ],
        "published": "2024-05-21T17:13:13Z"
    },
    {
        "title": "Aggregation of Reasoning: A Hierarchical Framework for Enhancing Answer\n  Selection in Large Language Models",
        "link": "http://arxiv.org/abs/2405.12939v1",
        "abstract": "Recent advancements in Chain-of-Thought prompting have facilitated\nsignificant breakthroughs for Large Language Models (LLMs) in complex reasoning\ntasks. Current research enhances the reasoning performance of LLMs by sampling\nmultiple reasoning chains and ensembling based on the answer frequency.\nHowever, this approach fails in scenarios where the correct answers are in the\nminority. We identify this as a primary factor constraining the reasoning\ncapabilities of LLMs, a limitation that cannot be resolved solely based on the\npredicted answers. To address this shortcoming, we introduce a hierarchical\nreasoning aggregation framework AoR (Aggregation of Reasoning), which selects\nanswers based on the evaluation of reasoning chains. Additionally, AoR\nincorporates dynamic sampling, adjusting the number of reasoning chains in\naccordance with the complexity of the task. Experimental results on a series of\ncomplex reasoning tasks show that AoR outperforms prominent ensemble methods.\nFurther analysis reveals that AoR not only adapts various LLMs but also\nachieves a superior performance ceiling when compared to current methods.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Zhangyue Yin",
            "Qiushi Sun",
            "Qipeng Guo",
            "Zhiyuan Zeng",
            "Xiaonan Li",
            "Tianxiang Sun",
            "Cheng Chang",
            "Qinyuan Cheng",
            "Ding Wang",
            "Xiaofeng Mou",
            "Xipeng Qiu",
            "XuanJing Huang"
        ],
        "published": "2024-05-21T17:12:19Z"
    },
    {
        "title": "Asymptotic analysis of sum-rate under SIC",
        "link": "http://arxiv.org/abs/2405.12937v1",
        "abstract": "Limitation of the cost of coordination and contention among a large number of\nnodes calls for grant-free approaches, exploiting physical layer techniques to\nsolve collisions. Successive Interference Cancellation (SIC) is becoming a key\nbuilding block of multiple access channel receiver, in an effort to support\nmassive Internet of Things (IoT). In this paper, we explore the large-scale\nperformance of SIC in a theoretical framework. A general model of a SIC\nreceiver is stated for a shared channel with $n$ transmitters. The asymptotic\nsum-rate performance is characterized as $n \\rightarrow \\infty$, for a suitably\nscaled target Signal to Noise Interference Ratio (SNIR). The probability\ndistribution of the number of correctly decoded packets is shown to tend to a\ndeterministic distribution asymptotically for large values of $n$. The\nasymptotic analysis is carried out for any probability distribution of the\nwireless channel gain, assuming that the average received power level is same\nfor all nodes, through power control.",
        "subjects": [
            "eess.SP",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Andrea Baiocchi",
            "Asmad Razzaque"
        ],
        "published": "2024-05-21T17:08:44Z"
    },
    {
        "title": "Address-Specific Sustainable Accommodation Choice Through Real-World\n  Data Integration",
        "link": "http://arxiv.org/abs/2405.12934v1",
        "abstract": "Consumers wish to choose sustainable accommodation for their travels, and in\nthe case of corporations, may be required to do so. Yet accommodation\nmarketplaces provide no meaningful capability for sustainable choice: typically\nCO2 estimates are provided that are identical for all accommodation of the same\ntype across an entire country. We propose a decision support system that\nenables real choice of sustainable accommodation. We develop a data-driven\naddress-specific metric called EcoGrade, which integrates government approved\ndatasets and uses interpolation where data is sparse. We validate the metric on\n10,000 UK addresses in 10 cities, showing the match of our interpolations to\nreality is statistically significant. We show how the metric has been embedded\ninto a decision support system for a global accommodation marketplace and\ntested by real users over several months with positive user feedback. In the\nEU, forty percent of final energy consumption is from buildings. We need to\nencourage all building owners to make their accommodation more efficient. The\nrental sector is one area where change can occur rapidly, as rented\naccommodation is renovated frequently. We anticipate our decision support\nsystem using EcoGrade will encourage this positive change.",
        "subjects": [
            "cs.CY",
            "cs.CE",
            "cs.IR",
            "68U35",
            "E.m; H.m"
        ],
        "authors": [
            "Peter J. Bentley",
            "Rajat Mathur",
            "Soo Ling Lim",
            "Sid Narang"
        ],
        "published": "2024-05-21T17:05:02Z"
    },
    {
        "title": "Skin-in-the-Game: Decision Making via Multi-Stakeholder Alignment in\n  LLMs",
        "link": "http://arxiv.org/abs/2405.12933v1",
        "abstract": "Large Language Models (LLMs) have shown remarkable capabilities in tasks such\nas summarization, arithmetic reasoning, and question answering. However, they\nencounter significant challenges in the domain of moral reasoning and ethical\ndecision-making, especially in complex scenarios with multiple stakeholders.\nThis paper introduces the Skin-in-the-Game (SKIG) framework, aimed at enhancing\nmoral reasoning in LLMs by exploring decisions' consequences from multiple\nstakeholder perspectives. Central to SKIG's mechanism is simulating\naccountability for actions, which, alongside empathy exercises and risk\nassessment, is pivotal to its effectiveness. We validate SKIG's performance\nacross various moral reasoning benchmarks with proprietary and opensource LLMs,\nand investigate its crucial components through extensive ablation analyses.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Bilgehan Sel",
            "Priya Shanmugasundaram",
            "Mohammad Kachuee",
            "Kun Zhou",
            "Ruoxi Jia",
            "Ming Jin"
        ],
        "published": "2024-05-21T17:04:44Z"
    },
    {
        "title": "Evaluating AI-generated code for C++, Fortran, Go, Java, Julia, Matlab,\n  Python, R, and Rust",
        "link": "http://arxiv.org/abs/2405.13101v1",
        "abstract": "This study evaluates the capabilities of ChatGPT versions 3.5 and 4 in\ngenerating code across a diverse range of programming languages. Our objective\nis to assess the effectiveness of these AI models for generating scientific\nprograms. To this end, we asked ChatGPT to generate three distinct codes: a\nsimple numerical integration, a conjugate gradient solver, and a parallel 1D\nstencil-based heat equation solver. The focus of our analysis was on the\ncompilation, runtime performance, and accuracy of the codes. While both\nversions of ChatGPT successfully created codes that compiled and ran (with some\nhelp), some languages were easier for the AI to use than others (possibly\nbecause of the size of the training sets used). Parallel codes -- even the\nsimple example we chose to study here -- also difficult for the AI to generate\ncorrectly.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "authors": [
            "Patrick Diehl",
            "Noujoud Nader",
            "Steve Brandt",
            "Hartmut Kaiser"
        ],
        "published": "2024-05-21T17:04:37Z"
    },
    {
        "title": "Enabling Additive Manufacturing Part Inspection of Digital Twins via\n  Collaborative Virtual Reality",
        "link": "http://arxiv.org/abs/2405.12931v1",
        "abstract": "Digital twins (DTs) are an emerging capability in additive manufacturing\n(AM), set to revolutionize design optimization, inspection, in situ monitoring,\nand root cause analysis. AM DTs typically incorporate multimodal data streams,\nranging from machine toolpaths and in-process imaging to X-ray CT scans and\nperformance metrics. Despite the evolution of DT platforms, challenges remain\nin effectively inspecting them for actionable insights, either individually or\nin a multidisciplinary team setting. Quality assurance, manufacturing\ndepartments, pilot labs, and plant operations must collaborate closely to\nreliably produce parts at scale. This is particularly crucial in AM where\ncomplex structures require a collaborative and multidisciplinary approach.\nAdditionally, the large-scale data originating from different modalities and\ntheir inherent 3D nature pose significant hurdles for traditional 2D\ndesktop-based inspection methods. To address these challenges and increase the\nvalue proposition of DTs, we introduce a novel virtual reality (VR) framework\nto facilitate collaborative and real-time inspection of DTs in AM. This\nframework includes advanced features for intuitive alignment and visualization\nof multimodal data, visual occlusion management, streaming large-scale\nvolumetric data, and collaborative tools, substantially improving the\ninspection of AM components and processes to fully exploit the potential of DTs\nin AM.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Vuthea Chheang",
            "Saurabh Narain",
            "Garrett Hooten",
            "Robert Cerda",
            "Brian Au",
            "Brian Weston",
            "Brian Giera",
            "Peer-Timo Bremer",
            "Haichao Miao"
        ],
        "published": "2024-05-21T16:59:21Z"
    },
    {
        "title": "Pytorch-Wildlife: A Collaborative Deep Learning Framework for\n  Conservation",
        "link": "http://arxiv.org/abs/2405.12930v1",
        "abstract": "The alarming decline in global biodiversity, driven by various factors,\nunderscores the urgent need for large-scale wildlife monitoring. In response,\nscientists have turned to automated deep learning methods for data processing\nin wildlife monitoring. However, applying these advanced methods in real-world\nscenarios is challenging due to their complexity and the need for specialized\nknowledge, primarily because of technical challenges and interdisciplinary\nbarriers.\n  To address these challenges, we introduce Pytorch-Wildlife, an open-source\ndeep learning platform built on PyTorch. It is designed for creating,\nmodifying, and sharing powerful AI models. This platform emphasizes usability\nand accessibility, making it accessible to individuals with limited or no\ntechnical background. It also offers a modular codebase to simplify feature\nexpansion and further development. Pytorch-Wildlife offers an intuitive,\nuser-friendly interface, accessible through local installation or Hugging Face,\nfor animal detection and classification in images and videos. As two real-world\napplications, Pytorch-Wildlife has been utilized to train animal classification\nmodels for species recognition in the Amazon Rainforest and for invasive\nopossum recognition in the Galapagos Islands. The Opossum model achieves 98%\naccuracy, and the Amazon model has 92% recognition accuracy for 36 animals in\n90% of the data. As Pytorch-Wildlife evolves, we aim to integrate more\nconservation tasks, addressing various environmental challenges.\nPytorch-Wildlife is available at https://github.com/microsoft/CameraTraps.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Andres Hernandez",
            "Zhongqi Miao",
            "Luisa Vargas",
            "Rahul Dodhia",
            "Juan Lavista"
        ],
        "published": "2024-05-21T16:58:35Z"
    },
    {
        "title": "Code-mixed Sentiment and Hate-speech Prediction",
        "link": "http://arxiv.org/abs/2405.12929v1",
        "abstract": "Code-mixed discourse combines multiple languages in a single text. It is\ncommonly used in informal discourse in countries with several official\nlanguages, but also in many other countries in combination with English or\nneighboring languages. As recently large language models have dominated most\nnatural language processing tasks, we investigated their performance in\ncode-mixed settings for relevant tasks. We first created four new bilingual\npre-trained masked language models for English-Hindi and English-Slovene\nlanguages, specifically aimed to support informal language. Then we performed\nan evaluation of monolingual, bilingual, few-lingual, and massively\nmultilingual models on several languages, using two tasks that frequently\ncontain code-mixed text, in particular, sentiment analysis and offensive\nlanguage detection in social media texts. The results show that the most\nsuccessful classifiers are fine-tuned bilingual models and multilingual models,\nspecialized for social media texts, followed by non-specialized massively\nmultilingual and monolingual models, while huge generative models are not\ncompetitive. For our affective problems, the models mostly perform slightly\nbetter on code-mixed data compared to non-code-mixed data.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Anjali Yadav",
            "Tanya Garg",
            "Matej Klemen",
            "Matej Ulcar",
            "Basant Agarwal",
            "Marko Robnik Sikonja"
        ],
        "published": "2024-05-21T16:56:36Z"
    },
    {
        "title": "On Image Registration and Subpixel Estimation",
        "link": "http://arxiv.org/abs/2405.12927v1",
        "abstract": "Image registration is a classical problem in machine vision which seeks\nmethods to align discrete images of the same scene to subpixel accuracy in\ngeneral situations. As with all estimation problems, the underlying difficulty\nis the partial information available about the ground truth. We consider a\nbasic and idealized one-dimensional image registration problem motivated by\nquestions about measurement and about quantization, and we demonstrate that the\nextent to which subinterval/subpixel inferences can be made in this setting\ndepends on a type of complexity associated with the function of interest, the\nrelationship between the function and the pixel size, and the number of\ndistinct sampling count observations available.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Serap A. Savari"
        ],
        "published": "2024-05-21T16:53:03Z"
    },
    {
        "title": "Trusting Fair Data: Leveraging Quality in Fairness-Driven Data Removal\n  Techniques",
        "link": "http://arxiv.org/abs/2405.12926v1",
        "abstract": "In this paper, we deal with bias mitigation techniques that remove specific\ndata points from the training set to aim for a fair representation of the\npopulation in that set. Machine learning models are trained on these\npre-processed datasets, and their predictions are expected to be fair. However,\nsuch approaches may exclude relevant data, making the attained subsets less\ntrustworthy for further usage. To enhance the trustworthiness of prior methods,\nwe propose additional requirements and objectives that the subsets must fulfill\nin addition to fairness: (1) group coverage, and (2) minimal data loss. While\nremoving entire groups may improve the measured fairness, this practice is very\nproblematic as failing to represent every group cannot be considered fair. In\nour second concern, we advocate for the retention of data while minimizing\ndiscrimination. By introducing a multi-objective optimization problem that\nconsiders fairness and data loss, we propose a methodology to find\nPareto-optimal solutions that balance these objectives. By identifying such\nsolutions, users can make informed decisions about the trade-off between\nfairness and data quality and select the most suitable subset for their\napplication.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Manh Khoi Duong",
            "Stefan Conrad"
        ],
        "published": "2024-05-21T16:51:28Z"
    },
    {
        "title": "Time-dependent Hamiltonian Simulation via Magnus Expansion: Algorithm\n  and Superconvergence",
        "link": "http://arxiv.org/abs/2405.12925v1",
        "abstract": "Hamiltonian simulation becomes more challenging as the underlying unitary\nbecomes more oscillatory. In such cases, an algorithm with commutator scaling\nand a weak dependence, such as logarithmic, on the derivatives of the\nHamiltonian is desired. We introduce a new time-dependent Hamiltonian\nsimulation algorithm based on the Magnus series expansion that exhibits both\nfeatures. Importantly, when applied to unbounded Hamiltonian simulation in the\ninteraction picture, we prove that the commutator in the second-order algorithm\nleads to a surprising fourth-order superconvergence, with an error preconstant\nindependent of the number of spatial grids. This extends the qHOP algorithm\n[An, Fang, Lin, Quantum 2022] based on first-order Magnus expansion, and the\nproof of superconvergence is based on semiclassical analysis that is of\nindependent interest.",
        "subjects": [
            "quant-ph",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Di Fang",
            "Diyi Liu",
            "Rahul Sarkar"
        ],
        "published": "2024-05-21T16:49:54Z"
    },
    {
        "title": "Panmodal Information Interaction",
        "link": "http://arxiv.org/abs/2405.12923v1",
        "abstract": "The emergence of generative artificial intelligence (GenAI) is transforming\ninformation interaction. For decades, search engines such as Google and Bing\nhave been the primary means of locating relevant information for the general\npopulation. They have provided search results in the same standard format (the\nso-called \"10 blue links\"). The recent ability to chat via natural language\nwith AI-based agents and have GenAI automatically synthesize answers in\nreal-time (grounded in top-ranked results) is changing how people interact with\nand consume information at massive scale. These two information interaction\nmodalities (traditional search and AI-powered chat) coexist in current search\nengines, either loosely coupled (e.g., as separate options/tabs) or tightly\ncoupled (e.g., integrated as a chat answer embedded directly within a\ntraditional search result page). We believe that the existence of these two\ndifferent modalities, and potentially many others, is creating an opportunity\nto re-imagine the search experience, capitalize on the strengths of many\nmodalities, and develop systems and strategies to support seamless flow between\nthem. We refer to these as panmodal experiences. Unlike monomodal experiences,\nwhere only one modality is available and/or used for the task at hand, panmodal\nexperiences make multiple modalities available to users (multimodal), directly\nsupport transitions between modalities (crossmodal), and seamlessly combine\nmodalities to tailor task assistance (transmodal). While our focus is search\nand chat, with learnings from insights from a survey of over 100 individuals\nwho have recently performed common tasks on these two modalities, we also\npresent a more general vision for the future of information interaction using\nmultiple modalities and the emergent capabilities of GenAI.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.HC"
        ],
        "authors": [
            "Chirag Shah",
            "Ryen W. White"
        ],
        "published": "2024-05-21T16:49:14Z"
    },
    {
        "title": "Is decidability of the Submonoid Membership Problem closed under finite\n  extensions?",
        "link": "http://arxiv.org/abs/2405.12921v1",
        "abstract": "We show that the rational subset membership problem in $G$ can be reduced to\nthe submonoid membership problem in $G{\\times}H$ where $H$ is virtually\nAbelian. We use this to show that there is no algorithm reducing submonoid\nmembership to a finite index subgroup uniformly for all virtually nilpotent\ngroups. We also provide evidence towards the existence of a group $G$ with a\nsubgroup $H<G$ of index 2, such that the submonoid membership problem is\ndecidable in $H$ but not in $G$.",
        "subjects": [
            "math.GR",
            "cs.FL"
        ],
        "authors": [
            "Doron Shafrir"
        ],
        "published": "2024-05-21T16:45:20Z"
    },
    {
        "title": "Streamlining Software Reviews: Efficient Predictive Modeling with\n  Minimal Examples",
        "link": "http://arxiv.org/abs/2405.12920v1",
        "abstract": "This paper proposes a new challenge problem for software analytics. In the\nprocess we shall call \"software review\", a panel of SMEs (subject matter\nexperts) review examples of software behavior to recommend how to improve\nthat's software's operation. SME time is usually extremely limited so, ideally,\nthis panel can complete this optimization task after looking at just a small\nnumber of very informative, examples.\n  To support this review process, we explore methods that train a predictive\nmodel to guess if some oracle will like/dislike the next example. Such a\npredictive model can work with the SMEs to guide them in their exploration of\nall the examples. Also, after the panelists leave, that model can be used as an\noracle in place of the panel (to handle new examples, while the panelists are\nbusy, elsewhere).\n  In 31 case studies (ranging from from high-level decisions about software\nprocesses to low-level decisions about how to configure video encoding\nsoftware), we show that such predictive models can be built using as few as 12\nto 30 labels. To the best of our knowledge, this paper's success with only a\nhandful of examples (and no large language model) is unprecedented.\n  In accordance with the principles of open science, we offer all our code and\ndata at https://github.com/timm/ez/tree/Stable-EMSE-paper so that others can\nrepeat/refute/improve these results.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Tim Menzies",
            "Andre Lustosa"
        ],
        "published": "2024-05-21T16:42:02Z"
    },
    {
        "title": "Commutative codensity monads and probability bimeasures",
        "link": "http://arxiv.org/abs/2405.12917v1",
        "abstract": "Several well-studied probability monads have been expressed as codensity\nmonads over small categories of stochastic maps, giving a limit description of\nspaces of probability measures. In this paper we show how properties of\nprobability monads such as commutativity and affineness can arise from their\ncodensity presentation. First we show that their codensity presentation is\nclosely related to another characterisation of probability monads as terminal\nendofunctors admitting certain maps into the Giry monad, which allows us to\ngeneralise a result by Van Breugel on the Kantorovich monad. We then provide\nsufficient conditions for a codensity monad to lift to $\\bf{MonCat}$, and give\na characterisation of exactly pointwise monoidal codensity monads; codensity\nmonads that satisfy a strengthening of these conditions. We show that the Radon\nmonad is exactly pointwise monoidal, and hence give a description of the tensor\nproduct of free algebras of the Radon monad in terms of Day convolution.\nFinally we show that the Giry monad is not exactly pointwise monoidal due to\nthe existence of probability bimeasures that do not extend to measures,\nalthough its restriction to standard Borel spaces is. We introduce the notion\nof a $*$-monad and its Kleisli monoidal op-multicategory to describe the\ncategorical structure that organises the spaces of probability polymeasures on\nmeasurable spaces.",
        "subjects": [
            "math.CT",
            "cs.LO",
            "math.PR"
        ],
        "authors": [
            "Zev Shirazi"
        ],
        "published": "2024-05-21T16:39:26Z"
    },
    {
        "title": "G-DIG: Towards Gradient-based DIverse and hiGh-quality Instruction Data\n  Selection for Machine Translation",
        "link": "http://arxiv.org/abs/2405.12915v1",
        "abstract": "Large Language Models (LLMs) have demonstrated remarkable abilities in\ngeneral scenarios. Instruction finetuning empowers them to align with humans in\nvarious tasks. Nevertheless, the Diversity and Quality of the instruction data\nremain two main challenges for instruction finetuning. With regard to this, in\nthis paper, we propose a novel gradient-based method to automatically select\nhigh-quality and diverse instruction finetuning data for machine translation.\nOur key innovation centers around analyzing how individual training examples\ninfluence the model during training. Specifically, we select training examples\nthat exert beneficial influences on the model as high-quality ones by means of\nInfluence Function plus a small high-quality seed dataset. Moreover, to enhance\nthe diversity of the training data we maximize the variety of influences they\nhave on the model by clustering on their gradients and resampling. Extensive\nexperiments on WMT22 and FLORES translation tasks demonstrate the superiority\nof our methods, and in-depth analysis further validates their effectiveness and\ngeneralization.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Xingyuan Pan",
            "Luyang Huang",
            "Liyan Kang",
            "Zhicheng Liu",
            "Yu Lu",
            "Shanbo Cheng"
        ],
        "published": "2024-05-21T16:38:13Z"
    },
    {
        "title": "An Empirical Study and Analysis of Text-to-Image Generation Using Large\n  Language Model-Powered Textual Representation",
        "link": "http://arxiv.org/abs/2405.12914v1",
        "abstract": "One critical prerequisite for faithful text-to-image generation is the\naccurate understanding of text inputs. Existing methods leverage the text\nencoder of the CLIP model to represent input prompts. However, the pre-trained\nCLIP model can merely encode English with a maximum token length of 77.\nMoreover, the model capacity of the text encoder from CLIP is relatively\nlimited compared to Large Language Models (LLMs), which offer multilingual\ninput, accommodate longer context, and achieve superior text representation. In\nthis paper, we investigate LLMs as the text encoder to improve the language\nunderstanding in text-to-image generation. Unfortunately, training\ntext-to-image generative model with LLMs from scratch demands significant\ncomputational resources and data. To this end, we introduce a three-stage\ntraining pipeline that effectively and efficiently integrates the existing\ntext-to-image model with LLMs. Specifically, we propose a lightweight adapter\nthat enables fast training of the text-to-image model using the textual\nrepresentations from LLMs. Extensive experiments demonstrate that our model\nsupports not only multilingual but also longer input context with superior\nimage generation quality.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhiyu Tan",
            "Mengping Yang",
            "Luozheng Qin",
            "Hao Yang",
            "Ye Qian",
            "Qiang Zhou",
            "Cheng Zhang",
            "Hao Li"
        ],
        "published": "2024-05-21T16:35:02Z"
    },
    {
        "title": "Topic Modelling Case Law Using a Large Language Model and a New Taxonomy\n  for UK Law: AI Insights into Summary Judgment",
        "link": "http://arxiv.org/abs/2405.12910v1",
        "abstract": "This paper addresses a critical gap in legal analytics by developing and\napplying a novel taxonomy for topic modelling summary judgment cases in the\nUnited Kingdom. Using a curated dataset of summary judgment cases, we use the\nLarge Language Model Claude 3 Opus to explore functional topics and trends. We\nfind that Claude 3 Opus correctly classified the topic with an accuracy of\n87.10%. The analysis reveals distinct patterns in the application of summary\njudgments across various legal domains. As case law in the United Kingdom is\nnot originally labelled with keywords or a topic filtering option, the findings\nnot only refine our understanding of the thematic underpinnings of summary\njudgments but also illustrate the potential of combining traditional and\nAI-driven approaches in legal classification. Therefore, this paper provides a\nnew and general taxonomy for UK law. The implications of this work serve as a\nfoundation for further research and policy discussions in the field of judicial\nadministration and computational legal research methodologies.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CY",
            "cs.LG"
        ],
        "authors": [
            "Holli Sargeant",
            "Ahmed Izzidien",
            "Felix Steffek"
        ],
        "published": "2024-05-21T16:30:25Z"
    },
    {
        "title": "Extremum Seeking is Stable for Scalar Maps that are Strictly but Not\n  Strongly Convex",
        "link": "http://arxiv.org/abs/2405.12908v1",
        "abstract": "For a map that is strictly but not strongly convex, model-based gradient\nextremum seeking has an eigenvalue of zero at the extremum, i.e., it fails at\nexponential convergence. Interestingly, perturbation-based model-free extremum\nseeking has a negative Jacobian, in the average, meaning that its (practical)\nconvergence is exponential, even though the map's Hessian is zero at the\nextremum. While these observations for the gradient algorithm are not trivial,\nwe focus in this paper on an even more nontrivial study of the same phenomenon\nfor Newton-based extremum seeking control (NESC).\n  NESC is a second-order method which corrects for the unknown Hessian of the\nunknown map, not only in order to speed up parameter convergence, but also (1)\nto make the convergence rate user-assignable in spite of the unknown Hessian,\nand (2) to equalize the convergence rates in different directions for\nmultivariable maps. Previous NESC work established stability only for maps\nwhose Hessians are strictly positive definite everywhere, so the Hessian is\ninvertible everywhere. For a scalar map, we establish the rather unexpected\nproperty that, even when the map behind is strictly convex but not strongly\nconvex, i.e., when the Hessian may be zero, NESC guarantees practical\nasymptotic stability, semiglobally. While a model-based Newton-based algorithm\nwould run into non-invertibility of the Hessian, the perturbation-based NESC,\nsurprisingly, avoids this challenge by leveraging the fact that the average of\nthe perturbation-based Hessian estimate is always positive, even though the\nactual Hessian may be zero.",
        "subjects": [
            "math.OC",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Patrick McNamee",
            "Miroslav Krstić",
            "Zahra Nili Ahmadabadi"
        ],
        "published": "2024-05-21T16:27:04Z"
    },
    {
        "title": "Exponential Steepest Ascent from Valued Constraint Graphs of Pathwidth\n  Four",
        "link": "http://arxiv.org/abs/2405.12906v1",
        "abstract": "We examine the complexity of maximising fitness via local search on valued\nconstraint satisfaction problems (VCSPs). We consider two kinds of local\nascents: (1) steepest ascents, where each step changes the domain that produces\na maximal increase in fitness; and (2) $\\prec$-ordered ascents, where -- of the\ndomains with available fitness increasing changes -- each step changes the\n$\\prec$-minimal domain. We provide a general padding argument to simulate any\nordered ascent by a steepest ascent. We construct a VCSP that is a path of\nbinary constraints between alternating 2-state and 3-state domains with\nexponentially long ordered ascents. We apply our padding argument to this VCSP\nto obtain a Boolean VCSP that has a constraint (hyper)graph of arity 5 and\npathwidth 4 with exponential steepest ascents. This is an improvement on the\nprevious best known construction for long steepest ascents, which had arity 8\nand pathwidth 7.",
        "subjects": [
            "cs.DM",
            "cs.DS",
            "q-bio.PE"
        ],
        "authors": [
            "Artem Kaznatcheev",
            "Melle van Marle"
        ],
        "published": "2024-05-21T16:22:06Z"
    },
    {
        "title": "Adversarial DPO: Harnessing Harmful Data for Reducing Toxicity with\n  Minimal Impact on Coherence and Evasiveness in Dialogue Agents",
        "link": "http://arxiv.org/abs/2405.12900v1",
        "abstract": "Recent advancements in open-domain dialogue systems have been propelled by\nthe emergence of high-quality large language models (LLMs) and various\neffective training methodologies. Nevertheless, the presence of toxicity within\nthese models presents a significant challenge that can potentially diminish the\nuser experience. In this study, we introduce an innovative training algorithm,\nan improvement upon direct preference optimization (DPO), called adversarial\nDPO (ADPO). The ADPO algorithm is designed to train models to assign higher\nprobability distributions to preferred responses and lower distributions to\nunsafe responses, which are self-generated using the toxic control token. We\ndemonstrate that ADPO enhances the model's resilience against harmful\nconversations while minimizing performance degradation. Furthermore, we\nillustrate that ADPO offers a more stable training procedure compared to the\ntraditional DPO. To the best of our knowledge, this is the first adaptation of\nthe DPO algorithm that directly incorporates harmful data into the generative\nmodel, thereby reducing the need to artificially create safe dialogue data.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "I.2.7"
        ],
        "authors": [
            "San Kim",
            "Gary Geunbae Lee"
        ],
        "published": "2024-05-21T16:14:55Z"
    },
    {
        "title": "On a time-frequency blurring operator with applications in data\n  augmentation",
        "link": "http://arxiv.org/abs/2405.12899v1",
        "abstract": "Inspired by the success of recent data augmentation methods for signals which\nact on time-frequency representations, we introduce an operator which convolves\nthe short-time Fourier transform of a signal with a specified kernel.\nAnalytical properties including boundedness, compactness and positivity are\ninvestigated from the perspective of time-frequency analysis. A convolutional\nneural network and a vision transformer are trained to classify audio signals\nusing spectrograms with different augmentation setups, including the above\nmentioned time-frequency blurring operator, with results indicating that the\noperator can significantly improve test performance, especially in the\ndata-starved regime.",
        "subjects": [
            "math.FA",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Simon Halvdansson"
        ],
        "published": "2024-05-21T16:14:16Z"
    },
    {
        "title": "Decentralized Federated Learning Over Imperfect Communication Channels",
        "link": "http://arxiv.org/abs/2405.12894v1",
        "abstract": "This paper analyzes the impact of imperfect communication channels on\ndecentralized federated learning (D-FL) and subsequently determines the optimal\nnumber of local aggregations per training round, adapting to the network\ntopology and imperfect channels. We start by deriving the bias of locally\naggregated D-FL models under imperfect channels from the ideal global models\nrequiring perfect channels and aggregations. The bias reveals that excessive\nlocal aggregations can accumulate communication errors and degrade convergence.\nAnother important aspect is that we analyze a convergence upper bound of D-FL\nbased on the bias. By minimizing the bound, the optimal number of local\naggregations is identified to balance a trade-off with accumulation of\ncommunication errors in the absence of knowledge of the channels. With this\nknowledge, the impact of communication errors can be alleviated, allowing the\nconvergence upper bound to decrease throughout aggregations. Experiments\nvalidate our convergence analysis and also identify the optimal number of local\naggregations on two widely considered image classification tasks. It is seen\nthat D-FL, with an optimal number of local aggregations, can outperform its\npotential alternatives by over 10% in training accuracy.",
        "subjects": [
            "cs.DC",
            "cs.IT",
            "cs.LG",
            "math.IT"
        ],
        "authors": [
            "Weicai Li",
            "Tiejun Lv",
            "Wei Ni",
            "Jingbo Zhao",
            "Ekram Hossain",
            "H. Vincent Poor"
        ],
        "published": "2024-05-21T16:04:32Z"
    },
    {
        "title": "Implicit-ARAP: Efficient Handle-Guided Deformation of High-Resolution\n  Meshes and Neural Fields via Local Patch Meshing",
        "link": "http://arxiv.org/abs/2405.12895v1",
        "abstract": "In this work, we present the local patch mesh representation for neural\nsigned distance fields. This technique allows to discretize local regions of\nthe level sets of an input SDF by projecting and deforming flat patch meshes\nonto the level set surface, using exclusively the SDF information and its\ngradient. Our analysis reveals this method to be more accurate than the\nstandard marching cubes algorithm for approximating the implicit surface. Then,\nwe apply this representation in the setting of handle-guided deformation: we\nintroduce two distinct pipelines, which make use of 3D neural fields to compute\nAs-Rigid-As-Possible deformations of both high-resolution meshes and neural\nfields under a given set of constraints. We run a comprehensive evaluation of\nour method and various baselines for neural field and mesh deformation which\nshow both pipelines achieve impressive efficiency and notable improvements in\nterms of quality of results and robustness. With our novel pipeline, we\nintroduce a scalable approach to solve a well-established geometry processing\nproblem on high-resolution meshes, and pave the way for extending other\ngeometric tasks to the domain of implicit surfaces via local patch meshing.",
        "subjects": [
            "cs.GR",
            "cs.CV",
            "68U05",
            "I.3.5; I.2.6"
        ],
        "authors": [
            "Daniele Baieri",
            "Filippo Maggioli",
            "Zorah Lähner",
            "Simone Melzi",
            "Emanuele Rodolà"
        ],
        "published": "2024-05-21T16:04:32Z"
    },
    {
        "title": "Better Simulations for Validating Causal Discovery with the\n  DAG-Adaptation of the Onion Method",
        "link": "http://arxiv.org/abs/2405.13100v1",
        "abstract": "The number of artificial intelligence algorithms for learning causal models\nfrom data is growing rapidly. Most ``causal discovery'' or ``causal structure\nlearning'' algorithms are primarily validated through simulation studies.\nHowever, no widely accepted simulation standards exist and publications often\nreport conflicting performance statistics -- even when only considering\npublications that simulate data from linear models. In response, several\nmanuscripts have criticized a popular simulation design for validating\nalgorithms in the linear case.\n  We propose a new simulation design for generating linear models for directed\nacyclic graphs (DAGs): the DAG-adaptation of the Onion (DaO) method. DaO\nsimulations are fundamentally different from existing simulations because they\nprioritize the distribution of correlation matrices rather than the\ndistribution of linear effects. Specifically, the DaO method uniformly samples\nthe space of all correlation matrices consistent with (i.e. Markov to) a DAG.\nWe also discuss how to sample DAGs and present methods for generating DAGs with\nscale-free in-degree or out-degree. We compare the DaO method against two\nalternative simulation designs and provide implementations of the DaO method in\nPython and R: https://github.com/bja43/DaO_simulation. We advocate for others\nto adopt DaO simulations as a fair universal benchmark.",
        "subjects": [
            "stat.ME",
            "cs.AI"
        ],
        "authors": [
            "Bryan Andrews",
            "Erich Kummerfeld"
        ],
        "published": "2024-05-21T16:04:25Z"
    },
    {
        "title": "Retrievable Domain-Sensitive Feature Memory for Multi-Domain\n  Recommendation",
        "link": "http://arxiv.org/abs/2405.12892v1",
        "abstract": "With the increase in the business scale and number of domains in online\nadvertising, multi-domain ad recommendation has become a mainstream solution in\nthe industry. The core of multi-domain recommendation is effectively modeling\nthe commonalities and distinctions among domains. Existing works are dedicated\nto designing model architectures for implicit multi-domain modeling while\noverlooking an in-depth investigation from a more fundamental perspective of\nfeature distributions. This paper focuses on features with significant\ndifferences across various domains in both distributions and effects on model\npredictions. We refer to these features as domain-sensitive features, which\nserve as carriers of domain distinctions and are crucial for multi-domain\nmodeling. Experiments demonstrate that existing multi-domain modeling methods\nmay neglect domain-sensitive features, indicating insufficient learning of\ndomain distinctions. To avoid this neglect, we propose a domain-sensitive\nfeature attribution method to identify features that best reflect domain\ndistinctions from the feature set. Further, we design a memory architecture\nthat extracts domain-specific information from domain-sensitive features for\nthe model to retrieve and integrate, thereby enhancing the awareness of domain\ndistinctions. Extensive offline and online experiments demonstrate the\nsuperiority of our method in capturing domain distinctions and improving\nmulti-domain recommendation performance.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "authors": [
            "Yuang Zhao",
            "Zhaocheng Du",
            "Qinglin Jia",
            "Linxuan Zhang",
            "Zhenhua Dong",
            "Ruiming Tang"
        ],
        "published": "2024-05-21T16:02:06Z"
    },
    {
        "title": "DARK: Denoising, Amplification, Restoration Kit",
        "link": "http://arxiv.org/abs/2405.12891v1",
        "abstract": "This paper introduces a novel lightweight computational framework for\nenhancing images under low-light conditions, utilizing advanced machine\nlearning and convolutional neural networks (CNNs). Traditional enhancement\ntechniques often fail to adequately address issues like noise, color\ndistortion, and detail loss in challenging lighting environments. Our approach\nleverages insights from the Retinex theory and recent advances in image\nrestoration networks to develop a streamlined model that efficiently processes\nillumination components and integrates context-sensitive enhancements through\noptimized convolutional blocks. This results in significantly improved image\nclarity and color fidelity, while avoiding over-enhancement and unnatural color\nshifts. Crucially, our model is designed to be lightweight, ensuring low\ncomputational demand and suitability for real-time applications on standard\nconsumer hardware. Performance evaluations confirm that our model not only\nsurpasses existing methods in enhancing low-light images but also maintains a\nminimal computational footprint.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhuoheng Li",
            "Yuheng Pan",
            "Houcheng Yu",
            "Zhiheng Zhang"
        ],
        "published": "2024-05-21T16:01:13Z"
    },
    {
        "title": "Keep the Momentum: Conservation Laws beyond Euclidean Gradient Flows",
        "link": "http://arxiv.org/abs/2405.12888v1",
        "abstract": "Conservation laws are well-established in the context of Euclidean gradient\nflow dynamics, notably for linear or ReLU neural network training. Yet, their\nexistence and principles for non-Euclidean geometries and momentum-based\ndynamics remain largely unknown. In this paper, we characterize \"all\"\nconservation laws in this general setting. In stark contrast to the case of\ngradient flows, we prove that the conservation laws for momentum-based dynamics\nexhibit temporal dependence. Additionally, we often observe a \"conservation\nloss\" when transitioning from gradient flow to momentum dynamics. Specifically,\nfor linear networks, our framework allows us to identify all momentum\nconservation laws, which are less numerous than in the gradient flow case\nexcept in sufficiently over-parameterized regimes. With ReLU networks, no\nconservation law remains. This phenomenon also manifests in non-Euclidean\nmetrics, used e.g. for Nonnegative Matrix Factorization (NMF): all conservation\nlaws can be determined in the gradient flow context, yet none persists in the\nmomentum case.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Sibylle Marcotte",
            "Rémi Gribonval",
            "Gabriel Peyré"
        ],
        "published": "2024-05-21T15:59:55Z"
    },
    {
        "title": "The Recovery of $λ$ from a Hilbert Polynomial",
        "link": "http://arxiv.org/abs/2405.12886v1",
        "abstract": "In the study of Hilbert schemes, the integer partition $\\lambda$ helps\nresearchers identify some geometric and combinatorial properties of the scheme\nin question. To aid researchers in extracting such information from a Hilbert\npolynomial, we describe an efficient algorithm which can identify if\n$p(x)\\in\\mathbb{Q}[x]$ is a Hilbert polynomial and if so, recover the integer\npartition $\\lambda$ associated with it.",
        "subjects": [
            "cs.SC"
        ],
        "authors": [
            "Joseph Donato",
            "Monica Lewis"
        ],
        "published": "2024-05-21T15:55:34Z"
    },
    {
        "title": "Investigating Persuasion Techniques in Arabic: An Empirical Study\n  Leveraging Large Language Models",
        "link": "http://arxiv.org/abs/2405.12884v1",
        "abstract": "In the current era of digital communication and widespread use of social\nmedia, it is crucial to develop an understanding of persuasive techniques\nemployed in written text. This knowledge is essential for effectively\ndiscerning accurate information and making informed decisions. To address this\nneed, this paper presents a comprehensive empirical study focused on\nidentifying persuasive techniques in Arabic social media content. To achieve\nthis objective, we utilize Pre-trained Language Models (PLMs) and leverage the\nArAlEval dataset, which encompasses two tasks: binary classification to\ndetermine the presence or absence of persuasion techniques, and multi-label\nclassification to identify the specific types of techniques employed in the\ntext. Our study explores three different learning approaches by harnessing the\npower of PLMs: feature extraction, fine-tuning, and prompt engineering\ntechniques. Through extensive experimentation, we find that the fine-tuning\napproach yields the highest results on the aforementioned dataset, achieving an\nf1-micro score of 0.865 and an f1-weighted score of 0.861. Furthermore, our\nanalysis sheds light on an interesting finding. While the performance of the\nGPT model is relatively lower compared to the other approaches, we have\nobserved that by employing few-shot learning techniques, we can enhance its\nresults by up to 20\\%. This offers promising directions for future research and\nexploration in this topic\\footnote{Upon Acceptance, the source code will be\nreleased on GitHub.}.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Abdurahmman Alzahrani",
            "Eyad Babkier",
            "Faisal Yanbaawi",
            "Firas Yanbaawi",
            "Hassan Alhuzali"
        ],
        "published": "2024-05-21T15:55:09Z"
    },
    {
        "title": "Centralized vs Decentralized Monitors for Hyperproperties",
        "link": "http://arxiv.org/abs/2405.12882v1",
        "abstract": "This paper focuses on the runtime verification of hyperproperties expressed\nin HypermuHML, an expressive yet simple logic for describing properties of sets\nof traces. To this end, we first consider a simple language of monitors that\ncan observe sets of system executions and report verdicts w.r.t. a given\nHypermuHML formula. In this setting, a unique omniscient monitor observes all\nsystem traces, and, in this sense, it is 'centralized'. However, in a possibly\ndistributed system, having a centralized entity is undesirable; hence, we also\nprovide a language for 'decentralized' monitors, where each trace has its own\nmonitor, and monitors for different traces can yield a unique verdict by\ncommunicating their observations. For both the centralized and the\ndecentralized settings, we provide a synthesis procedure that, given a formula,\nyields a monitor that is correct (i.e., sound and violation complete). A key\nstep in proving the correctness of the synthesis for decentralized monitors is\na result showing that, for each formula, the synthesized centralized monitor\nand its corresponding decentralized one are weakly bisimilar for a suitable\nnotion of weak bisimulation.",
        "subjects": [
            "cs.LO",
            "F.3.1"
        ],
        "authors": [
            "Luca Aceto",
            "Antonis Achilleos",
            "Elli Anastasiadi",
            "Adrian Francalanza",
            "Daniele Gorla",
            "Jana Wagemaker"
        ],
        "published": "2024-05-21T15:54:03Z"
    },
    {
        "title": "Explaining Expert Search and Team Formation Systems with ExES",
        "link": "http://arxiv.org/abs/2405.12881v1",
        "abstract": "Expert search and team formation systems operate on collaboration networks,\nwith nodes representing individuals, labeled with their skills, and edges\ndenoting collaboration relationships. Given a keyword query corresponding to\nthe desired skills, these systems identify experts that best match the query.\nHowever, state-of-the-art solutions to this problem lack transparency. To\naddress this issue, we propose ExES, a tool designed to explain expert search\nand team formation systems using factual and counterfactual methods from the\nfield of explainable artificial intelligence (XAI). ExES uses factual\nexplanations to highlight important skills and collaborations, and\ncounterfactual explanations to suggest new skills and collaborations to\nincrease the likelihood of being identified as an expert. Towards a practical\ndeployment as an interactive explanation tool, we present and experimentally\nevaluate a suite of pruning strategies to speed up the explanation search. In\nmany cases, our pruning strategies make ExES an order of magnitude faster than\nexhaustive search, while still producing concise and actionable explanations.",
        "subjects": [
            "cs.DB",
            "cs.AI"
        ],
        "authors": [
            "Kiarash Golzadeh",
            "Lukasz Golab",
            "Jaroslaw Szlichta"
        ],
        "published": "2024-05-21T15:53:35Z"
    },
    {
        "title": "Approximating TSP Variants Using a Bridge Lemma",
        "link": "http://arxiv.org/abs/2405.12876v1",
        "abstract": "We give improved approximations for two metric \\textsc{Traveling Salesman\nProblem} (TSP) variants. In \\textsc{Ordered TSP} (OTSP) we are given a linear\nordering on a subset of nodes $o_1, \\ldots, o_k$. The TSP solution must have\nthat $o_{i+1}$ is visited at some point after $o_i$ for each $1 \\leq i < k$.\nThis is the special case of \\textsc{Precedence-Constrained TSP} ($PTSP$) in\nwhich the precedence constraints are given by a single chain on a subset of\nnodes. In \\textsc{$k$-Person TSP Path} (k-TSPP), we are given pairs of nodes\n$(s_1,t_1), \\ldots, (s_k,t_k)$. The goal is to find an $s_i$-$t_i$ path with\nminimum total cost such that every node is visited by at least one path.\n  We obtain a $3/2 + e^{-1} < 1.878$ approximation for OTSP, the first\nimprovement over a trivial $\\alpha+1$ approximation where $\\alpha$ is the\ncurrent best TSP approximation. We also obtain a $1 + 2 \\cdot e^{-1/2} < 2.214$\napproximation for k-TSPP, the first improvement over a trivial\n$3$-approximation.\n  These algorithms both use an adaptation of the Bridge Lemma that was\ninitially used to obtain improved \\textsc{Steiner Tree} approximations [Byrka\net al., 2013]. Roughly speaking, our variant states that the cost of a cheapest\nforest rooted at a given set of terminal nodes will decrease by a substantial\namount if we randomly sample a set of non-terminal nodes to also become\nterminals such provided each non-terminal has a constant probability of being\nsampled. We believe this view of the Bridge Lemma will find further use for\nimproved vehicle routing approximations beyond this paper.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Martin Böhm",
            "Zachary Friggstad",
            "Tobias Mömke",
            "Joachim Spoerhase"
        ],
        "published": "2024-05-21T15:46:13Z"
    },
    {
        "title": "Diffusion-RSCC: Diffusion Probabilistic Model for Change Captioning in\n  Remote Sensing Images",
        "link": "http://arxiv.org/abs/2405.12875v1",
        "abstract": "Remote sensing image change captioning (RSICC) aims at generating human-like\nlanguage to describe the semantic changes between bi-temporal remote sensing\nimage pairs. It provides valuable insights into environmental dynamics and land\nmanagement. Unlike conventional change captioning task, RSICC involves not only\nretrieving relevant information across different modalities and generating\nfluent captions, but also mitigating the impact of pixel-level differences on\nterrain change localization. The pixel problem due to long time span decreases\nthe accuracy of generated caption. Inspired by the remarkable generative power\nof diffusion model, we propose a probabilistic diffusion model for RSICC to\nsolve the aforementioned problems. In training process, we construct a noise\npredictor conditioned on cross modal features to learn the distribution from\nthe real caption distribution to the standard Gaussian distribution under the\nMarkov chain. Meanwhile, a cross-mode fusion and a stacking self-attention\nmodule are designed for noise predictor in the reverse process. In testing\nphase, the well-trained noise predictor helps to estimate the mean value of the\ndistribution and generate change captions step by step. Extensive experiments\non the LEVIR-CC dataset demonstrate the effectiveness of our Diffusion-RSCC and\nits individual components. The quantitative results showcase superior\nperformance over existing methods across both traditional and newly augmented\nmetrics. The code and materials will be available online at\nhttps://github.com/Fay-Y/Diffusion-RSCC.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "authors": [
            "Xiaofei Yu",
            "Yitong Li",
            "Jie Ma"
        ],
        "published": "2024-05-21T15:44:31Z"
    },
    {
        "title": "Spatial-aware Attention Generative Adversarial Network for\n  Semi-supervised Anomaly Detection in Medical Image",
        "link": "http://arxiv.org/abs/2405.12872v1",
        "abstract": "Medical anomaly detection is a critical research area aimed at recognizing\nabnormal images to aid in diagnosis.Most existing methods adopt synthetic\nanomalies and image restoration on normal samples to detect anomaly. The\nunlabeled data consisting of both normal and abnormal data is not well\nexplored. We introduce a novel Spatial-aware Attention Generative Adversarial\nNetwork (SAGAN) for one-class semi-supervised generation of health images.Our\ncore insight is the utilization of position encoding and attention to\naccurately focus on restoring abnormal regions and preserving normal regions.\nTo fully utilize the unlabelled data, SAGAN relaxes the cyclic consistency\nrequirement of the existing unpaired image-to-image conversion methods, and\ngenerates high-quality health images corresponding to unlabeled data, guided by\nthe reconstruction of normal images and restoration of pseudo-anomaly\nimages.Subsequently, the discrepancy between the generated healthy image and\nthe original image is utilized as an anomaly score.Extensive experiments on\nthree medical datasets demonstrate that the proposed SAGAN outperforms the\nstate-of-the-art methods.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Zerui Zhang",
            "Zhichao Sun",
            "Zelong Liu",
            "Bo Du",
            "Rui Yu",
            "Zhou Zhao",
            "Yongchao Xu"
        ],
        "published": "2024-05-21T15:41:34Z"
    },
    {
        "title": "Efficient Influence Minimization via Node Blocking",
        "link": "http://arxiv.org/abs/2405.12871v1",
        "abstract": "Given a graph G, a budget k and a misinformation seed set S, Influence\nMinimization (IMIN) via node blocking aims to find a set of k nodes to be\nblocked such that the expected spread of S is minimized. This problem finds\nimportant applications in suppressing the spread of misinformation and has been\nextensively studied in the literature. However, existing solutions for IMIN\nstill incur significant computation overhead, especially when k becomes large.\nIn addition, there is still no approximation solution with non-trivial\ntheoretical guarantee for IMIN via node blocking prior to our work. In this\npaper, we conduct the first attempt to propose algorithms that yield\ndata-dependent approximation guarantees. Based on the Sandwich framework, we\nfirst develop submodular and monotonic lower and upper bounds for our\nnon-submodular objective function and prove the computation of proposed bounds\nis \\#P-hard. In addition, two advanced sampling methods are proposed to\nestimate the value of bounding functions. Moreover, we develop two novel\nmartingale-based concentration bounds to reduce the sample complexity and\ndesign two non-trivial algorithms that provide (1-1/e-\\epsilon)-approximate\nsolutions to our bounding functions. Comprehensive experiments on 9 real-world\ndatasets are conducted to validate the efficiency and effectiveness of the\nproposed techniques. Compared with the state-of-the-art methods, our solutions\ncan achieve up to two orders of magnitude speedup and provide theoretical\nguarantees for the quality of returned results.",
        "subjects": [
            "cs.DB"
        ],
        "authors": [
            "Jinghao Wang",
            "Yanping Wu",
            "Xiaoyang Wang",
            "Ying Zhang",
            "Lu Qin",
            "Wenjie Zhang",
            "Xuemin Lin"
        ],
        "published": "2024-05-21T15:39:11Z"
    },
    {
        "title": "Equivariant Spatio-Temporal Attentive Graph Networks to Simulate\n  Physical Dynamics",
        "link": "http://arxiv.org/abs/2405.12868v1",
        "abstract": "Learning to represent and simulate the dynamics of physical systems is a\ncrucial yet challenging task. Existing equivariant Graph Neural Network (GNN)\nbased methods have encapsulated the symmetry of physics, \\emph{e.g.},\ntranslations, rotations, etc, leading to better generalization ability.\nNevertheless, their frame-to-frame formulation of the task overlooks the\nnon-Markov property mainly incurred by unobserved dynamics in the environment.\nIn this paper, we reformulate dynamics simulation as a spatio-temporal\nprediction task, by employing the trajectory in the past period to recover the\nNon-Markovian interactions. We propose Equivariant Spatio-Temporal Attentive\nGraph Networks (ESTAG), an equivariant version of spatio-temporal GNNs, to\nfulfill our purpose. At its core, we design a novel Equivariant Discrete\nFourier Transform (EDFT) to extract periodic patterns from the history frames,\nand then construct an Equivariant Spatial Module (ESM) to accomplish spatial\nmessage passing, and an Equivariant Temporal Module (ETM) with the forward\nattention and equivariant pooling mechanisms to aggregate temporal message. We\nevaluate our model on three real datasets corresponding to the molecular-,\nprotein- and macro-level. Experimental results verify the effectiveness of\nESTAG compared to typical spatio-temporal GNNs and equivariant GNNs.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Liming Wu",
            "Zhichao Hou",
            "Jirui Yuan",
            "Yu Rong",
            "Wenbing Huang"
        ],
        "published": "2024-05-21T15:33:21Z"
    },
    {
        "title": "Transparency Distortion Robustness for SOTA Image Segmentation Tasks",
        "link": "http://arxiv.org/abs/2405.12864v1",
        "abstract": "Semantic Image Segmentation facilitates a multitude of real-world\napplications ranging from autonomous driving over industrial process\nsupervision to vision aids for human beings. These models are usually trained\nin a supervised fashion using example inputs. Distribution Shifts between these\nexamples and the inputs in operation may cause erroneous segmentations. The\nrobustness of semantic segmentation models against distribution shifts caused\nby differing camera or lighting setups, lens distortions, adversarial inputs\nand image corruptions has been topic of recent research. However, robustness\nagainst spatially varying radial distortion effects that can be caused by\nuneven glass structures (e.g. windows) or the chaotic refraction in heated air\nhas not been addressed by the research community yet. We propose a method to\nsynthetically augment existing datasets with spatially varying distortions. Our\nexperiments show, that these distortion effects degrade the performance of\nstate-of-the-art segmentation models. Pretraining and enlarged model capacities\nproof to be suitable strategies for mitigating performance degradation to some\ndegree, while fine-tuning on distorted images only leads to marginal\nperformance improvements.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Volker Knauthe",
            "Arne Rak",
            "Tristan Wirth",
            "Thomas Pöllabauer",
            "Simon Metzler",
            "Arjan Kuijper",
            "Dieter W. Fellner"
        ],
        "published": "2024-05-21T15:30:25Z"
    },
    {
        "title": "Robust portfolio optimization model for electronic coupon allocation",
        "link": "http://arxiv.org/abs/2405.12865v1",
        "abstract": "Currently, many e-commerce websites issue online/electronic coupons as an\neffective tool for promoting sales of various products and services. We focus\non the problem of optimally allocating coupons to customers subject to a budget\nconstraint on an e-commerce website. We apply a robust portfolio optimization\nmodel based on customer segmentation to the coupon allocation problem. We also\nvalidate the efficacy of our method through numerical experiments using actual\ndata from randomly distributed coupons. Main contributions of our research are\ntwofold. First, we handle six types of coupons, thereby making it extremely\ndifficult to accurately estimate the difference in the effects of various\ncoupons. Second, we demonstrate from detailed numerical results that the robust\noptimization model achieved larger uplifts of sales than did the commonly-used\nmultiple-choice knapsack model and the conventional mean-variance optimization\nmodel. Our results open up great potential for robust portfolio optimization as\nan effective tool for practical coupon allocation.",
        "subjects": [
            "cs.IR",
            "math.OC",
            "90B60, 90C05"
        ],
        "authors": [
            "Yuki Uehara",
            "Naoki Nishimura",
            "Yilin Li",
            "Jie Yang",
            "Deddy Jobson",
            "Koya Ohashi",
            "Takeshi Matsumoto",
            "Noriyoshi Sukegawa",
            "Yuichi Takano"
        ],
        "published": "2024-05-21T15:30:25Z"
    },
    {
        "title": "Toward Constraint Compliant Goal Formulation and Planning",
        "link": "http://arxiv.org/abs/2405.12862v1",
        "abstract": "One part of complying with norms, rules, and preferences is incorporating\nconstraints (such as knowledge of ethics) into one's goal formulation and\nplanning processing. We explore in a simple domain how the encoding of\nknowledge in different ethical frameworks influences an agent's goal\nformulation and planning processing and demonstrate ability of an agent to\nsatisfy and satisfice when its collection of relevant constraints includes a\nmix of \"hard\" and \"soft\" constraints of various types. How the agent attempts\nto comply with ethical constraints depends on the ethical framing and we\ninvestigate tradeoffs between deontological framing and utilitarian framing for\ncomplying with an ethical norm. Representative scenarios highlight how\nperforming the same task with different framings of the same norm leads to\ndifferent behaviors. Our explorations suggest an important role for\nmetacognitive judgments in resolving ethical conflicts during goal formulation\nand planning.",
        "subjects": [
            "cs.AI",
            "I.2.11; I.2.8"
        ],
        "authors": [
            "Steven J. Jones Robert E. Wray"
        ],
        "published": "2024-05-21T15:26:06Z"
    },
    {
        "title": "Influence of Water Droplet Contamination for Transparency Segmentation",
        "link": "http://arxiv.org/abs/2405.12861v1",
        "abstract": "Computer vision techniques are on the rise for industrial applications, like\nprocess supervision and autonomous agents, e.g., in the healthcare domain and\ndangerous environments. While the general usability of these techniques is\nhigh, there are still challenging real-world use-cases. Especially transparent\nstructures, which can appear in the form of glass doors, protective casings or\neveryday objects like glasses, pose a challenge for computer vision methods.\nThis paper evaluates the combination of transparent objects in conjunction with\n(naturally occurring) contamination through environmental effects like hazing.\nWe introduce a novel publicly available dataset containing 489 images\nincorporating three grades of water droplet contamination on transparent\nstructures and examine the resulting influence on transparency handling. Our\nfindings show, that contaminated transparent objects are easier to segment and\nthat we are able to distinguish between different severity levels of\ncontamination with a current state-of-the art machine-learning model. This in\nturn opens up the possibility to enhance computer vision systems regarding\nresilience against, e.g., datashifts through contaminated protection casings or\nimplement an automated cleaning alert.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Volker Knauthe",
            "Paul Weitz",
            "Thomas Pöllabauer",
            "Tristan Wirth",
            "Arne Rak",
            "Arjan Kuijper",
            "Dieter W. Fellner"
        ],
        "published": "2024-05-21T15:24:37Z"
    },
    {
        "title": "The Role of Emotions in Informational Support Question-Response Pairs in\n  Online Health Communities: A Multimodal Deep Learning Approach",
        "link": "http://arxiv.org/abs/2405.13099v1",
        "abstract": "This study explores the relationship between informational support seeking\nquestions, responses, and helpfulness ratings in online health communities. We\ncreated a labeled data set of question-response pairs and developed multimodal\nmachine learning and deep learning models to reliably predict informational\nsupport questions and responses. We employed explainable AI to reveal the\nemotions embedded in informational support exchanges, demonstrating the\nimportance of emotion in providing informational support. This complex\ninterplay between emotional and informational support has not been previously\nresearched. The study refines social support theory and lays the groundwork for\nthe development of user decision aids. Further implications are discussed.",
        "subjects": [
            "cs.AI",
            "cs.SI",
            "H.4.3; I.2.7"
        ],
        "authors": [
            "Mohsen Jozani",
            "Jason A. Williams",
            "Ahmed Aleroud",
            "Sarbottam Bhagat"
        ],
        "published": "2024-05-21T15:15:08Z"
    },
    {
        "title": "LLM Processes: Numerical Predictive Distributions Conditioned on Natural\n  Language",
        "link": "http://arxiv.org/abs/2405.12856v1",
        "abstract": "Machine learning practitioners often face significant challenges in formally\nintegrating their prior knowledge and beliefs into predictive models, limiting\nthe potential for nuanced and context-aware analyses. Moreover, the expertise\nneeded to integrate this prior knowledge into probabilistic modeling typically\nlimits the application of these models to specialists. Our goal is to build a\nregression model that can process numerical data and make probabilistic\npredictions at arbitrary locations, guided by natural language text which\ndescribes a user's prior knowledge. Large Language Models (LLMs) provide a\nuseful starting point for designing such a tool since they 1) provide an\ninterface where users can incorporate expert insights in natural language and\n2) provide an opportunity for leveraging latent problem-relevant knowledge\nencoded in LLMs that users may not have themselves. We start by exploring\nstrategies for eliciting explicit, coherent numerical predictive distributions\nfrom LLMs. We examine these joint predictive distributions, which we call LLM\nProcesses, over arbitrarily-many quantities in settings such as forecasting,\nmulti-dimensional regression, black-box optimization, and image modeling. We\ninvestigate the practical details of prompting to elicit coherent predictive\ndistributions, and demonstrate their effectiveness at regression. Finally, we\ndemonstrate the ability to usefully incorporate text into numerical\npredictions, improving predictive performance and giving quantitative structure\nthat reflects qualitative descriptions. This lets us begin to explore the rich,\ngrounded hypothesis space that LLMs implicitly encode.",
        "subjects": [
            "stat.ML",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "James Requeima",
            "John Bronskill",
            "Dami Choi",
            "Richard E. Turner",
            "David Duvenaud"
        ],
        "published": "2024-05-21T15:13:12Z"
    },
    {
        "title": "Inconsistency-Aware Cross-Attention for Audio-Visual Fusion in\n  Dimensional Emotion Recognition",
        "link": "http://arxiv.org/abs/2405.12853v1",
        "abstract": "Leveraging complementary relationships across modalities has recently drawn a\nlot of attention in multimodal emotion recognition. Most of the existing\napproaches explored cross-attention to capture the complementary relationships\nacross the modalities. However, the modalities may also exhibit weak\ncomplementary relationships, which may deteriorate the cross-attended features,\nresulting in poor multimodal feature representations. To address this problem,\nwe propose Inconsistency-Aware Cross-Attention (IACA), which can adaptively\nselect the most relevant features on-the-fly based on the strong or weak\ncomplementary relationships across audio and visual modalities. Specifically,\nwe design a two-stage gating mechanism that can adaptively select the\nappropriate relevant features to deal with weak complementary relationships.\nExtensive experiments are conducted on the challenging Aff-Wild2 dataset to\nshow the robustness of the proposed model.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "R Gnana Praveen",
            "Jahangir Alam"
        ],
        "published": "2024-05-21T15:11:35Z"
    },
    {
        "title": "Application Layer Cyber Deception without Developer Interaction",
        "link": "http://arxiv.org/abs/2405.12852v1",
        "abstract": "Cyber deception techniques that are tightly intertwined with applications\npose significant technical challenges in production systems. Security measures\nare usually the responsibility of a system operator, but they are typically\nlimited to accessing built software artifacts, not their source code. This\nlimitation makes it particularly challenging to deploy cyber deception\ntechniques at application runtime and without full control over the software\ndevelopment lifecycle. This work reviews 19 technical methods to accomplish\nthis and evaluates them based on technical, topological, operational, and\nefficacy properties. We find some novel techniques beyond honeypots and reverse\nproxies that seem to have received little research interest despite their\npromise for cyber deception. We believe that overcoming these technical\nchallenges can drive the adoption of more dynamic and personalized cyber\ndeception techniques, tailored to specific classes of applications.",
        "subjects": [
            "cs.CR",
            "cs.DC",
            "cs.NI",
            "cs.SE"
        ],
        "authors": [
            "Mario Kahlhofer",
            "Stefan Rass"
        ],
        "published": "2024-05-21T15:11:11Z"
    },
    {
        "title": "Weakly supervised alignment and registration of MR-CT for cervical\n  cancer radiotherapy",
        "link": "http://arxiv.org/abs/2405.12850v1",
        "abstract": "Cervical cancer is one of the leading causes of death in women, and\nbrachytherapy is currently the primary treatment method. However, it is\nimportant to precisely define the extent of paracervical tissue invasion to\nimprove cancer diagnosis and treatment options. The fusion of the information\ncharacteristics of both computed tomography (CT) and magnetic resonance\nimaging(MRI) modalities may be useful in achieving a precise outline of the\nextent of paracervical tissue invasion. Registration is the initial step in\ninformation fusion. However, when aligning multimodal images with varying\ndepths, manual alignment is prone to large errors and is time-consuming.\nFurthermore, the variations in the size of the Region of Interest (ROI) and the\nshape of multimodal images pose a significant challenge for achieving accurate\nregistration.In this paper, we propose a preliminary spatial alignment\nalgorithm and a weakly supervised multimodal registration network. The spatial\nposition alignment algorithm efficiently utilizes the limited annotation\ninformation in the two modal images provided by the doctor to automatically\nalign multimodal images with varying depths. By utilizing aligned multimodal\nimages for weakly supervised registration and incorporating pyramidal features\nand cost volume to estimate the optical flow, the results indicate that the\nproposed method outperforms traditional volume rendering alignment methods and\nregistration networks in various evaluation metrics. This demonstrates the\neffectiveness of our model in multimodal image registration.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jjahao Zhang",
            "Yin Gu",
            "Deyu Sun",
            "Yuhua Gao",
            "Ming Gao",
            "Ming Cui",
            "Teng Zhang",
            "He Ma"
        ],
        "published": "2024-05-21T15:05:51Z"
    },
    {
        "title": "Training and inference in the ReckON RSNN architecture implemented on a\n  MPSoC",
        "link": "http://arxiv.org/abs/2405.12849v1",
        "abstract": "With the rise of artificial intelligence, biological neuron models are being\nused to implement neural networks that can learn certain tasks after a training\nphase. One type of such networks are spiking neural networks (SNNs) that rely\non a simplified model for biological neurons, the Integrate and Fire neuron.\nSeveral accelerators have emerged to implement SNNs with this kind of neuron.\nThe ReckON system is one of these that allows both the training and execution\nof a recurrent SNN. The ReckON architecture, implemented on a custom ASIC, can\nbe fully described using a hardware description language. In this work, we\nadapt the Verilog description to implement it on a Xilinx Multiprocessor System\non Chip system (MPSoC). We present the circuits required for the efficient\noperation of the system, and a Python framework to use it on the Pynq ZU\nplatform. We validate the architecture and implementation in two different\nscenarios, and show how the simulated accuracy is preserved with a peak\nperformance of 3.8M events processed per second.",
        "subjects": [
            "cs.AR",
            "cs.AI"
        ],
        "authors": [
            "Alejandro Linares-Barranco",
            "Luciano Prono",
            "Robert Lengenstein",
            "Giacomo Indiveri",
            "Charlotte Frenkel"
        ],
        "published": "2024-05-21T14:59:39Z"
    },
    {
        "title": "A conservative relaxation Crank-Nicolson finite element method for the\n  Schrödinger-Poisson equation",
        "link": "http://arxiv.org/abs/2405.12848v1",
        "abstract": "In this paper, we propose a novel mass and energy conservative relaxation\nCrank-Nicolson finite element method for the Schr\\\"{o}dinger-Poisson equation.\nUtilizing only a single auxiliary variable, we simultaneously reformulate the\ndistinct nonlinear terms present in both the Schr\\\"{o}dinger equation and the\nPoisson equation into their equivalent expressions, constructing an equivalent\nsystem to the original Schr\\\"{o}dinger-Poisson equation. Our proposed scheme,\nderived from this new system, operates linearly and bypasses the need to solve\nthe nonlinear coupled equation, thus eliminating the requirement for iterative\ntechniques. We in turn rigorously derive error estimates for the proposed\nscheme, demonstrating second-order accuracy in time and $(k+1)$th order\naccuracy in space when employing polynomials of degree up to $k$. Numerical\nexperiments validate the accuracy and effectiveness of our method and emphasize\nits conservation properties over long-time simulations.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "35Q55, 65M15, 65M60"
        ],
        "authors": [
            "Huini Liu",
            "Nianyu Yi",
            "Peimeng Yin"
        ],
        "published": "2024-05-21T14:58:24Z"
    },
    {
        "title": "A Dataset and Baselines for Measuring and Predicting the Music Piece\n  Memorability",
        "link": "http://dx.doi.org/10.5281/zenodo.10265251",
        "abstract": "Nowadays, humans are constantly exposed to music, whether through voluntary\nstreaming services or incidental encounters during commercial breaks. Despite\nthe abundance of music, certain pieces remain more memorable and often gain\ngreater popularity. Inspired by this phenomenon, we focus on measuring and\npredicting music memorability. To achieve this, we collect a new music piece\ndataset with reliable memorability labels using a novel interactive\nexperimental procedure. We then train baselines to predict and analyze music\nmemorability, leveraging both interpretable features and audio mel-spectrograms\nas inputs. To the best of our knowledge, we are the first to explore music\nmemorability using data-driven deep learning-based methods. Through a series of\nexperiments and ablation studies, we demonstrate that while there is room for\nimprovement, predicting music memorability with limited data is possible.\nCertain intrinsic elements, such as higher valence, arousal, and faster tempo,\ncontribute to memorable music. As prediction techniques continue to evolve,\nreal-life applications like music recommendation systems and music style\ntransfer will undoubtedly benefit from this new area of research.",
        "subjects": [
            "cs.IR",
            "cs.LG",
            "cs.MM",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Li-Yang Tseng",
            "Tzu-Ling Lin",
            "Hong-Han Shuai",
            "Jen-Wei Huang",
            "Wen-Whei Chang"
        ],
        "published": "2024-05-21T14:57:04Z"
    },
    {
        "title": "OpenCarbonEval: A Unified Carbon Emission Estimation Framework in\n  Large-Scale AI Models",
        "link": "http://arxiv.org/abs/2405.12843v1",
        "abstract": "In recent years, large-scale auto-regressive models have made significant\nprogress in various tasks, such as text or video generation. However, the\nenvironmental impact of these models has been largely overlooked, with a lack\nof assessment and analysis of their carbon footprint. To address this gap, we\nintroduce OpenCarbonEval, a unified framework for integrating large-scale\nmodels across diverse modalities to predict carbon emissions, which could\nprovide AI service providers and users with a means to estimate emissions\nbeforehand and help mitigate the environmental pressure associated with these\nmodels. In OpenCarbonEval, we propose a dynamic throughput modeling approach\nthat could capture workload and hardware fluctuations in the training process\nfor more precise emissions estimates. Our evaluation results demonstrate that\nOpenCarbonEval can more accurately predict training emissions than previous\nmethods, and can be seamlessly applied to different modal tasks. Specifically,\nwe show that OpenCarbonEval achieves superior performance in predicting carbon\nemissions for both visual models and language models. By promoting sustainable\nAI development and deployment, OpenCarbonEval can help reduce the environmental\nimpact of large-scale models and contribute to a more environmentally\nresponsible future for the AI community.",
        "subjects": [
            "cs.CY",
            "cs.LG"
        ],
        "authors": [
            "Zhaojian Yu",
            "Yinghao Wu",
            "Zhuotao Deng",
            "Yansong Tang",
            "Xiao-Ping Zhang"
        ],
        "published": "2024-05-21T14:50:20Z"
    },
    {
        "title": "SmartFlow: Robotic Process Automation using LLMs",
        "link": "http://arxiv.org/abs/2405.12842v1",
        "abstract": "Robotic Process Automation (RPA) systems face challenges in handling complex\nprocesses and diverse screen layouts that require advanced human-like\ndecision-making capabilities. These systems typically rely on pixel-level\nencoding through drag-and-drop or automation frameworks such as Selenium to\ncreate navigation workflows, rather than visual understanding of screen\nelements. In this context, we present SmartFlow, an AI-based RPA system that\nuses pre-trained large language models (LLMs) coupled with deep-learning based\nimage understanding. Our system can adapt to new scenarios, including changes\nin the user interface and variations in input data, without the need for human\nintervention. SmartFlow uses computer vision and natural language processing to\nperceive visible elements on the graphical user interface (GUI) and convert\nthem into a textual representation. This information is then utilized by LLMs\nto generate a sequence of actions that are executed by a scripting engine to\ncomplete an assigned task. To assess the effectiveness of SmartFlow, we have\ndeveloped a dataset that includes a set of generic enterprise applications with\ndiverse layouts, which we are releasing for research use. Our evaluations on\nthis dataset demonstrate that SmartFlow exhibits robustness across different\nlayouts and applications. SmartFlow can automate a wide range of business\nprocesses such as form filling, customer service, invoice processing, and\nback-office operations. SmartFlow can thus assist organizations in enhancing\nproductivity by automating an even larger fraction of screen-based workflows.\nThe demo-video and dataset are available at\nhttps://smartflow-4c5a0a.webflow.io/.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "authors": [
            "Arushi Jain",
            "Shubham Paliwal",
            "Monika Sharma",
            "Lovekesh Vig",
            "Gautam Shroff"
        ],
        "published": "2024-05-21T14:49:12Z"
    },
    {
        "title": "Unveiling the Power of Intermediate Representations for Static Analysis:\n  A Survey",
        "link": "http://arxiv.org/abs/2405.12841v1",
        "abstract": "Static analysis techniques enhance the security, performance, and reliability\nof programs by analyzing and portraiting program behaviors without the need for\nactual execution. In essence, static analysis takes the Intermediate\nRepresentation (IR) of a target program as input to retrieve essential program\ninformation and understand the program. However, there is a lack of systematic\nanalysis on the benefit of IR for static analysis, besides serving as an\ninformation provider. In general, a modern static analysis framework should\npossess the ability to conduct diverse analyses on different languages,\nproducing reliable results with minimal time consumption, and offering\nextensive customization options. In this survey, we systematically characterize\nthese goals and review the potential solutions from the perspective of IR. It\ncan serve as a manual for learners and practitioners in the static analysis\nfield to better understand IR design. Meanwhile, numerous research\nopportunities are revealed for researchers.",
        "subjects": [
            "cs.PL",
            "cs.SE"
        ],
        "authors": [
            "Bowen Zhang",
            "Wei Chen",
            "Hung-Chun Chiu",
            "Charles Zhang"
        ],
        "published": "2024-05-21T14:46:55Z"
    },
    {
        "title": "GotFunding: A grant recommendation system based on scientific articles",
        "link": "http://dx.doi.org/10.1002/pra2.323",
        "abstract": "Obtaining funding is an important part of becoming a successful scientist.\nJunior faculty spend a great deal of time finding the right agencies and\nprograms that best match their research profile. But what are the factors that\ninfluence the best publication--grant matching? Some universities might employ\npre-award personnel to understand these factors, but not all institutions can\nafford to hire them. Historical records of publications funded by grants can\nhelp us understand the matching process and also help us develop recommendation\nsystems to automate it. In this work, we present \\textsc{GotFunding} (Grant\nrecOmmendaTion based on past FUNDING), a recommendation system trained on\nNational Institutes of Health's (NIH) grant--publication records. Our system\nachieves a high performance (NDCG@1 = 0.945) by casting the problem as learning\nto rank. By analyzing the features that make predictions effective, our results\nshow that the ranking considers most important 1) the year difference between\npublication and grant grant, 2) the amount of information provided in the\npublication, and 3) the relevance of the publication to the grant. We discuss\nfuture improvements of the system and an online tool for scientists to try.",
        "subjects": [
            "cs.IR",
            "cs.DL",
            "cs.LG"
        ],
        "authors": [
            "Tong Zeng",
            "Daniel E. Acuna"
        ],
        "published": "2024-05-21T14:45:34Z"
    },
    {
        "title": "A Survey of Deep Learning-based Radiology Report Generation Using\n  Multimodal Data",
        "link": "http://arxiv.org/abs/2405.12833v1",
        "abstract": "Automatic radiology report generation can alleviate the workload for\nphysicians and minimize regional disparities in medical resources, therefore\nbecoming an important topic in the medical image analysis field. It is a\nchallenging task, as the computational model needs to mimic physicians to\nobtain information from multi-modal input data (i.e., medical images, clinical\ninformation, medical knowledge, etc.), and produce comprehensive and accurate\nreports. Recently, numerous works emerged to address this issue using deep\nlearning-based methods, such as transformers, contrastive learning, and\nknowledge-base construction. This survey summarizes the key techniques\ndeveloped in the most recent works and proposes a general workflow for deep\nlearning-based report generation with five main components, including\nmulti-modality data acquisition, data preparation, feature learning, feature\nfusion/interaction, and report generation. The state-of-the-art methods for\neach of these components are highlighted. Additionally, training strategies,\npublic datasets, evaluation methods, current challenges, and future directions\nin this field are summarized. We have also conducted a quantitative comparison\nbetween different methods under the same experimental setting. This is the most\nup-to-date survey that focuses on multi-modality inputs and data fusion for\nradiology report generation. The aim is to provide comprehensive and rich\ninformation for researchers interested in automatic clinical report generation\nand medical image analysis, especially when using multimodal inputs, and assist\nthem in developing new algorithms to advance the field.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xinyi Wang",
            "Grazziela Figueredo",
            "Ruizhe Li",
            "Wei Emma Zhang",
            "Weitong Chen",
            "Xin Chen"
        ],
        "published": "2024-05-21T14:37:35Z"
    },
    {
        "title": "Wav-KAN: Wavelet Kolmogorov-Arnold Networks",
        "link": "http://arxiv.org/abs/2405.12832v1",
        "abstract": "In this paper , we introduce Wav-KAN, an innovative neural network\narchitecture that leverages the Wavelet Kolmogorov-Arnold Networks (Wav-KAN)\nframework to enhance interpretability and performance. Traditional multilayer\nperceptrons (MLPs) and even recent advancements like Spl-KAN face challenges\nrelated to interpretability, training speed, robustness, computational\nefficiency, and performance. Wav-KAN addresses these limitations by\nincorporating wavelet functions into the Kolmogorov-Arnold network structure,\nenabling the network to capture both high-frequency and low-frequency\ncomponents of the input data efficiently. Wavelet-based approximations employ\northogonal or semi-orthogonal basis and also maintains a balance between\naccurately representing the underlying data structure and avoiding overfitting\nto the noise. Analogous to how water conforms to the shape of its container,\nWav-KAN adapts to the data structure, resulting in enhanced accuracy, faster\ntraining speeds, and increased robustness compared to Spl-KAN and MLPs. Our\nresults highlight the potential of Wav-KAN as a powerful tool for developing\ninterpretable and high-performance neural networks, with applications spanning\nvarious fields. This work sets the stage for further exploration and\nimplementation of Wav-KAN in frameworks such as PyTorch, TensorFlow, and also\nit makes wavelet in KAN in wide-spread usage like nowadays activation functions\nlike ReLU, sigmoid in universal approximation theory (UAT).",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "eess.SP",
            "stat.ML"
        ],
        "authors": [
            "Zavareh Bozorgasl",
            "Hao Chen"
        ],
        "published": "2024-05-21T14:36:16Z"
    },
    {
        "title": "Chordal-NMF with Riemannian Multiplicative Update",
        "link": "http://arxiv.org/abs/2405.12823v2",
        "abstract": "Nonnegative Matrix Factorization (NMF) is the problem of approximating a\ngiven nonnegative matrix M through the conic combination of two nonnegative\nlow-rank matrices W and H. Traditionally NMF is tackled by optimizing a\nspecific objective function evaluating the quality of the approximation. This\nassessment is often done based on the Frobenius norm. In this study, we argue\nthat the Frobenius norm as the \"point-to-point\" distance may not always be\nappropriate. Due to the nonnegative combination resulting in a polyhedral cone,\nthis conic perspective of NMF may not naturally align with conventional\npoint-to-point distance measures. Hence, a ray-to-ray chordal distance is\nproposed as an alternative way of measuring the discrepancy between M and WH.\nThis measure is related to the Euclidean distance on the unit sphere,\nmotivating us to employ nonsmooth manifold optimization approaches.\n  We apply Riemannian optimization technique to solve chordal-NMF by casting it\non a manifold. Unlike existing works on Riemannian optimization that require\nthe manifold to be smooth, the nonnegativity in chordal-NMF is a\nnon-differentiable manifold. We propose a Riemannian Multiplicative Update\n(RMU) that preserves the convergence properties of Riemannian gradient descent\nwithout breaking the smoothness condition on the manifold.\n  We showcase the effectiveness of the Chordal-NMF on synthetic datasets as\nwell as real-world multispectral images.",
        "subjects": [
            "math.OC",
            "cs.NA",
            "math.NA",
            "15A23, 78M50, 49Q99, 90C26, 90C30"
        ],
        "authors": [
            "Flavia Esposito",
            "Andersen Ang"
        ],
        "published": "2024-05-21T14:26:53Z"
    },
    {
        "title": "Talk2Radar: Bridging Natural Language with 4D mmWave Radar for 3D\n  Referring Expression Comprehension",
        "link": "http://arxiv.org/abs/2405.12821v1",
        "abstract": "Embodied perception is essential for intelligent vehicles and robots,\nenabling more natural interaction and task execution. However, these\nadvancements currently embrace vision level, rarely focusing on using 3D\nmodeling sensors, which limits the full understanding of surrounding objects\nwith multi-granular characteristics. Recently, as a promising automotive sensor\nwith affordable cost, 4D Millimeter-Wave radar provides denser point clouds\nthan conventional radar and perceives both semantic and physical\ncharacteristics of objects, thus enhancing the reliability of perception\nsystem. To foster the development of natural language-driven context\nunderstanding in radar scenes for 3D grounding, we construct the first dataset,\nTalk2Radar, which bridges these two modalities for 3D Referring Expression\nComprehension. Talk2Radar contains 8,682 referring prompt samples with 20,558\nreferred objects. Moreover, we propose a novel model, T-RadarNet for 3D REC\nupon point clouds, achieving state-of-the-art performances on Talk2Radar\ndataset compared with counterparts, where Deformable-FPN and Gated Graph Fusion\nare meticulously designed for efficient point cloud feature modeling and\ncross-modal fusion between radar and text features, respectively. Further,\ncomprehensive experiments are conducted to give a deep insight into radar-based\n3D REC. We release our project at https://github.com/GuanRunwei/Talk2Radar.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "authors": [
            "Runwei Guan",
            "Ruixiao Zhang",
            "Ningwei Ouyang",
            "Jianan Liu",
            "Ka Lok Man",
            "Xiaohao Cai",
            "Ming Xu",
            "Jeremy Smith",
            "Eng Gee Lim",
            "Yutao Yue",
            "Hui Xiong"
        ],
        "published": "2024-05-21T14:26:36Z"
    },
    {
        "title": "NieR: Normal-Based Lighting Scene Rendering",
        "link": "http://arxiv.org/abs/2405.13097v1",
        "abstract": "In real-world road scenes, diverse material properties lead to complex light\nreflection phenomena, making accurate color reproduction crucial for enhancing\nthe realism and safety of simulated driving environments. However, existing\nmethods often struggle to capture the full spectrum of lighting effects,\nparticularly in dynamic scenarios where viewpoint changes induce significant\nmaterial color variations. To address this challenge, we introduce NieR\n(Normal-Based Lighting Scene Rendering), a novel framework that takes into\naccount the nuances of light reflection on diverse material surfaces, leading\nto more precise rendering. To simulate the lighting synthesis process, we\npresent the LD (Light Decomposition) module, which captures the lighting\nreflection characteristics on surfaces. Furthermore, to address dynamic\nlighting scenes, we propose the HNGD (Hierarchical Normal Gradient\nDensification) module to overcome the limitations of sparse Gaussian\nrepresentation. Specifically, we dynamically adjust the Gaussian density based\non normal gradients. Experimental evaluations demonstrate that our method\noutperforms state-of-the-art (SOTA) methods in terms of visual quality and\nexhibits significant advantages in performance indicators. Codes are available\nat https://wanghongsheng01.github.io/NieR/.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hongsheng Wang",
            "Yang Wang",
            "Yalan Liu",
            "Fayuan Hu",
            "Shengyu Zhang",
            "Fei Wu",
            "Feng Lin"
        ],
        "published": "2024-05-21T14:24:43Z"
    },
    {
        "title": "Large Language Models Meet NLP: A Survey",
        "link": "http://arxiv.org/abs/2405.12819v1",
        "abstract": "While large language models (LLMs) like ChatGPT have shown impressive\ncapabilities in Natural Language Processing (NLP) tasks, a systematic\ninvestigation of their potential in this field remains largely unexplored. This\nstudy aims to address this gap by exploring the following questions: (1) How\nare LLMs currently applied to NLP tasks in the literature? (2) Have traditional\nNLP tasks already been solved with LLMs? (3) What is the future of the LLMs for\nNLP? To answer these questions, we take the first step to provide a\ncomprehensive overview of LLMs in NLP. Specifically, we first introduce a\nunified taxonomy including (1) parameter-frozen application and (2)\nparameter-tuning application to offer a unified perspective for understanding\nthe current progress of LLMs in NLP. Furthermore, we summarize the new\nfrontiers and the associated challenges, aiming to inspire further\ngroundbreaking advancements. We hope this work offers valuable insights into\nthe {potential and limitations} of LLMs in NLP, while also serving as a\npractical guide for building effective LLMs in NLP.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Libo Qin",
            "Qiguang Chen",
            "Xiachong Feng",
            "Yang Wu",
            "Yongheng Zhang",
            "Yinghui Li",
            "Min Li",
            "Wanxiang Che",
            "Philip S. Yu"
        ],
        "published": "2024-05-21T14:24:01Z"
    },
    {
        "title": "A stable poro-mechanical formulation for Material Point Methods\n  leveraging overlapping meshes and multi-field ghost penalisation",
        "link": "http://arxiv.org/abs/2405.12814v1",
        "abstract": "The Material Point Method (MPM) is widely used to analyse coupled\n(solid-water) problems under large deformations/displacements. However, if not\naddressed carefully, MPM u-p formulations for poro-mechanics can be affected by\ntwo major sources of instability. Firstly, inf-sup condition violation can\narise when the spaces for the displacement and pressure fields are not chosen\ncorrectly, resulting in an unstable pressure field. Secondly, the intrinsic\nnature of particle-based discretisation makes the MPM an unfitted mesh-based\nmethod, which can affect the system's condition number and solvability,\nparticularly when background mesh elements are poorly populated. This work\nproposes a solution to both problems. The inf-sup condition is avoided using\ntwo overlapping meshes, a coarser one for the pressure and a finer one for the\ndisplacement. This approach does not require stabilisation of the primary\nequations since it is stable by design and is particularly valuable for\nlow-order shape functions. As for the system's poor condition number, a face\nghost penalisation method is added to both the primary equations, which\nconstitutes a novelty in the context of MPM mixed formulations. This study\nfrequently makes use of the theories of functional analysis or the unfitted\nFinite Element Method (FEM). Although these theories may not directly apply to\nthe MPM, they provide a robust and logical basis for the research. These\nrationales are further supported by three numerical examples, which encompass\nboth elastic and elasto-plastic cases and drained and undrained conditions.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "physics.comp-ph",
            "65M30"
        ],
        "authors": [
            "Giuliano Pretti",
            "Robert E. Bird",
            "Nathan D. Gavin",
            "William M. Coombs",
            "Charles E. Augarde"
        ],
        "published": "2024-05-21T14:13:46Z"
    },
    {
        "title": "FAdam: Adam is a natural gradient optimizer using diagonal empirical\n  Fisher information",
        "link": "http://arxiv.org/abs/2405.12807v2",
        "abstract": "This paper establishes a mathematical foundation for the Adam optimizer,\nelucidating its connection to natural gradient descent through Riemannian and\ninformation geometry. We rigorously analyze the diagonal empirical Fisher\ninformation matrix (FIM) in Adam, clarifying all detailed approximations and\nadvocating for the use of log probability functions as loss, which should be\nbased on discrete distributions, due to the limitations of empirical FIM. Our\nanalysis uncovers flaws in the original Adam algorithm, leading to proposed\ncorrections such as enhanced momentum calculations, adjusted bias corrections,\nadaptive epsilon, and gradient clipping. We refine the weight decay term based\non our theoretical framework. Our modified algorithm, Fisher Adam (FAdam),\ndemonstrates superior performance across diverse domains including LLM, ASR,\nand VQ-VAE, achieving state-of-the-art results in ASR.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Dongseong Hwang"
        ],
        "published": "2024-05-21T13:58:17Z"
    },
    {
        "title": "MOSS: Motion-based 3D Clothed Human Synthesis from Monocular Video",
        "link": "http://arxiv.org/abs/2405.12806v1",
        "abstract": "Single-view clothed human reconstruction holds a central position in virtual\nreality applications, especially in contexts involving intricate human motions.\nIt presents notable challenges in achieving realistic clothing deformation.\nCurrent methodologies often overlook the influence of motion on surface\ndeformation, resulting in surfaces lacking the constraints imposed by global\nmotion. To overcome these limitations, we introduce an innovative framework,\nMotion-Based 3D Clothed Humans Synthesis (MOSS), which employs kinematic\ninformation to achieve motion-aware Gaussian split on the human surface. Our\nframework consists of two modules: Kinematic Gaussian Locating Splatting (KGAS)\nand Surface Deformation Detector (UID). KGAS incorporates matrix-Fisher\ndistribution to propagate global motion across the body surface. The density\nand rotation factors of this distribution explicitly control the Gaussians,\nthereby enhancing the realism of the reconstructed surface. Additionally, to\naddress local occlusions in single-view, based on KGAS, UID identifies\nsignificant surfaces, and geometric reconstruction is performed to compensate\nfor these deformations. Experimental results demonstrate that MOSS achieves\nstate-of-the-art visual quality in 3D clothed human synthesis from monocular\nvideos. Notably, we improve the Human NeRF and the Gaussian Splatting by 33.94%\nand 16.75% in LPIPS* respectively. Codes are available at\nhttps://wanghongsheng01.github.io/MOSS/.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hongsheng Wang",
            "Xiang Cai",
            "Xi Sun",
            "Jinhong Yue",
            "Shengyu Zhang",
            "Feng Lin",
            "Fei Wu"
        ],
        "published": "2024-05-21T13:57:53Z"
    },
    {
        "title": "Deep LPPLS: Forecasting of temporal critical points in natural,\n  engineering and financial systems",
        "link": "http://arxiv.org/abs/2405.12803v1",
        "abstract": "The Log-Periodic Power Law Singularity (LPPLS) model offers a general\nframework for capturing dynamics and predicting transition points in diverse\nnatural and social systems. In this work, we present two calibration techniques\nfor the LPPLS model using deep learning. First, we introduce the Mono-LPPLS-NN\n(M-LNN) model; for any given empirical time series, a unique M-LNN model is\ntrained and shown to outperform state-of-the-art techniques in estimating the\nnonlinear parameters $(t_c, m, \\omega)$ of the LPPLS model as evidenced by the\ncomprehensive distribution of parameter errors. Second, we extend the M-LNN\nmodel to a more general model architecture, the Poly-LPPLS-NN (P-LNN), which is\nable to quickly estimate the nonlinear parameters of the LPPLS model for any\ngiven time-series of a fixed length, including previously unseen time-series\nduring training. The Poly class of models train on many synthetic LPPLS\ntime-series augmented with various noise structures in a supervised manner.\nGiven enough training examples, the P-LNN models also outperform\nstate-of-the-art techniques for estimating the parameters of the LPPLS model as\nevidenced by the comprehensive distribution of parameter errors. Additionally,\nthis class of models is shown to substantially reduce the time to obtain\nparameter estimates. Finally, we present applications to the diagnostic and\nprediction of two financial bubble peaks (followed by their crash) and of a\nfamous rockslide. These contributions provide a bridge between deep learning\nand the study of the prediction of transition times in complex time series.",
        "subjects": [
            "cs.CE",
            "I.2.6; J.2"
        ],
        "authors": [
            "Joshua Nielsen",
            "Didier Sornette",
            "Maziar Raissi"
        ],
        "published": "2024-05-21T13:56:22Z"
    },
    {
        "title": "Stochastic Inference of Plate Bending from Heterogeneous Data:\n  Physics-informed Gaussian Processes via Kirchhoff-Love Theory",
        "link": "http://arxiv.org/abs/2405.12802v1",
        "abstract": "Advancements in machine learning and an abundance of structural monitoring\ndata have inspired the integration of mechanical models with probabilistic\nmodels to identify a structure's state and quantify the uncertainty of its\nphysical parameters and response. In this paper, we propose an inference\nmethodology for classical Kirchhoff-Love plates via physics-informed Gaussian\nProcesses (GP). A probabilistic model is formulated as a multi-output GP by\nplacing a GP prior on the deflection and deriving the covariance function using\nthe linear differential operators of the plate governing equations. The\nposteriors of the flexural rigidity, hyperparameters, and plate response are\ninferred in a Bayesian manner using Markov chain Monte Carlo (MCMC) sampling\nfrom noisy measurements. We demonstrate the applicability with two examples: a\nsimply supported plate subjected to a sinusoidal load and a fixed plate\nsubjected to a uniform load. The results illustrate how the proposed\nmethodology can be employed to perform stochastic inference for plate rigidity\nand physical quantities by integrating measurements from various sensor types\nand qualities. Potential applications of the presented methodology are in\nstructural health monitoring and uncertainty quantification of plate-like\nstructures.",
        "subjects": [
            "cs.LG",
            "physics.data-an"
        ],
        "authors": [
            "Igor Kavrakov",
            "Gledson Rodrigo Tondo",
            "Guido Morgenthal"
        ],
        "published": "2024-05-21T13:53:58Z"
    },
    {
        "title": "Presentations are not always linear! GNN meets LLM for\n  Document-to-Presentation Transformation with Attribution",
        "link": "http://arxiv.org/abs/2405.13095v1",
        "abstract": "Automatically generating a presentation from the text of a long document is a\nchallenging and useful problem. In contrast to a flat summary, a presentation\nneeds to have a better and non-linear narrative, i.e., the content of a slide\ncan come from different and non-contiguous parts of the given document.\nHowever, it is difficult to incorporate such non-linear mapping of content to\nslides and ensure that the content is faithful to the document. LLMs are prone\nto hallucination and their performance degrades with the length of the input\ndocument. Towards this, we propose a novel graph based solution where we learn\na graph from the input document and use a combination of graph neural network\nand LLM to generate a presentation with attribution of content for each slide.\nWe conduct thorough experiments to show the merit of our approach compared to\ndirectly using LLMs for this task.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Himanshu Maheshwari",
            "Sambaran Bandyopadhyay",
            "Aparna Garimella",
            "Anandhavelu Natarajan"
        ],
        "published": "2024-05-21T13:52:33Z"
    },
    {
        "title": "Comparing Neighbors Together Makes it Easy: Jointly Comparing Multiple\n  Candidates for Efficient and Effective Retrieval",
        "link": "http://arxiv.org/abs/2405.12801v1",
        "abstract": "A common retrieve-and-rerank paradigm involves retrieving a broad set of\nrelevant candidates using a scalable bi-encoder, followed by expensive but more\naccurate cross-encoders to a limited candidate set. However, this small subset\noften leads to error propagation from the bi-encoders, thereby restricting the\nperformance of the overall pipeline. To address these issues, we propose the\nComparing Multiple Candidates (CMC) framework, which compares a query and\nmultiple candidate embeddings jointly through shallow self-attention layers.\nWhile providing contextualized representations, CMC is scalable enough to\nhandle multiple comparisons simultaneously, where comparing 2K candidates takes\nonly twice as long as comparing 100. Practitioners can use CMC as a lightweight\nand effective reranker to improve top-1 accuracy. Moreover, when integrated\nwith another retriever, CMC reranking can function as a virtually enhanced\nretriever. This configuration adds only negligible latency compared to using a\nsingle retriever (virtual), while significantly improving recall at K\n(enhanced).} Through experiments, we demonstrate that CMC, as a virtually\nenhanced retriever, significantly improves Recall@k (+6.7, +3.5%-p for R@16,\nR@64) compared to the initial retrieval stage on the ZeSHEL dataset. Meanwhile,\nwe conduct experiments for direct reranking on entity, passage, and dialogue\nranking. The results indicate that CMC is not only faster (11x) than\ncross-encoders but also often more effective, with improved prediction\nperformance in Wikipedia entity linking (+0.7%-p) and DSTC7 dialogue ranking\n(+3.3%-p). The code and link to datasets are available at\nhttps://github.com/yc-song/cmc",
        "subjects": [
            "cs.CL",
            "cs.IR",
            "cs.LG"
        ],
        "authors": [
            "Jonghyun Song",
            "Cheyon Jin",
            "Wenlong Zhao",
            "Jay-Yoon Lee"
        ],
        "published": "2024-05-21T13:51:48Z"
    },
    {
        "title": "Deep Reinforcement Learning for Time-Critical Wilderness Search And\n  Rescue Using Drones",
        "link": "http://arxiv.org/abs/2405.12800v2",
        "abstract": "Traditional search and rescue methods in wilderness areas can be\ntime-consuming and have limited coverage. Drones offer a faster and more\nflexible solution, but optimizing their search paths is crucial. This paper\nexplores the use of deep reinforcement learning to create efficient search\nmissions for drones in wilderness environments. Our approach leverages a priori\ndata about the search area and the missing person in the form of a probability\ndistribution map. This allows the deep reinforcement learning agent to learn\noptimal flight paths that maximize the probability of finding the missing\nperson quickly. Experimental results show that our method achieves a\nsignificant improvement in search times compared to traditional coverage\nplanning and search planning algorithms. In one comparison, deep reinforcement\nlearning is found to outperform other algorithms by over $160\\%$, a difference\nthat can mean life or death in real-world search operations. Additionally,\nunlike previous work, our approach incorporates a continuous action space\nenabled by cubature, allowing for more nuanced flight patterns.",
        "subjects": [
            "cs.RO",
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Jan-Hendrik Ewers",
            "David Anderson",
            "Douglas Thomson"
        ],
        "published": "2024-05-21T13:51:47Z"
    },
    {
        "title": "Scientific discourse on YouTube: Motivations for citing research in\n  comments",
        "link": "http://dx.doi.org/10.1002/pra2.754",
        "abstract": "YouTube is a valuable source of user-generated content on a wide range of\ntopics, and it encourages user participation through the use of a comment\nsystem. Video content is increasingly addressing scientific topics, and there\nis evidence that both academics and consumers use video descriptions and video\ncomments to refer to academic research and scientific publications. Because\ncommenting is a discursive behavior, this study will provide insights on why\nindividuals post links to research publications in comments. For this, a\nqualitative content analysis and iterative coding approach were applied.\nFurthermore, the reasons for mentioning academic publications in comments were\ncontrasted with the reasons for citing in scholarly works and with reasons for\ncommenting on YouTube. We discovered that the primary motives for sharing\nresearch links were (1) providing more insights into the topic and (2)\nchallenging information offered by other commentators.",
        "subjects": [
            "cs.CY",
            "cs.DL"
        ],
        "authors": [
            "Sören Striewski",
            "Olga Zagovora",
            "Isabella Peters"
        ],
        "published": "2024-05-21T13:50:02Z"
    },
    {
        "title": "Refined Graph Encoder Embedding via Self-Training and Latent Community\n  Recovery",
        "link": "http://arxiv.org/abs/2405.12797v1",
        "abstract": "This paper introduces a refined graph encoder embedding method, enhancing the\noriginal graph encoder embedding using linear transformation, self-training,\nand hidden community recovery within observed communities. We provide the\ntheoretical rationale for the refinement procedure, demonstrating how and why\nour proposed method can effectively identify useful hidden communities via\nstochastic block models, and how the refinement method leads to improved vertex\nembedding and better decision boundaries for subsequent vertex classification.\nThe efficacy of our approach is validated through a collection of simulated and\nreal-world graph data.",
        "subjects": [
            "cs.SI",
            "stat.ML"
        ],
        "authors": [
            "Cencheng Shen",
            "Jonathan Larson",
            "Ha Trinh",
            "Carey E. Priebe"
        ],
        "published": "2024-05-21T13:48:07Z"
    },
    {
        "title": "DisenStudio: Customized Multi-subject Text-to-Video Generation with\n  Disentangled Spatial Control",
        "link": "http://arxiv.org/abs/2405.12796v1",
        "abstract": "Generating customized content in videos has received increasing attention\nrecently. However, existing works primarily focus on customized text-to-video\ngeneration for single subject, suffering from subject-missing and\nattribute-binding problems when the video is expected to contain multiple\nsubjects. Furthermore, existing models struggle to assign the desired actions\nto the corresponding subjects (action-binding problem), failing to achieve\nsatisfactory multi-subject generation performance. To tackle the problems, in\nthis paper, we propose DisenStudio, a novel framework that can generate\ntext-guided videos for customized multiple subjects, given few images for each\nsubject. Specifically, DisenStudio enhances a pretrained diffusion-based\ntext-to-video model with our proposed spatial-disentangled cross-attention\nmechanism to associate each subject with the desired action. Then the model is\ncustomized for the multiple subjects with the proposed motion-preserved\ndisentangled finetuning, which involves three tuning strategies: multi-subject\nco-occurrence tuning, masked single-subject tuning, and multi-subject\nmotion-preserved tuning. The first two strategies guarantee the subject\noccurrence and preserve their visual attributes, and the third strategy helps\nthe model maintain the temporal motion-generation ability when finetuning on\nstatic images. We conduct extensive experiments to demonstrate our proposed\nDisenStudio significantly outperforms existing methods in various metrics.\nAdditionally, we show that DisenStudio can be used as a powerful tool for\nvarious controllable generation applications.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hong Chen",
            "Xin Wang",
            "Yipeng Zhang",
            "Yuwei Zhou",
            "Zeyang Zhang",
            "Siao Tang",
            "Wenwu Zhu"
        ],
        "published": "2024-05-21T13:44:55Z"
    },
    {
        "title": "Adaptive local boundary conditions to improve Deformable Image\n  Registration",
        "link": "http://arxiv.org/abs/2405.12791v1",
        "abstract": "Objective: In medical imaging, it is often crucial to accurately assess and\ncorrect movement during image-guided therapy. Deformable image registration\n(DIR) consists in estimating the required spatial transformation to align a\nmoving image with a fixed one. However, it is acknowledged that, boundary\nconditions applied to the solution are critical in preventing mis-registration.\nDespite the extensive research on registration techniques, relatively few have\naddressed the issue of boundary conditions in the context of medical DIR. Our\naim is a step towards customizing boundary conditions to suit the diverse\nregistration tasks at hand.\n  Approach: We propose a generic, locally adaptive, Robin-type condition\nenabling to balance between Dirichlet and Neumann boundary conditions,\ndepending on incoming/outgoing flow fields on the image boundaries. The\nproposed framework is entirely automatized through the determination of a\nreduced set of hyperparameters optimized via energy minimization.\n  Main results: The proposed approach was tested on a mono-modal CT thorax\nregistration task and an abdominal CT to MRI registration task. For the first\ntask, we observed a relative improvement in terms of target registration error\nof up to 12% (mean 4%), compared to homogeneous Dirichlet and homogeneous\nNeumann. For the second task, the automatic framework provides results closed\nto the best achievable.\n  Significance: This study underscores the importance of tailoring the\nregistration problem at the image boundaries. In this research, we introduce a\nnovel method to adapt the boundary conditions on a voxel-by-voxel basis,\nyielding optimized results in two distinct tasks: mono-modal CT thorax\nregistration and abdominal CT to MRI registration. The proposed framework\nenables optimized boundary conditions in image registration without any a\npriori assumptions regarding the images or the motion.",
        "subjects": [
            "cs.CV",
            "physics.med-ph"
        ],
        "authors": [
            "Eloïse Inacio",
            "Luc Lafitte",
            "Laurent Facq",
            "Clair Poignard",
            "Baudouin Denis de Senneville"
        ],
        "published": "2024-05-21T13:42:35Z"
    },
    {
        "title": "A Novel Methodology for Autonomous Planetary Exploration Using\n  Multi-Robot Teams",
        "link": "http://arxiv.org/abs/2405.12790v1",
        "abstract": "One of the fundamental limiting factors in planetary exploration is the\nautonomous capabilities of planetary exploration rovers. This study proposes a\nnovel methodology for trustworthy autonomous multi-robot teams which\nincorporates data from multiple sources (HiRISE orbiter imaging, probability\ndistribution maps, and on-board rover sensors) to find efficient exploration\nroutes in Jezero crater. A map is generated, consisting of a 3D terrain model,\ntraversability analysis, and probability distribution map of points of\nscientific interest. A three-stage mission planner generates an efficient\nroute, which maximises the accumulated probability of identifying points of\ninterest. A 4D RRT* algorithm is used to determine smooth, flat paths, and\nprioritised planning is used to coordinate a safe set of paths. The above\nmethodology is shown to coordinate safe and efficient rover paths, which ensure\nthe rovers remain within their nominal pitch and roll limits throughout\noperation.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Sarah Swinton",
            "Jan-Hendrik Ewers",
            "Euan McGookin",
            "David Anderson",
            "Douglas Thomson"
        ],
        "published": "2024-05-21T13:40:54Z"
    },
    {
        "title": "Anticipating Object State Changes",
        "link": "http://arxiv.org/abs/2405.12789v1",
        "abstract": "Anticipating object state changes in images and videos is a challenging\nproblem whose solution has important implications in vision-based scene\nunderstanding, automated monitoring systems, and action planning. In this work,\nwe propose the first method for solving this problem. The proposed method\npredicts object state changes that will occur in the near future as a result of\nyet unseen human actions. To address this new problem, we propose a novel\nframework that integrates learnt visual features that represent the recent\nvisual information, with natural language (NLP) features that represent past\nobject state changes and actions. Leveraging the extensive and challenging\nEgo4D dataset which provides a large-scale collection of first-person\nperspective videos across numerous interaction scenarios, we introduce new\ncurated annotation data for the object state change anticipation task (OSCA),\nnoted as Ego4D-OSCA. An extensive experimental evaluation was conducted that\ndemonstrates the efficacy of the proposed method in predicting object state\nchanges in dynamic scenarios. The proposed work underscores the potential of\nintegrating video and linguistic cues to enhance the predictive performance of\nvideo understanding systems. Moreover, it lays the groundwork for future\nresearch on the new task of object state change anticipation. The source code\nand the new annotation data (Ego4D-OSCA) will be made publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Victoria Manousaki",
            "Konstantinos Bacharidis",
            "Filippos Gouidis",
            "Konstantinos Papoutsakis",
            "Dimitris Plexousakis",
            "Antonis Argyros"
        ],
        "published": "2024-05-21T13:40:30Z"
    },
    {
        "title": "What Have We Achieved on Non-autoregressive Translation?",
        "link": "http://arxiv.org/abs/2405.12788v1",
        "abstract": "Recent advances have made non-autoregressive (NAT) translation comparable to\nautoregressive methods (AT). However, their evaluation using BLEU has been\nshown to weakly correlate with human annotations. Limited research compares\nnon-autoregressive translation and autoregressive translation comprehensively,\nleaving uncertainty about the true proximity of NAT to AT. To address this gap,\nwe systematically evaluate four representative NAT methods across various\ndimensions, including human evaluation. Our empirical results demonstrate that\ndespite narrowing the performance gap, state-of-the-art NAT still underperforms\nAT under more reliable evaluation metrics. Furthermore, we discover that\nexplicitly modeling dependencies is crucial for generating natural language and\ngeneralizing to out-of-distribution sequences.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yafu Li",
            "Huajian Zhang",
            "Jianhao Yan",
            "Yongjing Yin",
            "Yue Zhang"
        ],
        "published": "2024-05-21T13:38:15Z"
    },
    {
        "title": "Rethinking the Vulnerabilities of Face Recognition Systems:From a\n  Practical Perspective",
        "link": "http://arxiv.org/abs/2405.12786v1",
        "abstract": "Face Recognition Systems (FRS) have increasingly integrated into critical\napplications, including surveillance and user authentication, highlighting\ntheir pivotal role in modern security systems. Recent studies have revealed\nvulnerabilities in FRS to adversarial (e.g., adversarial patch attacks) and\nbackdoor attacks (e.g., training data poisoning), raising significant concerns\nabout their reliability and trustworthiness. Previous studies primarily focus\non traditional adversarial or backdoor attacks, overlooking the\nresource-intensive or privileged-manipulation nature of such threats, thus\nlimiting their practical generalization, stealthiness, universality and\nrobustness. Correspondingly, in this paper, we delve into the inherent\nvulnerabilities in FRS through user studies and preliminary explorations. By\nexploiting these vulnerabilities, we identify a novel attack, facial identity\nbackdoor attack dubbed FIBA, which unveils a potentially more devastating\nthreat against FRS:an enrollment-stage backdoor attack. FIBA circumvents the\nlimitations of traditional attacks, enabling broad-scale disruption by allowing\nany attacker donning a specific trigger to bypass these systems. This implies\nthat after a single, poisoned example is inserted into the database, the\ncorresponding trigger becomes a universal key for any attackers to spoof the\nFRS. This strategy essentially challenges the conventional attacks by\ninitiating at the enrollment stage, dramatically transforming the threat\nlandscape by poisoning the feature database rather than the training data.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Jiahao Chen",
            "Zhiqiang Shen",
            "Yuwen Pu",
            "Chunyi Zhou",
            "Shouling Ji"
        ],
        "published": "2024-05-21T13:34:23Z"
    },
    {
        "title": "Artificial Intelligence Approaches for Predictive Maintenance in the\n  Steel Industry: A Survey",
        "link": "http://arxiv.org/abs/2405.12785v1",
        "abstract": "Predictive Maintenance (PdM) emerged as one of the pillars of Industry 4.0,\nand became crucial for enhancing operational efficiency, allowing to minimize\ndowntime, extend lifespan of equipment, and prevent failures. A wide range of\nPdM tasks can be performed using Artificial Intelligence (AI) methods, which\noften use data generated from industrial sensors. The steel industry, which is\nan important branch of the global economy, is one of the potential\nbeneficiaries of this trend, given its large environmental footprint, the\nglobalized nature of the market, and the demanding working conditions. This\nsurvey synthesizes the current state of knowledge in the field of AI-based PdM\nwithin the steel industry and is addressed to researchers and practitioners. We\nidentified 219 articles related to this topic and formulated five research\nquestions, allowing us to gain a global perspective on current trends and the\nmain research gaps. We examined equipment and facilities subjected to PdM,\ndetermined common PdM approaches, and identified trends in the AI methods used\nto develop these solutions. We explored the characteristics of the data used in\nthe surveyed articles and assessed the practical implications of the research\npresented there. Most of the research focuses on the blast furnace or hot\nrolling, using data from industrial sensors. Current trends show increasing\ninterest in the domain, especially in the use of deep learning. The main\nchallenges include implementing the proposed methods in a production\nenvironment, incorporating them into maintenance plans, and enhancing the\naccessibility and reproducibility of the research.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Jakub Jakubowski",
            "Natalia Wojak-Strzelecka",
            "Rita P. Ribeiro",
            "Sepideh Pashami",
            "Szymon Bobek",
            "Joao Gama",
            "Grzegorz J Nalepa"
        ],
        "published": "2024-05-21T13:32:46Z"
    },
    {
        "title": "Generalize Polyp Segmentation via Inpainting across Diverse Backgrounds\n  and Pseudo-Mask Refinement",
        "link": "http://arxiv.org/abs/2405.12784v1",
        "abstract": "Inpainting lesions within different normal backgrounds is a potential method\nof addressing the generalization problem, which is crucial for polyp\nsegmentation models. However, seamlessly introducing polyps into complex\nendoscopic environments while simultaneously generating accurate pseudo-masks\nremains a challenge for current inpainting methods. To address these issues, we\nfirst leverage the pre-trained Stable Diffusion Inpaint and ControlNet, to\nintroduce a robust generative model capable of inpainting polyps across\ndifferent backgrounds. Secondly, we utilize the prior that synthetic polyps are\nconfined to the inpainted region, to establish an inpainted region-guided\npseudo-mask refinement network. We also propose a sample selection strategy\nthat prioritizes well-aligned and hard synthetic cases for further model\nfine-tuning. Experiments demonstrate that our inpainting model outperformed\nbaseline methods both qualitatively and quantitatively in inpainting quality.\nMoreover, our data augmentation strategy significantly enhances the performance\nof polyp segmentation models on external datasets, achieving or surpassing the\nlevel of fully supervised training benchmarks in that domain. Our code is\navailable at https://github.com/497662892/PolypInpainter.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jiajian Ma",
            "Fangqi Lu",
            "Silin Huang",
            "Song Wu",
            "Zhen Li"
        ],
        "published": "2024-05-21T13:29:35Z"
    },
    {
        "title": "Epanechnikov Variational Autoencoder",
        "link": "http://arxiv.org/abs/2405.12783v1",
        "abstract": "In this paper, we bridge Variational Autoencoders (VAEs) [17] and kernel\ndensity estimations (KDEs) [25 ],[23] by approximating the posterior by KDEs\nand deriving an upper bound of the Kullback-Leibler (KL) divergence in the\nevidence lower bound (ELBO). The flexibility of KDEs makes the optimization of\nposteriors in VAEs possible, which not only addresses the limitations of\nGaussian latent space in vanilla VAE but also provides a new perspective of\nestimating the KL-divergence in ELBO. Under appropriate conditions [ 9],[3 ],\nwe show that the Epanechnikov kernel is the optimal choice in minimizing the\nderived upper bound of KL-divergence asymptotically. Compared with Gaussian\nkernel, Epanechnikov kernel has compact support which should make the generated\nsample less noisy and blurry. The implementation of Epanechnikov kernel in ELBO\nis straightforward as it lies in the \"location-scale\" family of distributions\nwhere the reparametrization tricks can be directly employed. A series of\nexperiments on benchmark datasets such as MNIST, Fashion-MNIST, CIFAR-10 and\nCelebA further demonstrate the superiority of Epanechnikov Variational\nAutoenocoder (EVAE) over vanilla VAE in the quality of reconstructed images, as\nmeasured by the FID score and Sharpness[27].",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Tian Qin",
            "Wei-Min Huang"
        ],
        "published": "2024-05-21T13:29:24Z"
    },
    {
        "title": "Self-Supervised Modality-Agnostic Pre-Training of Swin Transformers",
        "link": "http://arxiv.org/abs/2405.12781v1",
        "abstract": "Unsupervised pre-training has emerged as a transformative paradigm,\ndisplaying remarkable advancements in various domains. However, the\nsusceptibility to domain shift, where pre-training data distribution differs\nfrom fine-tuning, poses a significant obstacle. To address this, we augment the\nSwin Transformer to learn from different medical imaging modalities, enhancing\ndownstream performance. Our model, dubbed SwinFUSE (Swin Multi-Modal Fusion for\nUnSupervised Enhancement), offers three key advantages: (i) it learns from both\nComputed Tomography (CT) and Magnetic Resonance Images (MRI) during\npre-training, resulting in complementary feature representations; (ii) a\ndomain-invariance module (DIM) that effectively highlights salient input\nregions, enhancing adaptability; (iii) exhibits remarkable generalizability,\nsurpassing the confines of tasks it was initially pre-trained on. Our\nexperiments on two publicly available 3D segmentation datasets show a modest\n1-2% performance trade-off compared to single-modality models, yet significant\nout-performance of up to 27% on out-of-distribution modality. This substantial\nimprovement underscores our proposed approach's practical relevance and\nreal-world applicability. Code is available at:\nhttps://github.com/devalab/SwinFUSE",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Abhiroop Talasila",
            "Maitreya Maity",
            "U. Deva Priyakumar"
        ],
        "published": "2024-05-21T13:28:32Z"
    },
    {
        "title": "Transformer in Touch: A Survey",
        "link": "http://arxiv.org/abs/2405.12779v1",
        "abstract": "The Transformer model, initially achieving significant success in the field\nof natural language processing, has recently shown great potential in the\napplication of tactile perception. This review aims to comprehensively outline\nthe application and development of Transformers in tactile technology. We first\nintroduce the two fundamental concepts behind the success of the Transformer:\nthe self-attention mechanism and large-scale pre-training. Then, we delve into\nthe application of Transformers in various tactile tasks, including but not\nlimited to object recognition, cross-modal generation, and object manipulation,\noffering a concise summary of the core methodologies, performance benchmarks,\nand design highlights. Finally, we suggest potential areas for further research\nand future work, aiming to generate more interest within the community, tackle\nexisting challenges, and encourage the use of Transformer models in the tactile\nfield.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Jing Gao",
            "Ning Cheng",
            "Bin Fang",
            "Wenjuan Han"
        ],
        "published": "2024-05-21T13:26:27Z"
    },
    {
        "title": "Unsupervised Multimodal Clustering for Semantics Discovery in Multimodal\n  Utterances",
        "link": "http://arxiv.org/abs/2405.12775v1",
        "abstract": "Discovering the semantics of multimodal utterances is essential for\nunderstanding human language and enhancing human-machine interactions. Existing\nmethods manifest limitations in leveraging nonverbal information for discerning\ncomplex semantics in unsupervised scenarios. This paper introduces a novel\nunsupervised multimodal clustering method (UMC), making a pioneering\ncontribution to this field. UMC introduces a unique approach to constructing\naugmentation views for multimodal data, which are then used to perform\npre-training to establish well-initialized representations for subsequent\nclustering. An innovative strategy is proposed to dynamically select\nhigh-quality samples as guidance for representation learning, gauged by the\ndensity of each sample's nearest neighbors. Besides, it is equipped to\nautomatically determine the optimal value for the top-$K$ parameter in each\ncluster to refine sample selection. Finally, both high- and low-quality samples\nare used to learn representations conducive to effective clustering. We build\nbaselines on benchmark multimodal intent and dialogue act datasets. UMC shows\nremarkable improvements of 2-6\\% scores in clustering metrics over\nstate-of-the-art methods, marking the first successful endeavor in this domain.\nThe complete code and data are available at https://github.com/thuiar/UMC.",
        "subjects": [
            "cs.MM",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Hanlei Zhang",
            "Hua Xu",
            "Fei Long",
            "Xin Wang",
            "Kai Gao"
        ],
        "published": "2024-05-21T13:24:07Z"
    },
    {
        "title": "Blind Separation of Vibration Sources using Deep Learning and\n  Deconvolution",
        "link": "http://arxiv.org/abs/2405.12774v1",
        "abstract": "Vibrations of rotating machinery primarily originate from two sources, both\nof which are distorted by the machine's transfer function on their way to the\nsensor: the dominant gear-related vibrations and a low-energy signal linked to\nbearing faults. The proposed method facilitates the blind separation of\nvibration sources, eliminating the need for any information about the monitored\nequipment or external measurements. This method estimates both sources in two\nstages: initially, the gear signal is isolated using a dilated CNN, followed by\nthe estimation of the bearing fault signal using the squared log envelope of\nthe residual. The effect of the transfer function is removed from both sources\nusing a novel whitening-based deconvolution method (WBD). Both simulation and\nexperimental results demonstrate the method's ability to detect bearing\nfailures early when no additional information is available. This study\nconsiders both local and distributed bearing faults, assuming that the\nvibrations are recorded under stable operating conditions.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "eess.AS",
            "eess.SP"
        ],
        "authors": [
            "Igor Makienko",
            "Michael Grebshtein",
            "Eli Gildish"
        ],
        "published": "2024-05-21T13:24:05Z"
    },
    {
        "title": "Test Oracle Automation in the era of LLMs",
        "link": "http://arxiv.org/abs/2405.12766v1",
        "abstract": "The effectiveness of a test suite in detecting faults highly depends on the\ncorrectness and completeness of its test oracles. Large Language Models (LLMs)\nhave already demonstrated remarkable proficiency in tackling diverse software\ntesting tasks, such as automated test generation and program repair. This paper\naims to enable discussions on the potential of using LLMs for test oracle\nautomation, along with the challenges that may emerge during the generation of\nvarious types of oracles. Additionally, our aim is to initiate discussions on\nthe primary threats that SE researchers must consider when employing LLMs for\noracle automation, encompassing concerns regarding oracle deficiencies and data\nleakages.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Facundo Molina",
            "Alessandra Gorla"
        ],
        "published": "2024-05-21T13:19:10Z"
    },
    {
        "title": "Faster Linear-Size And-Or Path and Adder Circuits",
        "link": "http://arxiv.org/abs/2405.12765v2",
        "abstract": "We consider the fundamental problem of constructing fast and small circuits\nfor binary addition. We propose a new algorithm with running time $\\mathcal O(n\n\\log_2 n)$ for constructing linear-size $n$-bit adder circuits with a\nsignificantly better depth guarantee compared to previous approaches: Our\ncircuits have a depth of at most $\\log_2 n + \\log_2 \\log_2 n + \\log_2 \\log_2\n\\log_2 n + \\text{const}$, improving upon the previously best circuits by [12]\nwith a depth of at most $\\log_2 n + 8 \\sqrt{\\log_2 n} + 6 \\log_2 \\log_2 n +\n\\text{const}$. Hence, we decrease the gap to the lower bound of $\\log_2 n +\n\\log_2 \\log_2 n + \\text{const}$ by [5] significantly from $\\mathcal O\n(\\sqrt{\\log_2 n})$ to $\\mathcal O(\\log_2 \\log_2 \\log_2 n)$.\n  Our core routine is a new algorithm for the construction of a circuit for a\nsingle carry bit, or, more generally, for an And-Or path, i.e., a Boolean\nfunction of type $t_0 \\lor ( t_1 \\land (t_2 \\lor ( \\dots t_{m-1}) \\dots ))$. We\ncompute linear-size And-Or path circuits with a depth of at most $\\log_2 m +\n\\log_2 \\log_2 m + 0.65$ in time $\\mathcal O(m \\log_2 m)$. These are the first\nAnd-Or path circuits known that, up to an additive constant, match the lower\nbound by [5] and at the same time have a linear size. The previously fastest\nAnd-Or path circuits are only by an additive constant worse in depth, but have\na much higher size in the order of $\\mathcal O (m \\log_2 m)$.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Ulrich Brenner",
            "Anna Silvanus"
        ],
        "published": "2024-05-21T13:18:54Z"
    },
    {
        "title": "Detecting and Mitigating Bias in Algorithms Used to Disseminate\n  Information in Social Networks",
        "link": "http://arxiv.org/abs/2405.12764v1",
        "abstract": "Social connections are a conduit through which individuals communicate,\ninformation propagates, and diseases spread. Identifying individuals that are\nmore likely to adopt ideas or technologies and spread them to others is\nessential in order to develop effective information campaigns, fight epidemics,\nand to maximize the reach of limited resources. Consequently a lot of work has\nfocused on identifying sets of influencers. Here we show that seeding\ninformation using these influence maximization methods, only benefits connected\nand central individuals, consistently leaving the most vulnerable behind. Our\nresults highlights troublesome outcomes of influence maximization algorithms:\nthey do not disseminate information in an equitable manner threatening to\ncreate an increasingly unequal society. To overcome this issue we devise a\nsimple, multi-objective algorithm, which maximises both influence and\ninformation equity. Our work demonstrates how to find fairer influencer sets,\nhighlighting that in our search for maximizing information, we do not need to\ncompromise on information equality.",
        "subjects": [
            "cs.SI",
            "cs.CY",
            "physics.soc-ph"
        ],
        "authors": [
            "Vedran Sekara",
            "Ivan Dotu",
            "Manuel Cebrian",
            "Esteban Moro",
            "Manuel Garcia-Herranz"
        ],
        "published": "2024-05-21T13:17:57Z"
    },
    {
        "title": "KPG: Key Propagation Graph Generator for Rumor Detection based on\n  Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.13094v1",
        "abstract": "The proliferation of rumors on social media platforms during significant\nevents, such as the US elections and the COVID-19 pandemic, has a profound\nimpact on social stability and public health. Existing approaches for rumor\ndetection primarily rely on propagation graphs to enhance model effectiveness.\nHowever, the presence of noisy and irrelevant structures during the propagation\nprocess limits the efficacy of these approaches. To tackle this issue,\ntechniques such as weight adjustment and data augmentation have been proposed.\nHowever, these techniques heavily depend on rich original propagation\nstructures, thus hindering performance when dealing with rumors that lack\nsufficient propagation information in the early propagation stages. In this\npaper, we propose Key Propagation Graph Generator (KPG), a novel reinforcement\nlearning-based rumor detection framework that generates contextually coherent\nand informative propagation patterns for events with insufficient topology\ninformation, while also identifies indicative substructures for events with\nredundant and noisy propagation structures. KPG consists of two key components:\nthe Candidate Response Generator (CRG) and the Ending Node Selector (ENS). CRG\nlearns the latent distribution from refined propagation patterns, filtering out\nnoise and generating new candidates for ENS. Simultaneously, ENS identifies the\nmost influential substructures within propagation graphs and generates training\ndata for CRG. Moreover, we introduce an end-to-end framework that utilizes\nrewards to guide the entire training process via a pre-trained graph neural\nnetwork. Extensive experiments conducted on four datasets demonstrate the\nsuperiority of our KPG compared to the state-of-the-art approaches.",
        "subjects": [
            "cs.SI",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Yusong Zhang",
            "Kun Xie",
            "Xingyi Zhang",
            "Xiangyu Dong",
            "Sibo Wang"
        ],
        "published": "2024-05-21T13:13:43Z"
    },
    {
        "title": "Cross-spectral Gated-RGB Stereo Depth Estimation",
        "link": "http://arxiv.org/abs/2405.12759v1",
        "abstract": "Gated cameras flood-illuminate a scene and capture the time-gated impulse\nresponse of a scene. By employing nanosecond-scale gates, existing sensors are\ncapable of capturing mega-pixel gated images, delivering dense depth improving\non today's LiDAR sensors in spatial resolution and depth precision. Although\ngated depth estimation methods deliver a million of depth estimates per frame,\ntheir resolution is still an order below existing RGB imaging methods. In this\nwork, we combine high-resolution stereo HDR RCCB cameras with gated imaging,\nallowing us to exploit depth cues from active gating, multi-view RGB and\nmulti-view NIR sensing -- multi-view and gated cues across the entire spectrum.\nThe resulting capture system consists only of low-cost CMOS sensors and\nflood-illumination. We propose a novel stereo-depth estimation method that is\ncapable of exploiting these multi-modal multi-view depth cues, including the\nactive illumination that is measured by the RCCB camera when removing the\nIR-cut filter. The proposed method achieves accurate depth at long ranges,\noutperforming the next best existing method by 39% for ranges of 100 to 220m in\nMAE on accumulated LiDAR ground-truth. Our code, models and datasets are\navailable at https://light.princeton.edu/gatedrccbstereo/ .",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Samuel Brucker",
            "Stefanie Walz",
            "Mario Bijelic",
            "Felix Heide"
        ],
        "published": "2024-05-21T13:10:43Z"
    },
    {
        "title": "BIMM: Brain Inspired Masked Modeling for Video Representation Learning",
        "link": "http://arxiv.org/abs/2405.12757v1",
        "abstract": "The visual pathway of human brain includes two sub-pathways, ie, the ventral\npathway and the dorsal pathway, which focus on object identification and\ndynamic information modeling, respectively. Both pathways comprise multi-layer\nstructures, with each layer responsible for processing different aspects of\nvisual information. Inspired by visual information processing mechanism of the\nhuman brain, we propose the Brain Inspired Masked Modeling (BIMM) framework,\naiming to learn comprehensive representations from videos. Specifically, our\napproach consists of ventral and dorsal branches, which learn image and video\nrepresentations, respectively. Both branches employ the Vision Transformer\n(ViT) as their backbone and are trained using masked modeling method. To\nachieve the goals of different visual cortices in the brain, we segment the\nencoder of each branch into three intermediate blocks and reconstruct\nprogressive prediction targets with light weight decoders. Furthermore, drawing\ninspiration from the information-sharing mechanism in the visual pathways, we\npropose a partial parameter sharing strategy between the branches during\ntraining. Extensive experiments demonstrate that BIMM achieves superior\nperformance compared to the state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhifan Wan",
            "Jie Zhang",
            "Changzhen Li",
            "Shiguang Shan"
        ],
        "published": "2024-05-21T13:09:04Z"
    },
    {
        "title": "Parallel Algorithm for Optimal Threshold Labeling of Ordinal Regression\n  Methods",
        "link": "http://arxiv.org/abs/2405.12756v1",
        "abstract": "Ordinal regression (OR) is classification of ordinal data in which the\nunderlying categorical target variable has a natural ordinal relation for the\nunderlying explanatory variable. For $K$-class OR tasks, threshold methods\nlearn a one-dimensional transformation (1DT) of the explanatory variable so\nthat 1DT values for observations of the explanatory variable preserve the order\nof label values $1,\\ldots,K$ for corresponding observations of the target\nvariable well, and then assign a label prediction to the learned 1DT through\nthreshold labeling, namely, according to the rank of an interval to which the\n1DT belongs among intervals on the real line separated by $(K-1)$ threshold\nparameters. In this study, we propose a parallelizable algorithm to find the\noptimal threshold labeling, which was developed in previous research, and\nderive sufficient conditions for that algorithm to successfully output the\noptimal threshold labeling. In a numerical experiment we performed, the\ncomputation time taken for the whole learning process of a threshold method\nwith the optimal threshold labeling could be reduced to approximately 60\\,\\% by\nusing the proposed algorithm with parallel processing compared to using an\nexisting algorithm based on dynamic programming.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ryoya Yamasaki",
            "Toshiyuki Tanaka"
        ],
        "published": "2024-05-21T13:06:55Z"
    },
    {
        "title": "Progress Measures for Grokking on Real-world Datasets",
        "link": "http://arxiv.org/abs/2405.12755v1",
        "abstract": "Grokking, a phenomenon where machine learning models generalize long after\noverfitting, has been primarily observed and studied in algorithmic tasks. This\npaper explores grokking in real-world datasets using deep neural networks for\nclassification under the cross-entropy loss. We challenge the prevalent\nhypothesis that the $L_2$ norm of weights is the primary cause of grokking by\ndemonstrating that grokking can occur outside the expected range of weight\nnorms. To better understand grokking, we introduce three new progress measures:\nactivation sparsity, absolute weight entropy, and approximate local circuit\ncomplexity. These measures are conceptually related to generalization and\ndemonstrate a stronger correlation with grokking in real-world datasets\ncompared to weight norms. Our findings suggest that while weight norms might\nusually correlate with grokking and our progress measures, they are not\ncausative, and our proposed measures provide a better understanding of the\ndynamics of grokking.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Satvik Golechha"
        ],
        "published": "2024-05-21T13:06:41Z"
    },
    {
        "title": "Neural Operator for Accelerating Coronal Magnetic Field Model",
        "link": "http://arxiv.org/abs/2405.12754v1",
        "abstract": "Studying the sun's outer atmosphere is challenging due to its complex\nmagnetic fields impacting solar activities. Magnetohydrodynamics (MHD)\nsimulations help model these interactions but are extremely time-consuming\n(usually on a scale of days). Our research applies the Fourier Neural Operator\n(FNO) to accelerate the coronal magnetic field modeling, specifically, the\nBifrost MHD model. We apply Tensorized FNO (TFNO) to generate solutions from\npartial differential equations (PDEs) over a 3D domain efficiently. TFNO's\nperformance is compared with other deep learning methods, highlighting its\naccuracy and scalability. Physics analysis confirms that TFNO is reliable and\ncapable of accelerating MHD simulations with high precision. This advancement\nimproves efficiency in data handling, enhances predictive capabilities, and\nprovides a better understanding of magnetic topologies.",
        "subjects": [
            "astro-ph.SR",
            "cs.AI",
            "cs.LG",
            "physics.space-ph"
        ],
        "authors": [
            "Yutao Du",
            "Qin Li",
            "Raghav Gnanasambandam",
            "Mengnan Du",
            "Haimin Wang",
            "Bo Shen"
        ],
        "published": "2024-05-21T13:04:53Z"
    },
    {
        "title": "C3L: Content Correlated Vision-Language Instruction Tuning Data\n  Generation via Contrastive Learning",
        "link": "http://arxiv.org/abs/2405.12752v1",
        "abstract": "Vision-Language Instruction Tuning (VLIT) is a critical training phase for\nLarge Vision-Language Models (LVLMs). With the improving capabilities of\nopen-source LVLMs, researchers have increasingly turned to generate VLIT data\nby using open-source LVLMs and achieved significant progress. However, such\ndata generation approaches are bottlenecked by the following challenges: 1)\nSince multi-modal models tend to be influenced by prior language knowledge,\ndirectly using LVLMs to generate VLIT data would inevitably lead to low content\nrelevance between generated data and images. 2) To improve the ability of the\nmodels to generate VLIT data, previous methods have incorporated an additional\ntraining phase to boost the generative capacity. This process hurts the\ngeneralization of the models to unseen inputs (i.e., \"exposure bias\" problem).\nIn this paper, we propose a new Content Correlated VLIT data generation via\nContrastive Learning (C3L). Specifically, we design a new content relevance\nmodule which enhances the content relevance between VLIT data and images by\ncomputing Image Instruction Correspondence Scores S(I2C). Moreover, a\ncontrastive learning module is introduced to further boost the VLIT data\ngeneration capability of the LVLMs. A large number of automatic measures on\nfour benchmarks show the effectiveness of our method.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ji Ma",
            "Wei Suo",
            "Peng Wang",
            "Yanning Zhang"
        ],
        "published": "2024-05-21T13:04:10Z"
    },
    {
        "title": "A Stealthy Backdoor Attack for Without-Label-Sharing Split Learning",
        "link": "http://arxiv.org/abs/2405.12751v1",
        "abstract": "As a novel privacy-preserving paradigm aimed at reducing client computational\ncosts and achieving data utility, split learning has garnered extensive\nattention and proliferated widespread applications across various fields,\nincluding smart health and smart transportation, among others. While recent\nstudies have primarily concentrated on addressing privacy leakage concerns in\nsplit learning, such as inference attacks and data reconstruction, the\nexploration of security issues (e.g., backdoor attacks) within the framework of\nsplit learning has been comparatively limited. Nonetheless, the security\nvulnerability within the context of split learning is highly posing a threat\nand can give rise to grave security implications, such as the illegal\nimpersonation in the face recognition model. Therefore, in this paper, we\npropose a stealthy backdoor attack strategy (namely SBAT) tailored to the\nwithout-label-sharing split learning architecture, which unveils the inherent\nsecurity vulnerability of split learning. We posit the existence of a potential\nattacker on the server side aiming to introduce a backdoor into the training\nmodel, while exploring two scenarios: one with known client network\narchitecture and the other with unknown architecture. Diverging from\ntraditional backdoor attack methods that manipulate the training data and\nlabels, we constructively conduct the backdoor attack by injecting the trigger\nembedding into the server network. Specifically, our SBAT achieves a higher\nlevel of attack stealthiness by refraining from modifying any intermediate\nparameters (e.g., gradients) during training and instead executing all\nmalicious operations post-training.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Yuwen Pu",
            "Zhuoyuan Ding",
            "Jiahao Chen",
            "Chunyi Zhou",
            "Qingming Li",
            "Chunqiang Hu",
            "Shouling Ji"
        ],
        "published": "2024-05-21T13:03:06Z"
    },
    {
        "title": "Generative AI and Large Language Models for Cyber Security: All Insights\n  You Need",
        "link": "http://arxiv.org/abs/2405.12750v1",
        "abstract": "This paper provides a comprehensive review of the future of cybersecurity\nthrough Generative AI and Large Language Models (LLMs). We explore LLM\napplications across various domains, including hardware design security,\nintrusion detection, software engineering, design verification, cyber threat\nintelligence, malware detection, and phishing detection. We present an overview\nof LLM evolution and its current state, focusing on advancements in models such\nas GPT-4, GPT-3.5, Mixtral-8x7B, BERT, Falcon2, and LLaMA. Our analysis extends\nto LLM vulnerabilities, such as prompt injection, insecure output handling,\ndata poisoning, DDoS attacks, and adversarial instructions. We delve into\nmitigation strategies to protect these models, providing a comprehensive look\nat potential attack scenarios and prevention techniques. Furthermore, we\nevaluate the performance of 42 LLM models in cybersecurity knowledge and\nhardware security, highlighting their strengths and weaknesses. We thoroughly\nevaluate cybersecurity datasets for LLM training and testing, covering the\nlifecycle from data creation to usage and identifying gaps for future research.\nIn addition, we review new strategies for leveraging LLMs, including techniques\nlike Half-Quadratic Quantization (HQQ), Reinforcement Learning with Human\nFeedback (RLHF), Direct Preference Optimization (DPO), Quantized Low-Rank\nAdapters (QLoRA), and Retrieval-Augmented Generation (RAG). These insights aim\nto enhance real-time cybersecurity defenses and improve the sophistication of\nLLM applications in threat detection and response. Our paper provides a\nfoundational understanding and strategic direction for integrating LLMs into\nfuture cybersecurity frameworks, emphasizing innovation and robust model\ndeployment to safeguard against evolving cyber threats.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "authors": [
            "Mohamed Amine Ferrag",
            "Fatima Alwahedi",
            "Ammar Battah",
            "Bilel Cherif",
            "Abdechakour Mechri",
            "Norbert Tihanyi"
        ],
        "published": "2024-05-21T13:02:27Z"
    },
    {
        "title": "Hierarchical Coded Caching with Low Subpacketization and Coding Delay",
        "link": "http://arxiv.org/abs/2405.12747v1",
        "abstract": "Coded caching scheme originally proposed by Maddah-Ali and Niesen (MN)\nconsidered a broadcast network consisting of a single server connected to a set\nof users each having a cache memory. Motivated by practical scenarios,\nKaramchandani \\textit{et al.} in [16] proposed a coded caching scheme for a\ntwo-layer hierarchical network consisting of a single server connected to\nmultiple mirror sites and each mirror site connected to a distinct set of\nusers, in which both mirror sites and users having cache memories. Low\nsubpacketization level coded caching schemes are desirable for practical\nimplementations. Placement delivery array (PDA) was proposed as a tool to\ndesign coded caching schemes with reduced subpacketization level by Yan\n\\textit{et al.} in [4]. Schemes with reduced subpacketization levels are\nstudied extensively in the literature for single-layer networks. Kong\n\\textit{et al.} in [17] proposed a structure called hierarchical placement\ndelivery arrays (HPDA), which characterizes a hierarchical coded caching system\nand also proposed a class of HPDAs that gives low subpacketization level\nschemes by using two PDAs. Low subpacketization level hierarchical schemes\nusing combinatorial $t$-designs is proposed in [20]. Apart from that there is\nno other existing work that discusses the subpacketization problem in a\nhierarchical network. This paper proposes a class of HPDA construction that\ngives low subpacketization level hierarchical coded caching schemes, by first\nconstructing a new class of PDAs. Compared with the existing schemes, in cases\nwhere the system parameters and subpacketization level are the same, the\nproposed hierarchical scheme has a better coding delay. Further, the new class\nof PDAs constructed either subsumes several known PDA constructions or achieves\nbetter transmission load for the same system parameters.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Rashid Ummer N. T.",
            "B. Sundar Rajan"
        ],
        "published": "2024-05-21T12:59:59Z"
    },
    {
        "title": "Graph neural networks informed locally by thermodynamics",
        "link": "http://arxiv.org/abs/2405.13093v1",
        "abstract": "Thermodynamics-informed neural networks employ inductive biases for the\nenforcement of the first and second principles of thermodynamics. To construct\nthese biases, a metriplectic evolution of the system is assumed. This provides\nexcellent results, when compared to uninformed, black box networks. While the\ndegree of accuracy can be increased in one or two orders of magnitude, in the\ncase of graph networks, this requires assembling global Poisson and dissipation\nmatrices, which breaks the local structure of such networks. In order to avoid\nthis drawback, a local version of the metriplectic biases has been developed in\nthis work, which avoids the aforementioned matrix assembly, thus preserving the\nnode-by-node structure of the graph networks. We apply this framework for\nexamples in the fields of solid and fluid mechanics. Our approach demonstrates\nsignificant computational efficiency and strong generalization capabilities,\naccurately making inferences on examples significantly different from those\nencountered during training.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Alicia Tierz",
            "Iciar Alfaro",
            "David González",
            "Francisco Chinesta",
            "Elías Cueto"
        ],
        "published": "2024-05-21T12:57:10Z"
    },
    {
        "title": "The Echoes of Multilinguality: Tracing Cultural Value Shifts during LM\n  Fine-tuning",
        "link": "http://arxiv.org/abs/2405.12744v1",
        "abstract": "Texts written in different languages reflect different culturally-dependent\nbeliefs of their writers. Thus, we expect multilingual LMs (MLMs), that are\njointly trained on a concatenation of text in multiple languages, to encode\ndifferent cultural values for each language. Yet, as the 'multilinguality' of\nthese LMs is driven by cross-lingual sharing, we also have reason to belief\nthat cultural values bleed over from one language into another. This limits the\nuse of MLMs in practice, as apart from being proficient in generating text in\nmultiple languages, creating language technology that can serve a community\nalso requires the output of LMs to be sensitive to their biases (Naous et al.,\n2023). Yet, little is known about how cultural values emerge and evolve in MLMs\n(Hershcovich et al., 2022a). We are the first to study how languages can exert\ninfluence on the cultural values encoded for different test languages, by\nstudying how such values are revised during fine-tuning. Focusing on the\nfine-tuning stage allows us to study the interplay between value shifts when\nexposed to new linguistic experience from different data sources and languages.\nLastly, we use a training data attribution method to find patterns in the\nfine-tuning examples, and the languages that they come from, that tend to\ninstigate value shifts.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Rochelle Choenni",
            "Anne Lauscher",
            "Ekaterina Shutova"
        ],
        "published": "2024-05-21T12:55:15Z"
    },
    {
        "title": "Multi-Subject Personalization",
        "link": "http://arxiv.org/abs/2405.12742v1",
        "abstract": "Creative story illustration requires a consistent interplay of multiple\ncharacters or objects. However, conventional text-to-image models face\nsignificant challenges while producing images featuring multiple personalized\nsubjects. For example, they distort the subject rendering, or the text\ndescriptions fail to render coherent subject interactions. We present\nMulti-Subject Personalization (MSP) to alleviate some of these challenges. We\nimplement MSP using Stable Diffusion and assess our approach against other\ntext-to-image models, showcasing its consistent generation of good-quality\nimages representing intended subjects and interactions.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Arushi Jain",
            "Shubham Paliwal",
            "Monika Sharma",
            "Vikram Jamwal",
            "Lovekesh Vig"
        ],
        "published": "2024-05-21T12:53:34Z"
    },
    {
        "title": "SPO: Multi-Dimensional Preference Sequential Alignment With Implicit\n  Reward Modeling",
        "link": "http://arxiv.org/abs/2405.12739v1",
        "abstract": "Human preference alignment is critical in building powerful and reliable\nlarge language models (LLMs). However, current methods either ignore the\nmulti-dimensionality of human preferences (e.g. helpfulness and harmlessness)\nor struggle with the complexity of managing multiple reward models. To address\nthese issues, we propose Sequential Preference Optimization (SPO), a method\nthat sequentially fine-tunes LLMs to align with multiple dimensions of human\npreferences. SPO avoids explicit reward modeling, directly optimizing the\nmodels to align with nuanced human preferences. We theoretically derive\nclosed-form optimal SPO policy and loss function. Gradient analysis is\nconducted to show how SPO manages to fine-tune the LLMs while maintaining\nalignment on previously optimized dimensions. Empirical results on LLMs of\ndifferent size and multiple evaluation datasets demonstrate that SPO\nsuccessfully aligns LLMs across multiple dimensions of human preferences and\nsignificantly outperforms the baselines.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Xingzhou Lou",
            "Junge Zhang",
            "Jian Xie",
            "Lifeng Liu",
            "Dong Yan",
            "Kaiqi Huang"
        ],
        "published": "2024-05-21T12:47:17Z"
    },
    {
        "title": "Predicting the Influence of Adverse Weather on Pedestrian Detection with\n  Automotive Radar and Lidar Sensors",
        "link": "http://arxiv.org/abs/2405.12736v1",
        "abstract": "Pedestrians are among the most endangered traffic participants in road\ntraffic. While pedestrian detection in nominal conditions is well established,\nthe sensor and, therefore, the pedestrian detection performance degrades under\nadverse weather conditions. Understanding the influences of rain and fog on a\nspecific radar and lidar sensor requires extensive testing, and if the sensors'\nspecifications are altered, a retesting effort is required. These challenges\nare addressed in this paper, firstly by conducting comprehensive measurements\ncollecting empirical data of pedestrian detection performance under varying\nrain and fog intensities in a controlled environment, and secondly, by\nintroducing a dedicated Weather Filter (WF) model that predicts the effects of\nrain and fog on a user-specified radar and lidar on pedestrian detection\nperformance. We use a state-of-the-art baseline model representing the physical\nrelation of sensor specifications, which, however, lacks the representation of\nsecondary weather effects, e.g., changes in pedestrian reflectivity or droplets\non a sensor, and adjust it with empirical data to account for such. We find\nthat our measurement results are in agreement with existent literature related\nto weather degredation and our WF outperforms the baseline model in predicting\nweather effects on pedestrian detection while only requiring a minimal testing\neffort.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Daniel Weihmayr",
            "Fatih Sezgin",
            "Leon Tolksdorf",
            "Christian Birkner",
            "Reza N. Jazar"
        ],
        "published": "2024-05-21T12:44:43Z"
    },
    {
        "title": "Amplifying Academic Research through YouTube: Engagement Metrics as\n  Predictors of Citation Impact",
        "link": "http://dx.doi.org/10.1145/3630744.3658414",
        "abstract": "This study explores the interplay between YouTube engagement metrics and the\nacademic impact of cited publications within video descriptions, amid declining\ntrust in traditional journalism and increased reliance on social media for\ninformation. By analyzing data from Altmetric.com and YouTube's API, it\nassesses how YouTube video features relate to citation impact. Initial results\nsuggest that videos citing scientific publications and garnering high\nengagement-likes, comments, and references to other publications-may function\nas a filtering mechanism or even as a predictor of impactful research.",
        "subjects": [
            "cs.CY",
            "cs.DL"
        ],
        "authors": [
            "Olga Zagovora",
            "Talisa Schwal",
            "Katrin Weller"
        ],
        "published": "2024-05-21T12:43:37Z"
    },
    {
        "title": "Review on modeling the societal impact of infrastructure disruptions due\n  to disasters",
        "link": "http://arxiv.org/abs/2405.12732v1",
        "abstract": "Infrastructure systems play a critical role in providing essential products\nand services for the functioning of modern society; however, they are\nvulnerable to disasters and their service disruptions can cause severe societal\nimpacts. To protect infrastructure from disasters and reduce potential impacts,\ngreat achievements have been made in modeling interdependent infrastructure\nsystems in past decades. In recent years, scholars have gradually shifted their\nresearch focus to understanding and modeling societal impacts of disruptions\nconsidering the fact that infrastructure systems are critical because of their\nrole in societal functioning, especially under situations of modern societies.\nExploring how infrastructure disruptions impair society to enhance resilient\ncity has become a key field of study. By comprehensively reviewing relevant\nstudies, this paper demonstrated the definition and types of societal impact of\ninfrastructure disruptions, and summarized the modeling approaches into four\ntypes: extended infrastructure modeling approaches, empirical approaches,\nagent-based approaches, and big data-driven approaches. For each approach, this\npaper organized relevant literature in terms of modeling ideas, advantages, and\ndisadvantages. Furthermore, the four approaches were compared according to\nseveral criteria, including the input data, types of societal impact, and\napplication scope. Finally, this paper illustrated the challenges and future\nresearch directions in the field.",
        "subjects": [
            "cs.MA",
            "physics.data-an"
        ],
        "authors": [
            "Yongsheng Yang",
            "Huan Liu",
            "Ali Mostafavi",
            "Hirokazu Tatano"
        ],
        "published": "2024-05-21T12:37:45Z"
    },
    {
        "title": "From Today's Code to Tomorrow's Symphony: The AI Transformation of\n  Developer's Routine by 2030",
        "link": "http://arxiv.org/abs/2405.12731v1",
        "abstract": "In the rapidly evolving landscape of software engineering, the integration of\nArtificial Intelligence (AI) into the Software Development Life-Cycle (SDLC)\nheralds a transformative era for developers. Recently, we have assisted to a\npivotal shift towards AI-assisted programming, exemplified by tools like GitHub\nCopilot and OpenAI's ChatGPT, which have become a crucial element for coding,\ndebugging, and software design. In this paper we provide a comparative analysis\nbetween the current state of AI-assisted programming in 2024 and our\nprojections for 2030, by exploring how AI advancements are set to enhance the\nimplementation phase, fundamentally altering developers' roles from manual\ncoders to orchestrators of AI-driven development ecosystems. We envision\nHyperAssistant, an augmented AI tool that offers comprehensive support to 2030\ndevelopers, addressing current limitations in mental health support, fault\ndetection, code optimization, team interaction, and skill development. We\nemphasize AI as a complementary force, augmenting developers' capabilities\nrather than replacing them, leading to the creation of sophisticated, reliable,\nand secure software solutions. Our vision seeks to anticipate the evolution of\nprogramming practices, challenges, and future directions, shaping a new\nparadigm where developers and AI collaborate more closely, promising a\nsignificant leap in SE efficiency, security and creativity.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Matteo Ciniselli",
            "Niccolò Puccinelli",
            "Ketai Qiu",
            "Luca Di Grazia"
        ],
        "published": "2024-05-21T12:37:36Z"
    },
    {
        "title": "Conditions for tractability of the weighted $L_p$-discrepancy and\n  integration in non-homogeneous tensor product spaces",
        "link": "http://arxiv.org/abs/2405.12729v1",
        "abstract": "We study tractability properties of the weighted $L_p$-discrepancy. The\nconcept of {\\it weighted} discrepancy was introduced by Sloan and\nWo\\'{z}\\-nia\\-kowski in 1998 in order to prove a weighted version of the\nKoksma-Hlawka inequality for the error of quasi-Monte Carlo integration rules.\nThe weights have the aim to model the influence of different coordinates of\nintegrands on the error. A discrepancy is said to be tractable if the\ninformation complexity, i.e., the minimal number $N$ of points such that the\ndiscrepancy is less than the initial discrepancy times an error threshold\n$\\varepsilon$, does not grow exponentially fast with the dimension. In this\ncase there are various notions of tractabilities used in order to classify the\nexact rate.\n  For even integer parameters $p$ there are sufficient conditions on the\nweights available in literature, which guarantee the one or other notion of\ntractability. In the present paper we prove matching sufficient conditions\n(upper bounds) and neccessary conditions (lower bounds) for polynomial and weak\ntractability for all $p \\in (1, \\infty)$.\n  The proofs of the lower bounds are based on a general result for the\ninformation complexity of integration with positive quadrature formulas for\ntensor product spaces. In order to demonstrate this lower bound we consider as\na second application the integration of tensor products of polynomials of\ndegree at most 2.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "math.NT",
            "11K38, 65C05, 65Y20"
        ],
        "authors": [
            "Erich Novak",
            "Friedrich Pillichshammer"
        ],
        "published": "2024-05-21T12:36:50Z"
    },
    {
        "title": "Leveraging Neural Radiance Fields for Pose Estimation of an Unknown\n  Space Object during Proximity Operations",
        "link": "http://arxiv.org/abs/2405.12728v1",
        "abstract": "We address the estimation of the 6D pose of an unknown target spacecraft\nrelative to a monocular camera, a key step towards the autonomous rendezvous\nand proximity operations required by future Active Debris Removal missions. We\npresent a novel method that enables an \"off-the-shelf\" spacecraft pose\nestimator, which is supposed to known the target CAD model, to be applied on an\nunknown target. Our method relies on an in-the wild NeRF, i.e., a Neural\nRadiance Field that employs learnable appearance embeddings to represent\nvarying illumination conditions found in natural scenes. We train the NeRF\nmodel using a sparse collection of images that depict the target, and in turn\ngenerate a large dataset that is diverse both in terms of viewpoint and\nillumination. This dataset is then used to train the pose estimation network.\nWe validate our method on the Hardware-In-the-Loop images of SPEED+ that\nemulate lighting conditions close to those encountered on orbit. We demonstrate\nthat our method successfully enables the training of an off-the-shelf\nspacecraft pose estimation network from a sparse set of images. Furthermore, we\nshow that a network trained using our method performs similarly to a model\ntrained on synthetic images generated using the CAD model of the target.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Antoine Legrand",
            "Renaud Detry",
            "Christophe De Vleeschouwer"
        ],
        "published": "2024-05-21T12:34:03Z"
    },
    {
        "title": "Nearest is Not Dearest: Towards Practical Defense against\n  Quantization-conditioned Backdoor Attacks",
        "link": "http://arxiv.org/abs/2405.12725v1",
        "abstract": "Model quantization is widely used to compress and accelerate deep neural\nnetworks. However, recent studies have revealed the feasibility of weaponizing\nmodel quantization via implanting quantization-conditioned backdoors (QCBs).\nThese special backdoors stay dormant on released full-precision models but will\ncome into effect after standard quantization. Due to the peculiarity of QCBs,\nexisting defenses have minor effects on reducing their threats or are even\ninfeasible. In this paper, we conduct the first in-depth analysis of QCBs. We\nreveal that the activation of existing QCBs primarily stems from the nearest\nrounding operation and is closely related to the norms of neuron-wise\ntruncation errors (i.e., the difference between the continuous full-precision\nweights and its quantized version). Motivated by these insights, we propose\nError-guided Flipped Rounding with Activation Preservation (EFRAP), an\neffective and practical defense against QCBs. Specifically, EFRAP learns a\nnon-nearest rounding strategy with neuron-wise error norm and layer-wise\nactivation preservation guidance, flipping the rounding strategies of neurons\ncrucial for backdoor effects but with minimal impact on clean accuracy.\nExtensive evaluations on benchmark datasets demonstrate that our EFRAP can\ndefeat state-of-the-art QCB attacks under various settings. Code is available\nat https://github.com/AntigoneRandy/QuantBackdoor_EFRAP.",
        "subjects": [
            "cs.CR",
            "cs.CV"
        ],
        "authors": [
            "Boheng Li",
            "Yishuo Cai",
            "Haowei Li",
            "Feng Xue",
            "Zhifeng Li",
            "Yiming Li"
        ],
        "published": "2024-05-21T12:25:49Z"
    },
    {
        "title": "RemoCap: Disentangled Representation Learning for Motion Capture",
        "link": "http://arxiv.org/abs/2405.12724v1",
        "abstract": "Reconstructing 3D human bodies from realistic motion sequences remains a\nchallenge due to pervasive and complex occlusions. Current methods struggle to\ncapture the dynamics of occluded body parts, leading to model penetration and\ndistorted motion. RemoCap leverages Spatial Disentanglement (SD) and Motion\nDisentanglement (MD) to overcome these limitations. SD addresses occlusion\ninterference between the target human body and surrounding objects. It achieves\nthis by disentangling target features along the dimension axis. By aligning\nfeatures based on their spatial positions in each dimension, SD isolates the\ntarget object's response within a global window, enabling accurate capture\ndespite occlusions. The MD module employs a channel-wise temporal shuffling\nstrategy to simulate diverse scene dynamics. This process effectively\ndisentangles motion features, allowing RemoCap to reconstruct occluded parts\nwith greater fidelity. Furthermore, this paper introduces a sequence velocity\nloss that promotes temporal coherence. This loss constrains inter-frame\nvelocity errors, ensuring the predicted motion exhibits realistic consistency.\nExtensive comparisons with state-of-the-art (SOTA) methods on benchmark\ndatasets demonstrate RemoCap's superior performance in 3D human body\nreconstruction. On the 3DPW dataset, RemoCap surpasses all competitors,\nachieving the best results in MPVPE (81.9), MPJPE (72.7), and PA-MPJPE (44.1)\nmetrics. Codes are available at https://wanghongsheng01.github.io/RemoCap/.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hongsheng Wang",
            "Lizao Zhang",
            "Zhangnan Zhong",
            "Shuolin Xu",
            "Xinrui Zhou",
            "Shengyu Zhang",
            "Huahao Xu",
            "Fei Wu",
            "Feng Lin"
        ],
        "published": "2024-05-21T12:24:01Z"
    },
    {
        "title": "StarLKNet: Star Mixup with Large Kernel Networks for Palm Vein\n  Identification",
        "link": "http://arxiv.org/abs/2405.12721v1",
        "abstract": "As a representative of a new generation of biometrics, vein identification\ntechnology offers a high level of security and convenience. Convolutional\nneural networks (CNNs), a prominent class of deep learning architectures, have\nbeen extensively utilized for vein identification. Since their performance and\nrobustness are limited by small Effective Receptive Fields (e.g. 3$\\times$3\nkernels) and insufficient training samples, however, they are unable to extract\nglobal feature representations from vein images in an effective manner. To\naddress these issues, we propose StarLKNet, a large kernel convolution-based\npalm-vein identification network, with the Mixup approach. Our StarMix learns\neffectively the distribution of vein features to expand samples. To enable CNNs\nto capture comprehensive feature representations from palm-vein images, we\nexplored the effect of convolutional kernel size on the performance of\npalm-vein identification networks and designed LaKNet, a network leveraging\nlarge kernel convolution and gating mechanism. In light of the current state of\nknowledge, this represents an inaugural instance of the deployment of a CNN\nwith large kernels in the domain of vein identification. Extensive experiments\nwere conducted to validate the performance of StarLKNet on two public palm-vein\ndatasets. The results demonstrated that StarMix provided superior augmentation,\nand LakNet exhibited more stable performance gains compared to mainstream\napproaches, resulting in the highest recognition accuracy and lowest\nidentification error.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xin Jin",
            "Hongyu Zhu",
            "Mounîm A. El Yacoubi",
            "Hongchao Liao",
            "Huafeng Qin",
            "Yun Jiang"
        ],
        "published": "2024-05-21T12:21:45Z"
    },
    {
        "title": "How to Train a Backdoor-Robust Model on a Poisoned Dataset without\n  Auxiliary Data?",
        "link": "http://arxiv.org/abs/2405.12719v1",
        "abstract": "Backdoor attacks have attracted wide attention from academia and industry due\nto their great security threat to deep neural networks (DNN). Most of the\nexisting methods propose to conduct backdoor attacks by poisoning the training\ndataset with different strategies, so it's critical to identify the poisoned\nsamples and then train a clean model on the unreliable dataset in the context\nof defending backdoor attacks. Although numerous backdoor countermeasure\nresearches are proposed, their inherent weaknesses render them limited in\npractical scenarios, such as the requirement of enough clean samples, unstable\ndefense performance under various attack conditions, poor defense performance\nagainst adaptive attacks, and so on.Therefore, in this paper, we are committed\nto overcome the above limitations and propose a more practical backdoor defense\nmethod. Concretely, we first explore the inherent relationship between the\npotential perturbations and the backdoor trigger, and the theoretical analysis\nand experimental results demonstrate that the poisoned samples perform more\nrobustness to perturbation than the clean ones. Then, based on our key\nexplorations, we introduce AdvrBD, an Adversarial perturbation-based and robust\nBackdoor Defense framework, which can effectively identify the poisoned samples\nand train a clean model on the poisoned dataset. Constructively, our AdvrBD\neliminates the requirement for any clean samples or knowledge about the\npoisoned dataset (e.g., poisoning ratio), which significantly improves the\npracticality in real-world scenarios.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Yuwen Pu",
            "Jiahao Chen",
            "Chunyi Zhou",
            "Zhou Feng",
            "Qingming Li",
            "Chunqiang Hu",
            "Shouling Ji"
        ],
        "published": "2024-05-21T12:20:19Z"
    },
    {
        "title": "Reinforcement Learning Enabled Peer-to-Peer Energy Trading for Dairy\n  Farms",
        "link": "http://arxiv.org/abs/2405.12716v1",
        "abstract": "Farm businesses are increasingly adopting renewables to enhance energy\nefficiency and reduce reliance on fossil fuels and the grid. This shift aims to\ndecrease dairy farms' dependence on traditional electricity grids by enabling\nthe sale of surplus renewable energy in Peer-to-Peer markets. However, the\ndynamic nature of farm communities poses challenges, requiring specialized\nalgorithms for P2P energy trading. To address this, the Multi-Agent\nPeer-to-Peer Dairy Farm Energy Simulator (MAPDES) has been developed, providing\na platform to experiment with Reinforcement Learning techniques. The\nsimulations demonstrate significant cost savings, including a 43% reduction in\nelectricity expenses, a 42% decrease in peak demand, and a 1.91% increase in\nenergy sales compared to baseline scenarios lacking peer-to-peer energy trading\nor renewable energy sources.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ],
        "authors": [
            "Mian Ibad Ali Shah",
            "Enda Barrett",
            "Karl Mason"
        ],
        "published": "2024-05-21T12:19:17Z"
    },
    {
        "title": "RecGPT: Generative Pre-training for Text-based Recommendation",
        "link": "http://arxiv.org/abs/2405.12715v1",
        "abstract": "We present the first domain-adapted and fully-trained large language model,\nRecGPT-7B, and its instruction-following variant, RecGPT-7B-Instruct, for\ntext-based recommendation. Experimental results on rating prediction and\nsequential recommendation tasks show that our model, RecGPT-7B-Instruct,\noutperforms previous strong baselines. We are releasing our RecGPT models as\nwell as their pre-training and fine-tuning datasets to facilitate future\nresearch and downstream applications in text-based recommendation. Public\n\"huggingface\" links to our RecGPT models and datasets are available at:\nhttps://github.com/VinAIResearch/RecGPT",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "authors": [
            "Hoang Ngo",
            "Dat Quoc Nguyen"
        ],
        "published": "2024-05-21T12:16:20Z"
    },
    {
        "title": "CausalPlayground: Addressing Data-Generation Requirements in\n  Cutting-Edge Causality Research",
        "link": "http://arxiv.org/abs/2405.13092v1",
        "abstract": "Research on causal effects often relies on synthetic data due to the scarcity\nof real-world datasets with ground-truth effects. Since current data-generating\ntools do not always meet all requirements for state-of-the-art research, ad-hoc\nmethods are often employed. This leads to heterogeneity among datasets and\ndelays research progress. We address the shortcomings of current\ndata-generating libraries by introducing CausalPlayground, a Python library\nthat provides a standardized platform for generating, sampling, and sharing\nstructural causal models (SCMs). CausalPlayground offers fine-grained control\nover SCMs, interventions, and the generation of datasets of SCMs for learning\nand quantitative research. Furthermore, by integrating with Gymnasium, the\nstandard framework for reinforcement learning (RL) environments, we enable\nonline interaction with the SCMs. Overall, by introducing CausalPlayground we\naim to foster more efficient and comparable research in the field. All code and\nAPI documentation is available at https://github.com/sa-and/CausalPlayground.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Andreas W M Sauter",
            "Erman Acar",
            "Aske Plaat"
        ],
        "published": "2024-05-21T12:08:48Z"
    },
    {
        "title": "Dynamic Identity-Guided Attention Network for Visible-Infrared Person\n  Re-identification",
        "link": "http://arxiv.org/abs/2405.12713v1",
        "abstract": "Visible-infrared person re-identification (VI-ReID) aims to match people with\nthe same identity between visible and infrared modalities. VI-ReID is a\nchallenging task due to the large differences in individual appearance under\ndifferent modalities. Existing methods generally try to bridge the cross-modal\ndifferences at image or feature level, which lacks exploring the discriminative\nembeddings. Effectively minimizing these cross-modal discrepancies relies on\nobtaining representations that are guided by identity and consistent across\nmodalities, while also filtering out representations that are irrelevant to\nidentity. To address these challenges, we introduce a dynamic identity-guided\nattention network (DIAN) to mine identity-guided and modality-consistent\nembeddings, facilitating effective bridging the gap between different\nmodalities. Specifically, in DIAN, to pursue a semantically richer\nrepresentation, we first use orthogonal projection to fuse the features from\ntwo connected coarse and fine layers. Furthermore, we first use dynamic\nconvolution kernels to mine identity-guided and modality-consistent\nrepresentations. More notably, a cross embedding balancing loss is introduced\nto effectively bridge cross-modal discrepancies by above embeddings.\nExperimental results on SYSU-MM01 and RegDB datasets show that DIAN achieves\nstate-of-the-art performance. Specifically, for indoor search on SYSU-MM01, our\nmethod achieves 86.28% rank-1 accuracy and 87.41% mAP, respectively. Our code\nwill be available soon.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Peng Gao",
            "Yujian Lee",
            "Hui Zhang",
            "Xubo Liu",
            "Yiyang Hu",
            "Guquan Jing"
        ],
        "published": "2024-05-21T12:04:56Z"
    },
    {
        "title": "From Human-to-Human to Human-to-Bot Conversations in Software\n  Engineering",
        "link": "http://arxiv.org/abs/2405.12712v1",
        "abstract": "Software developers use natural language to interact not only with other\nhumans, but increasingly also with chatbots. These interactions have different\nproperties and flow differently based on what goal the developer wants to\nachieve and who they interact with. In this paper, we aim to understand the\ndynamics of conversations that occur during modern software development after\nthe integration of AI and chatbots, enabling a deeper recognition of the\nadvantages and disadvantages of including chatbot interactions in addition to\nhuman conversations in collaborative work. We compile existing conversation\nattributes with humans and NLU-based chatbots and adapt them to the context of\nsoftware development. Then, we extend the comparison to include LLM-powered\nchatbots based on an observational study. We present similarities and\ndifferences between human-to-human and human-to-bot conversations, also\ndistinguishing between NLU- and LLM-based chatbots. Furthermore, we discuss how\nunderstanding the differences among the conversation styles guides the\ndeveloper on how to shape their expectations from a conversation and\nconsequently support the communication within a software team. We conclude that\nthe recent conversation styles that we observe with LLM-chatbots can not\nreplace conversations with humans due to certain attributes regarding social\naspects despite their ability to support productivity and decrease the\ndevelopers' mental load.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.CL",
            "cs.HC"
        ],
        "authors": [
            "Ranim Khojah",
            "Francisco Gomes de Oliveira Neto",
            "Philipp Leitner"
        ],
        "published": "2024-05-21T12:04:55Z"
    },
    {
        "title": "A Masked Semi-Supervised Learning Approach for Otago Micro Labels\n  Recognition",
        "link": "http://arxiv.org/abs/2405.12711v2",
        "abstract": "The Otago Exercise Program (OEP) serves as a vital rehabilitation initiative\nfor older adults, aiming to enhance their strength and balance, and\nconsequently prevent falls. While Human Activity Recognition (HAR) systems have\nbeen widely employed in recognizing the activities of individuals, existing\nsystems focus on the duration of macro activities (i.e. a sequence of\nrepetitions of the same exercise), neglecting the ability to discern micro\nactivities (i.e. the individual repetitions of the exercises), in the case of\nOEP. This study presents a novel semi-supervised machine learning approach\naimed at bridging this gap in recognizing the micro activities of OEP. To\nmanage the limited dataset size, our model utilizes a Transformer encoder for\nfeature extraction, subsequently classified by a Temporal Convolutional Network\n(TCN). Simultaneously, the Transformer encoder is employed for masked\nunsupervised learning to reconstruct input signals. Results indicate that the\nmasked unsupervised learning task enhances the performance of the supervised\nlearning (classification task), as evidenced by f1-scores surpassing the\nclinically applicable threshold of 0.8. From the micro activities, two\nclinically relevant outcomes emerge: counting the number of repetitions of each\nexercise and calculating the velocity during chair rising. These outcomes\nenable the automatic monitoring of exercise intensity and difficulty in the\ndaily lives of older adults.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Meng Shang",
            "Lenore Dedeyne",
            "Jolan Dupont",
            "Laura Vercauteren",
            "Nadjia Amini",
            "Laurence Lapauw",
            "Evelien Gielen",
            "Sabine Verschueren",
            "Carolina Varon",
            "Walter De Raedt",
            "Bart Vanrumste"
        ],
        "published": "2024-05-21T12:00:01Z"
    },
    {
        "title": "Text-Video Retrieval with Global-Local Semantic Consistent Learning",
        "link": "http://arxiv.org/abs/2405.12710v1",
        "abstract": "Adapting large-scale image-text pre-training models, e.g., CLIP, to the video\ndomain represents the current state-of-the-art for text-video retrieval. The\nprimary approaches involve transferring text-video pairs to a common embedding\nspace and leveraging cross-modal interactions on specific entities for semantic\nalignment. Though effective, these paradigms entail prohibitive computational\ncosts, leading to inefficient retrieval. To address this, we propose a simple\nyet effective method, Global-Local Semantic Consistent Learning (GLSCL), which\ncapitalizes on latent shared semantics across modalities for text-video\nretrieval. Specifically, we introduce a parameter-free global interaction\nmodule to explore coarse-grained alignment. Then, we devise a shared local\ninteraction module that employs several learnable queries to capture latent\nsemantic concepts for learning fine-grained alignment. Furthermore, an\nInter-Consistency Loss (ICL) is devised to accomplish the concept alignment\nbetween the visual query and corresponding textual query, and an\nIntra-Diversity Loss (IDL) is developed to repulse the distribution within\nvisual (textual) queries to generate more discriminative concepts. Extensive\nexperiments on five widely used benchmarks (i.e., MSR-VTT, MSVD, DiDeMo, LSMDC,\nand ActivityNet) substantiate the superior effectiveness and efficiency of the\nproposed method. Remarkably, our method achieves comparable performance with\nSOTA as well as being nearly 220 times faster in terms of computational cost.\nCode is available at: https://github.com/zchoi/GLSCL.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Haonan Zhang",
            "Pengpeng Zeng",
            "Lianli Gao",
            "Jingkuan Song",
            "Yihang Duan",
            "Xinyu Lyu",
            "Hengtao Shen"
        ],
        "published": "2024-05-21T11:59:36Z"
    },
    {
        "title": "Object-Centric Event Logs: Specifications, Comparative Analysis and\n  Refinement",
        "link": "http://arxiv.org/abs/2405.12709v1",
        "abstract": "Process mining aims to comprehend and enhance business processes by analyzing\nevent logs. Recently, object-centric process mining has gained traction by\nconsidering multiple objects interacting with each other in a process. This\nobject-centric approach offers advantages over traditional methods by avoiding\ndimension reduction issues. However, in contrast to traditional process mining\nwhere a standard event log format was quickly agreed upon with XES providing a\ncommon platform for further research and industry, various object-centric\nlogging formats have been proposed, each addressing specific challenges such as\nobject relations or dynamic attribute changes. This makes that interoperability\nof object-centric algorithms remains a challenge, hindering reproducibility and\ngeneralizability in research. Additionally, the object-centric process storage\nparadigm aligns well with a wide range of object-oriented databases storing\nprocess data.\n  This paper introduces a specifications framework from three perspectives\noriginating from process mining (what should be analyzed), object-centric\nprocess modeling (how it should be modeled), and database storage (how it\nshould be stored) perspectives in order to compare and evaluate object-centric\nlog formats. By identifying commonalities and discrepancies among these\nformats, the study delves into unresolved issues and proposes potential\nsolutions. Ultimately, this research contributes to advancing object-centric\nprocess mining by facilitating a deeper understanding of event log formats and\npromoting consistency and compatibility across methodologies.",
        "subjects": [
            "cs.DB"
        ],
        "authors": [
            "Alexandre Goossens",
            "Johannes De Smedt",
            "Jan Vanthienen"
        ],
        "published": "2024-05-21T11:58:11Z"
    },
    {
        "title": "Multimodal video analysis for crowd anomaly detection using open access\n  tourism cameras",
        "link": "http://arxiv.org/abs/2405.12708v1",
        "abstract": "In this article, we propose the detection of crowd anomalies through the\nextraction of information in the form of time series from video format using a\nmultimodal approach. Through pattern recognition algorithms and segmentation,\ninformative measures of the number of people and image occupancy are extracted\nat regular intervals, which are then analyzed to obtain trends and anomalous\nbehaviors. Specifically, through temporal decomposition and residual analysis,\nintervals or specific situations of unusual behaviors are identified, which can\nbe used in decision-making and improvement of actions in sectors related to\nhuman movement such as tourism or security.\n  The application of this methodology on the webcam of Turisme Comunitat\nValenciana in the town of Morella (Comunitat Valenciana, Spain) has provided\nexcellent results. It is shown to correctly detect specific anomalous\nsituations and unusual overall increases during the previous weekend and during\nthe festivities in October 2023. These results have been obtained while\npreserving the confidentiality of individuals at all times by using measures\nthat maximize anonymity, without trajectory recording or person recognition.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Alejandro Dionis-Ros",
            "Joan Vila-Francés",
            "Rafael Magdalena-Benedicto",
            "Fernando Mateo",
            "Antonio J. Serrano-López"
        ],
        "published": "2024-05-21T11:56:01Z"
    },
    {
        "title": "Disentangled Representation with Cross Experts Covariance Loss for\n  Multi-Domain Recommendation",
        "link": "http://arxiv.org/abs/2405.12706v1",
        "abstract": "Multi-domain learning (MDL) has emerged as a prominent research area aimed at\nenhancing the quality of personalized services. The key challenge in MDL lies\nin striking a balance between learning commonalities across domains while\npreserving the distinct characteristics of each domain. However, this gives\nrise to a challenging dilemma. On one hand, a model needs to leverage\ndomain-specific modules, such as experts or embeddings, to preserve the\nuniqueness of each domain. On the other hand, due to the long-tailed\ndistributions observed in real-world domains, some tail domains may lack\nsufficient samples to fully learn their corresponding modules. Unfortunately,\nexisting approaches have not adequately addressed this dilemma. To address this\nissue, we propose a novel model called Crocodile, which stands for\nCross-experts Covariance Loss for Disentangled Learning. Crocodile adopts a\nmulti-embedding paradigm to facilitate model learning and employs a Covariance\nLoss on these embeddings to disentangle them. This disentanglement enables the\nmodel to capture diverse user interests across domains effectively.\nAdditionally, we introduce a novel gating mechanism to further enhance the\ncapabilities of Crocodile. Through empirical analysis, we demonstrate that our\nproposed method successfully resolves these two challenges and outperforms all\nstate-of-the-art methods on publicly available datasets. We firmly believe that\nthe analytical perspectives and design concept of disentanglement presented in\nour work can pave the way for future research in the field of MDL.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Zhutian Lin",
            "Junwei Pan",
            "Haibin Yu",
            "Xi Xiao",
            "Ximei Wang",
            "Zhixiang Feng",
            "Shifeng Wen",
            "Shudong Huang",
            "Lei Xiao",
            "Jie Jiang"
        ],
        "published": "2024-05-21T11:54:16Z"
    },
    {
        "title": "Multimodal Adaptive Inference for Document Image Classification with\n  Anytime Early Exiting",
        "link": "http://arxiv.org/abs/2405.12705v1",
        "abstract": "This work addresses the need for a balanced approach between performance and\nefficiency in scalable production environments for visually-rich document\nunderstanding (VDU) tasks. Currently, there is a reliance on large document\nfoundation models that offer advanced capabilities but come with a heavy\ncomputational burden. In this paper, we propose a multimodal early exit (EE)\nmodel design that incorporates various training strategies, exit layer types\nand placements. Our goal is to achieve a Pareto-optimal balance between\npredictive performance and efficiency for multimodal document image\nclassification. Through a comprehensive set of experiments, we compare our\napproach with traditional exit policies and showcase an improved\nperformance-efficiency trade-off. Our multimodal EE design preserves the\nmodel's predictive capabilities, enhancing both speed and latency. This is\nachieved through a reduction of over 20% in latency, while fully retaining the\nbaseline accuracy. This research represents the first exploration of multimodal\nEE design within the VDU community, highlighting as well the effectiveness of\ncalibration in improving confidence scores for exiting at different layers.\nOverall, our findings contribute to practical VDU applications by enhancing\nboth performance and efficiency.",
        "subjects": [
            "cs.CV",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Omar Hamed",
            "Souhail Bakkali",
            "Marie-Francine Moens",
            "Matthew Blaschko",
            "Jordy Van Landeghem"
        ],
        "published": "2024-05-21T11:52:14Z"
    },
    {
        "title": "OLAPH: Improving Factuality in Biomedical Long-form Question Answering",
        "link": "http://arxiv.org/abs/2405.12701v1",
        "abstract": "In the medical domain, numerous scenarios necessitate the long-form\ngeneration ability of large language models (LLMs). Specifically, when\naddressing patients' questions, it is essential that the model's response\nconveys factual claims, highlighting the need for an automated method to\nevaluate those claims. Thus, we introduce MedLFQA, a benchmark dataset\nreconstructed using long-form question-answering datasets related to the\nbiomedical domain. We use MedLFQA to facilitate the automatic evaluations of\nfactuality. We also propose OLAPH, a simple and novel framework that enables\nthe improvement of factuality through automatic evaluations. The OLAPH\nframework iteratively trains LLMs to mitigate hallucinations using sampling\npredictions and preference optimization. In other words, we iteratively set the\nhighest-scoring response as a preferred response derived from sampling\npredictions and train LLMs to align with the preferred response that improves\nfactuality. We highlight that, even on evaluation metrics not used during\ntraining, LLMs trained with our OLAPH framework demonstrate significant\nperformance improvement in factuality. Our findings reveal that a 7B LLM\ntrained with our OLAPH framework can provide long answers comparable to the\nmedical experts' answers in terms of factuality. We believe that our work could\nshed light on gauging the long-text generation ability of LLMs in the medical\ndomain. Our code and datasets are available at\nhttps://github.com/dmis-lab/OLAPH}{https://github.com/dmis-lab/OLAPH.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Minbyul Jeong",
            "Hyeon Hwang",
            "Chanwoong Yoon",
            "Taewhoo Lee",
            "Jaewoo Kang"
        ],
        "published": "2024-05-21T11:50:16Z"
    },
    {
        "title": "Getting Wiser from Multiple Data: Probabilistic Updating according to\n  Jeffrey and Pearl",
        "link": "http://arxiv.org/abs/2405.12700v1",
        "abstract": "In probabilistic updating one transforms a prior distribution in the light of\ngiven evidence into a posterior distribution, via what is called conditioning,\nupdating, belief revision or inference. This is the essence of learning, as\nBayesian updating. It will be illustrated via a physical model involving\n(adapted) water flows through pipes with different diameters.\n  Bayesian updating makes us wiser, in the sense that the posterior\ndistribution makes the evidence more likely than the prior, since it\nincorporates the evidence. Things are less clear when one wishes to learn from\nmultiple pieces of evidence / data. It turns out that there are (at least) two\nforms of updating for this, associated with Jeffrey and Pearl. The difference\nis not always clearly recognised.\n  This paper provides an introduction and an overview in the setting of\ndiscrete probability theory. It starts from an elementary question, involving\nmultiple pieces of evidence, that has been sent to a small group academic\nspecialists. Their answers show considerable differences. This is used as\nmotivation and starting point to introduce the two forms of updating, of\nJeffrey and Pearl, for multiple inputs and to elaborate their properties. In\nthe end the account is related to so-called variational free energy (VFE)\nupdate in the cognitive theory of predictive processing. It is shown that both\nJeffrey and Pearl outperform VFE updating and that VFE updating need not\ndecrease divergence - that is correct errors - as it is supposed to do.",
        "subjects": [
            "cs.LO",
            "03B70, 68Q87, 18C50",
            "F.3.2; G.3"
        ],
        "authors": [
            "Bart Jacobs"
        ],
        "published": "2024-05-21T11:49:07Z"
    },
    {
        "title": "GeckoGraph: A Visual Language for Polymorphic Types",
        "link": "http://arxiv.org/abs/2405.12699v1",
        "abstract": "Polymorphic types are an important feature in most strongly typed programming\nlanguages. They allow functions to be written in a way that can be used with\ndifferent data types, while still enforcing the relationship and constraints\nbetween the values. However, programmers often find polymorphic types difficult\nto use and understand and tend to reason using concrete types. We propose\nGeckoGraph, a graphical notation for types. GeckoGraph aims to accompany\ntraditional text-based type notation and to make reading, understanding, and\ncomparing types easier. We conducted a large-scale human study using GeckoGraph\ncompared to text-based type notation. To our knowledge, this is the largest\ncontrolled user study on functional programming ever conducted. The results of\nthe study show that GeckoGraph helps improve programmers' ability to succeed in\nthe programming tasks we designed, especially for novice programmers.",
        "subjects": [
            "cs.PL",
            "cs.HC"
        ],
        "authors": [
            "Shuai Fu",
            "Tim Dwyer",
            "Peter J. Stuckey"
        ],
        "published": "2024-05-21T11:46:51Z"
    },
    {
        "title": "FedASTA: Federated adaptive spatial-temporal attention for traffic flow\n  prediction",
        "link": "http://arxiv.org/abs/2405.13090v1",
        "abstract": "Mobile devices and the Internet of Things (IoT) devices nowadays generate a\nlarge amount of heterogeneous spatial-temporal data. It remains a challenging\nproblem to model the spatial-temporal dynamics under privacy concern. Federated\nlearning (FL) has been proposed as a framework to enable model training across\ndistributed devices without sharing original data which reduce privacy concern.\nPersonalized federated learning (PFL) methods further address data heterogenous\nproblem. However, these methods don't consider natural spatial relations among\nnodes. For the sake of modeling spatial relations, Graph Neural Netowork (GNN)\nbased FL approach have been proposed. But dynamic spatial-temporal relations\namong edge nodes are not taken into account. Several approaches model\nspatial-temporal dynamics in a centralized environment, while less effort has\nbeen made under federated setting. To overcome these challeges, we propose a\nnovel Federated Adaptive Spatial-Temporal Attention (FedASTA) framework to\nmodel the dynamic spatial-temporal relations. On the client node, FedASTA\nextracts temporal relations and trend patterns from the decomposed terms of\noriginal time series. Then, on the server node, FedASTA utilize trend patterns\nfrom clients to construct adaptive temporal-spatial aware graph which captures\ndynamic correlation between clients. Besides, we design a masked spatial\nattention module with both static graph and constructed adaptive graph to model\nspatial dependencies among clients. Extensive experiments on five real-world\npublic traffic flow datasets demonstrate that our method achieves state-of-art\nperformance in federated scenario. In addition, the experiments made in\ncentralized setting show the effectiveness of our novel adaptive graph\nconstruction approach compared with other popular dynamic spatial-temporal\naware methods.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC"
        ],
        "authors": [
            "Kaiyuan Li",
            "Yihan Zhang",
            "Xinlei Chen"
        ],
        "published": "2024-05-21T11:44:07Z"
    },
    {
        "title": "SEGAN: semi-supervised learning approach for missing data imputation",
        "link": "http://arxiv.org/abs/2405.13089v1",
        "abstract": "In many practical real-world applications, data missing is a very common\nphenomenon, making the development of data-driven artificial intelligence\ntheory and technology increasingly difficult. Data completion is an important\nmethod for missing data preprocessing. Most existing miss-ing data completion\nmodels directly use the known information in the missing data set but ignore\nthe impact of the data label information contained in the data set on the\nmissing data completion model. To this end, this paper proposes a missing data\ncompletion model SEGAN based on semi-supervised learning, which mainly includes\nthree important modules: generator, discriminator and classifier. In the SEGAN\nmodel, the classifier enables the generator to make more full use of known data\nand its label information when predicting missing data values. In addition, the\nSE-GAN model introduces a missing hint matrix to allow the discriminator to\nmore effectively distinguish between known data and data filled by the\ngenerator. This paper theoretically proves that the SEGAN model that introduces\na classifier and a missing hint matrix can learn the real known data\ndistribution characteristics when reaching Nash equilibrium. Finally, a large\nnumber of experiments were conducted in this article, and the experimental\nresults show that com-pared with the current state-of-the-art multivariate data\ncompletion method, the performance of the SEGAN model is improved by more than\n3%.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Xiaohua Pan",
            "Weifeng Wu",
            "Peiran Liu",
            "Zhen Li",
            "Peng Lu",
            "Peijian Cao",
            "Jianfeng Zhang",
            "Xianfei Qiu",
            "YangYang Wu"
        ],
        "published": "2024-05-21T11:42:20Z"
    },
    {
        "title": "Combining Relevance and Magnitude for Resource-Aware DNN Pruning",
        "link": "http://arxiv.org/abs/2405.13088v1",
        "abstract": "Pruning neural networks, i.e., removing some of their parameters whilst\nretaining their accuracy, is one of the main ways to reduce the latency of a\nmachine learning pipeline, especially in resource- and/or bandwidth-constrained\nscenarios. In this context, the pruning technique, i.e., how to choose the\nparameters to remove, is critical to the system performance. In this paper, we\npropose a novel pruning approach, called FlexRel and predicated upon combining\ntraining-time and inference-time information, namely, parameter magnitude and\nrelevance, in order to improve the resulting accuracy whilst saving both\ncomputational resources and bandwidth. Our performance evaluation shows that\nFlexRel is able to achieve higher pruning factors, saving over 35% bandwidth\nfor typical accuracy targets.",
        "subjects": [
            "cs.LG",
            "cs.NE"
        ],
        "authors": [
            "Carla Fabiana Chiasserini",
            "Francesco Malandrino",
            "Nuria Molner",
            "Zhiqiang Zhao"
        ],
        "published": "2024-05-21T11:42:15Z"
    },
    {
        "title": "Goanna: Resolving Haskell Type Errors With Minimal Correction Subsets",
        "link": "http://arxiv.org/abs/2405.12697v1",
        "abstract": "Statically typed languages offer significant advantages, such as bug\nprevention, enhanced code quality, and reduced maintenance costs. However,\nthese benefits often come at the expense of a steep learning curve and a slower\ndevelopment pace. Haskell, known for its expressive and strict type system,\nposes challenges for inexperienced programmers in learning and using its type\nsystem, especially in debugging type errors. We introduce Goanna, a novel tool\nthat serves as a type checker and an interactive type error debugging tool for\nHaskell. When encountering type errors, Goanna identifies a comprehensive list\nof potential causes and resolutions based on the minimum correction subsets\n(MCS) enumeration. We evaluated Goanna's effectiveness using 86 diverse Haskell\nprograms from online discourse, demonstrating its ability to accurately\nidentify and resolve type errors. Additionally, we present a collection of\ntechniques and heuristics to enhance Goanna's suggestion-based error diagnosis\nand show their effectiveness from our evaluation.",
        "subjects": [
            "cs.HC",
            "cs.PL"
        ],
        "authors": [
            "Shuai Fu",
            "Tim Dwyer",
            "Peter J. Stuckey",
            "John Grundy"
        ],
        "published": "2024-05-21T11:40:39Z"
    },
    {
        "title": "Explainable offline automatic signature verifier to support forensic\n  handwriting examiners",
        "link": "http://dx.doi.org/10.1007/s00521-023-09192-7",
        "abstract": "Signature verification is a critical task in many applications, including\nforensic science, legal judgments, and financial markets. However, current\nsignature verification systems are often difficult to explain, which can limit\ntheir acceptance in these applications. In this paper, we propose a novel\nexplainable offline automatic signature verifier (ASV) to support forensic\nhandwriting examiners. Our ASV is based on a universal background model (UBM)\nconstructed from offline signature images. It allows us to assign a questioned\nsignature to the UBM and to a reference set of known signatures using simple\ndistance measures. This makes it possible to explain the verifier's decision in\na way that is understandable to non experts. We evaluated our ASV on publicly\navailable databases and found that it achieves competitive performance with\nstate of the art ASVs, even when challenging 1 versus 1 comparison are\nconsidered. Our results demonstrate that it is possible to develop an\nexplainable ASV that is also competitive in terms of performance. We believe\nthat our ASV has the potential to improve the acceptance of signature\nverification in critical applications such as forensic science and legal\njudgments.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Moises Diaz",
            "Miguel A. Ferrer",
            "Gennaro Vessio"
        ],
        "published": "2024-05-21T11:38:45Z"
    },
    {
        "title": "Spotting AI's Touch: Identifying LLM-Paraphrased Spans in Text",
        "link": "http://arxiv.org/abs/2405.12689v1",
        "abstract": "AI-generated text detection has attracted increasing attention as powerful\nlanguage models approach human-level generation. Limited work is devoted to\ndetecting (partially) AI-paraphrased texts. However, AI paraphrasing is\ncommonly employed in various application scenarios for text refinement and\ndiversity. To this end, we propose a novel detection framework, paraphrased\ntext span detection (PTD), aiming to identify paraphrased text spans within a\ntext. Different from text-level detection, PTD takes in the full text and\nassigns each of the sentences with a score indicating the paraphrasing degree.\nWe construct a dedicated dataset, PASTED, for paraphrased text span detection.\nBoth in-distribution and out-of-distribution results demonstrate the\neffectiveness of PTD models in identifying AI-paraphrased text spans.\nStatistical and model analysis explains the crucial role of the surrounding\ncontext of the paraphrased text spans. Extensive experiments show that PTD\nmodels can generalize to versatile paraphrasing prompts and multiple\nparaphrased text spans. We release our resources at\nhttps://github.com/Linzwcs/PASTED.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Yafu Li",
            "Zhilin Wang",
            "Leyang Cui",
            "Wei Bi",
            "Shuming Shi",
            "Yue Zhang"
        ],
        "published": "2024-05-21T11:22:27Z"
    },
    {
        "title": "Model Free Prediction with Uncertainty Assessment",
        "link": "http://arxiv.org/abs/2405.12684v1",
        "abstract": "Deep nonparametric regression, characterized by the utilization of deep\nneural networks to learn target functions, has emerged as a focal point of\nresearch attention in recent years. Despite considerable progress in\nunderstanding convergence rates, the absence of asymptotic properties hinders\nrigorous statistical inference. To address this gap, we propose a novel\nframework that transforms the deep estimation paradigm into a platform\nconducive to conditional mean estimation, leveraging the conditional diffusion\nmodel. Theoretically, we develop an end-to-end convergence rate for the\nconditional diffusion model and establish the asymptotic normality of the\ngenerated samples. Consequently, we are equipped to construct confidence\nregions, facilitating robust statistical inference. Furthermore, through\nnumerical experiments, we empirically validate the efficacy of our proposed\nmethodology.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Yuling Jiao",
            "Lican Kang",
            "Jin Liu",
            "Heng Peng",
            "Heng Zuo"
        ],
        "published": "2024-05-21T11:19:50Z"
    },
    {
        "title": "A Multimodal Learning-based Approach for Autonomous Landing of UAV",
        "link": "http://arxiv.org/abs/2405.12681v1",
        "abstract": "In the field of autonomous Unmanned Aerial Vehicles (UAVs) landing,\nconventional approaches fall short in delivering not only the required\nprecision but also the resilience against environmental disturbances. Yet,\nlearning-based algorithms can offer promising solutions by leveraging their\nability to learn the intelligent behaviour from data. On one hand, this paper\nintroduces a novel multimodal transformer-based Deep Learning detector, that\ncan provide reliable positioning for precise autonomous landing. It surpasses\nstandard approaches by addressing individual sensor limitations, achieving high\nreliability even in diverse weather and sensor failure conditions. It was\nrigorously validated across varying environments, achieving optimal true\npositive rates and average precisions of up to 90%. On the other hand, it is\nproposed a Reinforcement Learning (RL) decision-making model, based on a Deep\nQ-Network (DQN) rationale. Initially trained in sumlation, its adaptive\nbehaviour is successfully transferred and validated in a real outdoor scenario.\nFurthermore, this approach demonstrates rapid inference times of approximately\n5ms, validating its applicability on edge devices.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Francisco Neves",
            "Luís Branco",
            "Maria Pereira",
            "Rafael Claro",
            "Andry Pinto"
        ],
        "published": "2024-05-21T11:14:16Z"
    },
    {
        "title": "Sorting in One and Two Rounds using $t$-Comparators",
        "link": "http://arxiv.org/abs/2405.12678v1",
        "abstract": "We examine sorting algorithms for $n$ elements whose basic operation is\ncomparing $t$ elements simultaneously (a $t$-comparator). We focus on\nalgorithms that use only a single round or two rounds -- comparisons performed\nin the second round depend on the outcomes of the first round comparators.\n  We design deterministic and randomized algorithms. In the deterministic case,\nwe show an interesting relation to design theory (namely, to 2-Steiner\nsystems), which yields a single-round optimal algorithm for $n=t^{2^k}$ with\nany $k\\ge 1$ and a variety of possible values of $t$. For some values of $t$,\nhowever, no algorithm can reach the optimal (information-theoretic) bound on\nthe number of comparators. For this case (and any other $n$ and $t$), we show\nan algorithm that uses at most three times as many comparators as the\ntheoretical bound.\n  We also design a randomized Las-Vegas two-rounds sorting algorithm for any\n$n$ and $t$. Our algorithm uses an asymptotically optimal number of\n$O(\\max(\\frac{n^{3/2}}{t^2},\\frac{n}{t}))$ comparators, with high probability,\ni.e., with probability at least $1-1/n$. The analysis of this algorithm\ninvolves the gradual unveiling of randomness, using a novel technique which we\ncoin the binary tree of deferred randomness.",
        "subjects": [
            "cs.DS",
            "cs.DC"
        ],
        "authors": [
            "Ran Gelles",
            "Zvi Lotker",
            "Frederik Mallmann-Trenn"
        ],
        "published": "2024-05-21T11:11:13Z"
    },
    {
        "title": "Experimental investigation of trans-scale displacement responses of\n  wrinkle defects in fiber reinforced composite laminates",
        "link": "http://arxiv.org/abs/2405.12676v1",
        "abstract": "Wrinkle defects were found widely exist in the field of industrial products,\ni.e. wind turbine blades and filament-wound composite pressure vessels. The\nmagnitude of wrinkle wavelength varies from several millimeters to over one\nhundred millimeters. Locating the wrinkle defects and measuring their responses\nare very important to the assessment of the structures that containing wrinkle\ndefects. A meso-mechanical modeling is presented based on the homogenization\nmethod to obtain the effective stiffness of a graded wrinkle. The finite\nelement simulation predicts the trans-scale response of out-of-plane\ndisplacement of wrinkled laminates, where the maximum displacement ranges from\nnanoscale to millimeter scale. Such trans-scale effect requires different\nmeasurement approaches to observe the displacement responses. Here we employed\nShearography (Speckle Pattern Shearing Interferometry) and fringe projection\nprofilometry (FPP) method respectively according to the different magnitude of\ndisplacement. In FPP method, a displacement extraction algorithm was presented\nto obtain the out-of-plane displacement. The measurement sensitivity and\naccuracy of Shearography and FPP are compared, which provides a quantitative\nreference for industrial non-destructive test.",
        "subjects": [
            "cs.CV",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Li Ma",
            "Shoulong Wang",
            "Changchen Liu",
            "Ange Wen",
            "Kaidi Ying",
            "Jing Guo"
        ],
        "published": "2024-05-21T11:10:00Z"
    },
    {
        "title": "Towards an AI/ML-defined Radio for Wi-Fi: Overview, Challenges, and\n  Roadmap",
        "link": "http://arxiv.org/abs/2405.12675v1",
        "abstract": "Will AI/ML-defined radios become a reality in the near future? In this paper,\nwe introduce the concept of an AI/ML-defined radio - a radio architecture\nspecifically designed to support AI/ML-based optimization and decision-making\nin communication functions - and depict its promised benefits and potential\nchallenges. Additionally, we discuss a potential roadmap for the development\nand adoption of AI/ML-defined radios, and highlight the enablers for addressing\ntheir associated challenges. While we offer a general overview of the\nAI/ML-defined radio concept, our focus throughout the paper remains on Wi-Fi, a\nwireless technology that may significantly benefit from the integration of\nAI/ML-defined radios, owing to its inherent decentralized management and\noperation within unlicensed frequency bands.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Boris Bellalta",
            "Katarzyna Kosek-Szott",
            "Szymon Szott",
            "Francesc Wilhelmi"
        ],
        "published": "2024-05-21T10:56:57Z"
    },
    {
        "title": "A Survey on Multi-modal Machine Translation: Tasks, Methods and\n  Challenges",
        "link": "http://arxiv.org/abs/2405.12669v2",
        "abstract": "In recent years, multi-modal machine translation has attracted significant\ninterest in both academia and industry due to its superior performance. It\ntakes both textual and visual modalities as inputs, leveraging visual context\nto tackle the ambiguities in source texts. In this paper, we begin by offering\nan exhaustive overview of 99 prior works, comprehensively summarizing\nrepresentative studies from the perspectives of dominant models, datasets, and\nevaluation metrics. Afterwards, we analyze the impact of various factors on\nmodel performance and finally discuss the possible research directions for this\ntask in the future. Over time, multi-modal machine translation has developed\nmore types to meet diverse needs. Unlike previous surveys confined to the early\nstage of multi-modal machine translation, our survey thoroughly concludes these\nemerging types from different aspects, so as to provide researchers with a\nbetter understanding of its current state.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Huangjun Shen",
            "Liangying Shao",
            "Wenbo Li",
            "Zhibin Lan",
            "Zhanyu Liu",
            "Jinsong Su"
        ],
        "published": "2024-05-21T10:34:47Z"
    },
    {
        "title": "Spatial Mode Multiplexing for Fiber-Coupled IM/DD Optical Wireless Links\n  with Misalignment",
        "link": "http://arxiv.org/abs/2405.12667v1",
        "abstract": "Optical wireless communication (OWC) emerges as a pivotal solution for\nachieving terabit-level aggregate throughput in next-generation wireless\nnetworks. With the mature high-speed transceivers and advanced (de)multiplexing\ntechniques designed for fiber optics, fiber-coupled OWC can be seamlessly\nintegrated into existing ultra-high-speed networks such as data centres. In\nparticular, OWC leveraging spatial mode multiplexing (SMM) and few-mode fiber\n(FMF) coupling can significantly increase capacity, though misalignment may\nreduce performance. This paper presents a thorough investigation into the\nSMM-enabled FMF coupling OWC systems affected by link misalignment,\nspecifically focusing on systems with intensity modulation with direct\ndetection (IM/DD) receivers. A theoretical analysis is conducted to assess the\nfiber coupling efficiency of the considered system in the presence of both\npointing error and angle of arrival (AOA) fluctuations caused by random device\nvibrations. Our model elucidates the dependence of coupling efficiency to the\norder of the incident modes, highlighting the critical role of beam properties\nin system performance. To mitigate the intermodal crosstalk arising from link\nmisalignment, we employ zero-forcing beamforming (ZFBF) to enhance the overall\naggregated data rate. Through extensive numerical results, we identify optimal\nsystem configurations encompassing aperture design and mode selection, leading\nto a capacity boost exceeding 200%.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Jinzhe Che",
            "Shenjie Hunag",
            "Majid Safari"
        ],
        "published": "2024-05-21T10:27:42Z"
    },
    {
        "title": "SYMPLEX: Controllable Symbolic Music Generation using Simplex Diffusion\n  with Vocabulary Priors",
        "link": "http://arxiv.org/abs/2405.12666v1",
        "abstract": "We present a new approach for fast and controllable generation of symbolic\nmusic based on the simplex diffusion, which is essentially a diffusion process\noperating on probabilities rather than the signal space. This objective has\nbeen applied in domains such as natural language processing but here we apply\nit to generating 4-bar multi-instrument music loops using an orderless\nrepresentation. We show that our model can be steered with vocabulary priors,\nwhich affords a considerable level control over the music generation process,\nfor instance, infilling in time and pitch and choice of instrumentation -- all\nwithout task-specific model adaptation or applying extrinsic control.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "authors": [
            "Nicolas Jonason",
            "Luca Casini",
            "Bob L. T. Sturm"
        ],
        "published": "2024-05-21T10:27:34Z"
    },
    {
        "title": "IREE Oriented Green 6G Networks: A Radial Basis Function Based Approach",
        "link": "http://arxiv.org/abs/2405.12664v1",
        "abstract": "In order to provide design guidelines for energy efficient 6G networks, we\npropose a novel radial basis function (RBF) based optimization framework to\nmaximize the integrated relative energy efficiency (IREE) metric. Different\nfrom the conventional energy efficient optimization schemes, we maximize the\ntransformed utility for any given IREE using spectrum efficiency oriented RBF\nnetwork and gradually update the IREE metric using proposed Dinkelbach's\nalgorithm. The existence and uniqueness properties of RBF networks are\nprovided, and the convergence conditions of the entire framework are discussed\nas well. Through some numerical experiments, we show that the proposed IREE\noutperforms many existing SE or EE oriented designs and find a new\nJensen-Shannon (JS) divergence constrained region, which behaves differently\nfrom the conventional EE-SE region. Meanwhile, by studying IREE-SE trade-offs\nunder different traffic requirements, we suggest that network operators shall\nspend more efforts to balance the distributions of traffic demands and network\ncapacities in order to improve the IREE performance, especially when the\nspatial variations of the traffic distribution are significant.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Tao Yu",
            "Pengbo Huang",
            "Shunqing Zhang",
            "Xiaojing Chen",
            "Yanzan Sun",
            "Xin Wang"
        ],
        "published": "2024-05-21T10:24:59Z"
    },
    {
        "title": "LAGA: Layered 3D Avatar Generation and Customization via Gaussian\n  Splatting",
        "link": "http://arxiv.org/abs/2405.12663v1",
        "abstract": "Creating and customizing a 3D clothed avatar from textual descriptions is a\ncritical and challenging task. Traditional methods often treat the human body\nand clothing as inseparable, limiting users' ability to freely mix and match\ngarments. In response to this limitation, we present LAyered Gaussian Avatar\n(LAGA), a carefully designed framework enabling the creation of high-fidelity\ndecomposable avatars with diverse garments. By decoupling garments from avatar,\nour framework empowers users to conviniently edit avatars at the garment level.\nOur approach begins by modeling the avatar using a set of Gaussian points\norganized in a layered structure, where each layer corresponds to a specific\ngarment or the human body itself. To generate high-quality garments for each\nlayer, we introduce a coarse-to-fine strategy for diverse garment generation\nand a novel dual-SDS loss function to maintain coherence between the generated\ngarments and avatar components, including the human body and other garments.\nMoreover, we introduce three regularization losses to guide the movement of\nGaussians for garment transfer, allowing garments to be freely transferred to\nvarious avatars. Extensive experimentation demonstrates that our approach\nsurpasses existing methods in the generation of 3D clothed humans.",
        "subjects": [
            "cs.GR",
            "cs.CV"
        ],
        "authors": [
            "Jia Gong",
            "Shenyu Ji",
            "Lin Geng Foo",
            "Kang Chen",
            "Hossein Rahmani",
            "Jun Liu"
        ],
        "published": "2024-05-21T10:24:06Z"
    },
    {
        "title": "EmoEdit: Evoking Emotions through Image Manipulation",
        "link": "http://arxiv.org/abs/2405.12661v1",
        "abstract": "Affective Image Manipulation (AIM) seeks to modify user-provided images to\nevoke specific emotional responses. This task is inherently complex due to its\ntwofold objective: significantly evoking the intended emotion, while preserving\nthe original image composition. Existing AIM methods primarily adjust color and\nstyle, often failing to elicit precise and profound emotional shifts. Drawing\non psychological insights, we extend AIM by incorporating content modifications\nto enhance emotional impact. We introduce EmoEdit, a novel two-stage framework\ncomprising emotion attribution and image editing. In the emotion attribution\nstage, we leverage a Vision-Language Model (VLM) to create hierarchies of\nsemantic factors that represent abstract emotions. In the image editing stage,\nthe VLM identifies the most relevant factors for the provided image, and guides\na generative editing model to perform affective modifications. A ranking\ntechnique that we developed selects the best edit, balancing between emotion\nfidelity and structure integrity. To validate EmoEdit, we assembled a dataset\nof 416 images, categorized into positive, negative, and neutral classes. Our\nmethod is evaluated both qualitatively and quantitatively, demonstrating\nsuperior performance compared to existing state-of-the-art techniques.\nAdditionally, we showcase EmoEdit's potential in various manipulation tasks,\nincluding emotion-oriented and semantics-oriented editing.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jingyuan Yang",
            "Jiawei Feng",
            "Weibin Luo",
            "Dani Lischinski",
            "Daniel Cohen-Or",
            "Hui Huang"
        ],
        "published": "2024-05-21T10:18:45Z"
    },
    {
        "title": "Mitigating Overconfidence in Out-of-Distribution Detection by Capturing\n  Extreme Activations",
        "link": "http://arxiv.org/abs/2405.12658v1",
        "abstract": "Detecting out-of-distribution (OOD) instances is crucial for the reliable\ndeployment of machine learning models in real-world scenarios. OOD inputs are\ncommonly expected to cause a more uncertain prediction in the primary task;\nhowever, there are OOD cases for which the model returns a highly confident\nprediction. This phenomenon, denoted as \"overconfidence\", presents a challenge\nto OOD detection. Specifically, theoretical evidence indicates that\noverconfidence is an intrinsic property of certain neural network\narchitectures, leading to poor OOD detection. In this work, we address this\nissue by measuring extreme activation values in the penultimate layer of neural\nnetworks and then leverage this proxy of overconfidence to improve on several\nOOD detection baselines. We test our method on a wide array of experiments\nspanning synthetic data and real-world data, tabular and image datasets,\nmultiple architectures such as ResNet and Transformer, different training loss\nfunctions, and include the scenarios examined in previous theoretical work.\nCompared to the baselines, our method often grants substantial improvements,\nwith double-digit increases in OOD detection AUC, and it does not damage\nperformance in any scenario.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Mohammad Azizmalayeri",
            "Ameen Abu-Hanna",
            "Giovanni Cinà"
        ],
        "published": "2024-05-21T10:14:50Z"
    },
    {
        "title": "Retrieval-Augmented Language Model for Extreme Multi-Label Knowledge\n  Graph Link Prediction",
        "link": "http://arxiv.org/abs/2405.12656v1",
        "abstract": "Extrapolation in Large language models (LLMs) for open-ended inquiry\nencounters two pivotal issues: (1) hallucination and (2) expensive training\ncosts. These issues present challenges for LLMs in specialized domains and\npersonalized data, requiring truthful responses and low fine-tuning costs.\nExisting works attempt to tackle the problem by augmenting the input of a\nsmaller language model with information from a knowledge graph (KG). However,\nthey have two limitations: (1) failing to extract relevant information from a\nlarge one-hop neighborhood in KG and (2) applying the same augmentation\nstrategy for KGs with different characteristics that may result in low\nperformance. Moreover, open-ended inquiry typically yields multiple responses,\nfurther complicating extrapolation. We propose a new task, the extreme\nmulti-label KG link prediction task, to enable a model to perform extrapolation\nwith multiple responses using structured real-world knowledge. Our retriever\nidentifies relevant one-hop neighbors by considering entity, relation, and\ntextual data together. Our experiments demonstrate that (1) KGs with different\ncharacteristics require different augmenting strategies, and (2) augmenting the\nlanguage model's input with textual data improves task performance\nsignificantly. By incorporating the retrieval-augmented framework with KG, our\nframework, with a small parameter size, is able to extrapolate based on a given\nKG. The code can be obtained on GitHub:\nhttps://github.com/exiled1143/Retrieval-Augmented-Language-Model-for-Multi-Label-Knowledge-Graph-Link-Prediction.git",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Yu-Hsiang Lin",
            "Huang-Ting Shieh",
            "Chih-Yu Liu",
            "Kuang-Ting Lee",
            "Hsiao-Cheng Chang",
            "Jing-Lun Yang",
            "Yu-Sheng Lin"
        ],
        "published": "2024-05-21T10:10:56Z"
    },
    {
        "title": "Lipschitz minimization and the Goldstein modulus",
        "link": "http://arxiv.org/abs/2405.12655v1",
        "abstract": "Goldstein's 1977 idealized iteration for minimizing a Lipschitz objective\nfixes a distance - the step size - and relies on a certain approximate\nsubgradient. That \"Goldstein subgradient\" is the shortest convex combination of\nobjective gradients at points within that distance of the current iterate. A\nrecent implementable Goldstein-style algorithm allows a remarkable complexity\nanalysis (Zhang et al. 2020), and a more sophisticated variant (Davis and\nJiang, 2022) leverages typical objective geometry to force near-linear\nconvergence. To explore such methods, we introduce a new modulus, based on\nGoldstein subgradients, that robustly measures the slope of a Lipschitz\nfunction. We relate near-linear convergence of Goldstein-style methods to\nlinear growth of this modulus at minimizers. We illustrate the idea\ncomputationally with a simple heuristic for Lipschitz minimization.",
        "subjects": [
            "math.OC",
            "cs.NA",
            "math.NA",
            "90C56, 49J52, 65Y20",
            "G.1.6"
        ],
        "authors": [
            "Siyu Kong",
            "Adrian S. Lewis"
        ],
        "published": "2024-05-21T10:08:12Z"
    },
    {
        "title": "Utilizing Description Logics for Global Explanations of Heterogeneous\n  Graph Neural Networks",
        "link": "http://arxiv.org/abs/2405.12654v1",
        "abstract": "Graph Neural Networks (GNNs) are effective for node classification in\ngraph-structured data, but they lack explainability, especially at the global\nlevel. Current research mainly utilizes subgraphs of the input as local\nexplanations or generates new graphs as global explanations. However, these\ngraph-based methods are limited in their ability to explain classes with\nmultiple sufficient explanations. To provide more expressive explanations, we\npropose utilizing class expressions (CEs) from the field of description logic\n(DL). Our approach explains heterogeneous graphs with different types of nodes\nusing CEs in the EL description logic. To identify the best explanation among\nmultiple candidate explanations, we employ and compare two different scoring\nfunctions: (1) For a given CE, we construct multiple graphs, have the GNN make\na prediction for each graph, and aggregate the predicted scores. (2) We score\nthe CE in terms of fidelity, i.e., we compare the predictions of the GNN to the\npredictions by the CE on a separate validation set. Instead of subgraph-based\nexplanations, we offer CE-based explanations.",
        "subjects": [
            "cs.AI",
            "cs.LO"
        ],
        "authors": [
            "Dominik Köhler",
            "Stefan Heindorf"
        ],
        "published": "2024-05-21T10:07:29Z"
    },
    {
        "title": "Edge Information Hub-Empowered 6G NTN: Latency-Oriented Resource\n  Orchestration and Configuration",
        "link": "http://arxiv.org/abs/2405.12652v1",
        "abstract": "Quick response to disasters is crucial for saving lives and reducing loss.\nThis requires low-latency uploading of situation information to the remote\ncommand center. Since terrestrial infrastructures are often damaged in disaster\nareas, non-terrestrial networks (NTNs) are preferable to provide network\ncoverage, and mobile edge computing (MEC) could be integrated to improve the\nlatency performance. Nevertheless, the communications and computing in\nMEC-enabled NTNs are strongly coupled, which complicates the system design. In\nthis paper, an edge information hub (EIH) that incorporates communication,\ncomputing and storage capabilities is proposed to synergize communication and\ncomputing and enable systematic design. We first address the joint data\nscheduling and resource orchestration problem to minimize the latency for\nuploading sensing data. The problem is solved using an optimal resource\norchestration algorithm. On that basis, we propose the principles for resource\nconfiguration of the EIH considering payload constraints on size, weight and\nenergy supply. Simulation results demonstrate the superiority of our proposed\nscheme in reducing the overall upload latency, thus enabling quick emergency\nrescue.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "authors": [
            "Yueshan Lin",
            "Wei Feng",
            "Yunfei Chen",
            "Ning Ge",
            "Zhiyong Feng",
            "Yue Gao"
        ],
        "published": "2024-05-21T10:02:55Z"
    },
    {
        "title": "Scene Graph Generation Strategy with Co-occurrence Knowledge and\n  Learnable Term Frequency",
        "link": "http://arxiv.org/abs/2405.12648v1",
        "abstract": "Scene graph generation (SGG) is an important task in image understanding\nbecause it represents the relationships between objects in an image as a graph\nstructure, making it possible to understand the semantic relationships between\nobjects intuitively. Previous SGG studies used a message-passing neural\nnetworks (MPNN) to update features, which can effectively reflect information\nabout surrounding objects. However, these studies have failed to reflect the\nco-occurrence of objects during SGG generation. In addition, they only\naddressed the long-tail problem of the training dataset from the perspectives\nof sampling and learning methods. To address these two problems, we propose\nCooK, which reflects the Co-occurrence Knowledge between objects, and the\nlearnable term frequency-inverse document frequency (TF-l-IDF) to solve the\nlong-tail problem. We applied the proposed model to the SGG benchmark dataset,\nand the results showed a performance improvement of up to 3.8% compared with\nexisting state-of-the-art models in SGGen subtask. The proposed method exhibits\ngeneralization ability from the results obtained, showing uniform performance\nimprovement for all MPNN models.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Hyeongjin Kim",
            "Sangwon Kim",
            "Dasom Ahn",
            "Jong Taek Lee",
            "Byoung Chul Ko"
        ],
        "published": "2024-05-21T09:56:48Z"
    },
    {
        "title": "PoseGravity: Pose Estimation from Points and Lines with Axis Prior",
        "link": "http://arxiv.org/abs/2405.12646v1",
        "abstract": "This paper presents a new algorithm to estimate absolute camera pose given an\naxis of the camera's rotation matrix. Current algorithms solve the problem via\nalgebraic solutions on limited input domains. This paper shows that the problem\ncan be solved efficiently by finding the intersection points of a hyperbola and\nthe unit circle. The solution can flexibly accommodate combinations of point\nand line features in minimal and overconstrained configurations. In addition,\nthe two special cases of planar and minimal configurations are identified to\nyield simpler closed-form solutions. Extensive experiments validate the\napproach.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Akshay Chandrasekhar"
        ],
        "published": "2024-05-21T09:55:56Z"
    },
    {
        "title": "Combining Twitter and Mobile Phone Data to Observe Border-Rush: The\n  Turkish-European Border Opening",
        "link": "http://arxiv.org/abs/2405.12642v2",
        "abstract": "Following Turkey's 2020 decision to revoke border controls, many individuals\njourneyed towards the Greek, Bulgarian, and Turkish borders. However, the lack\nof verifiable statistics on irregular migration and discrepancies between media\nreports and actual migration patterns require further exploration. The\nobjective of this study is to bridge this knowledge gap by harnessing novel\ndata sources, specifically mobile phone and Twitter data, to construct\nestimators of cross-border mobility and to cultivate a qualitative\ncomprehension of the unfolding events. By employing a migration diplomacy\nframework, we analyse emergent mobility patterns at the border. Our findings\ndemonstrate the potential of mobile phone data for quantitative metrics and\nTwitter data for qualitative understanding. We underscore the ethical\nimplications of leveraging Big Data, particularly considering the vulnerability\nof the population under study. This underscores the imperative for exhaustive\nresearch into the socio-political facets of human mobility, with the aim of\ndiscerning the potentialities, limitations, and risks inherent in these data\nsources and their integration. This scholarly endeavour contributes to a more\nnuanced understanding of migration dynamics and paves the way for the\nformulation of regulations that preclude misuse and oppressive surveillance,\nthereby ensuring a more accurate representation of migration realities.",
        "subjects": [
            "cs.SI",
            "cs.CY"
        ],
        "authors": [
            "Carlos Arcila Calderón",
            "Bilgeçağ Aydoğdu",
            "Tuba Bircan",
            "Bünyamin Gündüz",
            "Onur Önes",
            "Albert Ali Salah",
            "Alina Sîrbu"
        ],
        "published": "2024-05-21T09:51:15Z"
    },
    {
        "title": "Fight Fire with Fire: How Much Can We Trust ChatGPT on Source\n  Code-Related Tasks?",
        "link": "http://arxiv.org/abs/2405.12641v1",
        "abstract": "With the increasing utilization of large language models such as ChatGPT\nduring software development, it has become crucial to verify the quality of\ncode content it generates. Recent studies proposed utilizing ChatGPT as both a\ndeveloper and tester for multi-agent collaborative software development. The\nmulti-agent collaboration empowers ChatGPT to produce test reports for its\ngenerated code, enabling it to self-verify the code content and fix bugs based\non these reports. However, these studies did not assess the effectiveness of\nthe generated test reports in validating the code. Therefore, we conduct a\ncomprehensive empirical investigation to evaluate ChatGPT's self-verification\ncapability in code generation, code completion, and program repair. We request\nChatGPT to (1) generate correct code and then self-verify its correctness; (2)\ncomplete code without vulnerabilities and then self-verify for the presence of\nvulnerabilities; and (3) repair buggy code and then self-verify whether the\nbugs are resolved. Our findings on two code generation datasets, one code\ncompletion dataset, and two program repair datasets reveal the following\nobservations: (1) ChatGPT often erroneously predicts its generated incorrect\ncode as correct. (2) The self-contradictory hallucinations in ChatGPT's\nbehavior arise. (3) The self-verification capability of ChatGPT can be enhanced\nby asking the guiding question, which queries whether ChatGPT agrees with\nassertions about incorrectly generated or repaired code and vulnerabilities in\ncompleted code. (4) Using test reports generated by ChatGPT can identify more\nvulnerabilities in completed code, but the explanations for incorrectly\ngenerated code and failed repairs are mostly inaccurate in the test reports.\nBased on these findings, we provide implications for further research or\ndevelopment using ChatGPT.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Xiao Yu",
            "Lei Liu",
            "Xing Hu",
            "Jacky Wai Keung",
            "Jin Liu",
            "Xin Xia"
        ],
        "published": "2024-05-21T09:47:33Z"
    },
    {
        "title": "Self-Determination Theory and HCI Games Research: Unfulfilled Promises\n  and Unquestioned Paradigms",
        "link": "http://arxiv.org/abs/2405.12639v1",
        "abstract": "Self-determination theory (SDT), a psychological theory of human motivation,\nis a prominent paradigm in human-computer interaction (HCI) research on games.\nHowever, our prior literature review observed a trend towards shallow\napplications of the theory. This follow-up work takes a broader view --\nexamining SDT scholarship on games, a wider corpus of SDT-based HCI games\nresearch (N=259), and perspectives from a games industry practitioner\nconference -- to help explain current applications of SDT. Our findings suggest\nthat perfunctory applications of the theory in HCI games research originate in\npart from within SDT scholarship on games, which itself exhibits limited\nengagement with theoretical tenets. Against this backdrop, we unpack the\npopularity of SDT in HCI games research and identify conditions underlying the\ntheory's current use as an oft-unquestioned paradigm. Finally, we outline\navenues for more productive SDT-informed games research and consider ways\ntowards more intentional practices of theory use in HCI.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "April Tyack",
            "Elisa D. Mekler"
        ],
        "published": "2024-05-21T09:44:11Z"
    },
    {
        "title": "Multiscale lubrication simulation based on fourier feature networks with\n  trainable frequency",
        "link": "http://arxiv.org/abs/2405.12638v1",
        "abstract": "Rough surface lubrication simulation is crucial for designing and optimizing\ntribological performance. Despite the growing application of Physical\nInformation Neural Networks (PINNs) in hydrodynamic lubrication analysis, their\nuse has been primarily limited to smooth surfaces. This is due to traditional\nPINN methods suffer from spectral bias, favoring to learn low-frequency\nfeatures and thus failing to analyze rough surfaces with high-frequency\nsignals. To date, no PINN methods have been reported for rough surface\nlubrication. To overcome these limitations, this work introduces a novel\nmulti-scale lubrication neural network architecture that utilizes a trainable\nFourier feature network. By incorporating learnable feature embedding\nfrequencies, this architecture automatically adapts to various frequency\ncomponents, thereby enhancing the analysis of rough surface characteristics.\nThis method has been tested across multiple surface morphologies, and the\nresults have been compared with those obtained using the finite element method\n(FEM). The comparative analysis demonstrates that this approach achieves a high\nconsistency with FEM results. Furthermore, this novel architecture surpasses\ntraditional Fourier feature networks with fixed feature embedding frequencies\nin both accuracy and computational efficiency. Consequently, the multi-scale\nlubrication neural network model offers a more efficient tool for rough surface\nlubrication analysis.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yihu Tang",
            "Li Huang",
            "Limin Wu",
            "Xianghui Meng"
        ],
        "published": "2024-05-21T09:41:56Z"
    },
    {
        "title": "TempoScale: A Cloud Workloads Prediction Approach Integrating Short-Term\n  and Long-Term Information",
        "link": "http://arxiv.org/abs/2405.12635v1",
        "abstract": "Cloud native solutions are widely applied in various fields, placing higher\ndemands on the efficient management and utilization of resource platforms. To\nachieve the efficiency, load forecasting and elastic scaling have become\ncrucial technologies for dynamically adjusting cloud resources to meet user\ndemands and minimizing resource waste. However, existing prediction-based\nmethods lack comprehensive analysis and integration of load characteristics\nacross different time scales. For instance, long-term trend analysis helps\nreveal long-term changes in load and resource demand, thereby supporting\nproactive resource allocation over longer periods, while short-term volatility\nanalysis can examine short-term fluctuations in load and resource demand,\nproviding support for real-time scheduling and rapid response. In response to\nthis, our research introduces TempoScale, which aims to enhance the\ncomprehensive understanding of temporal variations in cloud workloads, enabling\nmore intelligent and adaptive decision-making for elastic scaling. TempoScale\nutilizes the Complete Ensemble Empirical Mode Decomposition with Adaptive Noise\nalgorithm to decompose time-series load data into multiple Intrinsic Mode\nFunctions (IMF) and a Residual Component (RC). First, we integrate the IMF,\nwhich represents both long-term trends and short-term fluctuations, into the\ntime series prediction model to obtain intermediate results. Then, these\nintermediate results, along with the RC, are transferred into a fully connected\nlayer to obtain the final result. Finally, this result is fed into the resource\nmanagement system based on Kubernetes for resource scaling. Our proposed\napproach can reduce the Mean Square Error by 5.80% to 30.43% compared to the\nbaselines, and reduce the average response time by 5.58% to 31.15%.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Linfeng Wen",
            "Minxian Xu",
            "Adel N. Toosi",
            "Kejiang Ye"
        ],
        "published": "2024-05-21T09:39:55Z"
    },
    {
        "title": "Visuo-Tactile based Predictive Cross Modal Perception for Object\n  Exploration in Robotics",
        "link": "http://arxiv.org/abs/2405.12634v2",
        "abstract": "Autonomously exploring the unknown physical properties of novel objects such\nas stiffness, mass, center of mass, friction coefficient, and shape is crucial\nfor autonomous robotic systems operating continuously in unstructured\nenvironments. We introduce a novel visuo-tactile based predictive cross-modal\nperception framework where initial visual observations (shape) aid in obtaining\nan initial prior over the object properties (mass). The initial prior improves\nthe efficiency of the object property estimation, which is autonomously\ninferred via interactive non-prehensile pushing and using a dual filtering\napproach. The inferred properties are then used to enhance the predictive\ncapability of the cross-modal function efficiently by using a human-inspired\n`surprise' formulation. We evaluated our proposed framework in the real-robotic\nscenario, demonstrating superior performance.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Anirvan Dutta",
            "Etienne Burdet",
            "Mohsen Kaboli"
        ],
        "published": "2024-05-21T09:39:14Z"
    },
    {
        "title": "Automating Attendance Management in Human Resources: A Design Science\n  Approach Using Computer Vision and Facial Recognition",
        "link": "http://arxiv.org/abs/2405.12633v1",
        "abstract": "Haar Cascade is a cost-effective and user-friendly machine learning-based\nalgorithm for detecting objects in images and videos. Unlike Deep Learning\nalgorithms, which typically require significant resources and expensive\ncomputing costs, it uses simple image processing techniques like edge detection\nand Haar features that are easy to comprehend and implement. By combining Haar\nCascade with OpenCV2 on an embedded computer like the NVIDIA Jetson Nano, this\nsystem can accurately detect and match faces in a database for attendance\ntracking. This system aims to achieve several specific objectives that set it\napart from existing solutions. It leverages Haar Cascade, enriched with\ncarefully selected Haar features, such as Haar-like wavelets, and employs\nadvanced edge detection techniques. These techniques enable precise face\ndetection and matching in both images and videos, contributing to high accuracy\nand robust performance. By doing so, it minimizes manual intervention and\nreduces errors, thereby strengthening accountability. Additionally, the\nintegration of OpenCV2 and the NVIDIA Jetson Nano optimizes processing\nefficiency, making it suitable for resource-constrained environments. This\nsystem caters to a diverse range of educational institutions, including\nschools, colleges, vocational training centers, and various workplace settings\nsuch as small businesses, offices, and factories. ... The system's\naffordability and efficiency democratize attendance management technology,\nmaking it accessible to a broader audience. Consequently, it has the potential\nto transform attendance tracking and management practices, ultimately leading\nto heightened productivity and accountability. In conclusion, this system\nrepresents a groundbreaking approach to attendance tracking and management...",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.AR",
            "cs.HC",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Bao-Thien Nguyen-Tat",
            "Minh-Quoc Bui",
            "Vuong M. Ngo"
        ],
        "published": "2024-05-21T09:38:56Z"
    },
    {
        "title": "Exploration of Masked and Causal Language Modelling for Text Generation",
        "link": "http://arxiv.org/abs/2405.12630v1",
        "abstract": "Large Language Models (LLMs) have revolutionised the field of Natural\nLanguage Processing (NLP) and have achieved state-of-the-art performance in\npractically every task in this field. However, the prevalent approach used in\ntext generation, Causal Language Modelling (CLM), which generates text\nsequentially from left to right, inherently limits the freedom of the model,\nwhich does not decide when and where each token is generated. In contrast,\nMasked Language Modelling (MLM), primarily used for language understanding\ntasks, can generate tokens anywhere in the text and any order. This paper\nconducts an extensive comparison of MLM and CLM approaches for text generation\ntasks. To do so, we pre-train several language models of comparable sizes on\nthree different datasets, namely 1) medical discharge summaries, 2) movie plot\nsynopses, and 3) authorship verification datasets. To assess the quality of the\ngenerations, we first employ quantitative metrics and then perform a\nqualitative human evaluation to analyse coherence and grammatical correctness.\nIn addition, we evaluate the usefulness of the generated texts by using them in\nthree different downstream tasks: 1) Entity Recognition, 2) Text\nClassification, and 3) Authorship Verification. The results show that MLM\nconsistently outperforms CLM in text generation across all datasets, with\nhigher quantitative scores and better coherence in the generated text. The\nstudy also finds \\textit{no strong correlation} between the quality of the\ngenerated text and the performance of the models in the downstream tasks. With\nthis study, we show that MLM for text generation has great potential for future\nresearch and provides direction for future studies in this area.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Nicolo Micheletti",
            "Samuel Belkadi",
            "Lifeng Han",
            "Goran Nenadic"
        ],
        "published": "2024-05-21T09:33:31Z"
    },
    {
        "title": "A Local Gaussian Process Regression Approach to Frequency Response\n  Function Estimation",
        "link": "http://arxiv.org/abs/2405.12629v1",
        "abstract": "Frequency response function (FRF) estimation is a classical subject in system\nidentification. In the past two decades, there have been remarkable advances in\ndeveloping local methods for this subject, e.g., the local polynomial method,\nlocal rational method, and iterative local rational method. The recent\nconcentrations for local methods are two issues: the model order selection and\nthe identification of lightly damped systems. To address these two issues, we\npropose a new local method called local Gaussian process regression (LGPR). We\nshow that the frequency response function locally is either analytic or\nresonant, and this prior knowledge can be embedded into a kernel-based\nregularized estimate through a dot-product kernel plus a resonance kernel\ninduced by a second-order resonant system. The LGPR provides a new route to\ntackle the aforementioned issues. In the numerical simulations, the LGPR shows\nthe best FRF estimation accuracy compared with the existing local methods, and\nmoreover, the LGPR is more robust with respect to sample size and noise level.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Xiaozhu Fang",
            "Yu Xu",
            "Tianshi Chen"
        ],
        "published": "2024-05-21T09:31:23Z"
    },
    {
        "title": "Play Everywhere: A Temporal Logic based Game Environment Independent\n  Approach for Playing Soccer with Robots",
        "link": "http://dx.doi.org/10.1007/978-3-031-55015-7_1",
        "abstract": "Robots playing soccer often rely on hard-coded behaviors that struggle to\ngeneralize when the game environment change. In this paper, we propose a\ntemporal logic based approach that allows robots' behaviors and goals to adapt\nto the semantics of the environment. In particular, we present a hierarchical\nrepresentation of soccer in which the robot selects the level of operation\nbased on the perceived semantic characteristics of the environment, thus\nmodifying dynamically the set of rules and goals to apply. The proposed\napproach enables the robot to operate in unstructured environments, just as it\nhappens when humans go from soccer played on an official field to soccer played\non a street. Three different use cases set in different scenarios are presented\nto demonstrate the effectiveness of the proposed approach.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "authors": [
            "Vincenzo Suriani",
            "Emanuele Musumeci",
            "Daniele Nardi",
            "Domenico Daniele Bloisi"
        ],
        "published": "2024-05-21T09:30:47Z"
    },
    {
        "title": "Deep ReLU Neural Network Emulation in High-Frequency Acoustic Scattering",
        "link": "http://arxiv.org/abs/2405.12624v1",
        "abstract": "We obtain wavenumber-robust error bounds for the deep neural network (DNN)\nemulation of the solution to the time-harmonic, sound-soft acoustic scattering\nproblem in the exterior of a smooth, convex obstacle in two physical\ndimensions. The error bounds are based on a boundary reduction of the\nscattering problem in the unbounded exterior region to its smooth, curved\nboundary $\\Gamma$ using the so-called combined field integral equation (CFIE),\na well-posed, second-kind boundary integral equation (BIE) for the field's\nNeumann datum on $\\Gamma$. In this setting, the continuity and stability\nconstants of this formulation are explicit in terms of the (non-dimensional)\nwavenumber $\\kappa$. Using wavenumber-explicit asymptotics of the problem's\nNeumann datum, we analyze the DNN approximation rate for this problem. We use\nfully connected NNs of the feed-forward type with Rectified Linear Unit (ReLU)\nactivation. Through a constructive argument we prove the existence of DNNs with\nan $\\epsilon$-error bound in the $L^\\infty(\\Gamma)$-norm having a small, fixed\nwidth and a depth that increases $\\textit{spectrally}$ with the target accuracy\n$\\epsilon>0$. We show that for fixed $\\epsilon>0$, the depth of these NNs\nshould increase $\\textit{poly-logarithmically}$ with respect to the wavenumber\n$\\kappa$ whereas the width of the NN remains fixed. Unlike current\ncomputational approaches, such as wavenumber-adapted versions of the Galerkin\nBoundary Element Method (BEM) with shape- and wavenumber-tailored solution\n$\\textit{ansatz}$ spaces, our DNN approximations do not require any prior\nanalytic information about the scatterer's shape.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Fernando Henríquez",
            "Christoph Schwab"
        ],
        "published": "2024-05-21T09:25:58Z"
    },
    {
        "title": "Limits of Theory of Mind Modelling in Dialogue-Based Collaborative Plan\n  Acquisition",
        "link": "http://arxiv.org/abs/2405.12621v1",
        "abstract": "Recent work on dialogue-based collaborative plan acquisition (CPA) has\nsuggested that Theory of Mind (ToM) modelling can improve missing knowledge\nprediction in settings with asymmetric skill-sets and knowledge. Although ToM\nwas claimed to be important for effective collaboration, its real impact on\nthis novel task remains under-explored. By representing plans as graphs and by\nexploiting task-specific constraints we show that, as performance on CPA nearly\ndoubles when predicting one's own missing knowledge, the improvements due to\nToM modelling diminish. This phenomenon persists even when evaluating existing\nbaseline methods. To better understand the relevance of ToM for CPA, we report\na principled performance comparison of models with and without ToM features.\nResults across different models and ablations consistently suggest that learned\nToM features are indeed more likely to reflect latent patterns in the data with\nno perceivable link to ToM. This finding calls for a deeper understanding of\nthe role of ToM in CPA and beyond, as well as new methods for modelling and\nevaluating mental states in computational collaborative agents.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Matteo Bortoletto",
            "Constantin Ruhdorfer",
            "Adnen Abdessaied",
            "Lei Shi",
            "Andreas Bulling"
        ],
        "published": "2024-05-21T09:23:39Z"
    },
    {
        "title": "MentalQA: An Annotated Arabic Corpus for Questions and Answers of Mental\n  Healthcare",
        "link": "http://arxiv.org/abs/2405.12619v1",
        "abstract": "Mental health disorders significantly impact people globally, regardless of\nbackground, education, or socioeconomic status. However, access to adequate\ncare remains a challenge, particularly for underserved communities with limited\nresources. Text mining tools offer immense potential to support mental\nhealthcare by assisting professionals in diagnosing and treating patients. This\nstudy addresses the scarcity of Arabic mental health resources for developing\nsuch tools. We introduce MentalQA, a novel Arabic dataset featuring\nconversational-style question-and-answer (QA) interactions. To ensure data\nquality, we conducted a rigorous annotation process using a well-defined schema\nwith quality control measures. Data was collected from a question-answering\nmedical platform. The annotation schema for mental health questions and\ncorresponding answers draws upon existing classification schemes with some\nmodifications. Question types encompass six distinct categories: diagnosis,\ntreatment, anatomy \\& physiology, epidemiology, healthy lifestyle, and provider\nchoice. Answer strategies include information provision, direct guidance, and\nemotional support. Three experienced annotators collaboratively annotated the\ndata to ensure consistency. Our findings demonstrate high inter-annotator\nagreement, with Fleiss' Kappa of $0.61$ for question types and $0.98$ for\nanswer strategies. In-depth analysis revealed insightful patterns, including\nvariations in question preferences across age groups and a strong correlation\nbetween question types and answer strategies. MentalQA offers a valuable\nfoundation for developing Arabic text mining tools capable of supporting mental\nhealth professionals and individuals seeking information.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Hassan Alhuzali",
            "Ashwag Alasmari",
            "Hamad Alsaleh"
        ],
        "published": "2024-05-21T09:16:38Z"
    },
    {
        "title": "Quantifying Emergence in Large Language Models",
        "link": "http://arxiv.org/abs/2405.12617v1",
        "abstract": "Emergence, broadly conceptualized as the ``intelligent'' behaviors of LLMs,\nhas recently been studied and proved challenging to quantify due to the lack of\na measurable definition. Most commonly, it has been estimated statistically\nthrough model performances across extensive datasets and tasks, which consumes\nsignificant resources. In addition, such estimation is difficult to interpret\nand may not accurately reflect the models' intrinsic emergence. In this work,\nwe propose a quantifiable solution for estimating emergence. Inspired by\nemergentism in dynamics, we quantify the strength of emergence by comparing the\nentropy reduction of the macroscopic (semantic) level with that of the\nmicroscopic (token) level, both of which are derived from the representations\nwithin the transformer block. Using a low-cost estimator, our quantification\nmethod demonstrates consistent behaviors across a suite of LMs (GPT-2, GEMMA,\netc.) under both in-context learning (ICL) and natural sentences. Empirical\nresults show that (1) our method gives consistent measurements which align with\nexisting observations based on performance metrics, validating the\neffectiveness of our emergence quantification; (2) our proposed metric uncovers\nnovel emergence patterns such as the correlations between the variance of our\nmetric and the number of ``shots'' in ICL, which further suggests a new way of\ninterpreting hallucinations in LLMs; (3) we offer a potential solution towards\nestimating the emergence of larger and closed-resource LMs via smaller LMs like\nGPT-2. Our codes are available at:\nhttps://github.com/Zodiark-ch/Emergence-of-LLMs/.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Hang Chen",
            "Xinyu Yang",
            "Jiaying Zhu",
            "Wenya Wang"
        ],
        "published": "2024-05-21T09:12:20Z"
    },
    {
        "title": "Towards Using Fast Embedded Model Predictive Control for Human-Aware\n  Predictive Robot Navigation",
        "link": "http://arxiv.org/abs/2405.12616v1",
        "abstract": "Predictive planning is a key capability for robots to efficiently and safely\nnavigate populated environments. Particularly in densely crowded scenes, with\nuncertain human motion predictions, predictive path planning, and control can\nbecome expensive to compute in real time due to the curse of dimensionality.\nWith the goal of achieving pro-active and legible robot motion in shared\nenvironments, in this paper we present HuMAN-MPC, a computationally efficient\nalgorithm for Human Motion Aware Navigation using fast embedded Model\nPredictive Control. The approach consists of a novel model predictive control\n(MPC) formulation that leverages a fast state-of-the-art optimization backend\nbased on a sequential quadratic programming real-time iteration scheme while\nalso providing feasibility monitoring. Our experiments, in simulation and on a\nfully integrated ROS-based platform, show that the approach achieves great\nscalability with fast computation times without penalizing path quality and\nefficiency of the resulting avoidance behavior.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Till Hielscher",
            "Lukas Heuer",
            "Frederik Wulle",
            "Luigi Palmieri"
        ],
        "published": "2024-05-21T09:12:16Z"
    },
    {
        "title": "Learning Causal Dynamics Models in Object-Oriented Environments",
        "link": "http://arxiv.org/abs/2405.12615v1",
        "abstract": "Causal dynamics models (CDMs) have demonstrated significant potential in\naddressing various challenges in reinforcement learning. To learn CDMs, recent\nstudies have performed causal discovery to capture the causal dependencies\namong environmental variables. However, the learning of CDMs is still confined\nto small-scale environments due to computational complexity and sample\nefficiency constraints. This paper aims to extend CDMs to large-scale\nobject-oriented environments, which consist of a multitude of objects\nclassified into different categories. We introduce the Object-Oriented CDM\n(OOCDM) that shares causalities and parameters among objects belonging to the\nsame class. Furthermore, we propose a learning method for OOCDM that enables it\nto adapt to a varying number of objects. Experiments on large-scale tasks\nindicate that OOCDM outperforms existing CDMs in terms of causal discovery,\nprediction accuracy, generalization, and computational efficiency.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Zhongwei Yu",
            "Jingqing Ruan",
            "Dengpeng Xing"
        ],
        "published": "2024-05-21T09:10:51Z"
    },
    {
        "title": "Tagengo: A Multilingual Chat Dataset",
        "link": "http://arxiv.org/abs/2405.12612v1",
        "abstract": "Open source large language models (LLMs) have shown great improvements in\nrecent times. However, many of these models are focused solely on popular\nspoken languages. We present a high quality dataset of more than 70k\nprompt-response pairs in 74 languages which consist of human generated prompts\nand synthetic responses. We use this dataset to train a state-of-the-art open\nsource English LLM to chat multilingually. We evaluate our model on MT-Bench\nchat benchmarks in 6 languages, finding that our multilingual model outperforms\nprevious state-of-the-art open source LLMs across each language. We further\nfind that training on more multilingual data is beneficial to the performance\nin a chosen target language (Japanese) compared to simply training on only data\nin that language. These results indicate the necessity of training on large\namounts of high quality multilingual data to make a more accessible LLM.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Peter Devine"
        ],
        "published": "2024-05-21T09:06:36Z"
    },
    {
        "title": "Mamba in Speech: Towards an Alternative to Self-Attention",
        "link": "http://arxiv.org/abs/2405.12609v3",
        "abstract": "Transformer and its derivatives have achieved success in diverse tasks across\ncomputer vision, natural language processing, and speech processing. To reduce\nthe complexity of computations within the multi-head self-attention mechanism\nin Transformer, Selective State Space Models (i.e., Mamba) were proposed as an\nalternative. Mamba exhibited its effectiveness in natural language processing\nand computer vision tasks, but its superiority has rarely been investigated in\nspeech signal processing. This paper explores solutions for applying Mamba to\nspeech processing using two typical speech processing tasks: speech\nrecognition, which requires semantic and sequential information, and speech\nenhancement, which focuses primarily on sequential patterns. The experimental\nresults exhibit the superiority of bidirectional Mamba (BiMamba) for speech\nprocessing to vanilla Mamba. Moreover, experiments demonstrate the\neffectiveness of BiMamba as an alternative to the self-attention module in\nTransformer and its derivates, particularly for the semantic-aware task. The\ncrucial technologies for transferring Mamba to speech are then summarized in\nablation studies and the discussion section to offer insights for future\nresearch.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "authors": [
            "Xiangyu Zhang",
            "Qiquan Zhang",
            "Hexin Liu",
            "Tianyi Xiao",
            "Xinyuan Qian",
            "Beena Ahmed",
            "Eliathamby Ambikairajah",
            "Haizhou Li",
            "Julien Epps"
        ],
        "published": "2024-05-21T09:04:48Z"
    },
    {
        "title": "S3O: A Dual-Phase Approach for Reconstructing Dynamic Shape and Skeleton\n  of Articulated Objects from Single Monocular Video",
        "link": "http://arxiv.org/abs/2405.12607v1",
        "abstract": "Reconstructing dynamic articulated objects from a singular monocular video is\nchallenging, requiring joint estimation of shape, motion, and camera parameters\nfrom limited views. Current methods typically demand extensive computational\nresources and training time, and require additional human annotations such as\npredefined parametric models, camera poses, and key points, limiting their\ngeneralizability. We propose Synergistic Shape and Skeleton Optimization (S3O),\na novel two-phase method that forgoes these prerequisites and efficiently\nlearns parametric models including visible shapes and underlying skeletons.\nConventional strategies typically learn all parameters simultaneously, leading\nto interdependencies where a single incorrect prediction can result in\nsignificant errors. In contrast, S3O adopts a phased approach: it first focuses\non learning coarse parametric models, then progresses to motion learning and\ndetail addition. This method substantially lowers computational complexity and\nenhances robustness in reconstruction from limited viewpoints, all without\nrequiring additional annotations. To address the current inadequacies in 3D\nreconstruction from monocular video benchmarks, we collected the PlanetZoo\ndataset. Our experimental evaluations on standard benchmarks and the PlanetZoo\ndataset affirm that S3O provides more accurate 3D reconstruction, and plausible\nskeletons, and reduces the training time by approximately 60% compared to the\nstate-of-the-art, thus advancing the state of the art in dynamic object\nreconstruction.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hao Zhang",
            "Fang Li",
            "Samyak Rawlekar",
            "Narendra Ahuja"
        ],
        "published": "2024-05-21T09:01:00Z"
    },
    {
        "title": "Tiny Refinements Elicit Resilience: Toward Efficient Prefix-Model\n  Against LLM Red-Teaming",
        "link": "http://arxiv.org/abs/2405.12604v1",
        "abstract": "With the proliferation of red-teaming strategies for Large Language Models\n(LLMs), the deficiency in the literature about improving the safety and\nrobustness of LLM defense strategies is becoming increasingly pronounced. This\npaper introduces the LLM-based \\textbf{sentinel} model as a plug-and-play\nprefix module designed to reconstruct the input prompt with just a few ($<30$)\nadditional tokens, effectively reducing toxicity in responses from target LLMs.\nThe sentinel model naturally overcomes the \\textit{parameter inefficiency} and\n\\textit{limited model accessibility} for fine-tuning large target models. We\nemploy an interleaved training regimen using Proximal Policy Optimization (PPO)\nto optimize both red team and sentinel models dynamically, incorporating a\nvalue head-sharing mechanism inspired by the multi-agent centralized critic to\nmanage the complex interplay between agents. Our extensive experiments across\ntext-to-text and text-to-image demonstrate the effectiveness of our approach in\nmitigating toxic outputs, even when dealing with larger models like\n\\texttt{Llama-2}, \\texttt{GPT-3.5} and \\texttt{Stable-Diffusion}, highlighting\nthe potential of our framework in enhancing safety and robustness in various\napplications.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Jiaxu Liu",
            "Xiangyu Yin",
            "Sihao Wu",
            "Jianhong Wang",
            "Meng Fang",
            "Xinping Yi",
            "Xiaowei Huang"
        ],
        "published": "2024-05-21T08:57:44Z"
    },
    {
        "title": "FFAM: Feature Factorization Activation Map for Explanation of 3D\n  Detectors",
        "link": "http://arxiv.org/abs/2405.12601v1",
        "abstract": "LiDAR-based 3D object detection has made impressive progress recently, yet\nmost existing models are black-box, lacking interpretability. Previous\nexplanation approaches primarily focus on analyzing image-based models and are\nnot readily applicable to LiDAR-based 3D detectors. In this paper, we propose a\nfeature factorization activation map (FFAM) to generate high-quality visual\nexplanations for 3D detectors. FFAM employs non-negative matrix factorization\nto generate concept activation maps and subsequently aggregates these maps to\nobtain a global visual explanation. To achieve object-specific visual\nexplanations, we refine the global visual explanation using the feature\ngradient of a target object. Additionally, we introduce a voxel upsampling\nstrategy to align the scale between the activation map and input point cloud.\nWe qualitatively and quantitatively analyze FFAM with multiple detectors on\nseveral datasets. Experimental results validate the high-quality visual\nexplanations produced by FFAM. The Code will be available at\n\\url{https://github.com/Say2L/FFAM.git}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Shuai Liu",
            "Boyang Li",
            "Zhiyu Fang",
            "Mingyue Cui",
            "Kai Huang"
        ],
        "published": "2024-05-21T08:55:10Z"
    },
    {
        "title": "A Weeding Robot for Seedling Removal",
        "link": "http://arxiv.org/abs/2405.12596v1",
        "abstract": "Automatic weeding technologies have attained a lot of attention lately,\nbecause of the harms and challenges weeds are causing for livestock farming, in\naddition to that weeds reduce yields. We are targeting automatic and mechanical\nRumex weeding in open pasture fields using light weight mobile field robot\ntechnologies. We describe a mobile weeding robot with GNSS navigation, 3D\ncomputer vision for weed detection, and a robot arm with a mechanical weeding\ntool. Our main contribution is showing the feasibility of light weight robot,\nsensor, and tool technologies in mechanical removal of weed seedlings.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Jarkko Kotaniemi",
            "Niko Känsäkoski",
            "Tapio Heikkilä"
        ],
        "published": "2024-05-21T08:39:09Z"
    },
    {
        "title": "Unlocking Data-free Low-bit Quantization with Matrix Decomposition for\n  KV Cache Compression",
        "link": "http://arxiv.org/abs/2405.12591v1",
        "abstract": "Key-value~(KV) caching is an important technique to accelerate the inference\nof large language models~(LLMs), but incurs significant memory overhead. To\ncompress the size of KV cache, existing methods often compromise precision or\nrequire extra data for calibration, limiting their practicality in LLM\ndeployment. In this paper, we introduce \\textbf{DecoQuant}, a novel data-free\nlow-bit quantization technique based on tensor decomposition methods, to\neffectively compress KV cache. Our core idea is to adjust the outlier\ndistribution of the original matrix by performing tensor decomposition, so that\nthe quantization difficulties are migrated from the matrix to decomposed local\ntensors. Specially, we find that outliers mainly concentrate on small local\ntensors, while large tensors tend to have a narrower value range. Based on this\nfinding, we propose to apply low-bit quantization to the large tensor, while\nmaintaining high-precision representation for the small tensor. Furthermore, we\nutilize the proposed quantization method to compress the KV cache of LLMs to\naccelerate the inference and develop an efficient dequantization kernel\ntailored specifically for DecoQuant. Through extensive experiments, DecoQuant\ndemonstrates remarkable efficiency gains, showcasing up to a $\\sim$75\\%\nreduction in memory footprint while maintaining comparable generation quality.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Peiyu Liu",
            "Ze-Feng Gao",
            "Wayne Xin Zhao",
            "Yipeng Ma",
            "Tao Wang",
            "Ji-Rong Wen"
        ],
        "published": "2024-05-21T08:35:10Z"
    },
    {
        "title": "Maverick-Aware Shapley Valuation for Client Selection in Federated\n  Learning",
        "link": "http://arxiv.org/abs/2405.12590v1",
        "abstract": "Federated Learning (FL) allows clients to train a model collaboratively\nwithout sharing their private data. One key challenge in practical FL systems\nis data heterogeneity, particularly in handling clients with rare data, also\nreferred to as Mavericks. These clients own one or more data classes\nexclusively, and the model performance becomes poor without their\nparticipation. Thus, utilizing Mavericks throughout training is crucial. In\nthis paper, we first design a Maverick-aware Shapley valuation that fairly\nevaluates the contribution of Mavericks. The main idea is to compute the\nclients' Shapley values (SV) class-wise, i.e., per label. Next, we propose\nFedMS, a Maverick-Shapley client selection mechanism for FL that intelligently\nselects the clients that contribute the most in each round, by employing our\nMaverick-aware SV-based contribution score. We show that, compared to an\nextensive list of baselines, FedMS achieves better model performance and fairer\nShapley Rewards distribution.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "authors": [
            "Mengwei Yang",
            "Ismat Jarin",
            "Baturalp Buyukates",
            "Salman Avestimehr",
            "Athina Markopoulou"
        ],
        "published": "2024-05-21T08:34:39Z"
    },
    {
        "title": "An Improved Robust Total Logistic Distance Metric algorithm for\n  Generalized Gaussian Noise and Noisy Input",
        "link": "http://arxiv.org/abs/2405.12589v1",
        "abstract": "Although the known maximum total generalized correntropy (MTGC) and\ngeneralized maximum blakezisserman total correntropy (GMBZTC) algorithms can\nmaintain good performance under the errors-in-variables (EIV) model disrupted\nby generalized Gaussian noise, their requirement for manual ad-justment of\nparameters is excessive, greatly increasing the practical difficulty of use. To\nsolve this problem, the total arctangent based on logical distance metric\n(TACLDM) algo-rithm is proposed by utilizing the advantage of few parameters in\nlogical distance metric (LDM) theory and the convergence behavior is improved\nby the arctangent function. Compared with other competing algorithms, the\nTACLDM algorithm not only has fewer parameters, but also has better robustness\nto generalized Gaussian noise and significantly reduces the steady-state error.\nFurthermore, the analysis of the algorithm in the generalized Gaussian noise\nenvironment is analyzed in detail in this paper. Finally, computer simulations\ndemonstrate the outstanding performance of the TACLDM algorithm and the\nrigorous theoretical deduction in this paper.",
        "subjects": [
            "eess.SP",
            "cs.SY",
            "eess.SY",
            "94",
            "C.2; F.2; H.4"
        ],
        "authors": [
            "Haiquan Zhao",
            "Yi Peng",
            "Zian Cao"
        ],
        "published": "2024-05-21T08:32:59Z"
    },
    {
        "title": "Reduction Strategies in the Lambda Calculus and Their Implementation\n  through Derivable Abstract Machines: Introduction",
        "link": "http://arxiv.org/abs/2405.12586v1",
        "abstract": "The lambda calculus since more than half a century is a model and foundation\nof functional programming languages. However, lambda expressions can be\nevaluated with different reduction strategies and thus, there is no fixed cost\nmodel nor one canonical implementation for all applications of the lambda\ncalculus.\n  This article is an introduction to a dissertation is composed of four\nconference papers where: we present a systematic survey of reduction strategies\nof the lambda calculus; we take advantage of the functional correspondence as a\ntool for studying implementations of the lambda calculus by deriving an\nabstract machine for a precisely identified strong call-by-value reduction\nstrategy; we improve it to obtain an efficient abstract machine for strong call\nby value and provide a time complexity analysis for the new machine with the\nuse of a potential function; and we present the first provably efficient\nabstract machine for strong call by need.",
        "subjects": [
            "cs.PL"
        ],
        "authors": [
            "Tomasz Drab"
        ],
        "published": "2024-05-21T08:31:09Z"
    },
    {
        "title": "Is Dataset Quality Still a Concern in Diagnosis Using Large Foundation\n  Model?",
        "link": "http://arxiv.org/abs/2405.12584v1",
        "abstract": "Recent advancements in pre-trained large foundation models (LFM) have yielded\nsignificant breakthroughs across various domains, including natural language\nprocessing and computer vision. These models have been particularly impactful\nin the domain of medical diagnostic tasks. With abundant unlabeled data, an LFM\nhas been developed for fundus images using the Vision Transformer (VIT) and a\nself-supervised learning framework. This LFM has shown promising performance in\nfundus disease diagnosis across multiple datasets. On the other hand, deep\nlearning models have long been challenged by dataset quality issues, such as\nimage quality and dataset bias. To investigate the influence of data quality on\nLFM, we conducted explorations in two fundus diagnosis tasks using datasets of\nvarying quality. Specifically, we explored the following questions: Is LFM more\nrobust to image quality? Is LFM affected by dataset bias? Can fine-tuning\ntechniques alleviate these effects? Our investigation found that LFM exhibits\ngreater resilience to dataset quality issues, including image quality and\ndataset bias, compared to typical convolutional networks. Furthermore, we\ndiscovered that overall fine-tuning is an effective adapter for LFM to mitigate\nthe impact of dataset quality issues.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Ziqin Lin",
            "Heng Li",
            "Zinan Li",
            "Huazhu Fu",
            "Jiang Liu"
        ],
        "published": "2024-05-21T08:27:35Z"
    },
    {
        "title": "Ergodic Unobservable MDPs: Decidability of Approximation",
        "link": "http://arxiv.org/abs/2405.12583v1",
        "abstract": "Unobservable Markov decision processes (UMDPs) serve as a prominent\nmathematical framework for modeling sequential decision-making problems. A key\naspect in computational analysis is the consideration of decidability, which\nconcerns the existence of algorithms. In general, the computation of the exact\nand approximated values is undecidable for UMDPs with the long-run average\nobjective. Building on matrix product theory and ergodic properties, we\nintroduce a novel subclass of UMDPs, termed ergodic UMDPs. Our main result\ndemonstrates that approximating the value within this subclass is decidable.\nHowever, we show that the exact problem remains undecidable. Finally, we\ndiscuss the primary challenges of extending these results to partially\nobservable Markov decision processes.",
        "subjects": [
            "math.OC",
            "cs.CC",
            "90C40, 49M25, 90C59, 91A68, 68W25"
        ],
        "authors": [
            "Krishnendu Chatterjee",
            "David Lurie",
            "Raimundo Saona",
            "Bruno Ziliotto"
        ],
        "published": "2024-05-21T08:27:21Z"
    },
    {
        "title": "Carbon-aware Software Services",
        "link": "http://arxiv.org/abs/2405.12582v1",
        "abstract": "The significant carbon footprint of the ICT sector calls for methodologies to\ncontain carbon emissions of running software. This article proposes a novel\nframework for implementing, configuring and assessing carbon-aware interactive\nsoftware services. First, we propose a methodology to implement carbon-aware\nservices leveraging the Strategy design pattern to feature alternative service\nversions with different energy consumption. Then, we devise a bilevel\noptimisation scheme to configure which version to use at different times of the\nday, based on forecasts of carbon intensity and service requests, pursuing the\ntwo-fold goal of minimising carbon emissions and maintaining average output\nquality above a desired set-point. Last, an open-source prototype of such\noptimisation scheme is used to configure a software service implemented as per\nour methodology and assessed against traditional non-adaptive implementations\nof the same service. Results show the capability of our framework to control\nthe average quality of output results of carbon-aware services and to reduce\ncarbon emissions from 8% to 50%.",
        "subjects": [
            "cs.SE",
            "cs.DC"
        ],
        "authors": [
            "Stefano Forti",
            "Jacopo Soldani",
            "Antonio Brogi"
        ],
        "published": "2024-05-21T08:26:38Z"
    },
    {
        "title": "Mining the Explainability and Generalization: Fact Verification Based on\n  Self-Instruction",
        "link": "http://arxiv.org/abs/2405.12579v2",
        "abstract": "Fact-checking based on commercial LLMs has become mainstream. Although these\nmethods offer high explainability, it falls short in accuracy compared to\ntraditional fine-tuning approaches, and data security is also a significant\nconcern. In this paper, we propose a self-instruction based fine-tuning\napproach for fact-checking that balances accuracy and explainability. Our\nmethod consists of Data Augmentation and Improved DPO fine-tuning. The former\nstarts by instructing the model to generate both positive and negative\nexplanations based on claim-evidence pairs and labels, then sampling the\ndataset according to our customized difficulty standards. The latter employs\nour proposed improved DPO to fine-tune the model using the generated samples.\nWe fine-tune the smallest-scale LLaMA-7B model and evaluate it on the\nchallenging fact-checking datasets FEVEROUS and HOVER, utilizing four\nfine-tuning methods and three few-shot learning methods for comparison. The\nexperiments demonstrate that our approach not only retains accuracy comparable\nto, or even surpassing, traditional fine-tuning methods, but also generates\nfluent explanation text. Moreover, it also exhibit high generalization\nperformance. Our method is the first to leverage self-supervised learning for\nfact-checking and innovatively combines contrastive learning and improved DPO\nin fine-tuning LLMs, as shown in the experiments.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Guangyao Lu",
            "Yulin Liu"
        ],
        "published": "2024-05-21T08:23:54Z"
    },
    {
        "title": "Fast Estimation of Relative Transformation Based on Fusion of Odometry\n  and UWB Ranging Data",
        "link": "http://arxiv.org/abs/2405.12577v1",
        "abstract": "In this paper, we investigate the problem of estimating the 4-DOF\n(three-dimensional position and orientation) robot-robot relative frame\ntransformation using odometers and distance measurements between robots.\nFirstly, we apply a two-step estimation method based on maximum likelihood\nestimation. Specifically, a good initial value is obtained through\nunconstrained least squares and projection, followed by a more accurate\nestimate achieved through one-step Gauss-Newton iteration. Additionally, the\noptimal installation positions of Ultra-Wideband (UWB) are provided, and the\nminimum operating time under different quantities of UWB devices is determined.\nSimulation demonstrates that the two-step approach offers faster computation\nwith guaranteed accuracy while effectively addressing the relative\ntransformation estimation problem within limited space constraints.\nFurthermore, this method can be applied to real-time relative transformation\nestimation when a specific number of UWB devices are installed.",
        "subjects": [
            "cs.RO",
            "math.OC",
            "93J08",
            "G.m"
        ],
        "authors": [
            "Yuan Fu",
            "Zheng Zhang",
            "Guangyang Zeng",
            "Chun Liu",
            "Junfeng Wu",
            "Xiaoqiang Ren"
        ],
        "published": "2024-05-21T08:22:14Z"
    },
    {
        "title": "Multi-domain Knowledge Graph Collaborative Pre-training and Prompt\n  Tuning for Diverse Downstream Tasks",
        "link": "http://arxiv.org/abs/2405.13085v1",
        "abstract": "Knowledge graphs (KGs) provide reliable external knowledge for a wide variety\nof AI tasks in the form of structured triples. Knowledge graph pre-training\n(KGP) aims to pre-train neural networks on large-scale KGs and provide unified\ninterfaces to enhance different downstream tasks, which is a key direction for\nKG management, maintenance, and applications. Existing works often focus on\npurely research questions in open domains, or they are not open source due to\ndata security and privacy in real scenarios. Meanwhile, existing studies have\nnot explored the training efficiency and transferability of KGP models in\ndepth. To address these problems, We propose a framework MuDoK to achieve\nmulti-domain collaborative pre-training and efficient prefix prompt tuning to\nserve diverse downstream tasks like recommendation and text understanding. Our\ndesign is a plug-and-play prompt learning approach that can be flexibly adapted\nto different downstream task backbones. In response to the lack of open-source\nbenchmarks, we constructed a new multi-domain KGP benchmark called KPI with two\nlarge-scale KGs and six different sub-domain tasks to evaluate our method and\nopen-sourced it for subsequent research. We evaluated our approach based on\nconstructed KPI benchmarks using diverse backbone models in heterogeneous\ndownstream tasks. The experimental results show that our framework brings\nsignificant performance gains, along with its generality, efficiency, and\ntransferability.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Yichi Zhang",
            "Binbin Hu",
            "Zhuo Chen",
            "Lingbing Guo",
            "Ziqi Liu",
            "Zhiqiang Zhang",
            "Lei Liang",
            "Huajun Chen",
            "Wen Zhang"
        ],
        "published": "2024-05-21T08:22:14Z"
    },
    {
        "title": "EchoPT: A Pretrained Transformer Architecture that Predicts 2D In-Air\n  Sonar Images for Mobile Robotics",
        "link": "http://arxiv.org/abs/2405.12573v1",
        "abstract": "The predictive brain hypothesis suggests that perception can be interpreted\nas the process of minimizing the error between predicted perception tokens\ngenerated by an internal world model and actual sensory input tokens. When\nimplementing working examples of this hypothesis in the context of in-air\nsonar, significant difficulties arise due to the sparse nature of the\nreflection model that governs ultrasonic sensing. Despite these challenges,\ncreating consistent world models using sonar data is crucial for implementing\npredictive processing of ultrasound data in robotics. In an effort to enable\nrobust robot behavior using ultrasound as the sole exteroceptive sensor\nmodality, this paper introduces EchoPT, a pretrained transformer architecture\ndesigned to predict 2D sonar images from previous sensory data and robot\nego-motion information. We detail the transformer architecture that drives\nEchoPT and compare the performance of our model to several state-of-the-art\ntechniques. In addition to presenting and evaluating our EchoPT model, we\ndemonstrate the effectiveness of this predictive perception approach in two\nrobotic tasks.",
        "subjects": [
            "cs.RO",
            "cs.LG",
            "cs.SY",
            "eess.SP",
            "eess.SY"
        ],
        "authors": [
            "Jan Steckel",
            "Wouter Jansen",
            "Nico Huebel"
        ],
        "published": "2024-05-21T08:18:28Z"
    },
    {
        "title": "iHERO: Interactive Human-oriented Exploration and Supervision Under\n  Scarce Communication",
        "link": "http://arxiv.org/abs/2405.12571v1",
        "abstract": "Exploration of unknown scenes before human entry is essential for safety and\nefficiency in numerous scenarios, e.g., subterranean exploration,\nreconnaissance, search and rescue missions. Fleets of autonomous robots are\nparticularly suitable for this task, via concurrent exploration, multi-sensory\nperception and autonomous navigation. Communication however among the robots\ncan be severely restricted to only close-range exchange via ad-hoc networks.\nAlthough some recent works have addressed the problem of collaborative\nexploration under restricted communication, the crucial role of the human\noperator has been mostly neglected. Indeed, the operator may: (i) require\ntimely update regarding the exploration progress and fleet status; (ii)\nprioritize certain regions; and (iii) dynamically move within the explored\narea; To facilitate these requests, this work proposes an interactive\nhuman-oriented online coordination framework for collaborative exploration and\nsupervision under scarce communication (iHERO). The robots switch smoothly and\noptimally among fast exploration, intermittent exchange of map and sensory\ndata, and return to the operator for status update. It is ensured that these\nrequests are fulfilled online interactively with a pre-specified latency.\nExtensive large-scale human-in-the-loop simulations and hardware experiments\nare performed over numerous challenging scenes, which signify its performance\nsuch as explored area and efficiency, and validate its potential applicability\nto real-world scenarios.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Zhuoli Tian",
            "Yuyang Zhang",
            "Jinsheng Wei",
            "Meng Guo"
        ],
        "published": "2024-05-21T08:15:17Z"
    },
    {
        "title": "Unveiling Online Conspiracy Theorists: a Text-Based Approach and\n  Characterization",
        "link": "http://arxiv.org/abs/2405.12566v1",
        "abstract": "In today's digital landscape, the proliferation of conspiracy theories within\nthe disinformation ecosystem of online platforms represents a growing concern.\nThis paper delves into the complexities of this phenomenon. We conducted a\ncomprehensive analysis of two distinct X (formerly known as Twitter) datasets:\none comprising users with conspiracy theorizing patterns and another made of\nusers lacking such tendencies and thus serving as a control group. The\ndistinguishing factors between these two groups are explored across three\ndimensions: emotions, idioms, and linguistic features. Our findings reveal\nmarked differences in the lexicon and language adopted by conspiracy theorists\nwith respect to other users. We developed a machine learning classifier capable\nof identifying users who propagate conspiracy theories based on a rich set of\n871 features. The results demonstrate high accuracy, with an average F1 score\nof 0.88. Moreover, this paper unveils the most discriminating characteristics\nthat define conspiracy theory propagators.",
        "subjects": [
            "cs.SI",
            "cs.CY"
        ],
        "authors": [
            "Alessandra Recordare",
            "Guglielmo Cola",
            "Tiziano Fagni",
            "Maurizio Tesconi"
        ],
        "published": "2024-05-21T08:07:38Z"
    },
    {
        "title": "ProtT3: Protein-to-Text Generation for Text-based Protein Understanding",
        "link": "http://arxiv.org/abs/2405.12564v1",
        "abstract": "Language Models (LMs) excel in understanding textual descriptions of\nproteins, as evident in biomedical question-answering tasks. However, their\ncapability falters with raw protein data, such as amino acid sequences, due to\na deficit in pretraining on such data. Conversely, Protein Language Models\n(PLMs) can understand and convert protein data into high-quality\nrepresentations, but struggle to process texts. To address their limitations,\nwe introduce ProtT3, a framework for Protein-to-Text Generation for Text-based\nProtein Understanding. ProtT3 empowers an LM to understand protein sequences of\namino acids by incorporating a PLM as its protein understanding module,\nenabling effective protein-to-text generation. This collaboration between PLM\nand LM is facilitated by a cross-modal projector (i.e., Q-Former) that bridges\nthe modality gap between the PLM's representation space and the LM's input\nspace. Unlike previous studies focusing on protein property prediction and\nprotein-text retrieval, we delve into the largely unexplored field of\nprotein-to-text generation. To facilitate comprehensive benchmarks and promote\nfuture research, we establish quantitative evaluations for protein-text\nmodeling tasks, including protein captioning, protein question-answering, and\nprotein-text retrieval. Our experiments show that ProtT3 substantially\nsurpasses current baselines, with ablation studies further highlighting the\nefficacy of its core components. Our code is available at\nhttps://github.com/acharkq/ProtT3.",
        "subjects": [
            "q-bio.QM",
            "cs.CL",
            "cs.MM"
        ],
        "authors": [
            "Zhiyuan Liu",
            "An Zhang",
            "Hao Fei",
            "Enzhi Zhang",
            "Xiang Wang",
            "Kenji Kawaguchi",
            "Tat-Seng Chua"
        ],
        "published": "2024-05-21T08:06:13Z"
    },
    {
        "title": "NV-LIO: LiDAR-Inertial Odometry using Normal Vectors Towards Robust SLAM\n  in Multifloor Environments",
        "link": "http://arxiv.org/abs/2405.12563v1",
        "abstract": "Over the last few decades, numerous LiDAR-inertial odometry (LIO) algorithms\nhave been developed, demonstrating satisfactory performance across diverse\nenvironments. Most of these algorithms have predominantly been validated in\nopen outdoor environments, however they often encounter challenges in confined\nindoor settings. In such indoor environments, reliable point cloud registration\nbecomes problematic due to the rapid changes in LiDAR scans and repetitive\nstructural features like walls and stairs, particularly in multifloor\nbuildings. In this paper, we present NV-LIO, a normal vector based LIO\nframework, designed for simultaneous localization and mapping (SLAM) in indoor\nenvironments with multifloor structures. Our approach extracts the normal\nvectors from the LiDAR scans and utilizes them for correspondence search to\nenhance the point cloud registration performance. To ensure robust\nregistration, the distribution of the normal vector directions is analyzed, and\nsituations of degeneracy are examined to adjust the matching uncertainty.\nAdditionally, a viewpoint based loop closure module is implemented to avoid\nwrong correspondences that are blocked by the walls. The propsed method is\nvalidated through public datasets and our own dataset. To contribute to the\ncommunity, the code will be made public on https://github.com/dhchung/nv_lio.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Dongha Chung",
            "Jinwhan Kim"
        ],
        "published": "2024-05-21T08:05:43Z"
    },
    {
        "title": "Implicit-explicit Crank-Nicolson scheme for Oseen's equation at high\n  Reynolds number",
        "link": "http://arxiv.org/abs/2405.12562v1",
        "abstract": "In this paper we continue the work on implicit-explicit (IMEX) time\ndiscretizations for the incompressible Oseen equations that we started in\n\\cite{BGG23} (E. Burman, D. Garg, J. Guzm\\`an, {\\emph{Implicit-explicit time\ndiscretization for Oseen's equation at high Reynolds number with application to\nfractional step methods}}, SIAM J. Numer. Anal., 61, 2859--2886, 2023). The\npressure velocity coupling and the viscous terms are treated implicitly, while\nthe convection term is treated explicitly using extrapolation. Herein we focus\non the implicit-explicit Crank-Nicolson method for time discretization. For the\ndiscretization in space we consider finite element methods with stabilization\non the gradient jumps. The stabilizing terms ensures inf-sup stability for\nequal order interpolation and robustness at high Reynolds number. Under\nsuitable Courant conditions we prove stability of the implicit-explicit\nCrank-Nicolson scheme in this regime. The stabilization allows us to prove\nerror estimates of order $O(h^{k+\\frac12} + \\tau^2)$. Here $h$ is the mesh\nparameter, $k$ the polynomial order and $\\tau$ the time step. Finally we\ndiscuss some fractional step methods that are implied by the IMEX scheme.\nNumerical examples are reported comparing the different methods when applied to\nthe Navier-Stokes' equations.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Erik Burman",
            "Deepika Garg",
            "Johnny Guzman"
        ],
        "published": "2024-05-21T08:03:16Z"
    },
    {
        "title": "Gamification of IT for training in information systems management",
        "link": "http://arxiv.org/abs/2405.12561v1",
        "abstract": "This article examines the integration of IT competitions, in particular\nCapture The Flag, into an information systems management course to fill skills\ngaps, particularly in the field of cybersecurity. An educational CTF team has\nbeen set up at IAE Paris-Est with the aim of developing students' skills.\nWorkshops, challenges, and events have been organised to familiarise them with\nthe CTFs and offer them support adapted to their level. Preliminary results\nshow the importance of soft skills in improving cybersecurity skills. The CTF\npedagogical team is continuing to experiment with and evaluate these methods to\nimprove the accessibility and effectiveness of cybersecurity training.",
        "subjects": [
            "cs.CY",
            "cs.CR"
        ],
        "authors": [
            "Yann Goetgheluck",
            "Sarah Mernit",
            "Julie Pereira"
        ],
        "published": "2024-05-21T07:59:55Z"
    },
    {
        "title": "Online Signature Recognition: A Biologically Inspired Feature Vector\n  Splitting Approach",
        "link": "http://dx.doi.org/10.1007/s12559-023-10205-9",
        "abstract": "This research introduces an innovative approach to explore the cognitive and\nbiologically inspired underpinnings of feature vector splitting for analyzing\nthe significance of different attributes in e-security biometric signature\nrecognition applications. Departing from traditional methods of concatenating\nfeatures into an extended set, we employ multiple splitting strategies,\naligning with cognitive principles, to preserve control over the relative\nimportance of each feature subset. Our methodology is applied to three diverse\ndatabases (MCYT100, MCYT300,and SVC) using two classifiers (vector quantization\nand dynamic time warping with one and five training samples). Experimentation\ndemonstrates that the fusion of pressure data with spatial coordinates (x and\ny) consistently enhances performance. However, the inclusion of pen-tip angles\nin the same feature set yields mixed results, with performance improvements\nobserved in select cases. This work delves into the cognitive aspects of\nfeature fusion,shedding light on the cognitive relevance of feature vector\nsplitting in e-security biometric applications.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Marcos Faundez",
            "Moises Diaz",
            "Miguel Angel Ferrer"
        ],
        "published": "2024-05-21T07:51:01Z"
    },
    {
        "title": "A Subexponential Reduction from Product Partition to Subset Sum",
        "link": "http://arxiv.org/abs/2405.12555v1",
        "abstract": "In this paper we study the Product Partition Problem (PPP), i.e. we are given\na set of $n$ natural numbers represented on $m$ bits each and we are asked if a\nsubset exists such that the product of the numbers in the subset equals the\nproduct of the numbers not in the subset. Our approach is to obtain the integer\nfactorization of each number. This is the subexponential step. We then form a\nmatrix with the exponents of the primes and show that the PPP has a solution\niff some Subset Sum Problems have a common solution. Finally, using the fact\nthat the exponents are not large we combine all the Subset Sum Problems in a\nsingle Subset Sum Problem (SSP) and show that its size is polynomial in $m,n$.\nWe show that the PPP has a solution iff the final SSP has one.",
        "subjects": [
            "math.CO",
            "cs.CC"
        ],
        "authors": [
            "Marius Costandin"
        ],
        "published": "2024-05-21T07:50:38Z"
    },
    {
        "title": "Uncertainty quantification by block bootstrap for differentially private\n  stochastic gradient descent",
        "link": "http://arxiv.org/abs/2405.12553v1",
        "abstract": "Stochastic Gradient Descent (SGD) is a widely used tool in machine learning.\nIn the context of Differential Privacy (DP), SGD has been well studied in the\nlast years in which the focus is mainly on convergence rates and privacy\nguarantees. While in the non private case, uncertainty quantification (UQ) for\nSGD by bootstrap has been addressed by several authors, these procedures cannot\nbe transferred to differential privacy due to multiple queries to the private\ndata. In this paper, we propose a novel block bootstrap for SGD under local\ndifferential privacy that is computationally tractable and does not require an\nadjustment of the privacy budget. The method can be easily implemented and is\napplicable to a broad class of estimation problems. We prove the validity of\nour approach and illustrate its finite sample properties by means of a\nsimulation study. As a by-product, the new method also provides a simple\nalternative numerical tool for UQ for non-private SGD.",
        "subjects": [
            "stat.ML",
            "cs.CR",
            "cs.LG",
            "math.ST",
            "stat.CO",
            "stat.TH"
        ],
        "authors": [
            "Holger Dette",
            "Carina Graw"
        ],
        "published": "2024-05-21T07:47:21Z"
    },
    {
        "title": "RA: A machine based rational agent, Part 1",
        "link": "http://arxiv.org/abs/2405.12551v1",
        "abstract": "RA is a software package that couples machine learning with formal reasoning\nin an attempt to find the laws that generate the empirical data that it has\nbeen given access to. A brief outline of RA in its initial stage of development\nis presented. Particular emphasis is given to current design strategies that\naim to endow RA with the ability to construct its own conjectures of which it\nconstructs proofs.",
        "subjects": [
            "cs.LO",
            "cs.AI"
        ],
        "authors": [
            "G. Pantelis"
        ],
        "published": "2024-05-21T07:37:31Z"
    },
    {
        "title": "The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented\n  Generation (FutureDial-RAG)",
        "link": "http://arxiv.org/abs/2405.13084v1",
        "abstract": "The 2nd FutureDial Challenge: Dialog Systems with Retrieval Augmented\nGeneration (FutureDial-RAG), Co-located with SLT 2024",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Yucheng Cai",
            "Si Chen",
            "Yi Huang",
            "Junlan Feng",
            "Zhijian Ou"
        ],
        "published": "2024-05-21T07:35:21Z"
    },
    {
        "title": "Blockchain-based AI Methods for Managing Industrial IoT: Recent\n  Developments, Integration Challenges and Opportunities",
        "link": "http://arxiv.org/abs/2405.12550v1",
        "abstract": "Currently, Blockchain (BC), Artificial Intelligence (AI), and smart\nIndustrial Internet of Things (IIoT) are not only leading promising\ntechnologies in the world, but also these technologies facilitate the current\nsociety to develop the standard of living and make it easier for users.\nHowever, these technologies have been applied in various domains for different\npurposes. Then, these are successfully assisted in developing the desired\nsystem, such as-smart cities, homes, manufacturers, education, and industries.\nMoreover, these technologies need to consider various issues-security, privacy,\nconfidentiality, scalability, and application challenges in diverse fields. In\nthis context, with the increasing demand for these issues solutions, the\nauthors present a comprehensive survey on the AI approaches with BC in the\nsmart IIoT. Firstly, we focus on state-of-the-art overviews regarding AI, BC,\nand smart IoT applications. Then, we provide the benefits of integrating these\ntechnologies and discuss the established methods, tools, and strategies\nefficiently. Most importantly, we highlight the various issues--security,\nstability, scalability, and confidentiality and guide the way of addressing\nstrategy and methods. Furthermore, the individual and collaborative benefits of\napplications have been discussed. Lastly, we are extensively concerned about\nthe open research challenges and potential future guidelines based on BC-based\nAI approaches in the intelligent IIoT system.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Anichur Rahman",
            "Dipanjali Kundu",
            "Tanoy Debnath",
            "Muaz Rahman",
            "Airin Afroj Aishi",
            "Jahidul Islam"
        ],
        "published": "2024-05-21T07:34:49Z"
    },
    {
        "title": "Data-driven Coordinated AC/DC Control Strategy for Frequency Safety",
        "link": "http://arxiv.org/abs/2405.12546v1",
        "abstract": "With high penetrations of renewable energy and power electronics converters,\nless predictable operating conditions and strong uncertainties in\nunder-frequency events pose challenges for emergency frequency control (EFC).\nOn the other hand, the fast adjustability of converter-based sources presents\nopportunities to reduce economic losses from traditional load shedding for EFC.\nBy integrating DC power emergency support, a data-driven coordinated AC/DC\ncontrol strategy for frequency safety - Coordinated Emergency Frequency Control\n(CEFC) - has been designed. CEFC coordinates both the initiation and control\namount of emergency DC power support (EDCPS) and traditional load shedding.\nBased on real-time power system response data, CEFC ensures system frequency\nsafety at a minimum control cost under non-envisioned operating conditions and\nlarge power deficits. A sufficient condition where data-driven modeling errors\ndo not affect the precision of the control strategy for power system frequency\nis rigorously provided. Simulation results demonstrate CEFC's adaptability,\nprediction accuracy, and control effectiveness.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Qianni Cao",
            "Chen Shen"
        ],
        "published": "2024-05-21T07:28:49Z"
    },
    {
        "title": "Like Humans to Few-Shot Learning through Knowledge Permeation of Vision\n  and Text",
        "link": "http://arxiv.org/abs/2405.12543v2",
        "abstract": "Few-shot learning aims to generalize the recognizer from seen categories to\nan entirely novel scenario. With only a few support samples, several advanced\nmethods initially introduce class names as prior knowledge for identifying\nnovel classes. However, obstacles still impede achieving a comprehensive\nunderstanding of how to harness the mutual advantages of visual and textual\nknowledge. In this paper, we propose a coherent Bidirectional Knowledge\nPermeation strategy called BiKop, which is grounded in a human intuition: A\nclass name description offers a general representation, whereas an image\ncaptures the specificity of individuals. BiKop primarily establishes a\nhierarchical joint general-specific representation through bidirectional\nknowledge permeation. On the other hand, considering the bias of joint\nrepresentation towards the base set, we disentangle base-class-relevant\nsemantics during training, thereby alleviating the suppression of potential\nnovel-class-relevant information. Experiments on four challenging benchmarks\ndemonstrate the remarkable superiority of BiKop. Our code will be publicly\navailable.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Yuyu Jia",
            "Qing Zhou",
            "Wei Huang",
            "Junyu Gao",
            "Qi Wang"
        ],
        "published": "2024-05-21T07:18:26Z"
    },
    {
        "title": "Orthogonally Initiated Particle Swarm Optimization with Advanced\n  Mutation for Real-Parameter Optimization",
        "link": "http://arxiv.org/abs/2405.12542v1",
        "abstract": "This article introduces an enhanced particle swarm optimizer (PSO), termed\nOrthogonal PSO with Mutation (OPSO-m). Initially, it proposes an orthogonal\narray-based learning approach to cultivate an improved initial swarm for PSO,\nsignificantly boosting the adaptability of swarm-based optimization algorithms.\nThe article further presents archive-based self-adaptive learning strategies,\ndividing the population into regular and elite subgroups. Each subgroup employs\ndistinct learning mechanisms. The regular group utilizes efficient learning\nschemes derived from three unique archives, which categorize individuals based\non their quality levels. Additionally, a mutation strategy is implemented to\nupdate the positions of elite individuals. Comparative studies are conducted to\nassess the effectiveness of these learning strategies in OPSO-m, evaluating its\noptimization capacity through exploration-exploitation dynamics and population\ndiversity analysis. The proposed OPSO-m model is tested on real-parameter\nchallenges from the CEC 2017 suite in 10, 30, 50, and 100-dimensional search\nspaces, with its results compared to contemporary state-of-the-art algorithms\nusing a sensitivity metric. OPSO-m exhibits distinguished performance in the\nprecision of solutions, rapidity of convergence, efficiency in search, and\nrobust stability, thus highlighting its superior aptitude for resolving\nintricate optimization issues.",
        "subjects": [
            "cs.NE",
            "math.OC"
        ],
        "authors": [
            "Indu Bala",
            "Dikshit Chauhan",
            "Lewis Mitchell"
        ],
        "published": "2024-05-21T07:16:20Z"
    },
    {
        "title": "DrHouse: An LLM-empowered Diagnostic Reasoning System through Harnessing\n  Outcomes from Sensor Data and Expert Knowledge",
        "link": "http://arxiv.org/abs/2405.12541v1",
        "abstract": "Large language models (LLMs) have the potential to transform digital\nhealthcare, as evidenced by recent advances in LLM-based virtual doctors.\nHowever, current approaches rely on patient's subjective descriptions of\nsymptoms, causing increased misdiagnosis. Recognizing the value of daily data\nfrom smart devices, we introduce a novel LLM-based multi-turn consultation\nvirtual doctor system, DrHouse, which incorporates three significant\ncontributions: 1) It utilizes sensor data from smart devices in the diagnosis\nprocess, enhancing accuracy and reliability. 2) DrHouse leverages continuously\nupdating medical databases such as Up-to-Date and PubMed to ensure our model\nremains at diagnostic standard's forefront. 3) DrHouse introduces a novel\ndiagnostic algorithm that concurrently evaluates potential diseases and their\nlikelihood, facilitating more nuanced and informed medical assessments. Through\nmulti-turn interactions, DrHouse determines the next steps, such as accessing\ndaily data from smart devices or requesting in-lab tests, and progressively\nrefines its diagnoses. Evaluations on three public datasets and our\nself-collected datasets show that DrHouse can achieve up to an 18.8% increase\nin diagnosis accuracy over the state-of-the-art baselines. The results of a\n32-participant user study show that 75% medical experts and 91.7% patients are\nwilling to use DrHouse.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Bufang Yang",
            "Siyang Jiang",
            "Lilin Xu",
            "Kaiwei Liu",
            "Hai Li",
            "Guoliang Xing",
            "Hongkai Chen",
            "Xiaofan Jiang",
            "Zhenyu Yan"
        ],
        "published": "2024-05-21T07:16:12Z"
    },
    {
        "title": "Context-Enhanced Video Moment Retrieval with Large Language Models",
        "link": "http://arxiv.org/abs/2405.12540v1",
        "abstract": "Current methods for Video Moment Retrieval (VMR) struggle to align complex\nsituations involving specific environmental details, character descriptions,\nand action narratives. To tackle this issue, we propose a Large Language\nModel-guided Moment Retrieval (LMR) approach that employs the extensive\nknowledge of Large Language Models (LLMs) to improve video context\nrepresentation as well as cross-modal alignment, facilitating accurate\nlocalization of target moments. Specifically, LMR introduces a context\nenhancement technique with LLMs to generate crucial target-related context\nsemantics. These semantics are integrated with visual features for producing\ndiscriminative video representations. Finally, a language-conditioned\ntransformer is designed to decode free-form language queries, on the fly, using\naligned video representations for moment retrieval. Extensive experiments\ndemonstrate that LMR achieves state-of-the-art results, outperforming the\nnearest competitor by up to 3.28\\% and 4.06\\% on the challenging QVHighlights\nand Charades-STA benchmarks, respectively. More importantly, the performance\ngains are significantly higher for localization of complex queries.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "authors": [
            "Weijia Liu",
            "Bo Miao",
            "Jiuxin Cao",
            "Xuelin Zhu",
            "Bo Liu",
            "Mehwish Nasim",
            "Ajmal Mian"
        ],
        "published": "2024-05-21T07:12:27Z"
    },
    {
        "title": "Bridging the Intent Gap: Knowledge-Enhanced Visual Generation",
        "link": "http://arxiv.org/abs/2405.12538v1",
        "abstract": "For visual content generation, discrepancies between user intentions and the\ngenerated content have been a longstanding problem. This discrepancy arises\nfrom two main factors. First, user intentions are inherently complex, with\nsubtle details not fully captured by input prompts. The absence of such details\nmakes it challenging for generative models to accurately reflect the intended\nmeaning, leading to a mismatch between the desired and generated output.\nSecond, generative models trained on visual-label pairs lack the comprehensive\nknowledge to accurately represent all aspects of the input data in their\ngenerated outputs. To address these challenges, we propose a knowledge-enhanced\niterative refinement framework for visual content generation. We begin by\nanalyzing and identifying the key challenges faced by existing generative\nmodels. Then, we introduce various knowledge sources, including human insights,\npre-trained models, logic rules, and world knowledge, which can be leveraged to\naddress these challenges. Furthermore, we propose a novel visual generation\nframework that incorporates a knowledge-based feedback module to iteratively\nrefine the generation process. This module gradually improves the alignment\nbetween the generated content and user intentions. We demonstrate the efficacy\nof the proposed framework through preliminary results, highlighting the\npotential of knowledge-enhanced generative models for intention-aligned content\ngeneration.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yi Cheng",
            "Ziwei Xu",
            "Dongyun Lin",
            "Harry Cheng",
            "Yongkang Wong",
            "Ying Sun",
            "Joo Hwee Lim",
            "Mohan Kankanhalli"
        ],
        "published": "2024-05-21T07:07:44Z"
    },
    {
        "title": "PhiBE: A PDE-based Bellman Equation for Continuous Time Policy\n  Evaluation",
        "link": "http://arxiv.org/abs/2405.12535v1",
        "abstract": "In this paper, we address the problem of continuous-time reinforcement\nlearning in scenarios where the dynamics follow a stochastic differential\nequation. When the underlying dynamics remain unknown and we have access only\nto discrete-time information, how can we effectively conduct policy evaluation?\nWe first highlight that the commonly used Bellman equation (BE) is not always a\nreliable approximation to the true value function. We then introduce a new\nbellman equation, PhiBE, which integrates the discrete-time information into a\nPDE formulation. The new bellman equation offers a more accurate approximation\nto the true value function, especially in scenarios where the underlying\ndynamics change slowly. Moreover, we extend PhiBE to higher orders, providing\nincreasingly accurate approximations. We conduct the error analysis for both BE\nand PhiBE with explicit dependence on the discounted coefficient, the reward\nand the dynamics. Additionally, we present a model-free algorithm to solve\nPhiBE when only discrete-time trajectory data is available. Numerical\nexperiments are provided to validate the theoretical guarantees we propose.",
        "subjects": [
            "math.OC",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Yuhua Zhu"
        ],
        "published": "2024-05-21T06:58:00Z"
    },
    {
        "title": "Dataset and Benchmark for Urdu Natural Scenes Text Detection,\n  Recognition and Visual Question Answering",
        "link": "http://arxiv.org/abs/2405.12533v1",
        "abstract": "The development of Urdu scene text detection, recognition, and Visual\nQuestion Answering (VQA) technologies is crucial for advancing accessibility,\ninformation retrieval, and linguistic diversity in digital content,\nfacilitating better understanding and interaction with Urdu-language visual\ndata. This initiative seeks to bridge the gap between textual and visual\ncomprehension. We propose a new multi-task Urdu scene text dataset comprising\nover 1000 natural scene images, which can be used for text detection,\nrecognition, and VQA tasks. We provide fine-grained annotations for text\ninstances, addressing the limitations of previous datasets for facing\narbitrary-shaped texts. By incorporating additional annotation points, this\ndataset facilitates the development and assessment of methods that can handle\ndiverse text layouts, intricate shapes, and non-standard orientations commonly\nencountered in real-world scenarios. Besides, the VQA annotations make it the\nfirst benchmark for the Urdu Text VQA method, which can prompt the development\nof Urdu scene text understanding. The proposed dataset is available at:\nhttps://github.com/Hiba-MeiRuan/Urdu-VQA-Dataset-/tree/main",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hiba Maryam",
            "Ling Fu",
            "Jiajun Song",
            "Tajrian ABM Shafayet",
            "Qidi Luo",
            "Xiang Bai",
            "Yuliang Liu"
        ],
        "published": "2024-05-21T06:48:26Z"
    },
    {
        "title": "PyramidInfer: Pyramid KV Cache Compression for High-throughput LLM\n  Inference",
        "link": "http://arxiv.org/abs/2405.12532v1",
        "abstract": "Large Language Models (LLMs) have shown remarkable comprehension abilities\nbut face challenges in GPU memory usage during inference, hindering their\nscalability for real-time applications like chatbots. To accelerate inference,\nwe store computed keys and values (KV cache) in the GPU memory. Existing\nmethods study the KV cache compression to reduce memory by pruning the\npre-computed KV cache. However, they neglect the inter-layer dependency between\nlayers and huge memory consumption in pre-computation. To explore these\ndeficiencies, we find that the number of crucial keys and values that influence\nfuture generations decreases layer by layer and we can extract them by the\nconsistency in attention weights. Based on the findings, we propose\nPyramidInfer, a method that compresses the KV cache by layer-wise retaining\ncrucial context. PyramidInfer saves significant memory by computing fewer keys\nand values without sacrificing performance. Experimental results show\nPyramidInfer improves 2.2x throughput compared to Accelerate with over 54% GPU\nmemory reduction in KV cache.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Dongjie Yang",
            "XiaoDong Han",
            "Yan Gao",
            "Yao Hu",
            "Shilin Zhang",
            "Hai Zhao"
        ],
        "published": "2024-05-21T06:46:37Z"
    },
    {
        "title": "A Survey of Artificial Intelligence in Gait-Based Neurodegenerative\n  Disease Diagnosis",
        "link": "http://arxiv.org/abs/2405.13082v1",
        "abstract": "Recent years have witnessed an increasing global population affected by\nneurodegenerative diseases (NDs), which traditionally require extensive\nhealthcare resources and human effort for medical diagnosis and monitoring. As\na crucial disease-related motor symptom, human gait can be exploited to\ncharacterize different NDs. The current advances in artificial intelligence\n(AI) models enable automatic gait analysis for NDs identification and\nclassification, opening a new avenue to facilitate faster and more\ncost-effective diagnosis of NDs. In this paper, we provide a comprehensive\nsurvey on recent progress of machine learning and deep learning based AI\ntechniques applied to diagnosis of five typical NDs through gait. We provide an\noverview of the process of AI-assisted NDs diagnosis, and present a systematic\ntaxonomy of existing gait data and AI models. Through an extensive review and\nanalysis of 164 studies, we identify and discuss the challenges, potential\nsolutions, and future directions in this field. Finally, we envision the\nprospective utilization of 3D skeleton data for human gait representation and\nthe development of more efficient AI models for NDs diagnosis. We provide a\npublic resource repository to track and facilitate developments in this\nemerging field: https://github.com/Kali-Hac/AI4NDD-Survey.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Haocong Rao",
            "Minlin Zeng",
            "Xuejiao Zhao",
            "Chunyan Miao"
        ],
        "published": "2024-05-21T06:44:40Z"
    },
    {
        "title": "CustomText: Customized Textual Image Generation using Diffusion Models",
        "link": "http://arxiv.org/abs/2405.12531v1",
        "abstract": "Textual image generation spans diverse fields like advertising, education,\nproduct packaging, social media, information visualization, and branding.\nDespite recent strides in language-guided image synthesis using diffusion\nmodels, current models excel in image generation but struggle with accurate\ntext rendering and offer limited control over font attributes. In this paper,\nwe aim to enhance the synthesis of high-quality images with precise text\ncustomization, thereby contributing to the advancement of image generation\nmodels. We call our proposed method CustomText. Our implementation leverages a\npre-trained TextDiffuser model to enable control over font color, background,\nand types. Additionally, to address the challenge of accurately rendering\nsmall-sized fonts, we train the ControlNet model for a consistency decoder,\nsignificantly enhancing text-generation performance. We assess the performance\nof CustomText in comparison to previous methods of textual image generation on\nthe publicly available CTW-1500 dataset and a self-curated dataset for\nsmall-text generation, showcasing superior results.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Shubham Paliwal",
            "Arushi Jain",
            "Monika Sharma",
            "Vikram Jamwal",
            "Lovekesh Vig"
        ],
        "published": "2024-05-21T06:43:03Z"
    },
    {
        "title": "Multi-hop Multi-RIS Wireless Communication Systems: Multi-reflection\n  Path Scheduling and Beamforming",
        "link": "http://arxiv.org/abs/2405.12530v1",
        "abstract": "Reconfigurable intelligent surface (RIS) provides a promising way to\nproactively augment propagation environments for better transmission\nperformance in wireless communications. Existing multi-RIS works mainly focus\non link-level optimization with predetermined transmission paths, which cannot\nbe directly extended to system-level management, since they neither consider\nthe interference caused by undesired scattering of RISs, nor the performance\nbalancing between different transmission paths. To address this, we study an\ninnovative multi-hop multi-RIS communication system, where a base station (BS)\ntransmits information to a set of distributed users over multi-RIS\nconfiguration space in a multi-hop manner. The signals for each user are\nsubsequently reflected by the selected RISs via multi-reflection line-of-sight\n(LoS) links. To ensure that all users have fair access to the system to avoid\nexcessive number of RISs serving one user, we aim to find the optimal beam\nreflecting path for each user, while judiciously determining the path\nscheduling strategies with the corresponding beamforming design to ensure the\nfairness. Due to the presence of interference caused by undesired scattering of\nRISs, it is highly challenging to solve the formulated multi-RIS multi-path\nbeamforming optimization problem. To solve it, we first derive the optimal\nRISs' phase shifts and the corresponding reflecting path selection for each\nuser based on its practical deployment location. With the optimized\nmulti-reflection paths, we obtain a feasible user grouping pattern for\neffective interference mitigation by constructing the maximum independent sets\n(MISs). Finally, we propose a joint heuristic algorithm to iteratively update\nthe beamforming vectors and the group scheduling policies to maximize the\nminimum equivalent data rate of all users.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Xiaoyan Ma",
            "Haixia Zhang",
            "Xianhao Chen",
            "Yuguang Fangmand Dongfeng Yuan"
        ],
        "published": "2024-05-21T06:41:24Z"
    },
    {
        "title": "SirLLM: Streaming Infinite Retentive LLM",
        "link": "http://arxiv.org/abs/2405.12528v1",
        "abstract": "As Large Language Models (LLMs) become increasingly prevalent in various\ndomains, their ability to process inputs of any length and maintain a degree of\nmemory becomes essential. However, the one-off input of overly long texts is\nlimited, as studies have shown that when input lengths exceed the LLMs'\npre-trained text length, there is a dramatic decline in text generation\ncapabilities. Moreover, simply extending the length of pre-training texts is\nimpractical due to the difficulty in obtaining long text data and the\nsubstantial memory consumption costs this would entail for LLMs. Recent efforts\nhave employed streaming inputs to alleviate the pressure of excessively long\ntext inputs, but this approach can significantly impair the model's long-term\nmemory capabilities.\n  Motivated by this challenge, we introduce Streaming Infinite Retentive LLM\n(SirLLM), which allows LLMs to maintain longer memory during infinite-length\ndialogues without the need for fine-tuning. SirLLM utilizes the Token Entropy\nmetric and a memory decay mechanism to filter key phrases, endowing LLMs with\nboth long-lasting and flexible memory. We designed three distinct tasks and\nconstructed three datasets to measure the effectiveness of SirLLM from various\nangles: (1) DailyDialog; (2) Grocery Shopping; (3) Rock-Paper-Scissors. Our\nexperimental results robustly demonstrate that SirLLM can achieve stable and\nsignificant improvements across different LLMs and tasks, compellingly proving\nits effectiveness. When having a coversation, \"A sir could forget himself,\" but\nSirLLM never does! Our code is publicly available at\nhttps://github.com/Zoeyyao27/SirLLM",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yao Yao",
            "Zuchao Li",
            "Hai Zhao"
        ],
        "published": "2024-05-21T06:37:03Z"
    },
    {
        "title": "Cache Blocking of Distributed-Memory Parallel Matrix Power Kernels",
        "link": "http://arxiv.org/abs/2405.12525v2",
        "abstract": "Sparse matrix-vector products (SpMVs) are a bottleneck in many scientific\ncodes. Due to the heavy strain on the main memory interface from loading the\nsparse matrix and the possibly irregular memory access pattern, SpMV typically\nexhibits low arithmetic intensity. Repeating these products multiple times with\nthe same matrix is required in many algorithms. This so-called matrix power\nkernel (MPK) provides an opportunity for data reuse since the same matrix data\nis loaded from main memory multiple times, an opportunity that has only\nrecently been exploited successfully with the Recursive Algebraic Coloring\nEngine (RACE). Using RACE, one considers a graph based formulation of the SpMV\nand employs s level-based implementation of SpMV for reuse of relevant matrix\ndata. However, the underlying data dependencies have restricted the use of this\nconcept to shared memory parallelization and thus to single compute nodes.\nEnabling cache blocking for distributed-memory parallelization of MPK is\nchallenging due to the need for explicit communication and synchronization of\ndata in neighboring levels. In this work, we propose and implement a flexible\nmethod that interleaves the cache-blocking capabilities of RACE with an MPI\ncommunication scheme that fulfills all data dependencies among processes.\nCompared to a \"traditional\" distributed memory parallel MPK, our new\nDistributed Level-Blocked MPK yields substantial speed-ups on modern Intel and\nAMD architectures across a wide range of sparse matrices from various\nscientific applications. Finally, we address a modern quantum physics problem\nto demonstrate the applicability of our method, achieving a speed-up of up to\n4x on 832 cores of an Intel Sapphire Rapids cluster.",
        "subjects": [
            "cs.DC",
            "cs.PF"
        ],
        "authors": [
            "Dane C. Lacey",
            "Christie L. Alappat",
            "Florian Lange",
            "Georg Hager",
            "Holger Fehske",
            "Gerhard Wellein"
        ],
        "published": "2024-05-21T06:30:00Z"
    },
    {
        "title": "APTT: An accuracy-preserved tensor-train method for the Boltzmann-BGK\n  equation",
        "link": "http://arxiv.org/abs/2405.12524v1",
        "abstract": "Solving the Boltzmann-BGK equation with traditional numerical methods suffers\nfrom high computational and memory costs due to the curse of dimensionality. In\nthis paper, we propose a novel accuracy-preserved tensor-train (APTT) method to\nefficiently solve the Boltzmann-BGK equation. A second-order finite difference\nscheme is applied to discretize the Boltzmann-BGK equation, resulting in a\ntensor algebraic system at each time step. Based on the low-rank TT\nrepresentation, the tensor algebraic system is then approximated as a TT-based\nlow-rank system, which is efficiently solved using the TT-modified alternating\nleast-squares (TT-MALS) solver. Thanks to the low-rank TT representation, the\nAPTT method can significantly reduce the computational and memory costs\ncompared to traditional numerical methods. Theoretical analysis demonstrates\nthat the APTT method maintains the same convergence rate as that of the finite\ndifference scheme. The convergence rate and efficiency of the APTT method are\nvalidated by several benchmark test cases.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Zhitao Zhu",
            "Chuanfu Xiao",
            "Kejun Tang",
            "Jizu Huang",
            "Chao Yang"
        ],
        "published": "2024-05-21T06:27:25Z"
    },
    {
        "title": "Single Image Unlearning: Efficient Machine Unlearning in Multimodal\n  Large Language Models",
        "link": "http://arxiv.org/abs/2405.12523v1",
        "abstract": "Machine unlearning empowers individuals with the `right to be forgotten' by\nremoving their private or sensitive information encoded in machine learning\nmodels. However, it remains uncertain whether MU can be effectively applied to\nMultimodal Large Language Models (MLLMs), particularly in scenarios of\nforgetting the leaked visual data of concepts. To overcome the challenge, we\npropose an efficient method, Single Image Unlearning (SIU), to unlearn the\nvisual recognition of a concept by fine-tuning a single associated image for\nfew steps. SIU consists of two key aspects: (i) Constructing Multifaceted\nfine-tuning data. We introduce four targets, based on which we construct\nfine-tuning data for the concepts to be forgotten; (ii) Jointly training loss.\nTo synchronously forget the visual recognition of concepts and preserve the\nutility of MLLMs, we fine-tune MLLMs through a novel Dual Masked KL-divergence\nLoss combined with Cross Entropy loss. Alongside our method, we establish\nMMUBench, a new benchmark for MU in MLLMs and introduce a collection of metrics\nfor its evaluation. Experimental results on MMUBench show that SIU completely\nsurpasses the performance of existing methods. Furthermore, we surprisingly\nfind that SIU can avoid invasive membership inference attacks and jailbreak\nattacks. To the best of our knowledge, we are the first to explore MU in MLLMs.\nWe will release the code and benchmark in the near future.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Jiaqi Li",
            "Qianshan Wei",
            "Chuanyi Zhang",
            "Guilin Qi",
            "Miaozeng Du",
            "Yongrui Chen",
            "Sheng Bi"
        ],
        "published": "2024-05-21T06:27:12Z"
    },
    {
        "title": "Sparse Autoencoders Enable Scalable and Reliable Circuit Identification\n  in Language Models",
        "link": "http://arxiv.org/abs/2405.12522v1",
        "abstract": "This paper introduces an efficient and robust method for discovering\ninterpretable circuits in large language models using discrete sparse\nautoencoders. Our approach addresses key limitations of existing techniques,\nnamely computational complexity and sensitivity to hyperparameters. We propose\ntraining sparse autoencoders on carefully designed positive and negative\nexamples, where the model can only correctly predict the next token for the\npositive examples. We hypothesise that learned representations of attention\nhead outputs will signal when a head is engaged in specific computations. By\ndiscretising the learned representations into integer codes and measuring the\noverlap between codes unique to positive examples for each head, we enable\ndirect identification of attention heads involved in circuits without the need\nfor expensive ablations or architectural modifications. On three well-studied\ntasks - indirect object identification, greater-than comparisons, and docstring\ncompletion - the proposed method achieves higher precision and recall in\nrecovering ground-truth circuits compared to state-of-the-art baselines, while\nreducing runtime from hours to seconds. Notably, we require only 5-10 text\nexamples for each task to learn robust representations. Our findings highlight\nthe promise of discrete sparse autoencoders for scalable and efficient\nmechanistic interpretability, offering a new direction for analysing the inner\nworkings of large language models.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Charles O'Neill",
            "Thang Bui"
        ],
        "published": "2024-05-21T06:26:10Z"
    },
    {
        "title": "Unleash Graph Neural Networks from Heavy Tuning",
        "link": "http://arxiv.org/abs/2405.12521v1",
        "abstract": "Graph Neural Networks (GNNs) are deep-learning architectures designed for\ngraph-type data, where understanding relationships among individual\nobservations is crucial. However, achieving promising GNN performance,\nespecially on unseen data, requires comprehensive hyperparameter tuning and\nmeticulous training. Unfortunately, these processes come with high\ncomputational costs and significant human effort. Additionally, conventional\nsearching algorithms such as grid search may result in overfitting on\nvalidation data, diminishing generalization accuracy. To tackle these\nchallenges, we propose a graph conditional latent diffusion framework\n(GNN-Diff) to generate high-performing GNNs directly by learning from\ncheckpoints saved during a light-tuning coarse search. Our method: (1)\nunleashes GNN training from heavy tuning and complex search space design; (2)\nproduces GNN parameters that outperform those obtained through comprehensive\ngrid search; and (3) establishes higher-quality generation for GNNs compared to\ndiffusion frameworks designed for general neural networks.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Lequan Lin",
            "Dai Shi",
            "Andi Han",
            "Zhiyong Wang",
            "Junbin Gao"
        ],
        "published": "2024-05-21T06:23:47Z"
    },
    {
        "title": "Children's Mental Models of Generative Visual and Text Based AI Models",
        "link": "http://arxiv.org/abs/2405.13081v1",
        "abstract": "In this work we investigate how children ages 5-12 perceive, understand, and\nuse generative AI models such as a text-based LLMs ChatGPT and a visual-based\nmodel DALL-E. Generative AI is newly being used widely since chatGPT. Children\nare also building mental models of generative AI. Those haven't been studied\nbefore and it is also the case that the children's models are dynamic as they\nuse the tools, even with just very short usage. Upon surveying and\nexperimentally observing over 40 children ages 5-12, we found that children\ngenerally have a very positive outlook towards AI and are excited about the\nways AI may benefit and aid them in their everyday lives. In a forced choice,\nchildren robustly associated AI with positive adjectives versus negative ones.\nWe also categorize what children are querying AI models for and find that\nchildren search for more imaginative things that don't exist when using a\nvisual-based AI and not when using a text-based one. Our follow-up study\nmonitored children's responses and feelings towards AI before and after\ninteracting with GenAI models. We even find that children find AI to be less\nscary after interacting with it. We hope that these findings will shine a light\non children's mental models of AI and provide insight for how to design the\nbest possible tools for children who will inevitably be using AI in their\nlifetimes. The motivation of this work is to bridge the gap between\nHuman-Computer Interaction (HCI) and Psychology in an effort to study the\neffects of AI on society. We aim to identify the gaps in humans' mental models\nof what AI is and how it works. Previous work has investigated how both adults\nand children perceive various kinds of robots, computers, and other\ntechnological concepts. However, there is very little work investigating these\nconcepts for generative AI models and not simply embodied robots or physical\ntechnology.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Eliza Kosoy",
            "Soojin Jeong",
            "Anoop Sinha",
            "Alison Gopnik",
            "Tanya Kraljic"
        ],
        "published": "2024-05-21T06:18:00Z"
    },
    {
        "title": "MOSS: A Large-scale Open Microscopic Traffic Simulation System",
        "link": "http://arxiv.org/abs/2405.12520v1",
        "abstract": "In the research of Intelligent Transportation Systems (ITS), traffic\nsimulation is a key procedure for the evaluation of new methods and\noptimization of strategies. However, existing traffic simulation systems face\ntwo challenges. First, how to balance simulation scale with realism is a\ndilemma. Second, it is hard to simulate realistic results, which requires\nrealistic travel demand data and simulator. These problems limit computer-aided\noptimization of traffic management strategies for large-scale road networks and\nreduce the usability of traffic simulations in areas where real-world travel\ndemand data are lacking. To address these problems, we design and implement\nMObility Simulation System (MOSS). MOSS adopts GPU acceleration to\nsignificantly improve the efficiency and scale of microscopic traffic\nsimulation, which enables realistic and fast simulations for large-scale road\nnetworks. It provides realistic travel Origin-Destination (OD) matrices\ngeneration through a pre-trained generative neural network model based on\npublicly available data on a global scale, such as satellite imagery, to help\nresearchers build meaningful travel demand data. It also provides a complete\nopen toolchain to help users with road network construction, demand generation,\nsimulation, and result analysis. The whole toolchain including the simulator\ncan be accessed at https://moss.fiblab.net and the codes are open-source for\ncommunity collaboration.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Jun Zhang",
            "Wenxuan Ao",
            "Junbo Yan",
            "Can Rong",
            "Depeng Jin",
            "Wei Wu",
            "Yong Li"
        ],
        "published": "2024-05-21T06:16:42Z"
    },
    {
        "title": "EmInspector: Combating Backdoor Attacks in Federated Self-Supervised\n  Learning Through Embedding Inspection",
        "link": "http://arxiv.org/abs/2405.13080v1",
        "abstract": "Federated self-supervised learning (FSSL) has recently emerged as a promising\nparadigm that enables the exploitation of clients' vast amounts of unlabeled\ndata while preserving data privacy. While FSSL offers advantages, its\nsusceptibility to backdoor attacks, a concern identified in traditional\nfederated supervised learning (FSL), has not been investigated. To fill the\nresearch gap, we undertake a comprehensive investigation into a backdoor attack\nparadigm, where unscrupulous clients conspire to manipulate the global model,\nrevealing the vulnerability of FSSL to such attacks. In FSL, backdoor attacks\ntypically build a direct association between the backdoor trigger and the\ntarget label. In contrast, in FSSL, backdoor attacks aim to alter the global\nmodel's representation for images containing the attacker's specified trigger\npattern in favor of the attacker's intended target class, which is less\nstraightforward. In this sense, we demonstrate that existing defenses are\ninsufficient to mitigate the investigated backdoor attacks in FSSL, thus\nfinding an effective defense mechanism is urgent. To tackle this issue, we dive\ninto the fundamental mechanism of backdoor attacks on FSSL, proposing the\nEmbedding Inspector (EmInspector) that detects malicious clients by inspecting\nthe embedding space of local models. In particular, EmInspector assesses the\nsimilarity of embeddings from different local models using a small set of\ninspection images (e.g., ten images of CIFAR100) without specific requirements\non sample distribution or labels. We discover that embeddings from backdoored\nmodels tend to cluster together in the embedding space for a given inspection\nimage. Evaluation results show that EmInspector can effectively mitigate\nbackdoor attacks on FSSL across various adversary settings. Our code is\navaliable at https://github.com/ShuchiWu/EmInspector.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "authors": [
            "Yuwen Qian",
            "Shuchi Wu",
            "Kang Wei",
            "Ming Ding",
            "Di Xiao",
            "Tao Xiang",
            "Chuan Ma",
            "Song Guo"
        ],
        "published": "2024-05-21T06:14:49Z"
    },
    {
        "title": "MAGE: Model-Level Graph Neural Networks Explanations via Motif-based\n  Graph Generation",
        "link": "http://arxiv.org/abs/2405.12519v1",
        "abstract": "Graph Neural Networks (GNNs) have shown remarkable success in molecular\ntasks, yet their interpretability remains challenging. Traditional model-level\nexplanation methods like XGNN and GNNInterpreter often fail to identify valid\nsubstructures like rings, leading to questionable interpretability. This\nlimitation stems from XGNN's atom-by-atom approach and GNNInterpreter's\nreliance on average graph embeddings, which overlook the essential structural\nelements crucial for molecules. To address these gaps, we introduce an\ninnovative \\textbf{M}otif-b\\textbf{A}sed \\textbf{G}NN \\textbf{E}xplainer (MAGE)\nthat uses motifs as fundamental units for generating explanations. Our approach\nbegins with extracting potential motifs through a motif decomposition\ntechnique. Then, we utilize an attention-based learning method to identify\nclass-specific motifs. Finally, we employ a motif-based graph generator for\neach class to create molecular graph explanations based on these class-specific\nmotifs. This novel method not only incorporates critical substructures into the\nexplanations but also guarantees their validity, yielding results that are\nhuman-understandable. Our proposed method's effectiveness is demonstrated\nthrough quantitative and qualitative assessments conducted on six real-world\nmolecular datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.QM"
        ],
        "authors": [
            "Zhaoning Yu",
            "Hongyang Gao"
        ],
        "published": "2024-05-21T06:12:24Z"
    },
    {
        "title": "Future You: A Conversation with an AI-Generated Future Self Reduces\n  Anxiety, Negative Emotions, and Increases Future Self-Continuity",
        "link": "http://arxiv.org/abs/2405.12514v1",
        "abstract": "We introduce \"Future You,\" an interactive, brief, single-session, digital\nchat intervention designed to improve future self-continuity--the degree of\nconnection an individual feels with a temporally distant future self--a\ncharacteristic that is positively related to mental health and wellbeing. Our\nsystem allows users to chat with a relatable yet AI-powered virtual version of\ntheir future selves that is tuned to their future goals and personal qualities.\nTo make the conversation realistic, the system generates a \"synthetic\nmemory\"--a unique backstory for each user--that creates a throughline between\nthe user's present age (between 18-30) and their life at age 60. The \"Future\nYou\" character also adopts the persona of an age-progressed image of the user's\npresent self. After a brief interaction with the \"Future You\" character, users\nreported decreased anxiety, and increased future self-continuity. This is the\nfirst study successfully demonstrating the use of personalized AI-generated\ncharacters to improve users' future self-continuity and wellbeing.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Pat Pataranutaporn",
            "Kavin Winson",
            "Peggy Yin",
            "Auttasak Lapapirojn",
            "Pichayoot Ouppaphan",
            "Monchai Lertsutthiwong",
            "Pattie Maes",
            "Hal Hershfield"
        ],
        "published": "2024-05-21T06:00:51Z"
    },
    {
        "title": "Fully Randomized Pointers",
        "link": "http://arxiv.org/abs/2405.12513v1",
        "abstract": "Software security continues to be a critical concern for programs implemented\nin low-level programming languages such as C and C++. Many defenses have been\nproposed in the current literature, each with different trade-offs including\nperformance, compatibility, and attack resistance. One general class of defense\nis pointer randomization or authentication, where invalid object access (e.g.,\nmemory errors) is obfuscated or denied. Many defenses rely on the program\ntermination (e.g., crashing) to abort attacks, with the implicit assumption\nthat an adversary cannot \"brute force\" the defense with multiple attack\nattempts. However, such assumptions do not always hold, such as hardware\nspeculative execution attacks or network servers configured to restart on\nerror. In such cases, we argue that most existing defenses provide only weak\neffective security.\n  In this paper, we propose Fully Randomized Pointers (FRP) as a stronger\nmemory error defense that is resistant to even brute force attacks. The key\nidea is to fully randomize pointer bits -- as much as possible while also\npreserving binary compatibility -- rendering the relationships between pointers\nhighly unpredictable. Furthermore, the very high degree of randomization\nrenders brute force attacks impractical -- providing strong effective security\ncompared to existing work. We design a new FRP encoding that is: (1) compatible\nwith existing binary code (without recompilation); (2) decoupled from the\nunderlying object layout; and (3) can be efficiently decoded on-the-fly to the\nunderlying memory address. We prototype FRP in the form of a software\nimplementation (BlueFat) to test security and compatibility, and a\nproof-of-concept hardware implementation (GreenFat) to evaluate performance. We\nshow that FRP is secure, practical, and compatible at the binary level, while a\nhardware implementation can achieve low performance overheads (<10%).",
        "subjects": [
            "cs.CR",
            "cs.PL"
        ],
        "authors": [
            "Gregory J. Duck",
            "Sai Dhawal Phaye",
            "Roland H. C. Yap",
            "Trevor E. Carlson"
        ],
        "published": "2024-05-21T05:54:27Z"
    },
    {
        "title": "Rethink Predicting the Optical Flow with the Kinetics Perspective",
        "link": "http://arxiv.org/abs/2405.12512v1",
        "abstract": "Optical flow estimation is one of the fundamental tasks in low-level computer\nvision, which describes the pixel-wise displacement and can be used in many\nother tasks. From the apparent aspect, the optical flow can be viewed as the\ncorrelation between the pixels in consecutive frames, so continuously refining\nthe correlation volume can achieve an outstanding performance. However, it will\nmake the method have a catastrophic computational complexity. Not only that,\nthe error caused by the occlusion regions of the successive frames will be\namplified through the inaccurate warp operation. These challenges can not be\nsolved only from the apparent view, so this paper rethinks the optical flow\nestimation from the kinetics viewpoint.We propose a method combining the\napparent and kinetics information from this motivation. The proposed method\ndirectly predicts the optical flow from the feature extracted from images\ninstead of building the correlation volume, which will improve the efficiency\nof the whole network. Meanwhile, the proposed method involves a new\ndifferentiable warp operation that simultaneously considers the warping and\nocclusion. Moreover, the proposed method blends the kinetics feature with the\napparent feature through the novel self-supervised loss function. Furthermore,\ncomprehensive experiments and ablation studies prove that the proposed novel\ninsight into how to predict the optical flow can achieve the better performance\nof the state-of-the-art methods, and in some metrics, the proposed method\noutperforms the correlation-based method, especially in situations containing\nocclusion and fast moving. The code will be public.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM"
        ],
        "authors": [
            "Yuhao Cheng",
            "Siru Zhang",
            "Yiqiang Yan"
        ],
        "published": "2024-05-21T05:47:42Z"
    },
    {
        "title": "Quantum Computing for Databases: Overview and Challenges",
        "link": "http://arxiv.org/abs/2405.12511v1",
        "abstract": "In the decades, the general field of quantum computing has experienced\nremarkable progress since its inception. A plethora of researchers not only\nproposed quantum algorithms showing the power of quantum computing but also\nconstructed the prototype of quantum computers, making it walk into our\ntangible reality. Those remarkable advancements in quantum computing have\nopened doors for novel applications, one of which is quantum databases.\nResearchers are trying to use a paradigm brought by quantum computing to\nrevolutionize various aspects of database management systems. In this paper, we\nenvision the synergy between quantum computing and databases with two\nperspectives: Quantum computing-enabled technology, and quantum\ncomputing-inspired technology. Based on this classification, we present a\ndetailed overview of the research attained in this area, aiming to show the\nlandscape of the field and draw a road map of future directions.",
        "subjects": [
            "cs.DB"
        ],
        "authors": [
            "Gongsheng Yuan",
            "Yuxing Chen",
            "Jiaheng Lu",
            "Sai Wu",
            "Zhiwei Ye",
            "Ling Qian",
            "Gang Chen"
        ],
        "published": "2024-05-21T05:47:02Z"
    },
    {
        "title": "Active Object Detection with Knowledge Aggregation and Distillation from\n  Large Models",
        "link": "http://arxiv.org/abs/2405.12509v1",
        "abstract": "Accurately detecting active objects undergoing state changes is essential for\ncomprehending human interactions and facilitating decision-making. The existing\nmethods for active object detection (AOD) primarily rely on visual appearance\nof the objects within input, such as changes in size, shape and relationship\nwith hands. However, these visual changes can be subtle, posing challenges,\nparticularly in scenarios with multiple distracting no-change instances of the\nsame category. We observe that the state changes are often the result of an\ninteraction being performed upon the object, thus propose to use informed\npriors about object related plausible interactions (including semantics and\nvisual appearance) to provide more reliable cues for AOD. Specifically, we\npropose a knowledge aggregation procedure to integrate the aforementioned\ninformed priors into oracle queries within the teacher decoder, offering more\nobject affordance commonsense to locate the active object. To streamline the\ninference process and reduce extra knowledge inputs, we propose a knowledge\ndistillation approach that encourages the student decoder to mimic the\ndetection capabilities of the teacher decoder using the oracle query by\nreplicating its predictions and attention. Our proposed framework achieves\nstate-of-the-art performance on four datasets, namely Ego4D, Epic-Kitchens,\nMECCANO, and 100DOH, which demonstrates the effectiveness of our approach in\nimproving AOD.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Dejie Yang",
            "Yang Liu"
        ],
        "published": "2024-05-21T05:39:31Z"
    },
    {
        "title": "Compiler support for semi-manual AoS-to-SoA conversions with data views",
        "link": "http://arxiv.org/abs/2405.12507v1",
        "abstract": "The C programming language and its cousins such as C++ stipulate the static\nstorage of sets of structured data: Developers have to commit to one, invariant\ndata model -- typically a structure-of-arrays (SoA) or an array-of-structs\n(AoS) -- unless they manually rearrange, i.e.~convert it throughout the\ncomputation. Whether AoS or SoA is favourable depends on the execution context\nand algorithm step. We propose a language extension based upon C++ attributes\nthrough which developers can guide the compiler what memory arrangements are to\nbe used. The compiler can then automatically convert (parts of) the data into\nthe format of choice prior to a calculation and convert results back\nafterwards. As all conversions are merely annotations, it is straightforward\nfor the developer to experiment with different storage formats and to pick\nsubsets of data that are subject to memory rearrangements. Our work implements\nthe annotations within Clang and demonstrates their potential impact through a\nsmoothed particle hydrodynamics (SPH) code.",
        "subjects": [
            "cs.PL"
        ],
        "authors": [
            "Pawel K. Radtke",
            "Tobias Weinzierl"
        ],
        "published": "2024-05-21T05:34:34Z"
    },
    {
        "title": "NOVA-3D: Non-overlapped Views for 3D Anime Character Reconstruction",
        "link": "http://arxiv.org/abs/2405.12505v1",
        "abstract": "In the animation industry, 3D modelers typically rely on front and back\nnon-overlapped concept designs to guide the 3D modeling of anime characters.\nHowever, there is currently a lack of automated approaches for generating anime\ncharacters directly from these 2D designs. In light of this, we explore a novel\ntask of reconstructing anime characters from non-overlapped views. This\npresents two main challenges: existing multi-view approaches cannot be directly\napplied due to the absence of overlapping regions, and there is a scarcity of\nfull-body anime character data and standard benchmarks. To bridge the gap, we\npresent Non-Overlapped Views for 3D \\textbf{A}nime Character Reconstruction\n(NOVA-3D), a new framework that implements a method for view-aware feature\nfusion to learn 3D-consistent features effectively and synthesizes full-body\nanime characters from non-overlapped front and back views directly. To\nfacilitate this line of research, we collected the NOVA-Human dataset, which\ncomprises multi-view images and accurate camera parameters for 3D anime\ncharacters. Extensive experiments demonstrate that the proposed method\noutperforms baseline approaches, achieving superior reconstruction of anime\ncharacters with exceptional detail fidelity. In addition, to further verify the\neffectiveness of our method, we applied it to the animation head reconstruction\ntask and improved the state-of-the-art baseline to 94.453 in SSIM, 7.726 in\nLPIPS, and 19.575 in PSNR on average. Codes and datasets are available at\nhttps://wanghongsheng01.github.io/NOVA-3D/.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hongsheng Wang",
            "Nanjie Yao",
            "Xinrui Zhou",
            "Shengyu Zhang",
            "Huahao Xu",
            "Fei Wu",
            "Feng Lin"
        ],
        "published": "2024-05-21T05:31:03Z"
    },
    {
        "title": "CLRKDNet: Speeding up Lane Detection with Knowledge Distillation",
        "link": "http://arxiv.org/abs/2405.12503v1",
        "abstract": "Road lanes are integral components of the visual perception systems in\nintelligent vehicles, playing a pivotal role in safe navigation. In lane\ndetection tasks, balancing accuracy with real-time performance is essential,\nyet existing methods often sacrifice one for the other. To address this\ntrade-off, we introduce CLRKDNet, a streamlined model that balances detection\naccuracy with real-time performance. The state-of-the-art model CLRNet has\ndemonstrated exceptional performance across various datasets, yet its\ncomputational overhead is substantial due to its Feature Pyramid Network (FPN)\nand muti-layer detection head architecture. Our method simplifies both the FPN\nstructure and detection heads, redesigning them to incorporate a novel\nteacher-student distillation process alongside a newly introduced series of\ndistillation losses. This combination reduces inference time by up to 60% while\nmaintaining detection accuracy comparable to CLRNet. This strategic balance of\naccuracy and speed makes CLRKDNet a viable solution for real-time lane\ndetection tasks in autonomous driving applications.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Weiqing Qi",
            "Guoyang Zhao",
            "Fulong Ma",
            "Linwei Zheng",
            "Ming Liu"
        ],
        "published": "2024-05-21T05:20:04Z"
    },
    {
        "title": "EntropyStop: Unsupervised Deep Outlier Detection with Loss Entropy",
        "link": "http://arxiv.org/abs/2405.12502v1",
        "abstract": "Unsupervised Outlier Detection (UOD) is an important data mining task. With\nthe advance of deep learning, deep Outlier Detection (OD) has received broad\ninterest. Most deep UOD models are trained exclusively on clean datasets to\nlearn the distribution of the normal data, which requires huge manual efforts\nto clean the real-world data if possible. Instead of relying on clean datasets,\nsome approaches directly train and detect on unlabeled contaminated datasets,\nleading to the need for methods that are robust to such conditions. Ensemble\nmethods emerged as a superior solution to enhance model robustness against\ncontaminated training sets. However, the training time is greatly increased by\nthe ensemble.\n  In this study, we investigate the impact of outliers on the training phase,\naiming to halt training on unlabeled contaminated datasets before performance\ndegradation. Initially, we noted that blending normal and anomalous data causes\nAUC fluctuations, a label-dependent measure of detection accuracy. To\ncircumvent the need for labels, we propose a zero-label entropy metric named\nLoss Entropy for loss distribution, enabling us to infer optimal stopping\npoints for training without labels. Meanwhile, we theoretically demonstrate\nnegative correlation between entropy metric and the label-based AUC. Based on\nthis, we develop an automated early-stopping algorithm, EntropyStop, which\nhalts training when loss entropy suggests the maximum model detection\ncapability. We conduct extensive experiments on ADBench (including 47 real\ndatasets), and the overall results indicate that AutoEncoder (AE) enhanced by\nour approach not only achieves better performance than ensemble AEs but also\nrequires under 1\\% of training time. Lastly, our proposed metric and\nearly-stopping approach are evaluated on other deep OD models, exhibiting their\nbroad potential applicability.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Yihong Huang",
            "Yuang Zhang",
            "Liping Wang",
            "Fan Zhang",
            "Xuemin Lin"
        ],
        "published": "2024-05-21T05:17:43Z"
    },
    {
        "title": "Entropic associative memory for real world images",
        "link": "http://arxiv.org/abs/2405.12500v1",
        "abstract": "The entropic associative memory (EAM) is a computational model of natural\nmemory incorporating some of its putative properties of being associative,\ndistributed, declarative, abstractive and constructive. Previous experiments\nsatisfactorily tested the model on structured, homogeneous and conventional\ndata: images of manuscripts digits and letters, images of clothing, and phone\nrepresentations. In this work we show that EAM appropriately stores, recognizes\nand retrieves complex and unconventional images of animals and vehicles.\nAdditionally, the memory system generates meaningful retrieval association\nchains for such complex images. The retrieved objects can be seen as proper\nmemories, associated recollections or products of imagination.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Noé Hernández",
            "Rafael Morales",
            "Luis A. Pineda"
        ],
        "published": "2024-05-21T05:00:30Z"
    },
    {
        "title": "RaBitQ: Quantizing High-Dimensional Vectors with a Theoretical Error\n  Bound for Approximate Nearest Neighbor Search",
        "link": "http://arxiv.org/abs/2405.12497v1",
        "abstract": "Searching for approximate nearest neighbors (ANN) in the high-dimensional\nEuclidean space is a pivotal problem. Recently, with the help of fast\nSIMD-based implementations, Product Quantization (PQ) and its variants can\noften efficiently and accurately estimate the distances between the vectors and\nhave achieved great success in the in-memory ANN search. Despite their\nempirical success, we note that these methods do not have a theoretical error\nbound and are observed to fail disastrously on some real-world datasets.\nMotivated by this, we propose a new randomized quantization method named\nRaBitQ, which quantizes $D$-dimensional vectors into $D$-bit strings. RaBitQ\nguarantees a sharp theoretical error bound and provides good empirical accuracy\nat the same time. In addition, we introduce efficient implementations of\nRaBitQ, supporting to estimate the distances with bitwise operations or\nSIMD-based operations. Extensive experiments on real-world datasets confirm\nthat (1) our method outperforms PQ and its variants in terms of\naccuracy-efficiency trade-off by a clear margin and (2) its empirical\nperformance is well-aligned with our theoretical analysis.",
        "subjects": [
            "cs.DB",
            "cs.DS",
            "cs.IR"
        ],
        "authors": [
            "Jianyang Gao",
            "Cheng Long"
        ],
        "published": "2024-05-21T04:55:04Z"
    },
    {
        "title": "A Survey of Integrating Wireless Technology into Active Noise Control",
        "link": "http://arxiv.org/abs/2405.12496v1",
        "abstract": "Active Noise Control (ANC) is a widely adopted technology for reducing\nenvironmental noise across various scenarios. This paper focuses on enhancing\nnoise reduction performance, particularly through the refinement of signal\nquality fed into ANC systems. We discuss the main wireless technique integrated\ninto the ANC system, equipped with some innovative algorithms, in diverse\nenvironments. Instead of using microphone arrays, which increase the\ncomputation complexity of the ANC system, to isolate multiple noise sources to\nimprove noise reduction performance, the application of the wireless technique\navoids extra computation demand. Wireless transmissions of reference, error,\nand control signals are also applied to improve the convergence performance of\nthe ANC system. Furthermore, this paper lists some wireless ANC applications,\nsuch as earbuds, headphones, windows, and headrests, underscoring their\nadaptability and efficiency in various settings.",
        "subjects": [
            "eess.AS",
            "cs.NI",
            "cs.SD",
            "eess.SP"
        ],
        "authors": [
            "Xiaoyi Shen",
            "Dongyuan Shi",
            "Zhengding Luo",
            "Junwei Ji",
            "Woon-Seng Gan"
        ],
        "published": "2024-05-21T04:53:39Z"
    },
    {
        "title": "Exploring Dark Knowledge under Various Teacher Capacities and Addressing\n  Capacity Mismatch",
        "link": "http://arxiv.org/abs/2405.13078v1",
        "abstract": "Knowledge Distillation (KD) could transfer the ``dark knowledge\" of a\nwell-performed yet large neural network to a weaker but lightweight one. From\nthe view of output logits and softened probabilities, this paper goes deeper\ninto the dark knowledge provided by teachers with different capacities. Two\nfundamental observations are: (1) a larger teacher tends to produce probability\nvectors that are less distinct between non-ground-truth classes; (2) teachers\nwith different capacities are basically consistent in their cognition of\nrelative class affinity. Abundant experimental studies verify these\nobservations and in-depth empirical explanations are provided. The difference\nin dark knowledge leads to the peculiar phenomenon named ``capacity mismatch\"\nthat a more accurate teacher does not necessarily perform as well as a smaller\nteacher when teaching the same student network. Enlarging the distinctness\nbetween non-ground-truth class probabilities for larger teachers could address\nthe capacity mismatch problem. This paper explores multiple simple yet\neffective ways to achieve this goal and verify their success by comparing them\nwith popular KD methods that solve the capacity mismatch.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Xin-Chun Li",
            "Wen-Shu Fan",
            "Bowen Tao",
            "Le Gan",
            "De-Chuan Zhan"
        ],
        "published": "2024-05-21T04:43:15Z"
    },
    {
        "title": "Phishing Email Detection Using Inputs From Artificial Intelligence",
        "link": "http://arxiv.org/abs/2405.12494v1",
        "abstract": "Enterprise security is increasingly being threatened by social engineering\nattacks, such as phishing, which deceive employees into giving access to\nenterprise data. To protect both the users themselves and enterprise data, more\nand more organizations provide cyber security training that seeks to teach\nemployees/customers to identify and report suspicious content. By its very\nnature, such training seeks to focus on signals that are likely to persist\nacross a wide range of attacks. Further, it expects the user to apply the\nlearnings from these training on e-mail messages that were not filtered by\nexisting, automatic enterprise security (e.g., spam filters and commercial\nphishing detection software). However, relying on such training now shifts the\ndetection of phishing from an automatic process to a human driven one which is\nfallible especially when a user errs due to distraction, forgetfulness, etc. In\nthis work we explore treating this type of detection as a natural language\nprocessing task and modifying training pipelines accordingly. We present a\ndataset with annotated labels where these labels are created from the classes\nof signals that users are typically asked to identify in such training. We also\npresent baseline classifier models trained on these classes of labels. With a\ncomparative analysis of performance between human annotators and the models on\nthese labels, we provide insights which can contribute to the improvement of\nthe respective curricula for both machine and human training.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Mithün Paul",
            "Genevieve Bartlett",
            "Jelena Mirkovic",
            "Marjorie Freedman"
        ],
        "published": "2024-05-21T04:37:23Z"
    },
    {
        "title": "Visualizing, Rethinking, and Mining the Loss Landscape of Deep Neural\n  Networks",
        "link": "http://arxiv.org/abs/2405.12493v1",
        "abstract": "The loss landscape of deep neural networks (DNNs) is commonly considered\ncomplex and wildly fluctuated. However, an interesting observation is that the\nloss surfaces plotted along Gaussian noise directions are almost v-basin ones\nwith the perturbed model lying on the basin. This motivates us to rethink\nwhether the 1D or 2D subspace could cover more complex local geometry\nstructures, and how to mine the corresponding perturbation directions. This\npaper systematically and gradually categorizes the 1D curves from simple to\ncomplex, including v-basin, v-side, w-basin, w-peak, and vvv-basin curves.\nNotably, the latter two types are already hard to obtain via the intuitive\nconstruction of specific perturbation directions, and we need to propose proper\nmining algorithms to plot the corresponding 1D curves. Combining these 1D\ndirections, various types of 2D surfaces are visualized such as the saddle\nsurfaces and the bottom of a bottle of wine that are only shown by demo\nfunctions in previous works. Finally, we propose theoretical insights from the\nlens of the Hessian matrix to explain the observed several interesting\nphenomena.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Xin-Chun Li",
            "Lan Li",
            "De-Chuan Zhan"
        ],
        "published": "2024-05-21T04:30:09Z"
    },
    {
        "title": "Bridging the Gap Between Domain-specific Frameworks and Multiple\n  Hardware Devices",
        "link": "http://arxiv.org/abs/2405.12491v1",
        "abstract": "The rapid development of domain-specific frameworks has presented us with a\nsignificant challenge: The current approach of implementing solutions on a\ncase-by-case basis incurs a theoretical complexity of O(M*N), thereby\nincreasing the cost of porting applications to different hardware platforms. To\naddress these challenges, we propose a systematic methodology that effectively\nbridges the gap between domain-specific frameworks and multiple hardware\ndevices, reducing porting complexity to O(M+N). The approach utilizes\nmulti-layer abstractions. Different domain-specific abstractions are employed\nto represent applications from various domains. These abstractions are then\ntransformed into a unified abstraction, which is subsequently translated into\ncombinations of primitive operators. Finally, these operators are mapped to\nmultiple hardware platforms. The implemented unified framework supports deep\nlearning, classical machine learning, and data analysis across X86, ARM,\nRISC-V, IoT devices, and GPU. It outperforms existing solutions like\nscikit-learn, hummingbird, Spark, and pandas, achieving impressive speedups:\n1.1x to 3.83x on X86 servers, 1.06x to 4.33x on ARM IoT devices, 1.25x to 3.72x\non RISC-V IoT devices, and 1.93x on GPU. The source code is available at\nhttps://github.com/BenchCouncil/bridger.git.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Xu Wen",
            "Wanling Gao",
            "Lei Wang",
            "Jianfeng Zhan"
        ],
        "published": "2024-05-21T04:24:47Z"
    },
    {
        "title": "Customize Your Own Paired Data via Few-shot Way",
        "link": "http://arxiv.org/abs/2405.12490v1",
        "abstract": "Existing solutions to image editing tasks suffer from several issues. Though\nachieving remarkably satisfying generated results, some supervised methods\nrequire huge amounts of paired training data, which greatly limits their\nusages. The other unsupervised methods take full advantage of large-scale\npre-trained priors, thus being strictly restricted to the domains where the\npriors are trained on and behaving badly in out-of-distribution cases. The task\nwe focus on is how to enable the users to customize their desired effects\nthrough only few image pairs. In our proposed framework, a novel few-shot\nlearning mechanism based on the directional transformations among samples is\nintroduced and expands the learnable space exponentially. Adopting a diffusion\nmodel pipeline, we redesign the condition calculating modules in our model and\napply several technical improvements. Experimental results demonstrate the\ncapabilities of our method in various cases.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jinshu Chen",
            "Bingchuan Li",
            "Miao Hua",
            "Panpan Xu",
            "Qian He"
        ],
        "published": "2024-05-21T04:21:35Z"
    },
    {
        "title": "Exploring and Exploiting the Asymmetric Valley of Deep Neural Networks",
        "link": "http://arxiv.org/abs/2405.12489v1",
        "abstract": "Exploring the loss landscape offers insights into the inherent principles of\ndeep neural networks (DNNs). Recent work suggests an additional asymmetry of\nthe valley beyond the flat and sharp ones, yet without thoroughly examining its\ncauses or implications. Our study methodically explores the factors affecting\nthe symmetry of DNN valleys, encompassing (1) the dataset, network\narchitecture, initialization, and hyperparameters that influence the\nconvergence point; and (2) the magnitude and direction of the noise for 1D\nvisualization. Our major observation shows that the {\\it degree of sign\nconsistency} between the noise and the convergence point is a critical\nindicator of valley symmetry. Theoretical insights from the aspects of ReLU\nactivation and softmax function could explain the interesting phenomenon. Our\ndiscovery propels novel understanding and applications in the scenario of Model\nFusion: (1) the efficacy of interpolating separate models significantly\ncorrelates with their sign consistency ratio, and (2) imposing sign alignment\nduring federated learning emerges as an innovative approach for model parameter\nalignment.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Xin-Chun Li",
            "Jin-Lin Tang",
            "Bo Zhang",
            "Lan Li",
            "De-Chuan Zhan"
        ],
        "published": "2024-05-21T04:18:57Z"
    },
    {
        "title": "3DSS-Mamba: 3D-Spectral-Spatial Mamba for Hyperspectral Image\n  Classification",
        "link": "http://arxiv.org/abs/2405.12487v1",
        "abstract": "Hyperspectral image (HSI) classification constitutes the fundamental research\nin remote sensing fields. Convolutional Neural Networks (CNNs) and Transformers\nhave demonstrated impressive capability in capturing spectral-spatial\ncontextual dependencies. However, these architectures suffer from limited\nreceptive fields and quadratic computational complexity, respectively.\nFortunately, recent Mamba architectures built upon the State Space Model\nintegrate the advantages of long-range sequence modeling and linear\ncomputational efficiency, exhibiting substantial potential in low-dimensional\nscenarios. Motivated by this, we propose a novel 3D-Spectral-Spatial Mamba\n(3DSS-Mamba) framework for HSI classification, allowing for global\nspectral-spatial relationship modeling with greater computational efficiency.\nTechnically, a spectral-spatial token generation (SSTG) module is designed to\nconvert the HSI cube into a set of 3D spectral-spatial tokens. To overcome the\nlimitations of traditional Mamba, which is confined to modeling causal\nsequences and inadaptable to high-dimensional scenarios, a 3D-Spectral-Spatial\nSelective Scanning (3DSS) mechanism is introduced, which performs pixel-wise\nselective scanning on 3D hyperspectral tokens along the spectral and spatial\ndimensions. Five scanning routes are constructed to investigate the impact of\ndimension prioritization. The 3DSS scanning mechanism combined with\nconventional mapping operations forms the 3D-spectral-spatial mamba block\n(3DMB), enabling the extraction of global spectral-spatial semantic\nrepresentations. Experimental results and analysis demonstrate that the\nproposed method outperforms the state-of-the-art methods on HSI classification\nbenchmarks.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Yan He",
            "Bing Tu",
            "Bo Liu",
            "Jun Li",
            "Antonio Plaza"
        ],
        "published": "2024-05-21T04:10:26Z"
    },
    {
        "title": "Time Matters: Enhancing Pre-trained News Recommendation Models with\n  Robust User Dwell Time Injection",
        "link": "http://arxiv.org/abs/2405.12486v1",
        "abstract": "Large Language Models (LLMs) have revolutionized text comprehension, leading\nto State-of-the-Art (SOTA) news recommendation models that utilize LLMs for\nin-depth news understanding. Despite this, accurately modeling user preferences\nremains challenging due to the inherent uncertainty of click behaviors.\nTechniques like multi-head attention in Transformers seek to alleviate this by\ncapturing interactions among clicks, yet they fall short in integrating\nexplicit feedback signals. User Dwell Time emerges as a powerful indicator,\noffering the potential to enhance the weak signals emanating from clicks.\nNonetheless, its real-world applicability is questionable, especially when\ndwell time data collection is subject to delays. To bridge this gap, this paper\nproposes two novel and robust dwell time injection strategies, namely Dwell\ntime Weight (DweW) and Dwell time Aware (DweA). Dwe} concentrates on refining\nEffective User Clicks through detailed analysis of dwell time, integrating with\ninitial behavioral inputs to construct a more robust user preference. DweA\nempowers the model with awareness of dwell time information, thereby\nfacilitating autonomous adjustment of attention values in user modeling. This\nenhancement sharpens the model's ability to accurately identify user\npreferences. In our experiment using the real-world news dataset from MSN\nwebsite, we validated that our two strategies significantly improve\nrecommendation performance, favoring high-quality news. Crucially, our\napproaches exhibit robustness to user dwell time information, maintaining their\nability to recommend high-quality content even in extreme cases where dwell\ntime data is entirely missing.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "authors": [
            "Hao Jiang",
            "Chuanzhen Li",
            "Mingxiao An"
        ],
        "published": "2024-05-21T04:08:07Z"
    },
    {
        "title": "Meta-Homogenization for Knitwear Simulation",
        "link": "http://arxiv.org/abs/2405.12484v2",
        "abstract": "This paper presents meta-homogenization, a spatially varying homogenization\nscheme for knitwear simulation. We are motivated by the observation that\nmacro-scale fabric dynamics is strongly correlated with its underlying knitting\npatterns. Therefore, homogenization towards a single material is less effective\nwhen the knitting is complex and non-repetitive. Our method tackles this\nchallenge by homogenizing the yarn-level material locally at volumetric\nelements. Assigning a virtual volume of a knitting structure enables us to\nmodel bending and twisting effects via a simple volume-preserving penalty and\nthus effectively alleviates the material nonlinearity. We employ an adjoint\nGauss-Newton formulation to battle the dimensionality challenge of such\nper-element material optimization. This intuitive material model makes the\nforward simulation GPU-friendly. To this end, our pipeline also equips a novel\ndomain-decomposed subspace solver crafted for GPU projective dynamics, which\nmakes our simulator hundreds of times faster than the yarn-level simulator.\nExperiments validate the capability and effectiveness of meta-homogenization.\nOur method produces realistic animations of knitwear matching the quality of\nfull-scale yarn-level simulations. It is also orders of magnitude faster than\nexisting homogenization techniques in both the training and simulation stages.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Chun Yuan",
            "Kui Wu",
            "Haoyang Shi",
            "Lei Lan",
            "Yuxing Qiu",
            "Cem Yuksel",
            "Huamin Wang",
            "Chenfanfu Jiang",
            "Yin Yang"
        ],
        "published": "2024-05-21T04:06:14Z"
    },
    {
        "title": "Towards Detecting and Mitigating Cognitive Bias in Spoken Conversational\n  Search",
        "link": "http://arxiv.org/abs/2405.12480v1",
        "abstract": "Instruments such as eye-tracking devices have contributed to understanding\nhow users interact with screen-based search engines. However, user-system\ninteractions in audio-only channels -- as is the case for Spoken Conversational\nSearch (SCS) -- are harder to characterize, given the lack of instruments to\neffectively and precisely capture interactions. Furthermore, in this era of\ninformation overload, cognitive bias can significantly impact how we seek and\nconsume information -- especially in the context of controversial topics or\nmultiple viewpoints. This paper draws upon insights from multiple disciplines\n(including information seeking, psychology, cognitive science, and wearable\nsensors) to provoke novel conversations in the community. To this end, we\ndiscuss future opportunities and propose a framework including multimodal\ninstruments and methods for experimental designs and settings. We demonstrate\npreliminary results as an example. We also outline the challenges and offer\nsuggestions for adopting this multimodal approach, including ethical\nconsiderations, to assist future researchers and practitioners in exploring\ncognitive biases in SCS.",
        "subjects": [
            "cs.HC",
            "cs.IR"
        ],
        "authors": [
            "Kaixin Ji",
            "Sachin Pathiyan Cherumanal",
            "Johanne R. Trippas",
            "Danula Hettiachchi",
            "Flora D. Salim",
            "Falk Scholer",
            "Damiano Spina"
        ],
        "published": "2024-05-21T03:50:32Z"
    },
    {
        "title": "Efficient Economic Model Predictive Control of Water Treatment Process\n  with Learning-based Koopman Operator",
        "link": "http://arxiv.org/abs/2405.12478v1",
        "abstract": "Used water treatment plays a pivotal role in advancing environmental\nsustainability. Economic model predictive control holds the promise of\nenhancing the overall operational performance of the water treatment\nfacilities. In this study, we propose a data-driven economic predictive control\napproach within the Koopman modeling framework. First, we propose a deep\nlearning-enabled input-output Koopman modeling approach, which predicts the\noverall economic operational cost of the wastewater treatment process based on\ninput data and available output measurements that are directly linked to the\noperational costs. Subsequently, by leveraging this learned input-output\nKoopman model, a convex economic predictive control scheme is developed. The\nresulting predictive control problem can be efficiently solved by leveraging\nquadratic programming solvers, and complex non-convex optimization problems are\nbypassed. The proposed method is applied to a benchmark wastewater treatment\nprocess. The proposed method significantly improves the overall economic\noperational performance of the water treatment process. Additionally, the\ncomputational efficiency of the proposed method is significantly enhanced as\ncompared to benchmark control solutions.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Minghao Han",
            "Jingshi Yao",
            "Adrian Wing-Keung Law",
            "Xunyuan Yin"
        ],
        "published": "2024-05-21T03:42:34Z"
    },
    {
        "title": "Gaussian Control with Hierarchical Semantic Graphs in 3D Human Recovery",
        "link": "http://arxiv.org/abs/2405.12477v1",
        "abstract": "Although 3D Gaussian Splatting (3DGS) has recently made progress in 3D human\nreconstruction, it primarily relies on 2D pixel-level supervision, overlooking\nthe geometric complexity and topological relationships of different body parts.\nTo address this gap, we introduce the Hierarchical Graph Human Gaussian Control\n(HUGS) framework for achieving high-fidelity 3D human reconstruction. Our\napproach involves leveraging explicitly semantic priors of body parts to ensure\nthe consistency of geometric topology, thereby enabling the capture of the\ncomplex geometrical and topological associations among body parts.\nAdditionally, we disentangle high-frequency features from global human features\nto refine surface details in body parts. Extensive experiments demonstrate that\nour method exhibits superior performance in human body reconstruction,\nparticularly in enhancing surface details and accurately reconstructing body\npart junctions. Codes are available at https://wanghongsheng01.github.io/HUGS/.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hongsheng Wang",
            "Weiyue Zhang",
            "Sihao Liu",
            "Xinrui Zhou",
            "Shengyu Zhang",
            "Fei Wu",
            "Feng Lin"
        ],
        "published": "2024-05-21T03:40:56Z"
    },
    {
        "title": "Benchmarking Fish Dataset and Evaluation Metric in Keypoint Detection --\n  Towards Precise Fish Morphological Assessment in Aquaculture Breeding",
        "link": "http://arxiv.org/abs/2405.12476v1",
        "abstract": "Accurate phenotypic analysis in aquaculture breeding necessitates the\nquantification of subtle morphological phenotypes. Existing datasets suffer\nfrom limitations such as small scale, limited species coverage, and inadequate\nannotation of keypoints for measuring refined and complex morphological\nphenotypes of fish body parts. To address this gap, we introduce FishPhenoKey,\na comprehensive dataset comprising 23,331 high-resolution images spanning six\nfish species. Notably, FishPhenoKey includes 22 phenotype-oriented annotations,\nenabling the capture of intricate morphological phenotypes. Motivated by the\nnuanced evaluation of these subtle morphologies, we also propose a new\nevaluation metric, Percentage of Measured Phenotype (PMP). It is designed to\nassess the accuracy of individual keypoint positions and is highly sensitive to\nthe phenotypes measured using the corresponding keypoints. To enhance keypoint\ndetection accuracy, we further propose a novel loss, Anatomically-Calibrated\nRegularization (ACR), that can be integrated into keypoint detection models,\nleveraging biological insights to refine keypoint localization. Our\ncontributions set a new benchmark in fish phenotype analysis, addressing the\nchallenges of precise morphological quantification and opening new avenues for\nresearch in sustainable aquaculture and genetic studies. Our dataset and code\nare available at https://github.com/WeizhenLiuBioinform/Fish-Phenotype-Detect.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Weizhen Liu",
            "Jiayu Tan",
            "Guangyu Lan",
            "Ao Li",
            "Dongye Li",
            "Le Zhao",
            "Xiaohui Yuan",
            "Nanqing Dong"
        ],
        "published": "2024-05-21T03:36:13Z"
    },
    {
        "title": "GASE: Graph Attention Sampling with Edges Fusion for Solving Vehicle\n  Routing Problems",
        "link": "http://arxiv.org/abs/2405.12475v1",
        "abstract": "Learning-based methods have become increasingly popular for solving vehicle\nrouting problems due to their near-optimal performance and fast inference\nspeed. Among them, the combination of deep reinforcement learning and graph\nrepresentation allows for the abstraction of node topology structures and\nfeatures in an encoder-decoder style. Such an approach makes it possible to\nsolve routing problems end-to-end without needing complicated heuristic\noperators designed by domain experts. Existing research studies have been\nfocusing on novel encoding and decoding structures via various neural network\nmodels to enhance the node embedding representation. Despite the sophisticated\napproaches applied, there is a noticeable lack of consideration for the\ngraph-theoretic properties inherent to routing problems. Moreover, the\npotential ramifications of inter-nodal interactions on the decision-making\nefficacy of the models have not been adequately explored. To bridge this gap,\nwe propose an adaptive Graph Attention Sampling with the Edges Fusion framework\n(GASE),where nodes' embedding is determined through attention calculation from\ncertain highly correlated neighbourhoods and edges, utilizing a filtered\nadjacency matrix. In detail, the selections of particular neighbours and\nadjacency edges are led by a multi-head attention mechanism, contributing\ndirectly to the message passing and node embedding in graph attention sampling\nnetworks. Furthermore, we incorporate an adaptive actor-critic algorithm with\npolicy improvements to expedite the training convergence. We then conduct\ncomprehensive experiments against baseline methods on learning-based VRP tasks\nfrom different perspectives. Our proposed model outperforms the existing\nmethods by 2.08\\%-6.23\\% and shows stronger generalization ability, achieving\nstate-of-the-art performance on randomly generated instances and real-world\ndatasets.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Zhenwei Wang",
            "Ruibin Bai",
            "Fazlullah Khan",
            "Ender Ozcan",
            "Tiehua Zhang"
        ],
        "published": "2024-05-21T03:33:07Z"
    },
    {
        "title": "How Universal Polynomial Bases Enhance Spectral Graph Neural Networks:\n  Heterophily, Over-smoothing, and Over-squashing",
        "link": "http://arxiv.org/abs/2405.12474v1",
        "abstract": "Spectral Graph Neural Networks (GNNs), alternatively known as graph filters,\nhave gained increasing prevalence for heterophily graphs. Optimal graph filters\nrely on Laplacian eigendecomposition for Fourier transform. In an attempt to\navert prohibitive computations, numerous polynomial filters have been proposed.\nHowever, polynomials in the majority of these filters are predefined and remain\nfixed across different graphs, failing to accommodate the varying degrees of\nheterophily. Addressing this gap, we demystify the intrinsic correlation\nbetween the spectral property of desired polynomial bases and the heterophily\ndegrees via thorough theoretical analyses. Subsequently, we develop a novel\nadaptive heterophily basis wherein the basis vectors mutually form angles\nreflecting the heterophily degree of the graph. We integrate this heterophily\nbasis with the homophily basis to construct a universal polynomial basis\nUniBasis, which devises a polynomial filter based graph neural network -\nUniFilter. It optimizes the convolution and propagation in GNN, thus\neffectively limiting over-smoothing and alleviating over-squashing. Our\nextensive experiments, conducted on a diverse range of real-world and synthetic\ndatasets with varying degrees of heterophily, support the superiority of\nUniFilter. These results not only demonstrate the universality of UniBasis but\nalso highlight its proficiency in graph explanation.",
        "subjects": [
            "cs.LG",
            "cs.SI"
        ],
        "authors": [
            "Keke Huang",
            "Yu Guang Wang",
            "Ming Li",
            "and Pietro Liò"
        ],
        "published": "2024-05-21T03:28:45Z"
    },
    {
        "title": "Learning Partially Aligned Item Representation for Cross-Domain\n  Sequential Recommendation",
        "link": "http://arxiv.org/abs/2405.12473v1",
        "abstract": "Cross-domain sequential recommendation (CDSR) aims to uncover and transfer\nusers' sequential preferences across multiple recommendation domains. While\nsignificant endeavors have been made, they primarily concentrated on developing\nadvanced transfer modules and aligning user representations using\nself-supervised learning techniques. However, the problem of aligning item\nrepresentations has received limited attention, and misaligned item\nrepresentations can potentially lead to sub-optimal sequential modeling and\nuser representation alignment. To this end, we propose a model-agnostic\nframework called \\textbf{C}ross-domain item representation \\textbf{A}lignment\nfor \\textbf{C}ross-\\textbf{D}omain \\textbf{S}equential \\textbf{R}ecommendation\n(\\textbf{CA-CDSR}), which achieves sequence-aware generation and adaptively\npartial alignment for item representations. Specifically, we first develop a\nsequence-aware feature augmentation strategy, which captures both collaborative\nand sequential item correlations, thus facilitating holistic item\nrepresentation generation. Next, we conduct an empirical study to investigate\nthe partial representation alignment problem from a spectrum perspective. It\nmotivates us to devise an adaptive spectrum filter, achieving partial alignment\nadaptively. Furthermore, the aligned item representations can be fed into\ndifferent sequential encoders to obtain user representations. The entire\nframework is optimized in a multi-task learning paradigm with an annealing\nstrategy. Extensive experiments have demonstrated that CA-CDSR can surpass\nstate-of-the-art baselines by a significant margin and can effectively align\nitems in representation spaces to enhance performance.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "authors": [
            "Mingjia Yin",
            "Hao Wang",
            "Wei Guo",
            "Yong Liu",
            "Zhi Li",
            "Sirui Zhao",
            "Defu Lian",
            "Enhong Chen"
        ],
        "published": "2024-05-21T03:25:32Z"
    },
    {
        "title": "GPT-4 Jailbreaks Itself with Near-Perfect Success Using Self-Explanation",
        "link": "http://arxiv.org/abs/2405.13077v1",
        "abstract": "Research on jailbreaking has been valuable for testing and understanding the\nsafety and security issues of large language models (LLMs). In this paper, we\nintroduce Iterative Refinement Induced Self-Jailbreak (IRIS), a novel approach\nthat leverages the reflective capabilities of LLMs for jailbreaking with only\nblack-box access. Unlike previous methods, IRIS simplifies the jailbreaking\nprocess by using a single model as both the attacker and target. This method\nfirst iteratively refines adversarial prompts through self-explanation, which\nis crucial for ensuring that even well-aligned LLMs obey adversarial\ninstructions. IRIS then rates and enhances the output given the refined prompt\nto increase its harmfulness. We find IRIS achieves jailbreak success rates of\n98% on GPT-4 and 92% on GPT-4 Turbo in under 7 queries. It significantly\noutperforms prior approaches in automatic, black-box and interpretable\njailbreaking, while requiring substantially fewer queries, thereby establishing\na new standard for interpretable jailbreaking methods.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Govind Ramesh",
            "Yao Dou",
            "Wei Xu"
        ],
        "published": "2024-05-21T03:16:35Z"
    },
    {
        "title": "Optimizing Generative AI Networking: A Dual Perspective with Multi-Agent\n  Systems and Mixture of Experts",
        "link": "http://arxiv.org/abs/2405.12472v1",
        "abstract": "In the continued development of next-generation networking and artificial\nintelligence content generation (AIGC) services, the integration of multi-agent\nsystems (MAS) and the mixture of experts (MoE) frameworks is becoming\nincreasingly important. Motivated by this, this article studies the contrasting\nand converging of MAS and MoE in AIGC-enabled networking. First, we discuss the\narchitectural designs, operational procedures, and inherent advantages of using\nMAS and MoE in generative AI to explore its functionality and applications\nfully. Next, we review the applications of MAS and MoE frameworks in content\ngeneration and resource allocation, emphasizing their impact on networking\noperations. Subsequently, we propose a novel multi-agent-enabled MoE-proximal\npolicy optimization (MoE-PPO) framework for 3D object generation and data\ntransfer scenarios. The framework uses MAS for dynamic task coordination of\neach network service provider agent and MoE for expert-driven execution of\nrespective tasks, thereby improving overall system efficiency and adaptability.\nThe simulation results demonstrate the effectiveness of our proposed framework\nand significantly improve the performance indicators under different network\nconditions. Finally, we outline potential future research directions.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Ruichen Zhang",
            "Hongyang Du",
            "Dusit Niyato",
            "Jiawen Kang",
            "Zehui Xiong",
            "Ping Zhang",
            "Dong In Kim"
        ],
        "published": "2024-05-21T03:12:50Z"
    },
    {
        "title": "Last-Level Cache Side-Channel Attacks Are Feasible in the Modern Public\n  Cloud (Extended Version)",
        "link": "http://dx.doi.org/10.1145/3620665.3640403",
        "abstract": "Last-level cache side-channel attacks have been mostly demonstrated in\nhighly-controlled, quiescent local environments. Hence, it is unclear whether\nsuch attacks are feasible in a production cloud environment. In the cloud, side\nchannels are flooded with noise from activities of other tenants and, in\nFunction-as-a-Service (FaaS) workloads, the attacker has a very limited time\nwindow to mount the attack. In this paper, we show that such attacks are\nfeasible in practice, although they require new techniques. We present an\nend-to-end, cross-tenant attack on a vulnerable ECDSA implementation in the\npublic FaaS Google Cloud Run environment. We introduce several new techniques\nto improve every step of the attack. First, to speed-up the generation of\neviction sets, we introduce L2-driven candidate address filtering and a Binary\nSearch-based algorithm for address pruning. Second, to monitor victim memory\naccesses with high time resolution, we introduce Parallel Probing. Finally, we\nleverage power spectral density from signal processing to easily identify the\nvictim's target cache set in the frequency domain. Overall, using these\nmechanisms, we extract a median value of 81% of the secret ECDSA nonce bits\nfrom a victim container in 19 seconds on average.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Zirui Neil Zhao",
            "Adam Morrison",
            "Christopher W. Fletcher",
            "Josep Torrellas"
        ],
        "published": "2024-05-21T03:05:29Z"
    },
    {
        "title": "Leveraging Diverse Data Generation for Adaptable Zero-Shot Dialogue\n  State Tracking",
        "link": "http://arxiv.org/abs/2405.12468v1",
        "abstract": "This work demonstrates that substantial gains in zero-shot dialogue state\ntracking (DST) accuracy can be achieved by increasing the diversity of training\ndata using synthetic data generation techniques. Current DST training resources\nare severely limited in the number of application domains and slot types they\ncover due to the high costs of data collection, resulting in limited\nadaptability to new domains. The presented work overcomes this challenge using\na novel, fully automatic data generation approach to create synthetic zero-shot\nDST training resources. Unlike previous approaches for generating DST data, the\npresented approach generates entirely new application domains to generate\ndialogues, complete with silver dialogue state annotations and slot\ndescriptions. This approach is used to create the D0T dataset for training\nzero-shot DST models, which covers an unprecedented 1,000+ domains. Experiments\nperformed on the MultiWOZ benchmark indicate that training models on diverse\nsynthetic data yields a performance improvement of +6.7% Joint Goal Accuracy,\nachieving results competitive with much larger models.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "James D. Finch",
            "Boxin Zhao",
            "Jinho D. Choi"
        ],
        "published": "2024-05-21T03:04:14Z"
    },
    {
        "title": "A finite element-based physics-informed operator learning framework for\n  spatiotemporal partial differential equations on arbitrary domains",
        "link": "http://arxiv.org/abs/2405.12465v2",
        "abstract": "We propose a novel finite element-based physics-informed operator learning\nframework that allows for predicting spatiotemporal dynamics governed by\npartial differential equations (PDEs). The proposed framework employs a loss\nfunction inspired by the finite element method (FEM) with the implicit Euler\ntime integration scheme. A transient thermal conduction problem is considered\nto benchmark the performance. The proposed operator learning framework takes a\ntemperature field at the current time step as input and predicts a temperature\nfield at the next time step. The Galerkin discretized weak formulation of the\nheat equation is employed to incorporate physics into the loss function, which\nis coined finite operator learning (FOL). Upon training, the networks\nsuccessfully predict the temperature evolution over time for any initial\ntemperature field at high accuracy compared to the FEM solution. The framework\nis also confirmed to be applicable to a heterogeneous thermal conductivity and\narbitrary geometry. The advantages of FOL can be summarized as follows: First,\nthe training is performed in an unsupervised manner, avoiding the need for a\nlarge data set prepared from costly simulations or experiments. Instead, random\ntemperature patterns generated by the Gaussian random process and the Fourier\nseries, combined with constant temperature fields, are used as training data to\ncover possible temperature cases. Second, shape functions and backward\ndifference approximation are exploited for the domain discretization, resulting\nin a purely algebraic equation. This enhances training efficiency, as one\navoids time-consuming automatic differentiation when optimizing weights and\nbiases while accepting possible discretization errors. Finally, thanks to the\ninterpolation power of FEM, any arbitrary geometry can be handled with FOL,\nwhich is crucial to addressing various engineering application scenarios.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yusuke Yamazaki",
            "Ali Harandi",
            "Mayu Muramatsu",
            "Alexandre Viardin",
            "Markus Apel",
            "Tim Brepols",
            "Stefanie Reese",
            "Shahed Rezaei"
        ],
        "published": "2024-05-21T02:41:40Z"
    },
    {
        "title": "Evaluation of Connected Vehicle Identification-Aware Mixed Traffic\n  Freeway Cooperative Merging",
        "link": "http://arxiv.org/abs/2405.12464v1",
        "abstract": "Cooperative on-ramp merging control for connected automated vehicles (CAVs)\nhas been extensively investigated. However, they did neglect the connected\nvehicle identification process, which is a must for CAV cooperations. In this\npaper, we introduced a connected vehicle identification system (VIS) into the\non-ramp merging control process for the first time and proposed an evaluation\nframework to assess the impacts of VIS on on-ramp merging performance. First,\nthe mixed-traffic cooperative merging problem was formulated. Then, a\nreal-world merging trajectory dataset was processed to generate dangerous\nmerging scenarios. Aiming at resolving the potential collision risks in mixed\ntraffic where CAVs and traditional human-driven vehicles (THVs) coexist, we\nproposed on-ramp merging strategies for CAVs in different mixed traffic\nsituations considering the connected vehicle identification process. The\nperformances were evaluated via simulations. Results indicated that while\nsafety was assured for all cases with CAVs, the cases with VIS had delayed\ninitiation of cooperation, limiting the range of cooperative merging and\nleading to increased fuel consumption and acceleration variations.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Haoji Liu",
            "Fatemeh Jahedinia",
            "Zeyu Mu",
            "B. Brian Park"
        ],
        "published": "2024-05-21T02:39:46Z"
    },
    {
        "title": "Stochastic Learning of Computational Resource Usage as Graph Structured\n  Multimarginal Schrödinger Bridge",
        "link": "http://arxiv.org/abs/2405.12463v1",
        "abstract": "We propose to learn the time-varying stochastic computational resource usage\nof software as a graph structured Schr\\\"odinger bridge problem. In general,\nlearning the computational resource usage from data is challenging because\nresources such as the number of CPU instructions and the number of last level\ncache requests are both time-varying and statistically correlated. Our proposed\nmethod enables learning the joint time-varying stochasticity in computational\nresource usage from the measured profile snapshots in a nonparametric manner.\nThe method can be used to predict the most-likely time-varying distribution of\ncomputational resource availability at a desired time. We provide detailed\nalgorithms for stochastic learning in both single and multi-core cases, discuss\nthe convergence guarantees, computational complexities, and demonstrate their\npractical use in two case studies: a single-core nonlinear model predictive\ncontroller, and a synthetic multi-core software.",
        "subjects": [
            "math.OC",
            "cs.AI",
            "cs.LG",
            "cs.SY",
            "eess.SY",
            "stat.ML"
        ],
        "authors": [
            "Georgiy A. Bondar",
            "Robert Gifford",
            "Linh Thi Xuan Phan",
            "Abhishek Halder"
        ],
        "published": "2024-05-21T02:39:45Z"
    },
    {
        "title": "Boosting X-formers with Structured Matrix for Long Sequence Time Series\n  Forecasting",
        "link": "http://arxiv.org/abs/2405.12462v2",
        "abstract": "Transformer-based models for long sequence time series forecasting (LSTF)\nproblems have gained significant attention due to their exceptional forecasting\nprecision. As the cornerstone of these models, the self-attention mechanism\nposes a challenge to efficient training and inference due to its quadratic time\ncomplexity. In this article, we propose a novel architectural design for\nTransformer-based models in LSTF, leveraging a substitution framework that\nincorporates Surrogate Attention Blocks and Surrogate FFN Blocks. The framework\naims to boost any well-designed model's efficiency without sacrificing its\naccuracy. We further establish the equivalence of the Surrogate Attention Block\nto the self-attention mechanism in terms of both expressiveness and\ntrainability. Through extensive experiments encompassing nine Transformer-based\nmodels across five time series tasks, we observe an average performance\nimprovement of 9.45% while achieving a significant reduction in model size by\n46%",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Zhicheng Zhang",
            "Yong Wang",
            "Shaoqi Tan",
            "Bowei Xia",
            "Yujie Luo"
        ],
        "published": "2024-05-21T02:37:47Z"
    },
    {
        "title": "WorldAfford: Affordance Grounding based on Natural Language Instructions",
        "link": "http://arxiv.org/abs/2405.12461v1",
        "abstract": "Affordance grounding aims to localize the interaction regions for the\nmanipulated objects in the scene image according to given instructions. A\ncritical challenge in affordance grounding is that the embodied agent should\nunderstand human instructions and analyze which tools in the environment can be\nused, as well as how to use these tools to accomplish the instructions. Most\nrecent works primarily supports simple action labels as input instructions for\nlocalizing affordance regions, failing to capture complex human objectives.\nMoreover, these approaches typically identify affordance regions of only a\nsingle object in object-centric images, ignoring the object context and\nstruggling to localize affordance regions of multiple objects in complex scenes\nfor practical applications. To address this concern, for the first time, we\nintroduce a new task of affordance grounding based on natural language\ninstructions, extending it from previously using simple labels for complex\nhuman instructions. For this new task, we propose a new framework, WorldAfford.\nWe design a novel Affordance Reasoning Chain-of-Thought Prompting to reason\nabout affordance knowledge from LLMs more precisely and logically.\nSubsequently, we use SAM and CLIP to localize the objects related to the\naffordance knowledge in the image. We identify the affordance regions of the\nobjects through an affordance region localization module. To benchmark this new\ntask and validate our framework, an affordance grounding dataset, LLMaFF, is\nconstructed. We conduct extensive experiments to verify that WorldAfford\nperforms state-of-the-art on both the previous AGD20K and the new LLMaFF\ndataset. In particular, WorldAfford can localize the affordance regions of\nmultiple objects and provide an alternative when objects in the environment\ncannot fully match the given instruction.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Changmao Chen",
            "Yuren Cong",
            "Zhen Kan"
        ],
        "published": "2024-05-21T02:37:45Z"
    },
    {
        "title": "Physics-based Scene Layout Generation from Human Motion",
        "link": "http://dx.doi.org/10.1145/3641519.3657517",
        "abstract": "Creating scenes for captured motions that achieve realistic human-scene\ninteraction is crucial for 3D animation in movies or video games. As character\nmotion is often captured in a blue-screened studio without real furniture or\nobjects in place, there may be a discrepancy between the planned motion and the\ncaptured one. This gives rise to the need for automatic scene layout generation\nto relieve the burdens of selecting and positioning furniture and objects.\nPrevious approaches cannot avoid artifacts like penetration and floating due to\nthe lack of physical constraints. Furthermore, some heavily rely on specific\ndata to learn the contact affordances, restricting the generalization ability\nto different motions. In this work, we present a physics-based approach that\nsimultaneously optimizes a scene layout generator and simulates a moving human\nin a physics simulator. To attain plausible and realistic interaction motions,\nour method explicitly introduces physical constraints. To automatically recover\nand generate the scene layout, we minimize the motion tracking errors to\nidentify the objects that can afford interaction. We use reinforcement learning\nto perform a dual-optimization of both the character motion imitation\ncontroller and the scene layout generator. To facilitate the optimization, we\nreshape the tracking rewards and devise pose prior guidance obtained from our\nestimated pseudo-contact labels. We evaluate our method using motions from SAMP\nand PROX, and demonstrate physically plausible scene layout reconstruction\ncompared with the previous kinematics-based method.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "authors": [
            "Jianan Li",
            "Tao Huang",
            "Qingxu Zhu",
            "Tien-Tsin Wong"
        ],
        "published": "2024-05-21T02:36:37Z"
    },
    {
        "title": "PLM4Traj: Cognizing Movement Patterns and Travel Purposes from\n  Trajectories with Pre-trained Language Models",
        "link": "http://arxiv.org/abs/2405.12459v1",
        "abstract": "Spatio-temporal trajectories play a vital role in various spatio-temporal\ndata mining tasks. Developing a versatile trajectory learning approach that can\nadapt to different tasks while ensuring high accuracy is crucial. This requires\neffectively extracting movement patterns and travel purposes embedded in\ntrajectories. However, this task is challenging due to limitations in the size\nand quality of available trajectory datasets. On the other hand, pre-trained\nlanguage models (PLMs) have shown great success in adapting to different tasks\nby training on large-scale, high-quality corpus datasets. Given the\nsimilarities between trajectories and sentences, there is potential in\nleveraging PLMs to enhance the development of a versatile and effective\ntrajectory learning method. Nevertheless, vanilla PLMs are not tailored to\nhandle the unique spatio-temporal features present in trajectories and lack the\ncapability to extract movement patterns and travel purposes from them.\n  To overcome these obstacles, we propose a model called PLM4Traj that\neffectively utilizes PLMs to model trajectories. PLM4Traj leverages the\nstrengths of PLMs to create a versatile trajectory learning approach while\naddressing the limitations of vanilla PLMs in modeling trajectories. Firstly,\nPLM4Traj incorporates a novel trajectory semantic embedder that enables PLMs to\nprocess spatio-temporal features in trajectories and extract movement patterns\nand travel purposes from them. Secondly, PLM4Traj introduces a novel trajectory\nprompt that integrates movement patterns and travel purposes into PLMs, while\nalso allowing the model to adapt to various tasks. Extensive experiments\nconducted on two real-world datasets and two representative tasks demonstrate\nthat PLM4Traj successfully achieves its design goals. Codes are available at\nhttps://github.com/Zeru19/PLM4Traj.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Zeyu Zhou",
            "Yan Lin",
            "Haomin Wen",
            "Shengnan Guo",
            "Jilin Hu",
            "Youfang Lin",
            "Huaiyu Wan"
        ],
        "published": "2024-05-21T02:33:17Z"
    },
    {
        "title": "Studying Up Public Sector AI: How Networks of Power Relations Shape\n  Agency Decisions Around AI Design and Use",
        "link": "http://arxiv.org/abs/2405.12458v1",
        "abstract": "As public sector agencies rapidly introduce new AI tools in high-stakes\ndomains like social services, it becomes critical to understand how decisions\nto adopt these tools are made in practice. We borrow from the anthropological\npractice to ``study up'' those in positions of power, and reorient our study of\npublic sector AI around those who have the power and responsibility to make\ndecisions about the role that AI tools will play in their agency. Through\nsemi-structured interviews and design activities with 16 agency\ndecision-makers, we examine how decisions about AI design and adoption are\ninfluenced by their interactions with and assumptions about other actors within\nthese agencies (e.g., frontline workers and agency leaders), as well as those\nabove (legal systems and contracted companies), and below (impacted\ncommunities). By centering these networks of power relations, our findings shed\nlight on how infrastructural, legal, and social factors create barriers and\ndisincentives to the involvement of a broader range of stakeholders in\ndecisions about AI design and adoption. Agency decision-makers desired more\npractical support for stakeholder involvement around public sector AI to help\novercome the knowledge and power differentials they perceived between them and\nother stakeholders (e.g., frontline workers and impacted community members).\nBuilding on these findings, we discuss implications for future research and\npolicy around actualizing participatory AI approaches in public sector\ncontexts.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Anna Kawakami",
            "Amanda Coston",
            "Hoda Heidari",
            "Kenneth Holstein",
            "Haiyi Zhu"
        ],
        "published": "2024-05-21T02:31:26Z"
    },
    {
        "title": "A K-means Algorithm for Financial Market Risk Forecasting",
        "link": "http://arxiv.org/abs/2405.13076v1",
        "abstract": "Financial market risk forecasting involves applying mathematical models,\nhistorical data analysis and statistical methods to estimate the impact of\nfuture market movements on investments. This process is crucial for investors\nto develop strategies, financial institutions to manage assets and regulators\nto formulate policy. In today's society, there are problems of high error rate\nand low precision in financial market risk prediction, which greatly affect the\naccuracy of financial market risk prediction. K-means algorithm in machine\nlearning is an effective risk prediction technique for financial market. This\nstudy uses K-means algorithm to develop a financial market risk prediction\nsystem, which significantly improves the accuracy and efficiency of financial\nmarket risk prediction. Ultimately, the outcomes of the experiments confirm\nthat the K-means algorithm operates with user-friendly simplicity and achieves\na 94.61% accuracy rate",
        "subjects": [
            "q-fin.ST",
            "cs.LG"
        ],
        "authors": [
            "Jinxin Xu",
            "Kaixian Xu",
            "Yue Wang",
            "Qinyan Shen",
            "Ruisi Li"
        ],
        "published": "2024-05-21T02:24:46Z"
    },
    {
        "title": "Mutual Information Analysis in Multimodal Learning Systems",
        "link": "http://arxiv.org/abs/2405.12456v1",
        "abstract": "In recent years, there has been a significant increase in applications of\nmultimodal signal processing and analysis, largely driven by the increased\navailability of multimodal datasets and the rapid progress in multimodal\nlearning systems. Well-known examples include autonomous vehicles, audiovisual\ngenerative systems, vision-language systems, and so on. Such systems integrate\nmultiple signal modalities: text, speech, images, video, LiDAR, etc., to\nperform various tasks. A key issue for understanding such systems is the\nrelationship between various modalities and how it impacts task performance. In\nthis paper, we employ the concept of mutual information (MI) to gain insight\ninto this issue. Taking advantage of the recent progress in entropy modeling\nand estimation, we develop a system called InfoMeter to estimate MI between\nmodalities in a multimodal learning system. We then apply InfoMeter to analyze\na multimodal 3D object detection system over a large-scale dataset for\nautonomous driving. Our experiments on this system suggest that a lower MI\nbetween modalities is beneficial for detection accuracy. This new insight may\nfacilitate improvements in the development of future multimodal learning\nsystems.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Hadi Hadizadeh",
            "S. Faegheh Yeganli",
            "Bahador Rashidi",
            "Ivan V. Bajić"
        ],
        "published": "2024-05-21T02:16:16Z"
    },
    {
        "title": "Prompt-Enhanced Spatio-Temporal Graph Transfer Learning",
        "link": "http://arxiv.org/abs/2405.12452v1",
        "abstract": "Spatio-temporal graph neural networks have demonstrated efficacy in capturing\ncomplex dependencies for urban computing tasks such as forecasting and kriging.\nHowever, their performance is constrained by the reliance on extensive data for\ntraining on specific tasks, which limits their adaptability to new urban\ndomains with varied demands. Although transfer learning has been proposed to\naddress this problem by leveraging knowledge across domains, cross-task\ngeneralization remains underexplored in spatio-temporal graph transfer learning\nmethods due to the absence of a unified framework. To bridge this gap, we\npropose Spatio-Temporal Graph Prompting (STGP), a prompt-enhanced transfer\nlearning framework capable of adapting to diverse tasks in data-scarce domains.\nSpecifically, we first unify different tasks into a single template and\nintroduce a task-agnostic network architecture that aligns with this template.\nThis approach enables the capture of spatio-temporal dependencies shared across\ntasks. Furthermore, we employ learnable prompts to achieve domain and task\ntransfer in a two-stage prompting pipeline, enabling the prompts to effectively\ncapture domain knowledge and task-specific properties at each stage. Extensive\nexperiments demonstrate that STGP outperforms state-of-the-art baselines in\nthree downstream tasks forecasting, kriging, and extrapolation by a notable\nmargin.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Junfeng Hu",
            "Xu Liu",
            "Zhencheng Fan",
            "Yifang Yin",
            "Shili Xiang",
            "Savitha Ramasamy",
            "Roger Zimmermann"
        ],
        "published": "2024-05-21T02:06:40Z"
    },
    {
        "title": "Score-CDM: Score-Weighted Convolutional Diffusion Model for Multivariate\n  Time Series Imputation",
        "link": "http://arxiv.org/abs/2405.13075v1",
        "abstract": "Multivariant time series (MTS) data are usually incomplete in real scenarios,\nand imputing the incomplete MTS is practically important to facilitate various\ntime series mining tasks. Recently, diffusion model-based MTS imputation\nmethods have achieved promising results by utilizing CNN or attention\nmechanisms for temporal feature learning. However, it is hard to adaptively\ntrade off the diverse effects of local and global temporal features by simply\ncombining CNN and attention. To address this issue, we propose a Score-weighted\nConvolutional Diffusion Model (Score-CDM for short), whose backbone consists of\na Score-weighted Convolution Module (SCM) and an Adaptive Reception Module\n(ARM). SCM adopts a score map to capture the global temporal features in the\ntime domain, while ARM uses a Spectral2Time Window Block (S2TWB) to convolve\nthe local time series data in the spectral domain. Benefiting from the time\nconvolution properties of Fast Fourier Transformation, ARM can adaptively\nchange the receptive field of the score map, and thus effectively balance the\nlocal and global temporal features. We conduct extensive evaluations on three\nreal MTS datasets of different domains, and the result verifies the\neffectiveness of the proposed Score-CDM.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "S. Zhang",
            "S. Wang",
            "H. Miao",
            "H. Chen",
            "C. Fan",
            "J. Zhang"
        ],
        "published": "2024-05-21T02:00:55Z"
    },
    {
        "title": "PathOCL: Path-Based Prompt Augmentation for OCL Generation with GPT-4",
        "link": "http://arxiv.org/abs/2405.12450v1",
        "abstract": "The rapid progress of AI-powered programming assistants, such as GitHub\nCopilot, has facilitated the development of software applications. These\nassistants rely on large language models (LLMs), which are foundation models\n(FMs) that support a wide range of tasks related to understanding and\ngenerating language. LLMs have demonstrated their ability to express UML model\nspecifications using formal languages like the Object Constraint Language\n(OCL). However, the context size of the prompt is limited by the number of\ntokens an LLM can process. This limitation becomes significant as the size of\nUML class models increases. In this study, we introduce PathOCL, a novel\npath-based prompt augmentation technique designed to facilitate OCL generation.\nPathOCL addresses the limitations of LLMs, specifically their token processing\nlimit and the challenges posed by large UML class models. PathOCL is based on\nthe concept of chunking, which selectively augments the prompts with a subset\nof UML classes relevant to the English specification. Our findings demonstrate\nthat PathOCL, compared to augmenting the complete UML class model\n(UML-Augmentation), generates a higher number of valid and correct OCL\nconstraints using the GPT-4 model. Moreover, the average prompt size crafted\nusing PathOCL significantly decreases when scaling the size of the UML class\nmodels.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "authors": [
            "Seif Abukhalaf",
            "Mohammad Hamdaqa",
            "Foutse Khomh"
        ],
        "published": "2024-05-21T02:00:54Z"
    },
    {
        "title": "EPL: Empirical Prototype Learning for Deep Face Recognition",
        "link": "http://arxiv.org/abs/2405.12447v1",
        "abstract": "Prototype learning is widely used in face recognition, which takes the row\nvectors of coefficient matrix in the last linear layer of the feature\nextraction model as the prototypes for each class. When the prototypes are\nupdated using the facial sample feature gradients in the model training, they\nare prone to being pulled away from the class center by the hard samples,\nresulting in decreased overall model performance. In this paper, we explicitly\ndefine prototypes as the expectations of sample features in each class and\ndesign the empirical prototypes using the existing samples in the dataset. We\nthen devise a strategy to adaptively update these empirical prototypes during\nthe model training based on the similarity between the sample features and the\nempirical prototypes. Furthermore, we propose an empirical prototype learning\n(EPL) method, which utilizes an adaptive margin parameter with respect to\nsample features. EPL assigns larger margins to the normal samples and smaller\nmargins to the hard samples, allowing the learned empirical prototypes to\nbetter reflect the class center dominated by the normal samples and finally\npull the hard samples towards the empirical prototypes through the learning.\nThe extensive experiments on MFR, IJB-C, LFW, CFP-FP, AgeDB, and MegaFace\ndemonstrate the effectiveness of EPL. Our code is available at\n$\\href{https://github.com/WakingHours-GitHub/EPL}{https://github.com/WakingHours-GitHub/EPL}$.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Weijia Fan",
            "Jiajun Wen",
            "Xi Jia",
            "Linlin Shen",
            "Jiancan Zhou",
            "Qiufu Li"
        ],
        "published": "2024-05-21T01:55:33Z"
    },
    {
        "title": "Computer assisted proofs for transverse heteroclinics by the\n  parameterization method",
        "link": "http://arxiv.org/abs/2405.12446v1",
        "abstract": "This work develops a functional analytic framework for making computer\nassisted arguments involving transverse heteroclinic connecting orbits between\nhyperbolic periodic solutions of ordinary differential equations. We exploit a\nFourier-Taylor approximation of the local stable/unstable manifold of the\nperiodic orbit, combined with a numerical method for solving two point boundary\nvalue problems via Chebyshev series approximations. The a-posteriori analysis\ndeveloped provides mathematically rigorous bounds on all approximation errors,\nproviding both abstract existence results and quantitative information about\nthe true heteroclinic solution. Example calculations are given for both the\ndissipative Lorenz system and the Hamiltonian Hill Restricted Four Body\nProblem.",
        "subjects": [
            "math.DS",
            "cs.NA",
            "math-ph",
            "math.MP",
            "math.NA"
        ],
        "authors": [
            "Maxime Murray",
            "J. D. Mireles James"
        ],
        "published": "2024-05-21T01:50:17Z"
    },
    {
        "title": "Reach and hold flexibility characterization and trade-off analysis for\n  aggregations of thermostatically controlled loads",
        "link": "http://arxiv.org/abs/2405.12444v1",
        "abstract": "Thermostatically controlled loads (TCLs) have the potential to be flexible\nand responsive loads to be used in demand response (DR) schemes. With\nincreasing renewable penetration, DR is playing an increasingly important role\nin enhancing power grid reliability. The aggregate demand of a population of\nTCLs can be modulated by changing their temperature setpoint. When and/or what\nproportion of the population sees the setpoint change determines the change in\naggregate demand. However, since the TCL population is finite, not all changes\nin aggregate demand can be maintained for arbitrarily long periods of time. In\nthis paper, the dynamic behavior of a TCL fleet is modeled and used to\ncharacterize the set possible changes in aggregate demand that can be reached\nand the corresponding time for which the demand change can be held, for a given\nchange in setpoint. This set is referred to, in this paper, as the reach and\nhold set of a TCL fleet. Furthermore, the effect of the setpoint change and\nambient temperature on the reach and hold are analyzed. The characterized set\nis then validated through simulation using both the population TCL models and\nindividual TCL micro-models.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Mazen Elsaadany",
            "Mads R. Almassalkhi"
        ],
        "published": "2024-05-21T01:41:44Z"
    },
    {
        "title": "FFCL: Forward-Forward Net with Cortical Loops, Training and Inference on\n  Edge Without Backpropagation",
        "link": "http://arxiv.org/abs/2405.12443v1",
        "abstract": "The Forward-Forward Learning (FFL) algorithm is a recently proposed solution\nfor training neural networks without needing memory-intensive backpropagation.\nDuring training, labels accompany input data, classifying them as positive or\nnegative inputs. Each layer learns its response to these inputs independently.\nIn this study, we enhance the FFL with the following contributions: 1) We\noptimize label processing by segregating label and feature forwarding between\nlayers, enhancing learning performance. 2) By revising label integration, we\nenhance the inference process, reduce computational complexity, and improve\nperformance. 3) We introduce feedback loops akin to cortical loops in the\nbrain, where information cycles through and returns to earlier neurons,\nenabling layers to combine complex features from previous layers with\nlower-level features, enhancing learning efficiency.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ali Karkehabadi",
            "Houman Homayoun",
            "Avesta Sasan"
        ],
        "published": "2024-05-21T01:39:11Z"
    },
    {
        "title": "Learning Structure and Knowledge Aware Representation with Large\n  Language Models for Concept Recommendation",
        "link": "http://arxiv.org/abs/2405.12442v1",
        "abstract": "Concept recommendation aims to suggest the next concept for learners to study\nbased on their knowledge states and the human knowledge system. While knowledge\nstates can be predicted using knowledge tracing models, previous approaches\nhave not effectively integrated the human knowledge system into the process of\ndesigning these educational models. In the era of rapidly evolving Large\nLanguage Models (LLMs), many fields have begun using LLMs to generate and\nencode text, introducing external knowledge. However, integrating LLMs into\nconcept recommendation presents two urgent challenges: 1) How to construct text\nfor concepts that effectively incorporate the human knowledge system? 2) How to\nadapt non-smooth, anisotropic text encodings effectively for concept\nrecommendation? In this paper, we propose a novel Structure and Knowledge Aware\nRepresentation learning framework for concept Recommendation (SKarREC). We\nleverage factual knowledge from LLMs as well as the precedence and succession\nrelationships between concepts obtained from the knowledge graph to construct\ntextual representations of concepts. Furthermore, we propose a graph-based\nadapter to adapt anisotropic text embeddings to the concept recommendation\ntask. This adapter is pre-trained through contrastive learning on the knowledge\ngraph to get a smooth and structure-aware concept representation. Then, it's\nfine-tuned through the recommendation task, forming a\ntext-to-knowledge-to-recommendation adaptation pipeline, which effectively\nconstructs a structure and knowledge-aware concept representation. Our method\ndoes a better job than previous adapters in transforming text encodings for\napplication in concept recommendation. Extensive experiments on real-world\ndatasets demonstrate the effectiveness of the proposed approach.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "authors": [
            "Qingyao Li",
            "Wei Xia",
            "Kounianhua Du",
            "Qiji Zhang",
            "Weinan Zhang",
            "Ruiming Tang",
            "Yong Yu"
        ],
        "published": "2024-05-21T01:35:36Z"
    },
    {
        "title": "No-Regret M${}^{\\natural}$-Concave Function Maximization: Stochastic\n  Bandit Algorithms and NP-Hardness of Adversarial Full-Information Setting",
        "link": "http://arxiv.org/abs/2405.12439v1",
        "abstract": "M${}^{\\natural}$-concave functions, a.k.a. gross substitute valuation\nfunctions, play a fundamental role in many fields, including discrete\nmathematics and economics. In practice, perfect knowledge of\nM${}^{\\natural}$-concave functions is often unavailable a priori, and we can\noptimize them only interactively based on some feedback. Motivated by such\nsituations, we study online M${}^{\\natural}$-concave function maximization\nproblems, which are interactive versions of the problem studied by Murota and\nShioura (1999). For the stochastic bandit setting, we present\n$O(T^{-1/2})$-simple regret and $O(T^{2/3})$-regret algorithms under $T$ times\naccess to unbiased noisy value oracles of M${}^{\\natural}$-concave functions. A\nkey to proving these results is the robustness of the greedy algorithm to local\nerrors in M${}^{\\natural}$-concave function maximization, which is one of our\nmain technical results. While we obtain those positive results for the\nstochastic setting, another main result of our work is an impossibility in the\nadversarial setting. We prove that, even with full-information feedback, no\nalgorithms that run in polynomial time per round can achieve $O(T^{1-c})$\nregret for any constant $c > 0$ unless $\\mathsf{P} = \\mathsf{NP}$. Our proof is\nbased on a reduction from the matroid intersection problem for three matroids,\nwhich would be a novel idea in the context of online learning.",
        "subjects": [
            "cs.LG",
            "cs.DS"
        ],
        "authors": [
            "Taihei Oki",
            "Shinsaku Sakaue"
        ],
        "published": "2024-05-21T01:31:44Z"
    },
    {
        "title": "CoCo Matrix: Taxonomy of Cognitive Contributions in Co-writing with\n  Intelligent Agents",
        "link": "http://dx.doi.org/10.1145/3635636.3664260",
        "abstract": "In recent years, there has been a growing interest in employing intelligent\nagents in writing. Previous work emphasizes the evaluation of the quality of\nend product-whether it was coherent and polished, overlooking the journey that\nled to the product, which is an invaluable dimension of the creative process.\nTo understand how to recognize human efforts in co-writing with intelligent\nwriting systems, we adapt Flower and Hayes' cognitive process theory of writing\nand propose CoCo Matrix, a two-dimensional taxonomy of entropy and information\ngain, to depict the new human-agent co-writing model. We define four quadrants\nand situate thirty-four published systems within the taxonomy. Our research\nfound that low entropy and high information gain systems are under-explored,\nyet offer promising future directions in writing tasks that benefit from the\nagent's divergent planning and the human's focused translation. CoCo Matrix,\nnot only categorizes different writing systems but also deepens our\nunderstanding of the cognitive processes in human-agent co-writing. By\nanalyzing minimal changes in the writing process, CoCo Matrix serves as a proxy\nfor the writer's mental model, allowing writers to reflect on their\ncontributions. This reflection is facilitated through the measured metrics of\ninformation gain and entropy, which provide insights irrespective of the\nwriting system used.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Ruyuan Wan",
            "Simret Gebreegziabhe",
            "Toby Jia-Jun Li",
            "Karla Badillo-Urquiola"
        ],
        "published": "2024-05-21T01:31:17Z"
    },
    {
        "title": "Computational Fabrication and Assembly for In Situ Manufacturing",
        "link": "http://arxiv.org/abs/2405.12436v1",
        "abstract": "Fabrication today relies on disparate, large machines spread across\nindustrial facilities. These are operated by domain experts to construct and\nassemble artefacts in sequential steps from large numbers of parts. This\ntraditional, centralized mass manufacturing paradigm is characterized by large\ncapital costs and inflexibility to changing needs, complex global supply chains\nhinged on economic and political stability, and waste and over-manufacturing of\nuniform artefacts that fail to meet the technical and personal needs of today's\ndiverse individuals and use cases. Today, these challenges are particularly\nsevere at points of need, such as the space environment. The space environment\nis remote and unpredictable, and the ability to manufacture in situ offers\nunique opportunities to address new challenges as they arise. However, the\nchallenges faced in space are often mirrored on Earth. In hospitals, disaster\nzones, low resource environments and laboratories, the ability to manufacture\ncustomized artefacts at points of need can significantly enhance our ability to\nrespond rapidly to unforeseen events. In this thesis, I introduce digital\nfabrication platforms with co-developed hardware and software that draw on\ntools from robotics and human-computer interaction to automate manufacturing of\ncustomized artefacts at the point of need. Highlighting three research themes\nacross fabrication machines, modular assembly, and programmable materials, the\nthesis will cover a digital fabrication platform for producing functional\nrobots, a modular robotic platform for in-space assembly deployed in\nmicrogravity, and a method for programming magnetic material to selectively\nassemble.",
        "subjects": [
            "cs.RO",
            "cs.ET"
        ],
        "authors": [
            "Martin Nisser"
        ],
        "published": "2024-05-21T01:25:12Z"
    },
    {
        "title": "Resolving Word Vagueness with Scenario-guided Adapter for Natural\n  Language Inference",
        "link": "http://arxiv.org/abs/2405.12434v1",
        "abstract": "Natural Language Inference (NLI) is a crucial task in natural language\nprocessing that involves determining the relationship between two sentences,\ntypically referred to as the premise and the hypothesis. However, traditional\nNLI models solely rely on the semantic information inherent in independent\nsentences and lack relevant situational visual information, which can hinder a\ncomplete understanding of the intended meaning of the sentences due to the\nambiguity and vagueness of language. To address this challenge, we propose an\ninnovative ScenaFuse adapter that simultaneously integrates large-scale\npre-trained linguistic knowledge and relevant visual information for NLI tasks.\nSpecifically, we first design an image-sentence interaction module to\nincorporate visuals into the attention mechanism of the pre-trained model,\nallowing the two modalities to interact comprehensively. Furthermore, we\nintroduce an image-sentence fusion module that can adaptively integrate visual\ninformation from images and semantic information from sentences. By\nincorporating relevant visual information and leveraging linguistic knowledge,\nour approach bridges the gap between language and vision, leading to improved\nunderstanding and inference capabilities in NLI tasks. Extensive benchmark\nexperiments demonstrate that our proposed ScenaFuse, a scenario-guided\napproach, consistently boosts NLI performance.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yonghao Liu",
            "Mengyu Li",
            "Di Liang",
            "Ximing Li",
            "Fausto Giunchiglia",
            "Lan Huang",
            "Xiaoyue Feng",
            "Renchu Guan"
        ],
        "published": "2024-05-21T01:19:52Z"
    },
    {
        "title": "LLM+Reasoning+Planning for supporting incomplete user queries in\n  presence of APIs",
        "link": "http://arxiv.org/abs/2405.12433v1",
        "abstract": "Recent availability of Large Language Models (LLMs) has led to the\ndevelopment of numerous LLM-based approaches aimed at providing natural\nlanguage interfaces for various end-user tasks. These end-user tasks in turn\ncan typically be accomplished by orchestrating a given set of APIs. In\npractice, natural language task requests (user queries) are often incomplete,\ni.e., they may not contain all the information required by the APIs. While LLMs\nexcel at natural language processing (NLP) tasks, they frequently hallucinate\non missing information or struggle with orchestrating the APIs. The key idea\nbehind our proposed approach is to leverage logical reasoning and classical AI\nplanning along with an LLM for accurately answering user queries including\nidentification and gathering of any missing information in these queries. Our\napproach uses an LLM and ASP (Answer Set Programming) solver to translate a\nuser query to a representation in Planning Domain Definition Language (PDDL)\nvia an intermediate representation in ASP. We introduce a special API\n\"get_info_api\" for gathering missing information. We model all the APIs as PDDL\nactions in a way that supports dataflow between the APIs. Our approach then\nuses a classical AI planner to generate an orchestration of API calls\n(including calls to get_info_api) to answer the user query. Our evaluation\nresults show that our approach significantly outperforms a pure LLM based\napproach by achieving over 95\\% success rate in most cases on a dataset\ncontaining complete and incomplete single goal and multi-goal queries where the\nmulti-goal queries may or may not require dataflow among the APIs.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Sudhir Agarwal",
            "Anu Sreepathy",
            "David H. Alonso",
            "Prarit Lamba"
        ],
        "published": "2024-05-21T01:16:34Z"
    },
    {
        "title": "Power Measurement Based Channel Estimation for IRS-Enhanced Wireless\n  Coverage",
        "link": "http://arxiv.org/abs/2405.12432v1",
        "abstract": "In this paper, we study an IRS-assisted coverage enhancement problem for a\ngiven region, aiming to optimize the passive reflection of the IRS for\nimproving the average communication performance in the region by accounting for\nboth deterministic and random channels in the environment. To this end, we\nfirst derive the closed-form expression of the average received signal power in\nterms of the deterministic base station (BS)-IRS-user cascaded channels over\nall user locations, and propose an IRS-aided coverage enhancement framework to\nfacilitate the estimation of such deterministic channels for IRS passive\nreflection design. Specifically, to avoid the exorbitant overhead of estimating\nthe cascaded channels at all possible user locations, a location selection\nmethod is first proposed to select only a set of typical user locations for\nchannel estimation by exploiting the channel spatial correlation in the region.\nTo estimate the deterministic cascaded channels at the selected user locations,\nconventional IRS channel estimation methods require additional pilot signals,\nwhich not only results in high system training overhead but also may not be\ncompatible with the existing communication protocols. To overcome this issue,\nwe further propose a single-layer neural network (NN)-enabled IRS channel\nestimation method in this paper, based on only the average received signal\npower measurements at each selected location corresponding to different IRS\nrandom training reflections, which can be offline implemented in current\nwireless systems. Numerical results demonstrate that our proposed scheme can\nsignificantly improve the coverage performance of the target region and\noutperform the existing power-measurement-based IRS reflection designs.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "He Sun",
            "Lipeng Zhu",
            "Weidong Mei",
            "Rui Zhang"
        ],
        "published": "2024-05-21T01:15:12Z"
    },
    {
        "title": "Data Sharing at the Edge of the Network: A Disturbance Resilient\n  Multi-modal ITS",
        "link": "http://arxiv.org/abs/2405.12431v1",
        "abstract": "Mobility-as-a-Service (MaaS) is a paradigm that encourages the shift from\nprivate cars to more sustainable alternative mobility services. MaaS provides\nservices that enhances and enables multiple modes of transport to operate\nseamlessly and bringing Multimodal Intelligent Transport Systems (M-ITS) closer\nto reality. This requires sharing and integration of data collected from\nmultiple sources including modes of transports, sensors, and end-users' devices\nto allow a seamless and integrated services especially during unprecedented\ndisturbances. This paper discusses the interactions among transportation modes,\nnetworks, potential disturbance scenarios, and adaptation strategies to\nmitigate their impact on MaaS. We particularly discuss the need to share data\nbetween the modes of transport and relevant entities that are at the vicinity\nof each other, taking advantage of edge computing technology to avoid any\nlatency due to communication to the cloud and privacy concerns. However, when\nsharing at the edge, bandwidth, storage, and computational limitations must be\nconsidered.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Igor Mikolasek",
            "Saeedeh Ghanadbashi",
            "Nima Afraz",
            "Fatemeh Golpayegani"
        ],
        "published": "2024-05-21T01:14:33Z"
    },
    {
        "title": "Deep learning approaches to indoor wireless channel estimation for\n  low-power communication",
        "link": "http://arxiv.org/abs/2405.12427v1",
        "abstract": "In the rapidly growing development of the Internet of Things (IoT)\ninfrastructure, achieving reliable wireless communication is a challenge. IoT\ndevices operate in diverse environments with common signal interference and\nfluctuating channel conditions. Accurate channel estimation helps adapt the\ntransmission strategies to current conditions, ensuring reliable communication.\nTraditional methods, such as Least Squares (LS) and Minimum Mean Squared Error\n(MMSE) estimation techniques, often struggle to adapt to the diverse and\ncomplex environments typical of IoT networks. This research article delves into\nthe potential of Deep Learning (DL) to enhance channel estimation, focusing on\nthe Received Signal Strength Indicator (RSSI) metric - a critical yet\nchallenging aspect due to its susceptibility to noise and environmental\nfactors. This paper presents two Fully Connected Neural Networks (FCNNs)-based\nLow Power (LP-IoT) channel estimation models, leveraging RSSI for accurate\nchannel estimation in LP-IoT communication. Our Model A exhibits a remarkable\n99.02% reduction in Mean Squared Error (MSE), and Model B demonstrates a\nnotable 90.03% MSE reduction compared to the benchmarks set by current studies.\nAdditionally, the comparative studies of our model A with other DL-based\ntechniques show significant efficiency in our estimation models.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Samrah Arif",
            "Muhammad Arif Khan",
            "Sabih Ur Rehman"
        ],
        "published": "2024-05-21T00:36:34Z"
    },
    {
        "title": "Inferring Message Flows From System Communication Traces",
        "link": "http://arxiv.org/abs/2405.12426v1",
        "abstract": "This paper proposes a novel method for automatically inferring message flow\nspecifications from the communication traces of a system-on-chip (SoC) design\nthat captures messages exchanged among the components during a system\nexecution. The inferred message flows characterize the communication and\ncoordination of components in a system design for realizing various system\nfunctions, and they are essential for SoC validation and debugging. The\nproposed method relieves the burden of manual development and maintenance of\nsuch specifications on human designers. Our method also uses a new accuracy\nmetric, \\emph{acceptance ratio}, to evaluate the quality of the mined\nspecifications instead of the specification size often used in the previous\nwork, enabling more accurate specifications to be mined. Furthermore, this\npaper introduces the concept of essential causalities to enhance the accuracy\nof the message flow mining and accelerate the mining process. The effectiveness\nof the proposed method is evaluated on both synthetic traces and traces\ngenerated from executing several system models in GEM5. In both cases, the\nproposed method achieves superior accuracies compared to a previous approach.\nAdditionally, this paper includes some practical use cases.",
        "subjects": [
            "cs.LO",
            "cs.SE"
        ],
        "authors": [
            "Bardia Nadimi",
            "Hao Zheng"
        ],
        "published": "2024-05-21T00:34:35Z"
    },
    {
        "title": "Rethinking Robustness Assessment: Adversarial Attacks on Learning-based\n  Quadrupedal Locomotion Controllers",
        "link": "http://arxiv.org/abs/2405.12424v1",
        "abstract": "Legged locomotion has recently achieved remarkable success with the progress\nof machine learning techniques, especially deep reinforcement learning (RL).\nControllers employing neural networks have demonstrated empirical and\nqualitative robustness against real-world uncertainties, including sensor noise\nand external perturbations. However, formally investigating the vulnerabilities\nof these locomotion controllers remains a challenge. This difficulty arises\nfrom the requirement to pinpoint vulnerabilities across a long-tailed\ndistribution within a high-dimensional, temporally sequential space. As a first\nstep towards quantitative verification, we propose a computational method that\nleverages sequential adversarial attacks to identify weaknesses in learned\nlocomotion controllers. Our research demonstrates that, even state-of-the-art\nrobust controllers can fail significantly under well-designed, low-magnitude\nadversarial sequence. Through experiments in simulation and on the real robot,\nwe validate our approach's effectiveness, and we illustrate how the results it\ngenerates can be used to robustify the original policy and offer valuable\ninsights into the safety of these black-box policies.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "authors": [
            "Fan Shi",
            "Chong Zhang",
            "Takahiro Miki",
            "Joonho Lee",
            "Marco Hutter",
            "Stelian Coros"
        ],
        "published": "2024-05-21T00:26:11Z"
    }
]