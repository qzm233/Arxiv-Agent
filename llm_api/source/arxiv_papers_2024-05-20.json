[
    {
        "title": "GarmentDreamer: 3DGS Guided Garment Synthesis with Diverse Geometry and\n  Texture Details",
        "link": "http://arxiv.org/abs/2405.12420v1",
        "abstract": "Traditional 3D garment creation is labor-intensive, involving sketching,\nmodeling, UV mapping, and texturing, which are time-consuming and costly.\nRecent advances in diffusion-based generative models have enabled new\npossibilities for 3D garment generation from text prompts, images, and videos.\nHowever, existing methods either suffer from inconsistencies among multi-view\nimages or require additional processes to separate cloth from the underlying\nhuman model. In this paper, we propose GarmentDreamer, a novel method that\nleverages 3D Gaussian Splatting (GS) as guidance to generate wearable,\nsimulation-ready 3D garment meshes from text prompts. In contrast to using\nmulti-view images directly predicted by generative models as guidance, our 3DGS\nguidance ensures consistent optimization in both garment deformation and\ntexture synthesis. Our method introduces a novel garment augmentation module,\nguided by normal and RGBA information, and employs implicit Neural Texture\nFields (NeTF) combined with Score Distillation Sampling (SDS) to generate\ndiverse geometric and texture details. We validate the effectiveness of our\napproach through comprehensive qualitative and quantitative experiments,\nshowcasing the superior performance of GarmentDreamer over state-of-the-art\nalternatives. Our project page is available at:\nhttps://xuan-li.github.io/GarmentDreamerDemo/.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Boqian Li",
            "Xuan Li",
            "Ying Jiang",
            "Tianyi Xie",
            "Feng Gao",
            "Huamin Wang",
            "Yin Yang",
            "Chenfanfu Jiang"
        ],
        "published": "2024-05-20T23:54:28Z"
    },
    {
        "title": "GeoMask3D: Geometrically Informed Mask Selection for Self-Supervised\n  Point Cloud Learning in 3D",
        "link": "http://arxiv.org/abs/2405.12419v1",
        "abstract": "We introduce a pioneering approach to self-supervised learning for point\nclouds, employing a geometrically informed mask selection strategy called\nGeoMask3D (GM3D) to boost the efficiency of Masked Auto Encoders (MAE). Unlike\nthe conventional method of random masking, our technique utilizes a\nteacher-student model to focus on intricate areas within the data, guiding the\nmodel's focus toward regions with higher geometric complexity. This strategy is\ngrounded in the hypothesis that concentrating on harder patches yields a more\nrobust feature representation, as evidenced by the improved performance on\ndownstream tasks. Our method also presents a complete-to-partial feature-level\nknowledge distillation technique designed to guide the prediction of geometric\ncomplexity utilizing a comprehensive context from feature-level information.\nExtensive experiments confirm our method's superiority over State-Of-The-Art\n(SOTA) baselines, demonstrating marked improvements in classification, and\nfew-shot tasks.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Ali Bahri",
            "Moslem Yazdanpanah",
            "Mehrdad Noori",
            "Milad Cheraghalikhani",
            "Gustavo Adolfo Vargas Hakim",
            "David Osowiechi",
            "Farzad Beizaee",
            "Ismail Ben Ayed",
            "Christian Desrosiers"
        ],
        "published": "2024-05-20T23:53:42Z"
    },
    {
        "title": "Distribution Steering for Discrete-Time Uncertain Ensemble Systems",
        "link": "http://arxiv.org/abs/2405.12415v1",
        "abstract": "Ensemble systems appear frequently in many engineering applications and, as a\nresult, they have become an important research topic in control theory. These\nsystems are best characterized by the evolution of their underlying state\ndistribution. Despite the work to date, few results exist dealing with the\nproblem of directly modifying (i.e., \"steering\") the distribution of an\nensemble system. In addition, in most of the existing results, the distribution\nof the states of an ensemble of discrete-time systems is assumed to be\nGaussian. However, in case the system parameters are uncertain, it is not\nalways realistic to assume that the distribution of the system follows a\nGaussian distribution, thus complicating the solution of the overall problem.\nIn this paper, we address the general distribution steering problem for\nfirst-order discrete-time ensemble systems, where the distributions of the\nsystem parameters and the states are arbitrary with finite first few moments.\nBoth linear and nonlinear system dynamics are considered using the method of\npower moments to transform the original infinite-dimensional problem into a\nfinite-dimensional one. We also propose a control law for the ensuing moment\nsystem, which allows us to obtain the power moments of the desired control\ninputs. Finally, we solve the inverse problem to obtain the feasible control\ninputs from their corresponding power moments. We provide numerical results to\nvalidate our theoretical developments. These include cases where the parameter\ndistribution is uniform, Gaussian, non-Gaussian, and multi-modal, respectively.",
        "subjects": [
            "math.OC",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Guangyu Wu",
            "Panagiotis Tsiotras",
            "Anders Lindquist"
        ],
        "published": "2024-05-20T23:42:17Z"
    },
    {
        "title": "The Power of Two in Token Systems",
        "link": "http://arxiv.org/abs/2405.12414v1",
        "abstract": "In economies without monetary transfers, token systems serve as an\nalternative to sustain cooperation, alleviate free riding, and increase\nefficiency. This paper studies whether a token-based economy can be effective\nin marketplaces with thin exogenous supply. We consider a marketplace in which\nat each time period one agent requests a service, one agent provides the\nservice, and one token (artificial currency) is used to pay for service\nprovision. The number of tokens each agent has represents the difference\nbetween the amount of service provisions and service requests by the agent. We\nare interested in the behavior of this economy when very few agents are\navailable to provide the requested service. Since balancing the number of\ntokens across agents is key to sustain cooperation, the agent with the minimum\namount of tokens is selected to provide service among the available agents.\nWhen exactly one random agent is available to provide service, we show that the\ntoken distribution is unstable. However, already when just two random agents\nare available to provide service, the token distribution is stable, in the\nsense that agents' token balance is unlikely to deviate much from their initial\nendowment, and agents return to their initial endowment in finite expected\ntime. Our results mirror the power of two choices paradigm in load balancing\nproblems. Supported by numerical simulations using kidney exchange data, our\nfindings suggest that token systems may generate efficient outcomes in kidney\nexchange marketplaces by sustaining cooperation between hospitals.",
        "subjects": [
            "cs.GT"
        ],
        "authors": [
            "Itai Ashlagi",
            "Süleyman Kerimov",
            "Omer Tamuz"
        ],
        "published": "2024-05-20T23:39:30Z"
    },
    {
        "title": "Targeted Multilingual Adaptation for Low-resource Language Families",
        "link": "http://arxiv.org/abs/2405.12413v1",
        "abstract": "The \"massively-multilingual\" training of multilingual models is known to\nlimit their utility in any one language, and they perform particularly poorly\non low-resource languages. However, there is evidence that low-resource\nlanguages can benefit from targeted multilinguality, where the model is trained\non closely related languages. To test this approach more rigorously, we\nsystematically study best practices for adapting a pre-trained model to a\nlanguage family. Focusing on the Uralic family as a test case, we adapt XLM-R\nunder various configurations to model 15 languages; we then evaluate the\nperformance of each experimental setting on two downstream tasks and 11\nevaluation languages. Our adapted models significantly outperform mono- and\nmultilingual baselines. Furthermore, a regression analysis of hyperparameter\neffects reveals that adapted vocabulary size is relatively unimportant for\nlow-resource languages, and that low-resource languages can be aggressively\nup-sampled during training at little detriment to performance in high-resource\nlanguages. These results introduce new best practices for performing language\nadaptation in a targeted setting.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "C. M. Downey",
            "Terra Blevins",
            "Dhwani Serai",
            "Dwija Parikh",
            "Shane Steinert-Threlkeld"
        ],
        "published": "2024-05-20T23:38:06Z"
    },
    {
        "title": "On Measuring Calibration of Discrete Probabilistic Neural Networks",
        "link": "http://arxiv.org/abs/2405.12412v1",
        "abstract": "As machine learning systems become increasingly integrated into real-world\napplications, accurately representing uncertainty is crucial for enhancing\ntheir safety, robustness, and reliability. Training neural networks to fit\nhigh-dimensional probability distributions via maximum likelihood has become an\neffective method for uncertainty quantification. However, such models often\nexhibit poor calibration, leading to overconfident predictions. Traditional\nmetrics like Expected Calibration Error (ECE) and Negative Log Likelihood (NLL)\nhave limitations, including biases and parametric assumptions. This paper\nproposes a new approach using conditional kernel mean embeddings to measure\ncalibration discrepancies without these biases and assumptions. Preliminary\nexperiments on synthetic data demonstrate the method's potential, with future\nwork planned for more complex applications.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Spencer Young",
            "Porter Jenkins"
        ],
        "published": "2024-05-20T23:30:07Z"
    },
    {
        "title": "Local search for valued constraint satisfaction parameterized by\n  treedepth",
        "link": "http://arxiv.org/abs/2405.12410v1",
        "abstract": "Sometimes local search algorithms cannot efficiently find even local peaks.\nTo understand why, I look at the structure of ascents in fitness landscapes\nfrom valued constraint satisfaction problems (VCSPs). Given a VCSP with a\nconstraint graph of treedepth $d$, I prove that from any initial assignment\nthere always exists an ascent of length $2^{d + 1} \\cdot n$ to a local peak.\nThis means that short ascents always exist in fitness landscapes from\nconstraint graphs of logarithmic treedepth, and thus also for all VCSPs of\nbounded treewidth. But this does not mean that local search algorithms will\nalways find and follow such short ascents in sparse VCSPs. I show that with\nloglog treedepth, superpolynomial ascents exist; and for polylog treedepth,\nthere are initial assignments from which all ascents are superpolynomial.\nTogether, these results suggest that the study of sparse VCSPs can help us\nbetter understand the barriers to efficient local search.",
        "subjects": [
            "cs.DM",
            "cs.DS",
            "cs.NE",
            "q-bio.PE"
        ],
        "authors": [
            "Artem Kaznatcheev"
        ],
        "published": "2024-05-20T23:28:38Z"
    },
    {
        "title": "Flexible Active Safety Motion Control for Robotic Obstacle Avoidance: A\n  CBF-Guided MPC Approach",
        "link": "http://arxiv.org/abs/2405.12408v1",
        "abstract": "A flexible active safety motion (FASM) control approach is proposed for the\navoidance of dynamic obstacles and the reference tracking in robot\nmanipulators. The distinctive feature of the proposed method lies in its\nutilization of control barrier functions (CBF) to design flexible CBF-guided\nsafety criteria (CBFSC) with dynamically optimized decay rates, thereby\noffering flexibility and active safety for robot manipulators in dynamic\nenvironments. First, discrete-time CBFs are employed to formulate the novel\nflexible CBFSC with dynamic decay rates for robot manipulators. Following that,\nthe model predictive control (MPC) philosophy is applied, integrating flexible\nCBFSC as safety constraints into the receding-horizon optimization problem.\nSignificantly, the decay rates of the designed CBFSC are incorporated as\ndecision variables in the optimization problem, facilitating the dynamic\nenhancement of flexibility during the obstacle avoidance process. In\nparticular, a novel cost function that integrates a penalty term is designed to\ndynamically adjust the safety margins of the CBFSC. Finally, experiments are\nconducted in various scenarios using a Universal Robots 5 (UR5) manipulator to\nvalidate the effectiveness of the proposed approach.",
        "subjects": [
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Jinhao Liu",
            "Jun Yang",
            "Jianliang Mao",
            "Tianqi Zhu",
            "Qihang Xie",
            "Yimeng Li",
            "Xiangyu Wang",
            "Shihua Li"
        ],
        "published": "2024-05-20T23:12:55Z"
    },
    {
        "title": "A graph-structured distance for heterogeneous datasets with meta\n  variables",
        "link": "http://arxiv.org/abs/2405.13073v1",
        "abstract": "Heterogeneous datasets emerge in various machine learning or optimization\napplications that feature different data sources, various data types and\ncomplex relationships between variables. In practice, heterogeneous datasets\nare often partitioned into smaller well-behaved ones that are easier to\nprocess. However, some applications involve expensive-to-generate or limited\nsize datasets, which motivates methods based on the whole dataset. The first\nmain contribution of this work is a modeling graph-structured framework that\ngeneralizes state-of-the-art hierarchical, tree-structured, or variable-size\nframeworks. This framework models domains that involve heterogeneous datasets\nin which variables may be continuous, integer, or categorical, with some\nidentified as meta if their values determine the inclusion/exclusion or affect\nthe bounds of other so-called decreed variables. Excluded variables are\nintroduced to manage variables that are either included or excluded depending\non the given points. The second main contribution is the graph-structured\ndistance that compares extended points with any combination of included and\nexcluded variables: any pair of points can be compared, allowing to work\ndirectly in heterogeneous datasets with meta variables. The contributions are\nillustrated with some regression experiments, in which the performance of a\nmultilayer perceptron with respect to its hyperparameters is modeled with\ninverse distance weighting and $K$-nearest neighbors models.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "62-xx, 90-xx"
        ],
        "authors": [
            "Edward Hallé-Hannan",
            "Charles Audet",
            "Youssef Diouane",
            "Sébastien Le Digabel",
            "Paul Saves"
        ],
        "published": "2024-05-20T23:11:03Z"
    },
    {
        "title": "Diffusion for World Modeling: Visual Details Matter in Atari",
        "link": "http://arxiv.org/abs/2405.12399v1",
        "abstract": "World models constitute a promising approach for training reinforcement\nlearning agents in a safe and sample-efficient manner. Recent world models\npredominantly operate on sequences of discrete latent variables to model\nenvironment dynamics. However, this compression into a compact discrete\nrepresentation may ignore visual details that are important for reinforcement\nlearning. Concurrently, diffusion models have become a dominant approach for\nimage generation, challenging well-established methods modeling discrete\nlatents. Motivated by this paradigm shift, we introduce DIAMOND (DIffusion As a\nModel Of eNvironment Dreams), a reinforcement learning agent trained in a\ndiffusion world model. We analyze the key design choices that are required to\nmake diffusion suitable for world modeling, and demonstrate how improved visual\ndetails can lead to improved agent performance. DIAMOND achieves a mean human\nnormalized score of 1.46 on the competitive Atari 100k benchmark; a new best\nfor agents trained entirely within a world model. To foster future research on\ndiffusion for world modeling, we release our code, agents and playable world\nmodels at https://github.com/eloialonso/diamond.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Eloi Alonso",
            "Adam Jelley",
            "Vincent Micheli",
            "Anssi Kanervisto",
            "Amos Storkey",
            "Tim Pearce",
            "François Fleuret"
        ],
        "published": "2024-05-20T22:51:05Z"
    },
    {
        "title": "ASMR: Activation-sharing Multi-resolution Coordinate Networks For\n  Efficient Inference",
        "link": "http://arxiv.org/abs/2405.12398v1",
        "abstract": "Coordinate network or implicit neural representation (INR) is a fast-emerging\nmethod for encoding natural signals (such as images and videos) with the\nbenefits of a compact neural representation. While numerous methods have been\nproposed to increase the encoding capabilities of an INR, an often overlooked\naspect is the inference efficiency, usually measured in multiply-accumulate\n(MAC) count. This is particularly critical in use cases where inference\nthroughput is greatly limited by hardware constraints. To this end, we propose\nthe Activation-Sharing Multi-Resolution (ASMR) coordinate network that combines\nmulti-resolution coordinate decomposition with hierarchical modulations.\nSpecifically, an ASMR model enables the sharing of activations across grids of\nthe data. This largely decouples its inference cost from its depth which is\ndirectly correlated to its reconstruction capability, and renders a near O(1)\ninference complexity irrespective of the number of layers. Experiments show\nthat ASMR can reduce the MAC of a vanilla SIREN model by up to 500x while\nachieving an even higher reconstruction quality than its SIREN baseline.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Jason Chun Lok Li",
            "Steven Tin Sui Luo",
            "Le Xu",
            "Ngai Wong"
        ],
        "published": "2024-05-20T22:35:34Z"
    },
    {
        "title": "Automated Anomaly Detection on European XFEL Klystrons",
        "link": "http://arxiv.org/abs/2405.12391v1",
        "abstract": "High-power multi-beam klystrons represent a key component to amplify RF to\ngenerate the accelerating field of the superconducting radio frequency (SRF)\ncavities at European XFEL. Exchanging these high-power components takes time\nand effort, thus it is necessary to minimize maintenance and downtime and at\nthe same time maximize the device's operation. In an attempt to explore the\nbehavior of klystrons using machine learning, we completed a series of\nexperiments on our klystrons to determine various operational modes and conduct\nfeature extraction and dimensionality reduction to extract the most valuable\ninformation about a normal operation. To analyze recorded data we used\nstate-of-the-art data-driven learning techniques and recognized the most\npromising components that might help us better understand klystron operational\nstates and identify early on possible faults or anomalies.",
        "subjects": [
            "physics.acc-ph",
            "cs.AI"
        ],
        "authors": [
            "Antonin Sulc",
            "Annika Eichler",
            "Tim Wilksen"
        ],
        "published": "2024-05-20T21:59:07Z"
    },
    {
        "title": "A Metric-based Principal Curve Approach for Learning One-dimensional\n  Manifold",
        "link": "http://arxiv.org/abs/2405.12390v1",
        "abstract": "Principal curve is a well-known statistical method oriented in manifold\nlearning using concepts from differential geometry. In this paper, we propose a\nnovel metric-based principal curve (MPC) method that learns one-dimensional\nmanifold of spatial data. Synthetic datasets Real applications using MNIST\ndataset show that our method can learn the one-dimensional manifold well in\nterms of the shape.",
        "subjects": [
            "stat.ML",
            "cs.AI",
            "cs.LG",
            "stat.AP"
        ],
        "authors": [
            "Elvis Han Cui",
            "Sisi Shao"
        ],
        "published": "2024-05-20T21:50:19Z"
    },
    {
        "title": "Conformal Counterfactual Inference under Hidden Confounding",
        "link": "http://arxiv.org/abs/2405.12387v1",
        "abstract": "Personalized decision making requires the knowledge of potential outcomes\nunder different treatments, and confidence intervals about the potential\noutcomes further enrich this decision-making process and improve its\nreliability in high-stakes scenarios. Predicting potential outcomes along with\nits uncertainty in a counterfactual world poses the foundamental challenge in\ncausal inference. Existing methods that construct confidence intervals for\ncounterfactuals either rely on the assumption of strong ignorability, or need\naccess to un-identifiable lower and upper bounds that characterize the\ndifference between observational and interventional distributions. To overcome\nthese limitations, we first propose a novel approach wTCP-DR based on\ntransductive weighted conformal prediction, which provides confidence intervals\nfor counterfactual outcomes with marginal converage guarantees, even under\nhidden confounding. With less restrictive assumptions, our approach requires\naccess to a fraction of interventional data (from randomized controlled trials)\nto account for the covariate shift from observational distributoin to\ninterventional distribution. Theoretical results explicitly demonstrate the\nconditions under which our algorithm is strictly advantageous to the naive\nmethod that only uses interventional data. After ensuring valid intervals on\ncounterfactuals, it is straightforward to construct intervals for individual\ntreatment effects (ITEs). We demonstrate our method across synthetic and\nreal-world data, including recommendation systems, to verify the superiority of\nour methods compared against state-of-the-art baselines in terms of both\ncoverage and efficiency",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Zonghao Chen",
            "Ruocheng Guo",
            "Jean-François Ton",
            "Yang Liu"
        ],
        "published": "2024-05-20T21:43:43Z"
    },
    {
        "title": "Particle swarm optimization with Applications to Maximum Likelihood\n  Estimation and Penalized Negative Binomial Regression",
        "link": "http://arxiv.org/abs/2405.12386v1",
        "abstract": "General purpose optimization routines such as nlminb, optim (R) or nlmixed\n(SAS) are frequently used to estimate model parameters in nonstandard\ndistributions. This paper presents Particle Swarm Optimization (PSO), as an\nalternative to many of the current algorithms used in statistics. We find that\nPSO can not only reproduce the same results as the above routines, it can also\nproduce results that are more optimal or when others cannot converge. In the\nlatter case, it can also identify the source of the problem or problems. We\nhighlight advantages of using PSO using four examples, where: (1) some\nparameters in a generalized distribution are unidentified using PSO when it is\nnot apparent or computationally manifested using routines in R or SAS; (2) PSO\ncan produce estimation results for the log-binomial regressions when current\nroutines may not; (3) PSO provides flexibility in the link function for\nbinomial regression with LASSO penalty, which is unsupported by standard\npackages like GLM and GENMOD in Stata and SAS, respectively, and (4) PSO\nprovides superior MLE estimates for an EE-IW distribution compared with those\nfrom the traditional statistical methods that rely on moments.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.AP",
            "stat.CO"
        ],
        "authors": [
            "Sisi Shao",
            "Junhyung Park",
            "Weng Kee Wong"
        ],
        "published": "2024-05-20T21:42:42Z"
    },
    {
        "title": "SciJava Ops: An Improved Algorithms Framework for Fiji and Beyond",
        "link": "http://arxiv.org/abs/2405.12385v1",
        "abstract": "Many scientific software platforms provide plugin mechanisms that simplify\nthe integration, deployment, and execution of externally developed\nfunctionality. One of the most widely used platforms in the imaging space is\nFiji, a popular open-source application for scientific image analysis. Fiji\nincorporates and builds on the ImageJ and ImageJ2 platforms, which provide a\npowerful plugin architecture used by thousands of plugins to solve a wide\nvariety of problems. This capability is a major part of Fiji's success, and it\nhas become a widely used biological image analysis tool and a target for new\nfunctionality. However, a plugin-based software architecture cannot unify\ndisparate platforms operating on incompatible data structures; interoperability\nnecessitates the creation of adaptation or \"bridge\" layers to translate data\nand invoke functionality. As a result, while platforms like Fiji enable a high\ndegree of interconnectivity and extensibility, they were not fundamentally\ndesigned to integrate across the many data types, programming languages, and\narchitectural differences of various software platforms.To help address this\nchallenge, we present SciJava Ops, a foundational software library for\nexpressing algorithms as plugins in a unified and extensible way. Continuing\nthe evolution of Fiji's SciJava plugin mechanism, SciJava Ops enables users to\nharness algorithms from various software platforms within a central execution\nenvironment. In addition, SciJava Ops automatically adapts data into the most\nappropriate structure for each algorithm, allowing users to freely and\ntransparently combine algorithms from otherwise incompatible tools. While\nSciJava Ops is initially distributed as a Fiji update site, the framework does\nnot require Fiji, ImageJ, or ImageJ2, and would be suitable for integration\nwith additional image analysis platforms.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Gabriel J. Selzer",
            "Curtis T. Rueden",
            "Mark C. Hiner",
            "Edward L. Evans III",
            "David Kolb",
            "Marcel Wiedenmann",
            "Christian Birkhold",
            "Tim-Oliver Buchholz",
            "Stefan Helfrich",
            "Brian Northan",
            "Alison Walter",
            "Johannes Schindelin",
            "Tobias Pietzsch",
            "Stephan Saalfeld",
            "Michael R. Berthold",
            "Kevin W. Eliceiri"
        ],
        "published": "2024-05-20T21:40:08Z"
    },
    {
        "title": "Vulnerability Detection with Deep Learning",
        "link": "http://arxiv.org/abs/2405.12384v1",
        "abstract": "Deep learning has been shown to be a promising tool in detecting software\nvulnerabilities. In this work, we train neural networks with program slices\nextracted from the source code of C/C++ programs to detect software\nvulnerabilities. The program slices capture the syntax and semantic\ncharacteristics of vulnerability-related program constructs, including API\nfunction call, array usage, pointer usage, and arithmetic expression. To\nachieve a strong prediction model for both vulnerable code and non-vulnerable\ncode, we compare different types of training data, different optimizers, and\ndifferent types of neural networks. Our result shows that combining different\ntypes of characteristics of source code and using a balanced number of\nvulnerable program slices and non-vulnerable program slices produce a balanced\naccuracy in predicting both vulnerable code and non-vulnerable code. Among\ndifferent neural networks, BGRU with the ADAM optimizer performs the best in\ndetecting software vulnerabilities with an accuracy of 92.49%.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "authors": [
            "Zhen Huang",
            "Amy Aumpansub"
        ],
        "published": "2024-05-20T21:39:19Z"
    },
    {
        "title": "Half-closed Discontinuous Galerkin discretisations",
        "link": "http://arxiv.org/abs/2405.12383v1",
        "abstract": "We introduce the concept of half-closed nodes for nodal Discontinuous\nGalerkin (DG) discretisations. This is in contrast to more commonly used closed\nnodes in DG where in each element nodes are placed on every boundary.\nHalf-closed nodes relax this constraint by only requiring nodes on a subset of\nthe boundaries in each element, with this extra freedom in node placement\nallowing for increased efficiency in the assembly of DG operators. To determine\nwhich element boundaries half-closed nodes are placed on we outline a simple\nprocedure based on switch functions. We examine the effect on operator sparsity\nfrom using the different types of nodes and show that in particular for the\nLaplace operator there is no difference in the sparsity from using half-closed\nor closed nodes. We also discuss in this work some linear solver techniques\ncommonly used for Finite Element or Discontinuous Galerkin methods such as\nstatic condensation and block-based methods, and how they can be applied to\nhalf-closed DG discretisations.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Yulong Pan",
            "Per-Olof Persson"
        ],
        "published": "2024-05-20T21:29:25Z"
    },
    {
        "title": "Stochastic Reservoir Computers",
        "link": "http://arxiv.org/abs/2405.12382v1",
        "abstract": "Reservoir computing is a form of machine learning that utilizes nonlinear\ndynamical systems to perform complex tasks in a cost-effective manner when\ncompared to typical neural networks. Many recent advancements in reservoir\ncomputing, in particular quantum reservoir computing, make use of reservoirs\nthat are inherently stochastic. However, the theoretical justification for\nusing these systems has not yet been well established. In this paper, we\ninvestigate the universality of stochastic reservoir computers, in which we use\na stochastic system for reservoir computing using the probabilities of each\nreservoir state as the readout instead of the states themselves. In stochastic\nreservoir computing, the number of distinct states of the entire reservoir\ncomputer can potentially scale exponentially with the size of the reservoir\nhardware, offering the advantage of compact device size. We prove that classes\nof stochastic echo state networks, and therefore the class of all stochastic\nreservoir computers, are universal approximating classes. We also investigate\nthe performance of two practical examples of stochastic reservoir computers in\nclassification and chaotic time series prediction. While shot noise is a\nlimiting factor in the performance of stochastic reservoir computing, we show\nsignificantly improved performance compared to a deterministic reservoir\ncomputer with similar hardware in cases where the effects of noise are small.",
        "subjects": [
            "cs.LG",
            "cs.NE",
            "cs.SY",
            "eess.SY",
            "nlin.AO",
            "stat.ML"
        ],
        "authors": [
            "Peter J. Ehlers",
            "Hendra I. Nurdin",
            "Daniel Soh"
        ],
        "published": "2024-05-20T21:26:00Z"
    },
    {
        "title": "Large scale scattering using fast solvers based on neural operators",
        "link": "http://arxiv.org/abs/2405.12380v1",
        "abstract": "We extend a recently proposed machine-learning-based iterative solver, i.e.\nthe hybrid iterative transferable solver (HINTS), to solve the scattering\nproblem described by the Helmholtz equation in an exterior domain with a\ncomplex absorbing boundary condition. The HINTS method combines neural\noperators (NOs) with standard iterative solvers, e.g. Jacobi and Gauss-Seidel\n(GS), to achieve better performance by leveraging the spectral bias of neural\nnetworks. In HINTS, some iterations of the conventional iterative method are\nreplaced by inferences of the pre-trained NO. In this work, we employ HINTS to\nsolve the scattering problem for both 2D and 3D problems, where the standard\niterative solver fails. We consider square and triangular scatterers of various\nsizes in 2D, and a cube and a model submarine in 3D. We explore and illustrate\nthe extrapolation capability of HINTS in handling diverse geometries of the\nscatterer, which is achieved by training the NO on non-scattering scenarios and\nthen deploying it in HINTS to solve scattering problems. The accurate results\ndemonstrate that the NO in HINTS method remains effective without retraining or\nfine-tuning it whenever a new scatterer is given. Taken together, our results\nhighlight the adaptability and versatility of the extended HINTS methodology in\naddressing diverse scattering problems.",
        "subjects": [
            "cs.LG",
            "physics.comp-ph"
        ],
        "authors": [
            "Zongren Zou",
            "Adar Kahana",
            "Enrui Zhang",
            "Eli Turkel",
            "Rishikesh Ranade",
            "Jay Pathak",
            "George Em Karniadakis"
        ],
        "published": "2024-05-20T21:20:28Z"
    },
    {
        "title": "Spatio-temporal Attention-based Hidden Physics-informed Neural Network\n  for Remaining Useful Life Prediction",
        "link": "http://arxiv.org/abs/2405.12377v1",
        "abstract": "Predicting the Remaining Useful Life (RUL) is essential in Prognostic Health\nManagement (PHM) for industrial systems. Although deep learning approaches have\nachieved considerable success in predicting RUL, challenges such as low\nprediction accuracy and interpretability pose significant challenges, hindering\ntheir practical implementation. In this work, we introduce a Spatio-temporal\nAttention-based Hidden Physics-informed Neural Network (STA-HPINN) for RUL\nprediction, which can utilize the associated physics of the system degradation.\nThe spatio-temporal attention mechanism can extract important features from the\ninput data. With the self-attention mechanism on both the sensor dimension and\ntime step dimension, the proposed model can effectively extract degradation\ninformation. The hidden physics-informed neural network is utilized to capture\nthe physics mechanisms that govern the evolution of RUL. With the constraint of\nphysics, the model can achieve higher accuracy and reasonable predictions. The\napproach is validated on a benchmark dataset, demonstrating exceptional\nperformance when compared to cutting-edge methods, especially in the case of\ncomplex conditions.",
        "subjects": [
            "eess.SY",
            "cs.LG",
            "cs.SY"
        ],
        "authors": [
            "Feilong Jiang",
            "Xiaonan Hou",
            "Min Xia"
        ],
        "published": "2024-05-20T21:10:18Z"
    },
    {
        "title": "DispaRisk: Assessing and Interpreting Disparity Risks in Datasets",
        "link": "http://arxiv.org/abs/2405.12372v1",
        "abstract": "Machine Learning algorithms (ML) impact virtually every aspect of human lives\nand have found use across diverse sectors, including healthcare, finance, and\neducation. Often, ML algorithms have been found to exacerbate societal biases\npresented in datasets, leading to adversarial impacts on subsets/groups of\nindividuals, in many cases minority groups. To effectively mitigate these\nuntoward effects, it is crucial that disparities/biases are identified and\nassessed early in a ML pipeline. This proactive approach facilitates timely\ninterventions to prevent bias amplification and reduce complexity at later\nstages of model development. In this paper, we introduce DispaRisk, a novel\nframework designed to proactively assess the potential risks of disparities in\ndatasets during the initial stages of the ML pipeline. We evaluate DispaRisk's\neffectiveness by benchmarking it with commonly used datasets in fairness\nresearch. Our findings demonstrate the capabilities of DispaRisk to identify\ndatasets with a high-risk of discrimination, model families prone to biases,\nand characteristics that heighten discrimination susceptibility in a ML\npipeline. The code for our experiments is available in the following\nrepository: https://github.com/jovasque156/disparisk",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Jonathan Vasquez",
            "Carlotta Domeniconi",
            "Huzefa Rangwala"
        ],
        "published": "2024-05-20T20:56:01Z"
    },
    {
        "title": "A Novel Method for News Article Event-Based Embedding",
        "link": "http://arxiv.org/abs/2405.13071v1",
        "abstract": "Embedding news articles is a crucial tool for multiple fields, such as media\nbias detection, identifying fake news, and news recommendations. However,\nexisting news embedding methods are not optimized for capturing the latent\ncontext of news events. In many cases, news embedding methods rely on\nfull-textual information and neglect the importance of time-relevant embedding\ngeneration. Here, we aim to address these shortcomings by presenting a novel\nlightweight method that optimizes news embedding generation by focusing on the\nentities and themes mentioned in the articles and their historical connections\nto specific events. We suggest a method composed of three stages. First, we\nprocess and extract the events, entities, and themes for the given news\narticles. Second, we generate periodic time embeddings for themes and entities\nby training timely separated GloVe models on current and historical data.\nLastly, we concatenate the news embeddings generated by two distinct\napproaches: Smooth Inverse Frequency (SIF) for article-level vectors and\nSiamese Neural Networks for embeddings with nuanced event-related information.\nTo test and evaluate our method, we leveraged over 850,000 news articles and\n1,000,000 events from the GDELT project. For validation purposes, we conducted\na comparative analysis of different news embedding generation methods, applying\nthem twice to a shared event detection task - first on articles published\nwithin the same day and subsequently on those published within the same month.\nOur experiments show that our method significantly improves the\nPrecision-Recall (PR) AUC across all tasks and datasets. Specifically, we\nobserved an average PR AUC improvement of 2.15% and 2.57% compared to SIF, as\nwell as 2.57% and 2.43% compared to the semi-supervised approach for daily and\nmonthly shared event detection tasks, respectively.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.SI"
        ],
        "authors": [
            "Koren Ishlach",
            "Itzhak Ben-David",
            "Michael Fire",
            "Lior Rokach"
        ],
        "published": "2024-05-20T20:55:07Z"
    },
    {
        "title": "Algorithms for Generating Small Random Samples",
        "link": "http://arxiv.org/abs/2405.12371v1",
        "abstract": "This report presents algorithms for generating small random samples without\nreplacement. It considers two cases. It presents an algorithm for sampling a\npair of distinct integers, and an algorithm for sampling a triple of distinct\nintegers. The worst case runtime of both algorithms is constant, while the\nworst case runtime of common algorithms for the general case of sampling $k$\nelements from a set of $n$ are linear in $n$. Java implementations of both\nalgorithms are included in the open source library $\\rho\\mu$.",
        "subjects": [
            "cs.DS",
            "cs.DM",
            "math.PR",
            "68Q25, 68Q87, 68W20, 68W40, 60-04",
            "F.2.1; I.1.2; D.2.13; G.3; G.4"
        ],
        "authors": [
            "Vincent A. Cicirello"
        ],
        "published": "2024-05-20T20:52:11Z"
    },
    {
        "title": "AtomGS: Atomizing Gaussian Splatting for High-Fidelity Radiance Field",
        "link": "http://arxiv.org/abs/2405.12369v2",
        "abstract": "3D Gaussian Splatting (3DGS) has recently advanced radiance field\nreconstruction by offering superior capabilities for novel view synthesis and\nreal-time rendering speed. However, its strategy of blending optimization and\nadaptive density control might lead to sub-optimal results; it can sometimes\nyield noisy geometry and blurry artifacts due to prioritizing optimizing large\nGaussians at the cost of adequately densifying smaller ones. To address this,\nwe introduce AtomGS, consisting of Atomized Proliferation and Geometry-Guided\nOptimization. The Atomized Proliferation constrains ellipsoid Gaussians of\nvarious sizes into more uniform-sized Atom Gaussians. The strategy enhances the\nrepresentation of areas with fine features by placing greater emphasis on\ndensification in accordance with scene details. In addition, we proposed a\nGeometry-Guided Optimization approach that incorporates an Edge-Aware Normal\nLoss. This optimization method effectively smooths flat surfaces while\npreserving intricate details. Our evaluation shows that AtomGS outperforms\nexisting state-of-the-art methods in rendering quality. Additionally, it\nachieves competitive accuracy in geometry reconstruction and offers a\nsignificant improvement in training speed over other SDF-based methods. More\ninteractive demos can be found in our website\n(https://rongliu-leo.github.io/AtomGS/).",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Rong Liu",
            "Rui Xu",
            "Yue Hu",
            "Meida Chen",
            "Andrew Feng"
        ],
        "published": "2024-05-20T20:38:22Z"
    },
    {
        "title": "Layout Agnostic Human Activity Recognition in Smart Homes through\n  Textual Descriptions Of Sensor Triggers (TDOST)",
        "link": "http://arxiv.org/abs/2405.12368v1",
        "abstract": "Human activity recognition (HAR) using ambient sensors in smart homes has\nnumerous applications for human healthcare and wellness. However, building\ngeneral-purpose HAR models that can be deployed to new smart home environments\nrequires a significant amount of annotated sensor data and training overhead.\nMost smart homes vary significantly in their layouts, i.e., floor plans and the\nspecifics of sensors embedded, resulting in low generalizability of HAR models\ntrained for specific homes. We address this limitation by introducing a novel,\nlayout-agnostic modeling approach for HAR systems in smart homes that utilizes\nthe transferrable representational capacity of natural language descriptions of\nraw sensor data. To this end, we generate Textual Descriptions Of Sensor\nTriggers (TDOST) that encapsulate the surrounding trigger conditions and\nprovide cues for underlying activities to the activity recognition models.\nLeveraging textual embeddings, rather than raw sensor data, we create activity\nrecognition systems that predict standard activities across homes without\neither (re-)training or adaptation on target homes. Through an extensive\nevaluation, we demonstrate the effectiveness of TDOST-based models in unseen\nsmart homes through experiments on benchmarked CASAS datasets. Furthermore, we\nconduct a detailed analysis of how the individual components of our approach\naffect downstream activity recognition performance.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.HC"
        ],
        "authors": [
            "Megha Thukral",
            "Sourish Gunesh Dhekane",
            "Shruthi K. Hiremath",
            "Harish Haresamudram",
            "Thomas Ploetz"
        ],
        "published": "2024-05-20T20:37:44Z"
    },
    {
        "title": "Large-Scale Multi-Center CT and MRI Segmentation of Pancreas with Deep\n  Learning",
        "link": "http://arxiv.org/abs/2405.12367v1",
        "abstract": "Automated volumetric segmentation of the pancreas on cross-sectional imaging\nis needed for diagnosis and follow-up of pancreatic diseases. While CT-based\npancreatic segmentation is more established, MRI-based segmentation methods are\nunderstudied, largely due to a lack of publicly available datasets,\nbenchmarking research efforts, and domain-specific deep learning methods. In\nthis retrospective study, we collected a large dataset (767 scans from 499\nparticipants) of T1-weighted (T1W) and T2-weighted (T2W) abdominal MRI series\nfrom five centers between March 2004 and November 2022. We also collected CT\nscans of 1,350 patients from publicly available sources for benchmarking\npurposes. We developed a new pancreas segmentation method, called PanSegNet,\ncombining the strengths of nnUNet and a Transformer network with a new linear\nattention module enabling volumetric computation. We tested PanSegNet's\naccuracy in cross-modality (a total of 2,117 scans) and cross-center settings\nwith Dice and Hausdorff distance (HD95) evaluation metrics. We used Cohen's\nkappa statistics for intra and inter-rater agreement evaluation and paired\nt-tests for volume and Dice comparisons, respectively. For segmentation\naccuracy, we achieved Dice coefficients of 88.3% (std: 7.2%, at case level)\nwith CT, 85.0% (std: 7.9%) with T1W MRI, and 86.3% (std: 6.4%) with T2W MRI.\nThere was a high correlation for pancreas volume prediction with R^2 of 0.91,\n0.84, and 0.85 for CT, T1W, and T2W, respectively. We found moderate\ninter-observer (0.624 and 0.638 for T1W and T2W MRI, respectively) and high\nintra-observer agreement scores. All MRI data is made available at\nhttps://osf.io/kysnj/. Our source code is available at\nhttps://github.com/NUBagciLab/PaNSegNet.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Zheyuan Zhang",
            "Elif Keles",
            "Gorkem Durak",
            "Yavuz Taktak",
            "Onkar Susladkar",
            "Vandan Gorade",
            "Debesh Jha",
            "Asli C. Ormeci",
            "Alpay Medetalibeyoglu",
            "Lanhong Yao",
            "Bin Wang",
            "Ilkin Sevgi Isler",
            "Linkai Peng",
            "Hongyi Pan",
            "Camila Lopes Vendrami",
            "Amir Bourhani",
            "Yury Velichko",
            "Boqing Gong",
            "Concetto Spampinato",
            "Ayis Pyrros",
            "Pallavi Tiwari",
            "Derk C. F. Klatte",
            "Megan Engels",
            "Sanne Hoogenboom",
            "Candice W. Bolan",
            "Emil Agarunov",
            "Nassier Harfouch",
            "Chenchan Huang",
            "Marco J. Bruno",
            "Ivo Schoots",
            "Rajesh N. Keswani",
            "Frank H. Miller",
            "Tamas Gonda",
            "Cemal Yazici",
            "Temel Tirkes",
            "Baris Turkbey",
            "Michael B. Wallace",
            "Ulas Bagci"
        ],
        "published": "2024-05-20T20:37:27Z"
    },
    {
        "title": "Question-Based Retrieval using Atomic Units for Enterprise RAG",
        "link": "http://arxiv.org/abs/2405.12363v1",
        "abstract": "Enterprise retrieval augmented generation (RAG) offers a highly flexible\nframework for combining powerful large language models (LLMs) with internal,\npossibly temporally changing, documents. In RAG, documents are first chunked.\nRelevant chunks are then retrieved for a specific user query, which are passed\nas context to a synthesizer LLM to generate the query response. However, the\nretrieval step can limit performance, as incorrect chunks can lead the\nsynthesizer LLM to generate a false response. This work proposes a zero-shot\nadaptation of standard dense retrieval steps for more accurate chunk recall.\nSpecifically, a chunk is first decomposed into atomic statements. A set of\nsynthetic questions are then generated on these atoms (with the chunk as the\ncontext). Dense retrieval involves finding the closest set of synthetic\nquestions, and associated chunks, to the user query. It is found that retrieval\nwith the atoms leads to higher recall than retrieval with chunks. Further\nperformance gain is observed with retrieval using the synthetic questions\ngenerated over the atoms. Higher recall at the retrieval step enables higher\nperformance of the enterprise LLM using the RAG pipeline.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Vatsal Raina",
            "Mark Gales"
        ],
        "published": "2024-05-20T20:27:00Z"
    },
    {
        "title": "Design and Analysis of a Detuned Series-Series IPT System with Solenoid\n  Coil Structure for Drone Charging Applications",
        "link": "http://arxiv.org/abs/2405.12359v1",
        "abstract": "This paper proposes a new coil configuration that uses solenoid ferrites on\nthe receiver side instead of planar ferrite coils that are employed in existing\nwireless charging systems.The solenoid ferrites are used in the drone legs to\nhelp mount the receiver on a moving truck while the two parts of the\ntransmitter are placed on the truck.To validate this idea a detuned transmitter\nseries-series (SS) compensated IPT prototype system has been investigated to\ncharge the onboard battery of a drone.The proposed detuned design helps to\nlimit the system output power and transmitter side current at even zero\ncoupling condition and tolerates misalignment positions. Experimental results\ndemonstrate that the system switching frequency is 245 kHz and the primary side\nresonates at 223.5 kHz, which is a detuned design The transmitting current is\nlimited to 4.5 A at zero coupling condition with a low power loss of only 4.2 W\nat zero coupling condition. The target achievable power of the system is 50 W\nwith a 10 mm air gap and horizontal and vertical misalignment in the range of\n[0, 50 mm].This system has been validated by experiments to charge an 11.1V\nbattery at 48.2W with 88.2% efficiency.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Elias Nadi",
            "Hua Zhang"
        ],
        "published": "2024-05-20T20:17:30Z"
    },
    {
        "title": "Using Color Refinement to Boost Enumeration and Counting for Acyclic CQs\n  of Binary Schemas",
        "link": "http://arxiv.org/abs/2405.12358v1",
        "abstract": "We present an index structure, called the color-index, to boost the\nevaluation of acyclic conjunctive queries (ACQs) over binary schemas. The\ncolor-index is based on the color refinement algorithm, a widely used\nsubroutine for graph isomorphism testing algorithms. Given a database $D$, we\nuse a suitable version of the color refinement algorithm to produce a stable\ncoloring of $D$, an assignment from the active domain of $D$ to a set of colors\n$C_D$. The main ingredient of the color-index is a particular database $D_c$\nwhose active domain is $C_D$ and whose size is at most $|D|$. Using the\ncolor-index, we can evaluate any free-connex ACQ $Q$ over $D$ with\npreprocessing time $O(|Q| \\cdot |D_c|)$ and constant delay enumeration.\nFurthermore, we can also count the number of results of $Q$ over $D$ in time\n$O(|Q| \\cdot |D_c|)$. Given that $|D_c|$ could be much smaller than $|D|$ (even\nconstant-size for some families of databases), the color-index is the first\nindex structure for evaluating free-connex ACQs that allows efficient\nenumeration and counting with performance that may be strictly smaller than the\ndatabase size.",
        "subjects": [
            "cs.DB",
            "cs.LO"
        ],
        "authors": [
            "Cristian Riveros",
            "Benjamin Scheidt",
            "Nicole Schweikardt"
        ],
        "published": "2024-05-20T20:14:32Z"
    },
    {
        "title": "Paired Conditional Generative Adversarial Network for Highly Accelerated\n  Liver 4D MRI",
        "link": "http://arxiv.org/abs/2405.12357v1",
        "abstract": "Purpose: 4D MRI with high spatiotemporal resolution is desired for\nimage-guided liver radiotherapy. Acquiring densely sampling k-space data is\ntime-consuming. Accelerated acquisition with sparse samples is desirable but\noften causes degraded image quality or long reconstruction time. We propose the\nReconstruct Paired Conditional Generative Adversarial Network (Re-Con-GAN) to\nshorten the 4D MRI reconstruction time while maintaining the reconstruction\nquality.\n  Methods: Patients who underwent free-breathing liver 4D MRI were included in\nthe study. Fully- and retrospectively under-sampled data at 3, 6 and 10 times\n(3x, 6x and 10x) were first reconstructed using the nuFFT algorithm. Re-Con-GAN\nthen trained input and output in pairs. Three types of networks, ResNet9, UNet\nand reconstruction swin transformer, were explored as generators. PatchGAN was\nselected as the discriminator. Re-Con-GAN processed the data (3D+t) as temporal\nslices (2D+t). A total of 48 patients with 12332 temporal slices were split\ninto training (37 patients with 10721 slices) and test (11 patients with 1611\nslices).\n  Results: Re-Con-GAN consistently achieved comparable/better PSNR, SSIM, and\nRMSE scores compared to CS/UNet models. The inference time of Re-Con-GAN, UNet\nand CS are 0.15s, 0.16s, and 120s. The GTV detection task showed that\nRe-Con-GAN and CS, compared to UNet, better improved the dice score (3x\nRe-Con-GAN 80.98%; 3x CS 80.74%; 3x UNet 79.88%) of unprocessed under-sampled\nimages (3x 69.61%).\n  Conclusion: A generative network with adversarial training is proposed with\npromising and efficient reconstruction results demonstrated on an in-house\ndataset. The rapid and qualitative reconstruction of 4D liver MR has the\npotential to facilitate online adaptive MR-guided radiotherapy for liver\ncancer.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Di Xu",
            "Xin Miao",
            "Hengjie Liu",
            "Jessica E. Scholey",
            "Wensha Yang",
            "Mary Feng",
            "Michael Ohliger",
            "Hui Lin",
            "Yi Lao",
            "Yang Yang",
            "Ke Sheng"
        ],
        "published": "2024-05-20T20:14:23Z"
    },
    {
        "title": "Coarse-graining conformational dynamics with multi-dimensional\n  generalized Langevin equation: how, when, and why",
        "link": "http://arxiv.org/abs/2405.12356v1",
        "abstract": "A data-driven ab initio generalized Langevin equation (AIGLE) approach is\ndeveloped to learn and simulate high-dimensional, heterogeneous, coarse-grained\nconformational dynamics. Constrained by the fluctuation-dissipation theorem,\nthe approach can build coarse-grained models in dynamical consistency with\nall-atom molecular dynamics. We also propose practical criteria for AIGLE to\nenforce long-term dynamical consistency. Case studies of a toy polymer, with 20\ncoarse-grained sites, and the alanine dipeptide, with two dihedral angles,\nelucidate why one should adopt AIGLE or its Markovian limit for modeling\ncoarse-grained conformational dynamics in practice.",
        "subjects": [
            "physics.bio-ph",
            "cs.LG",
            "physics.chem-ph",
            "physics.data-an"
        ],
        "authors": [
            "Pinchen Xie",
            "Yunrui Qiu",
            "Weinan E"
        ],
        "published": "2024-05-20T20:14:09Z"
    },
    {
        "title": "Investigating the Impact of Choice on Deep Reinforcement Learning for\n  Space Controls",
        "link": "http://arxiv.org/abs/2405.12355v1",
        "abstract": "For many space applications, traditional control methods are often used\nduring operation. However, as the number of space assets continues to grow,\nautonomous operation can enable rapid development of control methods for\ndifferent space related tasks. One method of developing autonomous control is\nReinforcement Learning (RL), which has become increasingly popular after\ndemonstrating promising performance and success across many complex tasks.\nWhile it is common for RL agents to learn bounded continuous control values,\nthis may not be realistic or practical for many space tasks that traditionally\nprefer an on/off approach for control. This paper analyzes using discrete\naction spaces, where the agent must choose from a predefined list of actions.\nThe experiments explore how the number of choices provided to the agents\naffects their measured performance during and after training. This analysis is\nconducted for an inspection task, where the agent must circumnavigate an object\nto inspect points on its surface, and a docking task, where the agent must move\ninto proximity of another spacecraft and \"dock\" with a low relative speed. A\ncommon objective of both tasks, and most space tasks in general, is to minimize\nfuel usage, which motivates the agent to regularly choose an action that uses\nno fuel. Our results show that a limited number of discrete choices leads to\noptimal performance for the inspection task, while continuous control leads to\noptimal performance for the docking task.",
        "subjects": [
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Nathaniel Hamilton",
            "Kyle Dunlap",
            "Kerianne L. Hobbs"
        ],
        "published": "2024-05-20T20:06:54Z"
    },
    {
        "title": "A Study on Optimization Techniques for Variational Quantum Circuits in\n  Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.12354v1",
        "abstract": "Quantum Computing aims to streamline machine learning, making it more\neffective with fewer trainable parameters. This reduction of parameters can\nspeed up the learning process and reduce the use of computational resources.\nHowever, in the current phase of quantum computing development, known as the\nnoisy intermediate-scale quantum era (NISQ), learning is difficult due to a\nlimited number of qubits and widespread quantum noise. To overcome these\nchallenges, researchers are focusing on variational quantum circuits (VQCs).\nVQCs are hybrid algorithms that merge a quantum circuit, which can be adjusted\nthrough parameters, with traditional classical optimization techniques. These\ncircuits require only few qubits for effective learning. Recent studies have\npresented new ways of applying VQCs to reinforcement learning, showing\npromising results that warrant further exploration. This study investigates the\neffects of various techniques -- data re-uploading, input scaling, output\nscaling -- and introduces exponential learning rate decay in the quantum\nproximal policy optimization algorithm's actor-VQC. We assess these methods in\nthe popular Frozen Lake and Cart Pole environments. Our focus is on their\nability to reduce the number of parameters in the VQC without losing\neffectiveness. Our findings indicate that data re-uploading and an exponential\nlearning rate decay significantly enhance hyperparameter stability and overall\nperformance. While input scaling does not improve parameter efficiency, output\nscaling effectively manages greediness, leading to increased learning speed and\nrobustness.",
        "subjects": [
            "quant-ph",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Michael Kölle",
            "Timo Witter",
            "Tobias Rohe",
            "Gerhard Stenzel",
            "Philipp Altmann",
            "Thomas Gabor"
        ],
        "published": "2024-05-20T20:06:42Z"
    },
    {
        "title": "TinyM$^2$Net-V3: Memory-Aware Compressed Multimodal Deep Neural Networks\n  for Sustainable Edge Deployment",
        "link": "http://arxiv.org/abs/2405.12353v1",
        "abstract": "The advancement of sophisticated artificial intelligence (AI) algorithms has\nled to a notable increase in energy usage and carbon dioxide emissions,\nintensifying concerns about climate change. This growing problem has brought\nthe environmental sustainability of AI technologies to the forefront,\nespecially as they expand across various sectors. In response to these\nchallenges, there is an urgent need for the development of sustainable AI\nsolutions. These solutions must focus on energy-efficient embedded systems that\nare capable of handling diverse data types even in environments with limited\nresources, thereby ensuring both technological progress and environmental\nresponsibility. Integrating complementary multimodal data into tiny machine\nlearning models for edge devices is challenging due to increased complexity,\nlatency, and power consumption. This work introduces TinyM$^2$Net-V3, a system\nthat processes different modalities of complementary data, designs deep neural\nnetwork (DNN) models, and employs model compression techniques including\nknowledge distillation and low bit-width quantization with memory-aware\nconsiderations to fit models within lower memory hierarchy levels, reducing\nlatency and enhancing energy efficiency on resource-constrained devices. We\nevaluated TinyM$^2$Net-V3 in two multimodal case studies: COVID-19 detection\nusing cough, speech, and breathing audios, and pose classification from depth\nand thermal images. With tiny inference models (6 KB and 58 KB), we achieved\n92.95% and 90.7% accuracies, respectively. Our tiny machine learning models,\ndeployed on resource limited hardware, demonstrated low latencies within\nmilliseconds and very high power efficiency.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Hasib-Al Rashid",
            "Tinoosh Mohsenin"
        ],
        "published": "2024-05-20T20:03:51Z"
    },
    {
        "title": "A framework for extraction and transformation of documents",
        "link": "http://arxiv.org/abs/2405.12350v1",
        "abstract": "We present a theoretical framework for the extraction and transformation of\ntext documents. We propose to use a two-phase process where the first phase\nextracts span-tuples from a document, and the second phase maps the content of\nthe span-tuples into new documents. We base the extraction phase on the\nframework of document spanners and the transformation phase on the theory of\npolyregular functions, the class of regular string-to-string functions with\npolynomial growth.\n  For supporting practical extract-transform scenarios, we propose an extension\nof document spanners described by regex formulas from span-tuples to so-called\nmultispan-tuples, where variables are mapped to sets of spans. We prove that\nthis extension, called regex multispanners, has the same desirable properties\nas standard spanners described by regex formulas. In our framework, an\nExtract-Transform (ET) program is given by a regex multispanner followed by a\npolyregular function.\n  In this paper, we study the expressibility and evaluation problem of ET\nprograms when the transformation function is linear, called linear ET programs.\nWe show that linear ET programs are equally expressive as non-deterministic\nstreaming string transducers under bag semantics. Moreover, we show that linear\nET programs are closed under composition. Finally, we present an enumeration\nalgorithm for evaluating every linear ET program over a document with linear\ntime preprocessing and constant delay.",
        "subjects": [
            "cs.DB",
            "cs.FL"
        ],
        "authors": [
            "Cristian Riveros",
            "Markus L. Schmid",
            "Nicole Schweikardt"
        ],
        "published": "2024-05-20T19:59:25Z"
    },
    {
        "title": "Self-HWDebug: Automation of LLM Self-Instructing for Hardware Security\n  Verification",
        "link": "http://arxiv.org/abs/2405.12347v1",
        "abstract": "The rise of instruction-tuned Large Language Models (LLMs) marks a\nsignificant advancement in artificial intelligence (AI) (tailored to respond to\nspecific prompts). Despite their popularity, applying such models to debug\nsecurity vulnerabilities in hardware designs, i.e., register transfer language\n(RTL) modules, particularly at system-on-chip (SoC) level, presents\nconsiderable challenges. One of the main issues lies in the need for precisely\ndesigned instructions for pinpointing and mitigating the vulnerabilities, which\nrequires substantial time and expertise from human experts. In response to this\nchallenge, this paper proposes Self-HWDebug, an innovative framework that\nleverages LLMs to automatically create required debugging instructions. In\nSelf-HWDebug, a set of already identified bugs from the most critical hardware\ncommon weakness enumeration (CWE) listings, along with mitigation resolutions,\nis provided to the framework, followed by prompting the LLMs to generate\ntargeted instructions for such mitigation. The LLM-generated instructions are\nsubsequently used as references to address vulnerabilities within the same CWE\ncategory but in totally different designs, effectively demonstrating the\nframework's ability to extend solutions across related security issues.\nSelf-HWDebug significantly reduces human intervention by using the model's own\noutput to guide debugging. Through comprehensive testing, Self-HWDebug proves\nnot only to reduce experts' effort/time but also to even improve the quality of\nthe debugging process.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Mohammad Akyash",
            "Hadi Mardani Kamali"
        ],
        "published": "2024-05-20T19:47:13Z"
    },
    {
        "title": "Cascade-based Randomization for Inferring Causal Effects under Diffusion\n  Interference",
        "link": "http://arxiv.org/abs/2405.12340v1",
        "abstract": "The presence of interference, where the outcome of an individual may depend\non the treatment assignment and behavior of neighboring nodes, can lead to\nbiased causal effect estimation. Current approaches to network experiment\ndesign focus on limiting interference through cluster-based randomization, in\nwhich clusters are identified using graph clustering, and cluster randomization\ndictates the node assignment to treatment and control. However, cluster-based\nrandomization approaches perform poorly when interference propagates in\ncascades, whereby the response of individuals to treatment propagates to their\nmulti-hop neighbors. When we have knowledge of the cascade seed nodes, we can\nleverage this interference structure to mitigate the resulting causal effect\nestimation bias. With this goal, we propose a cascade-based network experiment\ndesign that initiates treatment assignment from the cascade seed node and\npropagates the assignment to their multi-hop neighbors to limit interference\nduring cascade growth and thereby reduce the overall causal effect estimation\nerror. Our extensive experiments on real-world and synthetic datasets\ndemonstrate that our proposed framework outperforms the existing\nstate-of-the-art approaches in estimating causal effects in network data.",
        "subjects": [
            "cs.LG",
            "cs.SI"
        ],
        "authors": [
            "Zahra Fatemi",
            "Jean Pouget-Abadie",
            "Elena Zheleva"
        ],
        "published": "2024-05-20T19:24:10Z"
    },
    {
        "title": "Interoperable Provenance Authentication of Broadcast Media using Open\n  Standards-based Metadata, Watermarking and Cryptography",
        "link": "http://arxiv.org/abs/2405.12336v1",
        "abstract": "The spread of false and misleading information is receiving significant\nattention from legislative and regulatory bodies. Consumers place trust in\nspecific sources of information, so a scalable, interoperable method for\ndetermining the provenance and authenticity of information is needed. In this\npaper we analyze the posting of broadcast news content to a social media\nplatform, the role of open standards, the interplay of cryptographic metadata\nand watermarks when validating provenance, and likely success and failure\nscenarios. We conclude that the open standards for cryptographically\nauthenticated metadata developed by the Coalition for Provenance and\nAuthenticity (C2PA) and for audio and video watermarking developed by the\nAdvanced Television Systems Committee (ATSC) are well suited to address\nbroadcast provenance. We suggest methods for using these standards for optimal\nsuccess.",
        "subjects": [
            "cs.CR",
            "cs.MM"
        ],
        "authors": [
            "John C. Simmons",
            "Joseph M. Winograd"
        ],
        "published": "2024-05-20T19:10:28Z"
    },
    {
        "title": "Efficacy of static analysis tools for software defect detection on\n  open-source projects",
        "link": "http://arxiv.org/abs/2405.12333v1",
        "abstract": "In software practice, static analysis tools remain an integral part of\ndetecting defects in software and there have been various tools designed to run\nthe analysis in different programming languages like Java, C++, and Python.\nThis paper presents an empirical comparison of popular static analysis tools\nfor identifying software defects using several datasets using Java, C++, and\nPython code. The study used popular analysis tools such as SonarQube, PMD,\nCheckstyle, and FindBugs to perform the comparison based on using the datasets.\nThe study also used various evaluation metrics such as Precision, Recall, and\nF1-score to determine the performance of each analysis tool. The study results\nshow that SonarQube performs considerably well than all other tools in terms of\nits defect detection across the various three programming languages. These\nfindings remain consistent with other existing studies that also agree on\nSonarQube being an effective tool for defect detection in software. The study\ncontributes to much insight on static analysis tools with different programming\nlanguages and additional information to understand the strengths and weaknesses\nof each analysis tool. The study also discusses the implications for software\ndevelopment researchers and practitioners, and future directions in this area.\nOur research approach aim is to provide a recommendation guideline to enable\nsoftware developers, practitioners, and researchers to make the right choice on\nstatic analysis tools to detect errors in their software codes. Also, for\nresearchers to embark on investigating and improving software analysis tools to\nenhance the quality and reliability of the software systems and its software\ndevelopment processes practice.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Jones Yeboah",
            "Saheed Popoola"
        ],
        "published": "2024-05-20T19:05:32Z"
    },
    {
        "title": "Multi-dimension Transformer with Attention-based Filtering for Medical\n  Image Segmentation",
        "link": "http://arxiv.org/abs/2405.12328v1",
        "abstract": "The accurate segmentation of medical images is crucial for diagnosing and\ntreating diseases. Recent studies demonstrate that vision transformer-based\nmethods have significantly improved performance in medical image segmentation,\nprimarily due to their superior ability to establish global relationships among\nfeatures and adaptability to various inputs. However, these methods struggle\nwith the low signal-to-noise ratio inherent to medical images. Additionally,\nthe effective utilization of channel and spatial information, which are\nessential for medical image segmentation, is limited by the representation\ncapacity of self-attention. To address these challenges, we propose a\nmulti-dimension transformer with attention-based filtering (MDT-AF), which\nredesigns the patch embedding and self-attention mechanism for medical image\nsegmentation. MDT-AF incorporates an attention-based feature filtering\nmechanism into the patch embedding blocks and employs a coarse-to-fine process\nto mitigate the impact of low signal-to-noise ratio. To better capture complex\nstructures in medical images, MDT-AF extends the self-attention mechanism to\nincorporate spatial and channel dimensions, enriching feature representation.\nMoreover, we introduce an interaction mechanism to improve the feature\naggregation between spatial and channel dimensions. Experimental results on\nthree public medical image segmentation benchmarks show that MDT-AF achieves\nstate-of-the-art (SOTA) performance.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Wentao Wang",
            "Xi Xiao",
            "Mingjie Liu",
            "Qing Tian",
            "Xuanyao Huang",
            "Qizhen Lan",
            "Swalpa Kumar Roy",
            "Tianyang Wang"
        ],
        "published": "2024-05-20T18:52:41Z"
    },
    {
        "title": "Diversifying by Intent in Recommender Systems",
        "link": "http://arxiv.org/abs/2405.12327v1",
        "abstract": "It has become increasingly clear that recommender systems overly focusing on\nshort-term engagement can inadvertently hurt long-term user experience.\nHowever, it is challenging to optimize long-term user experience directly as\nthe desired signal is sparse, noisy and manifests over a long horizon. In this\nwork, we show the benefits of incorporating higher-level user understanding,\nspecifically user intents that can persist across multiple interactions or\nrecommendation sessions, for whole-page recommendation toward optimizing\nlong-term user experience. User intent has primarily been investigated within\nthe context of search, but remains largely under-explored for recommender\nsystems. To bridge this gap, we develop a probabilistic intent-based whole-page\ndiversification framework in the final stage of a recommender system. Starting\nwith a prior belief of user intents, the proposed diversification framework\nsequentially selects items at each position based on these beliefs, and\nsubsequently updates posterior beliefs about the intents. It ensures that\ndifferent user intents are represented in a page towards optimizing long-term\nuser experience.\n  We experiment with the intent diversification framework on one of the world's\nlargest content recommendation platforms, serving billions of users daily. Our\nframework incorporates the user's exploration intent, capturing their\npropensity to explore new interests and content. Live experiments show that the\nproposed framework leads to an increase in user retention and overall user\nenjoyment, validating its effectiveness in facilitating long-term planning. In\nparticular, it enables users to consistently discover and engage with diverse\ncontents that align with their underlying intents over time, thereby leading to\nan improved long-term user experience.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "authors": [
            "Yuyan Wang",
            "Cheenar Banerjee",
            "Samer Chucri",
            "Fabio Soldo",
            "Sriraj Badam",
            "Ed H. Chi",
            "Minmin Chen"
        ],
        "published": "2024-05-20T18:52:33Z"
    },
    {
        "title": "Overlap Number of Balls Model-Agnostic CounterFactuals (ONB-MACF): A\n  Data-Morphology-based Counterfactual Generation Method for Trustworthy\n  Artificial Intelligence",
        "link": "http://arxiv.org/abs/2405.12326v1",
        "abstract": "Explainable Artificial Intelligence (XAI) is a pivotal research domain aimed\nat understanding the operational mechanisms of AI systems, particularly those\nconsidered ``black boxes'' due to their complex, opaque nature. XAI seeks to\nmake these AI systems more understandable and trustworthy, providing insight\ninto their decision-making processes. By producing clear and comprehensible\nexplanations, XAI enables users, practitioners, and stakeholders to trust a\nmodel's decisions. This work analyses the value of data morphology strategies\nin generating counterfactual explanations. It introduces the Overlap Number of\nBalls Model-Agnostic CounterFactuals (ONB-MACF) method, a model-agnostic\ncounterfactual generator that leverages data morphology to estimate a model's\ndecision boundaries. The ONB-MACF method constructs hyperspheres in the data\nspace whose covered points share a class, mapping the decision boundary.\nCounterfactuals are then generated by incrementally adjusting an instance's\nattributes towards the nearest alternate-class hypersphere, crossing the\ndecision boundary with minimal modifications. By design, the ONB-MACF method\ngenerates feasible and sparse counterfactuals that follow the data\ndistribution. Our comprehensive benchmark from a double perspective\n(quantitative and qualitative) shows that the ONB-MACF method outperforms\nexisting state-of-the-art counterfactual generation methods across multiple\nquality metrics on diverse tabular datasets. This supports our hypothesis,\nshowcasing the potential of data-morphology-based explainability strategies for\ntrustworthy AI.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "José Daniel Pascual-Triana",
            "Alberto Fernández",
            "Javier Del Ser",
            "Francisco Herrera"
        ],
        "published": "2024-05-20T18:51:42Z"
    },
    {
        "title": "Securing Blockchain-based IoT Systems with Physical Unclonable Functions\n  and Zero-Knowledge Proofs",
        "link": "http://arxiv.org/abs/2405.12322v1",
        "abstract": "This paper presents a framework for securing blockchain-based IoT systems by\nintegrating Physical Unclonable Functions (PUFs) and Zero-Knowledge Proofs\n(ZKPs) within a Hyperledger Fabric environment. The proposed framework\nleverages PUFs for unique device identification and ZKPs for privacy-preserving\nauthentication and transaction processing. Experimental results demonstrate the\nframework's feasibility, performance, and security against various attacks.\nThis framework provides a comprehensive solution for addressing the security\nchallenges in blockchain-based IoT systems.",
        "subjects": [
            "cs.CR",
            "cs.DC",
            "cs.NI"
        ],
        "authors": [
            "Daniel Commey",
            "Sena Hounsinou",
            "Garth V. Crosby"
        ],
        "published": "2024-05-20T18:40:27Z"
    },
    {
        "title": "Dynamic Line Rating using Hyper-local Weather Predictions: A Machine\n  Learning Approach",
        "link": "http://arxiv.org/abs/2405.12319v1",
        "abstract": "Dynamic Line Rating (DLR) systems are crucial for renewable energy\nintegration in transmission networks. However, traditional methods relying on\nsensor data face challenges due to the impracticality of installing sensors on\nevery pole or span. Additionally, sensor-based approaches may struggle\npredicting DLR in rapidly changing weather conditions. This paper proposes a\nnovel approach, leveraging machine learning (ML) techniques alongside\nhyper-local weather forecast data. Unlike conventional methods, which solely\nrely on sensor data, this approach utilizes ML models trained to predict\nhyper-local weather parameters on a full network scale. Integrating\ntopographical data enhances prediction accuracy by accounting for landscape\nfeatures and obstacles around overhead lines. The paper introduces confidence\nintervals for DLR assessments to mitigate risks associated with uncertainties.\nA case study from Estonia demonstrates the practical implementation of the\nproposed methodology, highlighting its effectiveness in real-world scenarios.\nBy addressing limitations of sensor-based approaches, this research contributes\nto the discourse of renewable energy integration in transmission systems,\nadvancing efficiency and reliability in the power grid.",
        "subjects": [
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Henri Manninen",
            "Markus Lippus",
            "Georg Rute"
        ],
        "published": "2024-05-20T18:29:53Z"
    },
    {
        "title": "Hierarchical SegNet with Channel and Context Attention for Accurate Lung\n  Segmentation in Chest X-ray Images",
        "link": "http://arxiv.org/abs/2405.12318v1",
        "abstract": "Lung segmentation in chest X-ray images is a critical task in medical image\nanalysis, enabling accurate diagnosis and treatment of various lung diseases.\nIn this paper, we propose a novel approach for lung segmentation by integrating\nHierarchical SegNet with a proposed multi-modal attention mechanism. The\nchannel attention mechanism highlights specific feature maps or channels\ncrucial for lung region segmentation, while the context attention mechanism\nadaptively weighs the importance of different spatial regions. By combining\nboth mechanisms, the proposed mechanism enables the model to better capture\ncomplex patterns and relationships between various features, leading to\nimproved segmentation accuracy and better feature representation. Furthermore,\nan attention gating mechanism is employed to integrate attention information\nwith encoder features, allowing the model to adaptively weigh the importance of\ndifferent attention features and ignore irrelevant ones. Experimental results\ndemonstrate that our proposed approach achieves state-of-the-art performance in\nlung segmentation tasks, outperforming existing methods. The proposed approach\nhas the potential to improve the accuracy and efficiency of lung disease\ndiagnosis and treatment, and can be extended to other medical image analysis\ntasks.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Mohammad Ali Labbaf Khaniki",
            "Nazanin Mahjourian",
            "Mohammad Manthouri"
        ],
        "published": "2024-05-20T18:29:41Z"
    },
    {
        "title": "Kernel spectral joint embeddings for high-dimensional noisy datasets\n  using duo-landmark integral operators",
        "link": "http://arxiv.org/abs/2405.12317v1",
        "abstract": "Integrative analysis of multiple heterogeneous datasets has become standard\npractice in many research fields, especially in single-cell genomics and\nmedical informatics. Existing approaches oftentimes suffer from limited power\nin capturing nonlinear structures, insufficient account of noisiness and\neffects of high-dimensionality, lack of adaptivity to signals and sample sizes\nimbalance, and their results are sometimes difficult to interpret. To address\nthese limitations, we propose a novel kernel spectral method that achieves\njoint embeddings of two independently observed high-dimensional noisy datasets.\nThe proposed method automatically captures and leverages possibly shared\nlow-dimensional structures across datasets to enhance embedding quality. The\nobtained low-dimensional embeddings can be utilized for many downstream tasks\nsuch as simultaneous clustering, data visualization, and denoising. The\nproposed method is justified by rigorous theoretical analysis. Specifically, we\nshow the consistency of our method in recovering the low-dimensional noiseless\nsignals, and characterize the effects of the signal-to-noise ratios on the\nrates of convergence. Under a joint manifolds model framework, we establish the\nconvergence of ultimate embeddings to the eigenfunctions of some newly\nintroduced integral operators. These operators, referred to as duo-landmark\nintegral operators, are defined by the convolutional kernel maps of some\nreproducing kernel Hilbert spaces (RKHSs). These RKHSs capture the either\npartially or entirely shared underlying low-dimensional nonlinear signal\nstructures of the two datasets. Our numerical experiments and analyses of two\nsingle-cell omics datasets demonstrate the empirical advantages of the proposed\nmethod over existing methods in both embeddings and several downstream tasks.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Xiucai Ding",
            "Rong Ma"
        ],
        "published": "2024-05-20T18:29:36Z"
    },
    {
        "title": "Deep learning-based hyperspectral image reconstruction for quality\n  assessment of agro-product",
        "link": "http://arxiv.org/abs/2405.12313v1",
        "abstract": "Hyperspectral imaging (HSI) has recently emerged as a promising tool for many\nagricultural applications; however, the technology cannot be directly used in a\nreal-time system due to the extensive time needed to process large volumes of\ndata. Consequently, the development of a simple, compact, and cost-effective\nimaging system is not possible with the current HSI systems. Therefore, the\noverall goal of this study was to reconstruct hyperspectral images from RGB\nimages through deep learning for agricultural applications. Specifically, this\nstudy used Hyperspectral Convolutional Neural Network - Dense (HSCNN-D) to\nreconstruct hyperspectral images from RGB images for predicting soluble solid\ncontent (SSC) in sweet potatoes. The algorithm accurately reconstructed the\nhyperspectral images from RGB images, with the resulting spectra closely\nmatching the ground-truth. The partial least squares regression (PLSR) model\nbased on reconstructed spectra outperformed the model using the full spectral\nrange, demonstrating its potential for SSC prediction in sweet potatoes. These\nfindings highlight the potential of deep learning-based hyperspectral image\nreconstruction as a low-cost, efficient tool for various agricultural uses.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Md. Toukir Ahmed",
            "Ocean Monjur",
            "Mohammed Kamruzzaman"
        ],
        "published": "2024-05-20T18:15:20Z"
    },
    {
        "title": "A Principled Approach for a New Bias Measure",
        "link": "http://arxiv.org/abs/2405.12312v1",
        "abstract": "The widespread use of machine learning and data-driven algorithms for\ndecision making has been steadily increasing over many years. The areas in\nwhich this is happening are diverse: healthcare, employment, finance,\neducation, the legal system to name a few; and the associated negative side\neffects are being increasingly harmful for society. Negative data \\emph{bias}\nis one of those, which tends to result in harmful consequences for specific\ngroups of people. Any mitigation strategy or effective policy that addresses\nthe negative consequences of bias must start with awareness that bias exists,\ntogether with a way to understand and quantify it. However, there is a lack of\nconsensus on how to measure data bias and oftentimes the intended meaning is\ncontext dependent and not uniform within the research community. The main\ncontributions of our work are: (1) a general algorithmic framework for defining\nand efficiently quantifying the bias level of a dataset with respect to a\nprotected group; and (2) the definition of a new bias measure. Our results are\nexperimentally validated using nine publicly available datasets and\ntheoretically analyzed, which provide novel insights about the problem. Based\non our approach, we also derive a bias mitigation algorithm that might be\nuseful to policymakers.",
        "subjects": [
            "cs.LG",
            "cs.CY"
        ],
        "authors": [
            "Bruno Scarone",
            "Alfredo Viola",
            "Ricardo Baeza-Yates"
        ],
        "published": "2024-05-20T18:14:33Z"
    },
    {
        "title": "Cost-Optimal Microservices Deployment with Cluster Autoscaling and Spot\n  Pricing",
        "link": "http://arxiv.org/abs/2405.12311v1",
        "abstract": "Microservices architecture has been established as an ideal software\narchitecture for cloud-based software development and deployment, offering many\nbenefits such as agility and efficiency. Microservices are often associated\nwith containers and container orchestration systems for deployment, as\ncontainerization provides convenient tools and techniques for resource\nmanagement, including the automation of orchestration processes. Among the\nfactors that make the cloud suitable for commercial software deployment,\ntransient pricing options like AWS Spot Pricing are particularly attractive as\nthey allow consumers to significantly reduce cloud costs. However, the dynamic\nnature of resource demand and the abrupt termination of spot VMs make transient\npricing challenging. Nonetheless, containerization and container orchestration\nsystems open new avenues to optimize the cost of microservices deployments by\nleveraging spot pricing on the public cloud while achieving application and\nbusiness goals.\n  We propose SpotKube, an open-source, Kubernetes-based, application-aware,\ngenetic algorithm-based solution for cost optimization, which autoscales\nclusters for microservices-based applications hosted on public clouds with spot\npricing options. SpotKube analyzes application characteristics and recommends\nthe optimal configuration for resource allocation to the cluster. It consists\nof an elastic cluster autoscaler powered by an optimization algorithm that\nensures cost-effective microservices deployment while meeting application\nperformance requirements and handling abrupt termination of nodes, thereby\nminimizing the impact on system availability. We implement and evaluate\nSpotKube with representative microservices-based applications in a real public\ncloud setup, demonstrating the effectiveness of our approach against\nalternative optimization strategies.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Dasith Edirisinghe",
            "Kavinda Rajapakse",
            "Pasindu Abeysinghe",
            "Sunimal Rathnayake"
        ],
        "published": "2024-05-20T18:14:31Z"
    },
    {
        "title": "Accurate Learning of Equivariant Quantum Systems from a Single Ground\n  State",
        "link": "http://arxiv.org/abs/2405.12309v1",
        "abstract": "Predicting properties across system parameters is an important task in\nquantum physics, with applications ranging from molecular dynamics to\nvariational quantum algorithms. Recently, provably efficient algorithms to\nsolve this task for ground states within a gapped phase were developed. Here we\ndramatically improve the efficiency of these algorithms by showing how to learn\nproperties of all ground states for systems with periodic boundary conditions\nfrom a single ground state sample. We prove that the prediction error tends to\nzero in the thermodynamic limit and numerically verify the results.",
        "subjects": [
            "quant-ph",
            "cs.LG"
        ],
        "authors": [
            "Štěpán Šmíd",
            "Roberto Bondesan"
        ],
        "published": "2024-05-20T18:13:15Z"
    },
    {
        "title": "Continual Deep Reinforcement Learning for Decentralized Satellite\n  Routing",
        "link": "http://arxiv.org/abs/2405.12308v1",
        "abstract": "This paper introduces a full solution for decentralized routing in Low Earth\nOrbit satellite constellations based on continual Deep Reinforcement Learning\n(DRL). This requires addressing multiple challenges, including the partial\nknowledge at the satellites and their continuous movement, and the time-varying\nsources of uncertainty in the system, such as traffic, communication links, or\ncommunication buffers. We follow a multi-agent approach, where each satellite\nacts as an independent decision-making agent, while acquiring a limited\nknowledge of the environment based on the feedback received from the nearby\nagents. The solution is divided into two phases. First, an offline learning\nphase relies on decentralized decisions and a global Deep Neural Network (DNN)\ntrained with global experiences. Then, the online phase with local, on-board,\nand pre-trained DNNs requires continual learning to evolve with the\nenvironment, which can be done in two different ways: (1) Model anticipation,\nwhere the predictable conditions of the constellation are exploited by each\nsatellite sharing local model with the next satellite; and (2) Federated\nLearning (FL), where each agent's model is merged first at the cluster level\nand then aggregated in a global Parameter Server. The results show that,\nwithout high congestion, the proposed Multi-Agent DRL framework achieves the\nsame E2E performance as a shortest-path solution, but the latter assumes\nintensive communication overhead for real-time network-wise knowledge of the\nsystem at a centralized node, whereas ours only requires limited feedback\nexchange among first neighbour satellites. Importantly, our solution adapts\nwell to congestion conditions and exploits less loaded paths. Moreover, the\ndivergence of models over time is easily tackled by the synergy between\nanticipation, applied in short-term alignment, and FL, utilized for long-term\nalignment.",
        "subjects": [
            "cs.LG",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Federico Lozano-Cuadra",
            "Beatriz Soret",
            "Israel Leyva-Mayorga",
            "Petar Popovski"
        ],
        "published": "2024-05-20T18:12:36Z"
    },
    {
        "title": "Automatic Hardware Pragma Insertion in High-Level Synthesis: A\n  Non-Linear Programming Approach",
        "link": "http://arxiv.org/abs/2405.12304v2",
        "abstract": "High-Level Synthesis enables the rapid prototyping of hardware accelerators,\nby combining a high-level description of the functional behavior of a kernel\nwith a set of micro-architecture optimizations as inputs. Such optimizations\ncan be described by inserting pragmas for e.g. pipelining and replication of\nunits, or even higher level transformations for HLS such as automatic data\ncaching using the AMD/Xilinx Merlin compiler. Selecting the best combination of\npragmas, even within a restricted set, remains particularly challenging and the\ntypical state-of-practice uses design-space exploration to navigate this space.\nBut due to the highly irregular performance distribution of pragma\nconfigurations, typical DSE approaches are either extremely time consuming, or\noperating on a severely restricted search space.\n  In this work we propose a framework to automatically insert HLS pragmas in\nregular loop-based programs, supporting pipelining, unit replication (coarse-\nand fine-grain), and data caching. We develop an analytical performance and\nresource model as a function of the input program properties and pragmas\ninserted, using non-linear constraints and objectives. We prove this model\nprovides a lower bound on the actual performance after HLS. We then encode this\nmodel as a Non-Linear Program, by making the pragma configuration unknowns of\nthe system, which is computed optimally by solving this NLP. This approach can\nalso be used during DSE, to quickly prune points with a (possibly partial)\npragma configuration, driven by lower bounds on achievable latency. We\nextensively evaluate our end-to-end, fully implemented system, showing it can\neffectively manipulate spaces of billions of designs in seconds to minutes for\nthe kernels evaluated.",
        "subjects": [
            "cs.AR"
        ],
        "authors": [
            "Stéphane Pouget",
            "Louis-Noël Pouchet",
            "Jason Cong"
        ],
        "published": "2024-05-20T18:11:45Z"
    },
    {
        "title": "Integration of Scanning Probe Microscope with High-Performance\n  Computing: fixed-policy and reward-driven workflows implementation",
        "link": "http://arxiv.org/abs/2405.12300v1",
        "abstract": "The rapid development of computation power and machine learning algorithms\nhas paved the way for automating scientific discovery with a scanning probe\nmicroscope (SPM). The key elements towards operationalization of automated SPM\nare the interface to enable SPM control from Python codes, availability of high\ncomputing power, and development of workflows for scientific discovery. Here we\nbuild a Python interface library that enables controlling an SPM from either a\nlocal computer or a remote high-performance computer (HPC), which satisfies the\nhigh computation power need of machine learning algorithms in autonomous\nworkflows. We further introduce a general platform to abstract the operations\nof SPM in scientific discovery into fixed-policy or reward-driven workflows.\nOur work provides a full infrastructure to build automated SPM workflows for\nboth routine operations and autonomous scientific discovery with machine\nlearning.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.LG"
        ],
        "authors": [
            "Yu Liu",
            "Utkarsh Pratiush",
            "Jason Bemis",
            "Roger Proksch",
            "Reece Emery",
            "Philip D. Rack",
            "Yu-Chen Liu",
            "Jan-Chi Yang",
            "Stanislav Udovenko",
            "Susan Trolier-McKinstry",
            "Sergei V. Kalinin"
        ],
        "published": "2024-05-20T18:08:34Z"
    },
    {
        "title": "Tensor-Train WENO Scheme for Compressible Flows",
        "link": "http://arxiv.org/abs/2405.12301v1",
        "abstract": "In this study, we introduce a tensor-train (TT) finite difference WENO method\nfor solving compressible Euler equations. In a step-by-step manner, the\ntensorization of the governing equations is demonstrated. We also introduce\n\\emph{LF-cross} and \\emph{WENO-cross} methods to compute numerical fluxes and\nthe WENO reconstruction using the cross interpolation technique. A tensor-train\napproach is developed for boundary condition types commonly encountered in\nComputational Fluid Dynamics (CFD). The performance of the proposed WENO-TT\nsolver is investigated in a rich set of numerical experiments. We demonstrate\nthat the WENO-TT method achieves the theoretical $\\text{5}^{\\text{th}}$-order\naccuracy of the classical WENO scheme in smooth problems while successfully\ncapturing complicated shock structures. In an effort to avoid the growth of TT\nranks, we propose a dynamic method to estimate the TT approximation error that\ngoverns the ranks and overall truncation error of the WENO-TT scheme. Finally,\nwe show that the traditional WENO scheme can be accelerated up to 1000 times in\nthe TT format, and the memory requirements can be significantly decreased for\nlow-rank problems, demonstrating the potential of tensor-train approach for\nfuture CFD application. This paper is the first study that develops a finite\ndifference WENO scheme using the tensor-train approach for compressible flows.\nIt is also the first comprehensive work that provides a detailed perspective\ninto the relationship between rank, truncation error, and the TT approximation\nerror for compressible WENO solvers.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "65M06, 76N30"
        ],
        "authors": [
            "Mustafa Engin Danis",
            "Duc Truong",
            "Ismael Boureima",
            "Oleg Korobkin",
            "Kim Rasmussen",
            "Boian Alexandrov"
        ],
        "published": "2024-05-20T18:08:34Z"
    },
    {
        "title": "Perturbing the Gradient for Alleviating Meta Overfitting",
        "link": "http://arxiv.org/abs/2405.12299v1",
        "abstract": "The reason for Meta Overfitting can be attributed to two factors: Mutual\nNon-exclusivity and the Lack of diversity, consequent to which a single global\nfunction can fit the support set data of all the meta-training tasks and fail\nto generalize to new unseen tasks. This issue is evidenced by low error rates\non the meta-training tasks, but high error rates on new tasks. However, there\ncan be a number of novel solutions to this problem keeping in mind any of the\ntwo objectives to be attained, i.e. to increase diversity in the tasks and to\nreduce the confidence of the model for some of the tasks. In light of the\nabove, this paper proposes a number of solutions to tackle meta-overfitting on\nfew-shot learning settings, such as few-shot sinusoid regression and few shot\nclassification. Our proposed approaches demonstrate improved generalization\nperformance compared to state-of-the-art baselines for learning in a\nnon-mutually exclusive task setting. Overall, this paper aims to provide\ninsights into tackling overfitting in meta-learning and to advance the field\ntowards more robust and generalizable models.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Manas Gogoi",
            "Sambhavi Tiwari",
            "Shekhar Verma"
        ],
        "published": "2024-05-20T18:04:59Z"
    },
    {
        "title": "Efficient Model-Stealing Attacks Against Inductive Graph Neural Networks",
        "link": "http://arxiv.org/abs/2405.12295v1",
        "abstract": "Graph Neural Networks (GNNs) are recognized as potent tools for processing\nreal-world data organized in graph structures. Especially inductive GNNs, which\nenable the processing of graph-structured data without relying on predefined\ngraph structures, are gaining importance in an increasingly wide variety of\napplications. As these networks demonstrate proficiency across a range of\ntasks, they become lucrative targets for model-stealing attacks where an\nadversary seeks to replicate the functionality of the targeted network. A large\neffort has been made to develop model-stealing attacks that focus on models\ntrained with images and texts. However, little attention has been paid to GNNs\ntrained on graph data. This paper introduces a novel method for unsupervised\nmodel-stealing attacks against inductive GNNs, based on graph contrasting\nlearning and spectral graph augmentations to efficiently extract information\nfrom the target model. The proposed attack is thoroughly evaluated on six\ndatasets. The results show that this approach demonstrates a higher level of\nefficiency compared to existing stealing attacks. More concretely, our attack\noutperforms the baseline on all benchmarks achieving higher fidelity and\ndownstream accuracy of the stolen model while requiring fewer queries sent to\nthe target model.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Marcin Podhajski",
            "Jan Dubiński",
            "Franziska Boenisch",
            "Adam Dziedzic",
            "Agnieszka Pregowska",
            "Tomasz Michalak"
        ],
        "published": "2024-05-20T18:01:15Z"
    },
    {
        "title": "Exact Random Graph Matching with Multiple Graphs",
        "link": "http://arxiv.org/abs/2405.12293v1",
        "abstract": "This work studies fundamental limits for recovering the underlying\ncorrespondence among multiple correlated random graphs. We identify a necessary\ncondition for any algorithm to correctly match all nodes across all graphs, and\npropose two algorithms for which the same condition is also sufficient. The\nfirst algorithm employs global information to simultaneously match all the\ngraphs, whereas the second algorithm first partially matches the graphs\npairwise and then combines the partial matchings by transitivity. Both\nalgorithms work down to the information theoretic threshold. Our analysis\nreveals a scenario where exact matching between two graphs alone is impossible,\nbut leveraging more than two graphs allows exact matching among all the graphs.\nAlong the way, we derive independent results about the k-core of Erdos-Renyi\ngraphs.",
        "subjects": [
            "cs.DS",
            "cs.DM",
            "math.ST",
            "stat.TH"
        ],
        "authors": [
            "Taha Ameen",
            "Bruce Hajek"
        ],
        "published": "2024-05-20T18:01:11Z"
    },
    {
        "title": "Images that Sound: Composing Images and Sounds on a Single Canvas",
        "link": "http://arxiv.org/abs/2405.12221v1",
        "abstract": "Spectrograms are 2D representations of sound that look very different from\nthe images found in our visual world. And natural images, when played as\nspectrograms, make unnatural sounds. In this paper, we show that it is possible\nto synthesize spectrograms that simultaneously look like natural images and\nsound like natural audio. We call these spectrograms images that sound. Our\napproach is simple and zero-shot, and it leverages pre-trained text-to-image\nand text-to-spectrogram diffusion models that operate in a shared latent space.\nDuring the reverse process, we denoise noisy latents with both the audio and\nimage diffusion models in parallel, resulting in a sample that is likely under\nboth models. Through quantitative evaluations and perceptual studies, we find\nthat our method successfully generates spectrograms that align with a desired\naudio prompt while also taking the visual appearance of a desired image prompt.\nPlease see our project page for video results:\nhttps://ificl.github.io/images-that-sound/",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "cs.MM",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Ziyang Chen",
            "Daniel Geng",
            "Andrew Owens"
        ],
        "published": "2024-05-20T17:59:59Z"
    },
    {
        "title": "Locational marginal burden: Quantifying the equity of optimal power flow\n  solutions",
        "link": "http://arxiv.org/abs/2405.12219v1",
        "abstract": "Fair distribution of benefits in electric power systems is a pertinent energy\npolicymaking problem; however, these efforts cannot be easily quantified in\npower system engineering studies. Therefore, we propose locational marginal\nburden (LMB) to provide an interface between a well-studied measure of energy\npricing equity, energy burden, with an optimal power flow problem (OPF). This\nis achieved by investigating the intrinsic link between the dual optimal\nsolution of an OPF problem and the electricity prices, which are used to\ncalculate the energy burden. By applying results from the field of\ndifferentiable optimization, locational marginal prices (LMPs) associated with\nan OPF solution can be differentiated with respect to demand. This enables\nelectricity retail prices, and thereby, energy burden itself, to be\ndifferentiated, resulting in the proposed LMB. Simulation of a synthetic Hawaii\nnetwork interfaced with real-world socioeconomic data shows how the LMB\nprovides new insights into how the operation of the electricity network affects\nthe equity of energy prices.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Samuel Talkington",
            "Amanda West",
            "Rabab Haider"
        ],
        "published": "2024-05-20T17:59:45Z"
    },
    {
        "title": "Fast Generalizable Gaussian Splatting Reconstruction from Multi-View\n  Stereo",
        "link": "http://arxiv.org/abs/2405.12218v1",
        "abstract": "We present MVSGaussian, a new generalizable 3D Gaussian representation\napproach derived from Multi-View Stereo (MVS) that can efficiently reconstruct\nunseen scenes. Specifically, 1) we leverage MVS to encode geometry-aware\nGaussian representations and decode them into Gaussian parameters. 2) To\nfurther enhance performance, we propose a hybrid Gaussian rendering that\nintegrates an efficient volume rendering design for novel view synthesis. 3) To\nsupport fast fine-tuning for specific scenes, we introduce a multi-view\ngeometric consistent aggregation strategy to effectively aggregate the point\nclouds generated by the generalizable model, serving as the initialization for\nper-scene optimization. Compared with previous generalizable NeRF-based\nmethods, which typically require minutes of fine-tuning and seconds of\nrendering per image, MVSGaussian achieves real-time rendering with better\nsynthesis quality for each scene. Compared with the vanilla 3D-GS, MVSGaussian\nachieves better view synthesis with less training computational cost. Extensive\nexperiments on DTU, Real Forward-facing, NeRF Synthetic, and Tanks and Temples\ndatasets validate that MVSGaussian attains state-of-the-art performance with\nconvincing generalizability, real-time rendering speed, and fast per-scene\noptimization.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Tianqi Liu",
            "Guangcong Wang",
            "Shoukang Hu",
            "Liao Shen",
            "Xinyi Ye",
            "Yuhang Zang",
            "Zhiguo Cao",
            "Wei Li",
            "Ziwei Liu"
        ],
        "published": "2024-05-20T17:59:30Z"
    },
    {
        "title": "Adapting Large Multimodal Models to Distribution Shifts: The Role of\n  In-Context Learning",
        "link": "http://arxiv.org/abs/2405.12217v1",
        "abstract": "Recent studies indicate that large multimodal models (LMMs) are highly robust\nagainst natural distribution shifts, often surpassing previous baselines.\nDespite this, domain-specific adaptation is still necessary, particularly in\nspecialized areas like healthcare. Due to the impracticality of fine-tuning\nLMMs given their vast parameter space, this work investigates in-context\nlearning (ICL) as an effective alternative for enhancing LMMs' adaptability. We\nfind that the success of ICL heavily relies on the choice of demonstration,\nmirroring challenges seen in large language models but introducing unique\ncomplexities for LMMs facing distribution shifts. Our study addresses this by\nevaluating an unsupervised ICL method, TopKNearestPR, which selects in-context\nexamples through a nearest example search based on feature similarity. We\nuncover that its effectiveness is limited by the deficiencies of pre-trained\nvision encoders under distribution shift scenarios. To address these\nchallenges, we propose InvariantSelectPR, a novel method leveraging\nClass-conditioned Contrastive Invariance (CCI) for more robust demonstration\nselection. Specifically, CCI enhances pre-trained vision encoders by improving\ntheir discriminative capabilities across different classes and ensuring\ninvariance to domain-specific variations. This enhancement allows the encoders\nto effectively identify and retrieve the most informative examples, which are\nthen used to guide LMMs in adapting to new query samples under varying\ndistributions. Our experiments show that InvariantSelectPR substantially\nimproves the adaptability of LMMs, achieving significant performance gains on\nbenchmark datasets, with a 34.2%$\\uparrow$ accuracy increase in 7-shot on\nCamelyon17 and 16.9%$\\uparrow$ increase in 7-shot on HAM10000 compared to the\nbaseline zero-shot performance.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Guanglin Zhou",
            "Zhongyi Han",
            "Shiming Chen",
            "Biwei Huang",
            "Liming Zhu",
            "Salman Khan",
            "Xin Gao",
            "Lina Yao"
        ],
        "published": "2024-05-20T17:59:21Z"
    },
    {
        "title": "Octo: An Open-Source Generalist Robot Policy",
        "link": "http://arxiv.org/abs/2405.12213v1",
        "abstract": "Large policies pretrained on diverse robot datasets have the potential to\ntransform robotic learning: instead of training new policies from scratch, such\ngeneralist robot policies may be finetuned with only a little in-domain data,\nyet generalize broadly. However, to be widely applicable across a range of\nrobotic learning scenarios, environments, and tasks, such policies need to\nhandle diverse sensors and action spaces, accommodate a variety of commonly\nused robotic platforms, and finetune readily and efficiently to new domains. In\nthis work, we aim to lay the groundwork for developing open-source, widely\napplicable, generalist policies for robotic manipulation. As a first step, we\nintroduce Octo, a large transformer-based policy trained on 800k trajectories\nfrom the Open X-Embodiment dataset, the largest robot manipulation dataset to\ndate. It can be instructed via language commands or goal images and can be\neffectively finetuned to robot setups with new sensory inputs and action spaces\nwithin a few hours on standard consumer GPUs. In experiments across 9 robotic\nplatforms, we demonstrate that Octo serves as a versatile policy initialization\nthat can be effectively finetuned to new observation and action spaces. We also\nperform detailed ablations of design decisions for the Octo model, from\narchitecture to training data, to guide future research on building generalist\nrobot models.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "authors": [
            " Octo Model Team",
            "Dibya Ghosh",
            "Homer Walke",
            "Karl Pertsch",
            "Kevin Black",
            "Oier Mees",
            "Sudeep Dasari",
            "Joey Hejna",
            "Tobias Kreiman",
            "Charles Xu",
            "Jianlan Luo",
            "You Liang Tan",
            "Pannag Sanketi",
            "Quan Vuong",
            "Ted Xiao",
            "Dorsa Sadigh",
            "Chelsea Finn",
            "Sergey Levine"
        ],
        "published": "2024-05-20T17:57:01Z"
    },
    {
        "title": "Slicedit: Zero-Shot Video Editing With Text-to-Image Diffusion Models\n  Using Spatio-Temporal Slices",
        "link": "http://arxiv.org/abs/2405.12211v1",
        "abstract": "Text-to-image (T2I) diffusion models achieve state-of-the-art results in\nimage synthesis and editing. However, leveraging such pretrained models for\nvideo editing is considered a major challenge. Many existing works attempt to\nenforce temporal consistency in the edited video through explicit\ncorrespondence mechanisms, either in pixel space or between deep features.\nThese methods, however, struggle with strong nonrigid motion. In this paper, we\nintroduce a fundamentally different approach, which is based on the observation\nthat spatiotemporal slices of natural videos exhibit similar characteristics to\nnatural images. Thus, the same T2I diffusion model that is normally used only\nas a prior on video frames, can also serve as a strong prior for enhancing\ntemporal consistency by applying it on spatiotemporal slices. Based on this\nobservation, we present Slicedit, a method for text-based video editing that\nutilizes a pretrained T2I diffusion model to process both spatial and\nspatiotemporal slices. Our method generates videos that retain the structure\nand motion of the original video while adhering to the target text. Through\nextensive experiments, we demonstrate Slicedit's ability to edit a wide range\nof real-world videos, confirming its clear advantages compared to existing\ncompeting methods. Webpage: https://matankleiner.github.io/slicedit/",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Nathaniel Cohen",
            "Vladimir Kulikov",
            "Matan Kleiner",
            "Inbar Huberman-Spiegelglas",
            "Tomer Michaeli"
        ],
        "published": "2024-05-20T17:55:56Z"
    },
    {
        "title": "EGAN: Evolutional GAN for Ransomware Evasion",
        "link": "http://dx.doi.org/10.1109/LCN58197.2023.10223320",
        "abstract": "Adversarial Training is a proven defense strategy against adversarial\nmalware. However, generating adversarial malware samples for this type of\ntraining presents a challenge because the resulting adversarial malware needs\nto remain evasive and functional. This work proposes an attack framework, EGAN,\nto address this limitation. EGAN leverages an Evolution Strategy and Generative\nAdversarial Network to select a sequence of attack actions that can mutate a\nRansomware file while preserving its original functionality. We tested this\nframework on popular AI-powered commercial antivirus systems listed on\nVirusTotal and demonstrated that our framework is capable of bypassing the\nmajority of these systems. Moreover, we evaluated whether the EGAN attack\nframework can evade other commercial non-AI antivirus solutions. Our results\nindicate that the adversarial ransomware generated can increase the probability\nof evading some of them.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Daniel Commey",
            "Benjamin Appiah",
            "Bill K. Frimpong",
            "Isaac Osei",
            "Ebenezer N. A. Hammond",
            "Garth V. Crosby"
        ],
        "published": "2024-05-20T17:52:40Z"
    },
    {
        "title": "MathBench: Evaluating the Theory and Application Proficiency of LLMs\n  with a Hierarchical Mathematics Benchmark",
        "link": "http://arxiv.org/abs/2405.12209v1",
        "abstract": "Recent advancements in large language models (LLMs) have showcased\nsignificant improvements in mathematics. However, traditional math benchmarks\nlike GSM8k offer a unidimensional perspective, falling short in providing a\nholistic assessment of the LLMs' math capabilities. To address this gap, we\nintroduce MathBench, a new benchmark that rigorously assesses the mathematical\ncapabilities of large language models. MathBench spans a wide range of\nmathematical disciplines, offering a detailed evaluation of both theoretical\nunderstanding and practical problem-solving skills. The benchmark progresses\nthrough five distinct stages, from basic arithmetic to college mathematics, and\nis structured to evaluate models at various depths of knowledge. Each stage\nincludes theoretical questions and application problems, allowing us to measure\na model's mathematical proficiency and its ability to apply concepts in\npractical scenarios. MathBench aims to enhance the evaluation of LLMs'\nmathematical abilities, providing a nuanced view of their knowledge\nunderstanding levels and problem solving skills in a bilingual context. The\nproject is released at https://github.com/open-compass/MathBench .",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Hongwei Liu",
            "Zilong Zheng",
            "Yuxuan Qiao",
            "Haodong Duan",
            "Zhiwei Fei",
            "Fengzhe Zhou",
            "Wenwei Zhang",
            "Songyang Zhang",
            "Dahua Lin",
            "Kai Chen"
        ],
        "published": "2024-05-20T17:52:29Z"
    },
    {
        "title": "Optimistic Query Routing in Clustering-based Approximate Maximum Inner\n  Product Search",
        "link": "http://arxiv.org/abs/2405.12207v1",
        "abstract": "Clustering-based nearest neighbor search is a simple yet effective method in\nwhich data points are partitioned into geometric shards to form an index, and\nonly a few shards are searched during query processing to find an approximate\nset of top-$k$ vectors. Even though the search efficacy is heavily influenced\nby the algorithm that identifies the set of shards to probe, it has received\nlittle attention in the literature. This work attempts to bridge that gap by\nstudying the problem of routing in clustering-based maximum inner product\nsearch (MIPS). We begin by unpacking existing routing protocols and notice the\nsurprising contribution of optimism. We then take a page from the sequential\ndecision making literature and formalize that insight following the principle\nof ``optimism in the face of uncertainty.'' In particular, we present a new\nframework that incorporates the moments of the distribution of inner products\nwithin each shard to optimistically estimate the maximum inner product. We then\npresent a simple instance of our algorithm that uses only the first two moments\nto reach the same accuracy as state-of-the-art routers such as \\scann by\nprobing up to $50%$ fewer points on a suite of benchmark MIPS datasets. Our\nalgorithm is also space-efficient: we design a sketch of the second moment\nwhose size is independent of the number of points and in practice requires\nstoring only $O(1)$ additional vectors per shard.",
        "subjects": [
            "cs.LG",
            "cs.IR"
        ],
        "authors": [
            "Sebastian Bruch",
            "Aditya Krishnan",
            "Franco Maria Nardini"
        ],
        "published": "2024-05-20T17:47:18Z"
    },
    {
        "title": "Modeling citation worthiness by using attention-based bidirectional long\n  short-term memory networks and interpretable models",
        "link": "http://dx.doi.org/10.1007/s11192-020-03421-9",
        "abstract": "Scientist learn early on how to cite scientific sources to support their\nclaims. Sometimes, however, scientists have challenges determining where a\ncitation should be situated -- or, even worse, fail to cite a source\naltogether. Automatically detecting sentences that need a citation (i.e.,\ncitation worthiness) could solve both of these issues, leading to more robust\nand well-constructed scientific arguments. Previous researchers have applied\nmachine learning to this task but have used small datasets and models that do\nnot take advantage of recent algorithmic developments such as attention\nmechanisms in deep learning. We hypothesize that we can develop significantly\naccurate deep learning architectures that learn from large supervised datasets\nconstructed from open access publications. In this work, we propose a\nBidirectional Long Short-Term Memory (BiLSTM) network with attention mechanism\nand contextual information to detect sentences that need citations. We also\nproduce a new, large dataset (PMOA-CITE) based on PubMed Open Access Subset,\nwhich is orders of magnitude larger than previous datasets. Our experiments\nshow that our architecture achieves state of the art performance on the\nstandard ACL-ARC dataset ($F_{1}=0.507$) and exhibits high performance\n($F_{1}=0.856$) on the new PMOA-CITE. Moreover, we show that it can transfer\nlearning across these datasets. We further use interpretable models to\nilluminate how specific language is used to promote and inhibit citations. We\ndiscover that sections and surrounding sentences are crucial for our improved\npredictions. We further examined purported mispredictions of the model, and\nuncovered systematic human mistakes in citation behavior and source data. This\nopens the door for our model to check documents during pre-submission and\npre-archival procedures. We make this new dataset, the code, and a web-based\ntool available to the community.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Tong Zeng",
            "Daniel E. Acuna"
        ],
        "published": "2024-05-20T17:45:36Z"
    },
    {
        "title": "Metacognitive Capabilities of LLMs: An Exploration in Mathematical\n  Problem Solving",
        "link": "http://arxiv.org/abs/2405.12205v1",
        "abstract": "Metacognitive knowledge refers to humans' intuitive knowledge of their own\nthinking and reasoning processes. Today's best LLMs clearly possess some\nreasoning processes. The paper gives evidence that they also have metacognitive\nknowledge, including ability to name skills and procedures to apply given a\ntask. We explore this primarily in context of math reasoning, developing a\nprompt-guided interaction procedure to get a powerful LLM to assign sensible\nskill labels to math questions, followed by having it perform semantic\nclustering to obtain coarser families of skill labels. These coarse skill\nlabels look interpretable to humans.\n  To validate that these skill labels are meaningful and relevant to the LLM's\nreasoning processes we perform the following experiments. (a) We ask GPT-4 to\nassign skill labels to training questions in math datasets GSM8K and MATH. (b)\nWhen using an LLM to solve the test questions, we present it with the full list\nof skill labels and ask it to identify the skill needed. Then it is presented\nwith randomly selected exemplar solved questions associated with that skill\nlabel. This improves accuracy on GSM8k and MATH for several strong LLMs,\nincluding code-assisted models. The methodology presented is domain-agnostic,\neven though this article applies it to math problems.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Aniket Didolkar",
            "Anirudh Goyal",
            "Nan Rosemary Ke",
            "Siyuan Guo",
            "Michal Valko",
            "Timothy Lillicrap",
            "Danilo Rezende",
            "Yoshua Bengio",
            "Michael Mozer",
            "Sanjeev Arora"
        ],
        "published": "2024-05-20T17:45:26Z"
    },
    {
        "title": "Accelerating Relative Entropy Coding with Space Partitioning",
        "link": "http://arxiv.org/abs/2405.12203v2",
        "abstract": "Relative entropy coding (REC) algorithms encode a random sample following a\ntarget distribution $Q$, using a coding distribution $P$ shared between the\nsender and receiver. Sadly, general REC algorithms suffer from prohibitive\nencoding times, at least on the order of $2^{D_{\\text{KL}}[Q||P]}$, and faster\nalgorithms are limited to very specific settings. This work addresses this\nissue by introducing a REC scheme utilizing space partitioning to reduce\nruntime in practical scenarios. We provide theoretical analyses of our method\nand demonstrate its effectiveness with both toy examples and practical\napplications. Notably, our method successfully handles REC tasks with\n$D_{\\text{KL}}[Q||P]$ about three times greater than what previous methods can\nmanage, and reduces the bitrate by approximately 5-15% in VAE-based lossless\ncompression on MNIST and INR-based lossy compression on CIFAR-10, compared to\nprevious methods, significantly improving the practicality of REC for neural\ncompression.",
        "subjects": [
            "cs.IT",
            "cs.LG",
            "math.IT"
        ],
        "authors": [
            "Jiajun He",
            "Gergely Flamich",
            "José Miguel Hernández-Lobato"
        ],
        "published": "2024-05-20T17:41:19Z"
    },
    {
        "title": "Hierarchical Neural Operator Transformer with Learnable Frequency-aware\n  Loss Prior for Arbitrary-scale Super-resolution",
        "link": "http://arxiv.org/abs/2405.12202v1",
        "abstract": "In this work, we present an arbitrary-scale super-resolution (SR) method to\nenhance the resolution of scientific data, which often involves complex\nchallenges such as continuity, multi-scale physics, and the intricacies of\nhigh-frequency signals. Grounded in operator learning, the proposed method is\nresolution-invariant. The core of our model is a hierarchical neural operator\nthat leverages a Galerkin-type self-attention mechanism, enabling efficient\nlearning of mappings between function spaces. Sinc filters are used to\nfacilitate the information transfer across different levels in the hierarchy,\nthereby ensuring representation equivalence in the proposed neural operator.\nAdditionally, we introduce a learnable prior structure that is derived from the\nspectral resizing of the input data. This loss prior is model-agnostic and is\ndesigned to dynamically adjust the weighting of pixel contributions, thereby\nbalancing gradients effectively across the model. We conduct extensive\nexperiments on diverse datasets from different domains and demonstrate\nconsistent improvements compared to strong baselines, which consist of various\nstate-of-the-art SR methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Xihaier Luo",
            "Xiaoning Qian",
            "Byung-Jun Yoon"
        ],
        "published": "2024-05-20T17:39:29Z"
    },
    {
        "title": "Multi-View Attentive Contextualization for Multi-View 3D Object\n  Detection",
        "link": "http://arxiv.org/abs/2405.12200v1",
        "abstract": "We present Multi-View Attentive Contextualization (MvACon), a simple yet\neffective method for improving 2D-to-3D feature lifting in query-based\nmulti-view 3D (MV3D) object detection. Despite remarkable progress witnessed in\nthe field of query-based MV3D object detection, prior art often suffers from\neither the lack of exploiting high-resolution 2D features in dense\nattention-based lifting, due to high computational costs, or from\ninsufficiently dense grounding of 3D queries to multi-scale 2D features in\nsparse attention-based lifting. Our proposed MvACon hits the two birds with one\nstone using a representationally dense yet computationally sparse attentive\nfeature contextualization scheme that is agnostic to specific 2D-to-3D feature\nlifting approaches. In experiments, the proposed MvACon is thoroughly tested on\nthe nuScenes benchmark, using both the BEVFormer and its recent 3D deformable\nattention (DFA3D) variant, as well as the PETR, showing consistent detection\nperformance improvement, especially in enhancing performance in location,\norientation, and velocity prediction. It is also tested on the Waymo-mini\nbenchmark using BEVFormer with similar improvement. We qualitatively and\nquantitatively show that global cluster-based contexts effectively encode dense\nscene-level contexts for MV3D object detection. The promising results of our\nproposed MvACon reinforces the adage in computer vision -- ``(contextualized)\nfeature matters\".",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xianpeng Liu",
            "Ce Zheng",
            "Ming Qian",
            "Nan Xue",
            "Chen Chen",
            "Zhebin Zhang",
            "Chen Li",
            "Tianfu Wu"
        ],
        "published": "2024-05-20T17:37:10Z"
    },
    {
        "title": "Automated Hardware Logic Obfuscation Framework Using GPT",
        "link": "http://arxiv.org/abs/2405.12197v1",
        "abstract": "Obfuscation stands as a promising solution for safeguarding hardware\nintellectual property (IP) against a spectrum of threats including reverse\nengineering, IP piracy, and tampering. In this paper, we introduce Obfus-chat,\na novel framework leveraging Generative Pre-trained Transformer (GPT) models to\nautomate the obfuscation process. The proposed framework accepts hardware\ndesign netlists and key sizes as inputs, and autonomously generates obfuscated\ncode tailored to enhance security. To evaluate the effectiveness of our\napproach, we employ the Trust-Hub Obfuscation Benchmark for comparative\nanalysis. We employed SAT attacks to assess the security of the design, along\nwith functional verification procedures to ensure that the obfuscated design\nremains consistent with the original. Our results demonstrate the efficacy and\nefficiency of the proposed framework in fortifying hardware IP against\npotential threats, thus providing a valuable contribution to the field of\nhardware security.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Banafsheh Saber Latibari",
            "Sujan Ghimire",
            "Muhtasim Alam Chowdhury",
            "Najmeh Nazari",
            "Kevin Immanuel Gubbi",
            "Houman Homayoun",
            "Avesta Sasan",
            "Soheil Salehi"
        ],
        "published": "2024-05-20T17:33:00Z"
    },
    {
        "title": "Developers' Perceptions on the Impact of ChatGPT in Software\n  Development: A Survey",
        "link": "http://arxiv.org/abs/2405.12195v1",
        "abstract": "As Large Language Models (LLMs), including ChatGPT and analogous systems,\ncontinue to advance, their robust natural language processing capabilities and\ndiverse applications have garnered considerable attention. Nonetheless, despite\nthe increasing acknowledgment of the convergence of Artificial Intelligence\n(AI) and Software Engineering (SE), there is a lack of studies involving the\nimpact of this convergence on the practices and perceptions of software\ndevelopers. Understanding how software developers perceive and engage with AI\ntools, such as ChatGPT, is essential for elucidating the impact and potential\nchallenges of incorporating AI-driven tools in the software development\nprocess. In this paper, we conducted a survey with 207 software developers to\nunderstand the impact of ChatGPT on software quality, productivity, and job\nsatisfaction. Furthermore, the study delves into developers' expectations\nregarding future adaptations of ChatGPT, concerns about potential job\ndisplacement, and perspectives on regulatory interventions.",
        "subjects": [
            "cs.SE",
            "D.2.0"
        ],
        "authors": [
            "Thiago S. Vaillant",
            "Felipe Deveza de Almeida",
            "Paulo Anselmo M. S. Neto",
            "Cuiyun Gao",
            "Jan Bosch",
            "Eduardo Santana de Almeida"
        ],
        "published": "2024-05-20T17:31:16Z"
    },
    {
        "title": "The Narrow Depth and Breadth of Corporate Responsible AI Research",
        "link": "http://arxiv.org/abs/2405.12193v1",
        "abstract": "The transformative potential of AI presents remarkable opportunities, but\nalso significant risks, underscoring the importance of responsible AI\ndevelopment and deployment. Despite a growing emphasis on this area, there is\nlimited understanding of industry's engagement in responsible AI research,\ni.e., the critical examination of AI's ethical, social, and legal dimensions.\nTo address this gap, we analyzed over 6 million peer-reviewed articles and 32\nmillion patent citations using multiple methods across five distinct datasets\nto quantify industry's engagement. Our findings reveal that the majority of AI\nfirms show limited or no engagement in this critical subfield of AI. We show a\nstark disparity between industry's dominant presence in conventional AI\nresearch and its limited engagement in responsible AI. Leading AI firms exhibit\nsignificantly lower output in responsible AI research compared to their\nconventional AI research and the contributions of leading academic\ninstitutions. Our linguistic analysis documents a narrower scope of responsible\nAI research within industry, with a lack of diversity in key topics addressed.\nOur large-scale patent citation analysis uncovers a pronounced disconnect\nbetween responsible AI research and the commercialization of AI technologies,\nsuggesting that industry patents rarely build upon insights generated by the\nresponsible AI literature. This gap highlights the potential for AI development\nto diverge from a socially optimal path, risking unintended consequences due to\ninsufficient consideration of ethical and societal implications. Our results\nhighlight the urgent need for industry to publicly engage in responsible AI\nresearch to absorb academic knowledge, cultivate public trust, and proactively\nmitigate AI-induced societal harms.",
        "subjects": [
            "cs.CY"
        ],
        "authors": [
            "Nur Ahmed",
            "Amit Das",
            "Kirsten Martin",
            "Kawshik Banerjee"
        ],
        "published": "2024-05-20T17:26:43Z"
    },
    {
        "title": "SEL-CIE: Knowledge-Guided Self-Supervised Learning Framework for CIE-XYZ\n  Reconstruction from Non-Linear sRGB Images",
        "link": "http://arxiv.org/abs/2405.12265v1",
        "abstract": "Modern cameras typically offer two types of image states: a minimally\nprocessed linear raw RGB image representing the raw sensor data, and a\nhighly-processed non-linear image state, such as the sRGB state. The CIE-XYZ\ncolor space is a device-independent linear space used as part of the camera\npipeline and can be helpful for computer vision tasks, such as image\ndeblurring, dehazing, and color recognition tasks in medical applications,\nwhere color accuracy is important. However, images are usually saved in\nnon-linear states, and achieving CIE-XYZ color images using conventional\nmethods is not always possible. To tackle this issue, classical methodologies\nhave been developed that focus on reversing the acquisition pipeline. More\nrecently, supervised learning has been employed, using paired CIE-XYZ and sRGB\nrepresentations of identical images. However, obtaining a large-scale dataset\nof CIE-XYZ and sRGB pairs can be challenging. To overcome this limitation and\nmitigate the reliance on large amounts of paired data, self-supervised learning\n(SSL) can be utilized as a substitute for relying solely on paired data. This\npaper proposes a framework for using SSL methods alongside paired data to\nreconstruct CIE-XYZ images and re-render sRGB images, outperforming existing\napproaches. The proposed framework is applied to the sRGB2XYZ dataset.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Shir Barzel",
            "Moshe Salhov",
            "Ofir Lindenbaum",
            "Amir Averbuch"
        ],
        "published": "2024-05-20T17:20:41Z"
    },
    {
        "title": "Brewer-Nash Scrutinised: Mechanised Checking of Policies featuring Write\n  Revocation",
        "link": "http://arxiv.org/abs/2405.12187v1",
        "abstract": "This paper revisits the Brewer-Nash security policy model inspired by ethical\nChinese Wall policies. We draw attention to the fact that write access can be\nrevoked in the Brewer-Nash model. The semantics of write access were\nunderspecified originally, leading to multiple interpretations for which we\nprovide a modern operational semantics. We go on to modernise the analysis of\ninformation flow in the Brewer-Nash model, by adopting a more precise\ndefinition adapted from Kessler. For our modernised reformulation, we provide\nfull mechanised coverage for all theorems proposed by Brewer & Nash. Most\ntheorems are established automatically using the tool {log} with the exception\nof a theorem regarding information flow, which combines a lemma in {log} with a\ntheorem mechanised in Coq. Having covered all theorems originally posed by\nBrewer-Nash, achieving modern precision and mechanisation, we propose this work\nas a step towards a methodology for automated checking of more complex security\npolicy models.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Alfredo Capozucca",
            "Maximiliano Cristiá",
            "Ross Horne",
            "Ricardo Katz"
        ],
        "published": "2024-05-20T17:18:26Z"
    },
    {
        "title": "Lockpicking LLMs: A Logit-Based Jailbreak Using Token-level Manipulation",
        "link": "http://arxiv.org/abs/2405.13068v1",
        "abstract": "Large language models (LLMs) have transformed the field of natural language\nprocessing, but they remain susceptible to jailbreaking attacks that exploit\ntheir capabilities to generate unintended and potentially harmful content.\nExisting token-level jailbreaking techniques, while effective, face scalability\nand efficiency challenges, especially as models undergo frequent updates and\nincorporate advanced defensive measures. In this paper, we introduce JailMine,\nan innovative token-level manipulation approach that addresses these\nlimitations effectively. JailMine employs an automated \"mining\" process to\nelicit malicious responses from LLMs by strategically selecting affirmative\noutputs and iteratively reducing the likelihood of rejection. Through rigorous\ntesting across multiple well-known LLMs and datasets, we demonstrate JailMine's\neffectiveness and efficiency, achieving a significant average reduction of 86%\nin time consumed while maintaining high success rates averaging 95%, even in\nthe face of evolving defensive strategies. Our work contributes to the ongoing\neffort to assess and mitigate the vulnerability of LLMs to jailbreaking\nattacks, underscoring the importance of continued vigilance and proactive\nmeasures to enhance the security and reliability of these powerful language\nmodels.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Yuxi Li",
            "Yi Liu",
            "Yuekang Li",
            "Ling Shi",
            "Gelei Deng",
            "Shengquan Chen",
            "Kailong Wang"
        ],
        "published": "2024-05-20T17:17:55Z"
    },
    {
        "title": "Training Data Attribution via Approximate Unrolled Differentiation",
        "link": "http://arxiv.org/abs/2405.12186v2",
        "abstract": "Many training data attribution (TDA) methods aim to estimate how a model's\nbehavior would change if one or more data points were removed from the training\nset. Methods based on implicit differentiation, such as influence functions,\ncan be made computationally efficient, but fail to account for\nunderspecification, the implicit bias of the optimization algorithm, or\nmulti-stage training pipelines. By contrast, methods based on unrolling address\nthese issues but face scalability challenges. In this work, we connect the\nimplicit-differentiation-based and unrolling-based approaches and combine their\nbenefits by introducing Source, an approximate unrolling-based TDA method that\nis computed using an influence-function-like formula. While being\ncomputationally efficient compared to unrolling-based approaches, Source is\nsuitable in cases where implicit-differentiation-based approaches struggle,\nsuch as in non-converged models and multi-stage training pipelines.\nEmpirically, Source outperforms existing TDA techniques in counterfactual\nprediction, especially in settings where implicit-differentiation-based\napproaches fall short.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Juhan Bae",
            "Wu Lin",
            "Jonathan Lorraine",
            "Roger Grosse"
        ],
        "published": "2024-05-20T17:17:44Z"
    },
    {
        "title": "Directed Metric Structures arising in Large Language Models",
        "link": "http://arxiv.org/abs/2405.12264v1",
        "abstract": "Large Language Models are transformer neural networks which are trained to\nproduce a probability distribution on the possible next words to given texts in\na corpus, in such a way that the most likely word predicted is the actual word\nin the training text. In this paper we find what is the mathematical structure\ndefined by such conditional probability distributions of text extensions.\nChanging the view point from probabilities to -log probabilities we observe\nthat the subtext order is completely encoded in a metric structure defined on\nthe space of texts $\\mathcal{L}$, by -log probabilities. We then construct a\nmetric polyhedron $P(\\mathcal{L})$ and an isometric embedding (called Yoneda\nembedding) of $\\mathcal{L}$ into $P(\\mathcal{L})$ such that texts map to\ngenerators of certain special extremal rays. We explain that $P(\\mathcal{L})$\nis a $(\\min,+)$ (tropical) linear span of these extremal ray generators. The\ngenerators also satisfy a system of $(\\min+)$ linear equations. We then show\nthat $P(\\mathcal{L})$ is compatible with adding more text and from this we\nderive an approximation of a text vector as a Boltzmann weighted linear\ncombination of the vectors for words in that text. We then prove a duality\ntheorem showing that texts extensions and text restrictions give isometric\npolyhedra (even though they look a priory very different). Moreover we prove\nthat $P(\\mathcal{L})$ is the lattice closure of (a version of) the so called,\nIsbell completion of $\\mathcal{L}$ which turns out to be the $(\\max,+)$ span of\nthe text extremal ray generators. All constructions have interpretations in\ncategory theory but we don't use category theory explicitly. The categorical\ninterpretations are briefly explained in an appendix. In the final appendix we\ndescribe how the syntax to semantics problem could fit in a general well known\nmathematical duality.",
        "subjects": [
            "cs.LG",
            "math.CT",
            "math.MG",
            "14T90, 18D20, 52B12, 51F99, 68T50"
        ],
        "authors": [
            "Stéphane Gaubert",
            "Yiannis Vlassopoulos"
        ],
        "published": "2024-05-20T17:16:27Z"
    },
    {
        "title": "Robust VAR Capability Curve of DER with Uncertain Renewable Generation",
        "link": "http://arxiv.org/abs/2405.12184v1",
        "abstract": "Active distribution system with high penetration of inverter based\ndistributed energy resources (DER) can be utilized for VAR-related ancillary\nservices. To utilize the DER flexibility, transmission system operator (TSO)\nmust be presented with the aggregated DER flexibility of distribution system.\nHowever, the uncertainty in renewable generation questions the credibility of\naggregated capability curve in practice. In this paper, we incorporate the\nuncertainty into aggregation process to develop a robust capability curve while\npreserving the real physics (unbalance and lossy nature) of distribution\nsystem. Statistical inference method is employed to quantify uncertainty in\nsolar generation and quantified uncertainty is integrated into a chance\nconstrained optimal power flow (OPF). It provides the grid operator with the\ndispatchable aggregated reactive power capability. The resulting capability\ncurve with the associated probability can be harnessed by the TSO for decision\nmaking for both planning and operation.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Aditya Shankar Kar",
            "Kiran Kumar Challa",
            "Alok Kumar Bharati",
            "Ankit Singhal",
            "Venkataramana Ajjarapu"
        ],
        "published": "2024-05-20T17:11:37Z"
    },
    {
        "title": "Multi-order Graph Clustering with Adaptive Node-level Weight Learning",
        "link": "http://arxiv.org/abs/2405.12183v1",
        "abstract": "Current graph clustering methods emphasize individual node and edge con\nnections, while ignoring higher-order organization at the level of motif. Re\ncently, higher-order graph clustering approaches have been designed by motif\nbased hypergraphs. However, these approaches often suffer from hypergraph\nfragmentation issue seriously, which degrades the clustering performance\ngreatly. Moreover, real-world graphs usually contain diverse motifs, with nodes\nparticipating in multiple motifs. A key challenge is how to achieve precise\nclustering results by integrating information from multiple motifs at the node\nlevel. In this paper, we propose a multi-order graph clustering model (MOGC) to\nintegrate multiple higher-order structures and edge connections at node level.\nMOGC employs an adaptive weight learning mechanism to au tomatically adjust the\ncontributions of different motifs for each node. This not only tackles\nhypergraph fragmentation issue but enhances clustering accuracy. MOGC is\nefficiently solved by an alternating minimization algo rithm. Experiments on\nseven real-world datasets illustrate the effectiveness of MOGC.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Ye Liu",
            "Xuelei Lin",
            "Yejia Chen",
            "Reynold Cheng"
        ],
        "published": "2024-05-20T17:09:58Z"
    },
    {
        "title": "Nearest Neighbors GParareal: Improving Scalability of Gaussian Processes\n  for Parallel-in-Time Solvers",
        "link": "http://arxiv.org/abs/2405.12182v1",
        "abstract": "With the advent of supercomputers, multi-processor environments and\nparallel-in-time (PinT) algorithms offer ways to solve initial value problems\nfor ordinary and partial differential equations (ODEs and PDEs) over long time\nintervals, a task often unfeasible with sequential solvers within realistic\ntime frames. A recent approach, GParareal, combines Gaussian Processes with\ntraditional PinT methodology (Parareal) to achieve faster parallel speed-ups.\nThe method is known to outperform Parareal for low-dimensional ODEs and a\nlimited number of computer cores. Here, we present Nearest Neighbors GParareal\n(nnGParareal), a novel data-enriched PinT integration algorithm. nnGParareal\nbuilds upon GParareal by improving its scalability properties for\nhigher-dimensional systems and increased processor count. Through data\nreduction, the model complexity is reduced from cubic to log-linear in the\nsample size, yielding a fast and automated procedure to integrate initial value\nproblems over long time intervals. First, we provide both an upper bound for\nthe error and theoretical details on the speed-up benefits. Then, we\nempirically illustrate the superior performance of nnGParareal, compared to\nGParareal and Parareal, on nine different systems with unique features (e.g.,\nstiff, chaotic, high-dimensional, or challenging-to-learn systems).",
        "subjects": [
            "stat.CO",
            "cs.DC",
            "cs.NA",
            "math.NA",
            "65M55, 65M22, 65L05, 50G15, 65Y05"
        ],
        "authors": [
            "Guglielmo Gattiglio",
            "Lyudmila Grigoryeva",
            "Massimiliano Tamborrino"
        ],
        "published": "2024-05-20T17:07:30Z"
    },
    {
        "title": "Building Temporal Kernels with Orthogonal Polynomials",
        "link": "http://arxiv.org/abs/2405.12179v2",
        "abstract": "We introduce a class of models named PLEIADES (PoLynomial Expansion In\nAdaptive Distributed Event-based Systems), which contains temporal convolution\nkernels generated from orthogonal polynomial basis functions. We focus on\ninterfacing these networks with event-based data to perform online\nspatiotemporal classification and detection with low latency. By virtue of\nusing structured temporal kernels and event-based data, we have the freedom to\nvary the sample rate of the data along with the discretization step-size of the\nnetwork without additional finetuning. We experimented with three event-based\nbenchmarks and obtained state-of-the-art results on all three by large margins\nwith significantly smaller memory and compute costs. We achieved: 1) 99.59%\naccuracy with 192K parameters on the DVS128 hand gesture recognition dataset\nand 100% with a small additional output filter; 2) 99.58% test accuracy with\n277K parameters on the AIS 2024 eye tracking challenge; and 3) 0.556 mAP with\n576k parameters on the PROPHESEE 1 Megapixel Automotive Detection Dataset.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Yan Ru Pei",
            "Olivier Coenen"
        ],
        "published": "2024-05-20T17:06:24Z"
    },
    {
        "title": "Establishing Trust in the Beyond-5G Core Network using Trusted Execution\n  Environments",
        "link": "http://arxiv.org/abs/2405.12177v1",
        "abstract": "The fifth generation (5G) of cellular networks starts a paradigm shift from\nthe traditional monolithic system design to a Service Based Architecture, that\nfits modern performance requirements and scales efficiently to new services.\nThis paradigm will be the foundation of future cellular core networks beyond\n5G. The new architecture splits network functionalities into smaller logical\nentities that can be disaggregated logically, physically, and geographically.\nThis affords interoperability between the mobile network operators and\ncommercial software and hardware vendors or cloud providers. By making use of\ncommodity services and products, this system construct inherits the\nvulnerabilities in those underlying technologies, thereby increasing its attack\nsurface and requiring a rigorous security analysis. In this work, we review the\nsecurity implications introduced in B5G networks, and the security mechanisms\nthat are supported by the 5G standard. We emphasize on the support of Zero\nTrust Architecture in 5G and its relevance in decentralized deployments. We\nrevisit the definition of trust in modern enterprise network operations and\nidentify important Zero Trust properties that are weakened by the nature of\ncloud deployments. To that end, we propose a vertical extension of Zero Trust,\nnamely, Zero Trust Execution, to model untrusted execution environments, and we\nprovide an analysis on how to establish trust in Beyond-5G network\narchitectures using Trusted Execution Environments. Our analysis shows how our\nmodel architecture handles the increased attack surface and reinforces the Zero\nTrust Architecture principles in the 5G Core, without any changes to the 5G\nstandard. Finally, we provide experimental results over a 5G testbed using\nOpen5GS and UERANSIM that demonstrate minimal performance overhead, and a\nmonetary cost evaluation.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Marinos Vomvas",
            "Norbert Ludant",
            "Guevara Noubir"
        ],
        "published": "2024-05-20T17:02:18Z"
    },
    {
        "title": "Enhancing Explainable AI: A Hybrid Approach Combining GradCAM and LRP\n  for CNN Interpretability",
        "link": "http://arxiv.org/abs/2405.12175v1",
        "abstract": "We present a new technique that explains the output of a CNN-based model\nusing a combination of GradCAM and LRP methods. Both of these methods produce\nvisual explanations by highlighting input regions that are important for\npredictions. In the new method, the explanation produced by GradCAM is first\nprocessed to remove noises. The processed output is then multiplied elementwise\nwith the output of LRP. Finally, a Gaussian blur is applied on the product. We\ncompared the proposed method with GradCAM and LRP on the metrics of\nFaithfulness, Robustness, Complexity, Localisation and Randomisation. It was\nobserved that this method performs better on Complexity than both GradCAM and\nLRP and is better than atleast one of them in the other metrics.",
        "subjects": [
            "cs.CV",
            "I.4.0; I.5.2"
        ],
        "authors": [
            "Vaibhav Dhore",
            "Achintya Bhat",
            "Viraj Nerlekar",
            "Kashyap Chavhan",
            "Aniket Umare"
        ],
        "published": "2024-05-20T16:58:24Z"
    },
    {
        "title": "CT-Eval: Benchmarking Chinese Text-to-Table Performance in Large\n  Language Models",
        "link": "http://arxiv.org/abs/2405.12174v1",
        "abstract": "Text-to-Table aims to generate structured tables to convey the key\ninformation from unstructured documents. Existing text-to-table datasets are\ntypically oriented English, limiting the research in non-English languages.\nMeanwhile, the emergence of large language models (LLMs) has shown great\nsuccess as general task solvers in multi-lingual settings (e.g., ChatGPT),\ntheoretically enabling text-to-table in other languages. In this paper, we\npropose a Chinese text-to-table dataset, CT-Eval, to benchmark LLMs on this\ntask. Our preliminary analysis of English text-to-table datasets highlights two\nkey factors for dataset construction: data diversity and data hallucination.\nInspired by this, the CT-Eval dataset selects a popular Chinese\nmultidisciplinary online encyclopedia as the source and covers 28 domains to\nensure data diversity. To minimize data hallucination, we first train an LLM to\njudge and filter out the task samples with hallucination, then employ human\nannotators to clean the hallucinations in the validation and testing sets.\nAfter this process, CT-Eval contains 88.6K task samples. Using CT-Eval, we\nevaluate the performance of open-source and closed-source LLMs. Our results\nreveal that zero-shot LLMs (including GPT-4) still have a significant\nperformance gap compared with human judgment. Furthermore, after fine-tuning,\nopen-source LLMs can significantly improve their text-to-table ability,\noutperforming GPT-4 by a large margin. In short, CT-Eval not only helps\nresearchers evaluate and quickly understand the Chinese text-to-table ability\nof existing LLMs but also serves as a valuable resource to significantly\nimprove the text-to-table performance of LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Haoxiang Shi",
            "Jiaan Wang",
            "Jiarong Xu",
            "Cen Wang",
            "Tetsuya Sakai"
        ],
        "published": "2024-05-20T16:58:02Z"
    },
    {
        "title": "State of the Practice for Medical Imaging Software",
        "link": "http://arxiv.org/abs/2405.12171v1",
        "abstract": "We selected 29 medical imaging projects from 48 candidates, assessed 10\nsoftware qualities by answering 108 questions for each software project, and\ninterviewed 8 of the 29 development teams. Based on the quantitative data, we\nranked the MI software with the Analytic Hierarchy Process (AHP). The four\ntop-ranked software products are 3D Slicer, ImageJ, Fiji, and OHIF Viewer.\nGenerally, MI software is in a healthy state as shown by the following: we\nobserved 88% of the documentation artifacts recommended by research software\ndevelopment guidelines, 100% of MI projects use version control tools, and\ndevelopers appear to use the common quasi-agile research software development\nprocess. However, the current state of the practice deviates from the existing\nguidelines because of the rarity of some recommended artifacts, low usage of\ncontinuous integration (17% of the projects), low use of unit testing (about\n50% of projects), and room for improvement with documentation (six of nine\ndevelopers felt their documentation was not clear enough). From interviewing\nthe developers, we identified five pain points and two qualities of potential\nconcern: lack of development time, lack of funding, technology hurdles,\nensuring correctness, usability, maintainability, and reproducibility. The\ninterviewees proposed strategies to improve the state of the practice, to\naddress the identified pain points, and to improve software quality. Combining\ntheir ideas with ours, we have the following list of recommendations: increase\ndocumentation, increase testing by enriching datasets, increase continuous\nintegration usage, move to web applications, employ linters, use peer reviews,\ndesign for change, add assurance cases, and incorporate a \"Generate All Things\"\napproach.",
        "subjects": [
            "cs.SE",
            "cs.CV",
            "D.2.7; I.4.0"
        ],
        "authors": [
            "W. Spencer Smith",
            "Ao Dong",
            "Jacques Carette",
            "Michael D. Noseworthy"
        ],
        "published": "2024-05-20T16:55:05Z"
    },
    {
        "title": "WiDRa -- Enabling Millimeter-Level Differential Ranging Accuracy in\n  Wi-Fi Using Carrier Phase",
        "link": "http://arxiv.org/abs/2405.12168v1",
        "abstract": "Although Wi-Fi is an ideal technology for many ranging applications, the\nperformance of current methods is limited by the system bandwidth, leading to\nlow accuracy of $\\sim 1$ m. For many applications, measuring differential\nrange, viz., the change in the range between adjacent measurements, is\nsufficient. Correspondingly, this work proposes WiDRa - a Wi-Fi based\nDifferential Ranging solution that provides differential range estimates by\nusing the sum-carrier-phase information. The proposed method is not limited by\nsystem bandwidth and can track range changes even smaller than the carrier\nwavelength. The proposed method is first theoretically justified, while taking\ninto consideration the various hardware impairments affecting Wi-Fi chips. In\nthe process, methods to isolate the sum-carrier phase from the hardware\nimpairments are proposed. Extensive simulation results show that WiDRa can\nachieve a differential range estimation root-mean-square-error (RMSE) of\n$\\approx 1$ mm in channels with a Rician-factor $\\geq 7$ (a $100 \\times$\nimprovement to existing methods). The proposed methods are also validated on\noff-the-shelf Wi-Fi hardware to demonstrate feasibility, where they achieve an\nRMSE of $< 1$ mm in the differential range. Finally, limitations of current\ninvestigation and future directions of exploration are suggested, to further\ntap into the potential of WiDRa.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Vishnu V. Ratnam",
            "Bilal Sadiq",
            "Hao Chen",
            "Wei Sun",
            "Shunyao Wu",
            "Boon L. Ng",
            " Jianzhong",
            " Zhang"
        ],
        "published": "2024-05-20T16:52:33Z"
    },
    {
        "title": "Open-Source Assessments of AI Capabilities: The Proliferation of AI\n  Analysis Tools, Replicating Competitor Models, and the Zhousidun Dataset",
        "link": "http://arxiv.org/abs/2405.12167v2",
        "abstract": "The integration of artificial intelligence (AI) into military capabilities\nhas become a norm for major military power across the globe. Understanding how\nthese AI models operate is essential for maintaining strategic advantages and\nensuring security. This paper demonstrates an open-source methodology for\nanalyzing military AI models through a detailed examination of the Zhousidun\ndataset, a Chinese-originated dataset that exhaustively labels critical\ncomponents on American and Allied destroyers. By demonstrating the replication\nof a state-of-the-art computer vision model on this dataset, we illustrate how\nopen-source tools can be leveraged to assess and understand key military AI\ncapabilities. This methodology offers a robust framework for evaluating the\nperformance and potential of AI-enabled military capabilities, thus enhancing\nthe accuracy and reliability of strategic assessments.",
        "subjects": [
            "cs.CY"
        ],
        "authors": [
            "Ritwik Gupta",
            "Leah Walker",
            "Eli Glickman",
            "Raine Koizumi",
            "Sarthak Bhatnagar",
            "Andrew W. Reddie"
        ],
        "published": "2024-05-20T16:51:25Z"
    },
    {
        "title": "Fennec: Fine-grained Language Model Evaluation and Correction Extended\n  through Branching and Bridging",
        "link": "http://arxiv.org/abs/2405.12163v1",
        "abstract": "The rapid advancement of large language models has given rise to a plethora\nof applications across a myriad of real-world tasks, mainly centered on\naligning with human intent. However, the complexities inherent in human intent\nnecessitate a dependence on labor-intensive and time-consuming human\nevaluation. To alleviate this constraint, we delve into the paradigm of\nemploying open-source large language models as evaluators, aligning with the\nprevailing trend of utilizing GPT-4. Particularly, we present a step-by-step\nevaluation framework: \\textbf{Fennec}, capable of \\textbf{F}ine-grained\n\\textbf{E}valuatio\\textbf{N} and correctio\\textbf{N} \\textbf{E}xtended through\nbran\\textbf{C}hing and bridging. Specifically, the branching operation dissects\nthe evaluation task into various dimensions and granularities, thereby\nalleviating the challenges associated with evaluation. Concurrently, the\nbridging operation amalgamates diverse training datasets, augmenting the\nvariety of evaluation tasks. In experimental trials, our 7B model consistently\noutperforms open-source larger-scale evaluation models across various widely\nadopted benchmarks in terms of both \\textit{Agreement} and\n\\textit{Consistency}, closely approaching the capabilities of GPT-4. We employ\nthe fine-grained correction capabilities induced by the evaluation model to\nrefine multiple model responses, and the results show that the refinement\nelevates the quality of responses, leading to an improvement of 1-2 points on\nthe MT-Bench. Our code is available at\nGithub\\footnote{\\url{https://github.com/dropreg/Fennec}}.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Xiaobo Liang",
            "Haoke Zhang",
            "Helan hu",
            "Juntao Li",
            "Jun Xu",
            "Min Zhang"
        ],
        "published": "2024-05-20T16:47:22Z"
    },
    {
        "title": "Embracing Radiance Field Rendering in 6G: Over-the-Air Training and\n  Inference with 3D Contents",
        "link": "http://arxiv.org/abs/2405.12155v1",
        "abstract": "The efficient representation, transmission, and reconstruction of\nthree-dimensional (3D) contents are becoming increasingly important for\nsixth-generation (6G) networks that aim to merge virtual and physical worlds\nfor offering immersive communication experiences. Neural radiance field (NeRF)\nand 3D Gaussian splatting (3D-GS) have recently emerged as two promising 3D\nrepresentation techniques based on radiance field rendering, which are able to\nprovide photorealistic rendering results for complex scenes. Therefore,\nembracing NeRF and 3D-GS in 6G networks is envisioned to be a prominent\nsolution to support emerging 3D applications with enhanced quality of\nexperience. This paper provides a comprehensive overview on the integration of\nNeRF and 3D-GS in 6G. First, we review the basics of the radiance field\nrendering techniques, and highlight their applications and implementation\nchallenges over wireless networks. Next, we consider the over-the-air training\nof NeRF and 3D-GS models over wireless networks by presenting various learning\ntechniques. We particularly focus on the federated learning design over a\nhierarchical device-edge-cloud architecture. Then, we discuss three practical\nrendering architectures of NeRF and 3D-GS models at wireless network edge. We\nprovide model compression approaches to facilitate the transmission of radiance\nfield models, and present rendering acceleration approaches and joint\ncomputation and communication designs to enhance the rendering efficiency. In\nparticular, we propose a new semantic communication enabled 3D content\ntransmission design, in which the radiance field models are exploited as the\nsemantic knowledge base to reduce the communication overhead for distributed\ninference. Furthermore, we present the utilization of radiance field rendering\nin wireless applications like radio mapping and radio imaging.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Guanlin Wu",
            "Zhonghao Lyu",
            "Juyong Zhang",
            "Jie Xu"
        ],
        "published": "2024-05-20T16:32:37Z"
    },
    {
        "title": "A Nearly Quadratic Improvement for Memory Reallocation",
        "link": "http://arxiv.org/abs/2405.12152v1",
        "abstract": "In the Memory Reallocation Problem a set of items of various sizes must be\ndynamically assigned to non-overlapping contiguous chunks of memory. It is\nguaranteed that the sum of the sizes of all items present at any time is at\nmost a $(1-\\varepsilon)$-fraction of the total size of memory (i.e., the\nload-factor is at most $1-\\varepsilon$). The allocator receives insert and\ndelete requests online, and can re-arrange existing items to handle the\nrequests, but at a reallocation cost defined to be the sum of the sizes of\nitems moved divided by the size of the item being inserted/deleted.\n  The folklore algorithm for Memory Reallocation achieves a cost of\n$O(\\varepsilon^{-1})$ per update. In recent work at FOCS'23, Kuszmaul showed\nthat, in the special case where each item is promised to be smaller than an\n$\\varepsilon^4$-fraction of memory, it is possible to achieve expected update\ncost $O(\\log\\varepsilon^{-1})$. Kuszmaul conjectures, however, that for larger\nitems the folklore algorithm is optimal.\n  In this work we disprove Kuszmaul's conjecture, giving an allocator that\nachieves expected update cost $O(\\varepsilon^{-1/2} \\operatorname*{polylog}\n\\varepsilon^{-1})$ on any input sequence. We also give the first non-trivial\nlower bound for the Memory Reallocation Problem: we demonstrate an input\nsequence on which any resizable allocator (even offline) must incur amortized\nupdate cost at least $\\Omega(\\log\\varepsilon^{-1})$.\n  Finally, we analyze the Memory Reallocation Problem on a stochastic sequence\nof inserts and deletes, with random sizes in $[\\delta, 2 \\delta]$ for some\n$\\delta$. We show that, in this simplified setting, it is possible to achieve\n$O(\\log\\varepsilon^{-1})$ expected update cost, even in the ``large item''\nparameter regime ($\\delta > \\varepsilon^4$).",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Martin Farach-Colton",
            "William Kuszmaul",
            "Nathan Sheffield",
            "Alek Westover"
        ],
        "published": "2024-05-20T16:27:25Z"
    },
    {
        "title": "Bangladeshi Native Vehicle Detection in Wild",
        "link": "http://arxiv.org/abs/2405.12150v1",
        "abstract": "The success of autonomous navigation relies on robust and precise vehicle\nrecognition, hindered by the scarcity of region-specific vehicle detection\ndatasets, impeding the development of context-aware systems. To advance\nterrestrial object detection research, this paper proposes a native vehicle\ndetection dataset for the most commonly appeared vehicle classes in Bangladesh.\n17 distinct vehicle classes have been taken into account, with fully annotated\n81542 instances of 17326 images. Each image width is set to at least 1280px.\nThe dataset's average vehicle bounding box-to-image ratio is 4.7036. This\nBangladesh Native Vehicle Dataset (BNVD) has accounted for several\ngeographical, illumination, variety of vehicle sizes, and orientations to be\nmore robust on surprised scenarios. In the context of examining the BNVD\ndataset, this work provides a thorough assessment with four successive You Only\nLook Once (YOLO) models, namely YOLO v5, v6, v7, and v8. These dataset's\neffectiveness is methodically evaluated and contrasted with other vehicle\ndatasets already in use. The BNVD dataset exhibits mean average precision(mAP)\nat 50% intersection over union (IoU) is 0.848 corresponding precision and\nrecall values of 0.841 and 0.774. The research findings indicate a mAP of 0.643\nat an IoU range of 0.5 to 0.95. The experiments show that the BNVD dataset\nserves as a reliable representation of vehicle distribution and presents\nconsiderable complexities.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ],
        "authors": [
            "Bipin Saha",
            "Md. Johirul Islam",
            "Shaikh Khaled Mostaque",
            "Aditya Bhowmik",
            "Tapodhir Karmakar Taton",
            "Md. Nakib Hayat Chowdhury",
            "Mamun Bin Ibne Reaz"
        ],
        "published": "2024-05-20T16:23:40Z"
    },
    {
        "title": "Eliciting Problem Specifications via Large Language Models",
        "link": "http://arxiv.org/abs/2405.12147v1",
        "abstract": "Cognitive systems generally require a human to translate a problem definition\ninto some specification that the cognitive system can use to attempt to solve\nthe problem or perform the task. In this paper, we illustrate that large\nlanguage models (LLMs) can be utilized to map a problem class, defined in\nnatural language, into a semi-formal specification that can then be utilized by\nan existing reasoning and learning system to solve instances from the problem\nclass. We present the design of LLM-enabled cognitive task analyst agent(s).\nImplemented with LLM agents, this system produces a definition of problem\nspaces for tasks specified in natural language. LLM prompts are derived from\nthe definition of problem spaces in the AI literature and general\nproblem-solving strategies (Polya's How to Solve It). A cognitive system can\nthen use the problem-space specification, applying domain-general problem\nsolving strategies (\"weak methods\" such as search), to solve multiple instances\nof problems from the problem class. This result, while preliminary, suggests\nthe potential for speeding cognitive systems research via disintermediation of\nproblem formulation while also retaining core capabilities of cognitive\nsystems, such as robust inference and online learning.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "I.2.11; I.2.7"
        ],
        "authors": [
            "Robert E. Wray",
            "James R. Kirk",
            "John E. Laird"
        ],
        "published": "2024-05-20T16:19:02Z"
    },
    {
        "title": "Practical Performance of a Distributed Processing Framework for\n  Machine-Learning-based NIDS",
        "link": "http://arxiv.org/abs/2405.13066v1",
        "abstract": "Network Intrusion Detection Systems (NIDSs) detect intrusion attacks in\nnetwork traffic. In particular, machine-learning-based NIDSs have attracted\nattention because of their high detection rates of unknown attacks. A\ndistributed processing framework for machine-learning-based NIDSs employing a\nscalable distributed stream processing system has been proposed in the\nliterature. However, its performance, when machine-learning-based classifiers\nare implemented has not been comprehensively evaluated. In this study, we\nimplement five representative classifiers (Decision Tree, Random Forest, Naive\nBayes, SVM, and kNN) based on this framework and evaluate their throughput and\nlatency. By conducting the experimental measurements, we investigate the\ndifference in the processing performance among these classifiers and the\nbottlenecks in the processing performance of the framework.",
        "subjects": [
            "cs.CR",
            "cs.DC",
            "cs.LG",
            "cs.NI"
        ],
        "authors": [
            "Maho Kajiura",
            "Junya Nakamura"
        ],
        "published": "2024-05-20T16:14:39Z"
    },
    {
        "title": "DTLLM-VLT: Diverse Text Generation for Visual Language Tracking Based on\n  LLM",
        "link": "http://arxiv.org/abs/2405.12139v1",
        "abstract": "Visual Language Tracking (VLT) enhances single object tracking (SOT) by\nintegrating natural language descriptions from a video, for the precise\ntracking of a specified object. By leveraging high-level semantic information,\nVLT guides object tracking, alleviating the constraints associated with relying\non a visual modality. Nevertheless, most VLT benchmarks are annotated in a\nsingle granularity and lack a coherent semantic framework to provide scientific\nguidance. Moreover, coordinating human annotators for high-quality annotations\nis laborious and time-consuming. To address these challenges, we introduce\nDTLLM-VLT, which automatically generates extensive and multi-granularity text\nto enhance environmental diversity. (1) DTLLM-VLT generates scientific and\nmulti-granularity text descriptions using a cohesive prompt framework. Its\nsuccinct and highly adaptable design allows seamless integration into various\nvisual tracking benchmarks. (2) We select three prominent benchmarks to deploy\nour approach: short-term tracking, long-term tracking, and global instance\ntracking. We offer four granularity combinations for these benchmarks,\nconsidering the extent and density of semantic information, thereby showcasing\nthe practicality and versatility of DTLLM-VLT. (3) We conduct comparative\nexperiments on VLT benchmarks with different text granularities, evaluating and\nanalyzing the impact of diverse text on tracking performance. Conclusionally,\nthis work leverages LLM to provide multi-granularity semantic information for\nVLT task from efficient and diverse perspectives, enabling fine-grained\nevaluation of multi-modal trackers. In the future, we believe this work can be\nextended to more datasets to support vision datasets understanding.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xuchen Li",
            "Xiaokun Feng",
            "Shiyu Hu",
            "Meiqi Wu",
            "Dailing Zhang",
            "Jing Zhang",
            "Kaiqi Huang"
        ],
        "published": "2024-05-20T16:01:01Z"
    },
    {
        "title": "A Vision on Open Science for the Evolution of Software Engineering\n  Research and Practice",
        "link": "http://dx.doi.org/10.1145/3663529.3663788",
        "abstract": "Open Science aims to foster openness and collaboration in research, leading\nto more significant scientific and social impact. However, practicing Open\nScience comes with several challenges and is currently not properly rewarded.\nIn this paper, we share our vision for addressing those challenges through a\nconceptual framework that connects essential building blocks for a change in\nthe Software Engineering community, both culturally and technically. The idea\nbehind this framework is that Open Science is treated as a first-class\nrequirement for better Software Engineering research, practice, recognition,\nand relevant social impact. There is a long road for us, as a community, to\ntruly embrace and gain from the benefits of Open Science. Nevertheless, we shed\nlight on the directions for promoting the necessary culture shift and\nempowering the Software Engineering community.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Edson OliveiraJr",
            "Fernanda Madeiral",
            "Alcemir Rodrigues Santos",
            "Christina von Flach",
            "Sergio Soares"
        ],
        "published": "2024-05-20T15:51:23Z"
    },
    {
        "title": "MoRA: High-Rank Updating for Parameter-Efficient Fine-Tuning",
        "link": "http://arxiv.org/abs/2405.12130v1",
        "abstract": "Low-rank adaptation is a popular parameter-efficient fine-tuning method for\nlarge language models. In this paper, we analyze the impact of low-rank\nupdating, as implemented in LoRA. Our findings suggest that the low-rank\nupdating mechanism may limit the ability of LLMs to effectively learn and\nmemorize new knowledge. Inspired by this observation, we propose a new method\ncalled MoRA, which employs a square matrix to achieve high-rank updating while\nmaintaining the same number of trainable parameters. To achieve it, we\nintroduce the corresponding non-parameter operators to reduce the input\ndimension and increase the output dimension for the square matrix. Furthermore,\nthese operators ensure that the weight can be merged back into LLMs, which\nmakes our method can be deployed like LoRA. We perform a comprehensive\nevaluation of our method across five tasks: instruction tuning, mathematical\nreasoning, continual pretraining, memory and pretraining. Our method\noutperforms LoRA on memory-intensive tasks and achieves comparable performance\non other tasks.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Ting Jiang",
            "Shaohan Huang",
            "Shengyue Luo",
            "Zihan Zhang",
            "Haizhen Huang",
            "Furu Wei",
            "Weiwei Deng",
            "Feng Sun",
            "Qi Zhang",
            "Deqing Wang",
            "Fuzhen Zhuang"
        ],
        "published": "2024-05-20T15:48:32Z"
    },
    {
        "title": "Alzheimer's Magnetic Resonance Imaging Classification Using Deep and\n  Meta-Learning Models",
        "link": "http://arxiv.org/abs/2405.12126v1",
        "abstract": "Deep learning, a cutting-edge machine learning approach, outperforms\ntraditional machine learning in identifying intricate structures in complex\nhigh-dimensional data, particularly in the domain of healthcare. This study\nfocuses on classifying Magnetic Resonance Imaging (MRI) data for Alzheimer's\ndisease (AD) by leveraging deep learning techniques characterized by\nstate-of-the-art CNNs. Brain imaging techniques such as MRI have enabled the\nmeasurement of pathophysiological brain changes related to Alzheimer's disease.\nAlzheimer's disease is the leading cause of dementia in the elderly, and it is\nan irreversible brain illness that causes gradual cognitive function disorder.\nIn this paper, we train some benchmark deep models individually for the\napproach of the solution and later use an ensembling approach to combine the\neffect of multiple CNNs towards the observation of higher recall and accuracy.\nHere, the model's effectiveness is evaluated using various methods, including\nstacking, majority voting, and the combination of models with high recall\nvalues. The majority voting performs better than the alternative modelling\napproach as the majority voting approach typically reduces the variance in the\npredictions. We report a test accuracy of 90% with a precision score of 0.90\nand a recall score of 0.89 in our proposed approach. In future, this study can\nbe extended to incorporate other types of medical data, including signals,\nimages, and other data. The same or alternative datasets can be used with\nadditional classifiers, neural networks, and AI techniques to enhance\nAlzheimer's detection.",
        "subjects": [
            "cs.CV",
            "cs.ET",
            "cs.LG",
            "cs.MM"
        ],
        "authors": [
            "Nida Nasir",
            "Muneeb Ahmed",
            "Neda Afreen",
            "Mustafa Sameer"
        ],
        "published": "2024-05-20T15:44:07Z"
    },
    {
        "title": "Design, Control, and Motion-Planning for a Root-Perching\n  Rotor-Distributed Manipulator",
        "link": "http://dx.doi.org/10.1109/TRO.2023.3327634",
        "abstract": "Manipulation performance improvement is crucial for aerial robots. For aerial\nmanipulators, the baselink position and attitude errors directly affect the\nprecision at the end effector. To address this stability problem, fixed-body\napproaches such as perching on the environment using the rotor suction force\nare useful. Additionally, conventional arm-equipped multirotors, called\nrotor-concentrated manipulators (RCMs), find it difficult to generate a large\nwrench at the end effector due to joint torque limitations. Using distributed\nrotors to each link, the thrust can support each link weight, decreasing the\narm joints' torque. Based on this approach, rotor-distributed manipulators\n(RDMs) can increase feasible wrench and reachability of the end-effector. This\npaper introduces a minimal configuration of a rotor-distributed manipulator\nthat can perch on surfaces, especially ceilings, using a part of their body.\nFirst, we design a minimal rotor-distributed arm considering the flight and\nend-effector performance. Second, a flight controller is proposed for this\nminimal RDM along with a perching controller adaptable for various types of\naerial robots. Third, we propose a motion planning method based on inverse\nkinematics (IK), considering specific constraints to the proposed RDMs such as\nperching force. Finally, we evaluate flight and perching motions and\n\\revise{confirm} that the proposed manipulator can significantly improve the\nmanipulation performance.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Takuzumi Nishio",
            "Moju Zhao",
            "Kei Okada",
            "Masayuki Inaba"
        ],
        "published": "2024-05-20T15:43:40Z"
    },
    {
        "title": "Exploring Teachers' Perception of Artificial Intelligence: The\n  Socio-emotional Deficiency as Opportunities and Challenges in Human-AI\n  Complementarity in K-12 Education",
        "link": "http://arxiv.org/abs/2405.13065v1",
        "abstract": "In schools, teachers play a multitude of roles, serving as educators,\ncounselors, decision-makers, and members of the school community. With recent\nadvances in artificial intelligence (AI), there is increasing discussion about\nhow AI can assist, complement, and collaborate with teachers. To pave the way\nfor better teacher-AI complementary relationships in schools, our study aims to\nexpand the discourse on teacher-AI complementarity by seeking educators'\nperspectives on the potential strengths and limitations of AI across a spectrum\nof responsibilities. Through a mixed method using a survey with 100 elementary\nschool teachers in South Korea and in-depth interviews with 12 teachers, our\nfindings indicate that teachers anticipate AI's potential to complement human\nteachers by automating administrative tasks and enhancing personalized learning\nthrough advanced intelligence. Interestingly, the deficit of AI's\nsocio-emotional capabilities has been perceived as both challenges and\nopportunities. Overall, our study demonstrates the nuanced perception of\nteachers and different levels of expectations over their roles, challenging the\nneed for decisions about AI adoption tailored to educators' preferences and\nconcerns.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.CY"
        ],
        "authors": [
            "Soon-young Oh",
            "Yongsu Ahn"
        ],
        "published": "2024-05-20T15:43:04Z"
    },
    {
        "title": "Prompt Learning for Generalized Vehicle Routing",
        "link": "http://arxiv.org/abs/2405.12262v1",
        "abstract": "Neural combinatorial optimization (NCO) is a promising learning-based\napproach to solving various vehicle routing problems without much manual\nalgorithm design. However, the current NCO methods mainly focus on the\nin-distribution performance, while the real-world problem instances usually\ncome from different distributions. A costly fine-tuning approach or generalized\nmodel retraining from scratch could be needed to tackle the out-of-distribution\ninstances. Unlike the existing methods, this work investigates an efficient\nprompt learning approach in NCO for cross-distribution adaptation. To be\nconcrete, we propose a novel prompt learning method to facilitate fast\nzero-shot adaptation of a pre-trained model to solve routing problem instances\nfrom different distributions. The proposed model learns a set of prompts among\nvarious distributions and then selects the best-matched one to prompt a\npre-trained attention model for each problem instance. Extensive experiments\nshow that the proposed prompt learning approach facilitates the fast adaptation\nof pre-trained routing models. It also outperforms existing generalized models\non both in-distribution prediction and zero-shot generalization to a diverse\nset of new tasks. Our code implementation is available online\nhttps://github.com/FeiLiu36/PromptVRP.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Fei Liu",
            "Xi Lin",
            "Weiduo Liao",
            "Zhenkun Wang",
            "Qingfu Zhang",
            "Xialiang Tong",
            "Mingxuan Yuan"
        ],
        "published": "2024-05-20T15:42:23Z"
    },
    {
        "title": "An Active Learning Framework with a Class Balancing Strategy for Time\n  Series Classification",
        "link": "http://arxiv.org/abs/2405.12122v1",
        "abstract": "Training machine learning models for classification tasks often requires\nlabeling numerous samples, which is costly and time-consuming, especially in\ntime series analysis. This research investigates Active Learning (AL)\nstrategies to reduce the amount of labeled data needed for effective time\nseries classification. Traditional AL techniques cannot control the selection\nof instances per class for labeling, leading to potential bias in\nclassification performance and instance selection, particularly in imbalanced\ntime series datasets. To address this, we propose a novel class-balancing\ninstance selection algorithm integrated with standard AL strategies. Our\napproach aims to select more instances from classes with fewer labeled\nexamples, thereby addressing imbalance in time series datasets. We demonstrate\nthe effectiveness of our AL framework in selecting informative data samples for\ntwo distinct domains of tactile texture recognition and industrial fault\ndetection. In robotics, our method achieves high-performance texture\ncategorization while significantly reducing labeled training data requirements\nto 70%. We also evaluate the impact of different sliding window time intervals\non robotic texture classification using AL strategies. In synthetic fiber\nmanufacturing, we adapt AL techniques to address the challenge of fault\nclassification, aiming to minimize data annotation cost and time for\nindustries. We also address real-life class imbalances in the multiclass\nindustrial anomalous dataset using our class-balancing instance algorithm\nintegrated with AL strategies. Overall, this thesis highlights the potential of\nour AL framework across these two distinct domains.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Shemonto Das"
        ],
        "published": "2024-05-20T15:39:40Z"
    },
    {
        "title": "Insecurity of Quantum Two-Party Computation with Applications to\n  Cheat-Sensitive Protocols and Oblivious Transfer Reductions",
        "link": "http://arxiv.org/abs/2405.12121v1",
        "abstract": "Oblivious transfer (OT) is a fundamental primitive for secure two-party\ncomputation. It is well known that OT cannot be implemented with\ninformation-theoretic security if the two players only have access to noiseless\ncommunication channels, even in the quantum case. As a result, weaker variants\nof OT have been studied. In this work, we rigorously establish the\nimpossibility of cheat-sensitive OT, where a dishonest party can cheat, but\nrisks being detected. We construct a general attack on any quantum protocol\nthat allows the receiver to compute all inputs of the sender and provide an\nexplicit upper bound on the success probability of this attack. This implies\nthat cheat-sensitive quantum Symmetric Private Information Retrieval cannot be\nimplemented with statistical information-theoretic security. Leveraging the\ntechniques devised for our proofs, we provide entropic bounds on primitives\nneeded for secure function evaluation. They imply impossibility results for\nprotocols where the players have access to OT as a resource. This result\nsignificantly improves upon existing bounds and yields tight bounds for\nreductions of 1-out-of-n OT to a resource primitive. Our results hold in\nparticular for transformations between a finite number of primitives and for\nany error.",
        "subjects": [
            "quant-ph",
            "cs.CR"
        ],
        "authors": [
            "Esther Hänggi",
            "Severin Winkler"
        ],
        "published": "2024-05-20T15:39:30Z"
    },
    {
        "title": "EdgeLoc: A Communication-Adaptive Parallel System for Real-Time\n  Localization in Infrastructure-Assisted Autonomous Driving",
        "link": "http://arxiv.org/abs/2405.12120v1",
        "abstract": "This paper presents EdgeLoc, an infrastructure-assisted, real-time\nlocalization system for autonomous driving that addresses the incompatibility\nbetween traditional localization methods and deep learning approaches. The\nsystem is built on top of the Robot Operating System (ROS) and combines the\nreal-time performance of traditional methods with the high accuracy of deep\nlearning approaches. The system leverages edge computing capabilities of\nroadside units (RSUs) for precise localization to enhance on-vehicle\nlocalization that is based on the real-time visual odometry. EdgeLoc is a\nparallel processing system, utilizing a proposed uncertainty-aware pose fusion\nsolution. It achieves communication adaptivity through online learning and\naddresses fluctuations via window-based detection. Moreover, it achieves\noptimal latency and maximum improvement by utilizing auto-splitting\nvehicle-infrastructure collaborative inference, as well as online distribution\nlearning for decision-making. Even with the most basic end-to-end deep neural\nnetwork for localization estimation, EdgeLoc realizes a 67.75\\% reduction in\nthe localization error for real-time local visual odometry, a 29.95\\% reduction\nfor non-real-time collaborative inference, and a 30.26\\% reduction compared to\nKalman filtering. Finally, accuracy-to-latency conversion was experimentally\nvalidated, and an overall experiment was conducted on a practical cellular\nnetwork. The system is open sourced at\nhttps://github.com/LoganCome/EdgeAssistedLocalization.",
        "subjects": [
            "cs.DC",
            "cs.NI"
        ],
        "authors": [
            "Boyi Liu",
            "Jingwen Tong",
            "Yufan Zhuang",
            "Jiawei Shao",
            "Jun Zhang"
        ],
        "published": "2024-05-20T15:38:53Z"
    },
    {
        "title": "Reindex-Then-Adapt: Improving Large Language Models for Conversational\n  Recommendation",
        "link": "http://arxiv.org/abs/2405.12119v1",
        "abstract": "Large language models (LLMs) are revolutionizing conversational recommender\nsystems by adeptly indexing item content, understanding complex conversational\ncontexts, and generating relevant item titles. However, controlling the\ndistribution of recommended items remains a challenge. This leads to suboptimal\nperformance due to the failure to capture rapidly changing data distributions,\nsuch as item popularity, on targeted conversational recommendation platforms.\nIn conversational recommendation, LLMs recommend items by generating the titles\n(as multiple tokens) autoregressively, making it difficult to obtain and\ncontrol the recommendations over all items. Thus, we propose a\nReindex-Then-Adapt (RTA) framework, which converts multi-token item titles into\nsingle tokens within LLMs, and then adjusts the probability distributions over\nthese single-token item titles accordingly. The RTA framework marries the\nbenefits of both LLMs and traditional recommender systems (RecSys):\nunderstanding complex queries as LLMs do; while efficiently controlling the\nrecommended item distributions in conversational recommendations as traditional\nRecSys do. Our framework demonstrates improved accuracy metrics across three\ndifferent conversational recommendation datasets and two adaptation settings",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Zhankui He",
            "Zhouhang Xie",
            "Harald Steck",
            "Dawen Liang",
            "Rahul Jha",
            "Nathan Kallus",
            "Julian McAuley"
        ],
        "published": "2024-05-20T15:37:55Z"
    },
    {
        "title": "Strongly-Consistent Distributed Discrete-event Systems",
        "link": "http://arxiv.org/abs/2405.12117v1",
        "abstract": "Discrete-event (DE) systems are concurrent programs where components\ncommunicate via tagged events, where tags are drawn from a totally ordered set.\nReactors are an emerging model of computation based on DE and realized in the\nopen-source coordination language Lingua Franca. Distributed DE (DDE) systems\nare DE systems where the components (reactors) communicate over networks. The\nprior art has required that for DDE systems with cycles, each cycle must\ncontain at least one logical delay, where the tag of events is incremented.\nSuch delays, however, are not required by the elegant fixed-point semantics of\nDE. The only requirement is that the program be constructive, meaning it is\nfree of causality cycles. This paper gives a way to coordinate the execution of\nDDE systems that can execute any constructive program, even one with zero-delay\ncycles. It provides a formal model that exposes exactly the information that\nmust be shared across networks for such execution to be possible. Furthermore,\nit describes a concrete implementation that is an extension of the coordination\nmechanisms in Lingua Franca.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Peter Donovan",
            "Erling Jellum",
            "Byeonggil Jun",
            "Hokeun Kim",
            "Edward A. Lee",
            "Shaokai Lin",
            "Marten Lohstroh",
            "Anirudh Rengarajan"
        ],
        "published": "2024-05-20T15:32:47Z"
    },
    {
        "title": "Clap: a Rust eDSL for PlonKish Proof Systems with a Semantics-preserving\n  Optimizing Compiler",
        "link": "http://arxiv.org/abs/2405.12115v1",
        "abstract": "Writing Plonkish constraint systems by hand is tedious and error-prone; as a\nresult, several libraries and DSL's have emerged over the years to facilitate\nthis task as well as techniques to directly analyze constraint systems.\nHowever, standalone languages require developers to use a foreign toolchain and\nleave gaps between the application and its circuits. On the other hand,\nRust-embedded DSL like Halo2 or Boojum lack in modularity; furthermore, it is\nusually impossible to tease apart the circuit from the proof system, making it\nhard to reuse circuits and even to compare performance of different proof\nsystems on the same circuits.\n  In this paper we introduce Clap, the first Rust eDSL to propose a\nprover-agnostic circuit format that enables extensibility, automatic\noptimizations, and formal guarantees for the resulting constraint system. Clap\ngenerates Plonkish constraint systems and witness generators that are sound and\ncomplete with respect to each other, leaving no room for subtle bugs due to\nunder- or over-constraining. A model of this equivalence is proved in the Agda\nproof assistant for a subset of Clap's Rust implementation that is expressive\nenough to capture the compositional properties of our format. In order to\nincrease the reuse of circuits, a number of optimizations are carried out\nautomatically, sparing the developer from over-specifying low-level constraint\nsystem details in their circuit descriptions. We test the expressivity and\nefficiency of Clap on an implementation of the Poseidon2 hash function that\nproduces a constraint system that is competitive in terms of size with\nhand-optimized Boojum circuits.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Marco Stronati",
            "Denis Firsov",
            "Antonio Locascio",
            "Benjamin Livshits"
        ],
        "published": "2024-05-20T15:31:32Z"
    },
    {
        "title": "A New Cross-Space Total Variation Regularization Model for Color Image\n  Restoration with Quaternion Blur Operator",
        "link": "http://arxiv.org/abs/2405.12114v1",
        "abstract": "The cross-channel deblurring problem in color image processing is difficult\nto solve due to the complex coupling and structural blurring of color pixels.\nUntil now, there are few efficient algorithms that can reduce color infection\nin deblurring process. To solve this challenging problem, we present a novel\ncross-space total variation (CSTV) regularization model for color image\ndeblurring by introducing a quaternion blur operator and a cross-color space\nregularization functional. The existence and uniqueness of the solution is\nproved and a new L-curve method is proposed to find a sweet balance of\nregularization functionals on different color spaces.\n  The Euler-Lagrange equation is derived to show that CSTV has taken into\naccount the coupling of all color channels and the local smoothing within each\ncolor channel. A quaternion operator splitting method is firstly proposed to\nenhance the ability of color infection reduction of the CSTV regularization\nmodel. This strategy also applies to the well-known color deblurring models.\nNumerical experiments on color image databases illustrate the efficiency and\nmanoeuvrability of the new model and algorithms. The color images restored by\nthem successfully maintain the color and spatial information and are of higher\nquality in terms of PSNR, SSIM, MSE and CIEde2000 than the restorations of\nthe-state-of-the-art methods.",
        "subjects": [
            "cs.CV",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Zhigang Jia",
            "Yuelian Xiang",
            "Meixiang Zhao",
            "Tingting Wu",
            "Michael K. Ng"
        ],
        "published": "2024-05-20T15:29:26Z"
    },
    {
        "title": "CoR-GS: Sparse-View 3D Gaussian Splatting via Co-Regularization",
        "link": "http://arxiv.org/abs/2405.12110v1",
        "abstract": "3D Gaussian Splatting (3DGS) creates a radiance field consisting of 3D\nGaussians to represent a scene. With sparse training views, 3DGS easily suffers\nfrom overfitting, negatively impacting the reconstruction quality. This paper\nintroduces a new co-regularization perspective for improving sparse-view 3DGS.\nWhen training two 3D Gaussian radiance fields with the same sparse views of a\nscene, we observe that the two radiance fields exhibit \\textit{point\ndisagreement} and \\textit{rendering disagreement} that can unsupervisedly\npredict reconstruction quality, stemming from the sampling implementation in\ndensification. We further quantify the point disagreement and rendering\ndisagreement by evaluating the registration between Gaussians' point\nrepresentations and calculating differences in their rendered pixels. The\nempirical study demonstrates the negative correlation between the two\ndisagreements and accurate reconstruction, which allows us to identify\ninaccurate reconstruction without accessing ground-truth information. Based on\nthe study, we propose CoR-GS, which identifies and suppresses inaccurate\nreconstruction based on the two disagreements: (\\romannumeral1) Co-pruning\nconsiders Gaussians that exhibit high point disagreement in inaccurate\npositions and prunes them. (\\romannumeral2) Pseudo-view co-regularization\nconsiders pixels that exhibit high rendering disagreement are inaccurately\nrendered and suppress the disagreement. Results on LLFF, Mip-NeRF360, DTU, and\nBlender demonstrate that CoR-GS effectively regularizes the scene geometry,\nreconstructs the compact representations, and achieves state-of-the-art novel\nview synthesis quality under sparse training views.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jiawei Zhang",
            "Jiahe Li",
            "Xiaohan Yu",
            "Lei Huang",
            "Lin Gu",
            "Jin Zheng",
            "Xiao Bai"
        ],
        "published": "2024-05-20T15:25:47Z"
    },
    {
        "title": "Linguistic Structure from a Bottleneck on Sequential Information\n  Processing",
        "link": "http://arxiv.org/abs/2405.12109v1",
        "abstract": "Human language is a unique form of communication in the natural world,\ndistinguished by its structured nature. Most fundamentally, it is systematic,\nmeaning that signals can be broken down into component parts that are\nindividually meaningful -- roughly, words -- which are combined in a regular\nway to form sentences. Furthermore, the way in which these parts are combined\nmaintains a kind of locality: words are usually concatenated together, and they\nform contiguous phrases, keeping related parts of sentences close to each\nother. We address the challenge of understanding how these basic properties of\nlanguage arise from broader principles of efficient communication under\ninformation processing constraints. Here we show that natural-language-like\nsystematicity arises from minimization of excess entropy, a measure of\nstatistical complexity that represents the minimum amount of information\nnecessary for predicting the future of a sequence based on its past. In\nsimulations, we show that codes that minimize excess entropy factorize their\nsource distributions into approximately independent components, and then\nexpress those components systematically and locally. Next, in a series of\nmassively cross-linguistic corpus studies, we show that human languages are\nstructured to have low excess entropy at the level of phonology, morphology,\nsyntax, and semantics. Our result suggests that human language performs a\nsequential generalization of Independent Components Analysis on the statistical\ndistribution over meanings that need to be expressed. It establishes a link\nbetween the statistical and algebraic structure of human language, and\nreinforces the idea that the structure of human language may have evolved to\nminimize cognitive load while maximizing communicative expressiveness.",
        "subjects": [
            "cs.CL",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Richard Futrell",
            "Michael Hahn"
        ],
        "published": "2024-05-20T15:25:18Z"
    },
    {
        "title": "Imp: Highly Capable Large Multimodal Models for Mobile Devices",
        "link": "http://arxiv.org/abs/2405.12107v1",
        "abstract": "By harnessing the capabilities of large language models (LLMs), recent large\nmultimodal models (LMMs) have shown remarkable versatility in open-world\nmultimodal understanding. Nevertheless, they are usually parameter-heavy and\ncomputation-intensive, thus hindering their applicability in\nresource-constrained scenarios. To this end, several lightweight LMMs have been\nproposed successively to maximize the capabilities under constrained scale\n(e.g., 3B). Despite the encouraging results achieved by these methods, most of\nthem only focus on one or two aspects of the design space, and the key design\nchoices that influence model capability have not yet been thoroughly\ninvestigated. In this paper, we conduct a systematic study for lightweight LMMs\nfrom the aspects of model architecture, training strategy, and training data.\nBased on our findings, we obtain Imp -- a family of highly capable LMMs at the\n2B-4B scales. Notably, our Imp-3B model steadily outperforms all the existing\nlightweight LMMs of similar size, and even surpasses the state-of-the-art LMMs\nat the 13B scale. With low-bit quantization and resolution reduction\ntechniques, our Imp model can be deployed on a Qualcomm Snapdragon 8Gen3 mobile\nchip with a high inference speed of about 13 tokens/s.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "authors": [
            "Zhenwei Shao",
            "Zhou Yu",
            "Jun Yu",
            "Xuecheng Ouyang",
            "Lihao Zheng",
            "Zhenbiao Gai",
            "Mingyang Wang",
            "Jiajun Ding"
        ],
        "published": "2024-05-20T15:23:19Z"
    },
    {
        "title": "Sheet Music Transformer ++: End-to-End Full-Page Optical Music\n  Recognition for Pianoform Sheet Music",
        "link": "http://arxiv.org/abs/2405.12105v2",
        "abstract": "Optical Music Recognition is a field that has progressed significantly,\nbringing accurate systems that transcribe effectively music scores into digital\nformats. Despite this, there are still several limitations that hinder OMR from\nachieving its full potential. Specifically, state of the art OMR still depends\non multi-stage pipelines for performing full-page transcription, as well as it\nhas only been demonstrated in monophonic cases, leaving behind very relevant\nengravings. In this work, we present the Sheet Music Transformer++, an\nend-to-end model that is able to transcribe full-page polyphonic music scores\nwithout the need of a previous Layout Analysis step. This is done thanks to an\nextensive curriculum learning-based pretraining with synthetic data generation.\nWe conduct several experiments on a full-page extension of a public polyphonic\ntranscription dataset. The experimental outcomes confirm that the model is\ncompetent at transcribing full-page pianoform scores, marking a noteworthy\nmilestone in end-to-end OMR transcription.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Antonio Ríos-Vila",
            "Jorge Calvo-Zaragoza",
            "David Rizo",
            "Thierry Paquet"
        ],
        "published": "2024-05-20T15:21:48Z"
    },
    {
        "title": "Deciding branching hyperproperties for real time systems",
        "link": "http://arxiv.org/abs/2405.12104v1",
        "abstract": "Security properties of real-time systems often involve reasoning about\nhyper-properties, as opposed to properties of single executions or trees of\nexecutions. These hyper-properties need to additionally be expressive enough to\nreason about real-time constraints. Examples of such properties include\ninformation flow, side channel attacks and service-level agreements. In this\npaper we study computational problems related to a branching-time,\nhyper-property extension of metric temporal logic (MTL) that we call HCMTL*. We\nconsider both the interval-based and point-based semantics of this logic. The\nverification problem that we consider is to determine if a given HCMTL* formula\n$\\varphi$ is true in a system represented by a timed automaton. We show that\nthis problem is undecidable. We then show that the verification problem is\ndecidable if we consider executions upto a fixed time horizon $T$. Our\ndecidability result relies on reducing the verification problem to the truth of\nan MSO formula over reals with a bounded time interval.",
        "subjects": [
            "cs.CR",
            "cs.LO"
        ],
        "authors": [
            "Nabarun Deka",
            "Minjian Zhang",
            "Rohit Chadha",
            "Mahesh Viswanathan"
        ],
        "published": "2024-05-20T15:21:12Z"
    },
    {
        "title": "Sustainable business decision modelling with blockchain and digital\n  twins: A survey",
        "link": "http://arxiv.org/abs/2405.12101v1",
        "abstract": "Industry 4.0 and beyond will rely heavily on sustainable Business Decision\nModelling (BDM) that can be accelerated by blockchain and Digital Twin (DT)\nsolutions. BDM is built on models and frameworks refined by key identification\nfactors, data analysis, and mathematical or computational aspects applicable to\ncomplex business scenarios. Gaining actionable intelligence from collected data\nfor BDM requires a carefully considered infrastructure to ensure data\ntransparency, security, accessibility and sustainability. Organisations should\nconsider social, economic and environmental factors (based on the triple bottom\nline approach) to ensure sustainability when integrating such an\ninfrastructure. These sustainability features directly impact BDM concerning\nresource optimisation, stakeholder engagement, regulatory compliance and\nenvironmental impacts. To further understand these segments, taxonomies are\ndefined to evaluate blockchain and DT sustainability features based on an\nin-depth review of the current state-of-the-art research. Detailed comparative\nevaluations provide insight into the reachability of the sustainable solution\nin terms of ideologies, access control and performance overheads. Several\nresearch questions are put forward to motivate further research that\nsignificantly impacts BDM. Finally, a case study based on an exemplary supply\nchain management system is presented to show the interoperability of blockchain\nand DT with BDM.",
        "subjects": [
            "cs.NI",
            "cs.ET"
        ],
        "authors": [
            "Gyan Wickremasinghe",
            "Siofra Frost",
            "Karen Rafferty",
            "Vishal Sharma"
        ],
        "published": "2024-05-20T15:15:14Z"
    },
    {
        "title": "Digital Health and Indoor Air Quality: An IoT-Driven Human-Centred\n  Visualisation Platform for Behavioural Change and Technology Acceptance",
        "link": "http://arxiv.org/abs/2405.13064v1",
        "abstract": "The detrimental effects of air pollutants on human health have prompted\nincreasing concerns regarding indoor air quality (IAQ). The emergence of\ndigital health interventions and citizen science initiatives has provided new\navenues for raising awareness, improving IAQ, and promoting behavioural\nchanges. The Technology Acceptance Model (TAM) offers a theoretical framework\nto understand user acceptance and adoption of IAQ technology. This paper\npresents a case study using the COM-B model and Internet of Things (IoT)\ntechnology to design a human-centred digital visualisation platform, leading to\nbehavioural changes and improved IAQ. The study also investigates users'\nacceptance and adoption of the technology, focusing on their experiences,\nexpectations, and the impact on IAQ. Integrating IAQ sensing, digital\nhealth-related interventions, citizen science, and the TAM model offers\nopportunities to address IAQ challenges, enhance public health, and foster\nsustainable indoor environments. The analytical results show that factors such\nas human behaviour, indoor activities, and awareness play crucial roles in\nshaping IAQ.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Rameez Raja Kureshi",
            "Bhupesh Kumar Mishra",
            "Dhavalkumar Thakker",
            "Suvodeep Mazumdar",
            "Xiao Li"
        ],
        "published": "2024-05-20T15:13:25Z"
    },
    {
        "title": "DOP: Diagnostic-Oriented Prompting for Large Language Models in\n  Mathematical Correction",
        "link": "http://arxiv.org/abs/2405.12100v1",
        "abstract": "Math world problems correction(MWPC) is a novel task dedicated to rectifying\nreasoning errors in the process of solving mathematical problems. In this\npaper, leveraging the advancements in large language models (LLMs), we address\ntwo key objectives:(1) Distinguishing between mathematical reasoning and error\ncorrection; (2) Exploring strategies to enhance the error correction\ncapabilities of LLMs in mathematics to solve MWPC task. We noticed that, in\nreal-time education,assisting students in recognizing their mistakes is more\ncrucial than simply providing correct answers. However, current research tends\nto prioritize obtaining accurate solutions to math problems rather than\ncorrecting potentially incorrect ones. Therefore, we modify the research\nparadigm, demonstrating that improving mathematical reasoning abilities does\nnot equate to mastery in error correction. Meanwhile, we propose a novel method\ncalled diagnostic-oriented promping(DOP) aimed at facilitating LLMs to excel in\nerror correction. In experiments, DOP has shown outstanding performance,\nhighlighting its significant impact. We argue that in mathematical education,\nthe demand for outstanding correctors surpasses that for proficient reasoners.\nCodes and data are available on\nhttps://github.com/ChenhaoEcnuCS/Reason-Correct.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Hao Chen",
            "Biaojie Zeng",
            "Xin Lin",
            "Liang He",
            "Aimin Zhou"
        ],
        "published": "2024-05-20T15:13:22Z"
    },
    {
        "title": "Using Unsupervised Learning to Explore Robot-Pedestrian Interactions in\n  Urban Environments",
        "link": "http://arxiv.org/abs/2405.12098v1",
        "abstract": "This study identifies a gap in data-driven approaches to robot-centric\npedestrian interactions and proposes a corresponding pipeline. The pipeline\nutilizes unsupervised learning techniques to identify patterns in interaction\ndata of urban environments, specifically focusing on conflict scenarios.\nAnalyzed features include the robot's and pedestrian's speed and contextual\nparameters such as proximity to intersections. They are extracted and reduced\nin dimensionality using Principal Component Analysis (PCA). Finally, K-means\nclustering is employed to uncover underlying patterns in the interaction data.\nA use case application of the pipeline is presented, utilizing real-world robot\nmission data from a mid-sized German city. The results indicate the need for\nenriching interaction representations with contextual information to enable\nfine-grained analysis and reasoning. Nevertheless, they also highlight the need\nfor expanding the data set and incorporating additional contextual factors to\nenhance the robots situational awareness and interaction quality.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Sebastian Zug",
            "Georg Jäger",
            "Norman Seyffer",
            "Martin Plank",
            "Gero Licht",
            "Felix Wilhelm Siebert"
        ],
        "published": "2024-05-20T15:08:15Z"
    },
    {
        "title": "PATE: Proximity-Aware Time series anomaly Evaluation",
        "link": "http://arxiv.org/abs/2405.12096v1",
        "abstract": "Evaluating anomaly detection algorithms in time series data is critical as\ninaccuracies can lead to flawed decision-making in various domains where\nreal-time analytics and data-driven strategies are essential. Traditional\nperformance metrics assume iid data and fail to capture the complex temporal\ndynamics and specific characteristics of time series anomalies, such as early\nand delayed detections. We introduce Proximity-Aware Time series anomaly\nEvaluation (PATE), a novel evaluation metric that incorporates the temporal\nrelationship between prediction and anomaly intervals. PATE uses\nproximity-based weighting considering buffer zones around anomaly intervals,\nenabling a more detailed and informed assessment of a detection. Using these\nweights, PATE computes a weighted version of the area under the Precision and\nRecall curve. Our experiments with synthetic and real-world datasets show the\nsuperiority of PATE in providing more sensible and accurate evaluations than\nother evaluation metrics. We also tested several state-of-the-art anomaly\ndetectors across various benchmark datasets using the PATE evaluation scheme.\nThe results show that a common metric like Point-Adjusted F1 Score fails to\ncharacterize the detection performances well, and that PATE is able to provide\na more fair model comparison. By introducing PATE, we redefine the\nunderstanding of model efficacy that steers future studies toward developing\nmore effective and accurate detection models.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ramin Ghorbani",
            "Marcel J. T. Reinders",
            "David M. J. Tax"
        ],
        "published": "2024-05-20T15:06:36Z"
    },
    {
        "title": "Is Mamba Compatible with Trajectory Optimization in Offline\n  Reinforcement Learning?",
        "link": "http://arxiv.org/abs/2405.12094v1",
        "abstract": "Transformer-based trajectory optimization methods have demonstrated\nexceptional performance in offline Reinforcement Learning (offline RL), yet it\nposes challenges due to substantial parameter size and limited scalability,\nwhich is particularly critical in sequential decision-making scenarios where\nresources are constrained such as in robots and drones with limited\ncomputational power. Mamba, a promising new linear-time sequence model, offers\nperformance on par with transformers while delivering substantially fewer\nparameters on long sequences. As it remains unclear whether Mamba is compatible\nwith trajectory optimization, this work aims to conduct comprehensive\nexperiments to explore the potential of Decision Mamba in offline RL (dubbed\nDeMa) from the aspect of data structures and network architectures with the\nfollowing insights: (1) Long sequences impose a significant computational\nburden without contributing to performance improvements due to the fact that\nDeMa's focus on sequences diminishes approximately exponentially. Consequently,\nwe introduce a Transformer-like DeMa as opposed to an RNN-like DeMa. (2) For\nthe components of DeMa, we identify that the hidden attention mechanism is key\nto its success, which can also work well with other residual structures and\ndoes not require position embedding. Extensive evaluations from eight Atari\ngames demonstrate that our specially designed DeMa is compatible with\ntrajectory optimization and surpasses previous state-of-the-art methods,\noutdoing Decision Transformer (DT) by 80\\% with 30\\% fewer parameters, and\nexceeds DT in MuJoCo with only a quarter of the parameters.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yang Dai",
            "Oubo Ma",
            "Longfei Zhang",
            "Xingxing Liang",
            "Shengchao Hu",
            "Mengzhu Wang",
            "Shouling Ji",
            "Jincai Huang",
            "Li Shen"
        ],
        "published": "2024-05-20T15:05:47Z"
    },
    {
        "title": "Using Formal Verification to Evaluate Single Event Upsets in a RISC-V\n  Core",
        "link": "http://arxiv.org/abs/2405.12089v1",
        "abstract": "Reliability has been a major concern in embedded systems. Higher transistor\ndensity and lower voltage supply increase the vulnerability of embedded systems\nto soft errors. A Single Event Upset (SEU), which is also called a soft error,\ncan reverse a bit in a sequential element, resulting in a system failure.\nSimulation-based fault injection has been widely used to evaluate reliability,\nas suggested by ISO26262. However, it is practically impossible to test all\nfaults for a complex design. Random fault injection is a compromise that\nreduces accuracy and fault coverage. Formal verification is an alternative\napproach. In this paper, we use formal verification, in the form of model\nchecking, to evaluate the hardware reliability of a RISC-V Ibex Core in the\npresence of soft errors. Backward tracing is performed to identify and\ncategorize faults according to their effects (no effect, Silent Data\nCorruption, crashes, and hangs). By using formal verification, the entire state\nspace and fault list can be exhaustively explored. It is found that misaligned\ninstructions can amplify fault effects. It is also found that some bits are\nmore vulnerable to SEUs than others. In general, most of the bits in the Ibex\nCore are vulnerable to Silent Data Corruption, and the second pipeline stage is\nmore vulnerable to Silent Data Corruption than the first.",
        "subjects": [
            "cs.AR"
        ],
        "authors": [
            "Bing Xue",
            "Mark Zwolinski"
        ],
        "published": "2024-05-20T15:02:13Z"
    },
    {
        "title": "Channel Balance Interpolation in the Lightning Network via Machine\n  Learning",
        "link": "http://arxiv.org/abs/2405.12087v1",
        "abstract": "The Bitcoin Lightning Network is a Layer 2 payment protocol that addresses\nBitcoin's scalability by facilitating quick and cost effective transactions\nthrough payment channels. This research explores the feasibility of using\nmachine learning models to interpolate channel balances within the network,\nwhich can be used for optimizing the network's pathfinding algorithms. While\nthere has been much exploration in balance probing and multipath payment\nprotocols, predicting channel balances using solely node and channel features\nremains an uncharted area. This paper evaluates the performance of several\nmachine learning models against two heuristic baselines and investigates the\npredictive capabilities of various features. Our model performs favorably in\nexperimental evaluation, outperforming by 10% against an equal split baseline\nwhere both edges are assigned half of the channel capacity.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            " Vincent",
            "Emanuele Rossi",
            "Vikash Singh"
        ],
        "published": "2024-05-20T14:57:16Z"
    },
    {
        "title": "Noise-tolerant learnability of shallow quantum circuits from statistics\n  and the cost of quantum pseudorandomness",
        "link": "http://arxiv.org/abs/2405.12085v1",
        "abstract": "This work studies the learnability of unknown quantum circuits in the near\nterm. We prove the natural robustness of quantum statistical queries for\nlearning quantum processes and provide an efficient way to benchmark various\nclasses of noise from statistics, which gives us a powerful framework for\ndeveloping noise-tolerant algorithms. We adapt a learning algorithm for\nconstant-depth quantum circuits to the quantum statistical query setting with a\nsmall overhead in the query complexity. We prove average-case lower bounds for\nlearning random quantum circuits of logarithmic and higher depths within\ndiamond distance with statistical queries. Additionally, we show the hardness\nof the quantum threshold search problem from quantum statistical queries and\ndiscuss its implications for the learnability of shallow quantum circuits.\nFinally, we prove that pseudorandom unitaries (PRUs) cannot be constructed\nusing circuits of constant depth by constructing an efficient distinguisher and\nproving a new variation of the quantum no-free lunch theorem.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "cs.CR",
            "cs.LG"
        ],
        "authors": [
            "Chirag Wadhwa",
            "Mina Doosti"
        ],
        "published": "2024-05-20T14:55:20Z"
    },
    {
        "title": "Distributional Semantics, Holism, and the Instability of Meaning",
        "link": "http://arxiv.org/abs/2405.12084v1",
        "abstract": "Current language models are built on the so-called distributional semantic\napproach to linguistic meaning that has the distributional hypothesis at its\ncore. The distributional hypothesis involves a holistic conception of word\nmeaning: the meaning of a word depends upon its relations to other words in the\nmodel. A standard objection to meaning holism is the charge of instability: any\nchange in the meaning properties of a linguistic system (a human speaker, for\nexample) would lead to many changes or possibly a complete change in the entire\nsystem. When the systems in question are trying to communicate with each other,\nit has been argued that instability of this kind makes communication impossible\n(Fodor and Lepore 1992, 1996, 1999). In this article, we examine whether the\ninstability objection poses a problem for distributional models of meaning.\nFirst, we distinguish between distinct forms of instability that these models\ncould exhibit, and we argue that only one such form is relevant for\nunderstanding the relation between instability and communication: what we call\ndifferential instability. Differential instability is variation in the relative\ndistances between points in a space, rather than variation in the absolute\nposition of those points. We distinguish differential and absolute instability\nby constructing two of our own models, a toy model constructed from the text of\ntwo novels, and a more sophisticated model constructed using the Word2vec\nalgorithm from a combination of Wikipedia and SEP articles. We demonstrate the\ntwo forms of instability by showing how these models change as the corpora they\nare constructed from increase in size.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Jumbly Grindrod",
            "J. D. Porter",
            "Nat Hansen"
        ],
        "published": "2024-05-20T14:53:25Z"
    },
    {
        "title": "Selective Annotation via Data Allocation: These Data Should Be Triaged\n  to Experts for Annotation Rather Than the Model",
        "link": "http://arxiv.org/abs/2405.12081v1",
        "abstract": "To obtain high-quality annotations under limited budget, semi-automatic\nannotation methods are commonly used, where a portion of the data is annotated\nby experts and a model is then trained to complete the annotations for the\nremaining data. However, these methods mainly focus on selecting informative\ndata for expert annotations to improve the model predictive ability (i.e.,\ntriage-to-human data), while the rest of the data is indiscriminately assigned\nto model annotation (i.e., triage-to-model data). This may lead to\ninefficiencies in budget allocation for annotations, as easy data that the\nmodel could accurately annotate may be unnecessarily assigned to the expert,\nand hard data may be misclassified by the model. As a result, the overall\nannotation quality may be compromised. To address this issue, we propose a\nselective annotation framework called SANT. It effectively takes advantage of\nboth the triage-to-human and triage-to-model data through the proposed\nerror-aware triage and bi-weighting mechanisms. As such, informative or hard\ndata is assigned to the expert for annotation, while easy data is handled by\nthe model. Experimental results show that SANT consistently outperforms other\nbaselines, leading to higher-quality annotation through its proper allocation\nof data to both expert and model workers. We provide pioneering work on data\nannotation within budget constraints, establishing a landmark for future\ntriage-based annotation studies.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Chen Huang",
            "Yang Deng",
            "Wenqiang Lei",
            "Jiancheng Lv",
            "Ido Dagan"
        ],
        "published": "2024-05-20T14:52:05Z"
    },
    {
        "title": "PARALLELGPUOS: A Concurrent OS-level GPU Checkpoint and Restore System\n  using Validated Speculation",
        "link": "http://arxiv.org/abs/2405.12079v1",
        "abstract": "Checkpointing (C) and restoring (R) are key components for GPU tasks. POS is\nan OS-level GPU C/R system: It can transparently checkpoint or restore\nprocesses that use the GPU, without requiring any cooperation from the\napplication, a key feature required by modern systems like the cloud. Moreover,\nPOS is the first OS-level C/R system that can concurrently execute C/R with the\napplication execution: a critical feature that can be trivially achieved when\nthe processes only running on the CPU, but becomes challenging when the\nprocesses use GPU. The problem is how to ensure consistency during concurrent\nexecution with the lack of application semantics due to transparency. CPU\nprocesses can leverage OS and hardware paging to fix inconsistency without\napplication semantics. Unfortunately, GPU bypasses OS and paging for high\nperformance. POS fills the semantic gap by speculatively extracting buffer\naccess information of GPU kernels during runtime. Thanks to the simple and\nwell-structured nature of GPU kernels, our speculative extraction (with runtime\nvalidation) achieves 100% accuracy on applications from training to inference\nwhose domains span from vision, large language models, and reinforcement\nlearning. Based on the extracted semantics, we systematically overlap C/R with\napplication execution, and achieves orders of magnitude higher performance\nunder various tasks compared with the state-of-the-art OS-level GPU C/R,\nincluding training fault tolerance, live GPU process migration, and cold starts\nacceleration in GPU-based serverless computing.",
        "subjects": [
            "cs.DC",
            "cs.OS"
        ],
        "authors": [
            "Zhuobin Huang",
            "Xingda Wei",
            "Yingyi Hao",
            "Rong Chen",
            "Mingcong Han",
            "Jinyu Gu",
            "Haibo Chen"
        ],
        "published": "2024-05-20T14:49:45Z"
    },
    {
        "title": "Aurora: A Foundation Model of the Atmosphere",
        "link": "http://arxiv.org/abs/2405.13063v1",
        "abstract": "Deep learning foundation models are revolutionizing many facets of science by\nleveraging vast amounts of data to learn general-purpose representations that\ncan be adapted to tackle diverse downstream tasks. Foundation models hold the\npromise to also transform our ability to model our planet and its subsystems by\nexploiting the vast expanse of Earth system data. Here we introduce Aurora, a\nlarge-scale foundation model of the atmosphere trained on over a million hours\nof diverse weather and climate data. Aurora leverages the strengths of the\nfoundation modelling approach to produce operational forecasts for a wide\nvariety of atmospheric prediction problems, including those with limited\ntraining data, heterogeneous variables, and extreme events. In under a minute,\nAurora produces 5-day global air pollution predictions and 10-day\nhigh-resolution weather forecasts that outperform state-of-the-art classical\nsimulation tools and the best specialized deep learning models. Taken together,\nthese results indicate that foundation models can transform environmental\nforecasting.",
        "subjects": [
            "physics.ao-ph",
            "cs.LG"
        ],
        "authors": [
            "Cristian Bodnar",
            "Wessel P. Bruinsma",
            "Ana Lucic",
            "Megan Stanley",
            "Johannes Brandstetter",
            "Patrick Garvan",
            "Maik Riechert",
            "Jonathan Weyn",
            "Haiyu Dong",
            "Anna Vaughan",
            "Jayesh K. Gupta",
            "Kit Tambiratnam",
            "Alex Archibald",
            "Elizabeth Heider",
            "Max Welling",
            "Richard E. Turner",
            "Paris Perdikaris"
        ],
        "published": "2024-05-20T14:45:18Z"
    },
    {
        "title": "GAN-GRID: A Novel Generative Attack on Smart Grid Stability Prediction",
        "link": "http://arxiv.org/abs/2405.12076v1",
        "abstract": "The smart grid represents a pivotal innovation in modernizing the electricity\nsector, offering an intelligent, digitalized energy network capable of\noptimizing energy delivery from source to consumer. It hence represents the\nbackbone of the energy sector of a nation. Due to its central role, the\navailability of the smart grid is paramount and is hence necessary to have\nin-depth control of its operations and safety. To this aim, researchers\ndeveloped multiple solutions to assess the smart grid's stability and guarantee\nthat it operates in a safe state. Artificial intelligence and Machine learning\nalgorithms have proven to be effective measures to accurately predict the smart\ngrid's stability. Despite the presence of known adversarial attacks and\npotential solutions, currently, there exists no standardized measure to protect\nsmart grids against this threat, leaving them open to new adversarial attacks.\nIn this paper, we propose GAN-GRID a novel adversarial attack targeting the\nstability prediction system of a smart grid tailored to real-world constraints.\nOur findings reveal that an adversary armed solely with the stability model's\noutput, devoid of data or model knowledge, can craft data classified as stable\nwith an Attack Success Rate (ASR) of 0.99. Also by manipulating authentic data\nand sensor values, the attacker can amplify grid issues, potentially undetected\ndue to a compromised stability prediction system. These results underscore the\nimperative of fortifying smart grid security mechanisms against adversarial\nmanipulation to uphold system stability and reliability.",
        "subjects": [
            "cs.CR",
            "eess.SP"
        ],
        "authors": [
            "Emad Efatinasab",
            "Alessandro Brighente",
            "Mirco Rampazzo",
            "Nahal Azadi",
            "Mauro Conti"
        ],
        "published": "2024-05-20T14:43:46Z"
    },
    {
        "title": "StatAvg: Mitigating Data Heterogeneity in Federated Learning for\n  Intrusion Detection Systems",
        "link": "http://arxiv.org/abs/2405.13062v1",
        "abstract": "Federated learning (FL) is a decentralized learning technique that enables\nparticipating devices to collaboratively build a shared Machine Leaning (ML) or\nDeep Learning (DL) model without revealing their raw data to a third party. Due\nto its privacy-preserving nature, FL has sparked widespread attention for\nbuilding Intrusion Detection Systems (IDS) within the realm of cybersecurity.\nHowever, the data heterogeneity across participating domains and entities\npresents significant challenges for the reliable implementation of an FL-based\nIDS. In this paper, we propose an effective method called Statistical Averaging\n(StatAvg) to alleviate non-independently and identically (non-iid) distributed\nfeatures across local clients' data in FL. In particular, StatAvg allows the FL\nclients to share their individual data statistics with the server, which then\naggregates this information to produce global statistics. The latter are shared\nwith the clients and used for universal data normalisation. It is worth\nmentioning that StatAvg can seamlessly integrate with any FL aggregation\nstrategy, as it occurs before the actual FL training process. The proposed\nmethod is evaluated against baseline approaches using datasets for network and\nhost Artificial Intelligence (AI)-powered IDS. The experimental results\ndemonstrate the efficiency of StatAvg in mitigating non-iid feature\ndistributions across the FL clients compared to the baseline methods.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.DC",
            "cs.LG"
        ],
        "authors": [
            "Pavlos S. Bouzinis",
            "Panagiotis Radoglou-Grammatikis",
            "Ioannis Makris",
            "Thomas Lagkas",
            "Vasileios Argyriou",
            "Georgios Th. Papadopoulos",
            "Panagiotis Sarigiannidis",
            "George K. Karagiannidis"
        ],
        "published": "2024-05-20T14:41:59Z"
    },
    {
        "title": "Goal-Oriented Communication for Networked Control Assisted by\n  Reconfigurable Meta-Surfaces",
        "link": "http://arxiv.org/abs/2405.12073v1",
        "abstract": "In this paper, we develop a theoretical framework for goal-oriented\ncommunication assisted by reconfigurable meta-surfaces in the context of\nnetworked control systems. The relation to goal-oriented communication stems\nfrom the fact that optimization of the phase shifts of the meta-surfaces is\nguided by the performance of networked control systems tasks. To that end, we\nconsider a networked control system in which a set of sensors observe the\nstates of a set of physical processes, and communicate this information over an\nunreliable wireless channel assisted by a reconfigurable intelligent surface\nwith multiple reflecting elements to a set of controllers that correct the\nbehaviors of the physical processes based on the received information. Our\nobjective is to find the optimal control policy for the controllers and the\noptimal phase policy for the reconfigurable intelligent surface that jointly\nminimize a regulation cost function associated with the networked control\nsystem. We characterize these policies, and also propose an approximate\nsolution based on a semi-definite relaxation technique.",
        "subjects": [
            "cs.IT",
            "math.IT",
            "math.OC"
        ],
        "authors": [
            "Mohamad Assaad",
            "Touraj Soleymani"
        ],
        "published": "2024-05-20T14:41:48Z"
    },
    {
        "title": "AutoSoccerPose: Automated 3D posture Analysis of Soccer Shot Movements",
        "link": "http://arxiv.org/abs/2405.12070v1",
        "abstract": "Image understanding is a foundational task in computer vision, with recent\napplications emerging in soccer posture analysis. However, existing publicly\navailable datasets lack comprehensive information, notably in the form of\nposture sequences and 2D pose annotations. Moreover, current analysis models\noften rely on interpretable linear models (e.g., PCA and regression), limiting\ntheir capacity to capture non-linear spatiotemporal relationships in complex\nand diverse scenarios. To address these gaps, we introduce the 3D Shot Posture\n(3DSP) dataset in soccer broadcast videos, which represents the most extensive\nsports image dataset with 2D pose annotations to our knowledge. Additionally,\nwe present the 3DSP-GRAE (Graph Recurrent AutoEncoder) model, a non-linear\napproach for embedding pose sequences. Furthermore, we propose AutoSoccerPose,\na pipeline aimed at semi-automating 2D and 3D pose estimation and posture\nanalysis. While achieving full automation proved challenging, we provide a\nfoundational baseline, extending its utility beyond the scope of annotated\ndata. We validate AutoSoccerPose on SoccerNet and 3DSP datasets, and present\nposture analysis results based on 3DSP. The dataset, code, and models are\navailable at: https://github.com/calvinyeungck/3D-Shot-Posture-Dataset.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Calvin Yeung",
            "Kenjiro Ide",
            "Keisuke Fujii"
        ],
        "published": "2024-05-20T14:40:26Z"
    },
    {
        "title": "Gaussian Head & Shoulders: High Fidelity Neural Upper Body Avatars with\n  Anchor Gaussian Guided Texture Warping",
        "link": "http://arxiv.org/abs/2405.12069v2",
        "abstract": "By equipping the most recent 3D Gaussian Splatting representation with head\n3D morphable models (3DMM), existing methods manage to create head avatars with\nhigh fidelity. However, most existing methods only reconstruct a head without\nthe body, substantially limiting their application scenarios. We found that\nnaively applying Gaussians to model the clothed chest and shoulders tends to\nresult in blurry reconstruction and noisy floaters under novel poses. This is\nbecause of the fundamental limitation of Gaussians and point clouds -- each\nGaussian or point can only have a single directional radiance without spatial\nvariance, therefore an unnecessarily large number of them is required to\nrepresent complicated spatially varying texture, even for simple geometry. In\ncontrast, we propose to model the body part with a neural texture that consists\nof coarse and pose-dependent fine colors. To properly render the body texture\nfor each view and pose without accurate geometry nor UV mapping, we optimize\nanother sparse set of Gaussians as anchors that constrain the neural warping\nfield that maps image plane coordinates to the texture space. We demonstrate\nthat Gaussian Head & Shoulders can fit the high-frequency details on the\nclothed upper body with high fidelity and potentially improve the accuracy and\nfidelity of the head region. We evaluate our method with casual phone-captured\nand internet videos and show our method archives superior reconstruction\nquality and robustness in both self and cross reenactment tasks. To fully\nutilize the efficient rendering speed of Gaussian splatting, we additionally\npropose an accelerated inference method of our trained model without\nMulti-Layer Perceptron (MLP) queries and reach a stable rendering speed of\naround 130 FPS for any subjects.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Tianhao Wu",
            "Jing Yang",
            "Zhilin Guo",
            "Jingyi Wan",
            "Fangcheng Zhong",
            "Cengiz Oztireli"
        ],
        "published": "2024-05-20T14:39:49Z"
    },
    {
        "title": "CLAMBER: A Benchmark of Identifying and Clarifying Ambiguous Information\n  Needs in Large Language Models",
        "link": "http://arxiv.org/abs/2405.12063v1",
        "abstract": "Large language models (LLMs) are increasingly used to meet user information\nneeds, but their effectiveness in dealing with user queries that contain\nvarious types of ambiguity remains unknown, ultimately risking user trust and\nsatisfaction. To this end, we introduce CLAMBER, a benchmark for evaluating\nLLMs using a well-organized taxonomy. Building upon the taxonomy, we construct\n~12K high-quality data to assess the strengths, weaknesses, and potential risks\nof various off-the-shelf LLMs. Our findings indicate the limited practical\nutility of current LLMs in identifying and clarifying ambiguous user queries,\neven enhanced by chain-of-thought (CoT) and few-shot prompting. These\ntechniques may result in overconfidence in LLMs and yield only marginal\nenhancements in identifying ambiguity. Furthermore, current LLMs fall short in\ngenerating high-quality clarifying questions due to a lack of conflict\nresolution and inaccurate utilization of inherent knowledge. In this paper,\nCLAMBER presents a guidance and promotes further research on proactive and\ntrustworthy LLMs. Our dataset is available at\nhttps://github.com/zt991211/CLAMBER",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Tong Zhang",
            "Peixin Qin",
            "Yang Deng",
            "Chen Huang",
            "Wenqiang Lei",
            "Junhong Liu",
            "Dingnan Jin",
            "Hongru Liang",
            "Tat-Seng Chua"
        ],
        "published": "2024-05-20T14:34:01Z"
    },
    {
        "title": "STYLE: Improving Domain Transferability of Asking Clarification\n  Questions in Large Language Model Powered Conversational Agents",
        "link": "http://arxiv.org/abs/2405.12059v1",
        "abstract": "Equipping a conversational search engine with strategies regarding when to\nask clarification questions is becoming increasingly important across various\ndomains. Attributing to the context understanding capability of LLMs and their\naccess to domain-specific sources of knowledge, LLM-based clarification\nstrategies feature rapid transfer to various domains in a post-hoc manner.\nHowever, they still struggle to deliver promising performance on unseen\ndomains, struggling to achieve effective domain transferability. We take the\nfirst step to investigate this issue and existing methods tend to produce\none-size-fits-all strategies across diverse domains, limiting their search\neffectiveness. In response, we introduce a novel method, called Style, to\nachieve effective domain transferability. Our experimental results indicate\nthat Style bears strong domain transferability, resulting in an average search\nperformance improvement of ~10% on four unseen domains.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yue Chen",
            "Chen Huang",
            "Yang Deng",
            "Wenqiang Lei",
            "Dingnan Jin",
            "Jia Liu",
            "Tat-Seng Chua"
        ],
        "published": "2024-05-20T14:28:25Z"
    },
    {
        "title": "NPLMV-PS: Neural Point-Light Multi-View Photometric Stereo",
        "link": "http://arxiv.org/abs/2405.12057v1",
        "abstract": "In this work we present a novel multi-view photometric stereo (PS) method.\nLike many works in 3D reconstruction we are leveraging neural shape\nrepresentations and learnt renderers. However, our work differs from the\nstate-of-the-art multi-view PS methods such as PS-NeRF or SuperNormal we\nexplicity leverage per-pixel intensity renderings rather than relying mainly on\nestimated normals.\n  We model point light attenuation and explicitly raytrace cast shadows in\norder to best approximate each points incoming radiance. This is used as input\nto a fully neural material renderer that uses minimal prior assumptions and it\nis jointly optimised with the surface. Finally, estimated normal and\nsegmentation maps can also incorporated in order to maximise the surface\naccuracy.\n  Our method is among the first to outperform the classical approach of\nDiLiGenT-MV and achieves average 0.2mm Chamfer distance for objects imaged at\napprox 1.5m distance away with approximate 400x400 resolution. Moreover, we\nshow robustness to poor normals in low light count scenario, achieving 0.27mm\nChamfer distance when pixel rendering is used instead of estimated normals.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Fotios Logothetis",
            "Ignas Budvytis",
            "Roberto Cipolla"
        ],
        "published": "2024-05-20T14:26:07Z"
    },
    {
        "title": "Unveiling factors influencing judgment variation in Sentiment Analysis\n  with Natural Language Processing and Statistics",
        "link": "http://arxiv.org/abs/2405.12055v1",
        "abstract": "TripAdvisor reviews and comparable data sources play an important role in\nmany tasks in Natural Language Processing (NLP), providing a data basis for the\nidentification and classification of subjective judgments, such as hotel or\nrestaurant reviews, into positive or negative polarities. This study explores\nthree important factors influencing variation in crowdsourced polarity\njudgments, focusing on TripAdvisor reviews in Spanish. Three hypotheses are\ntested: the role of Part Of Speech (POS), the impact of sentiment words such as\n\"tasty\", and the influence of neutral words like \"ok\" on judgment variation.\nThe study's methodology employs one-word titles, demonstrating their efficacy\nin studying polarity variation of words. Statistical tests on mean equality are\nperformed on word groups of our interest. The results of this study reveal that\nadjectives in one-word titles tend to result in lower judgment variation\ncompared to other word types or POS. Sentiment words contribute to lower\njudgment variation as well, emphasizing the significance of sentiment words in\nresearch on polarity judgments, and neutral words are associated with higher\njudgment variation as expected. However, these effects cannot be always\nreproduced in longer titles, which suggests that longer titles do not represent\nthe best data source for testing the ambiguity of single words due to the\ninfluence on word polarity by other words like negation in longer titles. This\nempirical investigation contributes valuable insights into the factors\ninfluencing polarity variation of words, providing a foundation for NLP\npractitioners that aim to capture and predict polarity judgments in Spanish and\nfor researchers that aim to understand factors influencing judgment variation.",
        "subjects": [
            "cs.CL",
            "68T50, 91F20",
            "I.2.7"
        ],
        "authors": [
            "Olga Kellert",
            "Carlos Gómez-Rodríguez",
            "Mahmud Uz Zaman"
        ],
        "published": "2024-05-20T14:24:18Z"
    },
    {
        "title": "Parallelization of the K-Means Algorithm with Applications to Big Data\n  Clustering",
        "link": "http://arxiv.org/abs/2405.12052v1",
        "abstract": "The K-Means clustering using LLoyd's algorithm is an iterative approach to\npartition the given dataset into K different clusters. The algorithm assigns\neach point to the cluster based on the following objective function\n  \\[\\ \\min \\Sigma_{i=1}^{n}||x_i-\\mu_{x_i}||^2\\] The serial algorithm involves\niterative steps where we compute the distance of each datapoint from the\ncentroids and assign the datapoint to the nearest centroid. This approach is\nessentially known as the expectation-maximization step. Clustering involves\nextensive computations to calculate distances at each iteration, which\nincreases as the number of data points increases. This provides scope for\nparallelism. However, we must ensure that in a parallel process, each thread\nhas access to the updated centroid value and no racing condition exists on any\ncentroid values. We will compare two different approaches in this project. The\nfirst approach is an OpenMP flat synchronous method where all processes are run\nin parallel, and we use synchronization to ensure safe updates of clusters. The\nsecond approach we adopt is a GPU based parallelization approach using OpenACC\nwherein we will try to make use of GPU architecture to parallelize chunks of\nthe algorithm to observe decreased computation time. We will analyze metrics\nsuch as speed up, efficiency,time taken with varying data points, and number of\nprocesses to compare the two approaches and understand the relative performance\nimprovement we can get.",
        "subjects": [
            "cs.DC",
            "cs.LG"
        ],
        "authors": [
            "Ashish Srivastava",
            "Mohammed Nawfal"
        ],
        "published": "2024-05-20T14:18:36Z"
    },
    {
        "title": "EXACT: Towards a platform for empirically benchmarking Machine Learning\n  model explanation methods",
        "link": "http://arxiv.org/abs/2405.12261v1",
        "abstract": "The evolving landscape of explainable artificial intelligence (XAI) aims to\nimprove the interpretability of intricate machine learning (ML) models, yet\nfaces challenges in formalisation and empirical validation, being an inherently\nunsupervised process. In this paper, we bring together various benchmark\ndatasets and novel performance metrics in an initial benchmarking platform, the\nExplainable AI Comparison Toolkit (EXACT), providing a standardised foundation\nfor evaluating XAI methods. Our datasets incorporate ground truth explanations\nfor class-conditional features, and leveraging novel quantitative metrics, this\nplatform assesses the performance of post-hoc XAI methods in the quality of the\nexplanations they produce. Our recent findings have highlighted the limitations\nof popular XAI methods, as they often struggle to surpass random baselines,\nattributing significance to irrelevant features. Moreover, we show the\nvariability in explanations derived from different equally performing model\narchitectures. This initial benchmarking platform therefore aims to allow XAI\nresearchers to test and assure the high quality of their newly developed\nmethods.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Benedict Clark",
            "Rick Wilming",
            "Artur Dox",
            "Paul Eschenbach",
            "Sami Hached",
            "Daniel Jin Wodke",
            "Michias Taye Zewdie",
            "Uladzislau Bruila",
            "Marta Oliveira",
            "Hjalmar Schulz",
            "Luca Matteo Cornils",
            "Danny Panknin",
            "Ahcène Boubekki",
            "Stefan Haufe"
        ],
        "published": "2024-05-20T14:16:06Z"
    },
    {
        "title": "Energy-Efficient Federated Edge Learning with Streaming Data: A Lyapunov\n  Optimization Approach",
        "link": "http://arxiv.org/abs/2405.12046v1",
        "abstract": "Federated learning (FL) has received significant attention in recent years\nfor its advantages in efficient training of machine learning models across\ndistributed clients without disclosing user-sensitive data. Specifically, in\nfederated edge learning (FEEL) systems, the time-varying nature of wireless\nchannels introduces inevitable system dynamics in the communication process,\nthereby affecting training latency and energy consumption. In this work, we\nfurther consider a streaming data scenario where new training data samples are\nrandomly generated over time at edge devices. Our goal is to develop a dynamic\nscheduling and resource allocation algorithm to address the inherent randomness\nin data arrivals and resource availability under long-term energy constraints.\nTo achieve this, we formulate a stochastic network optimization problem and use\nthe Lyapunov drift-plus-penalty framework to obtain a dynamic resource\nmanagement design. Our proposed algorithm makes adaptive decisions on device\nscheduling, computational capacity adjustment, and allocation of bandwidth and\ntransmit power in every round. We provide convergence analysis for the\nconsidered setting with heterogeneous data and time-varying objective\nfunctions, which supports the rationale behind our proposed scheduling design.\nThe effectiveness of our scheme is verified through simulation results,\ndemonstrating improved learning performance and energy efficiency as compared\nto baseline schemes.",
        "subjects": [
            "cs.LG",
            "cs.DC",
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Chung-Hsuan Hu",
            "Zheng Chen",
            "Erik G. Larsson"
        ],
        "published": "2024-05-20T14:13:22Z"
    },
    {
        "title": "The Incoherency Risk in the EU's New Cyber Security Policies",
        "link": "http://arxiv.org/abs/2405.12043v1",
        "abstract": "The European Union (EU) has been pursuing new cyber security policies in\nrecent years. This paper presents a short evaluation of four such policies. The\nfocus is on potential incoherency, meaning a lack of integration, divergence\nbetween the member states, institutional dysfunction, and other related\nproblems that should be at least partially avoidable by sound policy-making.\nAccording to the evaluation, the four policies have substantially increased the\ncomplexity of the EU's cyber security framework. In addition, there are\npotential problems with trust, divergence between industry sectors and\ndifferent technologies, bureaucratic conflicts, and technical issues, among\nother things. With these insights, the paper not only contributes to the study\nof EU policies but also advances the understanding of cyber security policies\nin general.",
        "subjects": [
            "cs.CR",
            "cs.CY"
        ],
        "authors": [
            "Jukka Ruohonen"
        ],
        "published": "2024-05-20T14:10:35Z"
    },
    {
        "title": "Attribute-Based Authentication in Secure Group Messaging for Distributed\n  Environments",
        "link": "http://arxiv.org/abs/2405.12042v1",
        "abstract": "Messaging Layer security (MLS) and its underlying Continuous Group Key\nAgreement (CGKA) protocol allows a group of users to share a cryptographic\nsecret in a dynamic manner, such that the secret is modified in member\ninsertions and deletions. Although this flexibility makes MLS ideal for\nimplementations in distributed environments, a number of issues need to be\novercome. Particularly, the use of digital certificates for authentication in a\ngroup goes against the group members' privacy. In this work we provide an\nalternative method of authentication in which the solicitors, instead of\nrevealing their identity, only need to prove possession of certain attributes,\ndynamically defined by the group, to become a member. Instead of digital\ncertificates, we employ Attribute-Based Credentials accompanied with Selective\nDisclosure in order to reveal the minimum required amount of information and to\nprevent attackers from linking the activity of a user through multiple groups.\nWe formally define a CGKA variant named Attribute-Authenticated Continuous\nGroup Key Agreement (AA-CGKA) and provide security proofs for its properties of\nRequirement Integrity, Unforgeability and Unlinkability. We also provide\nguidelines for an integration of our construction in MLS.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "David Soler",
            "Carlos Dafonte",
            "Manuel Fernández-Veiga",
            "Ana Fernández Vilas",
            "Francisco J. Nóvoa"
        ],
        "published": "2024-05-20T14:09:28Z"
    },
    {
        "title": "Reputation Transfer in the Twitter Diaspora",
        "link": "http://arxiv.org/abs/2405.12040v1",
        "abstract": "Social media platforms have witnessed a dynamic landscape of user migration\nin recent years, fueled by changes in ownership, policy, and user preferences.\nThis paper explores the phenomenon of user migration from established platforms\nlike X/Twitter to emerging alternatives such as Threads, Mastodon, and Truth\nSocial. Leveraging a large dataset from X/Twitter, we investigate the extent of\nuser departure from X/Twitter and the destinations they migrate to.\nAdditionally, we examine whether a user's reputation on one platform correlates\nwith their reputation on another, shedding light on the transferability of\ndigital reputation across social media ecosystems. Overall, we find that users\nwith a large following on X/Twitter are more likely to migrate to another\nplatform; and that their reputation on X/Twitter is highly correlated with\nreputations on Threads, but not Mastodon or Truth Social.",
        "subjects": [
            "cs.SI",
            "cs.HC"
        ],
        "authors": [
            "Kristina Radivojevic",
            "DJ Adams",
            "Griffin Laszlo",
            "Felixander Kery",
            "Tim Weninger"
        ],
        "published": "2024-05-20T14:07:59Z"
    },
    {
        "title": "Adaptive Extraction Network for Multivariate Long Sequence Time-Series\n  Forecasting",
        "link": "http://arxiv.org/abs/2405.12038v1",
        "abstract": "Models employing CNN architecture have made significant progress in\nmultivariate long sequence time-series forecasting (MLSTF), particularly in\nmodeling local time series characteristics. However, during the MLSTF process,\nextracting the global time series patterns and understanding the correlations\namong different variables are highly significant. To address this challenge, we\nintroduce multi-resolution convolution and deformable convolution operations.\nBy enlarging the receptive field using convolution kernels with different\ndilation factors to capture temporal correlation information across different\nresolutions, and adaptively adjusting the sampling positions through additional\noffset vectors, we enhance the network's ability to capture correlated features\nbetween variables. Building upon this, we propose ATVCNet, an adaptive\ntemporal-variable convolutional network designed to effectively model the\nlocal/global temporal dependencies and inter-variable dependencies of\nmultivariate time series. Specifically, extracting and fusing time series\nfeatures at different resolutions, captures both local contextual information\nand global patterns in the time series. The designed inter-variable feature\nadaptive extraction module captures the correlation among different variables\nin the time series. We evaluated the performance of ATVCNet across eight\nreal-world datasets. The results indicate that ATVCNet achieved a performance\nimprovement of approximately 63.4% over state-of-the-art MLSTF models.",
        "subjects": [
            "cs.LG",
            "cs.IR"
        ],
        "authors": [
            "Dandan Zhang",
            "Yun Wang"
        ],
        "published": "2024-05-20T14:05:35Z"
    },
    {
        "title": "KG-RAG: Bridging the Gap Between Knowledge and Creativity",
        "link": "http://arxiv.org/abs/2405.12035v1",
        "abstract": "Ensuring factual accuracy while maintaining the creative capabilities of\nLarge Language Model Agents (LMAs) poses significant challenges in the\ndevelopment of intelligent agent systems. LMAs face prevalent issues such as\ninformation hallucinations, catastrophic forgetting, and limitations in\nprocessing long contexts when dealing with knowledge-intensive tasks. This\npaper introduces a KG-RAG (Knowledge Graph-Retrieval Augmented Generation)\npipeline, a novel framework designed to enhance the knowledge capabilities of\nLMAs by integrating structured Knowledge Graphs (KGs) with the functionalities\nof LLMs, thereby significantly reducing the reliance on the latent knowledge of\nLLMs. The KG-RAG pipeline constructs a KG from unstructured text and then\nperforms information retrieval over the newly created graph to perform KGQA\n(Knowledge Graph Question Answering). The retrieval methodology leverages a\nnovel algorithm called Chain of Explorations (CoE) which benefits from LLMs\nreasoning to explore nodes and relationships within the KG sequentially.\nPreliminary experiments on the ComplexWebQuestions dataset demonstrate notable\nimprovements in the reduction of hallucinated content and suggest a promising\npath toward developing intelligent systems adept at handling\nknowledge-intensive tasks.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.IR"
        ],
        "authors": [
            "Diego Sanmartin"
        ],
        "published": "2024-05-20T14:03:05Z"
    },
    {
        "title": "Count-Min Sketch with Conservative Updates: Worst-Case Analysis",
        "link": "http://arxiv.org/abs/2405.12034v2",
        "abstract": "Count-Min Sketch with Conservative Updates (CMS-CU) is a memory-efficient\nhash-based data structure used to estimate the occurrences of items within a\ndata stream. CMS-CU stores $m$ counters and employs $d$ hash functions to map\nitems to these counters. We first argue that the estimation error in CMS-CU is\nmaximal when each item appears at most once in the stream. Next, we study\nCMS-CU in this setting. In the case where $d=m-1$, we prove that the average\nestimation error and the average counter rate converge almost surely to\n$\\frac{1}{2}$, contrasting with the vanilla Count-Min Sketch, where the average\ncounter rate is equal to $\\frac{m-1}{m}$. For any given $m$ and $d$, we prove\nnovel lower and upper bounds on the average estimation error, incorporating a\npositive integer parameter $g$. Larger values of this parameter improve the\naccuracy of the bounds. Moreover, the computation of each bound involves\nexamining an ergodic Markov process with a state space of size\n$\\binom{m+g-d}{g}$ and a sparse transition probabilities matrix containing\n$\\mathcal{O}(m\\binom{m+g-d}{g})$ non-zero entries. For $d=m-1$, $g=1$, and as\n$m\\to \\infty$, we show that the lower and upper bounds coincide. In general,\nour bounds exhibit high accuracy for small values of $g$, as shown by numerical\ncomputation. For example, for $m=50$, $d=4$, and $g=5$, the difference between\nthe lower and upper bounds is smaller than $10^{-4}$.",
        "subjects": [
            "cs.DS",
            "cs.PF"
        ],
        "authors": [
            "Younes Ben Mazziane",
            "Othmane Marfoq"
        ],
        "published": "2024-05-20T14:01:38Z"
    },
    {
        "title": "Neighborhood Attention Transformer with Progressive Channel Fusion for\n  Speaker Verification",
        "link": "http://arxiv.org/abs/2405.12031v1",
        "abstract": "Transformer-based architectures for speaker verification typically require\nmore training data than ECAPA-TDNN. Therefore, recent work has generally been\ntrained on VoxCeleb1&2. We propose a backbone network based on self-attention,\nwhich can achieve competitive results when trained on VoxCeleb2 alone. The\nnetwork alternates between neighborhood attention and global attention to\ncapture local and global features, then aggregates features of different\nhierarchical levels, and finally performs attentive statistical pooling.\nAdditionally, we employ a progressive channel fusion strategy to expand the\nreceptive field in the channel dimension as the network deepens. We trained the\nproposed PCF-NAT model on VoxCeleb2 and evaluated it on VoxCeleb1 and the\nvalidation sets of VoxSRC. The EER and minDCF of the shallow PCF-NAT are on\naverage more than 20% lower than those of similarly sized ECAPA-TDNN. Deep\nPCF-NAT achieves an EER lower than 0.5% on VoxCeleb1-O.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Nian Li",
            "Jianguo Wei"
        ],
        "published": "2024-05-20T13:55:19Z"
    },
    {
        "title": "The Case for DeepSOH: Addressing Path Dependency for Remaining Useful\n  Life",
        "link": "http://arxiv.org/abs/2405.12028v1",
        "abstract": "The battery state of health (SOH) based on capacity fade and resistance\nincrease is not sufficient for predicting Remaining Useful life (RUL). The\nelectrochemical community blames the path-dependency of the battery degradation\nmechanisms for our inability to forecast the degradation. The control community\nknows that the path-dependency is addressed by full state estimation. We show\nthat even the electrode-specific SOH (eSOH) estimation is not enough to fully\ndefine the degradation states by simulating infinite possible degradation\ntrajectories and remaining useful lives (RUL) from a unique eSOH. We finally\ndefine the deepSOH states that capture the individual contributions of all the\ncommon degradation mechanisms, namely, SEI, plating, and mechanical fracture to\nthe loss of lithium inventory. We show that the addition of cell expansion\nmeasurement may allow us to estimate the deepSOH and predict the remaining\nuseful life.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Hamidreza Movahedi",
            "Andrew Weng",
            "Sravan Pannala",
            "Jason B. Siegel",
            "Anna G. Stefanopoulou"
        ],
        "published": "2024-05-20T13:51:12Z"
    },
    {
        "title": "Enzymatic cycle-based receivers with high input impedance for\n  approximate maximum a posteriori demodulation of concentration modulated\n  signals",
        "link": "http://arxiv.org/abs/2405.12026v1",
        "abstract": "Molecular communication is a bio-inspired communication paradigm where\nmolecules are used as the information carrier. This paper considers a molecular\ncommunication network where the transmitter uses concentration modulated\nsignals for communication. Our focus is to design receivers that can demodulate\nthese signals. We impose three features on our receivers. We want the receivers\nto use enzymatic cycles as their building blocks, have high input impedance and\ncan work approximately as a maximum a posteriori (MAP) demodulator. No\nreceivers with all these three features exist in the current molecular\ncommunication literature. We consider enzymatic cycles because they are a very\ncommon class of chemical reactions that are found in living cells. Since a\nreceiver is to be placed in the communication environment, it should ideally\nhave a high input impedance so that it has minimal impact on the environment\nand on other receivers. Lastly, a MAP receiver has good statistical\nperformance. In this paper, we show how we can use time-scale separation to\nmake an enzymatic cycle to have high input impedance and how the parameters of\nthe enzymatic cycles can be chosen so that the receiver can approximately\nimplement a MAP demodulator. We use simulation to study the performance of this\nreceiver. In particular, we consider an environment with multiple receivers and\nshow that a receiver has little impact on the bit error ratio of a nearby\nreceiver because they have high input impedance.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Chun Tung Chou"
        ],
        "published": "2024-05-20T13:44:50Z"
    },
    {
        "title": "Can AI Relate: Testing Large Language Model Response for Mental Health\n  Support",
        "link": "http://arxiv.org/abs/2405.12021v1",
        "abstract": "Large language models (LLMs) are already being piloted for clinical use in\nhospital systems like NYU Langone, Dana-Farber and the NHS. A proposed\ndeployment use case is psychotherapy, where a LLM-powered chatbot can treat a\npatient undergoing a mental health crisis. Deployment of LLMs for mental health\nresponse could hypothetically broaden access to psychotherapy and provide new\npossibilities for personalizing care. However, recent high-profile failures,\nlike damaging dieting advice offered by the Tessa chatbot to patients with\neating disorders, have led to doubt about their reliability in high-stakes and\nsafety-critical settings.\n  In this work, we develop an evaluation framework for determining whether LLM\nresponse is a viable and ethical path forward for the automation of mental\nhealth treatment. Using human evaluation with trained clinicians and automatic\nquality-of-care metrics grounded in psychology research, we compare the\nresponses provided by peer-to-peer responders to those provided by a\nstate-of-the-art LLM.\n  We show that LLMs like GPT-4 use implicit and explicit cues to infer patient\ndemographics like race. We then show that there are statistically significant\ndiscrepancies between patient subgroups: Responses to Black posters\nconsistently have lower empathy than for any other demographic group (2%-13%\nlower than the control group). Promisingly, we do find that the manner in which\nresponses are generated significantly impacts the quality of the response. We\nconclude by proposing safety guidelines for the potential deployment of LLMs\nfor mental health response.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Saadia Gabriel",
            "Isha Puri",
            "Xuhai Xu",
            "Matteo Malgaroli",
            "Marzyeh Ghassemi"
        ],
        "published": "2024-05-20T13:42:27Z"
    },
    {
        "title": "Continuous Sign Language Recognition with Adapted Conformer via\n  Unsupervised Pretraining",
        "link": "http://arxiv.org/abs/2405.12018v1",
        "abstract": "Conventional Deep Learning frameworks for continuous sign language\nrecognition (CSLR) are comprised of a single or multi-modal feature extractor,\na sequence-learning module, and a decoder for outputting the glosses. The\nsequence learning module is a crucial part wherein transformers have\ndemonstrated their efficacy in the sequence-to-sequence tasks. Analyzing the\nresearch progress in the field of Natural Language Processing and Speech\nRecognition, a rapid introduction of various transformer variants is observed.\nHowever, in the realm of sign language, experimentation in the sequence\nlearning component is limited. In this work, the state-of-the-art Conformer\nmodel for Speech Recognition is adapted for CSLR and the proposed model is\ntermed ConSignformer. This marks the first instance of employing Conformer for\na vision-based task. ConSignformer has bimodal pipeline of CNN as feature\nextractor and Conformer for sequence learning. For improved context learning we\nalso introduce Cross-Modal Relative Attention (CMRA). By incorporating CMRA\ninto the model, it becomes more adept at learning and utilizing complex\nrelationships within the data. To further enhance the Conformer model,\nunsupervised pretraining called Regressional Feature Extraction is conducted on\na curated sign language dataset. The pretrained Conformer is then fine-tuned\nfor the downstream recognition task. The experimental results confirm the\neffectiveness of the adopted pretraining strategy and demonstrate how CMRA\ncontributes to the recognition process. Remarkably, leveraging a\nConformer-based backbone, our model achieves state-of-the-art performance on\nthe benchmark datasets: PHOENIX-2014 and PHOENIX-2014T.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Neena Aloysius",
            "Geetha M",
            "Prema Nedungadi"
        ],
        "published": "2024-05-20T13:40:52Z"
    },
    {
        "title": "Strategy-Proof Auctions through Conformal Prediction",
        "link": "http://arxiv.org/abs/2405.12016v2",
        "abstract": "Auctions are key for maximizing sellers' revenue and ensuring truthful\nbidding among buyers. Recently, an approach known as differentiable economics\nbased on deep learning shows promise in learning optimal auction mechanisms for\nmultiple items and participants. However, this approach has no guarantee of\nstrategy-proofness at test time. Strategy-proofness is crucial as it ensures\nthat buyers are incentivized to bid their true valuations, leading to optimal\nand fair auction outcomes without the risk of manipulation. Building on\nconformal prediction, we introduce a novel approach to achieve\nstrategy-proofness with rigorous statistical guarantees. The key novelties of\nour method are: (i) the formulation of a regret prediction model, used to\nquantify at test time violations of strategy-proofness; and (ii) an auction\nacceptance rule that leverages the predicted regret to ensure that for a new\nauction, the data-driven mechanism meets the strategy-proofness requirement\nwith high probability (e.g., 99\\%). Numerical experiments demonstrate the\nnecessity for rigorous guarantees, the validity of our theoretical results, and\nthe applicability of our proposed method.",
        "subjects": [
            "cs.GT",
            "cs.LG"
        ],
        "authors": [
            "Roy Maor Lotan",
            "Inbal Talgam-Cohen",
            "Yaniv Romano"
        ],
        "published": "2024-05-20T13:39:58Z"
    },
    {
        "title": "Fully graphic degree sequences and P-stable degree sequences",
        "link": "http://arxiv.org/abs/2405.12013v1",
        "abstract": "The notion of P-stability played an influential role in approximating the\npermanents, sampling rapidly the realizations of graphic degree sequences, or\neven studying and improving network privacy. However, we did not have a good\ninsight of the structure of P-stable degree sequence families. In this paper we\ndevelop a remedy to overstep this deficiency.\n  We will show, that if an infinite set of graphic degree sequences,\ncharacterized by some simple inequalities of their fundamental parameters, is\n$P$-stable, then it is ``fully graphic'' -- meaning that every degree sequence\nwith an even sum, meeting the specified inequalities, is graphic. The reverse\nstatement also holds: an infinite, fully graphic set of degree sequences\ncharacterized by some simple inequalities of their fundamental parameters is\nP-stable.\n  Along the way, we will significantly strengthen some well-known, older\nresults, and we construct new P-stable families of degree sequences.",
        "subjects": [
            "math.CO",
            "cs.DM",
            "05C99, 05C75"
        ],
        "authors": [
            "Péter L. Erdős",
            "István Miklós",
            "Lajos Soukup"
        ],
        "published": "2024-05-20T13:36:01Z"
    },
    {
        "title": "Higher weight spectra of ternary codes associated to the quadratic\n  Veronese $3$-fold",
        "link": "http://arxiv.org/abs/2405.12011v1",
        "abstract": "The problem studied in this work is to determine the higher weight spectra of\nthe Projective Reed-Muller codes associated to the Veronese $3$-fold $\\mathcal\nV$ in $PG(9,q)$, which is the image of the quadratic Veronese embedding of\n$PG(3,q)$ in $PG(9,q)$. We reduce the problem to the following combinatorial\nproblem in finite geometry: For each subset $S$ of $\\mathcal V$, determine the\ndimension of the linear subspace of $PG(9,q)$ generated by $S$. We develop a\nsystematic method to solve the latter problem. We implement the method for\n$q=3$, and use it to obtain the higher weight spectra of the associated code.\nThe case of a general finite field $\\mathbb F_q$ will be treated in a future\nwork.",
        "subjects": [
            "math.CO",
            "cs.IT",
            "math.IT",
            "94B27, 51E20, 05B25"
        ],
        "authors": [
            "Krishna Kaipa",
            "Puspendu Pradhan"
        ],
        "published": "2024-05-20T13:31:57Z"
    },
    {
        "title": "DarkDNS: Revisiting the Value of Rapid Zone Update",
        "link": "http://arxiv.org/abs/2405.12010v1",
        "abstract": "Malicious actors exploit the DNS namespace to launch spam campaigns, phishing\nattacks, malware, and other harmful activities. Combating these threats\nrequires visibility into domain existence, ownership and nameservice activity\nthat the DNS protocol does not itself provide. To facilitate visibility and\nsecurity-related study of the expanding gTLD namespace, ICANN introduced the\nCentralized Zone Data Service (CZDS) that shares daily zone file snapshots of\nnew gTLD zones. However, a remarkably high concentration of malicious activity\nis associated with domains that do not live long enough make it into these\ndaily snapshots. Using public and private sources of newly observed domains to\nidentify this activity, we discover that even with the best available data\nthere is a considerable visibility gap. We find that the daily snapshots miss\nat least 1% of newly registered and short-lived domains, which are almost\nalways registered with malicious intent. In reducing this critical visibility\ngap using public sources of data, we demonstrate how more timely access to TLD\nzone changes can help better prevent abuse. We hope that this work sparks a\ndiscussion in the community on how to effectively and safely revive the concept\nof sharing Rapid Zone Updates for security research.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Raffaele Sommese",
            "Gautam Akiwate",
            "Antonia Affinito",
            "Moritz Muller",
            "Mattijs Jonker",
            "KC Claffy"
        ],
        "published": "2024-05-20T13:26:59Z"
    },
    {
        "title": "Depth Reconstruction with Neural Signed Distance Fields in Structured\n  Light Systems",
        "link": "http://arxiv.org/abs/2405.12006v1",
        "abstract": "We introduce a novel depth estimation technique for multi-frame structured\nlight setups using neural implicit representations of 3D space. Our approach\nemploys a neural signed distance field (SDF), trained through self-supervised\ndifferentiable rendering. Unlike passive vision, where joint estimation of\nradiance and geometry fields is necessary, we capitalize on known radiance\nfields from projected patterns in structured light systems. This enables\nisolated optimization of the geometry field, ensuring convergence and network\nefficacy with fixed device positioning. To enhance geometric fidelity, we\nincorporate an additional color loss based on object surfaces during training.\nReal-world experiments demonstrate our method's superiority in geometric\nperformance for few-shot scenarios, while achieving comparable results with\nincreased pattern availability.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Rukun Qiao",
            "Hiroshi Kawasaki",
            "Hongbin Zha"
        ],
        "published": "2024-05-20T13:24:35Z"
    },
    {
        "title": "Mamba-in-Mamba: Centralized Mamba-Cross-Scan in Tokenized Mamba Model\n  for Hyperspectral Image Classification",
        "link": "http://arxiv.org/abs/2405.12003v1",
        "abstract": "Hyperspectral image (HSI) classification is pivotal in the remote sensing\n(RS) field, particularly with the advancement of deep learning techniques.\nSequential models, adapted from the natural language processing (NLP) field\nsuch as Recurrent Neural Networks (RNNs) and Transformers, have been tailored\nto this task, offering a unique viewpoint. However, several challenges persist\n1) RNNs struggle with centric feature aggregation and are sensitive to\ninterfering pixels, 2) Transformers require significant computational resources\nand often underperform with limited HSI training samples, and 3) Current\nscanning methods for converting images into sequence-data are simplistic and\ninefficient. In response, this study introduces the innovative Mamba-in-Mamba\n(MiM) architecture for HSI classification, the first attempt of deploying State\nSpace Model (SSM) in this task. The MiM model includes 1) A novel centralized\nMamba-Cross-Scan (MCS) mechanism for transforming images into sequence-data, 2)\nA Tokenized Mamba (T-Mamba) encoder that incorporates a Gaussian Decay Mask\n(GDM), a Semantic Token Learner (STL), and a Semantic Token Fuser (STF) for\nenhanced feature generation and concentration, and 3) A Weighted MCS Fusion\n(WMF) module coupled with a Multi-Scale Loss Design to improve decoding\nefficiency. Experimental results from three public HSI datasets with fixed and\ndisjoint training-testing samples demonstrate that our method outperforms\nexisting baselines and state-of-the-art approaches, highlighting its efficacy\nand potential in HSI applications.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Weilian Zhou",
            "Sei-Ichiro Kamata",
            "Haipeng Wang",
            "Man-Sing Wong",
            " Huiying",
            " Hou"
        ],
        "published": "2024-05-20T13:19:02Z"
    },
    {
        "title": "Scrutinize What We Ignore: Reining Task Representation Shift In\n  Context-Based Offline Meta Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.12001v1",
        "abstract": "Offline meta reinforcement learning (OMRL) has emerged as a promising\napproach for interaction avoidance and strong generalization performance by\nleveraging pre-collected data and meta-learning techniques. Previous\ncontext-based approaches predominantly rely on the intuition that maximizing\nthe mutual information between the task and the task representation ($I(Z;M)$)\ncan lead to performance improvements. Despite achieving attractive results, the\ntheoretical justification of performance improvement for such intuition has\nbeen lacking. Motivated by the return discrepancy scheme in the model-based RL\nfield, we find that maximizing $I(Z;M)$ can be interpreted as consistently\nraising the lower bound of the expected return for a given policy conditioning\non the optimal task representation. However, this optimization process ignores\nthe task representation shift between two consecutive updates, which may lead\nto performance improvement collapse. To address this problem, we turn to use\nthe framework of performance difference bound to consider the impacts of task\nrepresentation shift explicitly. We demonstrate that by reining the task\nrepresentation shift, it is possible to achieve monotonic performance\nimprovements, thereby showcasing the advantage against previous approaches. To\nmake it practical, we design an easy yet highly effective algorithm RETRO\n(\\underline{RE}ining \\underline{T}ask \\underline{R}epresentation shift in\ncontext-based \\underline{O}ffline meta reinforcement learning) with only adding\none line of code compared to the backbone. Empirical results validate its\nstate-of-the-art (SOTA) asymptotic performance, training stability and\ntraining-time consumption on MuJoCo and MetaWorld benchmarks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Hai Zhang",
            "Boyuan Zheng",
            "Anqi Guo",
            "Tianying Ji",
            "Pheng-Ann Heng",
            "Junqiao Zhao",
            "Lanqing Li"
        ],
        "published": "2024-05-20T13:14:26Z"
    },
    {
        "title": "Multi-Agent Optimization and Learning: A Non-Expansive Operators\n  Perspective",
        "link": "http://arxiv.org/abs/2405.11999v1",
        "abstract": "Multi-agent systems are increasingly widespread in a range of application\ndomains, with optimization and learning underpinning many of the tasks that\narise in this context. Different approaches have been proposed to enable the\ncooperative solution of these optimization and learning problems, including\nfirst- and second-order methods, and dual (or Lagrangian) methods, all of which\nrely on consensus and message-passing. In this article we discuss these\nalgorithms through the lens of non-expansive operator theory, providing a\nunifying perspective. We highlight the insights that this viewpoint delivers,\nand discuss how it can spark future original research.",
        "subjects": [
            "math.OC",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Nicola Bastianello",
            "Luca Schenato",
            "Ruggero Carli"
        ],
        "published": "2024-05-20T13:11:57Z"
    },
    {
        "title": "Learning to connect in action: Measuring and understanding the emergence\n  of boundary spanners in volatile times",
        "link": "http://arxiv.org/abs/2405.11998v1",
        "abstract": "Collective intelligence of diverse groups is key for tackling many of today's\ngrand challenges such as fostering resilience and climate adaptation.\nInformation exchange across such diverse groups is crucial for collective\nintelligence, especially in volatile environments. To facilitate inter-group\ninformation exchange, Informational Boundary Spanners (IBSs) as pivotal\ninformation exchange 'hubs' are promising. However, the mechanisms that drive\nthe emergence of IBSs remain poorly understood. To address this gap there is\nfirst a need for a method to identify and measure the emergence of IBSs.\nSecond, an Agent-Based Modelling (ABM) framework is not available to\nsystematically study mechanisms for the emergence of IBSs in volatile\nenvironments. Third, even though the ability to learn who provides high-quality\ninformation is thought to be essential to explain the emergence of IBSs, a\nrigorous test of this mechanism is missing. The learning mechanism is\nformalized using an ABM framework, with the model's outputs analyzed using the\nproposed IBS emergence measurement method. To illustrate both the method and\nthe learning mechanism, we present a case study focused on information sharing\nin the volatile environment of a disaster. The study shows that learning\nconstitutes a mechanism for the emergence of effective IBSs in (a)\nlow-volatility environments characterised by low uncertainty and (b) in\nhigh-volatility environments characterised by rapid change if the number of\ninter-group connections is sufficient. With the method and model, this paper\naims to lay the foundations for exploring mechanisms for the emergence of IBSs\nthat facilitate inter-group information exchange. This article advances\ncollective intelligence by providing the essential elements for measuring and\nunderstanding the emergence of IBSs and exploring the effect of learning on\ntheir emergence in volatile environments.",
        "subjects": [
            "cs.MA"
        ],
        "authors": [
            "Vittorio Nespeca",
            "Tina Comes",
            "Frances Brazier"
        ],
        "published": "2024-05-20T13:09:52Z"
    },
    {
        "title": "Max-Min Fairness and PHY-Layer Design of Uplink MIMO Rate-Splitting\n  Multiple Access with Finite Blocklength",
        "link": "http://arxiv.org/abs/2405.11996v1",
        "abstract": "Rate-Splitting Multiple Access (RSMA) has emerged as a potent and reliable\nmultiple access and interference management technique in wireless\ncommunications. While downlink Multiple-Input Multiple-Ouput (MIMO) RSMA has\nbeen widely investigated, uplink MIMO RSMA has not been fully explored. In this\npaper, we investigate the performance of uplink RSMA in short-packet\ncommunications with perfect Channel State Information at Transmitter (CSIT) and\nChannel State Information at Receiver (CSIR). We propose an uplink MIMO RSMA\nframework and optimize both precoders and combiners with Max-Min Fairness (MMF)\nmetric and Finite Blocklength (FBL) constraints. Due to the high coupling\nbetween precoders and combiners, we apply the Alternating Optimization (AO) to\ndecompose the optimization problem into two subproblems. To tackle these\nsubproblems, we propose a Successive Convex Approximation (SCA)-based approach.\nAdditionally, we introduce a low-complexity scheme to design the decoding order\nat the receiver. Subsequently, the Physical (PHY)-layer of the uplink MIMO RSMA\narchitecture is designed and evaluated using multi-user Link-Level Simulations\n(LLS), accounting for finite constellation modulation, finite length polar\ncodes, message splitting, adaptive modulation and coding, and Successive\nInterference Cancellation (SIC) at the receiver. Numerical results demonstrate\nthat applying RSMA in uplink MIMO with FBL constraints not only achieves MMF\ngains over conventional transmission schemes such as Space Division Multiple\nAccess (SDMA) and Non-orthogonal Multiple Access (NOMA) but also exhibits\nrobustness to network loads. The benefits of splitting messages from multiple\nusers are also illustrated. LLS results confirm the improved max-min throughput\nbenefits of RSMA over SDMA and NOMA.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Jiawei Xu",
            "Bruno Clercks"
        ],
        "published": "2024-05-20T13:06:04Z"
    },
    {
        "title": "Safe by Design Autonomous Driving Systems",
        "link": "http://arxiv.org/abs/2405.11995v1",
        "abstract": "Developing safe autonomous driving systems is a major scientific and\ntechnical challenge. Existing AI-based end-to-end solutions do not offer the\nnecessary safety guarantees, while traditional systems engineering approaches\nare defeated by the complexity of the problem. Currently, there is an\nincreasing interest in hybrid design solutions, integrating machine learning\ncomponents, when necessary, while using model-based components for goal\nmanagement and planning.\n  We study a method for building safe by design autonomous driving systems,\nbased on the assumption that the capability to drive boils down to the\ncoordinated execution of a given set of driving operations. The assumption is\nsubstantiated by a compositionality result considering that autopilots are\ndynamic systems receiving a small number of types of vistas as input, each\nvista defining a free space in its neighborhood. It is shown that safe driving\nfor each type of vista in the corresponding free space, implies safe driving\nfor any possible scenario under some easy-to-check conditions concerning the\ntransition between vistas. The designed autopilot comprises distinct control\npolicies one per type of vista, articulated in two consecutive phases. The\nfirst phase consists of carefully managing a potentially risky situation by\nvirtually reducing speed, while the second phase consists of exiting the\nsituation by accelerating.\n  The autopilots designed use for their predictions simple functions\ncharacterizing the acceleration and deceleration capabilities of the vehicles.\nThey cover the main driving operations, including entering a main road,\novertaking, crossing intersections protected by traffic lights or signals, and\ndriving on freeways. The results presented reinforce the case for hybrid\nsolutions that incorporate mathematically elegant and robust decision methods\nthat are safe by design.",
        "subjects": [
            "cs.MA"
        ],
        "authors": [
            "Marius Bozga",
            "Joseph Sifakis"
        ],
        "published": "2024-05-20T12:58:25Z"
    },
    {
        "title": "GGAvatar: Geometric Adjustment of Gaussian Head Avatar",
        "link": "http://arxiv.org/abs/2405.11993v1",
        "abstract": "We propose GGAvatar, a novel 3D avatar representation designed to robustly\nmodel dynamic head avatars with complex identities and deformations. GGAvatar\nemploys a coarse-to-fine structure, featuring two core modules: Neutral\nGaussian Initialization Module and Geometry Morph Adjuster. Neutral Gaussian\nInitialization Module pairs Gaussian primitives with deformable triangular\nmeshes, employing an adaptive density control strategy to model the geometric\nstructure of the target subject with neutral expressions. Geometry Morph\nAdjuster introduces deformation bases for each Gaussian in global space,\ncreating fine-grained low-dimensional representations of deformation behaviors\nto address the Linear Blend Skinning formula's limitations effectively.\nExtensive experiments show that GGAvatar can produce high-fidelity renderings,\noutperforming state-of-the-art methods in visual quality and quantitative\nmetrics.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xinyang Li",
            "Jiaxin Wang",
            "Yixin Xuan",
            "Gongxin Yao",
            "Yu Pan"
        ],
        "published": "2024-05-20T12:54:57Z"
    },
    {
        "title": "DuckDB-SGX2: The Good, The Bad and The Ugly within Confidential\n  Analytical Query Processing",
        "link": "http://dx.doi.org/10.1145/3662010.3663447",
        "abstract": "We provide an evaluation of an analytical workload in a confidential\ncomputing environment, combining DuckDB with two technologies: modular columnar\nencryption in Parquet files (data at rest) and the newest version of the Intel\nSGX Trusted Execution Environment (TEE), providing a hardware enclave where\ndata in flight can be (more) securely decrypted and processed. One finding is\nthat the \"performance tax\" for such confidential analytical processing is\nacceptable compared to not using these technologies. We eventually manage to\nrun TPC-H SF30 with under 2x overhead compared to non-encrypted, non-enclave\nexecution; we show that, specifically, columnar compression and encryption are\na good combination. Our second finding consists of dos and don'ts to tune\nDuckDB to work effectively in this environment. There are various performance\nhazards: potentially 5x higher cache miss costs due to memory encryption inside\nthe enclave, NUMA penalties, and highly elevated cost of swapping pages in and\nout of the enclave -- which is also triggered indirectly by using a\nnon-SGX-aware malloc library.",
        "subjects": [
            "cs.DB"
        ],
        "authors": [
            "Ilaria Battiston",
            "Lotte Felius",
            "Sam Ansmink",
            "Laurens Kuiper",
            "Peter Boncz"
        ],
        "published": "2024-05-20T12:44:26Z"
    },
    {
        "title": "On Separation Logic, Computational Independence, and Pseudorandomness\n  (Extended Version)",
        "link": "http://arxiv.org/abs/2405.11987v1",
        "abstract": "Separation logic is a substructural logic which has proved to have numerous\nand fruitful applications to the verification of programs working on dynamic\ndata structures. Recently, Barthe, Hsu and Liao have proposed a new way of\ngiving semantics to separation logic formulas in which separating conjunction\nis interpreted in terms of probabilistic independence. The latter is taken in\nits exact form, i.e., two events are independent if and only if the joint\nprobability is the product of the probabilities of the two events. There is\nindeed a literature on weaker notions of independence which are computational\nin nature, i.e. independence holds only against efficient adversaries and\nmodulo a negligible probability of success. The aim of this work is to explore\nthe nature of computational independence in a cryptographic scenario, in view\nof the aforementioned advances in separation logic. We show on the one hand\nthat the semantics of separation logic can be adapted so as to account for\ncomplexity bounded adversaries, and on the other hand that the obtained logical\nsystem is useful for writing simple and compact proofs of standard\ncryptographic results in which the adversary remains hidden. Remarkably, this\nallows for a fruitful interplay between independence and pseudorandomness,\nitself a crucial notion in cryptography.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Ugo Dal Lago",
            "Davide Davoli",
            "Bruce M. Kapron"
        ],
        "published": "2024-05-20T12:39:28Z"
    },
    {
        "title": "Generalization Ability of Feature-based Performance Prediction Models: A\n  Statistical Analysis across Benchmarks",
        "link": "http://arxiv.org/abs/2405.12259v1",
        "abstract": "This study examines the generalization ability of algorithm performance\nprediction models across various benchmark suites. Comparing the statistical\nsimilarity between the problem collections with the accuracy of performance\nprediction models that are based on exploratory landscape analysis features, we\nobserve that there is a positive correlation between these two measures.\nSpecifically, when the high-dimensional feature value distributions between\ntraining and testing suites lack statistical significance, the model tends to\ngeneralize well, in the sense that the testing errors are in the same range as\nthe training errors. Two experiments validate these findings: one involving the\nstandard benchmark suites, the BBOB and CEC collections, and another using five\ncollections of affine combinations of BBOB problem instances.",
        "subjects": [
            "cs.LG",
            "cs.NE"
        ],
        "authors": [
            "Ana Nikolikj",
            "Ana Kostovska",
            "Gjorgjina Cenikj",
            "Carola Doerr",
            "Tome Eftimov"
        ],
        "published": "2024-05-20T12:39:24Z"
    },
    {
        "title": "Scheduling Jobs with Work-Inefficient Parallel Solutions",
        "link": "http://arxiv.org/abs/2405.11986v1",
        "abstract": "This paper introduces the \\emph{serial-parallel decision problem}. Consider\nan online scheduler that receives a series of tasks, where each task has both a\nparallel and a serial implementation. The parallel implementation has the\nadvantage that it can make progress concurrently on multiple processors, but\nthe disadvantage that it is (potentially) work-inefficient. As tasks arrive,\nthe scheduler must decide for each task which implementation to use.\n  We begin by studying \\emph{total awake time}. We give a simple\n\\emph{decide-on-arrival} scheduler that achieves a competitive ratio of $3$ for\ntotal awake time -- this scheduler makes serial/parallel decisions immediately\nwhen jobs arrive. Our second result is an \\emph{parallel-work-oblivious}\nscheduler that achieves a competitive ratio of $6$ for total awake time -- this\nscheduler makes all of its decisions based only on the size of each serial job\nand without needing to know anything about the parallel implementations.\nFinally, we prove a lower bound showing that, if a scheduler wishes to achieve\na competitive ratio of $O(1)$, it can have at most one of the two\naforementioned properties (decide-on-arrival or parallel-work-oblivious). We\nalso prove lower bounds of the form $1 + \\Omega(1)$ on the optimal competitive\nratio for any scheduler.\n  Next, we turn our attention to optimizing \\emph{mean response time}. Here, we\nshow that it is possible to achieve an $O(1)$ competitive ratio with $O(1)$\nspeed augmentation. This is the most technically involved of our results. We\nalso prove that, in this setting, it is not possible for a\nparallel-work-oblivious scheduler to do well.\n  In addition to these results, we present tight bounds on the optimal\ncompetitive ratio if we allow for arrival dependencies between tasks (e.g.,\ntasks are components of a single parallel program), and we give an in-depth\ndiscussion of the remaining open questions.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "William Kuszmaul",
            "Alek Westover"
        ],
        "published": "2024-05-20T12:36:20Z"
    },
    {
        "title": "MTVQA: Benchmarking Multilingual Text-Centric Visual Question Answering",
        "link": "http://arxiv.org/abs/2405.11985v1",
        "abstract": "Text-Centric Visual Question Answering (TEC-VQA) in its proper format not\nonly facilitates human-machine interaction in text-centric visual environments\nbut also serves as a de facto gold proxy to evaluate AI models in the domain of\ntext-centric scene understanding. However, most TEC-VQA benchmarks have focused\non high-resource languages like English and Chinese. Despite pioneering works\nto expand multilingual QA pairs in non-text-centric VQA datasets using\ntranslation engines, the translation-based protocol encounters a substantial\n``Visual-textual misalignment'' problem when applied to TEC-VQA. Specifically,\nit prioritizes the text in question-answer pairs while disregarding the visual\ntext present in images. Furthermore, it does not adequately tackle challenges\nrelated to nuanced meaning, contextual distortion, language bias, and\nquestion-type diversity. In this work, we address the task of multilingual\nTEC-VQA and provide a benchmark with high-quality human expert annotations in 9\ndiverse languages, called MTVQA. To our knowledge, MTVQA is the first\nmultilingual TEC-VQA benchmark to provide human expert annotations for\ntext-centric scenarios. Further, by evaluating several state-of-the-art\nMultimodal Large Language Models (MLLMs), including GPT-4V, on our MTVQA\ndataset, it is evident that there is still room for performance improvement,\nunderscoring the value of our dataset. We hope this dataset will provide\nresearchers with fresh perspectives and inspiration within the community. The\nMTVQA dataset will be available at\nhttps://huggingface.co/datasets/ByteDance/MTVQA.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jingqun Tang",
            "Qi Liu",
            "Yongjie Ye",
            "Jinghui Lu",
            "Shu Wei",
            "Chunhui Lin",
            "Wanqing Li",
            "Mohamad Fitri Faiz Bin Mahmood",
            "Hao Feng",
            "Zhen Zhao",
            "Yanjie Wang",
            "Yuliang Liu",
            "Hao Liu",
            "Xiang Bai",
            "Can Huang"
        ],
        "published": "2024-05-20T12:35:01Z"
    },
    {
        "title": "A fully discrete evolving surface finite element method for the\n  Cahn-Hilliard equation with a regular potential",
        "link": "http://arxiv.org/abs/2405.11984v1",
        "abstract": "We study two fully discrete evolving surface finite element schemes for the\nCahn-Hilliard equation on an evolving surface, given a smooth potential with\npolynomial growth. In particular we establish optimal order error bounds for a\n(fully implicit) backward Euler time-discretisation, and an implicit-explicit\ntime-discretisation, with isoparametric surface finite elements discretising\nspace.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "65M60 (Primary), 65M15, 35K58 (Secondary)"
        ],
        "authors": [
            "Charles M. Elliott",
            "Thomas Sales"
        ],
        "published": "2024-05-20T12:34:17Z"
    },
    {
        "title": "A review on the use of large language models as virtual tutors",
        "link": "http://dx.doi.org/10.1007/s11191-024-00530-2",
        "abstract": "Transformer architectures contribute to managing long-term dependencies for\nNatural Language Processing, representing one of the most recent changes in the\nfield. These architectures are the basis of the innovative, cutting-edge Large\nLanguage Models (LLMs) that have produced a huge buzz in several fields and\nindustrial sectors, among the ones education stands out. Accordingly, these\ngenerative Artificial Intelligence-based solutions have directed the change in\ntechniques and the evolution in educational methods and contents, along with\nnetwork infrastructure, towards high-quality learning. Given the popularity of\nLLMs, this review seeks to provide a comprehensive overview of those solutions\ndesigned specifically to generate and evaluate educational materials and which\ninvolve students and teachers in their design or experimental plan. To the best\nof our knowledge, this is the first review of educational applications (e.g.,\nstudent assessment) of LLMs. As expected, the most common role of these systems\nis as virtual tutors for automatic question generation. Moreover, the most\npopular models are GTP-3 and BERT. However, due to the continuous launch of new\ngenerative models, new works are expected to be published shortly.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Silvia García-Méndez",
            "Francisco de Arriba-Pérez",
            "María del Carmen Somoza-López"
        ],
        "published": "2024-05-20T12:33:42Z"
    },
    {
        "title": "Robust Deep Reinforcement Learning with Adaptive Adversarial\n  Perturbations in Action Space",
        "link": "http://arxiv.org/abs/2405.11982v1",
        "abstract": "Deep reinforcement learning (DRL) algorithms can suffer from modeling errors\nbetween the simulation and the real world. Many studies use adversarial\nlearning to generate perturbation during training process to model the\ndiscrepancy and improve the robustness of DRL. However, most of these\napproaches use a fixed parameter to control the intensity of the adversarial\nperturbation, which can lead to a trade-off between average performance and\nrobustness. In fact, finding the optimal parameter of the perturbation is\nchallenging, as excessive perturbations may destabilize training and compromise\nagent performance, while insufficient perturbations may not impart enough\ninformation to enhance robustness. To keep the training stable while improving\nrobustness, we propose a simple but effective method, namely, Adaptive\nAdversarial Perturbation (A2P), which can dynamically select appropriate\nadversarial perturbations for each sample. Specifically, we propose an adaptive\nadversarial coefficient framework to adjust the effect of the adversarial\nperturbation during training. By designing a metric for the current intensity\nof the perturbation, our method can calculate the suitable perturbation levels\nbased on the current relative performance. The appealing feature of our method\nis that it is simple to deploy in real-world applications and does not require\naccessing the simulator in advance. The experiments in MuJoCo show that our\nmethod can improve the training stability and learn a robust policy when\nmigrated to different test environments. The code is available at\nhttps://github.com/Lqm00/A2P-SAC.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Qianmei Liu",
            "Yufei Kuang",
            "Jie Wang"
        ],
        "published": "2024-05-20T12:31:11Z"
    },
    {
        "title": "RNG: Reducing Multi-level Noise and Multi-grained Semantic Gap for Joint\n  Multimodal Aspect-Sentiment Analysis",
        "link": "http://arxiv.org/abs/2405.13059v1",
        "abstract": "As an important multimodal sentiment analysis task, Joint Multimodal\nAspect-Sentiment Analysis (JMASA), aiming to jointly extract aspect terms and\ntheir associated sentiment polarities from the given text-image pairs, has\ngained increasing concerns. Existing works encounter two limitations: (1)\nmulti-level modality noise, i.e., instance- and feature-level noise; and (2)\nmulti-grained semantic gap, i.e., coarse- and fine-grained gap. Both issues may\ninterfere with accurate identification of aspect-sentiment pairs. To address\nthese limitations, we propose a novel framework named RNG for JMASA.\nSpecifically, to simultaneously reduce multi-level modality noise and\nmulti-grained semantic gap, we design three constraints: (1) Global Relevance\nConstraint (GR-Con) based on text-image similarity for instance-level noise\nreduction, (2) Information Bottleneck Constraint (IB-Con) based on the\nInformation Bottleneck (IB) principle for feature-level noise reduction, and\n(3) Semantic Consistency Constraint (SC-Con) based on mutual information\nmaximization in a contrastive learning way for multi-grained semantic gap\nreduction. Extensive experiments on two datasets validate our new\nstate-of-the-art performance.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Yaxin Liu",
            "Yan Zhou",
            "Ziming Li",
            "Jinchuan Zhang",
            "Yu Shang",
            "Chenyang Zhang",
            "Songlin Hu"
        ],
        "published": "2024-05-20T12:18:46Z"
    },
    {
        "title": "SM-DTW: Stability Modulated Dynamic Time Warping for signature\n  verification",
        "link": "http://dx.doi.org/10.1016/j.patrec.2018.07.029",
        "abstract": "Building upon findings in computational model of handwriting learning and\nexecution, we introduce the concept of stability to explain the difference\nbetween the actual movements performed during multiple execution of the\nsubject's signature, and conjecture that the most stable parts of the signature\nshould play a paramount role in evaluating the similarity between a questioned\nsignature and the reference ones during signature verification. We then\nintroduce the Stability Modulated Dynamic Time Warping algorithm for\nincorporating the stability regions, i.e. the most similar parts between two\nsignatures, into the distance measure between a pair of signatures computed by\nthe Dynamic Time Warping for signature verification. Experiments were conducted\non two datasets largely adopted for performance evaluation. Experimental\nresults show that the proposed algorithm improves the performance of the\nbaseline system and compares favourably with other top performing signature\nverification systems.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Antonio Parziale",
            "Moises Diaz",
            "Miguel A. Ferrer",
            "Angelo Marcelli"
        ],
        "published": "2024-05-20T12:18:15Z"
    },
    {
        "title": "GuidedRec: Guiding Ill-Posed Unsupervised Volumetric Recovery",
        "link": "http://arxiv.org/abs/2405.11977v1",
        "abstract": "We introduce a novel unsupervised approach to reconstructing a 3D volume from\nonly two planar projections that exploits a previous\\-ly-captured 3D volume of\nthe patient. Such volume is readily available in many important medical\nprocedures and previous methods already used such a volume. Earlier methods\nthat work by deforming this volume to match the projections typically fail when\nthe number of projections is very low as the alignment becomes\nunderconstrained. We show how to use a generative model of the volume\nstructures to constrain the deformation and obtain a correct estimate.\nMoreover, our method is not bounded to a specific sensor calibration and can be\napplied to new calibrations without retraining. We evaluate our approach on a\nchallenging dataset and show it outperforms state-of-the-art methods. As a\nresult, our method could be used in treatment scenarios such as surgery and\nradiotherapy while drastically reducing patient radiation exposure.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Alexandre Cafaro",
            "Amaury Leroy",
            "Guillaume Beldjoudi",
            "Pauline Maury",
            "Charlotte Robert",
            "Eric Deutsch",
            "Vincent Grégoire",
            "Vincent Lepetit",
            "Nikos Paragios"
        ],
        "published": "2024-05-20T12:13:22Z"
    },
    {
        "title": "Position-Guided Prompt Learning for Anomaly Detection in Chest X-Rays",
        "link": "http://arxiv.org/abs/2405.11976v1",
        "abstract": "Anomaly detection in chest X-rays is a critical task. Most methods mainly\nmodel the distribution of normal images, and then regard significant deviation\nfrom normal distribution as anomaly. Recently, CLIP-based methods, pre-trained\non a large number of medical images, have shown impressive performance on\nzero/few-shot downstream tasks. In this paper, we aim to explore the potential\nof CLIP-based methods for anomaly detection in chest X-rays. Considering the\ndiscrepancy between the CLIP pre-training data and the task-specific data, we\npropose a position-guided prompt learning method. Specifically, inspired by the\nfact that experts diagnose chest X-rays by carefully examining distinct lung\nregions, we propose learnable position-guided text and image prompts to adapt\nthe task data to the frozen pre-trained CLIP-based model. To enhance the\nmodel's discriminative capability, we propose a novel structure-preserving\nanomaly synthesis method within chest x-rays during the training process.\nExtensive experiments on three datasets demonstrate that our proposed method\noutperforms some state-of-the-art methods. The code of our implementation is\navailable at https://github.com/sunzc-sunny/PPAD.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhichao Sun",
            "Yuliang Gu",
            "Yepeng Liu",
            "Zerui Zhang",
            "Zhou Zhao",
            "Yongchao Xu"
        ],
        "published": "2024-05-20T12:11:41Z"
    },
    {
        "title": "A Stochastic Sampling Approach to Privacy",
        "link": "http://arxiv.org/abs/2405.11975v2",
        "abstract": "This paper proposes an optimal stochastic sampling approach to privacy, in\nwhich a sensor observes a process which is correlated to private information,\nand a sampler decides to keep or discard the sensor's observations. The kept\nsamples are shared with an adversary who might attempt to infer the private\nprocess. The privacy leakages are captured with the mutual information between\nthe private process and sampler's output. We cast the optimal sampling design\nas an optimization problem that (i) minimizes the reconstruction error of the\nobserved process using the sampler's output, (ii) and reduces privacy leakages.\nWe first show the optimal reconstruction is obtained by solving a one-step\noptimization problem at each time step. We derive the optimality equations of\nthe sampler for a general processes via the dynamic decomposition method, and\nshow the sampler controls adversary's belief about the private input. Also, we\npropose a simplified design for linear Gaussian processes by restricting the\nsampling policy to a special collection. We show that the optimal\nreconstruction of states, the belief state and the optimization objective can\nbe analytically expressed based on a conditional mean and covariance matrix. We\ndevelop an numerical algorithm to optimize the sampling and reconstruction\npolicies based on the implicit function theorem. Finally, we verify our design\nand show its capabilities in state reconstruction, privacy protection and data\nsize reduction via simulations.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Chuanghong Weng",
            "Ehsan Nekouei"
        ],
        "published": "2024-05-20T12:10:26Z"
    },
    {
        "title": "Data Augmentation for Text-based Person Retrieval Using Large Language\n  Models",
        "link": "http://arxiv.org/abs/2405.11971v1",
        "abstract": "Text-based Person Retrieval (TPR) aims to retrieve person images that match\nthe description given a text query. The performance improvement of the TPR\nmodel relies on high-quality data for supervised training. However, it is\ndifficult to construct a large-scale, high-quality TPR dataset due to expensive\nannotation and privacy protection. Recently, Large Language Models (LLMs) have\napproached or even surpassed human performance on many NLP tasks, creating the\npossibility to expand high-quality TPR datasets. This paper proposes an\nLLM-based Data Augmentation (LLM-DA) method for TPR. LLM-DA uses LLMs to\nrewrite the text in the current TPR dataset, achieving high-quality expansion\nof the dataset concisely and efficiently. These rewritten texts are able to\nincrease the diversity of vocabulary and sentence structure while retaining the\noriginal key concepts and semantic information. In order to alleviate the\nhallucinations of LLMs, LLM-DA introduces a Text Faithfulness Filter (TFF) to\nfilter out unfaithful rewritten text. To balance the contributions of original\ntext and augmented text, a Balanced Sampling Strategy (BSS) is proposed to\ncontrol the proportion of original text and augmented text used for training.\nLLM-DA is a plug-and-play method that can be easily integrated into various TPR\nmodels. Comprehensive experiments on three TPR benchmarks show that LLM-DA can\nimprove the retrieval performance of current TPR models.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zheng Li",
            "Lijia Si",
            "Caili Guo",
            "Yang Yang",
            "Qiushi Cao"
        ],
        "published": "2024-05-20T11:57:50Z"
    },
    {
        "title": "Conditional Shift-Robust Conformal Prediction for Graph Neural Network",
        "link": "http://arxiv.org/abs/2405.11968v1",
        "abstract": "Graph Neural Networks (GNNs) have emerged as potent tools for predicting\noutcomes in graph-structured data. Despite their efficacy, a significant\ndrawback of GNNs lies in their limited ability to provide robust uncertainty\nestimates, posing challenges to their reliability in contexts where errors\ncarry significant consequences. Moreover, GNNs typically excel in\nin-distribution settings, assuming that training and test data follow identical\ndistributions: a condition often unmet in real-world graph data scenarios. In\nthis article, we leverage conformal prediction, a widely recognized statistical\ntechnique for quantifying uncertainty by transforming predictive model outputs\ninto prediction sets, to address uncertainty quantification in GNN predictions\namidst conditional shift \\footnote{Representing the change in conditional\nprobability distribution $P(label |input)$ from source domain to target\ndomain.} in graph-based semi-supervised learning (SSL). Additionally, we\npropose a novel loss function aimed at refining model predictions by minimizing\nconditional shift in latent stages. Termed Conditional Shift Robust (CondSR)\nconformal prediction for GNNs, our approach CondSR is model-agnostic and\nadaptable to various classification models. We validate the effectiveness of\nour method on standard graph benchmark datasets, integrating it with\nstate-of-the-art GNNs in node classification tasks. The code implementation is\npublicly available for further exploration and experimentation.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "NA"
        ],
        "authors": [
            "S. Akansha"
        ],
        "published": "2024-05-20T11:47:31Z"
    },
    {
        "title": "Recommender Algorithm for Supporting Self-Management of CVD Risk Factors\n  in an Adult Population at Home",
        "link": "http://arxiv.org/abs/2405.11967v1",
        "abstract": "One of the new trends in the development of recommendation algorithms is the\ndissemination of their capabilities to support the population in managing their\nhealth. This article focuses on the problem of improving the effectiveness of\ncardiovascular diseases (CVD) prevention, since CVD is the leading cause of\ndeath worldwide. To address this issue, a knowledge-based recommendation\nalgorithm was proposed to support self-management of CVD risk factors in adults\nat home. The proposed algorithm is based on the original multidimensional\nrecommendation model and on a new user profile model, which includes predictive\nassessments of CVD health in addition to its current ones as outlined in\nofficial guidelines. The main feature of the proposed algorithm is the\ncombination of rule-based logic with the capabilities of a large language model\nin generating human-like text for explanatory component of multidimensional\nrecommendation. The verification and evaluation of the proposed algorithm\nshowed the usefulness of the proposed recommendation algorithm for supporting\nadults in self-management of their CVD risk factors at home. As follows from\nthe comparison with similar knowledge-based recommendation algorithms, the\nproposed algorithm evaluates a larger number of CVD risk factors and has a\ngreater information and semantic capacity of the generated recommendations.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "I.2, J.3"
        ],
        "authors": [
            "Tatiana V. Afanasieva",
            "Pavel V. Platov",
            "Anastasia I. Medvedeva"
        ],
        "published": "2024-05-20T11:47:19Z"
    },
    {
        "title": "Multiple-Choice Questions are Efficient and Robust LLM Evaluators",
        "link": "http://arxiv.org/abs/2405.11966v2",
        "abstract": "We present GSM-MC and MATH-MC, two multiple-choice (MC) datasets constructed\nby collecting answers and incorrect predictions on GSM8K and MATH from over 50\nopen-source models. Through extensive experiments, we show that LLMs'\nperformance on the MC versions of these two popular benchmarks is strongly\ncorrelated with their performance on the original versions, and is quite robust\nto distractor choices and option orders, while the evaluation time is reduced\nby a factor of up to 30. Following a similar procedure, we also introduce\nPythonIO, a new program output prediction MC dataset constructed from two other\npopular LLM evaluation benchmarks HumanEval and MBPP. Our data and code are\navailable at https://github.com/Geralt-Targaryen/MC-Evaluation.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Ziyin Zhang",
            "Lizhen Xu",
            "Zhaokun Jiang",
            "Hongkun Hao",
            "Rui Wang"
        ],
        "published": "2024-05-20T11:47:13Z"
    },
    {
        "title": "Scientific Hypothesis Generation by a Large Language Model: Laboratory\n  Validation in Breast Cancer Treatment",
        "link": "http://arxiv.org/abs/2405.12258v1",
        "abstract": "Large language models (LLMs) have transformed AI and achieved breakthrough\nperformance on a wide range of tasks that require human intelligence. In\nscience, perhaps the most interesting application of LLMs is for hypothesis\nformation. A feature of LLMs, which results from their probabilistic structure,\nis that the output text is not necessarily a valid inference from the training\ntext. These are 'hallucinations', and are a serious problem in many\napplications. However, in science, hallucinations may be useful: they are novel\nhypotheses whose validity may be tested by laboratory experiments. Here we\nexperimentally test the use of LLMs as a source of scientific hypotheses using\nthe domain of breast cancer treatment. We applied the LLM GPT4 to hypothesize\nnovel pairs of FDA-approved non-cancer drugs that target the MCF7 breast cancer\ncell line relative to the non-tumorigenic breast cell line MCF10A. In the first\nround of laboratory experiments GPT4 succeeded in discovering three drug\ncombinations (out of 12 tested) with synergy scores above the positive\ncontrols. These combinations were itraconazole + atenolol, disulfiram +\nsimvastatin and dipyridamole + mebendazole. GPT4 was then asked to generate new\ncombinations after considering its initial results. It then discovered three\nmore combinations with positive synergy scores (out of four tested), these were\ndisulfiram + fulvestrant, mebendazole + quinacrine and disulfiram + quinacrine.\nA limitation of GPT4 as a generator of hypotheses was that its explanations for\nthem were formulaic and unconvincing. We conclude that LLMs are an exciting\nnovel source of scientific hypotheses.",
        "subjects": [
            "q-bio.QM",
            "cs.LG",
            "q-bio.CB"
        ],
        "authors": [
            "Abbi Abdel-Rehim",
            "Hector Zenil",
            "Oghenejokpeme Orhobor",
            "Marie Fisher",
            "Ross J. Collins",
            "Elizabeth Bourne",
            "Gareth W. Fearnley",
            "Emma Tate",
            "Holly X. Smith",
            "Larisa N. Soldatova",
            "Ross D. King"
        ],
        "published": "2024-05-20T11:40:23Z"
    },
    {
        "title": "No Free Lunch: Research Software Testing in Teaching",
        "link": "http://arxiv.org/abs/2405.11965v1",
        "abstract": "Software is at the core of most scientific discoveries today. Therefore, the\nquality of research results highly depends on the quality of the research\nsoftware. Rigorous testing, as we know it from software engineering in the\nindustry, could ensure the quality of the research software but it also\nrequires a substantial effort that is often not rewarded in academia.\nTherefore, this research explores the effects of research software testing\nintegrated into teaching on research software. In an in-vivo experiment, we\nintegrated the engineering of a test suite for a large-scale network simulation\nas group projects into a course on software testing at the Blekinge Institute\nof Technology, Sweden, and qualitatively measured the effects of this\nintegration on the research software. We found that the research software\nbenefited from the integration through substantially improved documentation and\nfewer hardware and software dependencies. However, this integration was\neffortful and although the student teams developed elegant and thoughtful test\nsuites, no code by students went directly into the research software since we\nwere not able to make the integration back into the research software\nobligatory or even remunerative. Although we strongly believe that integrating\nresearch software engineering such as testing into teaching is not only\nvaluable for the research software itself but also for students, the research\nof the next generation, as they get in touch with research software engineering\nand bleeding-edge research in their field as part of their education, the\nuncertainty about the intellectual properties of students' code substantially\nlimits the potential of integrating research software testing into teaching.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Michael Dorner",
            "Andreas Bauer",
            "Florian Angermeir"
        ],
        "published": "2024-05-20T11:40:01Z"
    },
    {
        "title": "Quantifying Individual and Joint Module Impact in Modular Optimization\n  Frameworks",
        "link": "http://arxiv.org/abs/2405.11964v1",
        "abstract": "This study explores the influence of modules on the performance of modular\noptimization frameworks for continuous single-objective black-box optimization.\nThere is an extensive variety of modules to choose from when designing\nalgorithm variants, however, there is a rather limited understanding of how\neach module individually influences the algorithm performance and how the\nmodules interact with each other when combined. We use the functional ANOVA\n(f-ANOVA) framework to quantify the influence of individual modules and module\ncombinations for two algorithms, the modular Covariance Matrix Adaptation\n(modCMA) and the modular Differential Evolution (modDE). We analyze the\nperformance data from 324 modCMA and 576 modDE variants on the BBOB benchmark\ncollection, for two problem dimensions, and three computational budgets.\nNoteworthy findings include the identification of important modules that\nstrongly influence the performance of modCMA, such as the~\\textit{weights\\\noption} and~\\textit{mirrored} modules for low dimensional problems, and\nthe~\\textit{base\\ sampler} for high dimensional problems. The large individual\ninfluence of the~\\textit{lpsr} module makes it very important for the\nperformance of modDE, regardless of the problem dimensionality and the\ncomputational budget. When comparing modCMA and modDE, modDE undergoes a shift\nfrom individual modules being more influential, to module combinations being\nmore influential, while modCMA follows the opposite pattern, with an increase\nin problem dimensionality and computational budget.",
        "subjects": [
            "cs.NE"
        ],
        "authors": [
            "Ana Nikolikj",
            "Ana Kostovska",
            "Diederick Vermetten",
            "Carola Doerr",
            "Tome Eftimov"
        ],
        "published": "2024-05-20T11:39:55Z"
    },
    {
        "title": "A Simulation Tool for V2G Enabled Demand Response Based on Model\n  Predictive Control",
        "link": "http://arxiv.org/abs/2405.11963v1",
        "abstract": "Integrating electric vehicles (EVs) into the power grid can revolutionize\nenergy management strategies, offering both challenges and opportunities for\ncreating a more sustainable and resilient grid. In this context, model\npredictive control (MPC) emerges as a powerful tool for addressing the\ncomplexities of Grid-to-vehicle (G2V) and vehicle-to-grid (V2G) enabled demand\nresponse management. By leveraging advanced optimization techniques, MPC\nalgorithms can anticipate future grid conditions and dynamically adjust EV\ncharging and discharging schedules to balance supply and demand while\nminimizing operational costs and maximizing flexibility. However, no standard\ntools exist to evaluate novel energy management strategies based on MPC\napproaches. Our research focuses on harnessing the potential of MPC in G2V and\nV2G applications, by providing a simulation tool that allows to maximize EV\nflexibility and support demand response initiatives while mitigating the impact\non EV battery health. In this paper, we propose an open-source MPC controller\nfor G2V and V2G-enabled demand response management. The proposed approach is\ncapable of tackling the uncertainties inherent in demand response operations.\nThrough extensive simulation and analysis, we demonstrate the efficacy of our\napproach in maximizing the benefits of G2V and V2G while assessing the impact\non the longevity and reliability of EV batteries. Specifically, our controller\nenables Charge Point Operators (CPOs) to optimize EV charging and discharging\nschedules in real-time, taking into account fluctuating energy prices, grid\nconstraints, and EV user preferences.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Cesar Diaz-Londono",
            "Stavros Orfanoudakis",
            "Pedro P. Vergara",
            "Peter Palensky",
            "Fredy Ruiz",
            "Giambattista Gruosso"
        ],
        "published": "2024-05-20T11:37:29Z"
    },
    {
        "title": "Subspace embedding with random Khatri-Rao products and its application\n  to eigensolvers",
        "link": "http://arxiv.org/abs/2405.11962v1",
        "abstract": "Various iterative eigenvalue solvers have been developed to compute parts of\nthe spectrum for a large sparse matrix, including the power method, Krylov\nsubspace methods, contour integral methods, and preconditioned solvers such as\nthe so called LOBPCG method. All of these solvers rely on random matrices to\ndetermine, e.g., starting vectors that have, with high probability, a\nnon-negligible overlap with the eigenvectors of interest. For this purpose, a\nsafe and common choice are unstructured Gaussian random matrices. In this work,\nwe investigate the use of random Khatri-Rao products in eigenvalue solvers. On\nthe one hand, we establish a novel subspace embedding property that provides\ntheoretical justification for the use of such structured random matrices. On\nthe other hand, we highlight the potential algorithmic benefits when solving\neigenvalue problems with Kronecker product structure, as they arise frequently\nfrom the discretization of eigenvalue problems for differential operators on\ntensor product domains. In particular, we consider the use of random Khatri-Rao\nproducts within a contour integral method and LOBPCG. Numerical experiments\nindicate that the gains for the contour integral method strongly depend on the\nability to efficiently and accurately solve (shifted) matrix equations with\nlow-rank right-hand side. The flexibility of LOBPCG to directly employ\npreconditioners makes it easier to benefit from Khatri-Rao product structure,\nat the expense of having less theoretical justification.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Zvonimir Bujanović",
            "Luka Grubišić",
            "Daniel Kressner",
            "Hei Yin Lam"
        ],
        "published": "2024-05-20T11:37:24Z"
    },
    {
        "title": "Dynamic classifier auditing by unsupervised anomaly detection methods:\n  an application in packaging industry predictive maintenance",
        "link": "http://arxiv.org/abs/2405.11960v1",
        "abstract": "Predictive maintenance in manufacturing industry applications is a\nchallenging research field. Packaging machines are widely used in a large\nnumber of logistic companies' warehouses and must be working uninterruptedly.\nTraditionally, preventive maintenance strategies have been carried out to\nimprove the performance of these machines. However, this kind of policies does\nnot take into account the information provided by the sensors implemented in\nthe machines. This paper presents an expert system for the automatic estimation\nof work orders to implement predictive maintenance policies for packaging\nmachines. The key idea is that, from a set of alarms related to sensors\nimplemented in the machine, the expert system should take a maintenance action\nwhile optimizing the response time. The work order estimator will act as a\nclassifier, yielding a binary decision of whether a machine must undergo a\nmaintenance action by a technician or not, followed by an unsupervised anomaly\ndetection-based filtering stage to audit the classifier's output. The methods\nused for anomaly detection were: One-Class Support Vector Machine (OCSVM),\nMinimum Covariance Determinant (MCD) and a majority (hard) voting ensemble of\nthem. All anomaly detection methods improve the performance of the baseline\nclassifer but the best performance in terms of F1 score was obtained by the\nmajority voting ensemble.",
        "subjects": [
            "cs.CE"
        ],
        "authors": [
            "Fernando Mateo",
            "Joan Vila-Francés",
            "Emilio Soria-Olivas",
            "Marcelino Martínez-Sober Juan Gómez-Sanchis",
            "Antonio-José Serrano-López"
        ],
        "published": "2024-05-20T11:36:37Z"
    },
    {
        "title": "Exploring Commonalities in Explanation Frameworks: A Multi-Domain Survey\n  Analysis",
        "link": "http://arxiv.org/abs/2405.11958v1",
        "abstract": "This study presents insights gathered from surveys and discussions with\nspecialists in three domains, aiming to find essential elements for a universal\nexplanation framework that could be applied to these and other similar use\ncases. The insights are incorporated into a software tool that utilizes GP\nalgorithms, known for their interpretability. The applications analyzed include\na medical scenario (involving predictive ML), a retail use case (involving\nprescriptive ML), and an energy use case (also involving predictive ML). We\ninterviewed professionals from each sector, transcribing their conversations\nfor further analysis. Additionally, experts and non-experts in these fields\nfilled out questionnaires designed to probe various dimensions of explanatory\nmethods. The findings indicate a universal preference for sacrificing a degree\nof accuracy in favor of greater explainability. Additionally, we highlight the\nsignificance of feature importance and counterfactual explanations as critical\ncomponents of such a framework. Our questionnaires are publicly available to\nfacilitate the dissemination of knowledge in the field of XAI.",
        "subjects": [
            "cs.LG",
            "cs.HC"
        ],
        "authors": [
            "Eduard Barbu",
            "Marharytha Domnich",
            "Raul Vicente",
            "Nikos Sakkas",
            "André Morim"
        ],
        "published": "2024-05-20T11:28:32Z"
    },
    {
        "title": "PET: Multi-agent Independent PPO-based Automatic ECN Tuning for\n  High-Speed Data Center Networks",
        "link": "http://arxiv.org/abs/2405.11956v1",
        "abstract": "Explicit Congestion Notification (ECN)-based congestion control schemes have\nbeen widely adopted in high-speed data center networks (DCNs), where the ECN\nmarking threshold plays a determinant role in guaranteeing a packet lossless\nDCN. However, existing approaches either employ static settings with immutable\nthresholds that cannot be dynamically self-adjusted to adapt to network\ndynamics, or fail to take into account many-to-one traffic patterns and\ndifferent requirements of different types of traffic, resulting in relatively\npoor performance. To address these problems, this paper proposes a novel\nlearning-based automatic ECN tuning scheme, named PET, based on the multi-agent\nIndependent Proximal Policy Optimization (IPPO) algorithm. PET dynamically\nadjusts ECN thresholds by fully considering pivotal congestion-contributing\nfactors, including queue length, output data rate, output rate of ECN-marked\npackets, current ECN threshold, the extent of incast, and the ratio of mice and\nelephant flows. PET adopts the Decentralized Training and Decentralized\nExecution (DTDE) paradigm and combines offline and online training to\naccommodate network dynamics. PET is also fair and readily deployable with\ncommodity hardware. Comprehensive experimental results demonstrate that,\ncompared with state-of-the-art static schemes and the learning-based automatic\nscheme, our PET achieves better performance in terms of flow completion time,\nconvergence rate, queue length variance, and system robustness.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Kai Cheng",
            "Ting Wang",
            "Xiao Du",
            "Shuyi Du",
            "Haibin Cai"
        ],
        "published": "2024-05-20T11:22:03Z"
    },
    {
        "title": "Shallow Recurrent Decoder for Reduced Order Modeling of Plasma Dynamics",
        "link": "http://arxiv.org/abs/2405.11955v1",
        "abstract": "Reduced order models are becoming increasingly important for rendering\ncomplex and multiscale spatio-temporal dynamics computationally tractable. The\ncomputational efficiency of such surrogate models is especially important for\ndesign, exhaustive exploration and physical understanding. Plasma simulations,\nin particular those applied to the study of ${\\bf E}\\times {\\bf B}$ plasma\ndischarges and technologies, such as Hall thrusters, require substantial\ncomputational resources in order to resolve the multidimentional dynamics that\nspan across wide spatial and temporal scales. Although high-fidelity\ncomputational tools are available to simulate such systems over limited\nconditions and in highly simplified geometries, simulations of full-size\nsystems and/or extensive parametric studies over many geometric configurations\nand under different physical conditions are computationally intractable with\nconventional numerical tools. Thus, scientific studies and industrially\noriented modeling of plasma systems, including the important ${\\bf E}\\times\n{\\bf B}$ technologies, stand to significantly benefit from reduced order\nmodeling algorithms. We develop a model reduction scheme based upon a {\\em\nShallow REcurrent Decoder} (SHRED) architecture. The scheme uses a neural\nnetwork for encoding limited sensor measurements in time (sequence-to-sequence\nencoding) to full state-space reconstructions via a decoder network. Based upon\nthe theory of separation of variables, the SHRED architecture is capable of (i)\nreconstructing full spatio-temporal fields with as little as three point\nsensors, even the fields that are not measured with sensor feeds but that are\nin dynamic coupling with the measured field, and (ii) forecasting the future\nstate of the system using neural network roll-outs from the trained time\nencoding model.",
        "subjects": [
            "physics.plasm-ph",
            "cs.LG",
            "nlin.PS",
            "physics.comp-ph"
        ],
        "authors": [
            "J. Nathan Kutz",
            "Maryam Reza",
            "Farbod Faraji",
            "Aaron Knoll"
        ],
        "published": "2024-05-20T11:21:23Z"
    },
    {
        "title": "The AI Community Building the Future? A Quantitative Analysis of\n  Development Activity on Hugging Face Hub",
        "link": "http://arxiv.org/abs/2405.13058v1",
        "abstract": "Open source developers have emerged as key actors in the political economy of\nartificial intelligence (AI), with open model development being recognised as\nan alternative to closed-source AI development. However, we still have a\nlimited understanding of collaborative practices in open source AI. This paper\nresponds to this gap with a three-part quantitative analysis of development\nactivity on the Hugging Face (HF) Hub, a popular platform for building,\nsharing, and demonstrating models. First, we find that various types of\nactivity across 348,181 model, 65,761 dataset, and 156,642 space repositories\nexhibit right-skewed distributions. Activity is extremely imbalanced between\nrepositories; for example, over 70% of models have 0 downloads, while 1%\naccount for 99% of downloads. Second, we analyse a snapshot of the social\nnetwork structure of collaboration on models, finding that the community has a\ncore-periphery structure, with a core of prolific developers and a majority of\nisolate developers (89%). Upon removing isolates, collaboration is\ncharacterised by high reciprocity regardless of developers' network positions.\nThird, we examine model adoption through the lens of model usage in spaces,\nfinding that a minority of models, developed by a handful of companies, are\nwidely used on the HF Hub. Overall, we find that various types of activity on\nthe HF Hub are characterised by Pareto distributions, congruent with prior\nobservations about OSS development patterns on platforms like GitHub. We\nconclude with a discussion of the implications of the findings and\nrecommendations for (open source) AI researchers, developers, and policymakers.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.CY",
            "cs.LG",
            "K.4.1"
        ],
        "authors": [
            "Cailean Osborne",
            "Jennifer Ding",
            "Hannah Rose Kirk"
        ],
        "published": "2024-05-20T11:10:49Z"
    },
    {
        "title": "Can Github issues be solved with Tree Of Thoughts?",
        "link": "http://arxiv.org/abs/2405.13057v1",
        "abstract": "While there have been extensive studies in code generation by large language\nmodels (LLM), where benchmarks like HumanEval have been surpassed with an\nimpressive 96.3% success rate, these benchmarks predominantly judge a model's\nperformance on basic function-level code generation and lack the critical\nthinking and concept of scope required of real-world scenarios such as solving\nGitHub issues. This research introduces the application of the Tree of Thoughts\n(ToT) language model reasoning framework for enhancing the decision-making and\nproblem-solving abilities of LLMs for this complex task. Compared to\ntraditional input-output (IO) prompting and Retrieval Augmented Generation\n(RAG) techniques, ToT is designed to improve performance by facilitating a\nstructured exploration of multiple reasoning trajectories and enabling\nself-assessment of potential solutions. We experimentally deploy ToT in\ntackling a Github issue contained within an instance of the SWE-bench. However,\nour results reveal that the ToT framework alone is not enough to give LLMs the\ncritical reasoning capabilities to outperform existing methods. In this paper\nwe analyze the potential causes of these shortcomings and identify key areas\nfor improvement such as deepening the thought process and introducing agentic\ncapabilities. The insights of this research are aimed at informing future\ndirections for refining the application of ToT and better harnessing the\npotential of LLMs in real-world problem-solving scenarios.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "authors": [
            "Ricardo La Rosa",
            "Corey Hulse",
            "Bangdi Liu"
        ],
        "published": "2024-05-20T11:05:56Z"
    },
    {
        "title": "Distinguished In Uniform: Self Attention Vs. Virtual Nodes",
        "link": "http://arxiv.org/abs/2405.11951v1",
        "abstract": "Graph Transformers (GTs) such as SAN and GPS are graph processing models that\ncombine Message-Passing GNNs (MPGNNs) with global Self-Attention. They were\nshown to be universal function approximators, with two reservations: 1. The\ninitial node features must be augmented with certain positional encodings. 2.\nThe approximation is non-uniform: Graphs of different sizes may require a\ndifferent approximating network.\n  We first clarify that this form of universality is not unique to GTs: Using\nthe same positional encodings, also pure MPGNNs and even 2-layer MLPs are\nnon-uniform universal approximators. We then consider uniform expressivity: The\ntarget function is to be approximated by a single network for graphs of all\nsizes. There, we compare GTs to the more efficient MPGNN + Virtual Node\narchitecture. The essential difference between the two model definitions is in\ntheir global computation method -- Self-Attention Vs Virtual Node. We prove\nthat none of the models is a uniform-universal approximator, before proving our\nmain result: Neither model's uniform expressivity subsumes the other's. We\ndemonstrate the theory with experiments on synthetic data. We further augment\nour study with real-world datasets, observing mixed results which indicate no\nclear ranking in practice as well.",
        "subjects": [
            "cs.LG",
            "68T05, 68T07",
            "I.2.6"
        ],
        "authors": [
            "Eran Rosenbluth",
            "Jan Tönshoff",
            "Martin Ritzert",
            "Berke Kisin",
            "Martin Grohe"
        ],
        "published": "2024-05-20T11:02:53Z"
    },
    {
        "title": "WisPerMed at BioLaySumm: Adapting Autoregressive Large Language Models\n  for Lay Summarization of Scientific Articles",
        "link": "http://arxiv.org/abs/2405.11950v1",
        "abstract": "This paper details the efforts of the WisPerMed team in the BioLaySumm2024\nShared Task on automatic lay summarization in the biomedical domain, aimed at\nmaking scientific publications accessible to non-specialists. Large language\nmodels (LLMs), specifically the BioMistral and Llama3 models, were fine-tuned\nand employed to create lay summaries from complex scientific texts. The\nsummarization performance was enhanced through various approaches, including\ninstruction tuning, few-shot learning, and prompt variations tailored to\nincorporate specific context information. The experiments demonstrated that\nfine-tuning generally led to the best performance across most evaluated\nmetrics. Few-shot learning notably improved the models' ability to generate\nrelevant and factually accurate texts, particularly when using a well-crafted\nprompt. Additionally, a Dynamic Expert Selection (DES) mechanism to optimize\nthe selection of text outputs based on readability and factuality metrics was\ndeveloped. Out of 54 participants, the WisPerMed team reached the 4th place,\nmeasured by readability, factuality, and relevance. Determined by the overall\nscore, our approach improved upon the baseline by approx. 5.5 percentage points\nand was only approx 1.5 percentage points behind the first place.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Tabea M. G. Pakull",
            "Hendrik Damm",
            "Ahmad Idrissi-Yaghir",
            "Henning Schäfer",
            "Peter A. Horn",
            "Christoph M. Friedrich"
        ],
        "published": "2024-05-20T10:54:47Z"
    },
    {
        "title": "FAME-MT Dataset: Formality Awareness Made Easy for Machine Translation\n  Purposes",
        "link": "http://arxiv.org/abs/2405.11942v1",
        "abstract": "People use language for various purposes. Apart from sharing information,\nindividuals may use it to express emotions or to show respect for another\nperson. In this paper, we focus on the formality level of machine-generated\ntranslations and present FAME-MT -- a dataset consisting of 11.2 million\ntranslations between 15 European source languages and 8 European target\nlanguages classified to formal and informal classes according to target\nsentence formality. This dataset can be used to fine-tune machine translation\nmodels to ensure a given formality level for each European target language\nconsidered. We describe the dataset creation procedure, the analysis of the\ndataset's quality showing that FAME-MT is a reliable source of language\nregister information, and we present a publicly available proof-of-concept\nmachine translation model that uses the dataset to steer the formality level of\nthe translation. Currently, it is the largest dataset of formality annotations,\nwith examples expressed in 112 European language pairs. The dataset is\npublished online: https://github.com/laniqo-public/fame-mt/ .",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Dawid Wiśniewski",
            "Zofia Rostek",
            "Artur Nowakowski"
        ],
        "published": "2024-05-20T10:35:30Z"
    },
    {
        "title": "Biomedical Entity Linking for Dutch: Fine-tuning a Self-alignment BERT\n  Model on an Automatically Generated Wikipedia Corpus",
        "link": "http://arxiv.org/abs/2405.11941v1",
        "abstract": "Biomedical entity linking, a main component in automatic information\nextraction from health-related texts, plays a pivotal role in connecting\ntextual entities (such as diseases, drugs and body parts mentioned by patients)\nto their corresponding concepts in a structured biomedical knowledge base. The\ntask remains challenging despite recent developments in natural language\nprocessing. This paper presents the first evaluated biomedical entity linking\nmodel for the Dutch language. We use MedRoBERTa.nl as base model and perform\nsecond-phase pretraining through self-alignment on a Dutch biomedical ontology\nextracted from the UMLS and Dutch SNOMED. We derive a corpus from Wikipedia of\nontology-linked Dutch biomedical entities in context and fine-tune our model on\nthis dataset. We evaluate our model on the Dutch portion of the Mantra\nGSC-corpus and achieve 54.7% classification accuracy and 69.8% 1-distance\naccuracy. We then perform a case study on a collection of unlabeled,\npatient-support forum data and show that our model is hampered by the limited\nquality of the preceding entity recognition step. Manual evaluation of small\nsample indicates that of the correctly extracted entities, around 65% is linked\nto the correct concept in the ontology. Our results indicate that biomedical\nentity linking in a language other than English remains challenging, but our\nDutch model can be used to for high-level analysis of patient-generated text.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Fons Hartendorp",
            "Tom Seinen",
            "Erik van Mulligen",
            "Suzan Verberne"
        ],
        "published": "2024-05-20T10:30:36Z"
    },
    {
        "title": "Optimal balanced-norm error estimate of the LDG method for\n  reaction-diffusion problems II: the two-dimensional case with layer-upwind\n  flux",
        "link": "http://arxiv.org/abs/2405.11939v1",
        "abstract": "A singularly perturbed reaction-diffusion problem posed on the unit square in\n$\\mathbb{R}^2$ is solved numerically by a local discontinuous Galerkin (LDG)\nfinite element method. Typical solutions of this class of problem exhibit\nboundary layers along the sides of the domain; these layers generally cause\ndifficulties for numerical methods. Our LDG method handles the boundary layers\nby using a Shishkin mesh and also introducing the new concept of a\n``layer-upwind flux\" -- a discrete flux whose values are chosen on the fine\nmesh (which lies inside the boundary layers) in the direction where the layer\nweakens. On the coarse mesh, one can use a standard central flux. No penalty\nterms are needed with these fluxes, unlike many other variants of the LDG\nmethod. Our choice of discrete flux makes it feasible to derive an\noptimal-order error analysis in a balanced norm; this norm is stronger than the\nusual energy norm and is a more appropriate measure for errors in computed\nsolutions for singularly perturbed reaction-diffusion problems. It will be\nproved that the LDG method is usually convergent of order $O((N^{-1}\\ln\nN)^{k+1})$ in the balanced norm, where $N$ is the number of mesh intervals in\neach coordinate direction and tensor-product piecewise polynomials of\ndegree~$k$ in each coordinate variable are used in the LDG method. This result\nis the first of its kind for the LDG method applied to this class of problem\nand is optimal for convergence on a Shishkin mesh. Its sharpness is confirmed\nby numerical experiments.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "65N15, 65N30"
        ],
        "authors": [
            "Yao Cheng",
            "Xuesong Wang",
            "Martin Stynes"
        ],
        "published": "2024-05-20T10:28:41Z"
    },
    {
        "title": "Chasing COMET: Leveraging Minimum Bayes Risk Decoding for Self-Improving\n  Machine Translation",
        "link": "http://arxiv.org/abs/2405.11937v1",
        "abstract": "This paper explores Minimum Bayes Risk (MBR) decoding for self-improvement in\nmachine translation (MT), particularly for domain adaptation and low-resource\nlanguages. We implement the self-improvement process by fine-tuning the model\non its MBR-decoded forward translations. By employing COMET as the MBR utility\nmetric, we aim to achieve the reranking of translations that better aligns with\nhuman preferences. The paper explores the iterative application of this\napproach and the potential need for language-specific MBR utility metrics. The\nresults demonstrate significant enhancements in translation quality for all\nexamined language pairs, including successful application to domain-adapted\nmodels and generalisation to low-resource settings. This highlights the\npotential of COMET-guided MBR for efficient MT self-improvement in various\nscenarios.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Kamil Guttmann",
            "Mikołaj Pokrywka",
            "Adrian Charkiewicz",
            "Artur Nowakowski"
        ],
        "published": "2024-05-20T10:25:03Z"
    },
    {
        "title": "UAV-VisLoc: A Large-scale Dataset for UAV Visual Localization",
        "link": "http://arxiv.org/abs/2405.11936v1",
        "abstract": "The application of unmanned aerial vehicles (UAV) has been widely extended\nrecently. It is crucial to ensure accurate latitude and longitude coordinates\nfor UAVs, especially when the global navigation satellite systems (GNSS) are\ndisrupted and unreliable. Existing visual localization methods achieve\nautonomous visual localization without error accumulation by matching the\nground-down view image of UAV with the ortho satellite maps. However,\ncollecting UAV ground-down view images across diverse locations is costly,\nleading to a scarcity of large-scale datasets for real-world scenarios.\nExisting datasets for UAV visual localization are often limited to small\ngeographic areas or are focused only on urban regions with distinct textures.\nTo address this, we define the UAV visual localization task by determining the\nUAV's real position coordinates on a large-scale satellite map based on the\ncaptured ground-down view. In this paper, we present a large-scale dataset,\nUAV-VisLoc, to facilitate the UAV visual localization task. This dataset\ncomprises images from diverse drones across 11 locations in China, capturing a\nrange of topographical features. The dataset features images from fixed-wing\ndrones and multi-terrain drones, captured at different altitudes and\norientations. Our dataset includes 6,742 drone images and 11 satellite maps,\nwith metadata such as latitude, longitude, altitude, and capture date. Our\ndataset is tailored to support both the training and testing of models by\nproviding a diverse and extensive data.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Wenjia Xu",
            "Yaxuan Yao",
            "Jiaqi Cao",
            "Zhiwei Wei",
            "Chunbo Liu",
            "Jiuniu Wang",
            "Mugen Peng"
        ],
        "published": "2024-05-20T10:24:10Z"
    },
    {
        "title": "A Flat Dual-Polarized Millimeter-Wave Luneburg Lens Antenna Using\n  Transformation Optics with Reduced Anisotropy and Impedance Mismatch",
        "link": "http://arxiv.org/abs/2405.11935v1",
        "abstract": "In this paper, a compact wideband dual-polarized Luneburg lens antenna (LLA)\nwith reduced anisotropy and improved impedance matching is proposed in Ka band\nwith a wide 2D beamscanning capability. Based on transformation optics, the\nspherical Luneburg lens is compressed into a cylindrical one, while the merits\nof high gain, broad band, wide scanning, and free polarization are preserved. A\ntrigonometric function is employed to the material property of the flattened\nLuneburg lens with reduced anisotropy, thus effectively alleviates the strong\nreflection, the high sidelobes and back radiation with a free cost on the\nantenna weight and volume. Furthermore, a light thin wideband 7-by-1\nmetasurface phased array is studied as the primary feed for the LLA. The\nproposed metantenna, shorted for metamaterial-based antenna, has a high\npotential for B5G, future wireless communication and radar sensing as an\nonboard system.",
        "subjects": [
            "eess.SY",
            "cs.SY",
            "physics.app-ph",
            "physics.optics"
        ],
        "authors": [
            "Yuanyan Su",
            "Teng Li",
            "Wei Hong",
            "Zhi Ning Chen",
            "Anja K. Skrivervik"
        ],
        "published": "2024-05-20T10:23:09Z"
    },
    {
        "title": "Nonequilbrium physics of generative diffusion models",
        "link": "http://arxiv.org/abs/2405.11932v1",
        "abstract": "Generative diffusion models apply the concept of Langevin dynamics in physics\nto machine leaning, attracting a lot of interest from industrial application,\nbut a complete picture about inherent mechanisms is still lacking. In this\npaper, we provide a transparent physics analysis of the diffusion models,\nderiving the fluctuation theorem, entropy production, Franz-Parisi potential to\nunderstand the intrinsic phase transitions discovered recently. Our analysis is\nrooted in non-equlibrium physics and concepts from equilibrium physics, i.e.,\ntreating both forward and backward dynamics as a Langevin dynamics, and\ntreating the reverse diffusion generative process as a statistical inference,\nwhere the time-dependent state variables serve as quenched disorder studied in\nspin glass theory. This unified principle is expected to guide machine learning\npractitioners to design better algorithms and theoretical physicists to link\nthe machine learning to non-equilibrium thermodynamics.",
        "subjects": [
            "cond-mat.stat-mech",
            "cond-mat.dis-nn",
            "cs.LG"
        ],
        "authors": [
            "Zhendong Yu",
            "Haiping Huang"
        ],
        "published": "2024-05-20T10:16:26Z"
    }
]