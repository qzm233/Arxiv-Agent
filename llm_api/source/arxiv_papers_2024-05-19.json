[
    {
        "title": "Fixed-parameter tractability of canonical polyadic decomposition over\n  finite fields",
        "link": "http://arxiv.org/abs/2405.11699v1",
        "abstract": "We present a simple proof that finding a rank-$R$ canonical polyadic\ndecomposition of 3-dimensional tensors over a finite field $\\mathbb{F}$ is\nfixed-parameter tractable with respect to $R$ and $\\mathbb{F}$. We also show\nsome more concrete upper bounds on the time complexity of this problem.",
        "subjects": [
            "cs.CC"
        ],
        "authors": [
            "Jason Yang"
        ],
        "published": "2024-05-19T23:31:04Z"
    },
    {
        "title": "Multi-Objective Learning Model Predictive Control",
        "link": "http://arxiv.org/abs/2405.11698v1",
        "abstract": "Multi-Objective Learning Model Predictive Control is a novel data-driven\ncontrol scheme which improves a system's closed-loop performance with respect\nto several control objectives over iterations of a repeated task. At each task\niteration, collected system data is used to construct terminal components of a\nModel Predictive Controller. The formulation presented in this paper ensures\nthat closed-loop control performance improves between successive iterations\nwith respect to each objective. We provide proofs of recursive feasibility and\nperformance improvement, and show that the converged policy is Pareto optimal.\nSimulation results demonstrate the applicability of the proposed approach.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Siddharth H. Nair",
            "Charlott Vallon",
            "Francesco Borrelli"
        ],
        "published": "2024-05-19T23:08:15Z"
    },
    {
        "title": "AMMeBa: A Large-Scale Survey and Dataset of Media-Based Misinformation\n  In-The-Wild",
        "link": "http://arxiv.org/abs/2405.11697v2",
        "abstract": "The prevalence and harms of online misinformation is a perennial concern for\ninternet platforms, institutions and society at large. Over time, information\nshared online has become more media-heavy and misinformation has readily\nadapted to these new modalities. The rise of generative AI-based tools, which\nprovide widely-accessible methods for synthesizing realistic audio, images,\nvideo and human-like text, have amplified these concerns. Despite intense\npublic interest and significant press coverage, quantitative information on the\nprevalence and modality of media-based misinformation remains scarce. Here, we\npresent the results of a two-year study using human raters to annotate online\nmedia-based misinformation, mostly focusing on images, based on claims assessed\nin a large sample of publicly-accessible fact checks with the ClaimReview\nmarkup. We present an image typology, designed to capture aspects of the image\nand manipulation relevant to the image's role in the misinformation claim. We\nvisualize the distribution of these types over time. We show the rise of\ngenerative AI-based content in misinformation claims, and that its commonality\nis a relatively recent phenomenon, occurring significantly after heavy press\ncoverage. We also show \"simple\" methods dominated historically, particularly\ncontext manipulations, and continued to hold a majority as of the end of data\ncollection in November 2023. The dataset, Annotated Misinformation, Media-Based\n(AMMeBa), is publicly-available, and we hope that these data will serve as both\na means of evaluating mitigation methods in a realistic setting and as a\nfirst-of-its-kind census of the types and modalities of online misinformation.",
        "subjects": [
            "cs.CY"
        ],
        "authors": [
            "Nicholas Dufour",
            "Arkanath Pathak",
            "Pouya Samangouei",
            "Nikki Hariri",
            "Shashi Deshetti",
            "Andrew Dudfield",
            "Christopher Guess",
            "Pablo Hern√°ndez Escayola",
            "Bobby Tran",
            "Mevan Babakar",
            "Christoph Bregler"
        ],
        "published": "2024-05-19T23:05:53Z"
    },
    {
        "title": "Approximation and Gradient Descent Training with Neural Networks",
        "link": "http://arxiv.org/abs/2405.11696v1",
        "abstract": "It is well understood that neural networks with carefully hand-picked weights\nprovide powerful function approximation and that they can be successfully\ntrained in over-parametrized regimes. Since over-parametrization ensures zero\ntraining error, these two theories are not immediately compatible. Recent work\nuses the smoothness that is required for approximation results to extend a\nneural tangent kernel (NTK) optimization argument to an under-parametrized\nregime and show direct approximation bounds for networks trained by gradient\nflow. Since gradient flow is only an idealization of a practical method, this\npaper establishes analogous results for networks trained by gradient descent.",
        "subjects": [
            "cs.LG",
            "41A46, 65K10, 68T07"
        ],
        "authors": [
            "G. Welper"
        ],
        "published": "2024-05-19T23:04:09Z"
    },
    {
        "title": "PBI: Position-Based Dynamics Handles Updated Lagrangian Inelasticity",
        "link": "http://arxiv.org/abs/2405.11694v1",
        "abstract": "Position-based Dynamics (PBD) and its extension, eXtended Position-based\nDynamics (XPBD), have been predominantly applied to compliant constrained\ndynamics, with their potential in finite strain inelasticity remaining\nunderexplored. XPBD stands in contrast to other meshless methods, such as the\nMaterial Point Method (MPM). MPM is based on discretizing the weak form of\ngoverning partial differential equations within a continuum domain, coupled\nwith a hybrid Lagrangian-Eulerian method for tracking deformation gradients. In\ncontrast, XPBD generally entails applying specific constraints, whether hard or\ncompliant, to collections of point masses. This paper revisits this perception,\ninvestigating the potential of XPBD in handling inelastic materials that are\ndescribed with continuum mechanics based yield surfaces and elastoplastic flow\nrules. Our inspiration is that a robust estimation of the velocity gradient is\nkey to effectively tracking deformation gradients in any meshless context. By\nfurther incorporating implicit inelastic constitutive relationships, we\nintroduce an updated Lagrangian augmentation to XPBD. This enhancement enables\nthe simulation of elastoplastic, viscoplastic, and granular substances\nfollowing their standard constitutive laws. We demonstrate the effectiveness of\nour method through high-resolution and real-time simulations of diverse\nmaterials such as snow, sand, and plasticine, and its integration with standard\nXPBD simulations of cloth and water.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Chang Yu",
            "Xuan Li",
            "Lei Lan",
            "Yin Yang",
            "Chenfanfu Jiang"
        ],
        "published": "2024-05-19T22:51:22Z"
    },
    {
        "title": "Your Transformer is Secretly Linear",
        "link": "http://arxiv.org/abs/2405.12250v1",
        "abstract": "This paper reveals a novel linear characteristic exclusive to transformer\ndecoders, including models such as GPT, LLaMA, OPT, BLOOM and others. We\nanalyze embedding transformations between sequential layers, uncovering a\nnear-perfect linear relationship (Procrustes similarity score of 0.99).\nHowever, linearity decreases when the residual component is removed due to a\nconsistently low output norm of the transformer layer. Our experiments show\nthat removing or linearly approximating some of the most linear blocks of\ntransformers does not affect significantly the loss or model performance.\nMoreover, in our pretraining experiments on smaller models we introduce a\ncosine-similarity-based regularization, aimed at reducing layer linearity. This\nregularization improves performance metrics on benchmarks like Tiny Stories and\nSuperGLUE and as well successfully decreases the linearity of the models. This\nstudy challenges the existing understanding of transformer architectures,\nsuggesting that their operation may be more linear than previously assumed.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Anton Razzhigaev",
            "Matvey Mikhalchuk",
            "Elizaveta Goncharova",
            "Nikolai Gerasimenko",
            "Ivan Oseledets",
            "Denis Dimitrov",
            "Andrey Kuznetsov"
        ],
        "published": "2024-05-19T22:44:00Z"
    },
    {
        "title": "InterAct: Capture and Modelling of Realistic, Expressive and Interactive\n  Activities between Two Persons in Daily Scenarios",
        "link": "http://arxiv.org/abs/2405.11690v1",
        "abstract": "We address the problem of accurate capture and expressive modelling of\ninteractive behaviors happening between two persons in daily scenarios.\nDifferent from previous works which either only consider one person or focus on\nconversational gestures, we propose to simultaneously model the activities of\ntwo persons, and target objective-driven, dynamic, and coherent interactions\nwhich often span long duration. To this end, we capture a new dataset dubbed\nInterAct, which is composed of 241 motion sequences where two persons perform a\nrealistic scenario over the whole sequence. The audios, body motions, and\nfacial expressions of both persons are all captured in our dataset. We also\ndemonstrate the first diffusion model based approach that directly estimates\nthe interactive motions between two persons from their audios alone. All the\ndata and code will be available for research purposes upon acceptance of the\npaper.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yinghao Huang",
            "Leo Ho",
            "Dafei Qin",
            "Mingyi Shi",
            "Taku Komura"
        ],
        "published": "2024-05-19T22:35:02Z"
    },
    {
        "title": "ColorFoil: Investigating Color Blindness in Large Vision and Language\n  Models",
        "link": "http://arxiv.org/abs/2405.11685v1",
        "abstract": "With the utilization of Transformer architecture, large Vision and Language\n(V&L) models have shown promising performance in even zero-shot settings.\nSeveral studies, however, indicate a lack of robustness of the models when\ndealing with complex linguistics and visual attributes. In this work, we\nintroduce a novel V&L benchmark - ColorFoil, by creating color-related foils to\nassess the models' perception ability to detect colors like red, white, green,\netc. We evaluate seven state-of-the-art V&L models including CLIP, ViLT,\nGroupViT, and BridgeTower, etc. in a zero-shot setting and present intriguing\nfindings from the V&L models. The experimental evaluation indicates that ViLT\nand BridgeTower demonstrate much better color perception capabilities compared\nto CLIP and its variants and GroupViT. Moreover, CLIP-based models and GroupViT\nstruggle to distinguish colors that are visually distinct to humans with normal\ncolor perception ability.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "authors": [
            "Ahnaf Mozib Samin",
            "M. Firoz Ahmed",
            "Md. Mushtaq Shahriyar Rafee"
        ],
        "published": "2024-05-19T22:04:57Z"
    },
    {
        "title": "Learning Regularities from Data using Spiking Functions: A Theory",
        "link": "http://arxiv.org/abs/2405.11684v1",
        "abstract": "Deep neural networks trained in an end-to-end manner are proven to be\nefficient in a wide range of machine learning tasks. However, there is one\ndrawback of end-to-end learning: The learned features and information are\nimplicitly represented in neural network parameters, which cannot be used as\nregularities, concepts or knowledge to explicitly represent the data\nprobability distribution. To resolve this issue, we propose in this paper a new\nmachine learning theory, which defines in mathematics what are regularities.\nBriefly, regularities are concise representations of the non-random features,\nor 'non-randomness' in the data probability distribution. Combining with\ninformation theory, we claim that regularities can also be regarded as a small\namount of information encoding a large amount of information. Our theory is\nbased on spiking functions. That is, if a function can react to, or spike on\nspecific data samples more frequently than random noise inputs, we say that\nsuch a function discovers non-randomness from the data distribution, and\nencodes the non-randomness into regularities. Our theory also discusses\napplying multiple spiking functions to the same data distribution. In this\nprocess, we claim that the 'best' regularities, or the optimal spiking\nfunctions, are those who can capture the largest amount of information from the\ndata distribution, and then encode the captured information in the most concise\nway. Theorems and hypotheses are provided to describe in mathematics what are\n'best' regularities and optimal spiking functions. Finally, we propose a\nmachine learning approach, which can potentially obtain the optimal spiking\nfunctions regarding the given dataset in practice.",
        "subjects": [
            "cs.LG",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Canlin Zhang",
            "Xiuwen Liu"
        ],
        "published": "2024-05-19T22:04:11Z"
    },
    {
        "title": "Conditionally-Conjugate Gaussian Process Factor Analysis for Spike Count\n  Data via Data Augmentation",
        "link": "http://arxiv.org/abs/2405.11683v1",
        "abstract": "Gaussian process factor analysis (GPFA) is a latent variable modeling\ntechnique commonly used to identify smooth, low-dimensional latent trajectories\nunderlying high-dimensional neural recordings. Specifically, researchers model\nspiking rates as Gaussian observations, resulting in tractable inference.\nRecently, GPFA has been extended to model spike count data. However, due to the\nnon-conjugacy of the likelihood, the inference becomes intractable. Prior works\nrely on either black-box inference techniques, numerical integration or\npolynomial approximations of the likelihood to handle intractability. To\novercome this challenge, we propose a conditionally-conjugate Gaussian process\nfactor analysis (ccGPFA) resulting in both analytically and computationally\ntractable inference for modeling neural activity from spike count data. In\nparticular, we develop a novel data augmentation based method that renders the\nmodel conditionally conjugate. Consequently, our model enjoys the advantage of\nsimple closed-form updates using a variational EM algorithm. Furthermore, due\nto its conditional conjugacy, we show our model can be readily scaled using\nsparse Gaussian Processes and accelerated inference via natural gradients. To\nvalidate our method, we empirically demonstrate its efficacy through\nexperiments.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yididiya Y. Nadew",
            "Xuhui Fan",
            "Christopher J. Quinn"
        ],
        "published": "2024-05-19T21:53:36Z"
    },
    {
        "title": "FADet: A Multi-sensor 3D Object Detection Network based on Local\n  Featured Attention",
        "link": "http://arxiv.org/abs/2405.11682v1",
        "abstract": "Camera, LiDAR and radar are common perception sensors for autonomous driving\ntasks. Robust prediction of 3D object detection is optimally based on the\nfusion of these sensors. To exploit their abilities wisely remains a challenge\nbecause each of these sensors has its own characteristics. In this paper, we\npropose FADet, a multi-sensor 3D detection network, which specifically studies\nthe characteristics of different sensors based on our local featured attention\nmodules. For camera images, we propose dual-attention-based sub-module. For\nLiDAR point clouds, triple-attention-based sub-module is utilized while\nmixed-attention-based sub-module is applied for features of radar points. With\nlocal featured attention sub-modules, our FADet has effective detection results\nin long-tail and complex scenes from camera, LiDAR and radar input. On NuScenes\nvalidation dataset, FADet achieves state-of-the-art performance on LiDAR-camera\nobject detection tasks with 71.8% NDS and 69.0% mAP, at the same time, on\nradar-camera object detection tasks with 51.7% NDS and 40.3% mAP. Code will be\nreleased at https://github.com/ZionGo6/FADet.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Ziang Guo",
            "Zakhar Yagudin",
            "Selamawit Asfaw",
            "Artem Lykov",
            "Dzmitry Tsetserukou"
        ],
        "published": "2024-05-19T21:52:50Z"
    },
    {
        "title": "Advancing 6-DoF Instrument Pose Estimation in Variable X-Ray Imaging\n  Geometries",
        "link": "http://dx.doi.org/10.1109/TIP.2024.3378469",
        "abstract": "Accurate 6-DoF pose estimation of surgical instruments during minimally\ninvasive surgeries can substantially improve treatment strategies and eventual\nsurgical outcome. Existing deep learning methods have achieved accurate\nresults, but they require custom approaches for each object and laborious setup\nand training environments often stretching to extensive simulations, whilst\nlacking real-time computation. We propose a general-purpose approach of data\nacquisition for 6-DoF pose estimation tasks in X-ray systems, a novel and\ngeneral purpose YOLOv5-6D pose architecture for accurate and fast object pose\nestimation and a complete method for surgical screw pose estimation under\nacquisition geometry consideration from a monocular cone-beam X-ray image. The\nproposed YOLOv5-6D pose model achieves competitive results on public benchmarks\nwhilst being considerably faster at 42 FPS on GPU. In addition, the method\ngeneralizes across varying X-ray acquisition geometry and semantic image\ncomplexity to enable accurate pose estimation over different domains. Finally,\nthe proposed approach is tested for bone-screw pose estimation for\ncomputer-aided guidance during spine surgeries. The model achieves a 92.41% by\nthe 0.1 ADD-S metric, demonstrating a promising approach for enhancing surgical\nprecision and patient outcomes. The code for YOLOv5-6D is publicly available at\nhttps://github.com/cviviers/YOLOv5-6D-Pose",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Christiaan G. A. Viviers",
            "Lena Filatova",
            "Maurice Termeer",
            "Peter H. N. de With",
            "Fons van der Sommen"
        ],
        "published": "2024-05-19T21:35:12Z"
    },
    {
        "title": "Deep Ensemble Art Style Recognition",
        "link": "http://arxiv.org/abs/2405.11675v1",
        "abstract": "The massive digitization of artworks during the last decades created the need\nfor categorization, analysis, and management of huge amounts of data related to\nabstract concepts, highlighting a challenging problem in the field of computer\nscience. The rapid progress of artificial intelligence and neural networks has\nprovided tools and technologies that seem worthy of the challenge. Recognition\nof various art features in artworks has gained attention in the deep learning\nsociety. In this paper, we are concerned with the problem of art style\nrecognition using deep networks. We compare the performance of 8 different deep\narchitectures (VGG16, VGG19, ResNet50, ResNet152, Inception-V3, DenseNet121,\nDenseNet201 and Inception-ResNet-V2), on two different art datasets, including\n3 architectures that have never been used on this task before, leading to\nstate-of-the-art performance. We study the effect of data preprocessing prior\nto applying a deep learning model. We introduce a stacking ensemble method\ncombining the results of first-stage classifiers through a meta-classifier,\nwith the innovation of a versatile approach based on multiple models that\nextract and recognize different characteristics of the input, creating a more\nconsistent model compared to existing works and achieving state-of-the-art\naccuracy on the largest art dataset available (WikiArt - 68,55%). We also\ndiscuss the impact of the data and art styles themselves on the performance of\nour models forming a manifold perspective on the problem.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Orfeas Menis-Mastromichalakis",
            "Natasa Sofou",
            "Giorgos Stamou"
        ],
        "published": "2024-05-19T21:26:11Z"
    },
    {
        "title": "MeteoRA: Multiple-tasks Embedded LoRA for Large Language Models",
        "link": "http://arxiv.org/abs/2405.13053v2",
        "abstract": "The pretrain+fine-tune paradigm is foundational in deploying large language\nmodels (LLMs) across a diverse range of downstream applications. Among these,\nLow-Rank Adaptation (LoRA) stands out for its parameter-efficient fine-tuning\n(PEFT), producing numerous off-the-shelf task-specific LoRA adapters. However,\nthis approach requires explicit task intention selection, posing challenges for\nautomatic task sensing and switching during inference with multiple existing\nLoRA adapters embedded in a single LLM. In this work, we introduce MeteoRA\n(Multiple-Tasks embedded LoRA), a scalable multi-knowledge LoRA fusion\nframework designed for LLMs. MeteoRA integrates various LoRA adapters in a\nMixture-of-Experts (MoE) style into the base LLM, enabling the model to\nautomatically select the most pertinent adapter based on the task input. This\nadvancement significantly enhances the LLM's capability to handle composite\ntasks that require different adapters to solve various components of the\nproblem. Our evaluations, featuring the LlaMA2-13B and LlaMA3-8B base models\nequipped with off-the-shelf 28 LoRA adapters through MeteoRA, demonstrate\nequivalent performance with the individual adapters. Furthermore, both base\nmodels equipped with MeteoRA achieve superior performance in sequentially\nsolving composite tasks with ten problems in only a single inference process,\nhighlighting the ability of timely intention switching in MeteoRA embedded\nLLMs.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "I.2.7"
        ],
        "authors": [
            "Jingwei Xu",
            "Junyu Lai",
            "Yunpeng Huang"
        ],
        "published": "2024-05-19T20:46:07Z"
    },
    {
        "title": "Interpretable Machine Learning Enhances Disease Prognosis: Applications\n  on COVID-19 and Onward",
        "link": "http://arxiv.org/abs/2405.11672v2",
        "abstract": "In response to the COVID-19 pandemic, the integration of interpretable\nmachine learning techniques has garnered significant attention, offering\ntransparent and understandable insights crucial for informed clinical decision\nmaking. This literature review delves into the applications of interpretable\nmachine learning in predicting the prognosis of respiratory diseases,\nparticularly focusing on COVID-19 and its implications for future research and\nclinical practice. We reviewed various machine learning models that are not\nonly capable of incorporating existing clinical domain knowledge but also have\nthe learning capability to explore new information from the data. These models\nand experiences not only aid in managing the current crisis but also hold\npromise for addressing future disease outbreaks. By harnessing interpretable\nmachine learning, healthcare systems can enhance their preparedness and\nresponse capabilities, thereby improving patient outcomes and mitigating the\nimpact of respiratory diseases in the years to come.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Jinzhi Shen",
            "Ke Ma"
        ],
        "published": "2024-05-19T20:39:46Z"
    },
    {
        "title": "BYO: A Unified Framework for Benchmarking Large-Scale Graph Containers",
        "link": "http://arxiv.org/abs/2405.11671v1",
        "abstract": "A fundamental building block in any graph algorithm is a graph container - a\ndata structure used to represent the graph. Ideally, a graph container enables\nefficient access to the underlying graph, has low space usage, and supports\nupdating the graph efficiently. In this paper, we conduct an extensive\nempirical evaluation of graph containers designed to support running algorithms\non large graphs. To our knowledge, this is the first apples-to-apples\ncomparison of graph containers rather than overall systems, which include\nconfounding factors such as differences in algorithm implementations and\ninfrastructure.\n  We measure the running time of 10 highly-optimized algorithms across over 20\ndifferent containers and 10 graphs. Somewhat surprisingly, we find that the\naverage algorithm running time does not differ much across containers,\nespecially those that support dynamic updates. Specifically, a simple container\nbased on an off-the-shelf B-tree is only 1.22x slower on average than a highly\noptimized static one. Moreover, we observe that simplifying a graph-container\nApplication Programming Interface (API) to only a few simple functions incurs a\nmere 1.16x slowdown compared to a complete API. Finally, we also measure\nbatch-insert throughput in dynamic-graph containers for a full picture of their\nperformance.\n  To perform the benchmarks, we introduce BYO, a unified framework that\nstandardizes evaluations of graph-algorithm performance across different graph\ncontainers. BYO extends the Graph Based Benchmark Suite (Dhulipala et al. 18),\na state-of-the-art graph algorithm benchmark, to easily plug into different\ndynamic graph containers and enable fair comparisons between them on a large\nsuite of graph algorithms. While several graph algorithm benchmarks have been\ndeveloped to date, to the best of our knowledge, BYO is the first system\ndesigned to benchmark graph containers",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Brian Wheatman",
            "Xiaojun Dong",
            "Zheqi Shen",
            "Laxman Dhulipala",
            "Jakub ≈ÅƒÖcki",
            "Prashant Pandey",
            "Helen Xu"
        ],
        "published": "2024-05-19T20:36:49Z"
    },
    {
        "title": "Large Language Models Can Infer Personality from Free-Form User\n  Interactions",
        "link": "http://arxiv.org/abs/2405.13052v1",
        "abstract": "This study investigates the capacity of Large Language Models (LLMs) to infer\nthe Big Five personality traits from free-form user interactions. The results\ndemonstrate that a chatbot powered by GPT-4 can infer personality with moderate\naccuracy, outperforming previous approaches drawing inferences from static text\ncontent. The accuracy of inferences varied across different conversational\nsettings. Performance was highest when the chatbot was prompted to elicit\npersonality-relevant information from users (mean r=.443, range=[.245, .640]),\nfollowed by a condition placing greater emphasis on naturalistic interaction\n(mean r=.218, range=[.066, .373]). Notably, the direct focus on personality\nassessment did not result in a less positive user experience, with participants\nreporting the interactions to be equally natural, pleasant, engaging, and\nhumanlike across both conditions. A chatbot mimicking ChatGPT's default\nbehavior of acting as a helpful assistant led to markedly inferior personality\ninferences and lower user experience ratings but still captured psychologically\nmeaningful information for some of the personality traits (mean r=.117,\nrange=[-.004, .209]). Preliminary analyses suggest that the accuracy of\npersonality inferences varies only marginally across different\nsocio-demographic subgroups. Our results highlight the potential of LLMs for\npsychological profiling based on conversational interactions. We discuss\npractical implications and ethical challenges associated with these findings.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.CL",
            "cs.CY",
            "cs.LG"
        ],
        "authors": [
            "Heinrich Peters",
            "Moran Cerf",
            "Sandra C. Matz"
        ],
        "published": "2024-05-19T20:33:36Z"
    },
    {
        "title": "Do No Harm: A Counterfactual Approach to Safe Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.11669v1",
        "abstract": "Reinforcement Learning (RL) for control has become increasingly popular due\nto its ability to learn rich feedback policies that take into account\nuncertainty and complex representations of the environment. When considering\nsafety constraints, constrained optimization approaches, where agents are\npenalized for constraint violations, are commonly used. In such methods, if\nagents are initialized in, or must visit, states where constraint violation\nmight be inevitable, it is unclear how much they should be penalized. We\naddress this challenge by formulating a constraint on the counterfactual harm\nof the learned policy compared to a default, safe policy. In a philosophical\nsense this formulation only penalizes the learner for constraint violations\nthat it caused; in a practical sense it maintains feasibility of the optimal\ncontrol problem. We present simulation studies on a rover with uncertain road\nfriction and a tractor-trailer parking environment that demonstrate our\nconstraint formulation enables agents to learn safer policies than contemporary\nconstrained RL methods.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Sean Vaskov",
            "Wilko Schwarting",
            "Chris L. Baker"
        ],
        "published": "2024-05-19T20:33:21Z"
    },
    {
        "title": "Cyber Risks of Machine Translation Critical Errors : Arabic Mental\n  Health Tweets as a Case Study",
        "link": "http://arxiv.org/abs/2405.11668v1",
        "abstract": "With the advent of Neural Machine Translation (NMT) systems, the MT output\nhas reached unprecedented accuracy levels which resulted in the ubiquity of MT\ntools on almost all online platforms with multilingual content. However, NMT\nsystems, like other state-of-the-art AI generative systems, are prone to errors\nthat are deemed machine hallucinations. The problem with NMT hallucinations is\nthat they are remarkably \\textit{fluent} hallucinations. Since they are trained\nto produce grammatically correct utterances, NMT systems are capable of\nproducing mistranslations that are too fluent to be recognised by both users of\nthe MT tool, as well as by automatic quality metrics that are used to gauge\ntheir performance. In this paper, we introduce an authentic dataset of machine\ntranslation critical errors to point to the ethical and safety issues involved\nin the common use of MT. The dataset comprises mistranslations of Arabic mental\nhealth postings manually annotated with critical error types. We also show how\nthe commonly used quality metrics do not penalise critical errors and highlight\nthis as a critical issue that merits further attention from researchers.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Hadeel Saadany",
            "Ashraf Tantawy",
            "Constantin Orasan"
        ],
        "published": "2024-05-19T20:24:51Z"
    },
    {
        "title": "Towards Contactless Elevators with TinyML using CNN-based Person\n  Detection and Keyword Spotting",
        "link": "http://arxiv.org/abs/2405.13051v1",
        "abstract": "This study presents a proof of concept for a contactless elevator operation\nsystem aimed at minimizing human intervention while enhancing safety,\nintelligence, and efficiency. A microcontroller-based edge device executing\ntiny Machine Learning (tinyML) inferences is developed for elevator operation.\nUsing person detection and keyword spotting algorithms, the system offers\ncost-effective and robust units requiring minimal infrastructural changes. The\ndesign incorporates preprocessing steps and quantized convolutional neural\nnetworks in a multitenant framework to optimize accuracy and response time.\nResults show a person detection accuracy of 83.34% and keyword spotting\nefficacy of 80.5%, with an overall latency under 5 seconds, indicating\neffectiveness in real-world scenarios. Unlike current high-cost and\ninconsistent contactless technologies, this system leverages tinyML to provide\na cost-effective, reliable, and scalable solution, enhancing user safety and\noperational efficiency without significant infrastructural changes. The study\nhighlights promising results, though further exploration is needed for\nscalability and integration with existing systems. The demonstrated energy\nefficiency, simplicity, and safety benefits suggest that tinyML adoption could\nrevolutionize elevator systems, serving as a model for future technological\nadvancements. This technology could significantly impact public health and\nconvenience in multi-floor buildings by reducing physical contact and improving\noperational efficiency, particularly relevant in the context of pandemics or\nhygiene concerns.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Anway S. Pimpalkar",
            "Deeplaxmi V. Niture"
        ],
        "published": "2024-05-19T20:24:31Z"
    },
    {
        "title": "The Limits and Potentials of Local SGD for Distributed Heterogeneous\n  Learning with Intermittent Communication",
        "link": "http://arxiv.org/abs/2405.11667v1",
        "abstract": "Local SGD is a popular optimization method in distributed learning, often\noutperforming other algorithms in practice, including mini-batch SGD. Despite\nthis success, theoretically proving the dominance of local SGD in settings with\nreasonable data heterogeneity has been difficult, creating a significant gap\nbetween theory and practice. In this paper, we provide new lower bounds for\nlocal SGD under existing first-order data heterogeneity assumptions, showing\nthat these assumptions are insufficient to prove the effectiveness of local\nupdate steps. Furthermore, under these same assumptions, we demonstrate the\nmin-max optimality of accelerated mini-batch SGD, which fully resolves our\nunderstanding of distributed optimization for several problem classes. Our\nresults emphasize the need for better models of data heterogeneity to\nunderstand the effectiveness of local SGD in practice. Towards this end, we\nconsider higher-order smoothness and heterogeneity assumptions, providing new\nupper bounds that imply the dominance of local SGD over mini-batch SGD when\ndata heterogeneity is low.",
        "subjects": [
            "cs.LG",
            "cs.DC",
            "math.OC",
            "stat.ML"
        ],
        "authors": [
            "Kumar Kshitij Patel",
            "Margalit Glasgow",
            "Ali Zindari",
            "Lingxiao Wang",
            "Sebastian U. Stich",
            "Ziheng Cheng",
            "Nirmit Joshi",
            "Nathan Srebro"
        ],
        "published": "2024-05-19T20:20:03Z"
    },
    {
        "title": "Auto-Platoon : Freight by example",
        "link": "http://arxiv.org/abs/2405.11659v1",
        "abstract": "The work introduces a bio-inspired leader-follower system based on an\ninnovative mechanism proposed as software latching that aims to improve\ncollaboration and coordination between a leader agent and the associated\nautonomous followers. The system utilizes software latching to establish\nreal-time communication and synchronization between the leader and followers. A\nlayered architecture is proposed, encompassing perception, decision-making, and\ncontrol modules. Challenges such as uncertainty, dynamic environments, and\ncommunication latency are addressed using Deep learning and real-time data\nprocessing pipelines. The follower robot is equipped with sensors and\ncommunication modules that enable it to track and trace the agent of interest\nor avoid obstacles. The followers track the leader and dynamically avoid\nobstacles while maintaining a safe distance from it. The experimental results\ndemonstrate the proposed system's effectiveness, making it a promising solution\nfor achieving success in tasks that demand multi-robot systems capable of\nnavigating complex dynamic environments.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Tharun V. Puthanveettil",
            "Abhijay Singh",
            "Yashveer Jain",
            "Vinay Bukka",
            "Sameer Arjun S"
        ],
        "published": "2024-05-19T20:11:30Z"
    },
    {
        "title": "A Starting Point for Dynamic Community Detection with Leiden Algorithm",
        "link": "http://arxiv.org/abs/2405.11658v1",
        "abstract": "Many real-world graphs evolve with time. Identifying communities or clusters\non such graphs is an important problem. In this technical report, we extend\nthree dynamic approaches, namely, Naive-dynamic (ND), Delta-screening (DS), and\nDynamic Frontier (DF), to our multicore implementation of the Leiden algorithm,\nan algorithm known for its high-quality community detection. Our experiments on\na server with a 64-core AMD EPYC-7742 processor demonstrate that ND, DS, and DF\nLeiden achieve speedups of 1.25x, 1.24x, and 1.37x on large graphs with random\nbatch updates, compared to Static, ND, and DS Leiden, respectively. However, on\nreal-world dynamic graphs, ND Leiden performs the best, being on average 1.14x\nfaster than Static Leiden. We hope our early results serve as a starting point\nfor dynamic approaches to the Leiden algorithm on evolving graphs.",
        "subjects": [
            "cs.DC",
            "cs.SI",
            "G.2.2; I.5.3"
        ],
        "authors": [
            "Subhajit Sahu"
        ],
        "published": "2024-05-19T20:10:55Z"
    },
    {
        "title": "On the Expressivity of Recurrent Neural Cascades with Identity",
        "link": "http://arxiv.org/abs/2405.11657v1",
        "abstract": "Recurrent Neural Cascades (RNC) are the class of recurrent neural networks\nwith no cyclic dependencies among recurrent neurons. Their subclass RNC+ with\npositive recurrent weights has been shown to be closely connected to the\nstar-free regular languages, which are the expressivity of many\nwell-established temporal logics. The existing expressivity results show that\nthe regular languages captured by RNC+ are the star-free ones, and they leave\nopen the possibility that RNC+ may capture languages beyond regular. We exclude\nthis possibility for languages that include an identity element, i.e., an input\nthat can occur an arbitrary number of times without affecting the output.\nNamely, in the presence of an identity element, we show that the languages\ncaptured by RNC+ are exactly the star-free regular languages. Identity elements\nare ubiquitous in temporal patterns, and hence our results apply to a large\nnumber of applications. The implications of our results go beyond expressivity.\nAt their core, we establish a close structural correspondence between RNC+ and\nsemiautomata cascades, showing that every neuron can be equivalently captured\nby a three-state semiautomaton. A notable consequence of this result is that\nRNC+ are no more succinct than cascades of three-state semiautomata.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.FL",
            "cs.LO",
            "cs.NE"
        ],
        "authors": [
            "Nadezda A. Knorozova",
            "Alessandro Ronca"
        ],
        "published": "2024-05-19T20:06:38Z"
    },
    {
        "title": "URDFormer: A Pipeline for Constructing Articulated Simulation\n  Environments from Real-World Images",
        "link": "http://arxiv.org/abs/2405.11656v1",
        "abstract": "Constructing simulation scenes that are both visually and physically\nrealistic is a problem of practical interest in domains ranging from robotics\nto computer vision. This problem has become even more relevant as researchers\nwielding large data-hungry learning methods seek new sources of training data\nfor physical decision-making systems. However, building simulation models is\noften still done by hand. A graphic designer and a simulation engineer work\nwith predefined assets to construct rich scenes with realistic dynamic and\nkinematic properties. While this may scale to small numbers of scenes, to\nachieve the generalization properties that are required for data-driven robotic\ncontrol, we require a pipeline that is able to synthesize large numbers of\nrealistic scenes, complete with 'natural' kinematic and dynamic structures. To\nattack this problem, we develop models for inferring structure and generating\nsimulation scenes from natural images, allowing for scalable scene generation\nfrom web-scale datasets. To train these image-to-simulation models, we show how\ncontrollable text-to-image generative models can be used in generating paired\ntraining data that allows for modeling of the inverse problem, mapping from\nrealistic images back to complete scene models. We show how this paradigm\nallows us to build large datasets of scenes in simulation with semantic and\nphysical realism. We present an integrated end-to-end pipeline that generates\nsimulation scenes complete with articulated kinematic and dynamic structures\nfrom real-world images and use these for training robotic control policies. We\nthen robustly deploy in the real world for tasks like articulated object\nmanipulation. In doing so, our work provides both a pipeline for large-scale\ngeneration of simulation environments and an integrated system for training\nrobust robotic control policies in the resulting environments.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "authors": [
            "Zoey Chen",
            "Aaron Walsman",
            "Marius Memmel",
            "Kaichun Mo",
            "Alex Fang",
            "Karthikeya Vemuri",
            "Alan Wu",
            "Dieter Fox",
            "Abhishek Gupta"
        ],
        "published": "2024-05-19T20:01:29Z"
    },
    {
        "title": "Track Anything Rapter(TAR)",
        "link": "http://arxiv.org/abs/2405.11655v1",
        "abstract": "Object tracking is a fundamental task in computer vision with broad practical\napplications across various domains, including traffic monitoring, robotics,\nand autonomous vehicle tracking. In this project, we aim to develop a\nsophisticated aerial vehicle system known as Track Anything Raptor (TAR),\ndesigned to detect, segment, and track objects of interest based on\nuser-provided multimodal queries, such as text, images, and clicks. TAR\nutilizes cutting-edge pre-trained models like DINO, CLIP, and SAM to estimate\nthe relative pose of the queried object. The tracking problem is approached as\na Visual Servoing task, enabling the UAV to consistently focus on the object\nthrough advanced motion planning and control algorithms. We showcase how the\nintegration of these foundational models with a custom high-level control\nalgorithm results in a highly stable and precise tracking system deployed on a\ncustom-built PX4 Autopilot-enabled Voxl2 M500 drone. To validate the tracking\nalgorithm's performance, we compare it against Vicon-based ground truth.\nAdditionally, we evaluate the reliability of the foundational models in aiding\ntracking in scenarios involving occlusions. Finally, we test and validate the\nmodel's ability to work seamlessly with multiple modalities, such as click,\nbounding box, and image templates.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "authors": [
            "Tharun V. Puthanveettil",
            "Fnu Obaid ur Rahman"
        ],
        "published": "2024-05-19T19:51:41Z"
    },
    {
        "title": "Movie Revenue Prediction using Machine Learning Models",
        "link": "http://arxiv.org/abs/2405.11651v1",
        "abstract": "In the contemporary film industry, accurately predicting a movie's earnings\nis paramount for maximizing profitability. This project aims to develop a\nmachine learning model for predicting movie earnings based on input features\nlike the movie name, the MPAA rating of the movie, the genre of the movie, the\nyear of release of the movie, the IMDb Rating, the votes by the watchers, the\ndirector, the writer and the leading cast, the country of production of the\nmovie, the budget of the movie, the production company and the runtime of the\nmovie. Through a structured methodology involving data collection,\npreprocessing, analysis, model selection, evaluation, and improvement, a robust\npredictive model is constructed. Linear Regression, Decision Trees, Random\nForest Regression, Bagging, XGBoosting and Gradient Boosting have been trained\nand tested. Model improvement strategies include hyperparameter tuning and\ncross-validation. The resulting model offers promising accuracy and\ngeneralization, facilitating informed decision-making in the film industry to\nmaximize profits.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Vikranth Udandarao",
            "Pratyush Gupta"
        ],
        "published": "2024-05-19T19:32:12Z"
    },
    {
        "title": "Hummer: Towards Limited Competitive Preference Dataset",
        "link": "http://arxiv.org/abs/2405.11647v2",
        "abstract": "Preference datasets are essential for incorporating human preferences into\npre-trained language models, playing a key role in the success of Reinforcement\nLearning from Human Feedback. However, these datasets often demonstrate\nconflicting alignment objectives, leading to increased vulnerability to\njailbreak attacks and challenges in adapting downstream tasks to prioritize\nspecific alignment objectives without negatively impacting others. In this\nwork, we introduce a novel statistical metric, Alignment Dimension Conflict, to\nquantify the degree of conflict within preference datasets. We then present\n\\texttt{Hummer} and its fine-grained variant, \\texttt{Hummer-F}, as innovative\npairwise preference datasets with reduced-conflict alignment objectives.\n\\texttt{Hummer} is built based on UltraFeedback and is enhanced by AI feedback\nfrom GPT-4, marking as the first preference dataset aimed at reducing the\ncompetition between alignment objectives. Furthermore, we develop reward\nmodels, HummerRM and HummerRM-F, which employ a hybrid sampling approach to\nbalance diverse alignment objectives effectively. This sampling method\npositions HummerRM as an ideal model for domain-specific further fine-tuning\nand reducing vulnerabilities to attacks.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Li Jiang",
            "Yusen Wu",
            "Junwu Xiong",
            "Jingqing Ruan",
            "Yichuan Ding",
            "Qingpei Guo",
            "Zujie Wen",
            "Jun Zhou",
            "Xiaotie Deng"
        ],
        "published": "2024-05-19T18:57:25Z"
    },
    {
        "title": "Morphological Prototyping for Unsupervised Slide Representation Learning\n  in Computational Pathology",
        "link": "http://arxiv.org/abs/2405.11643v1",
        "abstract": "Representation learning of pathology whole-slide images (WSIs) has been has\nprimarily relied on weak supervision with Multiple Instance Learning (MIL).\nHowever, the slide representations resulting from this approach are highly\ntailored to specific clinical tasks, which limits their expressivity and\ngeneralization, particularly in scenarios with limited data. Instead, we\nhypothesize that morphological redundancy in tissue can be leveraged to build a\ntask-agnostic slide representation in an unsupervised fashion. To this end, we\nintroduce PANTHER, a prototype-based approach rooted in the Gaussian mixture\nmodel that summarizes the set of WSI patches into a much smaller set of\nmorphological prototypes. Specifically, each patch is assumed to have been\ngenerated from a mixture distribution, where each mixture component represents\na morphological exemplar. Utilizing the estimated mixture parameters, we then\nconstruct a compact slide representation that can be readily used for a wide\nrange of downstream tasks. By performing an extensive evaluation of PANTHER on\nsubtyping and survival tasks using 13 datasets, we show that 1) PANTHER\noutperforms or is on par with supervised MIL baselines and 2) the analysis of\nmorphological prototypes brings new qualitative and quantitative insights into\nmodel interpretability.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "stat.AP"
        ],
        "authors": [
            "Andrew H. Song",
            "Richard J. Chen",
            "Tong Ding",
            "Drew F. K. Williamson",
            "Guillaume Jaume",
            "Faisal Mahmood"
        ],
        "published": "2024-05-19T18:42:36Z"
    },
    {
        "title": "Inquire, Interact, and Integrate: A Proactive Agent Collaborative\n  Framework for Zero-Shot Multimodal Medical Reasoning",
        "link": "http://arxiv.org/abs/2405.11640v1",
        "abstract": "The adoption of large language models (LLMs) in healthcare has attracted\nsignificant research interest. However, their performance in healthcare remains\nunder-investigated and potentially limited, due to i) they lack rich\ndomain-specific knowledge and medical reasoning skills; and ii) most\nstate-of-the-art LLMs are unimodal, text-only models that cannot directly\nprocess multimodal inputs. To this end, we propose a multimodal medical\ncollaborative reasoning framework \\textbf{MultiMedRes}, which incorporates a\nlearner agent to proactively gain essential information from domain-specific\nexpert models, to solve medical multimodal reasoning problems. Our method\nincludes three steps: i) \\textbf{Inquire}: The learner agent first decomposes\ngiven complex medical reasoning problems into multiple domain-specific\nsub-problems; ii) \\textbf{Interact}: The agent then interacts with\ndomain-specific expert models by repeating the ``ask-answer'' process to\nprogressively obtain different domain-specific knowledge; iii)\n\\textbf{Integrate}: The agent finally integrates all the acquired\ndomain-specific knowledge to accurately address the medical reasoning problem.\nWe validate the effectiveness of our method on the task of difference visual\nquestion answering for X-ray images. The experiments demonstrate that our\nzero-shot prediction achieves state-of-the-art performance, and even\noutperforms the fully supervised methods. Besides, our approach can be\nincorporated into various LLMs and multimodal LLMs to significantly boost their\nperformance.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "authors": [
            "Zishan Gu",
            "Fenglin Liu",
            "Changchang Yin",
            "Ping Zhang"
        ],
        "published": "2024-05-19T18:26:11Z"
    },
    {
        "title": "Fair Set Cover",
        "link": "http://arxiv.org/abs/2405.11639v1",
        "abstract": "The potential harms of algorithmic decisions have ignited algorithmic\nfairness as a central topic in computer science. One of the fundamental\nproblems in computer science is Set Cover, which has numerous applications with\nsocietal impacts, such as assembling a small team of individuals that\ncollectively satisfy a range of expertise requirements. However, despite its\nbroad application spectrum and significant potential impact, set cover has yet\nto be studied through the lens of fairness. Therefore, in this paper, we\nintroduce Fair Set Cover, which aims not only to cover with a minimum-size set\nbut also to satisfy demographic parity in its selection of sets. To this end,\nwe develop multiple versions of fair set cover, study their hardness, and\ndevise efficient approximation algorithms for each variant. Notably, under\ncertain assumptions, our algorithms always guarantees zero-unfairness, with\nonly a small increase in the approximation ratio compared to regular set cover.\nFurthermore, our experiments on various data sets and across different settings\nconfirm the negligible price of fairness, as (a) the output size increases only\nslightly (if any) and (b) the time to compute the output does not significantly\nincrease.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Mohsen Dehghankar",
            "Rahul Raychaudhury",
            "Stavros Sintos",
            "Abolfazl Asudeh"
        ],
        "published": "2024-05-19T18:16:03Z"
    },
    {
        "title": "Zero-Shot Stance Detection using Contextual Data Generation with LLMs",
        "link": "http://arxiv.org/abs/2405.11637v1",
        "abstract": "Stance detection, the classification of attitudes expressed in a text towards\na specific topic, is vital for applications like fake news detection and\nopinion mining. However, the scarcity of labeled data remains a challenge for\nthis task. To address this problem, we propose Dynamic Model Adaptation with\nContextual Data Generation (DyMoAdapt) that combines Few-Shot Learning and\nLarge Language Models. In this approach, we aim to fine-tune an existing model\nat test time. We achieve this by generating new topic-specific data using\nGPT-3. This method could enhance performance by allowing the adaptation of the\nmodel to new topics. However, the results did not increase as we expected.\nFurthermore, we introduce the Multi Generated Topic VAST (MGT-VAST) dataset,\nwhich extends VAST using GPT-3. In this dataset, each context is associated\nwith multiple topics, allowing the model to understand the relationship between\ncontexts and various potential topics",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Ghazaleh Mahmoudi",
            "Babak Behkamkia",
            "Sauleh Eetemadi"
        ],
        "published": "2024-05-19T17:58:26Z"
    },
    {
        "title": "Geometry-Aware Instrumental Variable Regression",
        "link": "http://arxiv.org/abs/2405.11633v1",
        "abstract": "Instrumental variable (IV) regression can be approached through its\nformulation in terms of conditional moment restrictions (CMR). Building on\nvariants of the generalized method of moments, most CMR estimators are\nimplicitly based on approximating the population data distribution via\nreweightings of the empirical sample. While for large sample sizes, in the\nindependent identically distributed (IID) setting, reweightings can provide\nsufficient flexibility, they might fail to capture the relevant information in\npresence of corrupted data or data prone to adversarial attacks. To address\nthese shortcomings, we propose the Sinkhorn Method of Moments, an optimal\ntransport-based IV estimator that takes into account the geometry of the data\nmanifold through data-derivative information. We provide a simple plug-and-play\nimplementation of our method that performs on par with related estimators in\nstandard settings but improves robustness against data corruption and\nadversarial attacks.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Heiner Kremer",
            "Bernhard Sch√∂lkopf"
        ],
        "published": "2024-05-19T17:49:33Z"
    },
    {
        "title": "Searching Realistic-Looking Adversarial Objects For Autonomous Driving\n  Systems",
        "link": "http://arxiv.org/abs/2405.11629v1",
        "abstract": "Numerous studies on adversarial attacks targeting self-driving policies fail\nto incorporate realistic-looking adversarial objects, limiting real-world\napplicability. Building upon prior research that facilitated the transition of\nadversarial objects from simulations to practical applications, this paper\ndiscusses a modified gradient-based texture optimization method to discover\nrealistic-looking adversarial objects. While retaining the core architecture\nand techniques of the prior research, the proposed addition involves an entity\ntermed the 'Judge'. This agent assesses the texture of a rendered object,\nassigning a probability score reflecting its realism. This score is integrated\ninto the loss function to encourage the NeRF object renderer to concurrently\nlearn realistic and adversarial textures. The paper analyzes four strategies\nfor developing a robust 'Judge': 1) Leveraging cutting-edge vision-language\nmodels. 2) Fine-tuning open-sourced vision-language models. 3) Pretraining\nneurosymbolic systems. 4) Utilizing traditional image processing techniques.\nOur findings indicate that strategies 1) and 4) yield less reliable outcomes,\npointing towards strategies 2) or 3) as more promising directions for future\nresearch.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Shengxiang Sun",
            "Shenzhe Zhu"
        ],
        "published": "2024-05-19T17:42:24Z"
    },
    {
        "title": "Continuous Predictive Modeling of Clinical Notes and ICD Codes in\n  Patient Health Records",
        "link": "http://arxiv.org/abs/2405.11622v1",
        "abstract": "Electronic Health Records (EHR) serve as a valuable source of patient\ninformation, offering insights into medical histories, treatments, and\noutcomes. Previous research has developed systems for detecting applicable ICD\ncodes that should be assigned while writing a given EHR document, mainly\nfocusing on discharge summaries written at the end of a hospital stay. In this\nwork, we investigate the potential of predicting these codes for the whole\npatient stay at different time points during their stay, even before they are\nofficially assigned by clinicians. The development of methods to predict\ndiagnoses and treatments earlier in advance could open opportunities for\npredictive medicine, such as identifying disease risks sooner, suggesting\ntreatments, and optimizing resource allocation. Our experiments show that\npredictions regarding final ICD codes can be made already two days after\nadmission and we propose a custom model that improves performance on this early\nprediction task.",
        "subjects": [
            "cs.CL",
            "cs.LG",
            "I.2.7; J.3"
        ],
        "authors": [
            "Mireia Hernandez Caralt",
            "Clarence Boon Liang Ng",
            "Marek Rei"
        ],
        "published": "2024-05-19T17:23:04Z"
    },
    {
        "title": "Computer Vision in the Food Industry: Accurate, Real-time, and Automatic\n  Food Recognition with Pretrained MobileNetV2",
        "link": "http://arxiv.org/abs/2405.11621v1",
        "abstract": "In contemporary society, the application of artificial intelligence for\nautomatic food recognition offers substantial potential for nutrition tracking,\nreducing food waste, and enhancing productivity in food production and\nconsumption scenarios. Modern technologies such as Computer Vision and Deep\nLearning are highly beneficial, enabling machines to learn automatically,\nthereby facilitating automatic visual recognition. Despite some research in\nthis field, the challenge of achieving accurate automatic food recognition\nquickly remains a significant research gap. Some models have been developed and\nimplemented, but maintaining high performance swiftly, with low computational\ncost and low access to expensive hardware accelerators, still needs further\nexploration and research. This study employs the pretrained MobileNetV2 model,\nwhich is efficient and fast, for food recognition on the public Food11 dataset,\ncomprising 16643 images. It also utilizes various techniques such as dataset\nunderstanding, transfer learning, data augmentation, regularization, dynamic\nlearning rate, hyperparameter tuning, and consideration of images in different\nsizes to enhance performance and robustness. These techniques aid in choosing\nappropriate metrics, achieving better performance, avoiding overfitting and\naccuracy fluctuations, speeding up the model, and increasing the generalization\nof findings, making the study and its results applicable to practical\napplications. Despite employing a light model with a simpler structure and\nfewer trainable parameters compared to some deep and dense models in the deep\nlearning area, it achieved commendable accuracy in a short time. This\nunderscores the potential for practical implementation, which is the main\nintention of this study.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Shayan Rokhva",
            "Babak Teimourpour",
            "Amir Hossein Soltani"
        ],
        "published": "2024-05-19T17:20:20Z"
    },
    {
        "title": "Novel Interpretable and Robust Web-based AI Platform for Phishing Email\n  Detection",
        "link": "http://arxiv.org/abs/2405.11619v1",
        "abstract": "Phishing emails continue to pose a significant threat, causing financial\nlosses and security breaches. This study addresses limitations in existing\nresearch, such as reliance on proprietary datasets and lack of real-world\napplication, by proposing a high-performance machine learning model for email\nclassification. Utilizing a comprehensive and largest available public dataset,\nthe model achieves a f1 score of 0.99 and is designed for deployment within\nrelevant applications. Additionally, Explainable AI (XAI) is integrated to\nenhance user trust. This research offers a practical and highly accurate\nsolution, contributing to the fight against phishing by empowering users with a\nreal-time web-based application for phishing email detection.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Abdulla Al-Subaiey",
            "Mohammed Al-Thani",
            "Naser Abdullah Alam",
            "Kaniz Fatema Antora",
            "Amith Khandakar",
            "SM Ashfaq Uz Zaman"
        ],
        "published": "2024-05-19T17:18:27Z"
    },
    {
        "title": "Transcriptomics-guided Slide Representation Learning in Computational\n  Pathology",
        "link": "http://arxiv.org/abs/2405.11618v1",
        "abstract": "Self-supervised learning (SSL) has been successful in building patch\nembeddings of small histology images (e.g., 224x224 pixels), but scaling these\nmodels to learn slide embeddings from the entirety of giga-pixel whole-slide\nimages (WSIs) remains challenging. Here, we leverage complementary information\nfrom gene expression profiles to guide slide representation learning using\nmultimodal pre-training. Expression profiles constitute highly detailed\nmolecular descriptions of a tissue that we hypothesize offer a strong\ntask-agnostic training signal for learning slide embeddings. Our slide and\nexpression (S+E) pre-training strategy, called Tangle, employs\nmodality-specific encoders, the outputs of which are aligned via contrastive\nlearning. Tangle was pre-trained on samples from three different organs: liver\n(n=6,597 S+E pairs), breast (n=1,020), and lung (n=1,012) from two different\nspecies (Homo sapiens and Rattus norvegicus). Across three independent test\ndatasets consisting of 1,265 breast WSIs, 1,946 lung WSIs, and 4,584 liver\nWSIs, Tangle shows significantly better few-shot performance compared to\nsupervised and SSL baselines. When assessed using prototype-based\nclassification and slide retrieval, Tangle also shows a substantial performance\nimprovement over all baselines. Code available at\nhttps://github.com/mahmoodlab/TANGLE.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Guillaume Jaume",
            "Lukas Oldenburg",
            "Anurag Vaidya",
            "Richard J. Chen",
            "Drew F. K. Williamson",
            "Thomas Peeters",
            "Andrew H. Song",
            "Faisal Mahmood"
        ],
        "published": "2024-05-19T17:17:35Z"
    },
    {
        "title": "Era3D: High-Resolution Multiview Diffusion using Efficient Row-wise\n  Attention",
        "link": "http://arxiv.org/abs/2405.11616v1",
        "abstract": "In this paper, we introduce Era3D, a novel multiview diffusion method that\ngenerates high-resolution multiview images from a single-view image. Despite\nsignificant advancements in multiview generation, existing methods still suffer\nfrom camera prior mismatch, inefficacy, and low resolution, resulting in\npoor-quality multiview images. Specifically, these methods assume that the\ninput images should comply with a predefined camera type, e.g. a perspective\ncamera with a fixed focal length, leading to distorted shapes when the\nassumption fails. Moreover, the full-image or dense multiview attention they\nemploy leads to an exponential explosion of computational complexity as image\nresolution increases, resulting in prohibitively expensive training costs. To\nbridge the gap between assumption and reality, Era3D first proposes a\ndiffusion-based camera prediction module to estimate the focal length and\nelevation of the input image, which allows our method to generate images\nwithout shape distortions. Furthermore, a simple but efficient attention layer,\nnamed row-wise attention, is used to enforce epipolar priors in the multiview\ndiffusion, facilitating efficient cross-view information fusion. Consequently,\ncompared with state-of-the-art methods, Era3D generates high-quality multiview\nimages with up to a 512*512 resolution while reducing computation complexity by\n12x times. Comprehensive experiments demonstrate that Era3D can reconstruct\nhigh-quality and detailed 3D meshes from diverse single-view input images,\nsignificantly outperforming baseline multiview diffusion methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Peng Li",
            "Yuan Liu",
            "Xiaoxiao Long",
            "Feihu Zhang",
            "Cheng Lin",
            "Mengfei Li",
            "Xingqun Qi",
            "Shanghang Zhang",
            "Wenhan Luo",
            "Ping Tan",
            "Wenping Wang",
            "Qifeng Liu",
            "Yike Guo"
        ],
        "published": "2024-05-19T17:13:16Z"
    },
    {
        "title": "Nickel and Diming Your GAN: A Dual-Method Approach to Enhancing GAN\n  Efficiency via Knowledge Distillation",
        "link": "http://arxiv.org/abs/2405.11614v1",
        "abstract": "In this paper, we address the challenge of compressing generative adversarial\nnetworks (GANs) for deployment in resource-constrained environments by\nproposing two novel methodologies: Distribution Matching for Efficient\ncompression (DiME) and Network Interactive Compression via Knowledge Exchange\nand Learning (NICKEL). DiME employs foundation models as embedding kernels for\nefficient distribution matching, leveraging maximum mean discrepancy to\nfacilitate effective knowledge distillation. Simultaneously, NICKEL employs an\ninteractive compression method that enhances the communication between the\nstudent generator and discriminator, achieving a balanced and stable\ncompression process. Our comprehensive evaluation on the StyleGAN2 architecture\nwith the FFHQ dataset shows the effectiveness of our approach, with NICKEL &\nDiME achieving FID scores of 10.45 and 15.93 at compression rates of 95.73% and\n98.92%, respectively. Remarkably, our methods sustain generative quality even\nat an extreme compression rate of 99.69%, surpassing the previous\nstate-of-the-art performance by a large margin. These findings not only\ndemonstrate our methodologies' capacity to significantly lower GANs'\ncomputational demands but also pave the way for deploying high-quality GAN\nmodels in settings with limited resources. Our code will be released soon.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Sangyeop Yeo",
            "Yoojin Jang",
            "Jaejun Yoo"
        ],
        "published": "2024-05-19T17:09:43Z"
    },
    {
        "title": "Decoding by Contrasting Knowledge: Enhancing LLMs' Confidence on Edited\n  Facts",
        "link": "http://arxiv.org/abs/2405.11613v2",
        "abstract": "The knowledge within large language models (LLMs) may become outdated\nquickly. While in-context editing (ICE) is currently the most effective method\nfor knowledge editing (KE), it is constrained by the black-box modeling of LLMs\nand thus lacks interpretability. Our work aims to elucidate the superior\nperformance of ICE on the KE by analyzing the impacts of in-context new\nknowledge on token-wise distributions. We observe that despite a significant\nboost in logits of the new knowledge, the performance of is still hindered by\nstubborn knowledge. Stubborn knowledge refers to as facts that have gained\nexcessive confidence during pretraining, making it hard to edit effectively. To\naddress this issue and further enhance the performance of ICE, we propose a\nnovel approach termed $\\textbf{De}$coding by $\\textbf{C}$ontrasting\n$\\textbf{K}$nowledge (DeCK). DeCK derives the distribution of the next token by\ncontrasting the logits obtained from the newly edited knowledge guided by ICE\nwith those from the unedited parametric knowledge. Our experiments consistently\ndemonstrate that DeCK enhances the confidence of LLMs in edited facts. For\ninstance, it improves the performance of LLaMA3-8B-instruct on MQuAKE by up to\n219%, demonstrating its capability to strengthen ICE in the editing of stubborn\nknowledge. Our work paves the way to develop the both effective and accountable\nKE methods for LLMs. (The source code is available at:\nhttps://deck-llm.meirtz.com)",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Baolong Bi",
            "Shenghua Liu",
            "Lingrui Mei",
            "Yiwei Wang",
            "Pengliang Ji",
            "Xueqi Cheng"
        ],
        "published": "2024-05-19T17:08:31Z"
    },
    {
        "title": "Sociotechnical Implications of Generative Artificial Intelligence for\n  Information Access",
        "link": "http://arxiv.org/abs/2405.11612v1",
        "abstract": "Robust access to trustworthy information is a critical need for society with\nimplications for knowledge production, public health education, and promoting\ninformed citizenry in democratic societies. Generative AI technologies may\nenable new ways to access information and improve effectiveness of existing\ninformation retrieval systems but we are only starting to understand and\ngrapple with their long-term social implications. In this chapter, we present\nan overview of some of the systemic consequences and risks of employing\ngenerative AI in the context of information access. We also provide\nrecommendations for evaluation and mitigation, and discuss challenges for\nfuture research.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "authors": [
            "Bhaskar Mitra",
            "Henriette Cramer",
            "Olya Gurevich"
        ],
        "published": "2024-05-19T17:04:39Z"
    },
    {
        "title": "Full private delegated quantum computing tailored from user to industry",
        "link": "http://arxiv.org/abs/2405.11608v2",
        "abstract": "In this paper, we present a set of private and secure delegated quantum\ncomputing protocols and techniques tailored to user-level and industry-level\nuse cases, depending on the computational resources available to the client,\nthe specific privacy needs required, and the type of algorithm. Our protocols\nare presented at a high level as they are independent of the particular\nalgorithm used for such encryption and decryption processes. Additionally, we\npropose a method to verify the correct execution of operations by the external\nserver.",
        "subjects": [
            "quant-ph",
            "cs.CR",
            "cs.DC",
            "cs.ET",
            "81P68",
            "E.3"
        ],
        "authors": [
            "Alejandro Mata Ali",
            "Adriano Mauricio Lusso",
            "Edgar Mencia"
        ],
        "published": "2024-05-19T16:36:16Z"
    },
    {
        "title": "OFHE: An Electro-Optical Accelerator for Discretized TFHE",
        "link": "http://arxiv.org/abs/2405.11607v1",
        "abstract": "This paper presents \\textit{OFHE}, an electro-optical accelerator designed to\nprocess Discretized TFHE (DTFHE) operations, which encrypt multi-bit messages\nand support homomorphic multiplications, lookup table operations and\nfull-domain functional bootstrappings. While DTFHE is more efficient and\nversatile than other fully homomorphic encryption schemes, it requires 32-,\n64-, and 128-bit polynomial multiplications, which can be time-consuming.\nExisting TFHE accelerators are not easily upgradable to support DTFHE\noperations due to limited datapaths, a lack of datapath bit-width\nreconfigurability, and power inefficiencies when processing FFT and inverse FFT\n(IFFT) kernels. Compared to prior TFHE accelerators, OFHE addresses these\nchallenges by improving the DTFHE operation latency by 8.7\\%, the DTFHE\noperation throughput by $57\\%$, and the DTFHE operation throughput per Watt by\n$94\\%$.",
        "subjects": [
            "cs.CR",
            "cs.AR"
        ],
        "authors": [
            "Mengxin Zheng",
            "Cheng Chu",
            "Qian Lou",
            "Nathan Youngblood",
            "Mo Li",
            "Sajjad Moazeni",
            "Lei Jiang"
        ],
        "published": "2024-05-19T16:27:21Z"
    },
    {
        "title": "Switched Flow Matching: Eliminating Singularities via Switching ODEs",
        "link": "http://arxiv.org/abs/2405.11605v2",
        "abstract": "Continuous-time generative models, such as Flow Matching (FM), construct\nprobability paths to transport between one distribution and another through the\nsimulation-free learning of the neural ordinary differential equations (ODEs).\nDuring inference, however, the learned model often requires multiple neural\nnetwork evaluations to accurately integrate the flow, resulting in a slow\nsampling speed. We attribute the reason to the inherent (joint) heterogeneity\nof source and/or target distributions, namely the singularity problem, which\nposes challenges for training the neural ODEs effectively. To address this\nissue, we propose a more general framework, termed Switched FM (SFM), that\neliminates singularities via switching ODEs, as opposed to using a uniform ODE\nin FM. Importantly, we theoretically show that FM cannot transport between two\nsimple distributions due to the existence and uniqueness of initial value\nproblems of ODEs, while these limitations can be well tackled by SFM. From an\northogonal perspective, our framework can seamlessly integrate with the\nexisting advanced techniques, such as minibatch optimal transport, to further\nenhance the straightness of the flow, yielding a more efficient sampling\nprocess with reduced costs. We demonstrate the effectiveness of the newly\nproposed SFM through several numerical examples.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Qunxi Zhu",
            "Wei Lin"
        ],
        "published": "2024-05-19T16:21:04Z"
    },
    {
        "title": "How to integrate cloud service, data analytic and machine learning\n  technique to reduce cyber risks associated with the modern cloud based\n  infrastructure",
        "link": "http://arxiv.org/abs/2405.11601v1",
        "abstract": "The combination of cloud technology, machine learning, and data visualization\ntechniques allows hybrid enterprise networks to hold massive volumes of data\nand provide employees and customers easy access to these cloud data. These\nmassive collections of complex data sets are facing security challenges. While\ncloud platforms are more vulnerable to security threats and traditional\nsecurity technologies are unable to cope with the rapid data explosion in cloud\nplatforms, machine learning powered security solutions and data visualization\ntechniques are playing instrumental roles in detecting security threat, data\nbreaches, and automatic finding software vulnerabilities. The purpose of this\npaper is to present some of the widely used cloud services, machine learning\ntechniques and data visualization approach and demonstrate how to integrate\ncloud service, data analytic and machine learning techniques that can be used\nto detect and reduce cyber risks associated with the modern cloud based\ninfrastructure. In this paper I applied the machine learning supervised\nclassifier to design a model based on well-known UNSW-NB15 dataset to predict\nthe network behavior metrics and demonstrated how data analytics techniques can\nbe integrated to visualize network traffics.",
        "subjects": [
            "cs.LG",
            "cs.CE"
        ],
        "authors": [
            "Upakar Bhatta"
        ],
        "published": "2024-05-19T16:10:03Z"
    },
    {
        "title": "AI-Assisted Diagnosis for Covid-19 CXR Screening: From Data Collection\n  to Clinical Validation",
        "link": "http://arxiv.org/abs/2405.11598v1",
        "abstract": "In this paper, we present the major results from the Covid Radiographic\nimaging System based on AI (Co.R.S.A.) project, which took place in Italy. This\nproject aims to develop a state-of-the-art AI-based system for diagnosing\nCovid-19 pneumonia from Chest X-ray (CXR) images. The contributions of this\nwork are manyfold: the release of the public CORDA dataset, a deep learning\npipeline for Covid-19 detection, and the clinical validation of the developed\nsolution by expert radiologists. The proposed detection model is based on a\ntwo-step approach that, paired with state-of-the-art debiasing, provides\nreliable results. Most importantly, our investigation includes the actual usage\nof the diagnosis aid tool by radiologists, allowing us to assess the real\nbenefits in terms of accuracy and time efficiency. Project homepage:\nhttps://corsa.di.unito.it/",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV",
            "68T07",
            "I.2.1; I.4.0"
        ],
        "authors": [
            "Carlo Alberto Barbano",
            "Riccardo Renzulli",
            "Marco Grosso",
            "Domenico Basile",
            "Marco Busso",
            "Marco Grangetto"
        ],
        "published": "2024-05-19T16:06:26Z"
    },
    {
        "title": "Language Reconstruction with Brain Predictive Coding from fMRI Data",
        "link": "http://arxiv.org/abs/2405.11597v1",
        "abstract": "Many recent studies have shown that the perception of speech can be decoded\nfrom brain signals and subsequently reconstructed as continuous language.\nHowever, there is a lack of neurological basis for how the semantic information\nembedded within brain signals can be used more effectively to guide language\nreconstruction. The theory of predictive coding suggests that human brain\nnaturally engages in continuously predicting future word representations that\nspan multiple timescales. This implies that the decoding of brain signals could\npotentially be associated with a predictable future. To explore the predictive\ncoding theory within the context of language reconstruction, this paper\nproposes a novel model \\textsc{PredFT} for jointly modeling neural decoding and\nbrain prediction. It consists of a main decoding network for language\nreconstruction and a side network for predictive coding. The side network\nobtains brain predictive coding representation from related brain regions of\ninterest with a multi-head self-attention module. This representation is fused\ninto the main decoding network with cross-attention to facilitate the language\nmodels' generation process. Experiments are conducted on the largest\nnaturalistic language comprehension fMRI dataset Narratives. \\textsc{PredFT}\nachieves current state-of-the-art decoding performance with a maximum BLEU-1\nscore of $27.8\\%$.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Congchi Yin",
            "Ziyi Ye",
            "Piji Li"
        ],
        "published": "2024-05-19T16:06:02Z"
    },
    {
        "title": "Bioinspired Nested-Isotropic Lattices with Tunable Anisotropy for\n  Additive Manufacturing",
        "link": "http://arxiv.org/abs/2405.11596v1",
        "abstract": "This study presents innovative nested-isotropic lattices for additive\nmanufacturing, drawing inspiration from bio-architectures found in cortical\nbone osteons, golden spirals, and fractals. These lattices provide tunable\nanisotropy by integrating architectural elements like ``nesting orders (NOs)''\nand corresponding ``nesting orientations (NORs),'' along with repetitive\nself-similar X-cross struts and three four-fold axes of symmetry, resulting in\na wide spectrum of lattice designs. Nine mono-nest and twenty multi-nest\nlattices, along with 252 parametric variations, are realized. The relative\ndensity \\( \\bar{\\rho} \\) and surface area density \\( \\bar{S} \\) are calculated.\nEmploying finite element-based numerical homogenization, elastic stiffness\ntensors are estimated to evaluate the anisotropic measure - Zener ratio \\( Z \\)\nand elastic modulus \\( \\bar{E} \\) for all lattice designs. The mono-nest\nlattices generated considering higher NOs and respective NORs exhibit a\ntransition from shear dominant to tensile/compression dominant (TCD)\nanisotropic behavior and their strut size variations show a strong influence on\n\\( \\bar{\\rho} \\), \\( \\bar{S} \\), and \\( \\bar{E} \\). In contrast, multi-nest\nlattices exhibit isotropic and neo-isotropic characteristics, with strut size\nmismatch exerting more influence on \\( Z \\). Increasing NOs and NORs result in\nisotropic or TCD behavior for most multi-nest lattices, with strut size\nmismatch leading to many isotropic lattices. These bio-inspired nested\nlattices, coupled with advancements in additive manufacturing, hold potential\nfor diverse applications.",
        "subjects": [
            "cs.CE"
        ],
        "authors": [
            "R. Boda",
            "B. Panda",
            "S. Kumar"
        ],
        "published": "2024-05-19T16:05:06Z"
    },
    {
        "title": "Generative Students: Using LLM-Simulated Student Profiles to Support\n  Question Item Evaluation",
        "link": "http://dx.doi.org/10.1145/3657604.3662031",
        "abstract": "Evaluating the quality of automatically generated question items has been a\nlong standing challenge. In this paper, we leverage LLMs to simulate student\nprofiles and generate responses to multiple-choice questions (MCQs). The\ngenerative students' responses to MCQs can further support question item\nevaluation. We propose Generative Students, a prompt architecture designed\nbased on the KLI framework. A generative student profile is a function of the\nlist of knowledge components the student has mastered, has confusion about or\nhas no evidence of knowledge of. We instantiate the Generative Students concept\non the subject domain of heuristic evaluation. We created 45 generative\nstudents using GPT-4 and had them respond to 20 MCQs. We found that the\ngenerative students produced logical and believable responses that were aligned\nwith their profiles. We then compared the generative students' responses to\nreal students' responses on the same set of MCQs and found a high correlation.\nMoreover, there was considerable overlap in the difficult questions identified\nby generative students and real students. A subsequent case study demonstrated\nthat an instructor could improve question quality based on the signals provided\nby Generative Students.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Xinyi Lu",
            "Xu Wang"
        ],
        "published": "2024-05-19T15:53:18Z"
    },
    {
        "title": "Global Convergence of Decentralized Retraction-Free Optimization on the\n  Stiefel Manifold",
        "link": "http://arxiv.org/abs/2405.11590v1",
        "abstract": "Many classical and modern machine learning algorithms require solving\noptimization tasks under orthogonal constraints. Solving these tasks often\nrequire calculating retraction-based gradient descent updates on the\ncorresponding Riemannian manifold, which can be computationally expensive.\nRecently Ablin et al. proposed an infeasible retraction-free algorithm, which\nis significantly more efficient. In this paper, we study the decentralized\nnon-convex optimization task over a network of agents on the Stiefel manifold\nwith retraction-free updates. We propose \\textbf{D}ecentralized\n\\textbf{R}etraction-\\textbf{F}ree \\textbf{G}radient \\textbf{T}racking (DRFGT)\nalgorithm, and show that DRFGT exhibits ergodic $\\mathcal{O}(1/K)$ convergence\nrate, the same rate of convergence as the centralized, retraction-based\nmethods. We also provide numerical experiments demonstrating that DRFGT\nperforms on par with the state-of-the-art retraction based methods with\nsubstantially reduced computational overhead.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Youbang Sun",
            "Shixiang Chen",
            "Alfredo Garcia",
            "Shahin Shahrampour"
        ],
        "published": "2024-05-19T15:50:57Z"
    },
    {
        "title": "Efficient absorbing boundary conditions for conservation laws:\n  Application to the piston problem of gas dynamics",
        "link": "http://arxiv.org/abs/2405.11588v1",
        "abstract": "In this work, we address the imposition of outflow boundary conditions for\none-dimensional conservation laws. While a highly accurate numerical solution\ncan be obtained in the interior of the domain, boundary discretization can lead\nto unphysical reflections. We investigate and implement some classes of\nrelaxation methods and far-field operators to deal with this problem without\nsignificantly increasing the size of the computational domain. Relations are\nestablished between these techniques, and extensions of them are explored. In\nparticular, we introduce a simple and robust relaxation method with a\nmatrix-valued weight function that selectively absorbs outgoing waves. As a\nchallenging model problem, we consider the Lagrangian formulation of the Euler\nequations for an isotropic gas with inflow boundary conditions determined by an\noscillating piston.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "65M08, 35L02, 76N99"
        ],
        "authors": [
            "Carlos Mu√±oz-Moncayo"
        ],
        "published": "2024-05-19T15:39:50Z"
    },
    {
        "title": "SLAB: Efficient Transformers with Simplified Linear Attention and\n  Progressive Re-parameterized Batch Normalization",
        "link": "http://arxiv.org/abs/2405.11582v1",
        "abstract": "Transformers have become foundational architectures for both natural language\nand computer vision tasks. However, the high computational cost makes it quite\nchallenging to deploy on resource-constraint devices. This paper investigates\nthe computational bottleneck modules of efficient transformer, i.e.,\nnormalization layers and attention modules. LayerNorm is commonly used in\ntransformer architectures but is not computational friendly due to statistic\ncalculation during inference. However, replacing LayerNorm with more efficient\nBatchNorm in transformer often leads to inferior performance and collapse in\ntraining. To address this problem, we propose a novel method named PRepBN to\nprogressively replace LayerNorm with re-parameterized BatchNorm in training.\nMoreover, we propose a simplified linear attention (SLA) module that is simple\nyet effective to achieve strong performance. Extensive experiments on image\nclassification as well as object detection demonstrate the effectiveness of our\nproposed method. For example, our SLAB-Swin obtains $83.6\\%$ top-1 accuracy on\nImageNet-1K with $16.2$ms latency, which is $2.4$ms less than that of\nFlatten-Swin with $0.1\\%$ higher accuracy. We also evaluated our method for\nlanguage modeling task and obtain comparable performance and lower\nlatency.Codes are publicly available at https://github.com/xinghaochen/SLAB and\nhttps://github.com/mindspore-lab/models/tree/master/research/huawei-noah/SLAB.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "authors": [
            "Jialong Guo",
            "Xinghao Chen",
            "Yehui Tang",
            "Yunhe Wang"
        ],
        "published": "2024-05-19T15:22:25Z"
    },
    {
        "title": "DOLLmC: DevOps for Large Language model Customization",
        "link": "http://arxiv.org/abs/2405.11581v2",
        "abstract": "The rapid integration of Large Language Models (LLMs) into various industries\npresents both revolutionary opportunities and unique challenges. This research\naims to establish a scalable and efficient framework for LLM customization,\nexploring how DevOps practices should be adapted to meet the specific demands\nof LLM customization. By integrating ontologies, knowledge maps, and prompt\nengineering into the DevOps pipeline, we propose a robust framework that\nenhances continuous learning, seamless deployment, and rigorous version control\nof LLMs. This methodology is demonstrated through the development of a\ndomain-specific chatbot for the agricultural sector, utilizing heterogeneous\ndata to deliver actionable insights. The proposed methodology, so called\nDOLLmC, not only addresses the immediate challenges of LLM customization but\nalso promotes scalability and operational efficiency. However, the\nmethodology's primary limitation lies in the need for extensive testing,\nvalidation, and broader adoption across different domains.",
        "subjects": [
            "cs.SE",
            "D.2.9"
        ],
        "authors": [
            "Panos Fitsilis",
            "Vyron Damasiotis",
            "Vasileios Kyriatzis",
            "Paraskevi Tsoutsa"
        ],
        "published": "2024-05-19T15:20:27Z"
    },
    {
        "title": "Securing Health Data on the Blockchain: A Differential Privacy and\n  Federated Learning Framework",
        "link": "http://arxiv.org/abs/2405.11580v1",
        "abstract": "This study proposes a framework to enhance privacy in Blockchain-based\nInternet of Things (BIoT) systems used in the healthcare sector. The framework\naddresses the challenge of leveraging health data for analytics while\nprotecting patient privacy. To achieve this, the study integrates Differential\nPrivacy (DP) with Federated Learning (FL) to protect sensitive health data\ncollected by IoT nodes. The proposed framework utilizes dynamic personalization\nand adaptive noise distribution strategies to balance privacy and data utility.\nAdditionally, blockchain technology ensures secure and transparent aggregation\nand storage of model updates. Experimental results on the SVHN dataset\ndemonstrate that the proposed framework achieves strong privacy guarantees\nagainst various attack scenarios while maintaining high accuracy in health\nanalytics tasks. For 15 rounds of federated learning with an epsilon value of\n8.0, the model obtains an accuracy of 64.50%. The blockchain integration,\nutilizing Ethereum, Ganache, Web3.py, and IPFS, exhibits an average transaction\nlatency of around 6 seconds and consistent gas consumption across rounds,\nvalidating the practicality and feasibility of the proposed approach.",
        "subjects": [
            "cs.CR",
            "cs.CY",
            "cs.DC",
            "cs.LG"
        ],
        "authors": [
            "Daniel Commey",
            "Sena Hounsinou",
            "Garth V. Crosby"
        ],
        "published": "2024-05-19T15:15:18Z"
    },
    {
        "title": "Exploring the Capabilities of Prompted Large Language Models in\n  Educational and Assessment Applications",
        "link": "http://arxiv.org/abs/2405.11579v1",
        "abstract": "In the era of generative artificial intelligence (AI), the fusion of large\nlanguage models (LLMs) offers unprecedented opportunities for innovation in the\nfield of modern education. We embark on an exploration of prompted LLMs within\nthe context of educational and assessment applications to uncover their\npotential. Through a series of carefully crafted research questions, we\ninvestigate the effectiveness of prompt-based techniques in generating\nopen-ended questions from school-level textbooks, assess their efficiency in\ngenerating open-ended questions from undergraduate-level technical textbooks,\nand explore the feasibility of employing a chain-of-thought inspired\nmulti-stage prompting approach for language-agnostic multiple-choice question\n(MCQ) generation. Additionally, we evaluate the ability of prompted LLMs for\nlanguage learning, exemplified through a case study in the low-resource Indian\nlanguage Bengali, to explain Bengali grammatical errors. We also evaluate the\npotential of prompted LLMs to assess human resource (HR) spoken interview\ntranscripts. By juxtaposing the capabilities of LLMs with those of human\nexperts across various educational tasks and domains, our aim is to shed light\non the potential and limitations of LLMs in reshaping educational practices.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Subhankar Maity",
            "Aniket Deroy",
            "Sudeshna Sarkar"
        ],
        "published": "2024-05-19T15:13:51Z"
    },
    {
        "title": "A Multi-Perspective Analysis of Memorization in Large Language Models",
        "link": "http://arxiv.org/abs/2405.11577v1",
        "abstract": "Large Language Models (LLMs), trained on massive corpora with billions of\nparameters, show unprecedented performance in various fields. Though surprised\nby their excellent performances, researchers also noticed some special\nbehaviors of those LLMs. One of those behaviors is memorization, in which LLMs\ncan generate the same content used to train them. Though previous research has\ndiscussed memorization, the memorization of LLMs still lacks explanation,\nespecially the cause of memorization and the dynamics of generating them. In\nthis research, we comprehensively discussed memorization from various\nperspectives and extended the discussion scope to not only just the memorized\ncontent but also less and unmemorized content. Through various studies, we\nfound that: (1) Through experiments, we revealed the relation of memorization\nbetween model size, continuation size, and context size. Further, we showed how\nunmemorized sentences transition to memorized sentences. (2) Through embedding\nanalysis, we showed the distribution and decoding dynamics across model size in\nembedding space for sentences with different memorization scores. The n-gram\nstatistics analysis presents d (3) An analysis over n-gram and entropy decoding\ndynamics discovered a boundary effect when the model starts to generate\nmemorized sentences or unmemorized sentences. (4)We trained a Transformer model\nto predict the memorization of different models, showing that it is possible to\npredict memorizations by context.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Bowen Chen",
            "Namgi Han",
            "Yusuke Miyao"
        ],
        "published": "2024-05-19T15:00:50Z"
    },
    {
        "title": "SEEP: Training Dynamics Grounds Latent Representation Search for\n  Mitigating Backdoor Poisoning Attacks",
        "link": "http://arxiv.org/abs/2405.11575v1",
        "abstract": "Modern NLP models are often trained on public datasets drawn from diverse\nsources, rendering them vulnerable to data poisoning attacks. These attacks can\nmanipulate the model's behavior in ways engineered by the attacker. One such\ntactic involves the implantation of backdoors, achieved by poisoning specific\ntraining instances with a textual trigger and a target class label. Several\nstrategies have been proposed to mitigate the risks associated with backdoor\nattacks by identifying and removing suspected poisoned examples. However, we\nobserve that these strategies fail to offer effective protection against\nseveral advanced backdoor attacks. To remedy this deficiency, we propose a\nnovel defensive mechanism that first exploits training dynamics to identify\npoisoned samples with high precision, followed by a label propagation step to\nimprove recall and thus remove the majority of poisoned instances. Compared\nwith recent advanced defense methods, our method considerably reduces the\nsuccess rates of several backdoor attacks while maintaining high classification\naccuracy on clean test sets.",
        "subjects": [
            "cs.CL",
            "cs.CR"
        ],
        "authors": [
            "Xuanli He",
            "Qiongkai Xu",
            "Jun Wang",
            "Benjamin I. P. Rubinstein",
            "Trevor Cohn"
        ],
        "published": "2024-05-19T14:50:09Z"
    },
    {
        "title": "Reproducibility Study of CDUL: CLIP-Driven Unsupervised Learning for\n  Multi-Label Image Classification",
        "link": "http://arxiv.org/abs/2405.11574v1",
        "abstract": "This report is a reproducibility study of the paper \"CDUL: CLIP-Driven\nUnsupervised Learning for Multi-Label Image Classification\" (Abdelfattah et al,\nICCV 2023). Our report makes the following contributions: (1) We provide a\nreproducible, well commented and open-sourced code implementation for the\nentire method specified in the original paper. (2) We try to verify the\neffectiveness of the novel aggregation strategy which uses the CLIP model to\ninitialize the pseudo labels for the subsequent unsupervised multi-label image\nclassification task. (3) We try to verify the effectiveness of the\ngradient-alignment training method specified in the original paper, which is\nused to update the network parameters and pseudo labels. The code can be found\nat https://github.com/cs-mshah/CDUL",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Manan Shah",
            "Yash Bhalgat"
        ],
        "published": "2024-05-19T14:48:19Z"
    },
    {
        "title": "Quantile Activation: departing from single point estimation for better\n  generalization across distortions",
        "link": "http://arxiv.org/abs/2405.11573v1",
        "abstract": "A classifier is, in its essence, a function which takes an input and returns\nthe class of the input and implicitly assumes an underlying distribution. We\nargue in this article that one has to move away from this basic tenet to obtain\ngeneralisation across distributions. Specifically, the class of the sample\nshould depend on the points from its context distribution for better\ngeneralisation across distributions.\n  How does one achieve this? The key idea is to adapt the outputs of each\nneuron of the network to its context distribution. We propose quantile\nactivation, QACT, which, in simple terms, outputs the relative quantile of the\nsample in its context distribution, instead of the actual values in traditional\nnetworks.\n  The scope of this article is to validate the proposed activation across\nseveral experimental settings, and compare it with conventional techniques. For\nthis, we use the datasets developed to test robustness against distortions\nCIFAR10C, CIFAR100C, MNISTC, TinyImagenetC, and show that we achieve a\nsignificantly higher generalisation across distortions than the conventional\nclassifiers, across different architectures. Although this paper is only a\nproof of concept, we surprisingly find that this approach outperforms\nDINOv2(small) at large distortions, even though DINOv2 is trained with a far\nbigger network on a considerably larger dataset.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Aditya Challa",
            "Sravan Danda",
            "Laurent Najman",
            "Snehanshu Saha"
        ],
        "published": "2024-05-19T14:42:19Z"
    },
    {
        "title": "Uncertainty-Aware PPG-2-ECG for Enhanced Cardiovascular Diagnosis using\n  Diffusion Models",
        "link": "http://arxiv.org/abs/2405.11566v1",
        "abstract": "Analyzing the cardiovascular system condition via Electrocardiography (ECG)\nis a common and highly effective approach, and it has been practiced and\nperfected over many decades. ECG sensing is non-invasive and relatively easy to\nacquire, and yet it is still cumbersome for holter monitoring tests that may\nspan over hours and even days. A possible alternative in this context is\nPhotoplethysmography (PPG): An optically-based signal that measures blood\nvolume fluctuations, as typically sensed by conventional ``wearable devices''.\nWhile PPG presents clear advantages in acquisition, convenience, and\ncost-effectiveness, ECG provides more comprehensive information, allowing for a\nmore precise detection of heart conditions. This implies that a conversion from\nPPG to ECG, as recently discussed in the literature, inherently involves an\nunavoidable level of uncertainty. In this paper we introduce a novel\nmethodology for addressing the PPG-2-ECG conversion, and offer an enhanced\nclassification of cardiovascular conditions using the given PPG, all while\ntaking into account the uncertainties arising from the conversion process. We\nprovide a mathematical justification for our proposed computational approach,\nand present empirical studies demonstrating its superior performance compared\nto state-of-the-art baseline methods.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Omer Belhasin",
            "Idan Kligvasser",
            "George Leifman",
            "Regev Cohen",
            "Erin Rainaldi",
            "Li-Fang Cheng",
            "Nishant Verma",
            "Paul Varghese",
            "Ehud Rivlin",
            "Michael Elad"
        ],
        "published": "2024-05-19T14:30:57Z"
    },
    {
        "title": "CRF360D: Monocular 360 Depth Estimation via Spherical Fully-Connected\n  CRFs",
        "link": "http://arxiv.org/abs/2405.11564v1",
        "abstract": "Monocular 360 depth estimation is challenging due to the inherent distortion\nof the equirectangular projection (ERP). This distortion causes a problem:\nspherical adjacent points are separated after being projected to the ERP plane,\nparticularly in the polar regions. To tackle this problem, recent methods\ncalculate the spherical neighbors in the tangent domain. However, as the\ntangent patch and sphere only have one common point, these methods construct\nneighboring spherical relationships around the common point. In this paper, we\npropose spherical fully-connected CRFs (SF-CRFs). We begin by evenly\npartitioning an ERP image with regular windows, where windows at the equator\ninvolve broader spherical neighbors than those at the poles. To improve the\nspherical relationships, our SF-CRFs enjoy two key components. Firstly, to\ninvolve sufficient spherical neighbors, we propose a Spherical Window Transform\n(SWT) module. This module aims to replicate the equator window's spherical\nrelationships to all other windows, leveraging the rotational invariance of the\nsphere. Remarkably, the transformation process is highly efficient, completing\nthe transformation of all windows in a 512X1024 ERP with 0.038 seconds on CPU.\nSecondly, we propose a Planar-Spherical Interaction (PSI) module to facilitate\nthe relationships between regular and transformed windows, which not only\npreserves the local details but also captures global structures. By building a\ndecoder based on the SF-CRFs blocks, we propose CRF360D, a novel 360 depth\nestimation framework that achieves state-of-the-art performance across diverse\ndatasets. Our CRF360D is compatible with different perspective image-trained\nbackbones (e.g., EfficientNet), serving as the encoder.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zidong Cao",
            "Lin Wang"
        ],
        "published": "2024-05-19T14:29:06Z"
    },
    {
        "title": "User-Centric Association and Feedback Bit Allocation for FDD Cell-Free\n  Massive MIMO",
        "link": "http://arxiv.org/abs/2405.11563v1",
        "abstract": "In this paper, we introduce a novel approach to user-centric association and\nfeedback bit allocation for the downlink of a cell-free massive MIMO (CF-mMIMO)\nsystem, operating under limited feedback constraints. In CF-mMIMO systems\nemploying frequency division duplexing, each access point (AP) relies on\nchannel information provided by its associated user equipments (UEs) for\nbeamforming design. Since the uplink control channel is typically shared among\nUEs, we take account of each AP's total feedback budget, which is distributed\namong its associated UEs. By employing the Saleh-Valenzuela multi-resolvable\npath channel model with different average path gains, we first identify\nnecessary feedback information for each UE, along with an appropriate codebook\nstructure. This structure facilitates adaptive quantization of multiple paths\nbased on their dominance. We then formulate a joint optimization problem\naddressing user-centric UE-AP association and feedback bit allocation. To\naddress this challenge, we analyze the impact of feedback bit allocation and\nderive our proposed scheme from the solution of an alternative optimization\nproblem aimed at devising long-term policies, explicitly considering the\neffects of feedback bit allocation. Numerical results show that our proposed\nscheme effectively enhances the performance of conventional approaches in\nCF-mMIMO systems.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Kwangjae Lee",
            "Jung Hoon Lee",
            "Wan Choi"
        ],
        "published": "2024-05-19T14:29:02Z"
    },
    {
        "title": "DaVinci at SemEval-2024 Task 9: Few-shot prompting GPT-3.5 for\n  Unconventional Reasoning",
        "link": "http://arxiv.org/abs/2405.11559v1",
        "abstract": "While significant work has been done in the field of NLP on vertical\nthinking, which involves primarily logical thinking, little work has been done\ntowards lateral thinking, which involves looking at problems from an\nunconventional perspective and defying existing conceptions and notions.\nTowards this direction, SemEval 2024 introduces the task of BRAINTEASER, which\ninvolves two types of questions -- Sentence Puzzles and Word Puzzles that defy\nconventional common-sense reasoning and constraints. In this paper, we tackle\nboth types of questions using few-shot prompting on GPT-3.5 and gain insights\nregarding the difference in the nature of the two types. Our prompting strategy\nplaced us 26th on the leaderboard for the Sentence Puzzle and 15th on the Word\nPuzzle task.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Suyash Vardhan Mathur",
            "Akshett Rai Jindal",
            "Manish Shrivastava"
        ],
        "published": "2024-05-19T14:21:53Z"
    },
    {
        "title": "DAC-JAX: A JAX Implementation of the Descript Audio Codec",
        "link": "http://arxiv.org/abs/2405.11554v1",
        "abstract": "We present an open-source implementation of the Descript Audio Codec (DAC)\nusing Google's JAX ecosystem of Flax, Optax, Orbax, AUX, and CLU. Our codebase\nenables the reuse of model weights from the original PyTorch DAC, and we\nconfirm that the two implementations produce equivalent token sequences and\ndecoded audio if given the same input. We provide a training and fine-tuning\nscript which supports device parallelism, although we have only verified it\nusing brief training runs with a small dataset. Even with limited GPU memory,\nthe original DAC can compress or decompress a long audio file by processing it\nas a sequence of overlapping \"chunks.\" We implement this feature in JAX and\nbenchmark the performance on two types of GPUs. On a consumer-grade GPU,\nDAC-JAX outperforms the original DAC for compression and decompression at all\nchunk sizes. However, on a high-performance, cluster-based GPU, DAC-JAX\noutperforms the original DAC for small chunk sizes but performs worse for large\nchunks.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "David Braun"
        ],
        "published": "2024-05-19T14:07:31Z"
    },
    {
        "title": "An Invisible Backdoor Attack Based On Semantic Feature",
        "link": "http://arxiv.org/abs/2405.11551v1",
        "abstract": "Backdoor attacks have severely threatened deep neural network (DNN) models in\nthe past several years. These attacks can occur in almost every stage of the\ndeep learning pipeline. Although the attacked model behaves normally on benign\nsamples, it makes wrong predictions for samples containing triggers. However,\nmost existing attacks use visible patterns (e.g., a patch or image\ntransformations) as triggers, which are vulnerable to human inspection. In this\npaper, we propose a novel backdoor attack, making imperceptible changes.\nConcretely, our attack first utilizes the pre-trained victim model to extract\nlow-level and high-level semantic features from clean images and generates\ntrigger pattern associated with high-level features based on channel attention.\nThen, the encoder model generates poisoned images based on the trigger and\nextracted low-level semantic features without causing noticeable feature loss.\nWe evaluate our attack on three prominent image classification DNN across three\nstandard datasets. The results demonstrate that our attack achieves high attack\nsuccess rates while maintaining robustness against backdoor defenses.\nFurthermore, we conduct extensive image similarity experiments to emphasize the\nstealthiness of our attack strategy.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Yangming Chen"
        ],
        "published": "2024-05-19T13:50:40Z"
    },
    {
        "title": "Towards Optimal Beacon Placement for Range-Aided Localization",
        "link": "http://arxiv.org/abs/2405.11550v1",
        "abstract": "Range-based localization is ubiquitous: global navigation satellite systems\n(GNSS) power mobile phone-based navigation, and autonomous mobile robots can\nuse range measurements from a variety of modalities including sonar, radar, and\neven WiFi signals. Many of these localization systems rely on fixed anchors or\nbeacons with known positions acting as transmitters or receivers. In this work,\nwe answer a fundamental question: given a set of positions we would like to\nlocalize, how should beacons be placed so as to minimize localization error?\nSpecifically, we present an information theoretic method for optimally\nselecting an arrangement consisting of a few beacons from a large set of\ncandidate positions. By formulating localization as maximum a posteriori (MAP)\nestimation, we can cast beacon arrangement as a submodular set function\nmaximization problem. This approach is probabilistically rigorous, simple to\nimplement, and extremely flexible. Furthermore, we prove that the submodular\nstructure of our problem formulation ensures that a greedy algorithm for beacon\narrangement has suboptimality guarantees. We compare our method with a number\nof benchmarks on simulated data and release an open source Python\nimplementation of our algorithm and experiments.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Ethan Sequeira",
            "Hussein Saad",
            "Stephen Kelly",
            "Matthew Giamou"
        ],
        "published": "2024-05-19T13:48:32Z"
    },
    {
        "title": "Adaptive Online Experimental Design for Causal Discovery",
        "link": "http://arxiv.org/abs/2405.11548v1",
        "abstract": "Causal discovery aims to uncover cause-and-effect relationships encoded in\ncausal graphs by leveraging observational, interventional data, or their\ncombination. The majority of existing causal discovery methods are developed\nassuming infinite interventional data. We focus on data interventional\nefficiency and formalize causal discovery from the perspective of online\nlearning, inspired by pure exploration in bandit problems. A graph separating\nsystem, consisting of interventions that cut every edge of the graph at least\nonce, is sufficient for learning causal graphs when infinite interventional\ndata is available, even in the worst case. We propose a track-and-stop causal\ndiscovery algorithm that adaptively selects interventions from the graph\nseparating system via allocation matching and learns the causal graph based on\nsampling history. Given any desired confidence value, the algorithm determines\na termination condition and runs until it is met. We analyze the algorithm to\nestablish a problem-dependent upper bound on the expected number of required\ninterventional samples. Our proposed algorithm outperforms existing methods in\nsimulations across various randomly generated causal graphs. It achieves higher\naccuracy, measured by the structural hamming distance (SHD) between the learned\ncausal graph and the ground truth, with significantly fewer samples.",
        "subjects": [
            "cs.LG",
            "stat.AP"
        ],
        "authors": [
            "Muhammad Qasim Elahi",
            "Lai Wei",
            "Murat Kocaoglu",
            "Mahsa Ghasemi"
        ],
        "published": "2024-05-19T13:26:33Z"
    },
    {
        "title": "Certified Robust Accuracy of Neural Networks Are Bounded due to Bayes\n  Errors",
        "link": "http://arxiv.org/abs/2405.11547v1",
        "abstract": "Adversarial examples pose a security threat to many critical systems built on\nneural networks. While certified training improves robustness, it also\ndecreases accuracy noticeably. Despite various proposals for addressing this\nissue, the significant accuracy drop remains. More importantly, it is not clear\nwhether there is a certain fundamental limit on achieving robustness whilst\nmaintaining accuracy. In this work, we offer a novel perspective based on Bayes\nerrors. By adopting Bayes error to robustness analysis, we investigate the\nlimit of certified robust accuracy, taking into account data distribution\nuncertainties. We first show that the accuracy inevitably decreases in the\npursuit of robustness due to changed Bayes error in the altered data\ndistribution. Subsequently, we establish an upper bound for certified robust\naccuracy, considering the distribution of individual classes and their\nboundaries. Our theoretical results are empirically evaluated on real-world\ndatasets and are shown to be consistent with the limited success of existing\ncertified training results, \\emph{e.g.}, for CIFAR10, our analysis results in\nan upper bound (of certified robust accuracy) of 67.49\\%, meanwhile existing\napproaches are only able to increase it from 53.89\\% in 2017 to 62.84\\% in\n2023.",
        "subjects": [
            "stat.ML",
            "cs.CR",
            "cs.LG"
        ],
        "authors": [
            "Ruihan Zhang",
            "Jun Sun"
        ],
        "published": "2024-05-19T13:23:05Z"
    },
    {
        "title": "From Fourier to Neural ODEs: Flow Matching for Modeling Complex Systems",
        "link": "http://arxiv.org/abs/2405.11542v2",
        "abstract": "Modeling complex systems using standard neural ordinary differential\nequations (NODEs) often faces some essential challenges, including high\ncomputational costs and susceptibility to local optima. To address these\nchallenges, we propose a simulation-free framework, called Fourier NODEs\n(FNODEs), that effectively trains NODEs by directly matching the target vector\nfield based on Fourier analysis. Specifically, we employ the Fourier analysis\nto estimate temporal and potential high-order spatial gradients from noisy\nobservational data. We then incorporate the estimated spatial gradients as\nadditional inputs to a neural network. Furthermore, we utilize the estimated\ntemporal gradient as the optimization objective for the output of the neural\nnetwork. Later, the trained neural network generates more data points through\nan ODE solver without participating in the computational graph, facilitating\nmore accurate estimations of gradients based on Fourier analysis. These two\nsteps form a positive feedback loop, enabling accurate dynamics modeling in our\nframework. Consequently, our approach outperforms state-of-the-art methods in\nterms of training time, dynamics prediction, and robustness. Finally, we\ndemonstrate the superior performance of our framework using a number of\nrepresentative complex systems.",
        "subjects": [
            "cs.LG",
            "physics.ed-ph"
        ],
        "authors": [
            "Xin Li",
            "Jingdong Zhang",
            "Qunxi Zhu",
            "Chengli Zhao",
            "Xue Zhang",
            "Xiaojun Duan",
            "Wei Lin"
        ],
        "published": "2024-05-19T13:15:23Z"
    },
    {
        "title": "R-NeRF: Neural Radiance Fields for Modeling RIS-enabled Wireless\n  Environments",
        "link": "http://arxiv.org/abs/2405.11541v1",
        "abstract": "Recently, ray tracing has gained renewed interest with the advent of\nReflective Intelligent Surfaces (RIS) technology, a key enabler of 6G wireless\ncommunications due to its capability of intelligent manipulation of\nelectromagnetic waves. However, accurately modeling RIS-enabled wireless\nenvironments poses significant challenges due to the complex variations caused\nby various environmental factors and the mobility of RISs. In this paper, we\npropose a novel modeling approach using Neural Radiance Fields (NeRF) to\ncharacterize the dynamics of electromagnetic fields in such environments. Our\nmethod utilizes NeRF-based ray tracing to intuitively capture and visualize the\ncomplex dynamics of signal propagation, effectively modeling the complete\nsignal pathways from the transmitter to the RIS, and from the RIS to the\nreceiver. This two-stage process accurately characterizes multiple complex\ntransmission paths, enhancing our understanding of signal behavior in\nreal-world scenarios. Our approach predicts the signal field for any specified\nRIS placement and receiver location, facilitating efficient RIS deployment.\nExperimental evaluations using both simulated and real-world data validate the\nsignificant benefits of our methodology.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Huiying Yang",
            "Zihan Jin",
            "Chenhao Wu",
            "Rujing Xiong",
            "Robert Caiming Qiu",
            "Zenan Ling"
        ],
        "published": "2024-05-19T13:11:48Z"
    },
    {
        "title": "Human-Centered LLM-Agent User Interface: A Position Paper",
        "link": "http://arxiv.org/abs/2405.13050v1",
        "abstract": "Large Language Model (LLM) -in-the-loop applications have been shown to\neffectively interpret the human user's commands, make plans, and operate\nexternal tools/systems accordingly. Still, the operation scope of the LLM agent\nis limited to passively following the user, requiring the user to frame his/her\nneeds with regard to the underlying tools/systems. We note that the potential\nof an LLM-Agent User Interface (LAUI) is much greater. A user mostly ignorant\nto the underlying tools/systems should be able to work with a LAUI to discover\nan emergent workflow. Contrary to the conventional way of designing an\nexplorable GUI to teach the user a predefined set of ways to use the system, in\nthe ideal LAUI, the LLM agent is initialized to be proficient with the system,\nproactively studies the user and his/her needs, and proposes new interaction\nschemes to the user. To illustrate LAUI, we present Flute X GPT, a concrete\nexample using an LLM agent, a prompt manager, and a flute-tutoring multi-modal\nsoftware-hardware system to facilitate the complex, real-time user experience\nof learning to play the flute.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Daniel Chin",
            "Yuxuan Wang",
            "Gus Xia"
        ],
        "published": "2024-05-19T13:02:45Z"
    },
    {
        "title": "VR-GPT: Visual Language Model for Intelligent Virtual Reality\n  Applications",
        "link": "http://arxiv.org/abs/2405.11537v1",
        "abstract": "The advent of immersive Virtual Reality applications has transformed various\ndomains, yet their integration with advanced artificial intelligence\ntechnologies like Visual Language Models remains underexplored. This study\nintroduces a pioneering approach utilizing VLMs within VR environments to\nenhance user interaction and task efficiency. Leveraging the Unity engine and a\ncustom-developed VLM, our system facilitates real-time, intuitive user\ninteractions through natural language processing, without relying on visual\ntext instructions. The incorporation of speech-to-text and text-to-speech\ntechnologies allows for seamless communication between the user and the VLM,\nenabling the system to guide users through complex tasks effectively.\nPreliminary experimental results indicate that utilizing VLMs not only reduces\ntask completion times but also improves user comfort and task engagement\ncompared to traditional VR interaction methods.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.ET"
        ],
        "authors": [
            "Mikhail Konenkov",
            "Artem Lykov",
            "Daria Trinitatova",
            "Dzmitry Tsetserukou"
        ],
        "published": "2024-05-19T12:56:00Z"
    },
    {
        "title": "RobMOT: Robust 3D Multi-Object Tracking by Observational Noise and State\n  Estimation Drift Mitigation on LiDAR PointCloud",
        "link": "http://arxiv.org/abs/2405.11536v1",
        "abstract": "This work addresses the inherited limitations in the current state-of-the-art\n3D multi-object tracking (MOT) methods that follow the tracking-by-detection\nparadigm, notably trajectory estimation drift for long-occluded objects in\nLiDAR point cloud streams acquired by autonomous cars. In addition, the absence\nof adequate track legitimacy verification results in ghost track accumulation.\nTo tackle these issues, we introduce a two-fold innovation. Firstly, we propose\nrefinement in Kalman filter that enhances trajectory drift noise mitigation,\nresulting in more robust state estimation for occluded objects. Secondly, we\npropose a novel online track validity mechanism to distinguish between\nlegitimate and ghost tracks combined with a multi-stage observational gating\nprocess for incoming observations. This mechanism substantially reduces ghost\ntracks by up to 80\\% and improves HOTA by 7\\%. Accordingly, we propose an\nonline 3D MOT framework, RobMOT, that demonstrates superior performance over\nthe top-performing state-of-the-art methods, including deep learning\napproaches, across various detectors with up to 3.28\\% margin in MOTA and\n2.36\\% in HOTA. RobMOT excels under challenging conditions, such as prolonged\nocclusions and the tracking of distant objects, with up to 59\\% enhancement in\nprocessing latency.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Mohamed Nagy",
            "Naoufel Werghi",
            "Bilal Hassan",
            "Jorge Dias",
            "Majid Khonji"
        ],
        "published": "2024-05-19T12:49:21Z"
    },
    {
        "title": "Proving Functional Program Equivalence via Directed Lemma Synthesis",
        "link": "http://arxiv.org/abs/2405.11535v1",
        "abstract": "Proving equivalence between functional programs is a fundamental problem in\nprogram verification, which often amounts to reasoning about algebraic data\ntypes (ADTs) and compositions of structural recursions. Modern theorem provers\naddress this problem by applying structural induction, which is insufficient\nfor proving many equivalence theorems. In such cases, one has to invent a set\nof lemmas, prove these lemmas by additional induction, and use these lemmas to\nprove the original theorem. There is, however, a lack of systematic\nunderstanding of what lemmas are needed for inductive proofs and how these\nlemmas can be synthesized automatically. This paper presents directed lemma\nsynthesis, an effective approach to automating equivalence proofs by\ndiscovering critical lemmas using program synthesis techniques. We first\nidentify two induction-friendly forms of propositions that give formal\nguarantees to the progress of the proof. We then propose two tactics that\nsynthesize and apply lemmas, thereby transforming the proof goal into\ninduction-friendly forms. Both tactics reduce lemma synthesis to a specialized\nclass of program synthesis problems with efficient algorithms. Experimental\nresults demonstrate the effectiveness of our approach: Compared to\nstate-of-the-art equivalence checkers employing heuristic-based lemma\nenumeration, directed lemma synthesis saves 95.47% runtime on average and\nsolves 38 more tasks over an extended version of the standard benchmark set.",
        "subjects": [
            "cs.PL"
        ],
        "authors": [
            "Yican Sun",
            "Ruyi Ji",
            "Jian Fang",
            "Xuanlin Jiang",
            "Mingshuai Chen",
            "Yingfei Xiong"
        ],
        "published": "2024-05-19T12:42:39Z"
    },
    {
        "title": "Hierarchical Selective Classification",
        "link": "http://arxiv.org/abs/2405.11533v1",
        "abstract": "Deploying deep neural networks for risk-sensitive tasks necessitates an\nuncertainty estimation mechanism. This paper introduces hierarchical selective\nclassification, extending selective classification to a hierarchical setting.\nOur approach leverages the inherent structure of class relationships, enabling\nmodels to reduce the specificity of their predictions when faced with\nuncertainty. In this paper, we first formalize hierarchical risk and coverage,\nand introduce hierarchical risk-coverage curves. Next, we develop algorithms\nfor hierarchical selective classification (which we refer to as \"inference\nrules\"), and propose an efficient algorithm that guarantees a target accuracy\nconstraint with high probability. Lastly, we conduct extensive empirical\nstudies on over a thousand ImageNet classifiers, revealing that training\nregimes such as CLIP, pretraining on ImageNet21k and knowledge distillation\nboost hierarchical selective performance.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Shani Goren",
            "Ido Galil",
            "Ran El-Yaniv"
        ],
        "published": "2024-05-19T12:24:30Z"
    },
    {
        "title": "Knowledge Graph Pruning for Recommendation",
        "link": "http://arxiv.org/abs/2405.11531v1",
        "abstract": "Recent years have witnessed the prosperity of knowledge graph based\nrecommendation system (KGRS), which enriches the representation of users,\nitems, and entities by structural knowledge with striking improvement.\nNevertheless, its unaffordable computational cost still limits researchers from\nexploring more sophisticated models. We observe that the bottleneck for\ntraining efficiency arises from the knowledge graph, which is plagued by the\nwell-known issue of knowledge explosion. Recently, some works have attempted to\nslim the inflated KG via summarization techniques. However, these summarized\nnodes may ignore the collaborative signals and deviate from the facts that\nnodes in knowledge graph represent symbolic abstractions of entities from the\nreal-world. To this end, in this paper, we propose a novel approach called\nKGTrimmer for knowledge graph pruning tailored for recommendation, to remove\nthe unessential nodes while minimizing performance degradation. Specifically,\nwe design an importance evaluator from a dual-view perspective. For the\ncollective view, we embrace the idea of collective intelligence by extracting\ncommunity consensus based on abundant collaborative signals, i.e. nodes are\nconsidered important if they attract attention of numerous users. For the\nholistic view, we learn a global mask to identify the valueless nodes from\ntheir inherent properties or overall popularity. Next, we build an end-to-end\nimportance-aware graph neural network, which injects filtered knowledge to\nenhance the distillation of valuable user-item collaborative signals.\nUltimately, we generate a pruned knowledge graph with lightweight, stable, and\nrobust properties to facilitate the following-up recommendation task. Extensive\nexperiments are conducted on three publicly available datasets to prove the\neffectiveness and generalization ability of KGTrimmer.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "authors": [
            "Fake Lin",
            "Xi Zhu",
            "Ziwei Zhao",
            "Deqiang Huang",
            "Yu Yu",
            "Xueying Li",
            "Tong Xu",
            "Enhong Chen"
        ],
        "published": "2024-05-19T12:07:24Z"
    },
    {
        "title": "Learning More Generalized Experts by Merging Experts in\n  Mixture-of-Experts",
        "link": "http://arxiv.org/abs/2405.11530v1",
        "abstract": "We observe that incorporating a shared layer in a mixture-of-experts can lead\nto performance degradation. This leads us to hypothesize that learning shared\nfeatures poses challenges in deep learning, potentially caused by the same\nfeature being learned as various different features. To address this issue, we\ntrack each expert's usage frequency and merge the two most frequently selected\nexperts. We then update the least frequently selected expert using the\ncombination of experts. This approach, combined with the subsequent learning of\nthe router's expert selection, allows the model to determine if the most\nfrequently selected experts have learned the same feature differently. If they\nhave, the combined expert can be further trained to learn a more general\nfeature. Consequently, our algorithm enhances transfer learning and mitigates\ncatastrophic forgetting when applied to multi-domain task incremental learning.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Sejik Park"
        ],
        "published": "2024-05-19T11:55:48Z"
    },
    {
        "title": "Benchmarking Data Management Systems for Microservices",
        "link": "http://arxiv.org/abs/2405.11529v1",
        "abstract": "Microservice architectures are a popular choice for deploying large-scale\ndata-intensive applications. This architectural style allows microservice\npractitioners to achieve requirements related to loose coupling, fault\ncontention, workload isolation, higher data availability, scalability, and\nindependent schema evolution.\n  Although the industry has been employing microservices for over a decade,\nexisting microservice benchmarks lack essential data management challenges\nobserved in practice, including distributed transaction processing, consistent\ndata querying and replication, event processing, and data integrity constraint\nenforcement. This gap jeopardizes the development of novel data systems that\nembrace the complex nature of data-intensive microservices. In this talk, we\nshare our experience in designing Online Marketplace, a novel benchmark that\nembraces core data management requirements intrinsic to real-world\nmicroservices.\n  By implementing the benchmark in state-of-the-art data platforms, we\nexperience the pain practitioners face in assembling several heterogeneous\ncomponents to realize their requirements. Our evaluation demonstrates Online\nMarketplace allows experimenting key properties sought by microservice\npractitioners, thus fomenting the design of novel data management systems.",
        "subjects": [
            "cs.DB",
            "cs.SE"
        ],
        "authors": [
            "Rodrigo Laigner",
            "Yongluan Zhou"
        ],
        "published": "2024-05-19T11:55:45Z"
    },
    {
        "title": "Register assisted aggregation for Visual Place Recognition",
        "link": "http://arxiv.org/abs/2405.11526v1",
        "abstract": "Visual Place Recognition (VPR) refers to the process of using computer vision\nto recognize the position of the current query image. Due to the significant\nchanges in appearance caused by season, lighting, and time spans between query\nimages and database images for retrieval, these differences increase the\ndifficulty of place recognition. Previous methods often discarded useless\nfeatures (such as sky, road, vehicles) while uncontrolled discarding features\nthat help improve recognition accuracy (such as buildings, trees). To preserve\nthese useful features, we propose a new feature aggregation method to address\nthis issue. Specifically, in order to obtain global and local features that\ncontain discriminative place information, we added some registers on top of the\noriginal image tokens to assist in model training. After reallocating attention\nweights, these registers were discarded. The experimental results show that\nthese registers surprisingly separate unstable features from the original image\nrepresentation and outperform state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xuan Yu",
            "Zhenyong Fu"
        ],
        "published": "2024-05-19T11:36:52Z"
    },
    {
        "title": "Overcoming Data and Model Heterogeneities in Decentralized Federated\n  Learning via Synthetic Anchors",
        "link": "http://arxiv.org/abs/2405.11525v1",
        "abstract": "Conventional Federated Learning (FL) involves collaborative training of a\nglobal model while maintaining user data privacy. One of its branches,\ndecentralized FL, is a serverless network that allows clients to own and\noptimize different local models separately, which results in saving management\nand communication resources. Despite the promising advancements in\ndecentralized FL, it may reduce model generalizability due to lacking a global\nmodel. In this scenario, managing data and model heterogeneity among clients\nbecomes a crucial problem, which poses a unique challenge that must be\novercome: How can every client's local model learn generalizable representation\nin a decentralized manner? To address this challenge, we propose a novel\nDecentralized FL technique by introducing Synthetic Anchors, dubbed as DeSA.\nBased on the theory of domain adaptation and Knowledge Distillation (KD), we\ntheoretically and empirically show that synthesizing global anchors based on\nraw data distribution facilitates mutual knowledge transfer. We further design\ntwo effective regularization terms for local training: 1) REG loss that\nregularizes the distribution of the client's latent embedding with the anchors\nand 2) KD loss that enables clients to learn from others. Through extensive\nexperiments on diverse client data distributions, we showcase the effectiveness\nof DeSA in enhancing both inter- and intra-domain accuracy of each client.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Chun-Yin Huang",
            "Kartik Srinivas",
            "Xin Zhang",
            "Xiaoxiao Li"
        ],
        "published": "2024-05-19T11:36:45Z"
    },
    {
        "title": "Simple-Sampling and Hard-Mixup with Prototypes to Rebalance Contrastive\n  Learning for Text Classification",
        "link": "http://arxiv.org/abs/2405.11524v1",
        "abstract": "Text classification is a crucial and fundamental task in natural language\nprocessing. Compared with the previous learning paradigm of pre-training and\nfine-tuning by cross entropy loss, the recently proposed supervised contrastive\nlearning approach has received tremendous attention due to its powerful feature\nlearning capability and robustness. Although several studies have incorporated\nthis technique for text classification, some limitations remain. First, many\ntext datasets are imbalanced, and the learning mechanism of supervised\ncontrastive learning is sensitive to data imbalance, which may harm the model\nperformance. Moreover, these models leverage separate classification branch\nwith cross entropy and supervised contrastive learning branch without explicit\nmutual guidance. To this end, we propose a novel model named SharpReCL for\nimbalanced text classification tasks. First, we obtain the prototype vector of\neach class in the balanced classification branch to act as a representation of\neach class. Then, by further explicitly leveraging the prototype vectors, we\nconstruct a proper and sufficient target sample set with the same size for each\nclass to perform the supervised contrastive learning procedure. The empirical\nresults show the effectiveness of our model, which even outperforms popular\nlarge language models across several datasets.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Mengyu Li",
            "Yonghao Liu",
            "Fausto Giunchiglia",
            "Xiaoyue Feng",
            "Renchu Guan"
        ],
        "published": "2024-05-19T11:33:49Z"
    },
    {
        "title": "Diffusion-Based Hierarchical Image Steganography",
        "link": "http://arxiv.org/abs/2405.11523v1",
        "abstract": "This paper introduces Hierarchical Image Steganography, a novel method that\nenhances the security and capacity of embedding multiple images into a single\ncontainer using diffusion models. HIS assigns varying levels of robustness to\nimages based on their importance, ensuring enhanced protection against\nmanipulation. It adaptively exploits the robustness of the Diffusion Model\nalongside the reversibility of the Flow Model. The integration of Embed-Flow\nand Enhance-Flow improves embedding efficiency and image recovery quality,\nrespectively, setting HIS apart from conventional multi-image steganography\ntechniques. This innovative structure can autonomously generate a container\nimage, thereby securely and efficiently concealing multiple images and text.\nRigorous subjective and objective evaluations underscore our advantage in\nanalytical resistance, robustness, and capacity, illustrating its expansive\napplicability in content safeguarding and privacy fortification.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Youmin Xu",
            "Xuanyu Zhang",
            "Jiwen Yu",
            "Chong Mou",
            "Xiandong Meng",
            "Jian Zhang"
        ],
        "published": "2024-05-19T11:29:52Z"
    },
    {
        "title": "On Performance of FAS-aided Wireless Powered NOMA Communication Systems",
        "link": "http://arxiv.org/abs/2405.11520v1",
        "abstract": "This paper studies the performance of a wireless powered communication\nnetwork (WPCN) under the non-orthogonal multiple access (NOMA) scheme, where\nusers take advantage of an emerging fluid antenna system (FAS). More precisely,\nwe consider a scenario where a transmitter is powered by a remote power beacon\n(PB) to send information to the planar NOMA FAS-equipped users through Rayleigh\nfading channels. After introducing the distribution of the equivalent channel\ncoefficients to the users, we derive compact analytical expressions for the\noutage probability (OP) in order to evaluate the system performance.\nAdditionally, we present asymptotic OP in the high signal-to-noise ratio (SNR)\nregime. Eventually, results reveal that deploying the FAS with only one\nactivated port in NOMA users can significantly enhance the WPCN performance\ncompared with using traditional antenna systems (TAS).",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Farshad Rostami Ghadi",
            "Masoud Kaveh",
            "Kai-Kit Wong",
            "Riku Jantti",
            "Zheng Yan"
        ],
        "published": "2024-05-19T11:22:51Z"
    },
    {
        "title": "MSNER: A Multilingual Speech Dataset for Named Entity Recognition",
        "link": "http://arxiv.org/abs/2405.11519v1",
        "abstract": "While extensively explored in text-based tasks, Named Entity Recognition\n(NER) remains largely neglected in spoken language understanding. Existing\nresources are limited to a single, English-only dataset. This paper addresses\nthis gap by introducing MSNER, a freely available, multilingual speech corpus\nannotated with named entities. It provides annotations to the VoxPopuli dataset\nin four languages (Dutch, French, German, and Spanish). We have also releasing\nan efficient annotation tool that leverages automatic pre-annotations for\nfaster manual refinement. This results in 590 and 15 hours of silver-annotated\nspeech for training and validation, alongside a 17-hour, manually-annotated\nevaluation set. We further provide an analysis comparing silver and gold\nannotations. Finally, we present baseline NER models to stimulate further\nresearch on this newly available dataset.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Quentin Meeus",
            "Marie-Francine Moens",
            "Hugo Van hamme"
        ],
        "published": "2024-05-19T11:17:00Z"
    },
    {
        "title": "On the Convergence of No-Regret Dynamics in Information Retrieval Games\n  with Proportional Ranking Functions",
        "link": "http://arxiv.org/abs/2405.11517v1",
        "abstract": "Publishers who publish their content on the web act strategically, in a\nbehavior that can be modeled within the online learning framework. Regret, a\ncentral concept in machine learning, serves as a canonical measure for\nassessing the performance of learning agents within this framework. We prove\nthat any proportional content ranking function with a concave activation\nfunction induces games in which no-regret learning dynamics converge. Moreover,\nfor proportional ranking functions, we prove the equivalence of the concavity\nof the activation function, the social concavity of the induced games and the\nconcavity of the induced games. We also study the empirical trade-offs between\npublishers' and users' welfare, under different choices of the activation\nfunction, using a state-of-the-art no-regret dynamics algorithm. Furthermore,\nwe demonstrate how the choice of the ranking function and changes in the\necosystem structure affect these welfare measures, as well as the dynamics'\nconvergence rate.",
        "subjects": [
            "cs.GT",
            "cs.IR"
        ],
        "authors": [
            "Omer Madmon",
            "Idan Pipano",
            "Itamar Reinman",
            "Moshe Tennenholtz"
        ],
        "published": "2024-05-19T11:12:10Z"
    },
    {
        "title": "Towards Translating Real-World Code with LLMs: A Study of Translating to\n  Rust",
        "link": "http://arxiv.org/abs/2405.11514v2",
        "abstract": "Large language models (LLMs) show promise in code translation - the task of\ntranslating code written in one programming language to another language - due\nto their ability to write code in most programming languages. However, LLM's\neffectiveness on translating real-world code remains largely unstudied. In this\nwork, we perform the first substantial study on LLM-based translation to Rust\nby assessing the ability of five state-of-the-art LLMs, GPT4, Claude 3, Claude\n2.1, Gemini Pro, and Mixtral. We conduct our study on code extracted from\nreal-world open source projects. To enable our study, we develop FLOURINE, an\nend-to-end code translation tool that uses differential fuzzing to check if a\nRust translation is I/O equivalent to the original source program, eliminating\nthe need for pre-existing test cases. As part of our investigation, we assess\nboth the LLM's ability to produce an initially successful translation, as well\nas their capacity to fix a previously generated buggy one. If the original and\nthe translated programs are not I/O equivalent, we apply a set of automated\nfeedback strategies, including feedback to the LLM with counterexamples. Our\nresults show that the most successful LLM can translate 47% of our benchmarks,\nand also provides insights into next steps for improvements.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Hasan Ferit Eniser",
            "Hanliang Zhang",
            "Cristina David",
            "Meng Wang",
            "Maria Christakis",
            "Brandon Paulsen",
            "Joey Dodds",
            "Daniel Kroening"
        ],
        "published": "2024-05-19T10:54:03Z"
    },
    {
        "title": "Optimizing Underwater IoT Routing with Multi-Criteria Decision Making\n  and Uncertainty Weights",
        "link": "http://arxiv.org/abs/2405.11513v1",
        "abstract": "Effective data routing is vital in the Internet of Things (IoT) paradigm,\nespecially in underwater mobile sensor networks where inefficiency can lead to\nsignificant resource consumption. This article presents an innovative method\ndesigned to enhance network performance and reduce resource usage, while also\naccurately determining component weights in these networks, ensuring quality\nservice. Building upon previous research on multi-criteria decision-making\nsystems in coastal RPL networks, our method involves key adaptations for\nunderwater environments. It integrates comprehensive network features to\nidentify the optimal parent node for each sensor, employing the fuzzy SWARA\ndecision-making approach under uncertain conditions. This method takes into\naccount various factors including hops, energy, ARSSI rate, delay, ETX, link\ndelivery rate, and depth to determine the most effective parent node\nassignment. Through simulation, our approach demonstrates marked improvements\nin network performance compared to existing solutions. These advancements are\nsignificant, offering a new direction in enhancing underwater IoT\ncommunications and suggesting wider applications for IoT systems facing similar\nchallenges.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Ali Karkehabadi",
            "Mitra Bakhshi",
            "Seyed Behnam Razavian"
        ],
        "published": "2024-05-19T10:50:06Z"
    },
    {
        "title": "Going into Orbit: Massively Parallelizing Episodic Reinforcement\n  Learning",
        "link": "http://arxiv.org/abs/2405.11512v1",
        "abstract": "The possibilities of robot control have multiplied across various domains\nthrough the application of deep reinforcement learning. To overcome safety and\nsampling efficiency issues, deep reinforcement learning models can be trained\nin a simulation environment, allowing for faster iteration cycles. This can be\nenhanced further by parallelizing the training process using GPUs. NVIDIA's\nopen-source robot learning framework Orbit leverages this potential by wrapping\ntensor-based reinforcement learning libraries for high parallelism and building\nupon Isaac Sim for its simulations. We contribute a detailed description of the\nimplementation of a benchmark reinforcement learning task, namely box pushing,\nusing Orbit. Additionally, we benchmark the performance of our implementation\nin comparison to a CPU-based implementation and report the performance metrics.\nFinally, we tune the hyper parameters of our implementation and show that we\ncan generate significantly more samples in the same amount of time by using\nOrbit.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Jan Oberst",
            "Johann Bonneau"
        ],
        "published": "2024-05-19T10:38:59Z"
    },
    {
        "title": "Online Action Representation using Change Detection and Symbolic\n  Programming",
        "link": "http://arxiv.org/abs/2405.11511v1",
        "abstract": "This paper addresses the critical need for online action representation,\nwhich is essential for various applications like rehabilitation, surveillance,\netc. The task can be defined as representation of actions as soon as they\nhappen in a streaming video without access to video frames in the future. Most\nof the existing methods use predefined window sizes for video segments, which\nis a restrictive assumption on the dynamics. The proposed method employs a\nchange detection algorithm to automatically segment action sequences, which\nform meaningful sub-actions and subsequently fit symbolic generative motion\nprograms to the clipped segments. We determine the start time and end time of\nsegments using change detection followed by a piece-wise linear fit algorithm\non joint angle and bone length sequences. Domain-specific symbolic primitives\nare fit to pose keypoint trajectories of those extracted segments in order to\nobtain a higher level semantic representation. Since this representation is\npart-based, it is complementary to the compositional nature of human actions,\ni.e., a complex activity can be broken down into elementary sub-actions. We\nshow the effectiveness of this representation in the downstream task of class\nagnostic repetition detection. We propose a repetition counting algorithm based\non consecutive similarity matching of primitives, which can do online\nrepetition counting. We also compare the results with a similar but offline\nrepetition counting algorithm. The results of the experiments demonstrate that,\ndespite operating online, the proposed method performs better or on par with\nthe existing method.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Vishnu S Nair",
            "Sneha Sree",
            "Jayaraj Joseph",
            "Mohanasankar Sivaprakasam"
        ],
        "published": "2024-05-19T10:31:59Z"
    },
    {
        "title": "Enhancing user experience in large language models through\n  human-centered design: Integrating theoretical insights with an experimental\n  study to meet diverse software learning needs with a single document\n  knowledge base",
        "link": "http://dx.doi.org/10.59400/cai.v2i1.535",
        "abstract": "This paper begins with a theoretical exploration of the rise of large\nlanguage models (LLMs) in Human-Computer Interaction (HCI), their impact on\nuser experience (HX), and related challenges. It then discusses the benefits of\nHuman-Centered Design (HCD) principles and the possibility of their application\nwithin LLMs, subsequently deriving six specific HCD guidelines for LLMs.\nFollowing this, a preliminary experiment is presented as an example to\ndemonstrate how HCD principles can be employed to enhance user experience\nwithin GPT by using a single document input to GPT's Knowledge base as a new\nknowledge resource to control the interactions between GPT and users, aiming to\nmeet the diverse needs of hypothetical software learners as much as possible.\nThe experimental results demonstrate the effect of different elements' forms\nand organizational methods in the document, as well as GPT's relevant\nconfigurations, on the interaction effectiveness between GPT and software\nlearners. A series of trials are conducted to explore better methods to realize\ntext and image displaying, and jump action. Two template documents are compared\nin the aspects of the performances of the four interaction modes. Through\ncontinuous optimization, an improved version of the document was obtained to\nserve as a template for future use and research.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Yuchen Wang",
            "Yin-Shan Lin",
            "Ruixin Huang",
            "Jinyin Wang",
            "Sensen Liu"
        ],
        "published": "2024-05-19T10:14:55Z"
    },
    {
        "title": "Machine Learning & Wi-Fi: Unveiling the Path Towards AI/ML-Native IEEE\n  802.11 Networks",
        "link": "http://arxiv.org/abs/2405.11504v1",
        "abstract": "Artificial intelligence (AI) and machine learning (ML) are nowadays mature\ntechnologies considered essential for driving the evolution of future\ncommunications systems. Simultaneously, Wi-Fi technology has constantly evolved\nover the past three decades and incorporated new features generation after\ngeneration, thus gaining in complexity. As such, researchers have observed that\nAI/ML functionalities may be required to address the upcoming Wi-Fi challenges\nthat will be otherwise difficult to solve with traditional approaches. This\npaper discusses the role of AI/ML in current and future Wi-Fi networks and\ndepicts the ways forward. A roadmap towards AI/ML-native Wi-Fi, key challenges,\nstandardization efforts, and major enablers are also discussed. An exemplary\nuse case is provided to showcase the potential of AI/ML in Wi-Fi at different\nadoption stages.",
        "subjects": [
            "cs.NI",
            "cs.AI"
        ],
        "authors": [
            "Francesc Wilhelmi",
            "Szymon Szott",
            "Katarzyna Kosek-Szott",
            "Boris Bellalta"
        ],
        "published": "2024-05-19T10:12:20Z"
    },
    {
        "title": "DogFLW: Dog Facial Landmarks in the Wild Dataset",
        "link": "http://arxiv.org/abs/2405.11501v1",
        "abstract": "Affective computing for animals is a rapidly expanding research area that is\ngoing deeper than automated movement tracking to address animal internal\nstates, like pain and emotions. Facial expressions can serve to communicate\ninformation about these states in mammals. However, unlike human-related\nstudies, there is a significant shortage of datasets that would enable the\nautomated analysis of animal facial expressions. Inspired by the recently\nintroduced Cat Facial Landmarks in the Wild dataset, presenting cat faces\nannotated with 48 facial anatomy-based landmarks, in this paper, we develop an\nanalogous dataset containing 3,274 annotated images of dogs. Our dataset is\nbased on a scheme of 46 facial anatomy-based landmarks. The DogFLW dataset is\navailable from the corresponding author upon a reasonable request.",
        "subjects": [
            "cs.CV",
            "I.5.4"
        ],
        "authors": [
            "George Martvel",
            "Greta Abele",
            "Annika Bremhorst",
            "Chiara Canori",
            "Nareed Farhat",
            "Giulia Pedretti",
            "Ilan Shimshoni",
            "Anna Zamansky"
        ],
        "published": "2024-05-19T09:59:36Z"
    },
    {
        "title": "SemEval-2024 Task 3: Multimodal Emotion Cause Analysis in Conversations",
        "link": "http://arxiv.org/abs/2405.13049v1",
        "abstract": "The ability to understand emotions is an essential component of human-like\nartificial intelligence, as emotions greatly influence human cognition,\ndecision making, and social interactions. In addition to emotion recognition in\nconversations, the task of identifying the potential causes behind an\nindividual's emotional state in conversations, is of great importance in many\napplication scenarios. We organize SemEval-2024 Task 3, named Multimodal\nEmotion Cause Analysis in Conversations, which aims at extracting all pairs of\nemotions and their corresponding causes from conversations. Under different\nmodality settings, it consists of two subtasks: Textual Emotion-Cause Pair\nExtraction in Conversations (TECPE) and Multimodal Emotion-Cause Pair\nExtraction in Conversations (MECPE). The shared task has attracted 143\nregistrations and 216 successful submissions. In this paper, we introduce the\ntask, dataset and evaluation settings, summarize the systems of the top teams,\nand discuss the findings of the participants.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.MM"
        ],
        "authors": [
            "Fanfan Wang",
            "Heqing Ma",
            "Jianfei Yu",
            "Rui Xia",
            "Erik Cambria"
        ],
        "published": "2024-05-19T09:59:00Z"
    },
    {
        "title": "Interpreting a Semantic Segmentation Model for Coastline Detection",
        "link": "http://dx.doi.org/10.1109/PIERS59004.2023.10221387",
        "abstract": "We interpret a deep-learning semantic segmentation model used to classify\ncoastline satellite images into land and water. This is to build trust in the\nmodel and gain new insight into the process of coastal water body extraction.\nSpecifically, we seek to understand which spectral bands are important for\npredicting segmentation masks. This is done using a permutation importance\napproach. Results show that the NIR is the most important spectral band.\nPermuting this band lead to a decrease in accuracy of 38.12 percentage points.\nThis is followed by Water Vapour, SWIR 1, and Blue bands with 2.58, 0.78 and\n0.19 respectively. Water Vapour is not typically used in water indices and\nthese results suggest it may be useful for water body extraction. Permuting,\nthe Coastal Aerosol, Green, Red, RE1, RE2, RE3, RE4, and SWIR 2 bands did not\ndecrease accuracy. This suggests they could be excluded from future model\nbuilds reducing complexity and computational requirements.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Conor O'Sullivan",
            "Seamus Coveney",
            "Xavier Monteys",
            "Soumyabrata Dev"
        ],
        "published": "2024-05-19T09:57:34Z"
    },
    {
        "title": "The Effectiveness of Edge Detection Evaluation Metrics for Automated\n  Coastline Detection",
        "link": "http://dx.doi.org/10.1109/PIERS59004.2023.10221292",
        "abstract": "We analyse the effectiveness of RMSE, PSNR, SSIM and FOM for evaluating edge\ndetection algorithms used for automated coastline detection. Typically, the\naccuracy of detected coastlines is assessed visually. This can be impractical\non a large scale leading to the need for objective evaluation metrics. Hence,\nwe conduct an experiment to find reliable metrics. We apply Canny edge\ndetection to 95 coastline satellite images across 49 testing locations. We vary\nthe Hysteresis thresholds and compare metric values to a visual analysis of\ndetected edges. We found that FOM was the most reliable metric for selecting\nthe best threshold. It could select a better threshold 92.6% of the time and\nthe best threshold 66.3% of the time. This is compared RMSE, PSNR and SSIM\nwhich could select the best threshold 6.3%, 6.3% and 11.6% of the time\nrespectively. We provide a reason for these results by reformulating RMSE, PSNR\nand SSIM in terms of confusion matrix measures. This suggests these metrics not\nonly fail for this experiment but are not useful for evaluating edge detection\nin general.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Conor O'Sullivan",
            "Seamus Coveney",
            "Xavier Monteys",
            "Soumyabrata Dev"
        ],
        "published": "2024-05-19T09:51:10Z"
    },
    {
        "title": "Towards in-situ Psychological Profiling of Cybercriminals Using\n  Dynamically Generated Deception Environments",
        "link": "http://arxiv.org/abs/2405.11497v1",
        "abstract": "Cybercrime is estimated to cost the global economy almost \\$10 trillion\nannually and with businesses and governments reporting an ever-increasing\nnumber of successful cyber-attacks there is a growing demand to rethink the\nstrategy towards cyber security. The traditional, perimeter security approach\nto cyber defence has so far proved inadequate to combat the growing threat of\ncybercrime. Cyber deception offers a promising alternative by creating a\ndynamic defence environment. Deceptive techniques aim to mislead attackers,\ndiverting them from critical assets whilst simultaneously gathering cyber\nthreat intelligence on the threat actor. This article presents a\nproof-of-concept (POC) cyber deception system that has been developed to\ncapture the profile of an attacker in-situ, during a simulated cyber-attack in\nreal time. By dynamically and autonomously generating deception material based\non the observed attacker behaviour and analysing how the attacker interacts\nwith the deception material, the system outputs a prediction on the attacker's\nmotive. The article also explores how this POC can be expanded to infer other\nfeatures of the attacker's profile such as psychological characteristics. By\ndynamically and autonomously generating deception material based on observed\nattacker behaviour and analysing how the attacker interacts with the deception\nmaterial, the system outputs a prediciton on the attacker's motive. The article\nalso explores how this POC can be expanded to infer other features of the\nattacker's profile such as psychological characteristics.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Jacob Quibell"
        ],
        "published": "2024-05-19T09:48:59Z"
    },
    {
        "title": "DEMO: A Statistical Perspective for Efficient Image-Text Matching",
        "link": "http://arxiv.org/abs/2405.11496v1",
        "abstract": "Image-text matching has been a long-standing problem, which seeks to connect\nvision and language through semantic understanding. Due to the capability to\nmanage large-scale raw data, unsupervised hashing-based approaches have gained\nprominence recently. They typically construct a semantic similarity structure\nusing the natural distance, which subsequently provides guidance to the model\noptimization process. However, the similarity structure could be biased at the\nboundaries of semantic distributions, causing error accumulation during\nsequential optimization. To tackle this, we introduce a novel hashing approach\ntermed Distribution-based Structure Mining with Consistency Learning (DEMO) for\nefficient image-text matching. From a statistical view, DEMO characterizes each\nimage using multiple augmented views, which are considered as samples drawn\nfrom its intrinsic semantic distribution. Then, we employ a non-parametric\ndistribution divergence to ensure a robust and precise similarity structure. In\naddition, we introduce collaborative consistency learning which not only\npreserves the similarity structure in the Hamming space but also encourages\nconsistency between retrieval distribution from different directions in a\nself-supervised manner. Through extensive experiments on three benchmark\nimage-text matching datasets, we demonstrate that DEMO achieves superior\nperformance compared with many state-of-the-art methods.",
        "subjects": [
            "cs.CV",
            "cs.IR"
        ],
        "authors": [
            "Fan Zhang",
            "Xian-Sheng Hua",
            "Chong Chen",
            "Xiao Luo"
        ],
        "published": "2024-05-19T09:38:56Z"
    },
    {
        "title": "Automated Coastline Extraction Using Edge Detection Algorithms",
        "link": "http://dx.doi.org/10.1109/IGARSS52108.2023.10282621",
        "abstract": "We analyse the effectiveness of edge detection algorithms for the purpose of\nautomatically extracting coastlines from satellite images. Four algorithms -\nCanny, Sobel, Scharr and Prewitt are compared visually and using metrics. With\nan average SSIM of 0.8, Canny detected edges that were closest to the reference\nedges. However, the algorithm had difficulty distinguishing noisy edges, e.g.\ndue to development, from coastline edges. In addition, histogram equalization\nand Gaussian blur were shown to improve the effectiveness of the edge detection\nalgorithms by up to 1.5 and 1.6 times respectively.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ],
        "authors": [
            "Conor O'Sullivan",
            "Seamus Coveney",
            "Xavier Monteys",
            "Soumyabrata Dev"
        ],
        "published": "2024-05-19T09:25:55Z"
    },
    {
        "title": "Point Cloud Compression with Implicit Neural Representations: A Unified\n  Framework",
        "link": "http://arxiv.org/abs/2405.11493v1",
        "abstract": "Point clouds have become increasingly vital across various applications\nthanks to their ability to realistically depict 3D objects and scenes.\nNevertheless, effectively compressing unstructured, high-precision point cloud\ndata remains a significant challenge. In this paper, we present a pioneering\npoint cloud compression framework capable of handling both geometry and\nattribute components. Unlike traditional approaches and existing learning-based\nmethods, our framework utilizes two coordinate-based neural networks to\nimplicitly represent a voxelized point cloud. The first network generates the\noccupancy status of a voxel, while the second network determines the attributes\nof an occupied voxel. To tackle an immense number of voxels within the\nvolumetric space, we partition the space into smaller cubes and focus solely on\nvoxels within non-empty cubes. By feeding the coordinates of these voxels into\nthe respective networks, we reconstruct the geometry and attribute components\nof the original point cloud. The neural network parameters are further\nquantized and compressed. Experimental results underscore the superior\nperformance of our proposed method compared to the octree-based approach\nemployed in the latest G-PCC standards. Moreover, our method exhibits high\nuniversality when contrasted with existing learning-based techniques.",
        "subjects": [
            "cs.CV",
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Hongning Ruan",
            "Yulin Shao",
            "Qianqian Yang",
            "Liang Zhao",
            "Dusit Niyato"
        ],
        "published": "2024-05-19T09:19:40Z"
    },
    {
        "title": "Enhancing Vehicle Aerodynamics with Deep Reinforcement Learning in\n  Voxelised Models",
        "link": "http://arxiv.org/abs/2405.11492v1",
        "abstract": "Aerodynamic design optimisation plays a crucial role in improving the\nperformance and efficiency of automotive vehicles. This paper presents a novel\napproach for aerodynamic optimisation in car design using deep reinforcement\nlearning (DRL). Traditional optimisation methods often face challenges in\nhandling the complexity of the design space and capturing non-linear\nrelationships between design parameters and aerodynamic performance metrics.\nThis study addresses these challenges by employing DRL to learn optimal\naerodynamic design strategies in a voxelised model representation. The proposed\napproach utilises voxelised models to discretise the vehicle geometry into a\ngrid of voxels, allowing for a detailed representation of the aerodynamic flow\nfield. The Proximal Policy Optimisation (PPO) algorithm is then employed to\ntrain a DRL agent to optimise the design parameters of the vehicle with respect\nto drag force, kinetic energy, and voxel collision count. Experimental results\ndemonstrate the effectiveness and efficiency of the proposed approach in\nachieving significant results in aerodynamic performance. The findings\nhighlight the potential of DRL techniques for addressing complex aerodynamic\ndesign optimisation problems in automotive engineering, with implications for\nimproving vehicle performance, fuel efficiency, and environmental\nsustainability.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "authors": [
            "Jignesh Patel",
            "Yannis Spyridis",
            "Vasileios Argyriou"
        ],
        "published": "2024-05-19T09:19:31Z"
    },
    {
        "title": "BOSC: A Backdoor-based Framework for Open Set Synthetic Image\n  Attribution",
        "link": "http://arxiv.org/abs/2405.11491v1",
        "abstract": "Synthetic image attribution addresses the problem of tracing back the origin\nof images produced by generative models. Extensive efforts have been made to\nexplore unique representations of generative models and use them to attribute a\nsynthetic image to the model that produced it. Most of the methods classify the\nmodels or the architectures among those in a closed set without considering the\npossibility that the system is fed with samples produced by unknown\narchitectures. With the continuous progress of AI technology, new generative\narchitectures continuously appear, thus driving the attention of researchers\ntowards the development of tools capable of working in open-set scenarios. In\nthis paper, we propose a framework for open set attribution of synthetic\nimages, named BOSC (Backdoor-based Open Set Classification), that relies on the\nconcept of backdoor attacks to design a classifier with rejection option. BOSC\nworks by purposely injecting class-specific triggers inside a portion of the\nimages in the training set to induce the network to establish a matching\nbetween class features and trigger features. The behavior of the trained model\nwith respect to triggered samples is then exploited at test time to perform\nsample rejection using an ad-hoc score. Experiments show that the proposed\nmethod has good performance, always surpassing the state-of-the-art. Robustness\nagainst image processing is also very good. Although we designed our method for\nthe task of synthetic image attribution, the proposed framework is a general\none and can be used for other image forensic applications.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jun Wang",
            "Benedetta Tondi",
            "Mauro Barni"
        ],
        "published": "2024-05-19T09:17:43Z"
    },
    {
        "title": "\"Previously on ...\" From Recaps to Story Summarization",
        "link": "http://arxiv.org/abs/2405.11487v1",
        "abstract": "We introduce multimodal story summarization by leveraging TV episode recaps -\nshort video sequences interweaving key story moments from previous episodes to\nbring viewers up to speed. We propose PlotSnap, a dataset featuring two crime\nthriller TV shows with rich recaps and long episodes of 40 minutes. Story\nsummarization labels are unlocked by matching recap shots to corresponding\nsub-stories in the episode. We propose a hierarchical model TaleSumm that\nprocesses entire episodes by creating compact shot and dialog representations,\nand predicts importance scores for each video shot and dialog utterance by\nenabling interactions between local story groups. Unlike traditional\nsummarization, our method extracts multiple plot points from long videos. We\npresent a thorough evaluation on story summarization, including promising\ncross-series generalization. TaleSumm also shows good results on classic video\nsummarization benchmarks.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Aditya Kumar Singh",
            "Dhruv Srivastava",
            "Makarand Tapaswi"
        ],
        "published": "2024-05-19T09:09:54Z"
    },
    {
        "title": "MICap: A Unified Model for Identity-aware Movie Descriptions",
        "link": "http://arxiv.org/abs/2405.11483v1",
        "abstract": "Characters are an important aspect of any storyline and identifying and\nincluding them in descriptions is necessary for story understanding. While\nprevious work has largely ignored identity and generated captions with someone\n(anonymized names), recent work formulates id-aware captioning as a\nfill-in-the-blanks (FITB) task, where, given a caption with blanks, the goal is\nto predict person id labels. However, to predict captions with ids, a two-stage\napproach is required: first predict captions with someone, then fill in\nidentities. In this work, we present a new single stage approach that can\nseamlessly switch between id-aware caption generation or FITB when given a\ncaption with blanks. Our model, Movie-Identity Captioner (MICap), uses a shared\nauto-regressive decoder that benefits from training with FITB and full-caption\ngeneration objectives, while the encoder can benefit from or disregard captions\nwith blanks as input. Another challenge with id-aware captioning is the lack of\na metric to capture subtle differences between person ids. To this end, we\nintroduce iSPICE, a caption evaluation metric that focuses on identity tuples\ncreated through intermediate scene graphs. We evaluate MICap on Large-Scale\nMovie Description Challenge (LSMDC), where we show a 4.2% improvement in FITB\naccuracy, and a 1-2% bump in classic captioning metrics.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Haran Raajesh",
            "Naveen Reddy Desanur",
            "Zeeshan Khan",
            "Makarand Tapaswi"
        ],
        "published": "2024-05-19T08:54:12Z"
    },
    {
        "title": "Explainable Facial Expression Recognition for People with Intellectual\n  Disabilities",
        "link": "http://dx.doi.org/10.1145/3612783.3612789",
        "abstract": "Facial expression recognition plays an important role in human behaviour,\ncommunication, and interaction. Recent neural networks have demonstrated to\nperform well at its automatic recognition, with different explainability\ntechniques available to make them more transparent. In this work, we propose a\nfacial expression recognition study for people with intellectual disabilities\nthat would be integrated into a social robot. We train two well-known neural\nnetworks with five databases of facial expressions and test them with two\ndatabases containing people with and without intellectual disabilities.\nFinally, we study in which regions the models focus to perceive a particular\nexpression using two different explainability techniques: LIME and RISE,\nassessing the differences when used on images containing disabled and\nnon-disabled people.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Silvia Ramis Guarinos",
            "Cristina Manresa Yee",
            "Jose Maria Buades Rubio",
            "Francesc Xavier Gaya-Morey"
        ],
        "published": "2024-05-19T08:42:16Z"
    },
    {
        "title": "Physics-aware Hand-object Interaction Denoising",
        "link": "http://arxiv.org/abs/2405.11481v1",
        "abstract": "The credibility and practicality of a reconstructed hand-object interaction\nsequence depend largely on its physical plausibility. However, due to high\nocclusions during hand-object interaction, physical plausibility remains a\nchallenging criterion for purely vision-based tracking methods. To address this\nissue and enhance the results of existing hand trackers, this paper proposes a\nnovel physically-aware hand motion de-noising method. Specifically, we\nintroduce two learned loss terms that explicitly capture two crucial aspects of\nphysical plausibility: grasp credibility and manipulation feasibility. These\nterms are used to train a physically-aware de-noising network. Qualitative and\nquantitative experiments demonstrate that our approach significantly improves\nboth fine-grained physical plausibility and overall pose accuracy, surpassing\ncurrent state-of-the-art de-noising methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Haowen Luo",
            "Yunze Liu",
            "Li Yi"
        ],
        "published": "2024-05-19T08:24:34Z"
    },
    {
        "title": "Unsupervised Image Prior via Prompt Learning and CLIP Semantic Guidance\n  for Low-Light Image Enhancement",
        "link": "http://arxiv.org/abs/2405.11478v1",
        "abstract": "Currently, low-light conditions present a significant challenge for machine\ncognition. In this paper, rather than optimizing models by assuming that human\nand machine cognition are correlated, we use zero-reference low-light\nenhancement to improve the performance of downstream task models. We propose to\nimprove the zero-reference low-light enhancement method by leveraging the rich\nvisual-linguistic CLIP prior without any need for paired or unpaired\nnormal-light data, which is laborious and difficult to collect. We propose a\nsimple but effective strategy to learn prompts that help guide the enhancement\nmethod and experimentally show that the prompts learned without any need for\nnormal-light data improve image contrast, reduce over-enhancement, and reduce\nnoise over-amplification. Next, we propose to reuse the CLIP model for semantic\nguidance via zero-shot open vocabulary classification to optimize low-light\nenhancement for task-based performance rather than human visual perception. We\nconduct extensive experimental results showing that the proposed method leads\nto consistent improvements across various datasets regarding task-based\nperformance and compare our method against state-of-the-art methods, showing\nfavorable results across various low-light datasets.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Igor Morawski",
            "Kai He",
            "Shusil Dangi",
            "Winston H. Hsu"
        ],
        "published": "2024-05-19T08:06:14Z"
    },
    {
        "title": "NubbleDrop: A Simple Way to Improve Matching Strategy for Prompted\n  One-Shot Segmentation",
        "link": "http://arxiv.org/abs/2405.11476v1",
        "abstract": "Driven by large data trained segmentation models, such as SAM , research in\none-shot segmentation has experienced significant advancements. Recent\ncontributions like PerSAM and MATCHER , presented at ICLR 2024, utilize a\nsimilar approach by leveraging SAM with one or a few reference images to\ngenerate high quality segmentation masks for target images. Specifically, they\nutilize raw encoded features to compute cosine similarity between patches\nwithin reference and target images along the channel dimension, effectively\ngenerating prompt points or boxes for the target images a technique referred to\nas the matching strategy. However, relying solely on raw features might\nintroduce biases and lack robustness for such a complex task. To address this\nconcern, we delve into the issues of feature interaction and uneven\ndistribution inherent in raw feature based matching. In this paper, we propose\na simple and training-free method to enhance the validity and robustness of the\nmatching strategy at no additional computational cost (NubbleDrop). The core\nconcept involves randomly dropping feature channels (setting them to zero)\nduring the matching process, thereby preventing models from being influenced by\nchannels containing deceptive information. This technique mimics discarding\npathological nubbles, and it can be seamlessly applied to other similarity\ncomputing scenarios. We conduct a comprehensive set of experiments, considering\na wide range of factors, to demonstrate the effectiveness and validity of our\nproposed method. Our results showcase the significant improvements achieved\nthrough this simmple and straightforward approach.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Zhiyu Xu",
            "Qingliang Chen"
        ],
        "published": "2024-05-19T08:00:38Z"
    },
    {
        "title": "String 2-Covers with No Length Restrictions",
        "link": "http://arxiv.org/abs/2405.11475v1",
        "abstract": "A $\\lambda$-cover of a string $S$ is a set of strings $\\{C_i\\}_1^\\lambda$\nsuch that every index in $S$ is contained in an occurrence of at least one\nstring $C_i$. The existence of a $1$-cover defines a well-known class of\nquasi-periodic strings. Quasi-periodicity can be decided in linear time, and\nall $1$-covers of a string can be reported in linear time plus the size of the\noutput. Since in general it is NP-complete to decide whether a string has a\n$\\lambda$-cover, the natural next step is the development of efficient\nalgorithms for $2$-covers. Radoszewski and Straszy\\'nski [ESA 2020] analysed\nthe particular case where the strings in a $2$-cover must be of the same\nlength. They provided an algorithm that reports all such $2$-covers of $S$ in\ntime near-linear in $|S|$ and in the size of the output.\n  In this work, we consider $2$-covers in full generality. Since every\nlength-$n$ string has $\\Omega(n^2)$ trivial $2$-covers (every prefix and suffix\nof total length at least $n$ constitute such a $2$-cover), we state the\nreporting problem as follows: given a string $S$ and a number $m$, report all\n$2$-covers $\\{C_1,C_2\\}$ of $S$ with length $|C_1|+|C_2|$ upper bounded by $m$.\nWe present an $\\tilde{O}(n + Output)$ time algorithm solving this problem, with\nOutput being the size of the output. This algorithm admits a simpler\nmodification that finds a $2$-cover of minimum length. We also provide an\n$\\tilde{O}(n)$ time construction of a $2$-cover oracle which, given two\nsubstrings $C_1,C_2$ of $S$, reports in poly-logarithmic time whether\n$\\{C_1,C_2\\}$ is a $2$-cover of $S$.",
        "subjects": [
            "cs.DS",
            "68W32",
            "F.2.2"
        ],
        "authors": [
            "Itai Boneh",
            "Shay Golan",
            "Arseny Shur"
        ],
        "published": "2024-05-19T08:00:16Z"
    },
    {
        "title": "FIFO-Diffusion: Generating Infinite Videos from Text without Training",
        "link": "http://arxiv.org/abs/2405.11473v1",
        "abstract": "We propose a novel inference technique based on a pretrained diffusion model\nfor text-conditional video generation. Our approach, called FIFO-Diffusion, is\nconceptually capable of generating infinitely long videos without training.\nThis is achieved by iteratively performing diagonal denoising, which\nconcurrently processes a series of consecutive frames with increasing noise\nlevels in a queue; our method dequeues a fully denoised frame at the head while\nenqueuing a new random noise frame at the tail. However, diagonal denoising is\na double-edged sword as the frames near the tail can take advantage of cleaner\nones by forward reference but such a strategy induces the discrepancy between\ntraining and inference. Hence, we introduce latent partitioning to reduce the\ntraining-inference gap and lookahead denoising to leverage the benefit of\nforward referencing. We have demonstrated the promising results and\neffectiveness of the proposed methods on existing text-to-video generation\nbaselines.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Jihwan Kim",
            "Junoh Kang",
            "Jinyoung Choi",
            "Bohyung Han"
        ],
        "published": "2024-05-19T07:48:41Z"
    },
    {
        "title": "CMA-ES with Adaptive Reevaluation for Multiplicative Noise",
        "link": "http://arxiv.org/abs/2405.11471v1",
        "abstract": "The covariance matrix adaptation evolution strategy (CMA-ES) is a powerful\noptimization method for continuous black-box optimization problems. Several\nnoise-handling methods have been proposed to bring out the optimization\nperformance of the CMA-ES on noisy objective functions. The adaptations of the\npopulation size and the learning rate are two major approaches that perform\nwell under additive Gaussian noise. The reevaluation technique is another\ntechnique that evaluates each solution multiple times. In this paper, we\ndiscuss the difference between those methods from the perspective of stochastic\nrelaxation that considers the maximization of the expected utility function. We\nderive that the set of maximizers of the noise-independent utility, which is\nused in the reevaluation technique, certainly contains the optimal solution,\nwhile the noise-dependent utility, which is used in the population size and\nleaning rate adaptations, does not satisfy it under multiplicative noise. Based\non the discussion, we develop the reevaluation adaptation CMA-ES (RA-CMA-ES),\nwhich computes two update directions using half of the evaluations and adapts\nthe number of reevaluations based on the estimated correlation of those two\nupdate directions. The numerical simulation shows that the RA-CMA-ES\noutperforms the comparative method under multiplicative noise, maintaining\ncompetitive performance under additive noise.",
        "subjects": [
            "cs.NE"
        ],
        "authors": [
            "Kento Uchida",
            "Kenta Nishihara",
            "Shinichi Shirakawa"
        ],
        "published": "2024-05-19T07:42:10Z"
    },
    {
        "title": "VCformer: Variable Correlation Transformer with Inherent Lagged\n  Correlation for Multivariate Time Series Forecasting",
        "link": "http://arxiv.org/abs/2405.11470v1",
        "abstract": "Multivariate time series (MTS) forecasting has been extensively applied\nacross diverse domains, such as weather prediction and energy consumption.\nHowever, current studies still rely on the vanilla point-wise self-attention\nmechanism to capture cross-variable dependencies, which is inadequate in\nextracting the intricate cross-correlation implied between variables. To fill\nthis gap, we propose Variable Correlation Transformer (VCformer), which\nutilizes Variable Correlation Attention (VCA) module to mine the correlations\namong variables. Specifically, based on the stochastic process theory, VCA\ncalculates and integrates the cross-correlation scores corresponding to\ndifferent lags between queries and keys, thereby enhancing its ability to\nuncover multivariate relationships. Additionally, inspired by Koopman dynamics\ntheory, we also develop Koopman Temporal Detector (KTD) to better address the\nnon-stationarity in time series. The two key components enable VCformer to\nextract both multivariate correlations and temporal dependencies. Our extensive\nexperiments on eight real-world datasets demonstrate the effectiveness of\nVCformer, achieving top-tier performance compared to other state-of-the-art\nbaseline models. Code is available at this repository:\nhttps://github.com/CSyyn/VCformer.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Yingnan Yang",
            "Qingling Zhu",
            "Jianyong Chen"
        ],
        "published": "2024-05-19T07:39:22Z"
    },
    {
        "title": "Numerical integration rules based on B-spline bases",
        "link": "http://arxiv.org/abs/2405.11469v1",
        "abstract": "In this work, we present some new integration formulas for any order of\naccuracy as an application of the B-spline relations obtained in [1]. The\nresulting rules are defined as a perturbation of the trapezoidal integration\nmethod. We prove the order of approximation and extend the results to several\ndimensions. Finally, some numerical experiments are performed in order to check\nthe theoretical results.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Dionisio F. Y√°√±ez"
        ],
        "published": "2024-05-19T07:11:28Z"
    },
    {
        "title": "Emphasizing Crucial Features for Efficient Image Restoration",
        "link": "http://arxiv.org/abs/2405.11468v1",
        "abstract": "Image restoration is a challenging ill-posed problem which estimates latent\nsharp image from its degraded counterpart. Although the existing methods have\nachieved promising performance by designing novelty architecture of module,\nthey ignore the fact that different regions in a corrupted image undergo\nvarying degrees of degradation. In this paper, we propose an efficient and\neffective framework to adapt to varying degrees of degradation across different\nregions for image restoration. Specifically, we design a spatial and frequency\nattention mechanism (SFAM) to emphasize crucial features for restoration. SFAM\nconsists of two modules: the spatial domain attention module (SDAM) and the\nfrequency domain attention module (FDAM). The SFAM discerns the degradation\nlocation through spatial selective attention and channel selective attention in\nthe spatial domain, while the FDAM enhances high-frequency signals to amplify\nthe disparities between sharp and degraded image pairs in the spectral domain.\nAdditionally, to capture global range information, we introduce a multi-scale\nblock (MSBlock) that consists of three scale branches, each containing multiple\nsimplified channel attention blocks (SCABlocks) and a multi-scale feed-forward\nblock (MSFBlock). Finally, we propose our ECFNet, which integrates the\naforementioned components into a U-shaped backbone for recovering high-quality\nimages. Extensive experimental results demonstrate the effectiveness of ECFNet,\noutperforming state-of-the-art (SOTA) methods on both synthetic and real-world\ndatasets.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hu Gao",
            "Bowen Ma",
            "Ying Zhang",
            "Jingfan Yang",
            "Jing Yang",
            "Depeng Dang"
        ],
        "published": "2024-05-19T07:04:05Z"
    },
    {
        "title": "AdaAugment: A Tuning-Free and Adaptive Approach to Enhance Data\n  Augmentation",
        "link": "http://arxiv.org/abs/2405.11467v2",
        "abstract": "Data augmentation (DA) is widely employed to improve the generalization\nperformance of deep models. However, most existing DA methods use augmentation\noperations with random magnitudes throughout training. While this fosters\ndiversity, it can also inevitably introduce uncontrolled variability in\naugmented data, which may cause misalignment with the evolving training status\nof the target models. Both theoretical and empirical findings suggest that this\nmisalignment increases the risks of underfitting and overfitting. To address\nthese limitations, we propose AdaAugment, an innovative and tuning-free\nAdaptive Augmentation method that utilizes reinforcement learning to\ndynamically adjust augmentation magnitudes for individual training samples\nbased on real-time feedback from the target network. Specifically, AdaAugment\nfeatures a dual-model architecture consisting of a policy network and a target\nnetwork, which are jointly optimized to effectively adapt augmentation\nmagnitudes. The policy network optimizes the variability within the augmented\ndata, while the target network utilizes the adaptively augmented samples for\ntraining. Extensive experiments across benchmark datasets and deep\narchitectures demonstrate that AdaAugment consistently outperforms other\nstate-of-the-art DA methods in effectiveness while maintaining remarkable\nefficiency.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Suorong Yang",
            "Peijia Li",
            "Xin Xiong",
            "Furao Shen",
            "Jian Zhao"
        ],
        "published": "2024-05-19T06:54:03Z"
    },
    {
        "title": "Measuring Impacts of Poisoning on Model Parameters and Embeddings for\n  Large Language Models of Code",
        "link": "http://dx.doi.org/10.1145/3664646.3664764",
        "abstract": "Large language models (LLMs) have revolutionized software development\npractices, yet concerns about their safety have arisen, particularly regarding\nhidden backdoors, aka trojans. Backdoor attacks involve the insertion of\ntriggers into training data, allowing attackers to manipulate the behavior of\nthe model maliciously. In this paper, we focus on analyzing the model\nparameters to detect potential backdoor signals in code models. Specifically,\nwe examine attention weights and biases, and context embeddings of the clean\nand poisoned CodeBERT and CodeT5 models. Our results suggest noticeable\npatterns in context embeddings of poisoned samples for both the poisoned\nmodels; however, attention weights and biases do not show any significant\ndifferences. This work contributes to ongoing efforts in white-box detection of\nbackdoor signals in LLMs of code through the analysis of parameters and\nembeddings.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Aftab Hussain",
            "Md Rafiqul Islam Rabin",
            "Mohammad Amin Alipour"
        ],
        "published": "2024-05-19T06:53:20Z"
    },
    {
        "title": "Effective In-Context Example Selection through Data Compression",
        "link": "http://arxiv.org/abs/2405.11465v1",
        "abstract": "In-context learning has been extensively validated in large language models.\nHowever, the mechanism and selection strategy for in-context example selection,\nwhich is a crucial ingredient in this approach, lacks systematic and in-depth\nresearch. In this paper, we propose a data compression approach to the\nselection of in-context examples. We introduce a two-stage method that can\neffectively choose relevant examples and retain sufficient information about\nthe training dataset within the in-context examples. Our method shows a\nsignificant improvement of an average of 5.90% across five different real-world\ndatasets using four language models.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Zhongxiang Sun",
            "Kepu Zhang",
            "Haoyu Wang",
            "Xiao Zhang",
            "Jun Xu"
        ],
        "published": "2024-05-19T06:46:28Z"
    },
    {
        "title": "Efficient Prompt Tuning by Multi-Space Projection and Prompt Fusion",
        "link": "http://arxiv.org/abs/2405.11464v1",
        "abstract": "Prompt tuning is a promising method to fine-tune a pre-trained language model\nwithout retraining its large-scale parameters. Instead, it attaches a soft\nprompt to the input text, whereby downstream tasks can be well adapted by\nmerely learning the embeddings of prompt tokens. Nevertheless, existing methods\nstill suffer from two challenges: (i) they are hard to balance accuracy and\nefficiency. A longer (shorter) soft prompt generally leads to a better (worse)\naccuracy but at the cost of more (less) training time. (ii) The performance may\nnot be consistent when adapting to different downstream tasks. We attribute it\nto the same embedding space but responsible for different requirements of\ndownstream tasks. To address these issues, we propose an Efficient Prompt\nTuning method (EPT) by multi-space projection and prompt fusion. Specifically,\nit decomposes a given soft prompt into a shorter prompt and two low-rank\nmatrices, whereby the number of parameters is greatly reduced as well as the\ntraining time. The accuracy is also enhanced by leveraging low-rank matrices\nand the short prompt as additional knowledge sources to enrich the semantics of\nthe original short prompt. In addition, we project the soft prompt into\nmultiple subspaces to improve the performance consistency, and then adaptively\nlearn the combination weights of different spaces through a gating network.\nExperimental experiments on 13 natural language processing downstream tasks\nshow that our method significantly and consistently outperforms 11 comparison\nmethods with the relative percentage of improvements up to 28.8%, and training\ntime decreased by 14%.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Pengxiang Lan",
            "Enneng Yang",
            "Yuting Liu",
            "Guibing Guo",
            "Linying Jiang",
            "Jianzhe Zhao",
            "Xingwei Wang"
        ],
        "published": "2024-05-19T06:43:12Z"
    },
    {
        "title": "DocReLM: Mastering Document Retrieval with Language Model",
        "link": "http://arxiv.org/abs/2405.11461v1",
        "abstract": "With over 200 million published academic documents and millions of new\ndocuments being written each year, academic researchers face the challenge of\nsearching for information within this vast corpus. However, existing retrieval\nsystems struggle to understand the semantics and domain knowledge present in\nacademic papers. In this work, we demonstrate that by utilizing large language\nmodels, a document retrieval system can achieve advanced semantic understanding\ncapabilities, significantly outperforming existing systems. Our approach\ninvolves training the retriever and reranker using domain-specific data\ngenerated by large language models. Additionally, we utilize large language\nmodels to identify candidates from the references of retrieved papers to\nfurther enhance the performance. We use a test set annotated by academic\nresearchers in the fields of quantum physics and computer vision to evaluate\nour system's performance. The results show that DocReLM achieves a Top 10\naccuracy of 44.12% in computer vision, compared to Google Scholar's 15.69%, and\nan increase to 36.21% in quantum physics, while that of Google Scholar is\n12.96%.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Gengchen Wei",
            "Xinle Pang",
            "Tianning Zhang",
            "Yu Sun",
            "Xun Qian",
            "Chen Lin",
            "Han-Sen Zhong",
            "Wanli Ouyang"
        ],
        "published": "2024-05-19T06:30:22Z"
    },
    {
        "title": "Du-IN: Discrete units-guided mask modeling for decoding speech from\n  Intracranial Neural signals",
        "link": "http://arxiv.org/abs/2405.11459v1",
        "abstract": "Invasive brain-computer interfaces have garnered significant attention due to\ntheir high performance. The current intracranial stereoElectroEncephaloGraphy\n(sEEG) foundation models typically build univariate representations based on a\nsingle channel. Some of them further use Transformer to model the relationship\namong channels. However, due to the locality and specificity of brain\ncomputation, their performance on more difficult tasks, e.g., speech decoding,\nwhich demands intricate processing in specific brain regions, is yet to be\nfully investigated. We hypothesize that building multi-variate representations\nwithin certain brain regions can better capture the specific neural processing.\nTo explore this hypothesis, we collect a well-annotated Chinese word-reading\nsEEG dataset, targeting language-related brain networks, over 12 subjects.\nLeveraging this benchmark dataset, we developed the Du-IN model that can\nextract contextual embeddings from specific brain regions through discrete\ncodebook-guided mask modeling. Our model achieves SOTA performance on the\ndownstream 61-word classification task, surpassing all baseline models. Model\ncomparison and ablation analysis reveal that our design choices, including (i)\nmulti-variate representation by fusing channels in vSMC and STG regions and\n(ii) self-supervision by discrete codebook-guided mask modeling, significantly\ncontribute to these performances. Collectively, our approach, inspired by\nneuroscience findings, capitalizing on multi-variate neural representation from\nspecific brain regions, is suitable for invasive brain modeling. It marks a\npromising neuro-inspired AI approach in BCI.",
        "subjects": [
            "eess.SP",
            "cs.CL",
            "q-bio.NC"
        ],
        "authors": [
            "Hui Zheng",
            "Hai-Teng Wang",
            "Wei-Bang Jiang",
            "Zhong-Tao Chen",
            "Li He",
            "Pei-Yang Lin",
            "Peng-Hu Wei",
            "Guo-Guang Zhao",
            "Yun-Zhe Liu"
        ],
        "published": "2024-05-19T06:00:36Z"
    },
    {
        "title": "CPS-LLM: Large Language Model based Safe Usage Plan Generator for\n  Human-in-the-Loop Human-in-the-Plant Cyber-Physical System",
        "link": "http://arxiv.org/abs/2405.11458v1",
        "abstract": "We explore the usage of large language models (LLM) in human-in-the-loop\nhuman-in-the-plant cyber-physical systems (CPS) to translate a high-level\nprompt into a personalized plan of actions, and subsequently convert that plan\ninto a grounded inference of sequential decision-making automated by a\nreal-world CPS controller to achieve a control goal. We show that it is\nrelatively straightforward to contextualize an LLM so it can generate\ndomain-specific plans. However, these plans may be infeasible for the physical\nsystem to execute or the plan may be unsafe for human users. To address this,\nwe propose CPS-LLM, an LLM retrained using an instruction tuning framework,\nwhich ensures that generated plans not only align with the physical system\ndynamics of the CPS but are also safe for human users. The CPS-LLM consists of\ntwo innovative components: a) a liquid time constant neural network-based\nphysical dynamics coefficient estimator that can derive coefficients of\ndynamical models with some unmeasured state variables; b) the model\ncoefficients are then used to train an LLM with prompts embodied with traces\nfrom the dynamical system and the corresponding model coefficients. We show\nthat when the CPS-LLM is integrated with a contextualized chatbot such as BARD\nit can generate feasible and safe plans to manage external events such as meals\nfor automated insulin delivery systems used by Type 1 Diabetes subjects.",
        "subjects": [
            "cs.AI",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Ayan Banerjee",
            "Aranyak Maity",
            "Payal Kamboj",
            "Sandeep K. S. Gupta"
        ],
        "published": "2024-05-19T06:00:18Z"
    },
    {
        "title": "Deep Dive into Model-free Reinforcement Learning for Biological and\n  Robotic Systems: Theory and Practice",
        "link": "http://arxiv.org/abs/2405.11457v1",
        "abstract": "Animals and robots exist in a physical world and must coordinate their bodies\nto achieve behavioral objectives. With recent developments in deep\nreinforcement learning, it is now possible for scientists and engineers to\nobtain sensorimotor strategies (policies) for specific tasks using physically\nsimulated bodies and environments. However, the utility of these methods goes\nbeyond the constraints of a specific task; they offer an exciting framework for\nunderstanding the organization of an animal sensorimotor system in connection\nto its morphology and physical interaction with the environment, as well as for\nderiving general design rules for sensing and actuation in robotic systems.\nAlgorithms and code implementing both learning agents and environments are\nincreasingly available, but the basic assumptions and choices that go into the\nformulation of an embodied feedback control problem using deep reinforcement\nlearning may not be immediately apparent. Here, we present a concise exposition\nof the mathematical and algorithmic aspects of model-free reinforcement\nlearning, specifically through the use of \\textit{actor-critic} methods, as a\ntool for investigating the feedback control underlying animal and robotic\nbehavior.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Yusheng Jiao",
            "Feng Ling",
            "Sina Heydari",
            "Nicolas Heess",
            "Josh Merel",
            "Eva Kanso"
        ],
        "published": "2024-05-19T05:58:44Z"
    },
    {
        "title": "Biometrics-Based Authenticated Key Exchange with Multi-Factor Fuzzy\n  Extractor",
        "link": "http://arxiv.org/abs/2405.11456v1",
        "abstract": "Existing fuzzy extractors and similar methods provide an effective way for\nextracting a secret key from a user's biometric data, but are susceptible to\nimpersonation attack: once a valid biometric sample is captured, the scheme is\nno longer secure. We propose a novel multi-factor fuzzy extractor that\nintegrates both a user's secret (e.g., a password) and a user's biometrics in\nthe generation and reconstruction process of a cryptographic key. We then\nemploy this multi-factor fuzzy extractor to construct personal identity\ncredentials which can be used in a new multi-factor authenticated key exchange\nprotocol that possesses multiple important features. First, the protocol\nprovides mutual authentication. Second, the user and service provider can\nauthenticate each other without the involvement of the identity authority.\nThird, the protocol can prevent user impersonation from a compromised identity\nauthority. Finally, even when both a biometric sample and the secret are\ncaptured, the user can re-register to create a new credential using a new\nsecret (reusable/reissued identity credentials). Most existing works on\nmulti-factor authenticated key exchange only have a subset of these features.\nWe formally prove that the proposed protocol is semantically secure. Our\nexperiments carried out on the finger vein dataset SDUMLA achieved a low equal\nerror rate (EER) of 0.04%, a reasonable averaged computation time of 0.93\nseconds for the user and service provider to authenticate and establish a\nshared session key, and a small communication overhead of only 448 bytes.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Hong Yen Tran",
            "Jiankun Hu",
            "Wen Hu"
        ],
        "published": "2024-05-19T05:50:28Z"
    },
    {
        "title": "Comparisons Are All You Need for Optimizing Smooth Functions",
        "link": "http://arxiv.org/abs/2405.11454v1",
        "abstract": "When optimizing machine learning models, there are various scenarios where\ngradient computations are challenging or even infeasible. Furthermore, in\nreinforcement learning (RL), preference-based RL that only compares between\noptions has wide applications, including reinforcement learning with human\nfeedback in large language models. In this paper, we systematically study\noptimization of a smooth function $f\\colon\\mathbb{R}^n\\to\\mathbb{R}$ only\nassuming an oracle that compares function values at two points and tells which\nis larger. When $f$ is convex, we give two algorithms using\n$\\tilde{O}(n/\\epsilon)$ and $\\tilde{O}(n^{2})$ comparison queries to find an\n$\\epsilon$-optimal solution, respectively. When $f$ is nonconvex, our algorithm\nuses $\\tilde{O}(n/\\epsilon^2)$ comparison queries to find an\n$\\epsilon$-approximate stationary point. All these results match the best-known\nzeroth-order algorithms with function evaluation queries in $n$ dependence,\nthus suggest that \\emph{comparisons are all you need for optimizing smooth\nfunctions using derivative-free methods}. In addition, we also give an\nalgorithm for escaping saddle points and reaching an $\\epsilon$-second order\nstationary point of a nonconvex $f$, using $\\tilde{O}(n^{1.5}/\\epsilon^{2.5})$\ncomparison queries.",
        "subjects": [
            "cs.LG",
            "cs.DS",
            "math.OC"
        ],
        "authors": [
            "Chenyi Zhang",
            "Tongyang Li"
        ],
        "published": "2024-05-19T05:39:46Z"
    },
    {
        "title": "Error Analysis of Three-Layer Neural Network Trained with PGD for Deep\n  Ritz Method",
        "link": "http://arxiv.org/abs/2405.11451v1",
        "abstract": "Machine learning is a rapidly advancing field with diverse applications\nacross various domains. One prominent area of research is the utilization of\ndeep learning techniques for solving partial differential equations(PDEs). In\nthis work, we specifically focus on employing a three-layer tanh neural network\nwithin the framework of the deep Ritz method(DRM) to solve second-order\nelliptic equations with three different types of boundary conditions. We\nperform projected gradient descent(PDG) to train the three-layer network and we\nestablish its global convergence. To the best of our knowledge, we are the\nfirst to provide a comprehensive error analysis of using overparameterized\nnetworks to solve PDE problems, as our analysis simultaneously includes\nestimates for approximation error, generalization error, and optimization\nerror. We present error bound in terms of the sample size $n$ and our work\nprovides guidance on how to set the network depth, width, step size, and number\nof iterations for the projected gradient descent algorithm. Importantly, our\nassumptions in this work are classical and we do not require any additional\nassumptions on the solution of the equation. This ensures the broad\napplicability and generality of our results.",
        "subjects": [
            "math.NA",
            "cs.AI",
            "cs.NA",
            "math.AP",
            "stat.ML",
            "65N12, 65N15, 68T07, 62G05, 35J25"
        ],
        "authors": [
            "Yuling Jiao",
            "Yanming Lai",
            "Yang Wang"
        ],
        "published": "2024-05-19T05:07:09Z"
    },
    {
        "title": "NetMamba: Efficient Network Traffic Classification via Pre-training\n  Unidirectional Mamba",
        "link": "http://arxiv.org/abs/2405.11449v1",
        "abstract": "Network traffic classification is a crucial research area aiming to enhance\nservice quality, streamline network management, and bolster cybersecurity. To\naddress the growing complexity of transmission encryption techniques, various\nmachine learning and deep learning methods have been proposed. However,\nexisting approaches encounter two main challenges. Firstly, they struggle with\nmodel inefficiency due to the quadratic complexity of the widely used\nTransformer architecture. Secondly, they suffer from unreliable traffic\nrepresentation because of discarding important byte information while retaining\nunwanted biases. To address these challenges, we propose NetMamba, an efficient\nlinear-time state space model equipped with a comprehensive traffic\nrepresentation scheme. We replace the Transformer with our specially selected\nand improved Mamba architecture for the networking field to address efficiency\nissues. In addition, we design a scheme for traffic representation, which is\nused to extract valid information from massive traffic while removing biased\ninformation. Evaluation experiments on six public datasets encompassing three\nmain classification tasks showcase NetMamba's superior classification\nperformance compared to state-of-the-art baselines. It achieves up to 4.83\\%\nhigher accuracy and 4.64\\% higher f1 score on encrypted traffic classification\ntasks. Additionally, NetMamba demonstrates excellent efficiency, improving\ninference speed by 2.24 times while maintaining comparably low memory usage.\nFurthermore, NetMamba exhibits superior few-shot learning abilities, achieving\nbetter classification performance with fewer labeled data. To the best of our\nknowledge, NetMamba is the first model to tailor the Mamba architecture for\nnetworking.",
        "subjects": [
            "cs.LG",
            "cs.NI"
        ],
        "authors": [
            "Tongze Wang",
            "Xiaohui Xie",
            "Wenduo Wang",
            "Chuyi Wang",
            "Youjian Zhao",
            "Yong Cui"
        ],
        "published": "2024-05-19T04:58:53Z"
    },
    {
        "title": "Cross-Domain Knowledge Distillation for Low-Resolution Human Pose\n  Estimation",
        "link": "http://arxiv.org/abs/2405.11448v1",
        "abstract": "In practical applications of human pose estimation, low-resolution inputs\nfrequently occur, and existing state-of-the-art models perform poorly with\nlow-resolution images. This work focuses on boosting the performance of\nlow-resolution models by distilling knowledge from a high-resolution model.\nHowever, we face the challenge of feature size mismatch and class number\nmismatch when applying knowledge distillation to networks with different input\nresolutions. To address this issue, we propose a novel cross-domain knowledge\ndistillation (CDKD) framework. In this framework, we construct a scale-adaptive\nprojector ensemble (SAPE) module to spatially align feature maps between models\nof varying input resolutions. It adopts a projector ensemble to map\nlow-resolution features into multiple common spaces and adaptively merges them\nbased on multi-scale information to match high-resolution features.\nAdditionally, we construct a cross-class alignment (CCA) module to solve the\nproblem of the mismatch of class numbers. By combining an easy-to-hard training\n(ETHT) strategy, the CCA module further enhances the distillation performance.\nThe effectiveness and efficiency of our approach are demonstrated by extensive\nexperiments on two common benchmark datasets: MPII and COCO. The code is made\navailable in supplementary material.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zejun Gu",
            "Zhong-Qiu Zhao",
            "Henghui Ding",
            "Hao Shen",
            "Zhao Zhang",
            "De-Shuang Huang"
        ],
        "published": "2024-05-19T04:57:17Z"
    },
    {
        "title": "MAML-en-LLM: Model Agnostic Meta-Training of LLMs for Improved\n  In-Context Learning",
        "link": "http://arxiv.org/abs/2405.11446v1",
        "abstract": "Adapting large language models (LLMs) to unseen tasks with in-context\ntraining samples without fine-tuning remains an important research problem. To\nlearn a robust LLM that adapts well to unseen tasks, multiple meta-training\napproaches have been proposed such as MetaICL and MetaICT, which involve\nmeta-training pre-trained LLMs on a wide variety of diverse tasks. These\nmeta-training approaches essentially perform in-context multi-task fine-tuning\nand evaluate on a disjointed test set of tasks. Even though they achieve\nimpressive performance, their goal is never to compute a truly general set of\nparameters. In this paper, we propose MAML-en-LLM, a novel method for\nmeta-training LLMs, which can learn truly generalizable parameters that not\nonly perform well on disjointed tasks but also adapts to unseen tasks. We see\nan average increase of 2% on unseen domains in the performance while a massive\n4% improvement on adaptation performance. Furthermore, we demonstrate that\nMAML-en-LLM outperforms baselines in settings with limited amount of training\ndata on both seen and unseen domains by an average of 2%. Finally, we discuss\nthe effects of type of tasks, optimizers and task complexity, an avenue barely\nexplored in meta-training literature. Exhaustive experiments across 7 task\nsettings along with two data settings demonstrate that models trained with\nMAML-en-LLM outperform SOTA meta-training approaches.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Sanchit Sinha",
            "Yuguang Yue",
            "Victor Soto",
            "Mayank Kulkarni",
            "Jianhua Lu",
            "Aidong Zhang"
        ],
        "published": "2024-05-19T04:49:42Z"
    },
    {
        "title": "Unifying 3D Vision-Language Understanding via Promptable Queries",
        "link": "http://arxiv.org/abs/2405.11442v1",
        "abstract": "A unified model for 3D vision-language (3D-VL) understanding is expected to\ntake various scene representations and perform a wide range of tasks in a 3D\nscene. However, a considerable gap exists between existing methods and such a\nunified model, due to the independent application of representation and\ninsufficient exploration of 3D multi-task training. In this paper, we introduce\nPQ3D, a unified model capable of using Promptable Queries to tackle a wide\nrange of 3D-VL tasks, from low-level instance segmentation to high-level\nreasoning and planning. This is achieved through three key innovations: (1)\nunifying various 3D scene representations (i.e., voxels, point clouds,\nmulti-view images) into a shared 3D coordinate space by segment-level grouping,\n(2) an attention-based query decoder for task-specific information retrieval\nguided by prompts, and (3) universal output heads for different tasks to\nsupport multi-task training. Tested across ten diverse 3D-VL datasets, PQ3D\ndemonstrates impressive performance on these tasks, setting new records on most\nbenchmarks. Particularly, PQ3D improves the state-of-the-art on ScanNet200 by\n1.8% (AP), ScanRefer by 5.4% (acc@0.5), Multi3DRefer by 11.7% (F1@0.5), and\nScan2Cap by 13.4% (CIDEr@0.5). Moreover, PQ3D supports flexible inference with\nindividual or combined forms of available 3D representations, e.g., solely\nvoxel input.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ziyu Zhu",
            "Zhuofan Zhang",
            "Xiaojian Ma",
            "Xuesong Niu",
            "Yixin Chen",
            "Baoxiong Jia",
            "Zhidong Deng",
            "Siyuan Huang",
            "Qing Li"
        ],
        "published": "2024-05-19T04:35:05Z"
    },
    {
        "title": "Focus on Low-Resolution Information: Multi-Granular Information-Lossless\n  Model for Low-Resolution Human Pose Estimation",
        "link": "http://arxiv.org/abs/2405.12247v1",
        "abstract": "In real-world applications of human pose estimation, low-resolution input\nimages are frequently encountered when the performance of the image acquisition\nequipment is limited or the shooting distance is too far. However, existing\nstate-of-the-art models for human pose estimation perform poorly on\nlow-resolution images. One key reason is the presence of downsampling layers in\nthese models, e.g., strided convolutions and pooling layers. It further reduces\nthe already insufficient image information. Another key reason is that the body\nskeleton and human kinematic information are not fully utilized. In this work,\nwe propose a Multi-Granular Information-Lossless (MGIL) model to replace the\ndownsampling layers to address the above issues. Specifically, MGIL employs a\nFine-grained Lossless Information Extraction (FLIE) module, which can prevent\nthe loss of local information. Furthermore, we design a Coarse-grained\nInformation Interaction (CII) module to adequately leverage human body\nstructural information. To efficiently fuse cross-granular information and\nthoroughly exploit the relationships among keypoints, we further introduce a\nMulti-Granular Adaptive Fusion (MGAF) mechanism. The mechanism assigns weights\nto features of different granularities based on the content of the image. The\nmodel is effective, flexible, and universal. We show its potential in various\nvision tasks with comprehensive experiments. It outperforms the SOTA methods by\n7.7 mAP on COCO and performs well with different input resolutions, different\nbackbones, and different vision tasks. The code is provided in supplementary\nmaterial.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zejun Gu",
            "Zhong-Qiu Zhao",
            "Hao Shen",
            "Zhao Zhang"
        ],
        "published": "2024-05-19T04:33:45Z"
    },
    {
        "title": "EmbSum: Leveraging the Summarization Capabilities of Large Language\n  Models for Content-Based Recommendations",
        "link": "http://arxiv.org/abs/2405.11441v1",
        "abstract": "Content-based recommendation systems play a crucial role in delivering\npersonalized content to users in the digital world. In this work, we introduce\nEmbSum, a novel framework that enables offline pre-computations of users and\ncandidate items while capturing the interactions within the user engagement\nhistory. By utilizing the pretrained encoder-decoder model and poly-attention\nlayers, EmbSum derives User Poly-Embedding (UPE) and Content Poly-Embedding\n(CPE) to calculate relevance scores between users and candidate items. EmbSum\nactively learns the long user engagement histories by generating user-interest\nsummary with supervision from large language model (LLM). The effectiveness of\nEmbSum is validated on two datasets from different domains, surpassing\nstate-of-the-art (SoTA) methods with higher accuracy and fewer parameters.\nAdditionally, the model's ability to generate summaries of user interests\nserves as a valuable by-product, enhancing its usefulness for personalized\ncontent recommendations.",
        "subjects": [
            "cs.IR",
            "cs.CL"
        ],
        "authors": [
            "Chiyu Zhang",
            "Yifei Sun",
            "Minghao Wu",
            "Jun Chen",
            "Jie Lei",
            "Muhammad Abdul-Mageed",
            "Rong Jin",
            "Angli Liu",
            "Ji Zhu",
            "Sem Park",
            "Ning Yao",
            "Bo Long"
        ],
        "published": "2024-05-19T04:31:54Z"
    },
    {
        "title": "A GAN-Based Data Poisoning Attack Against Federated Learning Systems and\n  Its Countermeasure",
        "link": "http://arxiv.org/abs/2405.11440v2",
        "abstract": "As a distributed machine learning paradigm, federated learning (FL) is\ncollaboratively carried out on privately owned datasets but without direct data\naccess. Although the original intention is to allay data privacy concerns,\n\"available but not visible\" data in FL potentially brings new security threats,\nparticularly poisoning attacks that target such \"not visible\" local data.\nInitial attempts have been made to conduct data poisoning attacks against FL\nsystems, but cannot be fully successful due to their high chance of causing\nstatistical anomalies. To unleash the potential for truly \"invisible\" attacks\nand build a more deterrent threat model, in this paper, a new data poisoning\nattack model named VagueGAN is proposed, which can generate seemingly\nlegitimate but noisy poisoned data by untraditionally taking advantage of\ngenerative adversarial network (GAN) variants. Capable of manipulating the\nquality of poisoned data on demand, VagueGAN enables to trade-off attack\neffectiveness and stealthiness. Furthermore, a cost-effective countermeasure\nnamed Model Consistency-Based Defense (MCD) is proposed to identify\nGAN-poisoned data or models after finding out the consistency of GAN outputs.\nExtensive experiments on multiple datasets indicate that our attack method is\ngenerally much more stealthy as well as more effective in degrading FL\nperformance with low complexity. Our defense method is also shown to be more\ncompetent in identifying GAN-poisoned data or models. The source codes are\npublicly available at\n\\href{https://github.com/SSssWEIssSS/VagueGAN-Data-Poisoning-Attack-and-Its-Countermeasure}{https://github.com/SSssWEIssSS/VagueGAN-Data-Poisoning-Attack-and-Its-Countermeasure}.",
        "subjects": [
            "cs.CR",
            "cs.DC",
            "cs.NI"
        ],
        "authors": [
            "Wei Sun",
            "Bo Gao",
            "Ke Xiong",
            "Yuwei Wang"
        ],
        "published": "2024-05-19T04:23:40Z"
    },
    {
        "title": "The First Swahili Language Scene Text Detection and Recognition Dataset",
        "link": "http://arxiv.org/abs/2405.11437v1",
        "abstract": "Scene text recognition is essential in many applications, including automated\ntranslation, information retrieval, driving assistance, and enhancing\naccessibility for individuals with visual impairments. Much research has been\ndone to improve the accuracy and performance of scene text detection and\nrecognition models. However, most of this research has been conducted in the\nmost common languages, English and Chinese. There is a significant gap in\nlow-resource languages, especially the Swahili Language. Swahili is widely\nspoken in East African countries but is still an under-explored language in\nscene text recognition. No studies have been focused explicitly on Swahili\nnatural scene text detection and recognition, and no dataset for Swahili\nlanguage scene text detection and recognition is publicly available. We propose\na comprehensive dataset of Swahili scene text images and evaluate the dataset\non different scene text detection and recognition models. The dataset contains\n976 images collected in different places and under various circumstances. Each\nimage has its annotation at the word level. The proposed dataset can also serve\nas a benchmark dataset specific to the Swahili language for evaluating and\ncomparing different approaches and fostering future research endeavors. The\ndataset is available on GitHub via this link:\nhttps://github.com/FadilaW/Swahili-STR-Dataset",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Fadila Wendigoundi Douamba",
            "Jianjun Song",
            "Ling Fu",
            "Yuliang Liu",
            "Xiang Bai"
        ],
        "published": "2024-05-19T03:55:02Z"
    },
    {
        "title": "A Method on Searching Better Activation Functions",
        "link": "http://arxiv.org/abs/2405.12954v2",
        "abstract": "The success of artificial neural networks (ANNs) hinges greatly on the\njudicious selection of an activation function, introducing non-linearity into\nnetwork and enabling them to model sophisticated relationships in data.\nHowever, the search of activation functions has largely relied on empirical\nknowledge in the past, lacking theoretical guidance, which has hindered the\nidentification of more effective activation functions. In this work, we offer a\nproper solution to such issue. Firstly, we theoretically demonstrate the\nexistence of the worst activation function with boundary conditions (WAFBC)\nfrom the perspective of information entropy. Furthermore, inspired by the\nTaylor expansion form of information entropy functional, we propose the\nEntropy-based Activation Function Optimization (EAFO) methodology. EAFO\nmethodology presents a novel perspective for designing static activation\nfunctions in deep neural networks and the potential of dynamically optimizing\nactivation during iterative training. Utilizing EAFO methodology, we derive a\nnovel activation function from ReLU, known as Correction Regularized ReLU\n(CRReLU). Experiments conducted with vision transformer and its variants on\nCIFAR-10, CIFAR-100 and ImageNet-1K datasets demonstrate the superiority of\nCRReLU over existing corrections of ReLU. Extensive empirical studies on task\nof large language model (LLM) fine-tuning, CRReLU exhibits superior performance\ncompared to GELU, suggesting its broader potential for practical applications.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Haoyuan Sun",
            "Zihao Wu",
            "Bo Xia",
            "Pu Chang",
            "Zibin Dong",
            "Yifu Yuan",
            "Yongzhe Chang",
            "Xueqian Wang"
        ],
        "published": "2024-05-19T03:48:05Z"
    },
    {
        "title": "Human-Generative AI Collaborative Problem Solving Who Leads and How\n  Students Perceive the Interactions",
        "link": "http://arxiv.org/abs/2405.13048v1",
        "abstract": "This research investigates distinct human-generative AI collaboration types\nand students' interaction experiences when collaborating with generative AI\n(i.e., ChatGPT) for problem-solving tasks and how these factors relate to\nstudents' sense of agency and perceived collaborative problem solving. By\nanalyzing the surveys and reflections of 79 undergraduate students, we\nidentified three human-generative AI collaboration types: even contribution,\nhuman leads, and AI leads. Notably, our study shows that 77.21% of students\nperceived they led or had even contributed to collaborative problem-solving\nwhen collaborating with ChatGPT. On the other hand, 15.19% of the human\nparticipants indicated that the collaborations were led by ChatGPT, indicating\na potential tendency for students to rely on ChatGPT. Furthermore, 67.09% of\nstudents perceived their interaction experiences with ChatGPT to be positive or\nmixed. We also found a positive correlation between positive interaction\nexperience and a sense of positive agency. The results of this study contribute\nto our understanding of the collaboration between students and generative AI\nand highlight the need to study further why some students let ChatGPT lead\ncollaborative problem-solving and how to enhance their interaction experience\nthrough curriculum and technology design.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Gaoxia Zhu",
            "Vidya Sudarshan",
            "Jason Fok Kow",
            "Yew Soon Ong"
        ],
        "published": "2024-05-19T03:29:16Z"
    },
    {
        "title": "On Robust Reinforcement Learning with Lipschitz-Bounded Policy Networks",
        "link": "http://arxiv.org/abs/2405.11432v1",
        "abstract": "This paper presents a study of robust policy networks in deep reinforcement\nlearning. We investigate the benefits of policy parameterizations that\nnaturally satisfy constraints on their Lipschitz bound, analyzing their\nempirical performance and robustness on two representative problems: pendulum\nswing-up and Atari Pong. We illustrate that policy networks with small\nLipschitz bounds are significantly more robust to disturbances, random noise,\nand targeted adversarial attacks than unconstrained policies composed of\nvanilla multi-layer perceptrons or convolutional neural networks. Moreover, we\nfind that choosing a policy parameterization with a non-conservative Lipschitz\nbound and an expressive, nonlinear layer architecture gives the user much finer\ncontrol over the performance-robustness trade-off than existing\nstate-of-the-art methods based on spectral normalization.",
        "subjects": [
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Nicholas H. Barbara",
            "Ruigang Wang",
            "Ian R. Manchester"
        ],
        "published": "2024-05-19T03:27:31Z"
    },
    {
        "title": "Review of deep learning models for crypto price prediction:\n  implementation and evaluation",
        "link": "http://arxiv.org/abs/2405.11431v1",
        "abstract": "There has been much interest in accurate cryptocurrency price forecast models\nby investors and researchers. Deep Learning models are prominent machine\nlearning techniques that have transformed various fields and have shown\npotential for finance and economics. Although various deep learning models have\nbeen explored for cryptocurrency price forecasting, it is not clear which\nmodels are suitable due to high market volatility. In this study, we review the\nliterature about deep learning for cryptocurrency price forecasting and\nevaluate novel deep learning models for cryptocurrency stock price prediction.\nOur deep learning models include variants of long short-term memory (LSTM)\nrecurrent neural networks, variants of convolutional neural networks (CNNs),\nand the Transformer model. We evaluate univariate and multivariate approaches\nfor multi-step ahead predicting of cryptocurrencies close-price. Our results\nshow that the univariate LSTM model variants perform best for cryptocurrency\npredictions. We also carry out volatility analysis on the four cryptocurrencies\nwhich reveals significant fluctuations in their prices throughout the COVID-19\npandemic. Additionally, we investigate the prediction accuracy of two scenarios\nidentified by different training sets for the models. First, we use the\npre-COVID-19 datasets to model cryptocurrency close-price forecasting during\nthe early period of COVID-19. Secondly, we utilise data from the COVID-19\nperiod to predict prices for 2023 to 2024.",
        "subjects": [
            "cs.LG",
            "q-fin.ST",
            "stat.ML"
        ],
        "authors": [
            "Jingyang Wu",
            "Xinyi Zhang",
            "Fangyixuan Huang",
            "Haochen Zhou",
            "Rohtiash Chandra"
        ],
        "published": "2024-05-19T03:15:27Z"
    },
    {
        "title": "MHPP: Exploring the Capabilities and Limitations of Language Models\n  Beyond Basic Code Generation",
        "link": "http://arxiv.org/abs/2405.11430v1",
        "abstract": "Recent advancements in large language models (LLMs) have greatly improved\ncode generation, specifically at the function level. For instance, GPT-4 has\nachieved an 88.4% pass rate on HumanEval. However, this draws into question the\nadequacy of existing benchmarks in thoroughly assessing function-level code\ngeneration capabilities. Our study analyzed two common benchmarks, HumanEval\nand MBPP, and found that these might not thoroughly evaluate LLMs' code\ngeneration capacities due to limitations in quality, difficulty, and\ngranularity. To resolve this, we introduce the Mostly Hard Python Problems\n(MHPP) dataset, consisting of 140 unique human-curated problems. By focusing on\nthe combination of natural language and code reasoning, MHPP gauges LLMs'\nabilities to comprehend specifications and restrictions, engage in multi-step\nreasoning, and apply coding knowledge effectively. Initial evaluations of 22\nLLMs using MHPP showed many high-performing models on HumanEval failed to\nachieve similar success on MHPP. Moreover, MHPP highlighted various previously\nundiscovered limitations within various LLMs, leading us to believe that it\ncould pave the way for a better understanding of LLMs' capabilities and\nlimitations. Dataset and code are available at\nhttps://github.com/SparksofAGI/MHPP.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Jianbo Dai",
            "Jianqiao Lu",
            "Yunlong Feng",
            "Rongju Ruan",
            "Ming Cheng",
            "Haochen Tan",
            "Zhijiang Guo"
        ],
        "published": "2024-05-19T03:08:02Z"
    },
    {
        "title": "Quantum Neural Networks for Solving Power System Transient Simulation\n  Problem",
        "link": "http://arxiv.org/abs/2405.11427v1",
        "abstract": "Quantum computing, leveraging principles of quantum mechanics, represents a\ntransformative approach in computational methodologies, offering significant\nenhancements over traditional classical systems. This study tackles the complex\nand computationally demanding task of simulating power system transients\nthrough solving differential algebraic equations (DAEs). We introduce two novel\nQuantum Neural Networks (QNNs): the Sinusoidal-Friendly QNN and the\nPolynomial-Friendly QNN, proposing them as effective alternatives to\nconventional simulation techniques. Our application of these QNNs successfully\nsimulates two small power systems, demonstrating their potential to achieve\ngood accuracy. We further explore various configurations, including time\nintervals, training points, and the selection of classical optimizers, to\noptimize the solving of DAEs using QNNs. This research not only marks a\npioneering effort in applying quantum computing to power system simulations but\nalso expands the potential of quantum technologies in addressing intricate\nengineering challenges.",
        "subjects": [
            "quant-ph",
            "cs.LG",
            "cs.SY",
            "eess.SP",
            "eess.SY",
            "math.OC"
        ],
        "authors": [
            "Mohammadreza Soltaninia",
            "Junpeng Zhan"
        ],
        "published": "2024-05-19T02:18:04Z"
    },
    {
        "title": "Enabling full-speed random access to the entire memory on the A100 GPU",
        "link": "http://arxiv.org/abs/2405.11425v1",
        "abstract": "We describe some features of the A100 memory architecture. In particular, we\ngive a technique to reverse-engineer some hardware layout information. Using\nthis information, we show how to avoid TLB issues to obtain full-speed random\nHBM access to the entire memory, as long as we constrain any particular thread\nto a reduced access window of less than 64GB.",
        "subjects": [
            "cs.PF",
            "cs.AR",
            "C.4; B.3.3"
        ],
        "authors": [
            "Alden Walker"
        ],
        "published": "2024-05-19T02:11:30Z"
    },
    {
        "title": "Metric Dimension and Resolvability of Jaccard Spaces",
        "link": "http://arxiv.org/abs/2405.11424v1",
        "abstract": "A subset of points in a metric space is said to resolve it if each point in\nthe space is uniquely characterized by its distance to each point in the\nsubset. In particular, resolving sets can be used to represent points in\nabstract metric spaces as Euclidean vectors. Importantly, due to the triangle\ninequality, points close by in the space are represented as vectors with\nsimilar coordinates, which may find applications in classification problems of\nsymbolic objects under suitably chosen metrics. In this manuscript, we address\nthe resolvability of Jaccard spaces, i.e., metric spaces of the form\n$(2^X,\\text{Jac})$, where $2^X$ is the power set of a finite set $X$, and\n$\\text{Jac}$ is the Jaccard distance between subsets of $X$. Specifically, for\ndifferent $a,b\\in 2^X$, $\\text{Jac}(a,b)=\\frac{|a\\Delta b|}{|a\\cup b|}$, where\n$|\\cdot|$ denotes size (i.e., cardinality) and $\\Delta$ denotes the symmetric\ndifference of sets. We combine probabilistic and linear algebra arguments to\nconstruct highly likely but nearly optimal (i.e., of minimal size) resolving\nsets of $(2^X,\\text{Jac})$. In particular, we show that the metric dimension of\n$(2^X,\\text{Jac})$, i.e., the minimum size of a resolving set of this space, is\n$\\Theta(|X|/\\ln|X|)$.",
        "subjects": [
            "cs.DM",
            "cs.CL",
            "math.CO",
            "math.PR",
            "05C12, 60C05, 68R05, 68R12, 46B85, 33D90, 68T50",
            "G.2; G.3; E.4; G.2.1; G.2.2"
        ],
        "authors": [
            "Manuel E. Lladser",
            "Alexander J. Paradise"
        ],
        "published": "2024-05-19T02:09:50Z"
    },
    {
        "title": "Large Language Models are Biased Reinforcement Learners",
        "link": "http://arxiv.org/abs/2405.11422v1",
        "abstract": "In-context learning enables large language models (LLMs) to perform a variety\nof tasks, including learning to make reward-maximizing choices in simple bandit\ntasks. Given their potential use as (autonomous) decision-making agents, it is\nimportant to understand how these models perform such reinforcement learning\n(RL) tasks and the extent to which they are susceptible to biases. Motivated by\nthe fact that, in humans, it has been widely documented that the value of an\noutcome depends on how it compares to other local outcomes, the present study\nfocuses on whether similar value encoding biases apply to how LLMs encode\nrewarding outcomes. Results from experiments with multiple bandit tasks and\nmodels show that LLMs exhibit behavioral signatures of a relative value bias.\nAdding explicit outcome comparisons to the prompt produces opposing effects on\nperformance, enhancing maximization in trained choice sets but impairing\ngeneralization to new choice sets. Computational cognitive modeling reveals\nthat LLM behavior is well-described by a simple RL algorithm that incorporates\nrelative values at the outcome encoding stage. Lastly, we present preliminary\nevidence that the observed biases are not limited to fine-tuned LLMs, and that\nrelative value processing is detectable in the final hidden layer activations\nof a raw, pretrained model. These findings have important implications for the\nuse of LLMs in decision-making applications.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "William M. Hayes",
            "Nicolas Yax",
            "Stefano Palminteri"
        ],
        "published": "2024-05-19T01:43:52Z"
    },
    {
        "title": "Assessing Group Fairness with Social Welfare Optimization",
        "link": "http://arxiv.org/abs/2405.11421v1",
        "abstract": "Statistical parity metrics have been widely studied and endorsed in the AI\ncommunity as a means of achieving fairness, but they suffer from at least two\nweaknesses. They disregard the actual welfare consequences of decisions and may\ntherefore fail to achieve the kind of fairness that is desired for\ndisadvantaged groups. In addition, they are often incompatible with each other,\nand there is no convincing justification for selecting one rather than another.\nThis paper explores whether a broader conception of social justice, based on\noptimizing a social welfare function (SWF), can be useful for assessing various\ndefinitions of parity. We focus on the well-known alpha fairness SWF, which has\nbeen defended by axiomatic and bargaining arguments over a period of 70 years.\nWe analyze the optimal solution and show that it can justify demographic parity\nor equalized odds under certain conditions, but frequently requires a departure\nfrom these types of parity. In addition, we find that predictive rate parity is\nof limited usefulness. These results suggest that optimization theory can shed\nlight on the intensely discussed question of how to achieve group fairness in\nAI.",
        "subjects": [
            "cs.AI",
            "cs.CY",
            "cs.GT"
        ],
        "authors": [
            "Violet Chen",
            "J. N. Hooker",
            "Derek Leben"
        ],
        "published": "2024-05-19T01:41:04Z"
    },
    {
        "title": "Sketches-based join size estimation under local differential privacy",
        "link": "http://arxiv.org/abs/2405.11419v1",
        "abstract": "Join size estimation on sensitive data poses a risk of privacy leakage. Local\ndifferential privacy (LDP) is a solution to preserve privacy while collecting\nsensitive data, but it introduces significant noise when dealing with sensitive\njoin attributes that have large domains. Employing probabilistic structures\nsuch as sketches is a way to handle large domains, but it leads to\nhash-collision errors. To achieve accurate estimations, it is necessary to\nreduce both the noise error and hash-collision error. To tackle the noise error\ncaused by protecting sensitive join values with large domains, we introduce a\nnovel algorithm called LDPJoinSketch for sketch-based join size estimation\nunder LDP. Additionally, to address the inherent hash-collision errors in\nsketches under LDP, we propose an enhanced method called LDPJoinSketch+. It\nutilizes a frequency-aware perturbation mechanism that effectively separates\nhigh-frequency and low-frequency items without compromising privacy. The\nproposed methods satisfy LDP, and the estimation error is bounded. Experimental\nresults show that our method outperforms existing methods, effectively\nenhancing the accuracy of join size estimation under LDP.",
        "subjects": [
            "cs.DB",
            "cs.CR"
        ],
        "authors": [
            "Meifan Zhang",
            "Xin Liu",
            "Lihua Yin"
        ],
        "published": "2024-05-19T01:21:54Z"
    },
    {
        "title": "Completeness of two fragments of a logic for conditional strategic\n  reasoning",
        "link": "http://arxiv.org/abs/2405.11418v1",
        "abstract": "Classical logics for strategic reasoning, such as Coalition Logic and\nAlternating-time Temporal Logic, formalize absolute strategic reasoning about\nthe unconditional strategic abilities of agents to achieve their goals. Goranko\nand Ju introduced a logic ConStR for strategic reasoning about conditional\nstrategic abilities. However, its completeness is still an open problem. ConStR\nhas three featured operators, and one of them has the following reading: For\nsome action of A that guarantees the achievement of her goal, B has an action\nto guarantee the achievement of his goal. The logic about this operator is\ncalled CConStR. In this paper, we prove completeness for two fragments of\nCConStR. The key notions of our proof approach include downward validity lemma,\ngrafted models, and upward derivability lemma. The proof approach has good\npotential to be applied to the completeness of ConStR and other logics.",
        "subjects": [
            "cs.LO"
        ],
        "authors": [
            "Yinfeng Li",
            "Fengkui Ju"
        ],
        "published": "2024-05-19T00:51:51Z"
    },
    {
        "title": "Budgeted Recommendation with Delayed Feedback",
        "link": "http://arxiv.org/abs/2405.11417v1",
        "abstract": "In a conventional contextual multi-armed bandit problem, the feedback (or\nreward) is immediately observable after an action. Nevertheless, delayed\nfeedback arises in numerous real-life situations and is particularly crucial in\ntime-sensitive applications. The exploration-exploitation dilemma becomes\nparticularly challenging under such conditions, as it couples with the\ninterplay between delays and limited resources. Besides, a limited budget often\naggravates the problem by restricting the exploration potential. A motivating\nexample is the distribution of medical supplies at the early stage of COVID-19.\nThe delayed feedback of testing results, thus insufficient information for\nlearning, degraded the efficiency of resource allocation. Motivated by such\napplications, we study the effect of delayed feedback on constrained contextual\nbandits. We develop a decision-making policy, delay-oriented resource\nallocation with learning (DORAL), to optimize the resource expenditure in a\ncontextual multi-armed bandit problem with arm-dependent delayed feedback.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Kweiguu Liu",
            "Setareh Maghsudi"
        ],
        "published": "2024-05-19T00:19:59Z"
    },
    {
        "title": "Discrete-state Continuous-time Diffusion for Graph Generation",
        "link": "http://arxiv.org/abs/2405.11416v1",
        "abstract": "Graph is a prevalent discrete data structure, whose generation has wide\napplications such as drug discovery and circuit design. Diffusion generative\nmodels, as an emerging research focus, have been applied to graph generation\ntasks. Overall, according to the space of states and time steps, diffusion\ngenerative models can be categorized into discrete-/continuous-state\ndiscrete-/continuous-time fashions. In this paper, we formulate the graph\ndiffusion generation in a discrete-state continuous-time setting, which has\nnever been studied in previous graph diffusion models. The rationale of such a\nformulation is to preserve the discrete nature of graph-structured data and\nmeanwhile provide flexible sampling trade-offs between sample quality and\nefficiency. Analysis shows that our training objective is closely related to\ngeneration quality, and our proposed generation framework enjoys ideal\ninvariant/equivariant properties concerning the permutation of node ordering.\nOur proposed model shows competitive empirical performance against\nstate-of-the-art graph generation solutions on various benchmarks and, at the\nsame time, can flexibly trade off the generation quality and efficiency in the\nsampling phase.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Zhe Xu",
            "Ruizhong Qiu",
            "Yuzhong Chen",
            "Huiyuan Chen",
            "Xiran Fan",
            "Menghai Pan",
            "Zhichen Zeng",
            "Mahashweta Das",
            "Hanghang Tong"
        ],
        "published": "2024-05-19T00:09:42Z"
    }
]