[
    {
        "title": "Verifying Cake-Cutting, Faster",
        "link": "http://arxiv.org/abs/2405.14068v1",
        "abstract": "Envy-free cake-cutting protocols procedurally divide an infinitely divisible\ngood among a set of agents so that no agent prefers another's allocation to\ntheir own. These protocols are highly complex and difficult to prove correct.\nRecently, Bertram, Levinson, and Hsu introduced a language called Slice for\ndescribing and verifying cake-cutting protocols. Slice programs can be\ntranslated to formulas encoding envy-freeness, which are solved by SMT. While\nSlice works well on smaller protocols, it has difficulty scaling to more\ncomplex cake-cutting protocols.\n  We improve Slice in two ways. First, we show any protocol execution in Slice\ncan be replicated using piecewise uniform valuations. We then reduce Slice's\nconstraint formulas to formulas within the theory of linear real arithmetic,\nshowing that verifying envy-freeness is efficiently decidable. Second, we\ndesign and implement a linear type system which enforces that no two agents\nreceive the same part of the good. We implement our methods and verify a range\nof challenging examples, including the first nontrivial four-agent protocol.",
        "subjects": [
            "cs.GT",
            "cs.PL",
            "D.3.1; J.4"
        ],
        "authors": [
            "Noah Bertram",
            "Tean Lai",
            "Justin Hsu"
        ],
        "published": "2024-05-22T23:56:26Z"
    },
    {
        "title": "ABI Approach: Automatic Bias Identification in Decision-Making Under\n  Risk based in an Ontology of Behavioral Economics",
        "link": "http://arxiv.org/abs/2405.14067v1",
        "abstract": "Organizational decision-making is crucial for success, yet cognitive biases\ncan significantly affect risk preferences, leading to suboptimal outcomes. Risk\nseeking preferences for losses, driven by biases such as loss aversion, pose\nchallenges and can result in severe negative consequences, including financial\nlosses. This research introduces the ABI approach, a novel solution designed to\nsupport organizational decision-makers by automatically identifying and\nexplaining risk seeking preferences during decision-making. This research makes\na novel contribution by automating the identification and explanation of risk\nseeking preferences using Cumulative Prospect theory (CPT) from Behavioral\nEconomics. The ABI approach transforms theoretical insights into actionable,\nreal-time guidance, making them accessible to a broader range of organizations\nand decision-makers without requiring specialized personnel. By contextualizing\nCPT concepts into business language, the approach facilitates widespread\nadoption and enhances decision-making processes with deep behavioral insights.\nOur systematic literature review identified significant gaps in existing\nmethods, especially the lack of automated solutions with a concrete mechanism\nfor automatically identifying risk seeking preferences, and the absence of\nformal knowledge representation, such as ontologies, for identifying and\nexplaining the risk preferences. The ABI Approach addresses these gaps,\noffering a significant contribution to decision-making research and practice.\nFurthermore, it enables automatic collection of historical decision data with\nrisk preferences, providing valuable insights for enhancing strategic\nmanagement and long-term organizational performance. An experiment provided\npreliminary evidence on its effectiveness in helping decision-makers recognize\ntheir risk seeking preferences during decision-making in the loss domain.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "H.4.2; J.4"
        ],
        "authors": [
            "Eduardo da C. Ramos",
            "Maria Luiza M. Campos",
            "Fernanda Bai√£o"
        ],
        "published": "2024-05-22T23:53:46Z"
    },
    {
        "title": "Online Classification with Predictions",
        "link": "http://arxiv.org/abs/2405.14066v1",
        "abstract": "We study online classification when the learner has access to predictions\nabout future examples. We design an online learner whose expected regret is\nnever worse than the worst-case regret, gracefully improves with the quality of\nthe predictions, and can be significantly better than the worst-case regret\nwhen the predictions of future examples are accurate. As a corollary, we show\nthat if the learner is always guaranteed to observe data where future examples\nare easily predictable, then online learning can be as easy as transductive\nonline learning. Our results complement recent work in online algorithms with\npredictions and smoothed online classification, which go beyond a worse-case\nanalysis by using machine-learned predictions and distributional assumptions\nrespectively.",
        "subjects": [
            "cs.LG",
            "cs.DS",
            "stat.ML"
        ],
        "authors": [
            "Vinod Raman",
            "Ambuj Tewari"
        ],
        "published": "2024-05-22T23:45:33Z"
    },
    {
        "title": "Building a stable classifier with the inflated argmax",
        "link": "http://arxiv.org/abs/2405.14064v1",
        "abstract": "We propose a new framework for algorithmic stability in the context of\nmulticlass classification. In practice, classification algorithms often operate\nby first assigning a continuous score (for instance, an estimated probability)\nto each possible label, then taking the maximizer -- i.e., selecting the class\nthat has the highest score. A drawback of this type of approach is that it is\ninherently unstable, meaning that it is very sensitive to slight perturbations\nof the training data, since taking the maximizer is discontinuous. Motivated by\nthis challenge, we propose a pipeline for constructing stable classifiers from\ndata, using bagging (i.e., resampling and averaging) to produce stable\ncontinuous scores, and then using a stable relaxation of argmax, which we call\nthe \"inflated argmax,\" to convert these scores to a set of candidate labels.\nThe resulting stability guarantee places no distributional assumptions on the\ndata, does not depend on the number of classes or dimensionality of the\ncovariates, and holds for any base classifier. Using a common benchmark data\nset, we demonstrate that the inflated argmax provides necessary protection\nagainst unstable classifiers, without loss of accuracy.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST",
            "stat.TH"
        ],
        "authors": [
            "Jake A. Soloff",
            "Rina Foygel Barber",
            "Rebecca Willett"
        ],
        "published": "2024-05-22T23:28:24Z"
    },
    {
        "title": "ChatScene: Knowledge-Enabled Safety-Critical Scenario Generation for\n  Autonomous Vehicles",
        "link": "http://arxiv.org/abs/2405.14062v1",
        "abstract": "We present ChatScene, a Large Language Model (LLM)-based agent that leverages\nthe capabilities of LLMs to generate safety-critical scenarios for autonomous\nvehicles. Given unstructured language instructions, the agent first generates\ntextually described traffic scenarios using LLMs. These scenario descriptions\nare subsequently broken down into several sub-descriptions for specified\ndetails such as behaviors and locations of vehicles. The agent then\ndistinctively transforms the textually described sub-scenarios into\ndomain-specific languages, which then generate actual code for prediction and\ncontrol in simulators, facilitating the creation of diverse and complex\nscenarios within the CARLA simulation environment. A key part of our agent is a\ncomprehensive knowledge retrieval component, which efficiently translates\nspecific textual descriptions into corresponding domain-specific code snippets\nby training a knowledge database containing the scenario description and code\npairs. Extensive experimental results underscore the efficacy of ChatScene in\nimproving the safety of autonomous vehicles. For instance, the scenarios\ngenerated by ChatScene show a 15% increase in collision rates compared to\nstate-of-the-art baselines when tested against different reinforcement\nlearning-based ego vehicles. Furthermore, we show that by using our generated\nsafety-critical scenarios to fine-tune different RL-based autonomous driving\nmodels, they can achieve a 9% reduction in collision rates, surpassing current\nSOTA methods. ChatScene effectively bridges the gap between textual\ndescriptions of traffic scenarios and practical CARLA simulations, providing a\nunified way to conveniently generate safety-critical scenarios for safety\ntesting and improvement for AVs.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Jiawei Zhang",
            "Chejian Xu",
            "Bo Li"
        ],
        "published": "2024-05-22T23:21:15Z"
    },
    {
        "title": "Meanings and Feelings of Large Language Models: Observability of Latent\n  States in Generative AI",
        "link": "http://arxiv.org/abs/2405.14061v1",
        "abstract": "We tackle the question of whether Large Language Models (LLMs), viewed as\ndynamical systems with state evolving in the embedding space of symbolic\ntokens, are observable. That is, whether there exist multiple 'mental' state\ntrajectories that yield the same sequence of generated tokens, or sequences\nthat belong to the same Nerode equivalence class ('meaning'). If not\nobservable, mental state trajectories ('experiences') evoked by an input\n('perception') or by feedback from the model's own state ('thoughts') could\nremain self-contained and evolve unbeknown to the user while being potentially\naccessible to the model provider. Such \"self-contained experiences evoked by\nperception or thought\" are akin to what the American Psychological Association\n(APA) defines as 'feelings'. Beyond the lexical curiosity, we show that current\nLLMs implemented by autoregressive Transformers cannot have 'feelings'\naccording to this definition: The set of state trajectories indistinguishable\nfrom the tokenized output is a singleton. But if there are 'system prompts' not\nvisible to the user, then the set of indistinguishable trajectories becomes\nnon-trivial, and there can be multiple state trajectories that yield the same\nverbalized output. We prove these claims analytically, and show examples of\nmodifications to standard LLMs that engender such 'feelings.' Our analysis\nsheds light on possible designs that would enable a model to perform\nnon-trivial computation that is not visible to the user, as well as on controls\nthat the provider of services using the model could take to prevent unintended\nbehavior.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Tian Yu Liu",
            "Stefano Soatto",
            "Matteo Marchi",
            "Pratik Chaudhari",
            "Paulo Tabuada"
        ],
        "published": "2024-05-22T23:18:58Z"
    },
    {
        "title": "Probabilistic Inference in the Era of Tensor Networks and Differential\n  Programming",
        "link": "http://arxiv.org/abs/2405.14060v1",
        "abstract": "Probabilistic inference is a fundamental task in modern machine learning.\nRecent advances in tensor network (TN) contraction algorithms have enabled the\ndevelopment of better exact inference methods. However, many common inference\ntasks in probabilistic graphical models (PGMs) still lack corresponding\nTN-based adaptations. In this work, we advance the connection between PGMs and\nTNs by formulating and implementing tensor-based solutions for the following\ninference tasks: (i) computing the partition function, (ii) computing the\nmarginal probability of sets of variables in the model, (iii) determining the\nmost likely assignment to a set of variables, and (iv) the same as (iii) but\nafter having marginalized a different set of variables. We also present a\ngeneralized method for generating samples from a learned probability\ndistribution. Our work is motivated by recent technical advances in the fields\nof quantum circuit simulation, quantum many-body physics, and statistical\nphysics. Through an experimental evaluation, we demonstrate that the\nintegration of these quantum technologies with a series of algorithms\nintroduced in this study significantly improves the effectiveness of existing\nmethods for solving probabilistic inference tasks.",
        "subjects": [
            "cs.LG",
            "physics.comp-ph"
        ],
        "authors": [
            "Martin Roa-Villescas",
            "Xuanzhao Gao",
            "Sander Stuijk",
            "Henk Corporaal",
            "Jin-Guo Liu"
        ],
        "published": "2024-05-22T23:09:57Z"
    },
    {
        "title": "Formally Verifying Deep Reinforcement Learning Controllers with Lyapunov\n  Barrier Certificates",
        "link": "http://arxiv.org/abs/2405.14058v1",
        "abstract": "Deep reinforcement learning (DRL) is a powerful machine learning paradigm for\ngenerating agents that control autonomous systems. However, the \"black box\"\nnature of DRL agents limits their deployment in real-world safety-critical\napplications. A promising approach for providing strong guarantees on an\nagent's behavior is to use Neural Lyapunov Barrier (NLB) certificates, which\nare learned functions over the system whose properties indirectly imply that an\nagent behaves as desired. However, NLB-based certificates are typically\ndifficult to learn and even more difficult to verify, especially for complex\nsystems. In this work, we present a novel method for training and verifying\nNLB-based certificates for discrete-time systems. Specifically, we introduce a\ntechnique for certificate composition, which simplifies the verification of\nhighly-complex systems by strategically designing a sequence of certificates.\nWhen jointly verified with neural network verification engines, these\ncertificates provide a formal guarantee that a DRL agent both achieves its\ngoals and avoids unsafe behavior. Furthermore, we introduce a technique for\ncertificate filtering, which significantly simplifies the process of producing\nformally verified certificates. We demonstrate the merits of our approach with\na case study on providing safety and liveness guarantees for a DRL-controlled\nspacecraft.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Udayan Mandal",
            "Guy Amir",
            "Haoze Wu",
            "Ieva Daukantas",
            "Fletcher Lee Newell",
            "Umberto J. Ravaioli",
            "Baoluo Meng",
            "Michael Durling",
            "Milan Ganai",
            "Tobey Shim",
            "Guy Katz",
            "Clark Barrett"
        ],
        "published": "2024-05-22T23:06:34Z"
    },
    {
        "title": "Your Large Language Models Are Leaving Fingerprints",
        "link": "http://arxiv.org/abs/2405.14057v1",
        "abstract": "It has been shown that finetuned transformers and other supervised detectors\neffectively distinguish between human and machine-generated text in some\nsituations arXiv:2305.13242, but we find that even simple classifiers on top of\nn-gram and part-of-speech features can achieve very robust performance on both\nin- and out-of-domain data. To understand how this is possible, we analyze\nmachine-generated output text in five datasets, finding that LLMs possess\nunique fingerprints that manifest as slight differences in the frequency of\ncertain lexical and morphosyntactic features. We show how to visualize such\nfingerprints, describe how they can be used to detect machine-generated text\nand find that they are even robust across textual domains. We find that\nfingerprints are often persistent across models in the same model family (e.g.\nllama-13b vs. llama-65b) and that models fine-tuned for chat are easier to\ndetect than standard language models, indicating that LLM fingerprints may be\ndirectly induced by the training data.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Hope McGovern",
            "Rickard Stureborg",
            "Yoshi Suhara",
            "Dimitris Alikaniotis"
        ],
        "published": "2024-05-22T23:02:42Z"
    },
    {
        "title": "How Many Bytes Can You Take Out Of Brain-To-Text Decoding?",
        "link": "http://arxiv.org/abs/2405.14055v1",
        "abstract": "Brain-computer interfaces have promising medical and scientific applications\nfor aiding speech and studying the brain. In this work, we propose an\ninformation-based evaluation metric for brain-to-text decoders. Using this\nmetric, we examine two methods to augment existing state-of-the-art continuous\ntext decoders. We show that these methods, in concert, can improve brain\ndecoding performance by upwards of 40% when compared to a baseline model. We\nfurther examine the informatic properties of brain-to-text decoders and show\nempirically that they have Zipfian power law dynamics. Finally, we provide an\nestimate for the idealized performance of an fMRI-based text decoder. We\ncompare this idealized model to our current model, and use our\ninformation-based metric to quantify the main sources of decoding error. We\nconclude that a practical brain-to-text decoder is likely possible given\nfurther algorithmic improvements.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.ET"
        ],
        "authors": [
            "Richard Antonello",
            "Nihita Sarma",
            "Jerry Tang",
            "Jiaru Song",
            "Alexander Huth"
        ],
        "published": "2024-05-22T22:57:04Z"
    },
    {
        "title": "On the Role of Non-Terrestrial Networks for Boosting Terrestrial Network\n  Performance in Dynamic Traffic Scenarios",
        "link": "http://arxiv.org/abs/2405.14053v1",
        "abstract": "Due to an ever-expansive network deployment, numerous questions are being\nraised regarding the energy consumption of the mobile network. Recently,\nNon-Terrestrial Networks (NTNs) have proven to be a useful, and complementary\nsolution to Terrestrial Networks (TN) to provide ubiquitous coverage. In this\npaper, we consider an integrated TN-NTN, and study how to maximize its resource\nusage in a dynamic traffic scenario. We introduce BLASTER, a framework designed\nto control User Equipment (UE) association, Base Station (BS) transmit power\nand activation, and bandwidth allocation between the terrestrial and\nnon-terrestrial tiers. Our proposal is able to adapt to fluctuating daily\ntraffic, focusing on reducing power consumption throughout the network during\nlow traffic and distributing the load otherwise. Simulation results show an\naverage daily decrease of total power consumption by 45% compared to a network\nmodel following 3GPP recommendation, as well as an average throughput increase\nof roughly 250%. Our paper underlines the central and dynamic role that the NTN\nplays in improving key areas of concern for network flexibility.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Henri Alam",
            "Antonio de Domenico",
            "Florian Kaltenberger",
            "David L√≥pez-P√©rez"
        ],
        "published": "2024-05-22T22:49:54Z"
    },
    {
        "title": "Reverse Engineering Structure and Semantics of Input of a Binary\n  Executable",
        "link": "http://arxiv.org/abs/2405.14052v1",
        "abstract": "Knowledge of the input format of binary executables is important for finding\nbugs and vulnerabilities, such as generating data for fuzzing or manual reverse\nengineering. This paper presents an algorithm to recover the structure and\nsemantic relations between fields of the input of binary executables using\ndynamic taint analysis. The algorithm improves upon prior work by not just\npartitioning the input into consecutive bytes representing values but also\nidentifying syntactic components of structures, such as atomic fields of fixed\nand variable lengths, and different types of arrays, such as arrays of atomic\nfields, arrays of records, and arrays with variant records. It also infers the\nsemantic relations between fields of a structure, such as count fields that\nspecify the count of an array of records or offset fields that specify the\nstart location of a variable-length field within the input data. The algorithm\nconstructs a C/C++-like structure to represent the syntactic components and\nsemantic relations.\n  The algorithm was implemented in a prototype system named ByteRI 2.0. The\nsystem was evaluated using a controlled experiment with synthetic subject\nprograms and real-world programs. The subject programs were created to accept a\nvariety of input formats that mimic syntactic components and selected semantic\nrelations found in conventional data formats, such as PE, PNG, ZIP, and CSV.\nThe results show that ByteRI 2.0 correctly identifies the syntactic elements\nand their grammatical structure, as well as the semantic relations between the\nfields for both synthetic subject programs and real-world programs. The\nrecovered structures, when used as a generator, produced valid data that was\nacceptable for all the synthetic subject programs and some of the real-world\nprograms.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Seshagiri Prabhu Narasimha",
            "Arun Lakhotia"
        ],
        "published": "2024-05-22T22:47:33Z"
    },
    {
        "title": "A Concentration Inequality for Maximum Mean Discrepancy (MMD)-based\n  Statistics and Its Application in Generative Models",
        "link": "http://arxiv.org/abs/2405.14051v1",
        "abstract": "Maximum Mean Discrepancy (MMD) is a probability metric that has found\nnumerous applications in machine learning. In this work, we focus on its\napplication in generative models, including the minimum MMD estimator,\nGenerative Moment Matching Network (GMMN), and Generative Adversarial Network\n(GAN). In these cases, MMD is part of an objective function in a minimization\nor min-max optimization problem. Even if its empirical performance is\ncompetitive, the consistency and convergence rate analysis of the corresponding\nMMD-based estimators has yet to be carried out.\n  We propose a uniform concentration inequality for a class of Maximum Mean\nDiscrepancy (MMD)-based estimators, that is, a maximum deviation bound of\nempirical MMD values over a collection of generated distributions and\nadversarially learned kernels. Here, our inequality serves as an efficient tool\nin the theoretical analysis for MMD-based generative models. As elaborating\nexamples, we applied our main result to provide the generalization error bounds\nfor the MMD-based estimators in the context of the minimum MMD estimator and\nMMD GAN.",
        "subjects": [
            "cs.LG",
            "math.ST",
            "stat.TH"
        ],
        "authors": [
            "Yijin Ni",
            "Xiaoming Huo"
        ],
        "published": "2024-05-22T22:41:56Z"
    },
    {
        "title": "Particle physics DL-simulation with control over generated data\n  properties",
        "link": "http://arxiv.org/abs/2405.14049v1",
        "abstract": "The research of innovative methods aimed at reducing costs and shortening the\ntime needed for simulation, going beyond conventional approaches based on Monte\nCarlo methods, has been sparked by the development of collision simulations at\nthe Large Hadron Collider at CERN. Deep learning generative methods including\nVAE, GANs and diffusion models have been used for this purpose. Although they\nare much faster and simpler than standard approaches, they do not always keep\nhigh fidelity of the simulated data. This work aims to mitigate this issue, by\nproviding an alternative solution to currently employed algorithms by\nintroducing the mechanism of control over the generated data properties. To\nachieve this, we extend the recently introduced CorrVAE, which enables\nuser-defined parameter manipulation of the generated output. We adapt the model\nto the problem of particle physics simulation. The proposed solution achieved\npromising results, demonstrating control over the parameters of the generated\noutput and constituting an alternative for simulating the ZDC calorimeter in\nthe ALICE experiment at CERN.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Karol Rogozi≈Ñski",
            "Jan Dubi≈Ñski",
            "Przemys≈Çaw Rokita",
            "Kamil Deja"
        ],
        "published": "2024-05-22T22:39:29Z"
    },
    {
        "title": "IOT Based Environment Monitoring System Using",
        "link": "http://arxiv.org/abs/2405.14047v1",
        "abstract": "In this project a modern approach and technology are adopted for monitoring\nthe environmental conditions in a particular location. This system is efficient\nin retrieving the environmental data from the device because the environmental\nconditions change spontaneously based on different atmospheric conditions.\nThere is a need for us to pay close attention to our environment as human\nbeings the weather has an effect on our physical and psychological health\nconditions. Even if we do not consider any reason to monitor our environment\nour health condition is enough to motivate us to be concerned about our\nenvironmental situation. So environmental monitoring system makes it easier for\nus to have access to this data at will by updating us about current\nenvironmental conditions and information from the weather station using apps or\nweb pages. IoT is known as a system that connects the world together and is the\nway to disseminate information so we build the system on IoT and use it as a\ncentral point for monitoring collating and managing our data. This project has\ndesigned an environmental system based on a microcontroller Board EPS32 and\nBlynk app. This is an IoT-based project that measures environmental data on\ntemperature and humidity.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Adesunmbo Adeboye Adeagbo"
        ],
        "published": "2024-05-22T22:34:54Z"
    },
    {
        "title": "Deep Reinforcement Learning Based Resource Allocation for MIMO Bistatic\n  Backscatter Networks",
        "link": "http://arxiv.org/abs/2405.14046v1",
        "abstract": "Bistatic backscatter communication promises ubiquitous, massive connectivity\nby utilizing passive tags to connect with a reader by reflecting carrier\nemitter (CE) signals for future Internet-of-Things (IoT) networks. This study\nfocuses on the joint design of the transmit/received beamformers at the\nCE/reader and the reflection coefficient of the tag. A throughput maximization\nproblem is thus formulated, subject to satisfying the tag requirements. We\ndevelop a joint design through a series of trial-and-error interactions within\nthe environment, driven by a predefined reward system in a continuous state and\naction context. We propose two deep reinforcement learning (DRL) algorithms to\naddress the underlying optimization problem, namely deep deterministic policy\ngradient (DDPG) and soft actor-critic (SAC). Simulation results indicate that\nthe proposed algorithm can learn from the environment and incrementally enhance\nits behavior, achieving performance that is on par with two leading benchmarks.\nFurther, we also compared the performance of the proposed method with deep\nQ-network (DQN), double deep Q-network (DDQN), and dueling DQN (DuelDQN). For a\nsystem with twelve antennas, SAC leads with a 26.76% gain over DQN, followed by\nalternative optimization (AO) and DDPG at 23.02% and 19.16%. DDQN and DuelDQN\nshow smaller improvements of 10.40% and 14.36%, respectively, against DQN.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "S. Zargari",
            "D. Galappaththige",
            "C. Tellambura"
        ],
        "published": "2024-05-22T22:32:12Z"
    },
    {
        "title": "Learning rigid-body simulators over implicit shapes for large-scale\n  scenes and vision",
        "link": "http://arxiv.org/abs/2405.14045v1",
        "abstract": "Simulating large scenes with many rigid objects is crucial for a variety of\napplications, such as robotics, engineering, film and video games. Rigid\ninteractions are notoriously hard to model: small changes to the initial state\nor the simulation parameters can lead to large changes in the final state.\nRecently, learned simulators based on graph networks (GNNs) were developed as\nan alternative to hand-designed simulators like MuJoCo and PyBullet. They are\nable to accurately capture dynamics of real objects directly from real-world\nobservations. However, current state-of-the-art learned simulators operate on\nmeshes and scale poorly to scenes with many objects or detailed shapes. Here we\npresent SDF-Sim, the first learned rigid-body simulator designed for scale. We\nuse learned signed-distance functions (SDFs) to represent the object shapes and\nto speed up distance computation. We design the simulator to leverage SDFs and\navoid the fundamental bottleneck of the previous simulators associated with\ncollision detection. For the first time in literature, we demonstrate that we\ncan scale the GNN-based simulators to scenes with hundreds of objects and up to\n1.1 million nodes, where mesh-based approaches run out of memory. Finally, we\nshow that SDF-Sim can be applied to real world scenes by extracting SDFs from\nmulti-view images.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Yulia Rubanova",
            "Tatiana Lopez-Guevara",
            "Kelsey R. Allen",
            "William F. Whitney",
            "Kimberly Stachenfeld",
            "Tobias Pfaff"
        ],
        "published": "2024-05-22T22:32:04Z"
    },
    {
        "title": "Attitudes Towards Migration in a COVID-19 Context: Testing a Behavioral\n  Immune System Hypothesis with Twitter Data",
        "link": "http://arxiv.org/abs/2405.14043v1",
        "abstract": "The COVID-19 outbreak implied many changes in the daily life of most of the\nworld's population for a long time, prompting severe restrictions on sociality.\nThe Behavioral Immune System (BIS) suggests that when facing pathogens, a\npsychological mechanism would be activated that, among other things, would\ngenerate an increase in prejudice and discrimination towards marginalized\ngroups, including immigrants. This study aimed to test if people tend to\nenhance their rejection of minorities and foreign groups under the threat of\ncontagious diseases, using the users' attitudes towards migrants in Twitter\ndata from Chile, for pre-pandemic and pandemic contexts. Our results only\npartially support the BIS hypothesis, since threatened users increased their\ntweet production in the pandemic period, compared to empathetic users, but the\nlatter grew in number and also increased the reach of their tweets between the\ntwo periods. We also found differences in the use of language between these\ntypes of users. Alternative explanations for these results may be\ncontext-dependent.",
        "subjects": [
            "cs.CY",
            "cs.SI"
        ],
        "authors": [
            "Yerka Freire-Vidal",
            "Gabriela Fajardo",
            "Carlos Rodr√≠guez-Sickert",
            "Eduardo Graells-Garrido",
            "Jos√© Antonio Mu√±oz-Reyes",
            "Oriana Figueroa"
        ],
        "published": "2024-05-22T22:30:46Z"
    },
    {
        "title": "Synchronized Video Storytelling: Generating Video Narrations with\n  Structured Storyline",
        "link": "http://arxiv.org/abs/2405.14040v1",
        "abstract": "Video storytelling is engaging multimedia content that utilizes video and its\naccompanying narration to attract the audience, where a key challenge is\ncreating narrations for recorded visual scenes. Previous studies on dense video\ncaptioning and video story generation have made some progress. However, in\npractical applications, we typically require synchronized narrations for\nongoing visual scenes. In this work, we introduce a new task of Synchronized\nVideo Storytelling, which aims to generate synchronous and informative\nnarrations for videos. These narrations, associated with each video clip,\nshould relate to the visual content, integrate relevant knowledge, and have an\nappropriate word count corresponding to the clip's duration. Specifically, a\nstructured storyline is beneficial to guide the generation process, ensuring\ncoherence and integrity. To support the exploration of this task, we introduce\na new benchmark dataset E-SyncVidStory with rich annotations. Since existing\nMultimodal LLMs are not effective in addressing this task in one-shot or\nfew-shot settings, we propose a framework named VideoNarrator that can generate\na storyline for input videos and simultaneously generate narrations with the\nguidance of the generated or predefined storyline. We further introduce a set\nof evaluation metrics to thoroughly assess the generation. Both automatic and\nhuman evaluations validate the effectiveness of our approach. Our dataset,\ncodes, and evaluations will be released.",
        "subjects": [
            "cs.MM"
        ],
        "authors": [
            "Dingyi Yang",
            "Chunru Zhan",
            "Ziheng Wang",
            "Biao Wang",
            "Tiezheng Ge",
            "Bo Zheng",
            "Qin Jin"
        ],
        "published": "2024-05-22T22:22:26Z"
    },
    {
        "title": "Trajectory Volatility for Out-of-Distribution Detection in Mathematical\n  Reasoning",
        "link": "http://arxiv.org/abs/2405.14039v1",
        "abstract": "Real-world data deviating from the independent and identically distributed\n(i.i.d.) assumption of in-distribution training data poses security threats to\ndeep networks, thus advancing out-of-distribution (OOD) detection algorithms.\nDetection methods in generative language models (GLMs) mainly focus on\nuncertainty estimation and embedding distance measurement, with the latter\nproven to be most effective in traditional linguistic tasks like summarization\nand translation. However, another complex generative scenario mathematical\nreasoning poses significant challenges to embedding-based methods due to its\nhigh-density feature of output spaces, but this feature causes larger\ndiscrepancies in the embedding shift trajectory between different samples in\nlatent spaces. Hence, we propose a trajectory-based method TV score, which uses\ntrajectory volatility for OOD detection in mathematical reasoning. Experiments\nshow that our method outperforms all traditional algorithms on GLMs under\nmathematical reasoning scenarios and can be extended to more applications with\nhigh-density features in output spaces, such as multiple-choice questions.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Yiming Wang",
            "Pei Zhang",
            "Baosong Yang",
            "Derek F. Wong",
            "Zhuosheng Zhang",
            "Rui Wang"
        ],
        "published": "2024-05-22T22:22:25Z"
    },
    {
        "title": "FLIPHAT: Joint Differential Privacy for High Dimensional Sparse Linear\n  Bandits",
        "link": "http://arxiv.org/abs/2405.14038v1",
        "abstract": "High dimensional sparse linear bandits serve as an efficient model for\nsequential decision-making problems (e.g. personalized medicine), where high\ndimensional features (e.g. genomic data) on the users are available, but only a\nsmall subset of them are relevant. Motivated by data privacy concerns in these\napplications, we study the joint differentially private high dimensional sparse\nlinear bandits, where both rewards and contexts are considered as private data.\nFirst, to quantify the cost of privacy, we derive a lower bound on the regret\nachievable in this setting. To further address the problem, we design a\ncomputationally efficient bandit algorithm, \\textbf{F}orgetfu\\textbf{L}\n\\textbf{I}terative \\textbf{P}rivate \\textbf{HA}rd \\textbf{T}hresholding\n(FLIPHAT). Along with doubling of episodes and episodic forgetting, FLIPHAT\ndeploys a variant of Noisy Iterative Hard Thresholding (N-IHT) algorithm as a\nsparse linear regression oracle to ensure both privacy and regret-optimality.\nWe show that FLIPHAT achieves optimal regret up to logarithmic factors. We\nanalyze the regret by providing a novel refined analysis of the estimation\nerror of N-IHT, which is of parallel interest.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST",
            "stat.TH"
        ],
        "authors": [
            "Sunrit Chakraborty",
            "Saptarshi Roy",
            "Debabrota Basu"
        ],
        "published": "2024-05-22T22:19:12Z"
    },
    {
        "title": "Remote Keylogging Attacks in Multi-user VR Applications",
        "link": "http://arxiv.org/abs/2405.14036v1",
        "abstract": "As Virtual Reality (VR) applications grow in popularity, they have bridged\ndistances and brought users closer together. However, with this growth, there\nhave been increasing concerns about security and privacy, especially related to\nthe motion data used to create immersive experiences. In this study, we\nhighlight a significant security threat in multi-user VR applications, which\nare applications that allow multiple users to interact with each other in the\nsame virtual space. Specifically, we propose a remote attack that utilizes the\navatar rendering information collected from an adversary's game clients to\nextract user-typed secrets like credit card information, passwords, or private\nconversations. We do this by (1) extracting motion data from network packets,\nand (2) mapping motion data to keystroke entries. We conducted a user study to\nverify the attack's effectiveness, in which our attack successfully inferred\n97.62% of the keystrokes. Besides, we performed an additional experiment to\nunderline that our attack is practical, confirming its effectiveness even when\n(1) there are multiple users in a room, and (2) the attacker cannot see the\nvictims. Moreover, we replicated our proposed attack on four applications to\ndemonstrate the generalizability of the attack. These results underscore the\nseverity of the vulnerability and its potential impact on millions of VR social\nplatform users.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Zihao Su",
            "Kunlin Cai",
            "Reuben Beeler",
            "Lukas Dresel",
            "Allan Garcia",
            "Ilya Grishchenko",
            "Yuan Tian",
            "Christopher Kruegel",
            "Giovanni Vigna"
        ],
        "published": "2024-05-22T22:10:40Z"
    },
    {
        "title": "Generative AI Search Engines as Arbiters of Public Knowledge: An Audit\n  of Bias and Authority",
        "link": "http://arxiv.org/abs/2405.14034v1",
        "abstract": "This paper reports on an audit study of generative AI systems (ChatGPT, Bing\nChat, and Perplexity) which investigates how these new search engines construct\nresponses and establish authority for topics of public importance. We collected\nsystem responses using a set of 48 authentic queries for 4 topics over a 7-day\nperiod and analyzed the data using sentiment analysis, inductive coding and\nsource classification. Results provide an overview of the nature of system\nresponses across these systems and provide evidence of sentiment bias based on\nthe queries and topics, and commercial and geographic bias in sources. The\nquality of sources used to support claims is uneven, relying heavily on News\nand Media, Business and Digital Media websites. Implications for system users\nemphasize the need to critically examine Generative AI system outputs when\nmaking decisions related to public interest and personal well-being.",
        "subjects": [
            "cs.IR",
            "cs.HC"
        ],
        "authors": [
            "Alice Li",
            "Luanne Sinnamon"
        ],
        "published": "2024-05-22T22:09:32Z"
    },
    {
        "title": "Adversarial Training of Two-Layer Polynomial and ReLU Activation\n  Networks via Convex Optimization",
        "link": "http://arxiv.org/abs/2405.14033v1",
        "abstract": "Training neural networks which are robust to adversarial attacks remains an\nimportant problem in deep learning, especially as heavily overparameterized\nmodels are adopted in safety-critical settings. Drawing from recent work which\nreformulates the training problems for two-layer ReLU and polynomial activation\nnetworks as convex programs, we devise a convex semidefinite program (SDP) for\nadversarial training of polynomial activation networks via the S-procedure. We\nalso derive a convex SDP to compute the minimum distance from a correctly\nclassified example to the decision boundary of a polynomial activation network.\nAdversarial training for two-layer ReLU activation networks has been explored\nin the literature, but, in contrast to prior work, we present a scalable\napproach which is compatible with standard machine libraries and GPU\nacceleration. The adversarial training SDP for polynomial activation networks\nleads to large increases in robust test accuracy against $\\ell^\\infty$ attacks\non the Breast Cancer Wisconsin dataset from the UCI Machine Learning\nRepository. For two-layer ReLU networks, we leverage our scalable\nimplementation to retrain the final two fully connected layers of a\nPre-Activation ResNet-18 model on the CIFAR-10 dataset. Our 'robustified' model\nachieves higher clean and robust test accuracies than the same architecture\ntrained with sharpness-aware minimization.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Daniel Kuelbs",
            "Sanjay Lall",
            "Mert Pilanci"
        ],
        "published": "2024-05-22T22:08:13Z"
    },
    {
        "title": "Energy-efficient predictive control for connected, automated driving\n  under localization uncertainty",
        "link": "http://arxiv.org/abs/2405.14031v1",
        "abstract": "This paper presents a data-driven Model Predictive Control (MPC) for\nenergy-efficient urban road driving for connected, automated vehicles. The\nproposed MPC aims to minimize total energy consumption by controlling the\nvehicle's longitudinal motion on roads with traffic lights and preceding\nvehicles. Its terminal cost function and terminal constraints are learned from\ndata, which consists of the closed-loop state and input trajectories. The\nterminal cost function represents the remaining energy-to-spend starting from a\ngiven terminal state. The terminal constraints are designed to ensure that the\ncontrolled vehicle timely crosses the upcoming traffic light, adheres to\ntraffic laws, and accounts for the preceding vehicles. We validate the\neffectiveness of our method through both simulations and real-world vehicle\nexperiments, demonstrating $\\textbf{19\\%}$ improvement in average energy\nconsumption compared to conventional approaches that involve solving a\nlong-horizon optimal control problem for speed planning and employing a\nseparate controller for speed tracking.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Eunhyek Joa",
            "Eric Yongkeun Choi",
            "Francesco Borrelli"
        ],
        "published": "2024-05-22T22:04:54Z"
    },
    {
        "title": "Refining Skewed Perceptions in Vision-Language Models through Visual\n  Representations",
        "link": "http://arxiv.org/abs/2405.14030v1",
        "abstract": "Large vision-language models (VLMs), such as CLIP, have become foundational,\ndemonstrating remarkable success across a variety of downstream tasks. Despite\ntheir advantages, these models, akin to other foundational systems, inherit\nbiases from the disproportionate distribution of real-world data, leading to\nmisconceptions about the actual environment. Prevalent datasets like ImageNet\nare often riddled with non-causal, spurious correlations that can diminish VLM\nperformance in scenarios where these contextual elements are absent. This study\npresents an investigation into how a simple linear probe can effectively\ndistill task-specific core features from CLIP's embedding for downstream\napplications. Our analysis reveals that the CLIP text representations are often\ntainted by spurious correlations, inherited in the biased pre-training dataset.\nEmpirical evidence suggests that relying on visual representations from CLIP,\nas opposed to text embedding, is more practical to refine the skewed\nperceptions in VLMs, emphasizing the superior utility of visual representations\nin overcoming embedded biases. Our codes will be available here.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "authors": [
            "Haocheng Dai",
            "Sarang Joshi"
        ],
        "published": "2024-05-22T22:03:11Z"
    },
    {
        "title": "Analog Beamforming Enabled Multicasting: Finite-Alphabet Inputs and\n  Statistical CSI",
        "link": "http://arxiv.org/abs/2405.14029v1",
        "abstract": "The average multicast rate (AMR) is analyzed in a multicast channel utilizing\nanalog beamforming with finite-alphabet inputs, considering statistical channel\nstate information (CSI). New expressions for the AMR are derived for\nnon-cooperative and cooperative multicasting scenarios. Asymptotic analyses are\nconducted in the high signal-to-noise ratio regime to derive the array gain and\ndiversity order. It is proved that the analog beamformer influences the AMR\nthrough its array gain, leading to the proposal of efficient beamforming\nalgorithms aimed at maximizing the array gain to enhance the AMR.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Yanjun Wu",
            "Zhong Xie",
            "Zhuochen Xie",
            "Chongjun Ouyang",
            "Xuwen Liang"
        ],
        "published": "2024-05-22T22:02:54Z"
    },
    {
        "title": "A Dynamic By-example BTF Synthesis Scheme",
        "link": "http://arxiv.org/abs/2405.14025v1",
        "abstract": "Measured Bidirectional Texture Function (BTF) can faithfully reproduce a\nrealistic appearance but is costly to acquire and store due to its 6D nature\n(2D spatial and 4D angular). Therefore, it is practical and necessary for\nrendering to synthesize BTFs from a small example patch. While previous methods\nmanaged to produce plausible results, we find that they seldomly take into\nconsideration the property of being dynamic, so a BTF must be synthesized\nbefore the rendering process, resulting in limited size, costly pre-generation\nand storage issues. In this paper, we propose a dynamic BTF synthesis scheme,\nwhere a BTF at any position only needs to be synthesized when being queried.\nOur insight is that, with the recent advances in neural dimension reduction\nmethods, a BTF can be decomposed into disjoint low-dimensional components. We\ncan perform dynamic synthesis only on the positional dimensions, and during\nrendering, recover the BTF by querying and combining these low-dimensional\nfunctions with the help of a lightweight Multilayer Perceptron (MLP).\nConsequently, we obtain a fully dynamic 6D BTF synthesis scheme that does not\nrequire any pre-generation, which enables efficient rendering of our infinitely\nlarge and non-repetitive BTFs on the fly. We demonstrate the effectiveness of\nour method through various types of BTFs taken from UBO2014.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Zilin Xu",
            "Zahra Montazeri",
            "Beibei Wang",
            "Ling-Qi Yan"
        ],
        "published": "2024-05-22T21:59:58Z"
    },
    {
        "title": "Two Heads are Better Than One: Neural Networks Quantization with 2D\n  Hilbert Curve-based Output Representation",
        "link": "http://arxiv.org/abs/2405.14024v1",
        "abstract": "Quantization is widely used to increase deep neural networks' (DNN) memory,\ncomputation, and power efficiency. Various techniques, such as post-training\nquantization and quantization-aware training, have been proposed to improve\nquantization quality. We introduce a novel approach for DNN quantization that\nuses a redundant representation of DNN's output. We represent the target\nquantity as a point on a 2D parametric curve. The DNN model is modified to\npredict 2D points that are mapped back to the target quantity at a\npost-processing stage. We demonstrate that this mapping can reduce quantization\nerror. For the low-order parametric Hilbert curve, Depth-From-Stereo task, and\ntwo models represented by U-Net architecture and vision transformer, we\nachieved a quantization error reduction by about 5 times for the INT8 model at\nboth CPU and DSP delegates. This gain comes with a minimal inference time\nincrease (less than 7%). Our approach can be applied to other tasks, including\nsegmentation, object detection, and key-points prediction.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Mykhailo Uss",
            "Ruslan Yermolenko",
            "Olena Kolodiazhna",
            "Oleksii Shashko",
            "Ivan Safonov",
            "Volodymyr Savin",
            "Yoonjae Yeo",
            "Seowon Ji",
            "Jaeyun Jeong"
        ],
        "published": "2024-05-22T21:59:46Z"
    },
    {
        "title": "WordGame: Efficient & Effective LLM Jailbreak via Simultaneous\n  Obfuscation in Query and Response",
        "link": "http://arxiv.org/abs/2405.14023v1",
        "abstract": "The recent breakthrough in large language models (LLMs) such as ChatGPT has\nrevolutionized production processes at an unprecedented pace. Alongside this\nprogress also comes mounting concerns about LLMs' susceptibility to\njailbreaking attacks, which leads to the generation of harmful or unsafe\ncontent. While safety alignment measures have been implemented in LLMs to\nmitigate existing jailbreak attempts and force them to become increasingly\ncomplicated, it is still far from perfect. In this paper, we analyze the common\npattern of the current safety alignment and show that it is possible to exploit\nsuch patterns for jailbreaking attacks by simultaneous obfuscation in queries\nand responses. Specifically, we propose WordGame attack, which replaces\nmalicious words with word games to break down the adversarial intent of a query\nand encourage benign content regarding the games to precede the anticipated\nharmful content in the response, creating a context that is hardly covered by\nany corpus used for safety alignment. Extensive experiments demonstrate that\nWordGame attack can break the guardrails of the current leading proprietary and\nopen-source LLMs, including the latest Claude-3, GPT-4, and Llama-3 models.\nFurther ablation studies on such simultaneous obfuscation in query and response\nprovide evidence of the merits of the attack strategy beyond an individual\nattack.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Tianrong Zhang",
            "Bochuan Cao",
            "Yuanpu Cao",
            "Lu Lin",
            "Prasenjit Mitra",
            "Jinghui Chen"
        ],
        "published": "2024-05-22T21:59:22Z"
    },
    {
        "title": "I2I-Mamba: Multi-modal medical image synthesis via selective state space\n  modeling",
        "link": "http://arxiv.org/abs/2405.14022v1",
        "abstract": "In recent years, deep learning models comprising transformer components have\npushed the performance envelope in medical image synthesis tasks. Contrary to\nconvolutional neural networks (CNNs) that use static, local filters,\ntransformers use self-attention mechanisms to permit adaptive, non-local\nfiltering to sensitively capture long-range context. However, this sensitivity\ncomes at the expense of substantial model complexity, which can compromise\nlearning efficacy particularly on relatively modest-sized imaging datasets.\nHere, we propose a novel adversarial model for multi-modal medical image\nsynthesis, I2I-Mamba, that leverages selective state space modeling (SSM) to\nefficiently capture long-range context while maintaining local precision. To do\nthis, I2I-Mamba injects channel-mixed Mamba (cmMamba) blocks in the bottleneck\nof a convolutional backbone. In cmMamba blocks, SSM layers are used to learn\ncontext across the spatial dimension and channel-mixing layers are used to\nlearn context across the channel dimension of feature maps. Comprehensive\ndemonstrations are reported for imputing missing images in multi-contrast MRI\nand MRI-CT protocols. Our results indicate that I2I-Mamba offers superior\nperformance against state-of-the-art CNN- and transformer-based methods in\nsynthesizing target-modality images.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Omer F. Atli",
            "Bilal Kabas",
            "Fuat Arslan",
            "Mahmut Yurt",
            "Onat Dalmaz",
            "Tolga √áukur"
        ],
        "published": "2024-05-22T21:55:58Z"
    },
    {
        "title": "A Study of Posterior Stability for Time-Series Latent Diffusion",
        "link": "http://arxiv.org/abs/2405.14021v1",
        "abstract": "Latent diffusion has shown promising results in image generation and permits\nefficient sampling. However, this framework might suffer from the problem of\nposterior collapse when applied to time series. In this paper, we conduct an\nimpact analysis of this problem. With a theoretical insight, we first explain\nthat posterior collapse reduces latent diffusion to a VAE, making it less\nexpressive. Then, we introduce the notion of dependency measures, showing that\nthe latent variable sampled from the diffusion model loses control of the\ngeneration process in this situation and that latent diffusion exhibits\ndependency illusion in the case of shuffled time series. We also analyze the\ncauses of posterior collapse and introduce a new framework based on this\nanalysis, which addresses the problem and supports a more expressive prior\ndistribution. Our experiments on various real-world time-series datasets\ndemonstrate that our new model maintains a stable posterior and outperforms the\nbaselines in time series generation.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yangming Li",
            "Mihaela van der Schaar"
        ],
        "published": "2024-05-22T21:54:12Z"
    },
    {
        "title": "Unlearning Information Bottleneck: Machine Unlearning of Systematic\n  Patterns and Biases",
        "link": "http://arxiv.org/abs/2405.14020v1",
        "abstract": "Effective adaptation to distribution shifts in training data is pivotal for\nsustaining robustness in neural networks, especially when removing specific\nbiases or outdated information, a process known as machine unlearning.\nTraditional approaches typically assume that data variations are random, which\nmakes it difficult to adjust the model parameters accurately to remove patterns\nand characteristics from unlearned data. In this work, we present Unlearning\nInformation Bottleneck (UIB), a novel information-theoretic framework designed\nto enhance the process of machine unlearning that effectively leverages the\ninfluence of systematic patterns and biases for parameter adjustment. By\nproposing a variational upper bound, we recalibrate the model parameters\nthrough a dynamic prior that integrates changes in data distribution with an\naffordable computational cost, allowing efficient and accurate removal of\noutdated or unwanted data patterns and biases. Our experiments across various\ndatasets, models, and unlearning methods demonstrate that our approach\neffectively removes systematic patterns and biases while maintaining the\nperformance of models post-unlearning.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Ling Han",
            "Hao Huang",
            "Dustin Scheinost",
            "Mary-Anne Hartley",
            "Mar√≠a Rodr√≠guez Mart√≠nez"
        ],
        "published": "2024-05-22T21:54:05Z"
    },
    {
        "title": "BrainMorph: A Foundational Keypoint Model for Robust and Flexible Brain\n  MRI Registration",
        "link": "http://arxiv.org/abs/2405.14019v1",
        "abstract": "We present a keypoint-based foundation model for general purpose brain MRI\nregistration, based on the recently-proposed KeyMorph framework. Our model,\ncalled BrainMorph, serves as a tool that supports multi-modal, pairwise, and\nscalable groupwise registration. BrainMorph is trained on a massive dataset of\nover 100,000 3D volumes, skull-stripped and non-skull-stripped, from nearly\n16,000 unique healthy and diseased subjects. BrainMorph is robust to large\nmisalignments, interpretable via interrogating automatically-extracted\nkeypoints, and enables rapid and controllable generation of many plausible\ntransformations with different alignment types and different degrees of\nnonlinearity at test-time. We demonstrate the superiority of BrainMorph in\nsolving 3D rigid, affine, and nonlinear registration on a variety of\nmulti-modal brain MRI scans of healthy and diseased subjects, in both the\npairwise and groupwise setting. In particular, we show registration accuracy\nand speeds that surpass current state-of-the-art methods, especially in the\ncontext of large initial misalignments and large group settings. All code and\nmodels are available at https://github.com/alanqrwang/brainmorph.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Alan Q. Wang",
            "Rachit Saluja",
            "Heejong Kim",
            "Xinzi He",
            "Adrian Dalca",
            "Mert R. Sabuncu"
        ],
        "published": "2024-05-22T21:52:30Z"
    },
    {
        "title": "Watermarking Generative Tabular Data",
        "link": "http://arxiv.org/abs/2405.14018v1",
        "abstract": "In this paper, we introduce a simple yet effective tabular data watermarking\nmechanism with statistical guarantees. We show theoretically that the proposed\nwatermark can be effectively detected, while faithfully preserving the data\nfidelity, and also demonstrates appealing robustness against additive noise\nattack. The general idea is to achieve the watermarking through a strategic\nembedding based on simple data binning. Specifically, it divides the feature's\nvalue range into finely segmented intervals and embeds watermarks into selected\n``green list\" intervals. To detect the watermarks, we develop a principled\nstatistical hypothesis-testing framework with minimal assumptions: it remains\nvalid as long as the underlying data distribution has a continuous density\nfunction. The watermarking efficacy is demonstrated through rigorous\ntheoretical analysis and empirical validation, highlighting its utility in\nenhancing the security of synthetic and real-world datasets.",
        "subjects": [
            "cs.CR",
            "stat.AP"
        ],
        "authors": [
            "Hengzhi He",
            "Peiyu Yu",
            "Junpeng Ren",
            "Ying Nian Wu",
            "Guang Cheng"
        ],
        "published": "2024-05-22T21:52:12Z"
    },
    {
        "title": "MagicPose4D: Crafting Articulated Models with Appearance and Motion\n  Control",
        "link": "http://arxiv.org/abs/2405.14017v1",
        "abstract": "With the success of 2D and 3D visual generative models, there is growing\ninterest in generating 4D content. Existing methods primarily rely on text\nprompts to produce 4D content, but they often fall short of accurately defining\ncomplex or rare motions. To address this limitation, we propose MagicPose4D, a\nnovel framework for refined control over both appearance and motion in 4D\ngeneration. Unlike traditional methods, MagicPose4D accepts monocular videos as\nmotion prompts, enabling precise and customizable motion generation.\nMagicPose4D comprises two key modules:\n  i) Dual-Phase 4D Reconstruction Module} which operates in two phases. The\nfirst phase focuses on capturing the model's shape using accurate 2D\nsupervision and less accurate but geometrically informative 3D\npseudo-supervision without imposing skeleton constraints. The second phase\nrefines the model using more accurate pseudo-3D supervision, obtained in the\nfirst phase and introduces kinematic chain-based skeleton constraints to ensure\nphysical plausibility. Additionally, we propose a Global-local Chamfer loss\nthat aligns the overall distribution of predicted mesh vertices with the\nsupervision while maintaining part-level alignment without extra annotations.\n  ii) Cross-category Motion Transfer Module} leverages the predictions from the\n4D reconstruction module and uses a kinematic-chain-based skeleton to achieve\ncross-category motion transfer. It ensures smooth transitions between frames\nthrough dynamic rigidity, facilitating robust generalization without additional\ntraining.\n  Through extensive experiments, we demonstrate that MagicPose4D significantly\nimproves the accuracy and consistency of 4D content generation, outperforming\nexisting methods in various benchmarks.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hao Zhang",
            "Di Chang",
            "Fang Li",
            "Mohammad Soleymani",
            "Narendra Ahuja"
        ],
        "published": "2024-05-22T21:51:01Z"
    },
    {
        "title": "Towards a Unified Framework for Evaluating Explanations",
        "link": "http://arxiv.org/abs/2405.14016v1",
        "abstract": "The challenge of creating interpretable models has been taken up by two main\nresearch communities: ML researchers primarily focused on lower-level\nexplainability methods that suit the needs of engineers, and HCI researchers\nwho have more heavily emphasized user-centered approaches often based on\nparticipatory design methods. This paper reviews how these communities have\nevaluated interpretability, identifying overlaps and semantic misalignments. We\npropose moving towards a unified framework of evaluation criteria and lay the\ngroundwork for such a framework by articulating the relationships between\nexisting criteria. We argue that explanations serve as mediators between models\nand stakeholders, whether for intrinsically interpretable models or opaque\nblack-box models analyzed via post-hoc techniques. We further argue that useful\nexplanations require both faithfulness and intelligibility. Explanation\nplausibility is a prerequisite for intelligibility, while stability is a\nprerequisite for explanation faithfulness. We illustrate these criteria, as\nwell as specific evaluation methods, using examples from an ongoing study of an\ninterpretable neural network for predicting a particular learner behavior.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Juan D. Pinto",
            "Luc Paquette"
        ],
        "published": "2024-05-22T21:49:28Z"
    },
    {
        "title": "RadarOcc: Robust 3D Occupancy Prediction with 4D Imaging Radar",
        "link": "http://arxiv.org/abs/2405.14014v1",
        "abstract": "3D occupancy-based perception pipeline has significantly advanced autonomous\ndriving by capturing detailed scene descriptions and demonstrating strong\ngeneralizability across various object categories and shapes. Current methods\npredominantly rely on LiDAR or camera inputs for 3D occupancy prediction. These\nmethods are susceptible to adverse weather conditions, limiting the all-weather\ndeployment of self-driving cars. To improve perception robustness, we leverage\nthe recent advances in automotive radars and introduce a novel approach that\nutilizes 4D imaging radar sensors for 3D occupancy prediction. Our method,\nRadarOcc, circumvents the limitations of sparse radar point clouds by directly\nprocessing the 4D radar tensor, thus preserving essential scene details.\nRadarOcc innovatively addresses the challenges associated with the voluminous\nand noisy 4D radar data by employing Doppler bins descriptors, sidelobe-aware\nspatial sparsification, and range-wise self-attention mechanisms. To minimize\nthe interpolation errors associated with direct coordinate transformations, we\nalso devise a spherical-based feature encoding followed by\nspherical-to-Cartesian feature aggregation. We benchmark various baseline\nmethods based on distinct modalities on the public K-Radar dataset. The results\ndemonstrate RadarOcc's state-of-the-art performance in radar-based 3D occupancy\nprediction and promising results even when compared with LiDAR- or camera-based\nmethods. Additionally, we present qualitative evidence of the superior\nperformance of 4D radar in adverse weather conditions and explore the impact of\nkey pipeline components through ablation studies.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ],
        "authors": [
            "Fangqiang Ding",
            "Xiangyu Wen",
            "Yunzhou Zhu",
            "Yiming Li",
            "Chris Xiaoxuan Lu"
        ],
        "published": "2024-05-22T21:48:17Z"
    },
    {
        "title": "Prompt-Time Ontology-Driven Symbolic Knowledge Capture with Large\n  Language Models",
        "link": "http://arxiv.org/abs/2405.14012v1",
        "abstract": "In applications such as personal assistants, large language models (LLMs)\nmust consider the user's personal information and preferences. However, LLMs\nlack the inherent ability to learn from user interactions. This paper explores\ncapturing personal information from user prompts using ontology and\nknowledge-graph approaches. We use a subset of the KNOW ontology, which models\npersonal information, to train the language model on these concepts. We then\nevaluate the success of knowledge capture using a specially constructed\ndataset. Our code and datasets are publicly available at\nhttps://github.com/HaltiaAI/paper-PTODSKC",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "I.2.7"
        ],
        "authors": [
            "Tolga √á√∂pl√º",
            "Arto Bendiken",
            "Andrii Skomorokhov",
            "Eduard Bateiko",
            "Stephen Cobb"
        ],
        "published": "2024-05-22T21:40:34Z"
    },
    {
        "title": "One-shot Training for Video Object Segmentation",
        "link": "http://arxiv.org/abs/2405.14010v1",
        "abstract": "Video Object Segmentation (VOS) aims to track objects across frames in a\nvideo and segment them based on the initial annotated frame of the target\nobjects. Previous VOS works typically rely on fully annotated videos for\ntraining. However, acquiring fully annotated training videos for VOS is\nlabor-intensive and time-consuming. Meanwhile, self-supervised VOS methods have\nattempted to build VOS systems through correspondence learning and label\npropagation. Still, the absence of mask priors harms their robustness to\ncomplex scenarios, and the label propagation paradigm makes them impractical in\nterms of efficiency. To address these issues, we propose, for the first time, a\ngeneral one-shot training framework for VOS, requiring only a single labeled\nframe per training video and applicable to a majority of state-of-the-art VOS\nnetworks. Specifically, our algorithm consists of: i) Inferring object masks\ntime-forward based on the initial labeled frame. ii) Reconstructing the initial\nobject mask time-backward using the masks from step i). Through this\nbi-directional training, a satisfactory VOS network can be obtained. Notably,\nour approach is extremely simple and can be employed end-to-end. Finally, our\napproach uses a single labeled frame of YouTube-VOS and DAVIS datasets to\nachieve comparable results to those trained on fully labeled datasets. The code\nwill be released.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Baiyu Chen",
            "Sixian Chan",
            "Xiaoqin Zhang"
        ],
        "published": "2024-05-22T21:37:08Z"
    },
    {
        "title": "SlipStream: Adapting Pipelines for Distributed Training of Large DNNs\n  Amid Failures",
        "link": "http://arxiv.org/abs/2405.14009v1",
        "abstract": "Training large Deep Neural Network (DNN) models requires thousands of GPUs\nfor days or weeks at a time. At these scales, failures are frequent and can\nhave a big impact on training throughput. Restoring performance using spare GPU\nservers becomes increasingly expensive as models grow. SlipStream is a system\nfor efficient DNN training in the presence of failures, without using spare\nservers. It exploits the functional redundancy inherent in distributed training\nsystems -- servers hold the same model parameters across data-parallel groups\n-- as well as the bubbles in the pipeline schedule within each data-parallel\ngroup. SlipStream dynamically re-routes the work of a failed server to its\ndata-parallel peers, ensuring continuous training despite multiple failures.\nHowever, re-routing work leads to imbalances across pipeline stages that\ndegrades training throughput. SlipStream introduces two optimizations that\nallow re-routed work to execute within bubbles of the original pipeline\nschedule. First, it decouples the backward pass computation into two phases.\nSecond, it staggers the execution of the optimizer step across pipeline stages.\nCombined, these optimizations enable schedules that minimize or even eliminate\ntraining throughput degradation during failures. We describe a prototype for\nSlipStream and show that it achieves high training throughput under multiple\nfailures, outperforming recent proposals for fault-tolerant training such as\nOobleck and Bamboo by up to 1.46x and 1.64x, respectively.",
        "subjects": [
            "cs.DC",
            "cs.LG"
        ],
        "authors": [
            "Swapnil Gandhi",
            "Mark Zhao",
            "Athinagoras Skiadopoulos",
            "Christos Kozyrakis"
        ],
        "published": "2024-05-22T21:35:56Z"
    },
    {
        "title": "Bayesian Inverse Problems with Conditional Sinkhorn Generative\n  Adversarial Networks in Least Volume Latent Spaces",
        "link": "http://arxiv.org/abs/2405.14008v1",
        "abstract": "Solving inverse problems in scientific and engineering fields has long been\nintriguing and holds great potential for many applications, yet most techniques\nstill struggle to address issues such as high dimensionality, nonlinearity and\nmodel uncertainty inherent in these problems. Recently, generative models such\nas Generative Adversarial Networks (GANs) have shown great potential in\napproximating complex high dimensional conditional distributions and have paved\nthe way for characterizing posterior densities in Bayesian inverse problems,\nyet the problems' high dimensionality and high nonlinearity often impedes the\nmodel's training. In this paper we show how to tackle these issues with Least\nVolume--a novel unsupervised nonlinear dimension reduction method--that can\nlearn to represent the given datasets with the minimum number of latent\nvariables while estimating their intrinsic dimensions. Once the low dimensional\nlatent spaces are identified, efficient and accurate training of conditional\ngenerative models becomes feasible, resulting in a latent conditional GAN\nframework for posterior inference. We demonstrate the power of the proposed\nmethodology on a variety of applications including inversion of parameters in\nsystems of ODEs and high dimensional hydraulic conductivities in subsurface\nflow problems, and reveal the impact of the observables' and unobservables'\nintrinsic dimensions on inverse problems.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Qiuyi Chen",
            "Panagiotis Tsilifis",
            "Mark Fuge"
        ],
        "published": "2024-05-22T21:34:26Z"
    },
    {
        "title": "A Practice in Enrollment Prediction with Markov Chain Models",
        "link": "http://arxiv.org/abs/2405.14007v1",
        "abstract": "Enrollment projection is a critical aspect of university management, guiding\ndecisions related to resource allocation and revenue forecasting. However,\ndespite its importance, there remains a lack of transparency regarding the\nmethodologies utilized by many institutions. This paper presents an innovative\napproach to enrollment projection using Markov Chain modeling, drawing upon a\ncase study conducted at Eastern Michigan University (EMU). Markov Chain\nmodeling emerges as a promising approach for enrollment projection, offering\nprecise predictions based on historical trends. This paper outlines the\nimplementation of Enhanced Markov Chain modeling at EMU, detailing the\nmethodology used to compute transition probabilities and evaluate model\nperformance. Despite challenges posed by external uncertainties such as the\nCOVID-19 pandemic, Markov Chain modeling has demonstrated impressive accuracy,\nwith an average difference of less than 1 percent between predicted and actual\nenrollments. The paper concludes with a discussion of future directions and\nopportunities for collaboration among institutions.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yan Zhao",
            "Amy Otteson"
        ],
        "published": "2024-05-22T21:25:37Z"
    },
    {
        "title": "Evaluating Large Language Models with Human Feedback: Establishing a\n  Swedish Benchmark",
        "link": "http://arxiv.org/abs/2405.14006v1",
        "abstract": "In the rapidly evolving field of artificial intelligence, large language\nmodels (LLMs) have demonstrated significant capabilities across numerous\napplications. However, the performance of these models in languages with fewer\nresources, such as Swedish, remains under-explored. This study introduces a\ncomprehensive human benchmark to assess the efficacy of prominent LLMs in\nunderstanding and generating Swedish language texts using forced choice\nranking. We employ a modified version of the ChatbotArena benchmark,\nincorporating human feedback to evaluate eleven different models, including\nGPT-4, GPT-3.5, various Claude and Llama models, and bespoke models like\nDolphin-2.9-llama3b-8b-flashback and BeagleCatMunin. These models were chosen\nbased on their performance on LMSYS chatbot arena and the Scandeval benchmarks.\nWe release the chatbotarena.se benchmark as a tool to improve our understanding\nof language model performance in Swedish with the hopes that it will be widely\nused. We aim to create a leaderboard once sufficient data has been collected\nand analysed.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Birger Moell"
        ],
        "published": "2024-05-22T21:22:51Z"
    },
    {
        "title": "Neural Scaling Laws for Embodied AI",
        "link": "http://arxiv.org/abs/2405.14005v1",
        "abstract": "Scaling laws have driven remarkable progress across machine learning domains\nlike language modeling and computer vision. However, the exploration of scaling\nlaws in embodied AI and robotics has been limited, despite the rapidly\nincreasing usage of machine learning in this field. This paper presents the\nfirst study to quantify scaling laws for Robot Foundation Models (RFMs) and the\nuse of LLMs in robotics tasks. Through a meta-analysis spanning 198 research\npapers, we analyze how key factors like compute, model size, and training data\nquantity impact model performance across various robotic tasks. Our findings\nconfirm that scaling laws apply to both RFMs and LLMs in robotics, with\nperformance consistently improving as resources increase. The power law\ncoefficients for RFMs closely match those of LLMs in robotics, resembling those\nfound in computer vision and outperforming those for LLMs in the language\ndomain. We also note that these coefficients vary with task complexity, with\nfamiliar tasks scaling more efficiently than unfamiliar ones, emphasizing the\nneed for large and diverse datasets. Furthermore, we highlight the absence of\nstandardized benchmarks in embodied AI. Most studies indicate diminishing\nreturns, suggesting that significant resources are necessary to achieve high\nperformance, posing challenges due to data and computational limitations.\nFinally, as models scale, we observe the emergence of new capabilities,\nparticularly related to data and model size.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Sebastian Sartor",
            "Neil Thompson"
        ],
        "published": "2024-05-22T21:22:44Z"
    },
    {
        "title": "Towards A Comprehensive Assessment of AI's Environmental Impact",
        "link": "http://arxiv.org/abs/2405.14004v1",
        "abstract": "Artificial Intelligence, machine learning (AI/ML) has allowed exploring\nsolutions for a variety of environmental and climate questions ranging from\nnatural disasters, greenhouse gas emission, monitoring biodiversity,\nagriculture, to weather and climate modeling, enabling progress towards climate\nchange mitigation. However, the intersection of AI/ML and environment is not\nalways positive. The recent surge of interest in ML, made possible by\nprocessing very large volumes of data, fueled by access to massive compute\npower, has sparked a trend towards large-scale adoption of AI/ML. This interest\nplaces tremendous pressure on natural resources, that are often overlooked and\nunder-reported. There is a need for a framework that monitors the environmental\nimpact and degradation from AI/ML throughout its lifecycle for informing\npolicymakers, stakeholders to adequately implement standards and policies and\ntrack the policy outcome over time. For these policies to be effective, AI's\nenvironmental impact needs to be monitored in a spatially-disaggregated, timely\nmanner across the globe at the key activity sites. This study proposes a\nmethodology to track environmental variables relating to the multifaceted\nimpact of AI around datacenters using openly available energy data and globally\nacquired satellite observations. We present a case study around Northern\nVirginia, United States that hosts a growing number of datacenters and observe\nchanges in multiple satellite-based environmental metrics. We then discuss the\nsteps to expand this methodology for comprehensive assessment of AI's\nenvironmental impact across the planet. We also identify data gaps and\nformulate recommendations for improving the understanding and monitoring\nAI-induced changes to the environment and climate.",
        "subjects": [
            "cs.CY"
        ],
        "authors": [
            "Srija Chakraborty"
        ],
        "published": "2024-05-22T21:19:35Z"
    },
    {
        "title": "Animal Behavior Analysis Methods Using Deep Learning: A Survey",
        "link": "http://arxiv.org/abs/2405.14002v1",
        "abstract": "Animal behavior serves as a reliable indicator of the adaptation of organisms\nto their environment and their overall well-being. Through rigorous observation\nof animal actions and interactions, researchers and observers can glean\nvaluable insights into diverse facets of their lives, encompassing health,\nsocial dynamics, ecological relationships, and neuroethological dimensions.\nAlthough state-of-the-art deep learning models have demonstrated remarkable\naccuracy in classifying various forms of animal data, their adoption in animal\nbehavior studies remains limited. This survey article endeavors to\ncomprehensively explore deep learning architectures and strategies applied to\nthe identification of animal behavior, spanning auditory, visual, and\naudiovisual methodologies. Furthermore, the manuscript scrutinizes extant\nanimal behavior datasets, offering a detailed examination of the principal\nchallenges confronting this research domain. The article culminates in a\ncomprehensive discussion of key research directions within deep learning that\nhold potential for advancing the field of animal behavior studies.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Edoardo Fazzari",
            "Donato Romano",
            "Fabrizio Falchi",
            "Cesare Stefanini"
        ],
        "published": "2024-05-22T21:17:54Z"
    },
    {
        "title": "Nondeterministic Causal Models",
        "link": "http://arxiv.org/abs/2405.14001v1",
        "abstract": "I generalize acyclic deterministic structural equation models to the\nnondeterministic case and argue that it offers an improved semantics for\ncounterfactuals. The standard, deterministic, semantics developed by Halpern\n(and based on the initial proposal of Galles & Pearl) assumes that for each\nassignment of values to parent variables there is a unique assignment to their\nchild variable, and it assumes that the actual world (an assignment of values\nto all variables of a model) specifies a unique counterfactual world for each\nintervention. Both assumptions are unrealistic, and therefore I drop both of\nthem in my proposal. I do so by allowing multi-valued functions in the\nstructural equations. In addition, I adjust the semantics so that the solutions\nto the equations that obtained in the actual world are preserved in any\ncounterfactual world. I motivate the resulting logic by comparing it to the\nstandard one by Halpern and to more recent proposals that are closer to mine.\nFinally, I extend these models to the probabilistic case and show that they\nopen up the way to identifying counterfactuals even in Causal Bayesian\nNetworks.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Sander Beckers"
        ],
        "published": "2024-05-22T21:17:52Z"
    },
    {
        "title": "Neural Fluidic System Design and Control with Differentiable Simulation",
        "link": "http://arxiv.org/abs/2405.14903v1",
        "abstract": "We present a novel framework to explore neural control and design of complex\nfluidic systems with dynamic solid boundaries. Our system features a fast\ndifferentiable Navier-Stokes solver with solid-fluid interface handling, a\nlow-dimensional differentiable parametric geometry representation, a\ncontrol-shape co-design algorithm, and gym-like simulation environments to\nfacilitate various fluidic control design applications. Additionally, we\npresent a benchmark of design, control, and learning tasks on high-fidelity,\nhigh-resolution dynamic fluid environments that pose challenges for existing\ndifferentiable fluid simulators. These tasks include designing the control of\nartificial hearts, identifying robotic end-effector shapes, and controlling a\nfluid gate. By seamlessly incorporating our differentiable fluid simulator into\na learning framework, we demonstrate successful design, control, and learning\nresults that surpass gradient-free solutions in these benchmark tasks.",
        "subjects": [
            "physics.flu-dyn",
            "cs.AI",
            "cs.GR"
        ],
        "authors": [
            "Yifei Li",
            "Yuchen Sun",
            "Pingchuan Ma",
            "Eftychios Sifakis",
            "Tao Du",
            "Bo Zhu",
            "Wojciech Matusik"
        ],
        "published": "2024-05-22T21:16:59Z"
    },
    {
        "title": "Computer-Vision-Enabled Worker Video Analysis for Motion Amount\n  Quantification",
        "link": "http://arxiv.org/abs/2405.13999v1",
        "abstract": "The performance of physical workers is significantly influenced by the\nquantity of their motions. However, monitoring and assessing these motions is\nchallenging due to the complexities of motion sensing, tracking, and\nquantification. Recent advancements have utilized in-situ video analysis for\nreal-time observation of worker behaviors, enabling data-driven quantification\nof motion amounts. Nevertheless, there are limitations to monitoring worker\nmovements using video data. This paper introduces a novel framework based on\ncomputer vision to track and quantify the motion of workers' upper and lower\nlimbs, issuing alerts when the motion reaches critical thresholds. Using joint\nposition data from posture estimation, the framework employs Hotelling's T$^2$\nstatistic to quantify and monitor motion amounts, integrating computer vision\ntools to address challenges in automated worker training and enhance\nexploratory research in this field. We collected data of participants\nperforming lifting and moving tasks with large boxes and small wooden cubes, to\nsimulate macro and micro assembly tasks respectively. It was found that the\ncorrelation between workers' joint motion amount and the Hotelling's T$^2$\nstatistic was approximately 35% greater for micro tasks compared to macro\ntasks, highlighting the framework's ability to identify fine-grained motion\ndifferences. This study demonstrates the effectiveness of the proposed system\nin real-time applications across various industry settings. It provides a tool\nfor enhancing worker safety and productivity through precision motion analysis\nand proactive ergonomic adjustments.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hari Iyer",
            "Neel Macwan",
            "Shenghan Guo",
            "Heejin Jeong"
        ],
        "published": "2024-05-22T21:15:03Z"
    },
    {
        "title": "Bridging Operator Learning and Conditioned Neural Fields: A Unifying\n  Perspective",
        "link": "http://arxiv.org/abs/2405.13998v1",
        "abstract": "Operator learning is an emerging area of machine learning which aims to learn\nmappings between infinite dimensional function spaces. Here we uncover a\nconnection between operator learning architectures and conditioned neural\nfields from computer vision, providing a unified perspective for examining\ndifferences between popular operator learning models. We find that many\ncommonly used operator learning models can be viewed as neural fields with\nconditioning mechanisms restricted to point-wise and/or global information.\nMotivated by this, we propose the Continuous Vision Transformer (CViT), a novel\nneural operator architecture that employs a vision transformer encoder and uses\ncross-attention to modulate a base field constructed with a trainable\ngrid-based positional encoding of query coordinates. Despite its simplicity,\nCViT achieves state-of-the-art results across challenging benchmarks in climate\nmodeling and fluid dynamics. Our contributions can be viewed as a first step\ntowards adapting advanced computer vision architectures for building more\nflexible and accurate machine learning models in physical sciences.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Sifan Wang",
            "Jacob H Seidman",
            "Shyam Sankaran",
            "Hanwen Wang",
            "George J. Pappas",
            "Paris Perdikaris"
        ],
        "published": "2024-05-22T21:13:23Z"
    },
    {
        "title": "Sigmoid Gating is More Sample Efficient than Softmax Gating in Mixture\n  of Experts",
        "link": "http://arxiv.org/abs/2405.13997v1",
        "abstract": "The softmax gating function is arguably the most popular choice in mixture of\nexperts modeling. Despite its widespread use in practice, softmax gating may\nlead to unnecessary competition among experts, potentially causing the\nundesirable phenomenon of representation collapse due to its inherent\nstructure. In response, the sigmoid gating function has been recently proposed\nas an alternative and has been demonstrated empirically to achieve superior\nperformance. However, a rigorous examination of the sigmoid gating function is\nlacking in current literature. In this paper, we verify theoretically that\nsigmoid gating, in fact, enjoys a higher sample efficiency than softmax gating\nfor the statistical task of expert estimation. Towards that goal, we consider a\nregression framework in which the unknown regression function is modeled as a\nmixture of experts, and study the rates of convergence of the least squares\nestimator in the over-specified case in which the number of experts fitted is\nlarger than the true value. We show that two gating regimes naturally arise\nand, in each of them, we formulate identifiability conditions for the expert\nfunctions and derive the corresponding convergence rates. In both cases, we\nfind that experts formulated as feed-forward networks with commonly used\nactivation such as $\\mathrm{ReLU}$ and $\\mathrm{GELU}$ enjoy faster convergence\nrates under sigmoid gating than softmax gating. Furthermore, given the same\nchoice of experts, we demonstrate that the sigmoid gating function requires a\nsmaller sample size than its softmax counterpart to attain the same error of\nexpert estimation and, therefore, is more sample efficient.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Huy Nguyen",
            "Nhat Ho",
            "Alessandro Rinaldo"
        ],
        "published": "2024-05-22T21:12:34Z"
    },
    {
        "title": "Detecting Gait Abnormalities in Foot-Floor Contacts During Walking\n  Through FootstepInduced Structural Vibrations",
        "link": "http://arxiv.org/abs/2405.13996v1",
        "abstract": "Gait abnormality detection is critical for the early discovery and\nprogressive tracking of musculoskeletal and neurological disorders, such as\nParkinson's and Cerebral Palsy. Especially, analyzing the foot-floor contacts\nduring walking provides important insights into gait patterns, such as contact\narea, contact force, and contact time, enabling gait abnormality detection\nthrough these measurements. Existing studies use various sensing devices to\ncapture such information, including cameras, wearables, and force plates.\nHowever, the former two lack force-related information, making it difficult to\nidentify the causes of gait health issues, while the latter has limited\ncoverage of the walking path. In this study, we leverage footstep-induced\nstructural vibrations to infer foot-floor contact profiles and detect gait\nabnormalities. The main challenge lies in modeling the complex force transfer\nmechanism between the foot and the floor surfaces, leading to difficulty in\nreconstructing the force and contact profile during foot-floor interaction\nusing structural vibrations. To overcome the challenge, we first characterize\nthe floor vibration for each contact type (e.g., heel, midfoot, and toe\ncontact) to understand how contact forces and areas affect the induced floor\nvibration. Then, we leverage the time-frequency response spectrum resulting\nfrom those contacts to develop features that are representative of each contact\ntype. Finally, gait abnormalities are detected by comparing the predicted\nfoot-floor contact force and motion with the healthy gait. To evaluate our\napproach, we conducted a real-world walking experiment with 8 subjects. Our\napproach achieves 91.6% and 96.7% accuracy in predicting contact type and time,\nrespectively, leading to 91.9% accuracy in detecting various types of gait\nabnormalities, including asymmetry, dragging, and midfoot/toe contacts.",
        "subjects": [
            "eess.SP",
            "cs.HC"
        ],
        "authors": [
            "Yiwen Dong",
            "Yuyan Wu",
            "Hae Young Noh"
        ],
        "published": "2024-05-22T21:11:43Z"
    },
    {
        "title": "Leveraging World Events to Predict E-Commerce Consumer Demand under\n  Anomaly",
        "link": "http://dx.doi.org/10.1145/3488560.3498452",
        "abstract": "Consumer demand forecasting is of high importance for many e-commerce\napplications, including supply chain optimization, advertisement placement, and\ndelivery speed optimization. However, reliable time series sales forecasting\nfor e-commerce is difficult, especially during periods with many anomalies, as\ncan often happen during pandemics, abnormal weather, or sports events. Although\nmany time series algorithms have been applied to the task, prediction during\nanomalies still remains a challenge. In this work, we hypothesize that\nleveraging external knowledge found in world events can help overcome the\nchallenge of prediction under anomalies. We mine a large repository of 40 years\nof world events and their textual representations. Further, we present a novel\nmethodology based on transformers to construct an embedding of a day based on\nthe relations of the day's events. Those embeddings are then used to forecast\nfuture consumer behavior. We empirically evaluate the methods over a large\ne-commerce products sales dataset, extracted from eBay, one of the world's\nlargest online marketplaces. We show over numerous categories that our method\noutperforms state-of-the-art baselines during anomalies.",
        "subjects": [
            "cs.LG",
            "I.2"
        ],
        "authors": [
            "Dan Kalifa",
            "Uriel Singer",
            "Ido Guy",
            "Guy D. Rosin",
            "Kira Radinsky"
        ],
        "published": "2024-05-22T21:05:35Z"
    },
    {
        "title": "Practical $0.385$-Approximation for Submodular Maximization Subject to a\n  Cardinality Constraint",
        "link": "http://arxiv.org/abs/2405.13994v1",
        "abstract": "Non-monotone constrained submodular maximization plays a crucial role in\nvarious machine learning applications. However, existing algorithms often\nstruggle with a trade-off between approximation guarantees and practical\nefficiency. The current state-of-the-art is a recent $0.401$-approximation\nalgorithm, but its computational complexity makes it highly impractical. The\nbest practical algorithms for the problem only guarantee $1/e$-approximation.\nIn this work, we present a novel algorithm for submodular maximization subject\nto a cardinality constraint that combines a guarantee of $0.385$-approximation\nwith a low and practical query complexity of $O(n+k^2)$. Furthermore, we\nevaluate the empirical performance of our algorithm in experiments based on\nvarious machine learning applications, including Movie Recommendation, Image\nSummarization, and more. These experiments demonstrate the efficacy of our\napproach.",
        "subjects": [
            "cs.LG",
            "cs.DM",
            "cs.DS"
        ],
        "authors": [
            "Murad Tukan",
            "Loay Mualem",
            "Moran Feldman"
        ],
        "published": "2024-05-22T20:56:57Z"
    },
    {
        "title": "AutoLCZ: Towards Automatized Local Climate Zone Mapping from Rule-Based\n  Remote Sensing",
        "link": "http://arxiv.org/abs/2405.13993v1",
        "abstract": "Local climate zones (LCZs) established a standard classification system to\ncategorize the landscape universe for improved urban climate studies. Existing\nLCZ mapping is guided by human interaction with geographic information systems\n(GIS) or modelled from remote sensing (RS) data. GIS-based methods do not scale\nto large areas. However, RS-based methods leverage machine learning techniques\nto automatize LCZ classification from RS. Yet, RS-based methods require huge\namounts of manual labels for training.\n  We propose a novel LCZ mapping framework, termed AutoLCZ, to extract the LCZ\nclassification features from high-resolution RS modalities. We study the\ndefinition of numerical rules designed to mimic the LCZ definitions. Those\nrules model geometric and surface cover properties from LiDAR data.\nCorrespondingly, we enable LCZ classification from RS data in a GIS-based\nscheme. The proposed AutoLCZ method has potential to reduce the human labor to\nacquire accurate metadata. At the same time, AutoLCZ sheds light on the\nphysical interpretability of RS-based methods. In a proof-of-concept for New\nYork City (NYC) we leverage airborne LiDAR surveys to model 4 LCZ features to\ndistinguish 10 LCZ types. The results indicate the potential of AutoLCZ as\npromising avenue for large-scale LCZ mapping from RS data.",
        "subjects": [
            "cs.CV",
            "cs.CE",
            "cs.IR",
            "cs.LG"
        ],
        "authors": [
            "Chenying Liu",
            "Hunsoo Song",
            "Anamika Shreevastava",
            "Conrad M Albrecht"
        ],
        "published": "2024-05-22T20:56:51Z"
    },
    {
        "title": "Learning Cut Generating Functions for Integer Programming",
        "link": "http://arxiv.org/abs/2405.13992v1",
        "abstract": "The branch-and-cut algorithm is the method of choice to solve large scale\ninteger programming problems in practice. A key ingredient of branch-and-cut is\nthe use of cutting planes which are derived constraints that reduce the search\nspace for an optimal solution. Selecting effective cutting planes to produce\nsmall branch-and-cut trees is a critical challenge in the branch-and-cut\nalgorithm. Recent advances have employed a data-driven approach to select\noptimal cutting planes from a parameterized family, aimed at reducing the\nbranch-and-bound tree size (in expectation) for a given distribution of integer\nprogramming instances. We extend this idea to the selection of the best cut\ngenerating function (CGF), which is a tool in the integer programming\nliterature for generating a wide variety of cutting planes that generalize the\nwell-known Gomory Mixed-Integer (GMI) cutting planes. We provide rigorous\nsample complexity bounds for the selection of an effective CGF from certain\nparameterized families that provably performs well for any specified\ndistribution on the problem instances. Our empirical results show that the\nselected CGF can outperform the GMI cuts for certain distributions.\nAdditionally, we explore the sample complexity of using neural networks for\ninstance-dependent CGF selection.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "authors": [
            "Hongyu Cheng",
            "Amitabh Basu"
        ],
        "published": "2024-05-22T20:56:34Z"
    },
    {
        "title": "TS40K: a 3D Point Cloud Dataset of Rural Terrain and Electrical\n  Transmission System",
        "link": "http://arxiv.org/abs/2405.13989v1",
        "abstract": "Research on supervised learning algorithms in 3D scene understanding has\nrisen in prominence and witness great increases in performance across several\ndatasets. The leading force of this research is the problem of autonomous\ndriving followed by indoor scene segmentation. However, openly available 3D\ndata on these tasks mainly focuses on urban scenarios. In this paper, we\npropose TS40K, a 3D point cloud dataset that encompasses more than 40,000 Km on\nelectrical transmission systems situated in European rural terrain. This is not\nonly a novel problem for the research community that can aid in the high-risk\nmission of power-grid inspection, but it also offers 3D point clouds with\ndistinct characteristics from those in self-driving and indoor 3D data, such as\nhigh point-density and no occlusion. In our dataset, each 3D point is labeled\nwith 1 out of 22 annotated classes. We evaluate the performance of\nstate-of-the-art methods on our dataset concerning 3D semantic segmentation and\n3D object detection. Finally, we provide a comprehensive analysis of the\nresults along with key challenges such as using labels that were not originally\nintended for learning tasks.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Diogo Lavado",
            "Cl√°udia Soares",
            "Alessandra Micheletti",
            "Ricardo Santos",
            "Andr√© Coelho",
            "Jo√£o Santos"
        ],
        "published": "2024-05-22T20:53:23Z"
    },
    {
        "title": "Analysis of Corrected Graph Convolutions",
        "link": "http://arxiv.org/abs/2405.13987v1",
        "abstract": "Machine learning for node classification on graphs is a prominent area driven\nby applications such as recommendation systems. State-of-the-art models often\nuse multiple graph convolutions on the data, as empirical evidence suggests\nthey can enhance performance. However, it has been shown empirically and\ntheoretically, that too many graph convolutions can degrade performance\nsignificantly, a phenomenon known as oversmoothing. In this paper, we provide a\nrigorous theoretical analysis, based on the contextual stochastic block model\n(CSBM), of the performance of vanilla graph convolution from which we remove\nthe principal eigenvector to avoid oversmoothing. We perform a spectral\nanalysis for $k$ rounds of corrected graph convolutions, and we provide results\nfor partial and exact classification. For partial classification, we show that\neach round of convolution can reduce the misclassification error exponentially\nup to a saturation level, after which performance does not worsen. For exact\nclassification, we show that the separability threshold can be improved\nexponentially up to $O({\\log{n}}/{\\log\\log{n}})$ corrected convolutions.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DM",
            "math.ST",
            "stat.ML",
            "stat.TH"
        ],
        "authors": [
            "Robert Wang",
            "Aseem Baranwal",
            "Kimon Fountoulakis"
        ],
        "published": "2024-05-22T20:50:17Z"
    },
    {
        "title": "High order finite-difference ghost-point methods for elliptic problems\n  in domains with curved boundaries",
        "link": "http://arxiv.org/abs/2405.13986v1",
        "abstract": "In this paper a fourth order finite difference ghost point method for the\nPoisson equation on regular Cartesian mesh is presented. The method can be\nconsidered the high order extension of the second ghost method introduced\nearlier by the authors. Three different discretizations are considered, which\ndiffer in the stencil that discretizes the Laplacian and the source term. It is\nshown that only two of them provide a stable method. The accuracy of such\nstable methods are numerically verified on several test problems.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "65N06",
            "G.1.8"
        ],
        "authors": [
            "Armando Coco",
            "Giovanni Russo"
        ],
        "published": "2024-05-22T20:48:00Z"
    },
    {
        "title": "LookHere: Vision Transformers with Directed Attention Generalize and\n  Extrapolate",
        "link": "http://arxiv.org/abs/2405.13985v1",
        "abstract": "High-resolution images offer more information about scenes that can improve\nmodel accuracy. However, the dominant model architecture in computer vision,\nthe vision transformer (ViT), cannot effectively leverage larger images without\nfinetuning -- ViTs poorly extrapolate to more patches at test time, although\ntransformers offer sequence length flexibility. We attribute this shortcoming\nto the current patch position encoding methods, which create a distribution\nshift when extrapolating.\n  We propose a drop-in replacement for the position encoding of plain ViTs that\nrestricts attention heads to fixed fields of view, pointed in different\ndirections, using 2D attention masks. Our novel method, called LookHere,\nprovides translation-equivariance, ensures attention head diversity, and limits\nthe distribution shift that attention heads face when extrapolating. We\ndemonstrate that LookHere improves performance on classification (avg. 1.6%),\nagainst adversarial attack (avg. 5.4%), and decreases calibration error (avg.\n1.5%) -- on ImageNet without extrapolation. With extrapolation, LookHere\noutperforms the current SoTA position encoding method, 2D-RoPE, by 21.7% on\nImageNet when trained at $224^2$ px and tested at $1024^2$ px. Additionally, we\nrelease a high-resolution test set to improve the evaluation of high-resolution\nimage classifiers, called ImageNet-HR.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Anthony Fuller",
            "Daniel G. Kyrollos",
            "Yousef Yassin",
            "James R. Green"
        ],
        "published": "2024-05-22T20:47:25Z"
    },
    {
        "title": "Feedback-aligned Mixed LLMs for Machine Language-Molecule Translation",
        "link": "http://arxiv.org/abs/2405.13984v1",
        "abstract": "The intersection of chemistry and Artificial Intelligence (AI) is an active\narea of research focused on accelerating scientific discovery. While using\nlarge language models (LLMs) with scientific modalities has shown potential,\nthere are significant challenges to address, such as improving training\nefficiency and dealing with the out-of-distribution problem. Focussing on the\ntask of automated language-molecule translation, we are the first to use\nstate-of-the art (SOTA) human-centric optimisation algorithms in the\ncross-modal setting, successfully aligning cross-language-molecule modals. We\nempirically show that we can augment the capabilities of scientific LLMs\nwithout the need for extensive data or large models. We conduct experiments\nusing only 10% of the available data to mitigate memorisation effects\nassociated with training large models on extensive datasets. We achieve\nsignificant performance gains, surpassing the best benchmark model trained on\nextensive in-distribution data by a large margin and reach new SOTA levels.\nAdditionally we are the first to propose employing non-linear fusion for mixing\ncross-modal LLMs which further boosts performance gains without increasing\ntraining costs or data needs. Finally, we introduce a fine-grained,\ndomain-agnostic evaluation method to assess hallucination in LLMs and promote\nresponsible use.",
        "subjects": [
            "cs.CL",
            "cs.MM"
        ],
        "authors": [
            "Dimitris Gkoumas",
            "Maria Liakata"
        ],
        "published": "2024-05-22T20:40:53Z"
    },
    {
        "title": "DirectMultiStep: Direct Route Generation for Multi-Step Retrosynthesis",
        "link": "http://arxiv.org/abs/2405.13983v1",
        "abstract": "Traditional computer-aided synthesis planning (CASP) methods rely on\niterative single-step predictions, leading to exponential search space growth\nthat limits efficiency and scalability. We introduce a transformer-based model\nthat directly generates multi-step synthetic routes as a single string by\nconditionally predicting each molecule based on all preceding ones. The model\naccommodates specific conditions such as the desired number of steps and\nstarting materials, outperforming state-of-the-art methods on the PaRoutes\ndataset with a 2.2x improvement in Top-1 accuracy on the n$_1$ test set and a\n3.3x improvement on the n$_5$ test set. It also successfully predicts routes\nfor FDA-approved drugs not included in the training data, showcasing its\ngeneralization capabilities. While the current suboptimal diversity of the\ntraining set may impact performance on less common reaction types, our approach\npresents a promising direction towards fully automated retrosynthetic planning.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Yu Shee",
            "Haote Li",
            "Anton Morgunov",
            "Victor Batista"
        ],
        "published": "2024-05-22T20:39:05Z"
    },
    {
        "title": "Rank Reduction Autoencoders -- Enhancing interpolation on nonlinear\n  manifolds",
        "link": "http://arxiv.org/abs/2405.13980v1",
        "abstract": "The efficiency of classical Autoencoders (AEs) is limited in many practical\nsituations. When the latent space is reduced through autoencoders, feature\nextraction becomes possible. However, overfitting is a common issue, leading to\n``holes'' in AEs' interpolation capabilities. On the other hand, increasing the\nlatent dimension results in a better approximation with fewer non-linearly\ncoupled features (e.g., Koopman theory or kPCA), but it doesn't necessarily\nlead to dimensionality reduction, which makes feature extraction problematic.\nAs a result, interpolating using Autoencoders gets harder. In this work, we\nintroduce the Rank Reduction Autoencoder (RRAE), an autoencoder with an\nenlarged latent space, which is constrained to have a small pre-specified\nnumber of dominant singular values (i.e., low-rank). The latent space of RRAEs\nis large enough to enable accurate predictions while enabling feature\nextraction. As a result, the proposed autoencoder features a minimal rank\nlinear latent space. To achieve what's proposed, two formulations are\npresented, a strong and a weak one, that build a reduced basis accurately\nrepresenting the latent space. The first formulation consists of a truncated\nSVD in the latent space, while the second one adds a penalty term to the loss\nfunction. We show the efficiency of our formulations by using them for\ninterpolation tasks and comparing the results to other autoencoders on both\nsynthetic data and MNIST.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Jad Mounayer",
            "Sebastian Rodriguez",
            "Chady Ghnatios",
            "Charbel Farhat",
            "Francisco Chinesta"
        ],
        "published": "2024-05-22T20:33:09Z"
    },
    {
        "title": "Optimizing Curvature Learning for Robust Hyperbolic Deep Learning in\n  Computer Vision",
        "link": "http://arxiv.org/abs/2405.13979v1",
        "abstract": "Hyperbolic deep learning has become a growing research direction in computer\nvision for the unique properties afforded by the alternate embedding space. The\nnegative curvature and exponentially growing distance metric provide a natural\nframework for capturing hierarchical relationships between datapoints and\nallowing for finer separability between their embeddings. However, these\nmethods are still computationally expensive and prone to instability,\nespecially when attempting to learn the negative curvature that best suits the\ntask and the data. Current Riemannian optimizers do not account for changes in\nthe manifold which greatly harms performance and forces lower learning rates to\nminimize projection errors. Our paper focuses on curvature learning by\nintroducing an improved schema for popular learning algorithms and providing a\nnovel normalization approach to constrain embeddings within the variable\nrepresentative radius of the manifold. Additionally, we introduce a novel\nformulation for Riemannian AdamW, and alternative hybrid encoder techniques and\nfoundational formulations for current convolutional hyperbolic operations,\ngreatly reducing the computational penalty of the hyperbolic embedding space.\nOur approach demonstrates consistent performance improvements across both\ndirect classification and hierarchical metric learning tasks while allowing for\nlarger hyperbolic models.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ahmad Bdeir",
            "Niels Landwehr"
        ],
        "published": "2024-05-22T20:30:14Z"
    },
    {
        "title": "Mitigating Interference in the Knowledge Continuum through\n  Attention-Guided Incremental Learning",
        "link": "http://arxiv.org/abs/2405.13978v1",
        "abstract": "Continual learning (CL) remains a significant challenge for deep neural\nnetworks, as it is prone to forgetting previously acquired knowledge. Several\napproaches have been proposed in the literature, such as experience rehearsal,\nregularization, and parameter isolation, to address this problem. Although\nalmost zero forgetting can be achieved in task-incremental learning,\nclass-incremental learning remains highly challenging due to the problem of\ninter-task class separation. Limited access to previous task data makes it\ndifficult to discriminate between classes of current and previous tasks. To\naddress this issue, we propose `Attention-Guided Incremental Learning' (AGILE),\na novel rehearsal-based CL approach that incorporates compact task attention to\neffectively reduce interference between tasks. AGILE utilizes lightweight,\nlearnable task projection vectors to transform the latent representations of a\nshared task attention module toward task distribution. Through extensive\nempirical evaluation, we show that AGILE significantly improves generalization\nperformance by mitigating task interference and outperforming rehearsal-based\napproaches in several CL scenarios. Furthermore, AGILE can scale well to a\nlarge number of tasks with minimal overhead while remaining well-calibrated\nwith reduced task-recency bias.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Prashant Bhat",
            "Bharath Renjith",
            "Elahe Arani",
            "Bahram Zonooz"
        ],
        "published": "2024-05-22T20:29:15Z"
    },
    {
        "title": "Removing Bias from Maximum Likelihood Estimation with Model Autophagy",
        "link": "http://arxiv.org/abs/2405.13977v1",
        "abstract": "We propose autophagy penalized likelihood estimation (PLE), an unbiased\nalternative to maximum likelihood estimation (MLE) which is more fair and less\nsusceptible to model autophagy disorder (madness). Model autophagy refers to\nmodels trained on their own output; PLE ensures the statistics of these outputs\ncoincide with the data statistics. This enables PLE to be statistically\nunbiased in certain scenarios where MLE is biased. When biased, MLE unfairly\npenalizes minority classes in unbalanced datasets and exacerbates the recently\ndiscovered issue of self-consuming generative modeling. Theoretical and\nempirical results show that 1) PLE is more fair to minority classes and 2) PLE\nis more stable in a self-consumed setting. Furthermore, we provide a scalable\nand portable implementation of PLE with a hypernetwork framework, allowing\nexisting deep learning architectures to be easily trained with PLE. Finally, we\nshow PLE can bridge the gap between Bayesian and frequentist paradigms in\nstatistics.",
        "subjects": [
            "cs.LG",
            "stat.ML",
            "68T07"
        ],
        "authors": [
            "Paul Mayer",
            "Lorenzo Luzi",
            "Ali Siahkoohi",
            "Don H. Johnson",
            "Richard G. Baraniuk"
        ],
        "published": "2024-05-22T20:24:41Z"
    },
    {
        "title": "EchoSpike Predictive Plasticity: An Online Local Learning Rule for\n  Spiking Neural Networks",
        "link": "http://arxiv.org/abs/2405.13976v1",
        "abstract": "The drive to develop artificial neural networks that efficiently utilize\nresources has generated significant interest in bio-inspired Spiking Neural\nNetworks (SNNs). These networks are particularly attractive due to their\npotential in applications requiring low power and memory. This potential is\nfurther enhanced by the ability to perform online local learning, enabling them\nto adapt to dynamic environments. This requires the model to be adaptive in a\nself-supervised manner. While self-supervised learning has seen great success\nin many deep learning domains, its application for online local learning in\nmulti-layer SNNs remains underexplored. In this paper, we introduce the\n\"EchoSpike Predictive Plasticity\" (ESPP) learning rule, a pioneering online\nlocal learning rule designed to leverage hierarchical temporal dynamics in SNNs\nthrough predictive and contrastive coding. We validate the effectiveness of\nthis approach using benchmark datasets, demonstrating that it performs on par\nwith current state-of-the-art supervised learning rules. The temporal and\nspatial locality of ESPP makes it particularly well-suited for low-cost\nneuromorphic processors, representing a significant advancement in developing\nbiologically plausible self-supervised learning models for neuromorphic\ncomputing at the edge.",
        "subjects": [
            "cs.NE",
            "cs.LG"
        ],
        "authors": [
            "Lars Graf",
            "Zhe Su",
            "Giacomo Indiveri"
        ],
        "published": "2024-05-22T20:20:43Z"
    },
    {
        "title": "There is HOPE to Avoid HiPPOs for Long-memory State Space Models",
        "link": "http://arxiv.org/abs/2405.13975v1",
        "abstract": "State-space models (SSMs) that utilize linear, time-invariant (LTI) systems\nare known for their effectiveness in learning long sequences. However, these\nmodels typically face several challenges: (i) they require specifically\ndesigned initializations of the system matrices to achieve state-of-the-art\nperformance, (ii) they require training of state matrices on a logarithmic\nscale with very small learning rates to prevent instabilities, and (iii) they\nrequire the model to have exponentially decaying memory in order to ensure an\nasymptotically stable LTI system. To address these issues, we view SSMs through\nthe lens of Hankel operator theory, which provides us with a unified theory for\nthe initialization and training of SSMs. Building on this theory, we develop a\nnew parameterization scheme, called HOPE, for LTI systems that utilizes Markov\nparameters within Hankel operators. This approach allows for random\ninitializations of the LTI systems and helps to improve training stability,\nwhile also provides the SSMs with non-decaying memory capabilities. Our model\nefficiently implements these innovations by nonuniformly sampling the transfer\nfunctions of LTI systems, and it requires fewer parameters compared to\ncanonical SSMs. When benchmarked against HiPPO-initialized models such as S4\nand S4D, an SSM parameterized by Hankel operators demonstrates improved\nperformance on Long-Range Arena (LRA) tasks. Moreover, we use a sequential\nCIFAR-10 task with padded noise to empirically corroborate our SSM's long\nmemory capacity.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Annan Yu",
            "Michael W. Mahoney",
            "N. Benjamin Erichson"
        ],
        "published": "2024-05-22T20:20:14Z"
    },
    {
        "title": "CIVICS: Building a Dataset for Examining Culturally-Informed Values in\n  Large Language Models",
        "link": "http://arxiv.org/abs/2405.13974v1",
        "abstract": "This paper introduces the \"CIVICS: Culturally-Informed & Values-Inclusive\nCorpus for Societal impacts\" dataset, designed to evaluate the social and\ncultural variation of Large Language Models (LLMs) across multiple languages\nand value-sensitive topics. We create a hand-crafted, multilingual dataset of\nvalue-laden prompts which address specific socially sensitive topics, including\nLGBTQI rights, social welfare, immigration, disability rights, and surrogacy.\nCIVICS is designed to generate responses showing LLMs' encoded and implicit\nvalues. Through our dynamic annotation processes, tailored prompt design, and\nexperiments, we investigate how open-weight LLMs respond to value-sensitive\nissues, exploring their behavior across diverse linguistic and cultural\ncontexts. Using two experimental set-ups based on log-probabilities and\nlong-form responses, we show social and cultural variability across different\nLLMs. Specifically, experiments involving long-form responses demonstrate that\nrefusals are triggered disparately across models, but consistently and more\nfrequently in English or translated statements. Moreover, specific topics and\nsources lead to more pronounced differences across model answers, particularly\non immigration, LGBTQI rights, and social welfare. As shown by our experiments,\nthe CIVICS dataset aims to serve as a tool for future research, promoting\nreproducibility and transparency across broader linguistic settings, and\nfurthering the development of AI technologies that respect and reflect global\ncultural diversities and value pluralism. The CIVICS dataset and tools will be\nmade available upon publication under open licenses; an anonymized version is\ncurrently available at https://huggingface.co/CIVICS-dataset.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Giada Pistilli",
            "Alina Leidinger",
            "Yacine Jernite",
            "Atoosa Kasirzadeh",
            "Alexandra Sasha Luccioni",
            "Margaret Mitchell"
        ],
        "published": "2024-05-22T20:19:10Z"
    },
    {
        "title": "Infinite-Dimensional Feature Interaction",
        "link": "http://arxiv.org/abs/2405.13972v2",
        "abstract": "The past neural network design has largely focused on feature representation\nspace dimension and its capacity scaling (e.g., width, depth), but overlooked\nthe feature interaction space scaling.\n  Recent advancements have shown shifted focus towards element-wise\nmultiplication to facilitate higher-dimensional feature interaction space for\nbetter information transformation. Despite this progress, multiplications\npredominantly capture low-order interactions, thus remaining confined to a\nfinite-dimensional interaction space. To transcend this limitation, classic\nkernel methods emerge as a promising solution to engage features in an\ninfinite-dimensional space. We introduce InfiNet, a model architecture that\nenables feature interaction within an infinite-dimensional space created by RBF\nkernel. Our experiments reveal that InfiNet achieves new state-of-the-art,\nowing to its capability to leverage infinite-dimensional interactions,\nsignificantly enhancing model performance.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Chenhui Xu",
            "Fuxun Yu",
            "Maoliang Li",
            "Zihao Zheng",
            "Zirui Xu",
            "Jinjun Xiong",
            "Xiang Chen"
        ],
        "published": "2024-05-22T20:17:22Z"
    },
    {
        "title": "Uncertainty-Aware DRL for Autonomous Vehicle Crowd Navigation in Shared\n  Space",
        "link": "http://arxiv.org/abs/2405.13969v1",
        "abstract": "Safe, socially compliant, and efficient navigation of low-speed autonomous\nvehicles (AVs) in pedestrian-rich environments necessitates considering\npedestrians' future positions and interactions with the vehicle and others.\nDespite the inevitable uncertainties associated with pedestrians' predicted\ntrajectories due to their unobserved states (e.g., intent), existing deep\nreinforcement learning (DRL) algorithms for crowd navigation often neglect\nthese uncertainties when using predicted trajectories to guide policy learning.\nThis omission limits the usability of predictions when diverging from ground\ntruth. This work introduces an integrated prediction and planning approach that\nincorporates the uncertainties of predicted pedestrian states in the training\nof a model-free DRL algorithm. A novel reward function encourages the AV to\nrespect pedestrians' personal space, decrease speed during close approaches,\nand minimize the collision probability with their predicted paths. Unlike\nprevious DRL methods, our model, designed for AV operation in crowded spaces,\nis trained in a novel simulation environment that reflects realistic pedestrian\nbehaviour in a shared space with vehicles. Results show a 40% decrease in\ncollision rate and a 15% increase in minimum distance to pedestrians compared\nto the state of the art model that does not account for prediction uncertainty.\nAdditionally, the approach outperforms model predictive control methods that\nincorporate the same prediction uncertainties in terms of both performance and\ncomputational time, while producing trajectories closer to human drivers in\nsimilar scenarios.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Mahsa Golchoubian",
            "Moojan Ghafurian",
            "Kerstin Dautenhahn",
            "Nasser Lashgarian Azad"
        ],
        "published": "2024-05-22T20:09:21Z"
    },
    {
        "title": "TaleMate: Exploring the use of Voice Agents for Parent-Child Joint\n  Reading Experiences",
        "link": "http://arxiv.org/abs/2405.13968v1",
        "abstract": "Joint reading is a key activity for early learners, with caregiver-child\ninteractions such as questioning and feedback playing an essential role in\nchildren's cognitive and linguistic development. However, for some parents,\nactively engaging children in storytelling can be challenging. To address this,\nwe introduce TaleMate a platform designed to enhance shared reading by\nleveraging conversational agents that have been shown to support children's\nengagement and learning. TaleMate enables a dynamic, participatory reading\nexperience where parents and children can choose which characters they wish to\nembody. Moreover, the system navigates the challenges posed by digital reading\ntools, such as decreased parent-child interaction, and builds upon the benefits\nof traditional and digital reading techniques. TaleMate offers an innovative\napproach to fostering early reading habits, bridging the gap between\ntraditional joint reading practices and the digital reading landscape.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Daniel Vargas-Diaz",
            "Jisun Kim",
            "Sulakna Karunaratna",
            "Maegan Reinhardt",
            "Caroline Hornburg",
            "Koeun Choi",
            "Sang Won Lee"
        ],
        "published": "2024-05-22T20:09:03Z"
    },
    {
        "title": "DeTox: Toxic Subspace Projection for Model Editing",
        "link": "http://arxiv.org/abs/2405.13967v1",
        "abstract": "Recent alignment algorithms such as direct preference optimization (DPO) have\nbeen developed to improve the safety of large language models (LLMs) by\ntraining these models to match human behaviors exemplified by preference data.\nHowever, these methods are both computationally intensive and lacking in\ncontrollability and transparency, making them prone to jailbreaking and\ninhibiting their widespread use. Furthermore, these tuning-based methods\nrequire large-scale preference data for training and are susceptible to noisy\npreference data. In this paper, we introduce a tuning-free alignment\nalternative (DeTox) and demonstrate its effectiveness under the use case of\ntoxicity reduction. Grounded on theory from factor analysis, DeTox is a\nsample-efficient model editing approach that identifies a toxic subspace in the\nmodel parameter space and reduces model toxicity by projecting away the\ndetected subspace. The toxic sub-space is identified by extracting preference\ndata embeddings from the language model, and removing non-toxic information\nfrom these embeddings. We show that DeTox is more sample-efficient than DPO,\nfurther showcasing greater robustness to noisy data. Finally, we establish both\ntheoretical and empirical connections between DeTox and DPO, showing that DeTox\ncan be interpreted as a denoised version of a single DPO step.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Rheeya Uppaal",
            "Apratim De",
            "Yiting He",
            "Yiquao Zhong",
            "Junjie Hu"
        ],
        "published": "2024-05-22T20:08:48Z"
    },
    {
        "title": "On the Brittle Foundations of ReAct Prompting for Agentic Large Language\n  Models",
        "link": "http://arxiv.org/abs/2405.13966v1",
        "abstract": "The reasoning abilities of Large Language Models (LLMs) remain a topic of\ndebate. Some methods such as ReAct-based prompting, have gained popularity for\nclaiming to enhance sequential decision-making abilities of agentic LLMs.\nHowever, it is unclear what is the source of improvement in LLM reasoning with\nReAct based prompting. In this paper we examine these claims of ReAct based\nprompting in improving agentic LLMs for sequential decision-making. By\nintroducing systematic variations to the input prompt we perform a sensitivity\nanalysis along the claims of ReAct and find that the performance is minimally\ninfluenced by the \"interleaving reasoning trace with action execution\" or the\ncontent of the generated reasoning traces in ReAct, contrary to original claims\nand common usage. Instead, the performance of LLMs is driven by the similarity\nbetween input example tasks and queries, implicitly forcing the prompt designer\nto provide instance-specific examples which significantly increases the\ncognitive burden on the human. Our investigation shows that the perceived\nreasoning abilities of LLMs stem from the exemplar-query similarity and\napproximate retrieval rather than any inherent reasoning abilities.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Mudit Verma",
            "Siddhant Bhambri",
            "Subbarao Kambhampati"
        ],
        "published": "2024-05-22T20:05:49Z"
    },
    {
        "title": "Unleashing the Power of Unlabeled Data: A Self-supervised Learning\n  Framework for Cyber Attack Detection in Smart Grids",
        "link": "http://arxiv.org/abs/2405.13965v1",
        "abstract": "Modern power grids are undergoing significant changes driven by information\nand communication technologies (ICTs), and evolving into smart grids with\nhigher efficiency and lower operation cost. Using ICTs, however, comes with an\ninevitable side effect that makes the power system more vulnerable to cyber\nattacks. In this paper, we propose a self-supervised learning-based framework\nto detect and identify various types of cyber attacks. Different from existing\napproaches, the proposed framework does not rely on large amounts of\nwell-curated labeled data but makes use of the massive unlabeled data in the\nwild which are easily accessible. Specifically, the proposed framework adopts\nthe BERT model from the natural language processing domain and learns\ngeneralizable and effective representations from the unlabeled sensing data,\nwhich capture the distinctive patterns of different attacks. Using the learned\nrepresentations, together with a very small amount of labeled data, we can\ntrain a task-specific classifier to detect various types of cyber attacks.\nMeanwhile, real-world training datasets are usually imbalanced, i.e., there are\nonly a limited number of data samples containing attacks. In order to cope with\nsuch data imbalance, we propose a new loss function, separate mean error (SME),\nwhich pays equal attention to the large and small categories to better train\nthe model. Experiment results in a 5-area power grid system with 37 buses\ndemonstrate the superior performance of our framework over existing approaches,\nespecially when a very limited portion of labeled data are available, e.g., as\nlow as 0.002\\%. We believe such a framework can be easily adopted to detect a\nvariety of cyber attacks in other power grid scenarios.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Hanyu Zeng",
            "Pengfei Zhou",
            "Xin Lou",
            "Zhen Wei Ng",
            "David K. Y. Yau",
            "Marianne Winslett"
        ],
        "published": "2024-05-22T20:04:52Z"
    },
    {
        "title": "Design Editing for Offline Model-based Optimization",
        "link": "http://arxiv.org/abs/2405.13964v1",
        "abstract": "Offline model-based optimization (MBO) aims to maximize a black-box objective\nfunction using only an offline dataset of designs and scores. A prevalent\napproach involves training a conditional generative model on existing designs\nand their associated scores, followed by the generation of new designs\nconditioned on higher target scores. However, these newly generated designs\noften underperform due to the lack of high-scoring training data. To address\nthis challenge, we introduce a novel method, Design Editing for Offline\nModel-based Optimization (DEMO), which consists of two phases. In the first\nphase, termed pseudo-target distribution generation, we apply gradient ascent\non the offline dataset using a trained surrogate model, producing a synthetic\ndataset where the predicted scores serve as new labels. A conditional diffusion\nmodel is subsequently trained on this synthetic dataset to capture a\npseudo-target distribution, which enhances the accuracy of the conditional\ndiffusion model in generating higher-scoring designs. Nevertheless, the\npseudo-target distribution is susceptible to noise stemming from inaccuracies\nin the surrogate model, consequently predisposing the conditional diffusion\nmodel to generate suboptimal designs. We hence propose the second phase,\nexisting design editing, to directly incorporate the high-scoring features from\nthe offline dataset into design generation. In this phase, top designs from the\noffline dataset are edited by introducing noise, which are subsequently refined\nusing the conditional diffusion model to produce high-scoring designs. Overall,\nhigh-scoring designs begin with inheriting high-scoring features from the\nsecond phase and are further refined with a more accurate conditional diffusion\nmodel in the first phase. Empirical evaluations on 7 offline MBO tasks show\nthat DEMO outperforms various baseline methods.",
        "subjects": [
            "cs.LG",
            "cs.CE"
        ],
        "authors": [
            "Ye Yuan",
            "Youyuan Zhang",
            "Can Chen",
            "Haolun Wu",
            "Zixuan Li",
            "Jianmo Li",
            "James J. Clark",
            "Xue Liu"
        ],
        "published": "2024-05-22T20:00:19Z"
    },
    {
        "title": "Learning heavy-tailed distributions with\n  Wasserstein-proximal-regularized $Œ±$-divergences",
        "link": "http://arxiv.org/abs/2405.13962v1",
        "abstract": "In this paper, we propose Wasserstein proximals of $\\alpha$-divergences as\nsuitable objective functionals for learning heavy-tailed distributions in a\nstable manner. First, we provide sufficient, and in some cases necessary,\nrelations among data dimension, $\\alpha$, and the decay rate of data\ndistributions for the Wasserstein-proximal-regularized divergence to be finite.\nFinite-sample convergence rates for the estimation in the case of the\nWasserstein-1 proximal divergences are then provided under certain tail\nconditions. Numerical experiments demonstrate stable learning of heavy-tailed\ndistributions -- even those without first or second moment -- without any\nexplicit knowledge of the tail behavior, using suitable generative models such\nas GANs and flow-based models related to our proposed\nWasserstein-proximal-regularized $\\alpha$-divergences. Heuristically,\n$\\alpha$-divergences handle the heavy tails and Wasserstein proximals allow\nnon-absolute continuity between distributions and control the velocities of\nflow-based algorithms as they learn the target distribution deep into the\ntails.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Ziyu Chen",
            "Hyemin Gu",
            "Markos A. Katsoulakis",
            "Luc Rey-Bellet",
            "Wei Zhu"
        ],
        "published": "2024-05-22T19:58:13Z"
    },
    {
        "title": "SADDLe: Sharpness-Aware Decentralized Deep Learning with Heterogeneous\n  Data",
        "link": "http://arxiv.org/abs/2405.13961v1",
        "abstract": "Decentralized training enables learning with distributed datasets generated\nat different locations without relying on a central server. In realistic\nscenarios, the data distribution across these sparsely connected learning\nagents can be significantly heterogeneous, leading to local model over-fitting\nand poor global model generalization. Another challenge is the high\ncommunication cost of training models in such a peer-to-peer fashion without\nany central coordination. In this paper, we jointly tackle these two-fold\npractical challenges by proposing SADDLe, a set of sharpness-aware\ndecentralized deep learning algorithms. SADDLe leverages Sharpness-Aware\nMinimization (SAM) to seek a flatter loss landscape during training, resulting\nin better model generalization as well as enhanced robustness to communication\ncompression. We present two versions of our approach and conduct extensive\nexperiments to show that SADDLe leads to 1-20% improvement in test accuracy\ncompared to other existing techniques. Additionally, our proposed approach is\nrobust to communication compression, with an average drop of only 1% in the\npresence of up to 4x compression.",
        "subjects": [
            "cs.LG",
            "cs.DC",
            "cs.MA"
        ],
        "authors": [
            "Sakshi Choudhary",
            "Sai Aparna Aketi",
            "Kaushik Roy"
        ],
        "published": "2024-05-22T19:57:11Z"
    },
    {
        "title": "Learning To Play Atari Games Using Dueling Q-Learning and Hebbian\n  Plasticity",
        "link": "http://arxiv.org/abs/2405.13960v1",
        "abstract": "In this work, an advanced deep reinforcement learning architecture is used to\ntrain neural network agents playing atari games. Given only the raw game\npixels, action space, and reward information, the system can train agents to\nplay any Atari game. At first, this system uses advanced techniques like deep\nQ-networks and dueling Q-networks to train efficient agents, the same\ntechniques used by DeepMind to train agents that beat human players in Atari\ngames. As an extension, plastic neural networks are used as agents, and their\nfeasibility is analyzed in this scenario. The plasticity implementation was\nbased on backpropagation and the Hebbian update rule. Plastic neural networks\nhave excellent features like lifelong learning after the initial training,\nwhich makes them highly suitable in adaptive learning environments. As a new\nanalysis of plasticity in this context, this work might provide valuable\ninsights and direction for future works.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Md Ashfaq Salehin"
        ],
        "published": "2024-05-22T19:55:33Z"
    },
    {
        "title": "Fair Evaluation of Federated Learning Algorithms for Automated Breast\n  Density Classification: The Results of the 2022 ACR-NCI-NVIDIA Federated\n  Learning Challenge",
        "link": "http://dx.doi.org/10.1016/j.media.2024.103206.",
        "abstract": "The correct interpretation of breast density is important in the assessment\nof breast cancer risk. AI has been shown capable of accurately predicting\nbreast density, however, due to the differences in imaging characteristics\nacross mammography systems, models built using data from one system do not\ngeneralize well to other systems. Though federated learning (FL) has emerged as\na way to improve the generalizability of AI without the need to share data, the\nbest way to preserve features from all training data during FL is an active\narea of research. To explore FL methodology, the breast density classification\nFL challenge was hosted in partnership with the American College of Radiology,\nHarvard Medical School's Mass General Brigham, University of Colorado, NVIDIA,\nand the National Institutes of Health National Cancer Institute. Challenge\nparticipants were able to submit docker containers capable of implementing FL\non three simulated medical facilities, each containing a unique large\nmammography dataset. The breast density FL challenge ran from June 15 to\nSeptember 5, 2022, attracting seven finalists from around the world. The\nwinning FL submission reached a linear kappa score of 0.653 on the challenge\ntest data and 0.413 on an external testing dataset, scoring comparably to a\nmodel trained on the same data in a central location.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Kendall Schmidt",
            "Benjamin Bearce",
            "Ken Chang",
            "Laura Coombs",
            "Keyvan Farahani",
            "Marawan Elbatele",
            "Kaouther Mouhebe",
            "Robert Marti",
            "Ruipeng Zhang",
            "Yao Zhang",
            "Yanfeng Wang",
            "Yaojun Hu",
            "Haochao Ying",
            "Yuyang Xu",
            "Conrad Testagrose",
            "Mutlu Demirer",
            "Vikash Gupta",
            "√únal Ak√ºnal",
            "Markus Bujotzek",
            "Klaus H. Maier-Hein",
            "Yi Qin",
            "Xiaomeng Li",
            "Jayashree Kalpathy-Cramer",
            "Holger R. Roth"
        ],
        "published": "2024-05-22T19:54:09Z"
    },
    {
        "title": "Exploring the Relationship Between Feature Attribution Methods and Model\n  Performance",
        "link": "http://arxiv.org/abs/2405.13957v1",
        "abstract": "Machine learning and deep learning models are pivotal in educational\ncontexts, particularly in predicting student success. Despite their widespread\napplication, a significant gap persists in comprehending the factors\ninfluencing these models' predictions, especially in explainability within\neducation. This work addresses this gap by employing nine distinct explanation\nmethods and conducting a comprehensive analysis to explore the correlation\nbetween the agreement among these methods in generating explanations and the\npredictive model's performance. Applying Spearman's correlation, our findings\nreveal a very strong correlation between the model's performance and the\nagreement level observed among the explanation methods.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Priscylla Silva",
            "Claudio T. Silva",
            "Luis Gustavo Nonato"
        ],
        "published": "2024-05-22T19:46:45Z"
    },
    {
        "title": "Attention as an RNN",
        "link": "http://arxiv.org/abs/2405.13956v1",
        "abstract": "The advent of Transformers marked a significant breakthrough in sequence\nmodelling, providing a highly performant architecture capable of leveraging GPU\nparallelism. However, Transformers are computationally expensive at inference\ntime, limiting their applications, particularly in low-resource settings (e.g.,\nmobile and embedded devices). Addressing this, we (1) begin by showing that\nattention can be viewed as a special Recurrent Neural Network (RNN) with the\nability to compute its \\textit{many-to-one} RNN output efficiently. We then (2)\nshow that popular attention-based models such as Transformers can be viewed as\nRNN variants. However, unlike traditional RNNs (e.g., LSTMs), these models\ncannot be updated efficiently with new tokens, an important property in\nsequence modelling. Tackling this, we (3) introduce a new efficient method of\ncomputing attention's \\textit{many-to-many} RNN output based on the parallel\nprefix scan algorithm. Building on the new attention formulation, we (4)\nintroduce \\textbf{Aaren}, an attention-based module that can not only (i) be\ntrained in parallel (like Transformers) but also (ii) be updated efficiently\nwith new tokens, requiring only constant memory for inferences (like\ntraditional RNNs). Empirically, we show Aarens achieve comparable performance\nto Transformers on $38$ datasets spread across four popular sequential problem\nsettings: reinforcement learning, event forecasting, time series\nclassification, and time series forecasting tasks while being more time and\nmemory-efficient.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Leo Feng",
            "Frederick Tung",
            "Hossein Hajimirsadeghi",
            "Mohamed Osama Ahmed",
            "Yoshua Bengio",
            "Greg Mori"
        ],
        "published": "2024-05-22T19:45:01Z"
    },
    {
        "title": "Cognitive Internet of Vulnerable Road Users in Traffic: Predictive\n  Neural Modulations of Road Crossing Intention",
        "link": "http://arxiv.org/abs/2405.13955v1",
        "abstract": "Vulnerable Road Users (VRUs) present a significant challenge for road safety\ndue to the frequent unpredictability of their behaviors. In typical Intelligent\nTransportation Systems, vision-based approaches supported by networked cameras\nare often used to anticipate VRUs motion intentions and trajectories. However,\nseveral limitations posed by occlusions and distractions set a boundary for the\nefficacy of such methods. To address these challenges, this study introduces a\nframework that leverages data collected using wearable neurophysiological\nsensors on VRUs to integrate them seamlessly into the Vehicle-to-Everything\ncommunication framework. This integration empowers VRUs to autonomously\nbroadcast their intended movements to other road agents, especially autonomous\nvehicles, thereby bridging a critical gap in current vehicular communication\nsystems. To validate this concept, we conducted an experiment involving 12\nparticipants, from whom EEG signals were collected as they engaged in\nroad-crossing decisions within simulated environments. Employing Hidden Markov\nModels, we identified four cognitive stages intrinsic to a pedestrian's\ndecision-making process. Our statistical analysis further revealed significant\nvariations in EEG activities across these stages, shedding light on the neural\ncorrelates and cognitive dynamics underpinning pedestrian road-crossing\nbehavior. We then developed a predictive cognitive model using dynamic time\nwarping and K-nearest neighbors algorithms, optimized through a data-driven\nsliding window approach. This model demonstrated high predictive accuracy,\nevidenced by an Area Under the Curve of 0.91, indicating its capability to\nanticipate pedestrian road-crossing actions approximately 1 second in advance\nof any pedestrian movement. This research paves the way for a novel VRU-Vehicle\ninteraction paradigm and signifies a shift towards a forward-thinking\necosystem.",
        "subjects": [
            "cs.HC",
            "cs.ET"
        ],
        "authors": [
            "Xiaoshan Zhou",
            "Carol C. Menassa",
            "Vineet R. Kamat"
        ],
        "published": "2024-05-22T19:40:37Z"
    },
    {
        "title": "What is Your Data Worth to GPT? LLM-Scale Data Valuation with Influence\n  Functions",
        "link": "http://arxiv.org/abs/2405.13954v1",
        "abstract": "Large language models (LLMs) are trained on a vast amount of human-written\ndata, but data providers often remain uncredited. In response to this issue,\ndata valuation (or data attribution), which quantifies the contribution or\nvalue of each data to the model output, has been discussed as a potential\nsolution. Nevertheless, applying existing data valuation methods to recent LLMs\nand their vast training datasets has been largely limited by prohibitive\ncompute and memory costs. In this work, we focus on influence functions, a\npopular gradient-based data valuation method, and significantly improve its\nscalability with an efficient gradient projection strategy called LoGra that\nleverages the gradient structure in backpropagation. We then provide a\ntheoretical motivation of gradient projection approaches to influence functions\nto promote trust in the data valuation process. Lastly, we lower the barrier to\nimplementing data valuation systems by introducing LogIX, a software package\nthat can transform existing training code into data valuation code with minimal\neffort. In our data valuation experiments, LoGra achieves competitive accuracy\nagainst more expensive baselines while showing up to 6,500x improvement in\nthroughput and 5x reduction in GPU memory usage when applied to\nLlama3-8B-Instruct and the 1B-token dataset.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Sang Keun Choe",
            "Hwijeen Ahn",
            "Juhan Bae",
            "Kewen Zhao",
            "Minsoo Kang",
            "Youngseog Chung",
            "Adithya Pratapa",
            "Willie Neiswanger",
            "Emma Strubell",
            "Teruko Mitamura",
            "Jeff Schneider",
            "Eduard Hovy",
            "Roger Grosse",
            "Eric Xing"
        ],
        "published": "2024-05-22T19:39:05Z"
    },
    {
        "title": "Spectral Adapter: Fine-Tuning in Spectral Space",
        "link": "http://arxiv.org/abs/2405.13952v1",
        "abstract": "Recent developments in Parameter-Efficient Fine-Tuning (PEFT) methods for\npretrained deep neural networks have captured widespread interest. In this\nwork, we study the enhancement of current PEFT methods by incorporating the\nspectral information of pretrained weight matrices into the fine-tuning\nprocedure. We investigate two spectral adaptation mechanisms, namely additive\ntuning and orthogonal rotation of the top singular vectors, both are done via\nfirst carrying out Singular Value Decomposition (SVD) of pretrained weights and\nthen fine-tuning the top spectral space. We provide a theoretical analysis of\nspectral fine-tuning and show that our approach improves the rank capacity of\nlow-rank adapters given a fixed trainable parameter budget. We show through\nextensive experiments that the proposed fine-tuning model enables better\nparameter efficiency and tuning performance as well as benefits multi-adapter\nfusion. The code will be open-sourced for reproducibility.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Fangzhao Zhang",
            "Mert Pilanci"
        ],
        "published": "2024-05-22T19:36:55Z"
    },
    {
        "title": "Text Prompting for Multi-Concept Video Customization by Autoregressive\n  Generation",
        "link": "http://arxiv.org/abs/2405.13951v1",
        "abstract": "We present a method for multi-concept customization of pretrained\ntext-to-video (T2V) models. Intuitively, the multi-concept customized video can\nbe derived from the (non-linear) intersection of the video manifolds of the\nindividual concepts, which is not straightforward to find. We hypothesize that\nsequential and controlled walking towards the intersection of the video\nmanifolds, directed by text prompting, leads to the solution. To do so, we\ngenerate the various concepts and their corresponding interactions,\nsequentially, in an autoregressive manner. Our method can generate videos of\nmultiple custom concepts (subjects, action and background) such as a teddy bear\nrunning towards a brown teapot, a dog playing violin and a teddy bear swimming\nin the ocean. We quantitatively evaluate our method using videoCLIP and DINO\nscores, in addition to human evaluation. Videos for results presented in this\npaper can be found at https://github.com/divyakraman/MultiConceptVideo2024.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Divya Kothandaraman",
            "Kihyuk Sohn",
            "Ruben Villegas",
            "Paul Voigtlaender",
            "Dinesh Manocha",
            "Mohammad Babaeizadeh"
        ],
        "published": "2024-05-22T19:35:00Z"
    },
    {
        "title": "Actor-critic algorithms for fiber sampling problems",
        "link": "http://arxiv.org/abs/2405.13950v1",
        "abstract": "We propose an actor-critic algorithm for a family of complex problems arising\nin algebraic statistics and discrete optimization. The core task is to produce\na sample from a finite subset of the non-negative integer lattice defined by a\nhigh-dimensional polytope. We translate the problem into a Markov decision\nprocess and devise an actor-critic reinforcement learning (RL) algorithm to\nlearn a set of good moves that can be used for sampling. We prove that the\nactor-critic algorithm converges to an approximately optimal sampling policy.\n  To tackle complexity issues that typically arise in these sampling problems,\nand to allow the RL to function at scale, our solution strategy takes three\nsteps: decomposing the starting point of the sample, using RL on each induced\nsubproblem, and reconstructing to obtain a sample in the original polytope. In\nthis setup, the proof of convergence applies to each subproblem in the\ndecomposition.\n  We test the method in two regimes. In statistical applications, a\nhigh-dimensional polytope arises as the support set for the reference\ndistribution in a model/data fit test for a broad family of statistical models\nfor categorical data. We demonstrate how RL can be used for model fit testing\nproblems for data sets for which traditional MCMC samplers converge too slowly\ndue to problem size and sparsity structure. To test the robustness of the\nalgorithm and explore its generalization properties, we apply it to\nsynthetically generated data of various sizes and sparsity levels.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "62R01"
        ],
        "authors": [
            "Ivan Gvozdanoviƒá",
            "Sonja Petroviƒá"
        ],
        "published": "2024-05-22T19:33:58Z"
    },
    {
        "title": "PitVQA: Image-grounded Text Embedding LLM for Visual Question Answering\n  in Pituitary Surgery",
        "link": "http://arxiv.org/abs/2405.13949v1",
        "abstract": "Visual Question Answering (VQA) within the surgical domain, utilizing Large\nLanguage Models (LLMs), offers a distinct opportunity to improve\nintra-operative decision-making and facilitate intuitive surgeon-AI\ninteraction. However, the development of LLMs for surgical VQA is hindered by\nthe scarcity of diverse and extensive datasets with complex reasoning tasks.\nMoreover, contextual fusion of the image and text modalities remains an open\nresearch challenge due to the inherent differences between these two types of\ninformation and the complexity involved in aligning them. This paper introduces\nPitVQA, a novel dataset specifically designed for VQA in endonasal pituitary\nsurgery and PitVQA-Net, an adaptation of the GPT2 with a novel image-grounded\ntext embedding for surgical VQA. PitVQA comprises 25 procedural videos and a\nrich collection of question-answer pairs spanning crucial surgical aspects such\nas phase and step recognition, context understanding, tool detection and\nlocalization, and tool-tissue interactions. PitVQA-Net consists of a novel\nimage-grounded text embedding that projects image and text features into a\nshared embedding space and GPT2 Backbone with an excitation block\nclassification head to generate contextually relevant answers within the\ncomplex domain of endonasal pituitary surgery. Our image-grounded text\nembedding leverages joint embedding, cross-attention and contextual\nrepresentation to understand the contextual relationship between questions and\nsurgical images. We demonstrate the effectiveness of PitVQA-Net on both the\nPitVQA and the publicly available EndoVis18-VQA dataset, achieving improvements\nin balanced accuracy of 8% and 9% over the most recent baselines, respectively.\nOur code and dataset is available at https://github.com/mobarakol/PitVQA.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Runlong He",
            "Mengya Xu",
            "Adrito Das",
            "Danyal Z. Khan",
            "Sophia Bano",
            "Hani J. Marcus",
            "Danail Stoyanov",
            "Matthew J. Clarkson",
            "Mobarakol Islam"
        ],
        "published": "2024-05-22T19:30:24Z"
    },
    {
        "title": "Embodied Design for Enhanced Flipper-Based Locomotion in Complex\n  Terrains",
        "link": "http://arxiv.org/abs/2405.13948v1",
        "abstract": "Robots are becoming increasingly essential for traversing complex\nenvironments such as disaster areas, extraterrestrial terrains, and marine\nenvironments. Yet, their potential is often limited by mobility and\nadaptability constraints. In nature, various animals have evolved finely tuned\ndesigns and anatomical features that enable efficient locomotion in diverse\nenvironments. Sea turtles, for instance, possess specialized flippers that\nfacilitate both long-distance underwater travel and adept maneuvers across a\nrange of coastal terrains. Building on the principles of embodied intelligence\nand drawing inspiration from sea turtle hatchings, this paper examines the\ncritical interplay between a robot's physical form and its environmental\ninteractions, focusing on how morphological traits and locomotive behaviors\naffect terrestrial navigation. We present a bio-inspired robotic system and\nstudy the impacts of flipper/body morphology and gait patterns on its\nterrestrial mobility across diverse terrains ranging from sand to rocks.\nEvaluating key performance metrics such as speed and cost of transport, our\nexperimental results highlight adaptive designs as crucial for multi-terrain\nrobotic mobility to achieve not only speed and efficiency but also the\nversatility needed to tackle the varied and complex terrains encountered in\nreal-world applications.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Nnamdi Chikere",
            "John McElroy",
            "Yasemin Ozkan-Aydin"
        ],
        "published": "2024-05-22T19:27:17Z"
    },
    {
        "title": "Leader Reward for POMO-Based Neural Combinatorial Optimization",
        "link": "http://arxiv.org/abs/2405.13947v1",
        "abstract": "Deep neural networks based on reinforcement learning (RL) for solving\ncombinatorial optimization (CO) problems are developing rapidly and have shown\na tendency to approach or even outperform traditional solvers. However,\nexisting methods overlook an important distinction: CO problems differ from\nother traditional problems in that they focus solely on the optimal solution\nprovided by the model within a specific length of time, rather than considering\nthe overall quality of all solutions generated by the model. In this paper, we\npropose Leader Reward and apply it during two different training phases of the\nPolicy Optimization with Multiple Optima (POMO) model to enhance the model's\nability to generate optimal solutions. This approach is applicable to a variety\nof CO problems, such as the Traveling Salesman Problem (TSP), the Capacitated\nVehicle Routing Problem (CVRP), and the Flexible Flow Shop Problem (FFSP), but\nalso works well with other POMO-based models or inference phase's strategies.\nWe demonstrate that Leader Reward greatly improves the quality of the optimal\nsolutions generated by the model. Specifically, we reduce the POMO's gap to the\noptimum by more than 100 times on TSP100 with almost no additional\ncomputational overhead.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Chaoyang Wang",
            "Pengzhi Cheng",
            "Jingze Li",
            "Weiwei Sun"
        ],
        "published": "2024-05-22T19:27:03Z"
    },
    {
        "title": "Coded Computing Meets Quantum Circuit Simulation: Coded Parallel Tensor\n  Network Contraction Algorithm",
        "link": "http://arxiv.org/abs/2405.13946v1",
        "abstract": "Parallel tensor network contraction algorithms have emerged as the pivotal\nbenchmarks for assessing the classical limits of computation, exemplified by\nGoogle's demonstration of quantum supremacy through random circuit sampling.\nHowever, the massive parallelization of the algorithm makes it vulnerable to\ncomputer node failures. In this work, we apply coded computing to a practical\nparallel tensor network contraction algorithm. To the best of our knowledge,\nthis is the first attempt to code tensor network contractions. Inspired by\nmatrix multiplication codes, we provide two coding schemes: 2-node code for\npracticality in quantum simulation and hyperedge code for generality. Our\n2-node code successfully achieves significant gain for $f$-resilient number\ncompared to naive replication, proportional to both the number of node failures\nand the dimension product of sliced indices. Our hyperedge code can cover\ntensor networks out of the scope of quantum, with degraded gain in the exchange\nof its generality.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Jin Lee",
            "Sofia Gonzalez-Garcia",
            "Zheng Zhang",
            "Haewon Jeong"
        ],
        "published": "2024-05-22T19:21:37Z"
    },
    {
        "title": "A Survey on Design-space Dimensionality Reduction Methods for Shape\n  Optimization",
        "link": "http://arxiv.org/abs/2405.13944v1",
        "abstract": "The rapidly evolving field of engineering design of functional surfaces\nnecessitates sophisticated tools to manage the inherent complexity of\nhigh-dimensional design spaces. This review delves into the field of\ndesign-space dimensionality reduction techniques tailored for shape\noptimization, bridging traditional methods and cutting-edge technologies.\nDissecting the spectrum of these techniques, from classical linear approaches\nlike principal component analysis to more nuanced nonlinear methods such as\nautoencoders, the discussion extends to innovative physics-informed methods\nthat integrate physical data into the dimensionality reduction process,\nenhancing the predictive accuracy and relevance of reduced models. By\nintegrating these methods into optimization frameworks, it is shown how they\nsignificantly mitigate the curse of dimensionality, streamline computational\nprocesses, and refine the exploration and optimization of complex functional\nsurfaces. The survey provides a classification of method and highlights the\ntransformative impact of these techniques in simplifying design challenges,\nthereby fostering more efficient and effective engineering solutions.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "authors": [
            "Andrea Serani",
            "Matteo Diez"
        ],
        "published": "2024-05-22T19:19:09Z"
    },
    {
        "title": "DoGaussian: Distributed-Oriented Gaussian Splatting for Large-Scale 3D\n  Reconstruction Via Gaussian Consensus",
        "link": "http://arxiv.org/abs/2405.13943v1",
        "abstract": "The recent advances in 3D Gaussian Splatting (3DGS) show promising results on\nthe novel view synthesis (NVS) task. With its superior rendering performance\nand high-fidelity rendering quality, 3DGS is excelling at its previous NeRF\ncounterparts. The most recent 3DGS method focuses either on improving the\ninstability of rendering efficiency or reducing the model size. On the other\nhand, the training efficiency of 3DGS on large-scale scenes has not gained much\nattention. In this work, we propose DoGaussian, a method that trains 3DGS\ndistributedly. Our method first decomposes a scene into K blocks and then\nintroduces the Alternating Direction Method of Multipliers (ADMM) into the\ntraining procedure of 3DGS. During training, our DoGaussian maintains one\nglobal 3DGS model on the master node and K local 3DGS models on the slave\nnodes. The K local 3DGS models are dropped after training and we only query the\nglobal 3DGS model during inference. The training time is reduced by scene\ndecomposition, and the training convergence and stability are guaranteed\nthrough the consensus on the shared 3D Gaussians. Our method accelerates the\ntraining of 3DGS by 6+ times when evaluated on large-scale scenes while\nconcurrently achieving state-of-the-art rendering quality. Our project page is\navailable at https://aibluefisher.github.io/DoGaussian.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yu Chen",
            "Gim Hee Lee"
        ],
        "published": "2024-05-22T19:17:58Z"
    },
    {
        "title": "Distributed and Decentralized Control and Task Allocation for Flexible\n  Swarms",
        "link": "http://arxiv.org/abs/2405.13941v1",
        "abstract": "This paper introduces a novel bio-mimetic approach for distributed control of\nrobotic swarms, inspired by the collective behaviors of swarms in nature such\nas schools of fish and flocks of birds. The agents are assumed to have limited\nsensory perception, lack memory, be Identical, anonymous, and operate without\ninteragent explicit communication. Despite these limitations, we demonstrate\nthat collaborative exploration and task allocation can be executed by applying\nsimple local rules of interactions between the agents. A comprehensive model\ncomprised of agent, formation, and swarm layers is proposed in this paper,\nwhere each layer performs a specific function in shaping the swarm's collective\nbehavior, thereby contributing to the emergence of the anticipated behaviors.\nWe consider four principles combined in the design of the distributed control\nprocess: Cohesiveness, Flexibility, Attraction-Repulsion, and Peristaltic\nMotion. We design the control algorithms as reactive behaviour that enables the\nswarm to maintain connectivity, adapt to dynamic environments, spread out and\ncover a region with a size determined by the number of agents, and respond to\nvarious local task requirements. We explore some simple broadcast control-based\nsteering methods, that result in inducing \"anonymous ad-hoc leaders\" among the\nagents, capable of guiding the swarm towards yet unexplored regions with\nfurther tasks. Our analysis is complemented by simulations, validating the\nefficacy of our algorithms. The experiments with various scenarios showcase the\nswarm`s capability to self-organize and perform tasks effectively under the\nproposed framework. The possible implementations include domains that\nnecessitate emergent coordination and control in multi-agent systems, without\nthe need for advanced individual abilities or direct communication.",
        "subjects": [
            "cs.MA"
        ],
        "authors": [
            "Yigal Koifman",
            "Ariel Barel",
            "Alfred M. Bruckstein"
        ],
        "published": "2024-05-22T19:16:53Z"
    },
    {
        "title": "Principal eigenstate classical shadows",
        "link": "http://arxiv.org/abs/2405.13939v1",
        "abstract": "Given many copies of an unknown quantum state $\\rho$, we consider the task of\nlearning a classical description of its principal eigenstate. Namely, assuming\nthat $\\rho$ has an eigenstate $|\\phi\\rangle$ with (unknown) eigenvalue $\\lambda\n> 1/2$, the goal is to learn a (classical shadows style) classical description\nof $|\\phi\\rangle$ which can later be used to estimate expectation values\n$\\langle \\phi |O| \\phi \\rangle$ for any $O$ in some class of observables. We\nconsider the sample-complexity setting in which generating a copy of $\\rho$ is\nexpensive, but joint measurements on many copies of the state are possible. We\npresent a protocol for this task scaling with the principal eigenvalue\n$\\lambda$ and show that it is optimal within a space of natural approaches,\ne.g., applying quantum state purification followed by a single-copy classical\nshadows scheme. Furthermore, when $\\lambda$ is sufficiently close to $1$, the\nperformance of our algorithm is optimal--matching the sample complexity for\npure state classical shadows.",
        "subjects": [
            "quant-ph",
            "cs.IT",
            "cs.LG",
            "math.IT"
        ],
        "authors": [
            "Daniel Grier",
            "Hakop Pashayan",
            "Luke Schaeffer"
        ],
        "published": "2024-05-22T19:13:05Z"
    },
    {
        "title": "eXmY: A Data Type and Technique for Arbitrary Bit Precision Quantization",
        "link": "http://arxiv.org/abs/2405.13938v1",
        "abstract": "eXmY is a novel data type for quantization of ML models. It supports both\narbitrary bit widths and arbitrary integer and floating point formats. For\nexample, it seamlessly supports 3, 5, 6, 7, 9 bit formats. For a specific bit\nwidth, say 7, it defines all possible formats e.g. e0m6, e1m5, e2m4, e3m3,\ne4m2, e5m1 and e6m0. For non-power of two bit widths e.g. 5, 6, 7, we created a\nnovel encoding and decoding scheme which achieves perfect compression, byte\naddressability and is amenable to sharding and vector processing. We\nimplemented libraries for emulation, encoding and decoding tensors and\ncheckpoints in C++, TensorFlow, JAX and PAX. For optimal performance, the\ncodecs use SIMD instructions on CPUs and vector instructions on TPUs and GPUs.\neXmY is also a technique and exploits the statistical distribution of exponents\nin tensors. It can be used to quantize weights, static and dynamic activations,\ngradients, master weights and optimizer state. It can reduce memory (CPU DRAM\nand accelerator HBM), network and disk storage and transfers. It can increase\nmulti tenancy and accelerate compute. eXmY has been deployed in production for\nalmost 2 years.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.AR",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Aditya Agrawal",
            "Matthew Hedlund",
            "Blake Hechtman"
        ],
        "published": "2024-05-22T19:11:28Z"
    },
    {
        "title": "DyGPrompt: Learning Feature and Time Prompts on Dynamic Graphs",
        "link": "http://arxiv.org/abs/2405.13937v1",
        "abstract": "Dynamic graphs are pervasive in the real world, modeling dynamic relations\nbetween objects across various fields. For dynamic graph modeling, dynamic\ngraph neural networks (DGNNs) have emerged as a mainstream technique, which are\ngenerally pre-trained on the link prediction task, leaving a significant gap\nfrom the objectives of downstream tasks such as node classification. To bridge\nthe gap, prompt-based learning has gained traction on graphs. However, existing\nefforts focus on static graphs, neglecting the evolution of dynamic graphs. In\nthis paper, we propose DyGPrompt, a novel pre-training and prompting framework\nfor dynamic graph modeling. First, we design dual prompts to address the gap in\nboth task objectives and dynamic variations across pre-training and downstream\ntasks. Second, we recognize that node and time features mutually characterize\neach other, and propose dual condition-nets to model the evolving node-time\npatterns in downstream tasks. Finally, we thoroughly evaluate and analyze\nDyGPrompt through extensive experiments on three public datasets.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Xingtong Yu",
            "Zhenghao Liu",
            "Yuan Fang",
            "Xinming Zhang"
        ],
        "published": "2024-05-22T19:10:24Z"
    },
    {
        "title": "Nonisothermal Cahn-Hilliard Navier-Stokes system",
        "link": "http://arxiv.org/abs/2405.13936v1",
        "abstract": "In this research, we introduce and investigate an approximation method that\npreserves the structural integrity of the non-isothermal\nCahn-Hilliard-Navier-Stokes system. Our approach extends a previously proposed\ntechnique [1], which utilizes conforming (inf-sup stable) finite elements in\nspace, coupled with implicit time discretization employing convex-concave\nsplitting. Expanding upon this method, we incorporate the unstable P1|P1 pair\nfor the Navier-Stokes contributions, integrating Brezzi-Pitk\\\"aranta\nstabilization. Additionally, we improve the enforcement of incompressibility\nconditions through grad div stabilization. While these techniques are\nwell-established for Navier-Stokes equations, it becomes apparent that for\nnon-isothermal models, they introduce additional coupling terms to the equation\ngoverning internal energy. To ensure the conservation of total energy and\nmaintain entropy production, these stabilization terms are appropriately\nintegrated into the internal energy equation.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Aaron Brunk",
            "Dennis Schumann"
        ],
        "published": "2024-05-22T19:07:56Z"
    },
    {
        "title": "Text-Free Multi-domain Graph Pre-training:Toward Graph Foundation Models",
        "link": "http://arxiv.org/abs/2405.13934v1",
        "abstract": "Given the ubiquity of graph data, it is intriguing to ask: Is it possible to\ntrain a graph foundation model on a broad range of graph data across diverse\ndomains? A major hurdle toward this goal lies in the fact that graphs from\ndifferent domains often exhibit profoundly divergent characteristics. Although\nthere have been some initial efforts in integrating multi-domain graphs for\npre-training, they primarily rely on textual descriptions to align the graphs,\nlimiting their application to text-attributed graphs. Moreover, different\nsource domains may conflict or interfere with each other, and their relevance\nto the target domain can vary significantly. To address these issues, we\npropose MDGPT, a text free Multi-Domain Graph Pre-Training and adaptation\nframework designed to exploit multi-domain knowledge for graph learning. First,\nwe propose a set of domain tokens to to align features across source domains\nfor synergistic pre-training. Second, we propose a dual prompts, consisting of\na unifying prompt and a mixing prompt, to further adapt the target domain with\nunified multi-domain knowledge and a tailored mixture of domain-specific\nknowledge. Finally, we conduct extensive experiments involving six public\ndatasets to evaluate and analyze MDGPT, which outperforms prior art by up to\n37.9%.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Xingtong Yu",
            "Chang Zhou",
            "Yuan Fang",
            "Xinming Zhang"
        ],
        "published": "2024-05-22T19:06:39Z"
    },
    {
        "title": "Resurrection Attack: Defeating Xilinx MPU's Memory Protection",
        "link": "http://arxiv.org/abs/2405.13933v1",
        "abstract": "Memory protection units (MPUs) are hardware-assisted security features that\nare commonly used in embedded processors such as the ARM 940T, Infineon TC1775,\nand Xilinx Zynq. MPUs partition the memory statically, and set individual\nprotection attributes for each partition. MPUs typically define two protection\ndomains: user mode and supervisor mode. Normally, this is sufficient for\nprotecting the kernel and applications. However, we have discovered a way to\naccess a process memory due to a vulnerability in Xilinx MPU (XMPU)\nimplementation that we call Resurrection Attack. We find that XMPU security\npolicy protects user memory from unauthorized access when the user is active.\nHowever, when a user's session is terminated, the contents of the memory region\nof the terminated process are not cleared. An attacker can exploit this\nvulnerability by gaining access to the memory region after it has been\nreassigned. The attacker can read the data from the previous user's memory\nregion, thereby compromising the confidentiality. To prevent the Resurrection\nAttack, the memory region of a terminated process must be cleared. However,\nthis is not the case in the XMPU implementation, which allows our attack to\nsucceed. The Resurrection Attack is a serious security flaw that could be\nexploited to steal sensitive data or gain unauthorized access to a system. It\nis important for users of Xilinx FPGAs to be aware of this vulnerability until\nthis flaw is addressed.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Bharadwaj Madabhushi",
            "Chandra Sekhar Mummidi",
            "Sandip Kundu",
            "Daniel Holcomb"
        ],
        "published": "2024-05-22T19:05:21Z"
    },
    {
        "title": "Chain of Targeted Verification Questions to Improve the Reliability of\n  Code Generated by LLMs",
        "link": "http://arxiv.org/abs/2405.13932v1",
        "abstract": "LLM-based assistants, such as GitHub Copilot and ChatGPT, have the potential\nto generate code that fulfills a programming task described in a natural\nlanguage description, referred to as a prompt. The widespread accessibility of\nthese assistants enables users with diverse backgrounds to generate code and\nintegrate it into software projects. However, studies show that code generated\nby LLMs is prone to bugs and may miss various corner cases in task\nspecifications. Presenting such buggy code to users can impact their\nreliability and trust in LLM-based assistants. Moreover, significant efforts\nare required by the user to detect and repair any bug present in the code,\nespecially if no test cases are available. In this study, we propose a\nself-refinement method aimed at improving the reliability of code generated by\nLLMs by minimizing the number of bugs before execution, without human\nintervention, and in the absence of test cases. Our approach is based on\ntargeted Verification Questions (VQs) to identify potential bugs within the\ninitial code. These VQs target various nodes within the Abstract Syntax Tree\n(AST) of the initial code, which have the potential to trigger specific types\nof bug patterns commonly found in LLM-generated code. Finally, our method\nattempts to repair these potential bugs by re-prompting the LLM with the\ntargeted VQs and the initial code. Our evaluation, based on programming tasks\nin the CoderEval dataset, demonstrates that our proposed method outperforms\nstate-of-the-art methods by decreasing the number of targeted errors in the\ncode between 21% to 62% and improving the number of executable code instances\nto 13%.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "authors": [
            "Sylvain Kouemo Ngassom",
            "Arghavan Moradi Dakhel",
            "Florian Tambon",
            "Foutse Khomh"
        ],
        "published": "2024-05-22T19:02:50Z"
    },
    {
        "title": "A Methodology to Identify Physical or Computational Experiment\n  Conditions for Uncertainty Mitigation",
        "link": "http://arxiv.org/abs/2405.13931v1",
        "abstract": "Complex engineering systems require integration of simulation of sub-systems\nand calculation of metrics to drive design decisions. This paper introduces a\nmethodology for designing computational or physical experiments for\nsystem-level uncertainty mitigation purposes. The methodology follows a\npreviously determined problem ontology, where physical, functional and modeling\narchitectures are decided upon. By carrying out sensitivity analysis techniques\nutilizing system-level tools, critical epistemic uncertainties can be\nidentified. Afterwards, a framework is introduced to design specific\ncomputational and physical experimentation for generating new knowledge about\nparameters, and for uncertainty mitigation. The methodology is demonstrated\nthrough a case study on an early-stage design Blended-Wing-Body (BWB) aircraft\nconcept, showcasing how aerostructures analyses can be leveraged for mitigating\nsystem-level uncertainty, by computer experiments or guiding physical\nexperimentation. The proposed methodology is versatile enough to tackle\nuncertainty management across various design challenges, highlighting the\npotential for more risk-informed design processes.",
        "subjects": [
            "cs.CE",
            "cs.LG"
        ],
        "authors": [
            "Efe Y. Yarbasi",
            "Dimitri N. Mavris"
        ],
        "published": "2024-05-22T18:59:42Z"
    },
    {
        "title": "AlabOS: A Python-based Reconfigurable Workflow Management Framework for\n  Autonomous Laboratories",
        "link": "http://arxiv.org/abs/2405.13930v1",
        "abstract": "The recent advent of autonomous laboratories, coupled with algorithms for\nhigh-throughput screening and active learning, promises to accelerate materials\ndiscovery and innovation. As these autonomous systems grow in complexity, the\ndemand for robust and efficient workflow management software becomes\nincreasingly critical. In this paper, we introduce AlabOS, a general-purpose\nsoftware framework for orchestrating experiments and managing resources, with\nan emphasis on automated laboratories for materials synthesis and\ncharacterization. We demonstrate the implementation of AlabOS in a prototype\nautonomous materials laboratory. AlabOS features a reconfigurable experiment\nworkflow model, enabling the simultaneous execution of varied workflows\ncomposed of modular tasks. Therefore, AlabOS is well-suited to handle the\nrapidly changing experimental protocols defining the progress of self-driving\nlaboratory development for materials research.",
        "subjects": [
            "cond-mat.mtrl-sci",
            "cs.RO",
            "cs.SE"
        ],
        "authors": [
            "Yuxing Fei",
            "Bernardus Rendy",
            "Rishi Kumar",
            "Olympia Dartsi",
            "Hrushikesh P. Sahasrabuddhe",
            "Matthew J. McDermott",
            "Zheren Wang",
            "Nathan J. Szymanski",
            "Lauren N. Walters",
            "David Milsted",
            "Yan Zeng",
            "Anubhav Jain",
            "Gerbrand Ceder"
        ],
        "published": "2024-05-22T18:59:39Z"
    },
    {
        "title": "Vikhr: The Family of Open-Source Instruction-Tuned Large Language Models\n  for Russian",
        "link": "http://arxiv.org/abs/2405.13929v1",
        "abstract": "There has been a surge in the development of various Large Language Models\n(LLMs). However, text generation for languages other than English often faces\nsignificant challenges, including poor generation quality and the reduced\ncomputational performance due to the disproportionate representation of tokens\nin model's vocabulary. In this work, we address these issues and introduce\nVikhr, a new state-of-the-art open-source instruction-tuned LLM designed\nspecifically for the Russian language. Unlike previous efforts for Russian that\nutilize computationally inexpensive LoRA adapters on top of English-oriented\nmodels, Vikhr features an adapted tokenizer vocabulary and undergoes the\ncontinued pre-training and instruction tuning of all weights. This approach not\nonly enhances the model's performance but also significantly improves its\ncomputational and contextual efficiency. The remarkable performance of Vikhr\nacross various Russian-language benchmarks can also be attributed to our\nefforts in expanding instruction datasets and corpora for continued\npre-training. Vikhr not only sets the new state of the art among open-source\nLLMs for Russian, but even outperforms some proprietary closed-source models on\ncertain benchmarks. The model weights, instruction sets, and code are publicly\navailable",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Aleksandr Nikolich",
            "Konstantin Korolev",
            "Artem Shelmanov"
        ],
        "published": "2024-05-22T18:58:58Z"
    },
    {
        "title": "Counting the number of inequivalent arithmetic expressions on $n$\n  variables",
        "link": "http://arxiv.org/abs/2405.13928v1",
        "abstract": "An expression is any mathematical formula that contains certain formal\nvariables and operations to be executed in a specified order. In computer\nscience, it is usually convenient to represent each expression in the form of\nan expression tree. Here, we consider only arithmetic expressions, i.e., those\nthat contain only the four standard arithmetic operations: addition,\nsubtraction, multiplication and division, alongside additive inversion. We\nfirst provide certain theoretical results concerning the equivalence of such\nexpressions and then disclose a $\\Theta(n^2)$ algorithm that computes the\nnumber of inequivalent arithmetic expressions on $n$ distinct variables.",
        "subjects": [
            "cs.DM",
            "math.CO",
            "math.NT",
            "68R05, 05A15, 05A19, 11C08"
        ],
        "authors": [
            "Ivan Sto≈°iƒá",
            "Ivan Damnjanoviƒá",
            "≈Ωarko Ranƒëeloviƒá"
        ],
        "published": "2024-05-22T18:58:23Z"
    },
    {
        "title": "Memory Scraping Attack on Xilinx FPGAs: Private Data Extraction from\n  Terminated Processes",
        "link": "http://arxiv.org/abs/2405.13927v1",
        "abstract": "FPGA-based hardware accelerators are becoming increasingly popular due to\ntheir versatility, customizability, energy efficiency, constant latency, and\nscalability. FPGAs can be tailored to specific algorithms, enabling efficient\nhardware implementations that effectively leverage algorithm parallelism. This\ncan lead to significant performance improvements over CPUs and GPUs,\nparticularly for highly parallel applications. For example, a recent study\nfound that Stratix 10 FPGAs can achieve up to 90\\% of the performance of a\nTitanX Pascal GPU while consuming less than 50\\% of the power. This makes FPGAs\nan attractive choice for accelerating machine learning (ML) workloads. However,\nour research finds privacy and security vulnerabilities in existing Xilinx\nFPGA-based hardware acceleration solutions. These vulnerabilities arise from\nthe lack of memory initialization and insufficient process isolation, which\ncreates potential avenues for unauthorized access to private data used by\nprocesses. To illustrate this issue, we conducted experiments using a Xilinx\nZCU104 board running the PetaLinux tool from Xilinx. We found that PetaLinux\ndoes not effectively clear memory locations associated with a terminated\nprocess, leaving them vulnerable to memory scraping attack (MSA). This paper\nmakes two main contributions. The first contribution is an attack methodology\nof using the Xilinx debugger from a different user space. We find that we are\nable to access process IDs, virtual address spaces, and pagemaps of one user\nfrom a different user space because of lack of adequate process isolation. The\nsecond contribution is a methodology for characterizing terminated processes\nand accessing their private data. We illustrate this on Xilinx ML application\nlibrary.",
        "subjects": [
            "cs.CR",
            "cs.AR"
        ],
        "authors": [
            "Bharadwaj Madabhushi",
            "Sandip Kundu",
            "Daniel Holcomb"
        ],
        "published": "2024-05-22T18:58:20Z"
    },
    {
        "title": "Narrative Review of Support for Emotional Expressions in Virtual\n  Reality: Psychophysiology of speech-to-text interfaces",
        "link": "http://arxiv.org/abs/2405.13924v1",
        "abstract": "This narrative review on emotional expression in Speech-to-Text (STT)\ninterfaces with Virtual Reality (VR) aims to identify advancements,\nlimitations, and research gaps in incorporating emotional expression into\ntranscribed text generated by STT systems. Using a rigorous search strategy,\nrelevant articles published between 2020 and 2024 are extracted and categorized\ninto themes such as communication enhancement technologies, innovations in\ncaptioning, emotion recognition in AR and VR, and empathic machines. The\nfindings reveal the evolution of tools and techniques to meet the needs of\nindividuals with hearing impairments, showcasing innovations in live\ntranscription, closed captioning, AR, VR, and emotion recognition technologies.\nDespite improvements in accessibility, the absence of emotional nuance in\ntranscribed text remains a significant communication challenge. The study\nunderscores the urgency for innovations in STT technology to capture emotional\nexpressions. The research discusses integrating emotional expression into text\nthrough strategies like animated text captions, emojilization tools, and models\nassociating emotions with animation properties. Extending these efforts into AR\nand VR environments opens new possibilities for immersive and emotionally\nresonant experiences, especially in educational contexts. The study also\nexplores empathic applications in healthcare, education, and human-robot\ninteractions, highlighting the potential for personalized and effective\ninteractions. The multidisciplinary nature of the literature underscores the\npotential for collaborative and interdisciplinary research.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Sunday David Ubur",
            "Denis Gracanin"
        ],
        "published": "2024-05-22T18:53:27Z"
    },
    {
        "title": "Why Not Transform Chat Large Language Models to Non-English?",
        "link": "http://arxiv.org/abs/2405.13923v1",
        "abstract": "The scarcity of non-English data limits the development of non-English large\nlanguage models (LLMs). Transforming English-centric LLMs to non-English has\nbeen identified as an effective and resource-efficient method. Previous works\nstart from base LLMs and perform knowledge distillation (KD) with data\ngenerated by stronger LLMs, e.g. GPT-4. Compared to base LLMs, chat LLMs are\nfurther optimized for advanced abilities, e.g. multi-turn conversation and\nhuman preference alignment, and thus more powerful in both helpfulness and\nsafety. However, transforming a chat LLM involves two critical issues: (1) How\ncan we effectively transfer advanced abilities without their supervised data?\n(2) How can we prevent the original knowledge from catastrophic forgetting\nduring transformation? We target these issues by introducing a simple framework\ncalled TransLLM. For the first issue, TransLLM divides the transfer problem\ninto some common sub-tasks with the translation chain-of-thought, which uses\nthe translation as the bridge between English and non-English step-by-step. We\nfurther enhance the performance of sub-tasks with publicly available data. For\nthe second issue, we propose a method comprising two synergistic components:\nlow-rank adaptation for training to maintain the original LLM parameters, and\nrecovery KD, which utilizes data generated by the chat LLM itself to recover\nthe original knowledge from the frozen parameters. In the experiments, we\ntransform the LLaMA-2-chat-7B to the Thai language. Our method, using only\nsingle-turn data, outperforms strong baselines and ChatGPT on multi-turn\nbenchmark MT-bench. Furthermore, our method, without safety data, rejects more\nharmful queries of safety benchmark AdvBench than both ChatGPT and GPT-4.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Xiang Geng",
            "Ming Zhu",
            "Jiahuan Li",
            "Zhejian Lai",
            "Wei Zou",
            "Shuaijie She",
            "Jiaxin Guo",
            "Xiaofeng Zhao",
            "Yinglu Li",
            "Yuang Li",
            "Chang Su",
            "Yanqing Zhao",
            "Min Zhang",
            "Hao Yang",
            "Xinglin Lyu",
            "Jiajun Chen",
            "Shujian Huang"
        ],
        "published": "2024-05-22T18:53:25Z"
    },
    {
        "title": "Towards Certification of Uncertainty Calibration under Adversarial\n  Attacks",
        "link": "http://arxiv.org/abs/2405.13922v1",
        "abstract": "Since neural classifiers are known to be sensitive to adversarial\nperturbations that alter their accuracy, \\textit{certification methods} have\nbeen developed to provide provable guarantees on the insensitivity of their\npredictions to such perturbations. Furthermore, in safety-critical\napplications, the frequentist interpretation of the confidence of a classifier\n(also known as model calibration) can be of utmost importance. This property\ncan be measured via the Brier score or the expected calibration error. We show\nthat attacks can significantly harm calibration, and thus propose certified\ncalibration as worst-case bounds on calibration under adversarial\nperturbations. Specifically, we produce analytic bounds for the Brier score and\napproximate bounds via the solution of a mixed-integer program on the expected\ncalibration error. Finally, we propose novel calibration attacks and\ndemonstrate how they can improve model calibration through \\textit{adversarial\ncalibration training}.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Cornelius Emde",
            "Francesco Pinto",
            "Thomas Lukasiewicz",
            "Philip H. S. Torr",
            "Adel Bibi"
        ],
        "published": "2024-05-22T18:52:09Z"
    },
    {
        "title": "Algebraic Conditions for Stability in Runge-Kutta Methods and Their\n  Certification via Semidefinite Programming",
        "link": "http://arxiv.org/abs/2405.13921v1",
        "abstract": "In this work, we present approaches to rigorously certify $A$- and\n$A(\\alpha)$-stability in Runge-Kutta methods through the solution of convex\nfeasibility problems defined by linear matrix inequalities. We adopt two\napproaches. The first is based on sum-of-squares programming applied to the\nRunge-Kutta $E$-polynomial and is applicable to both $A$- and\n$A(\\alpha)$-stability. In the second, we sharpen the algebraic conditions for\n$A$-stability of Cooper, Scherer, T{\\\"u}rke, and Wendler to incorporate the\nRunge-Kutta order conditions. We demonstrate how the theoretical improvement\nenables the practical use of these conditions for certification of\n$A$-stability within a computational framework. We then use both approaches to\nobtain rigorous certificates of stability for several diagonally implicit\nschemes devised in the literature.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "math.OC",
            "65L06, 65L07, 65L20"
        ],
        "authors": [
            "Austin Juhl",
            "David Shirokoff"
        ],
        "published": "2024-05-22T18:50:49Z"
    },
    {
        "title": "Fair Online Bilateral Trade",
        "link": "http://arxiv.org/abs/2405.13919v1",
        "abstract": "In online bilateral trade, a platform posts prices to incoming pairs of\nbuyers and sellers that have private valuations for a certain good. If the\nprice is lower than the buyers' valuation and higher than the sellers'\nvaluation, then a trade takes place. Previous work focused on the platform\nperspective, with the goal of setting prices maximizing the gain from trade\n(the sum of sellers' and buyers' utilities). Gain from trade is, however,\npotentially unfair to traders, as they may receive highly uneven shares of the\ntotal utility. In this work we enforce fairness by rewarding the platform with\nthe fair gain from trade, defined as the minimum between sellers' and buyers'\nutilities. After showing that any no-regret learning algorithm designed to\nmaximize the sum of the utilities may fail badly with fair gain from trade, we\npresent our main contribution: a complete characterization of the regret\nregimes for fair gain from trade when, after each interaction, the platform\nonly learns whether each trader accepted the current price. Specifically, we\nprove the following regret bounds: $\\Theta(\\ln T)$ in the deterministic\nsetting, $\\Omega(T)$ in the stochastic setting, and $\\tilde{\\Theta}(T^{2/3})$\nin the stochastic setting when sellers' and buyers' valuations are independent\nof each other. We conclude by providing tight regret bounds when, after each\ninteraction, the platform is allowed to observe the true traders' valuations.",
        "subjects": [
            "cs.GT",
            "cs.LG"
        ],
        "authors": [
            "Fran√ßois Bachoc",
            "Nicol√≤ Cesa-Bianchi",
            "Tommaso Cesari",
            "Roberto Colomboni"
        ],
        "published": "2024-05-22T18:49:11Z"
    },
    {
        "title": "HeteGraph-Mamba: Heterogeneous Graph Learning via Selective State Space\n  Model",
        "link": "http://arxiv.org/abs/2405.13915v1",
        "abstract": "We propose a heterogeneous graph mamba network (HGMN) as the first\nexploration in leveraging the selective state space models (SSSMs) for\nheterogeneous graph learning. Compared with the literature, our HGMN overcomes\ntwo major challenges: (i) capturing long-range dependencies among heterogeneous\nnodes and (ii) adapting SSSMs to heterogeneous graph data. Our key contribution\nis a general graph architecture that can solve heterogeneous nodes in\nreal-world scenarios, followed an efficient flow. Methodologically, we\nintroduce a two-level efficient tokenization approach that first captures\nlong-range dependencies within identical node types, and subsequently across\nall node types. Empirically, we conduct comparisons between our framework and\n19 state-of-the-art methods on the heterogeneous benchmarks. The extensive\ncomparisons demonstrate that our framework outperforms other methods in both\nthe accuracy and efficiency dimensions.",
        "subjects": [
            "cs.LG",
            "cs.SI"
        ],
        "authors": [
            "Zhenyu Pan",
            "Yoonsung Jeong",
            "Xiaoda Liu",
            "Han Liu"
        ],
        "published": "2024-05-22T18:41:11Z"
    },
    {
        "title": "Matrix Denoising with Doubly Heteroscedastic Noise: Fundamental Limits\n  and Optimal Spectral Methods",
        "link": "http://arxiv.org/abs/2405.13912v1",
        "abstract": "We study the matrix denoising problem of estimating the singular vectors of a\nrank-$1$ signal corrupted by noise with both column and row correlations.\nExisting works are either unable to pinpoint the exact asymptotic estimation\nerror or, when they do so, the resulting approaches (e.g., based on whitening\nor singular value shrinkage) remain vastly suboptimal. On top of this, most of\nthe literature has focused on the special case of estimating the left singular\nvector of the signal when the noise only possesses row correlation (one-sided\nheteroscedasticity). In contrast, our work establishes the\ninformation-theoretic and algorithmic limits of matrix denoising with doubly\nheteroscedastic noise. We characterize the exact asymptotic minimum mean square\nerror, and design a novel spectral estimator with rigorous optimality\nguarantees: under a technical condition, it attains positive correlation with\nthe signals whenever information-theoretically possible and, for one-sided\nheteroscedasticity, it also achieves the Bayes-optimal error. Numerical\nexperiments demonstrate the significant advantage of our theoretically\nprincipled method with the state of the art. The proofs draw connections with\nstatistical physics and approximate message passing, departing drastically from\nstandard random matrix theory techniques.",
        "subjects": [
            "math.ST",
            "cs.IT",
            "cs.LG",
            "math.IT",
            "math.PR",
            "stat.ML",
            "stat.TH"
        ],
        "authors": [
            "Yihan Zhang",
            "Marco Mondelli"
        ],
        "published": "2024-05-22T18:38:10Z"
    },
    {
        "title": "TOPA: Extend Large Language Models for Video Understanding via Text-Only\n  Pre-Alignment",
        "link": "http://arxiv.org/abs/2405.13911v1",
        "abstract": "Recent advancements in image understanding have benefited from the extensive\nuse of web image-text pairs. However, video understanding remains a challenge\ndespite the availability of substantial web video-text data. This difficulty\nprimarily arises from the inherent complexity of videos and the inefficient\nlanguage supervision in recent web-collected video-text datasets. In this\npaper, we introduce Text-Only Pre-Alignment (TOPA), a novel approach to extend\nlarge language models (LLMs) for video understanding, without the need for\npre-training on real video data. Specifically, we first employ an advanced LLM\nto automatically generate Textual Videos comprising continuous textual frames,\nalong with corresponding annotations to simulate real video-text data. Then,\nthese annotated textual videos are used to pre-align a language-only LLM with\nthe video modality. To bridge the gap between textual and real videos, we\nemploy the CLIP model as the feature extractor to align image and text\nmodalities. During text-only pre-alignment, the continuous textual frames,\nencoded as a sequence of CLIP text features, are analogous to continuous CLIP\nimage features, thus aligning the LLM with real video representation. Extensive\nexperiments, including zero-shot evaluation and finetuning on various video\nunderstanding tasks, demonstrate that TOPA is an effective and efficient\nframework for aligning video content with LLMs. In particular, without training\non any video data, the TOPA-Llama2-13B model achieves a Top-1 accuracy of 51.0%\non the challenging long-form video understanding benchmark, Egoschema. This\nperformance surpasses previous video-text pre-training approaches and proves\ncompetitive with recent GPT-3.5-based video agents.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Wei Li",
            "Hehe Fan",
            "Yongkang Wong",
            "Mohan Kankanhalli",
            "Yi Yang"
        ],
        "published": "2024-05-22T18:35:10Z"
    },
    {
        "title": "Learning Latent Space Hierarchical EBM Diffusion Models",
        "link": "http://arxiv.org/abs/2405.13910v1",
        "abstract": "This work studies the learning problem of the energy-based prior model and\nthe multi-layer generator model. The multi-layer generator model, which\ncontains multiple layers of latent variables organized in a top-down\nhierarchical structure, typically assumes the Gaussian prior model. Such a\nprior model can be limited in modelling expressivity, which results in a gap\nbetween the generator posterior and the prior model, known as the prior hole\nproblem. Recent works have explored learning the energy-based (EBM) prior model\nas a second-stage, complementary model to bridge the gap. However, the EBM\ndefined on a multi-layer latent space can be highly multi-modal, which makes\nsampling from such marginal EBM prior challenging in practice, resulting in\nineffectively learned EBM. To tackle the challenge, we propose to leverage the\ndiffusion probabilistic scheme to mitigate the burden of EBM sampling and thus\nfacilitate EBM learning. Our extensive experiments demonstrate a superior\nperformance of our diffusion-learned EBM prior on various challenging tasks.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "stat.ML"
        ],
        "authors": [
            "Jiali Cui",
            "Tian Han"
        ],
        "published": "2024-05-22T18:34:25Z"
    },
    {
        "title": "Just rephrase it! Uncertainty estimation in closed-source language\n  models via multiple rephrased queries",
        "link": "http://arxiv.org/abs/2405.13907v1",
        "abstract": "State-of-the-art large language models are sometimes distributed as\nopen-source software but are also increasingly provided as a closed-source\nservice. These closed-source large-language models typically see the widest\nusage by the public, however, they often do not provide an estimate of their\nuncertainty when responding to queries. As even the best models are prone to\n``hallucinating\" false information with high confidence, a lack of a reliable\nestimate of uncertainty limits the applicability of these models in critical\nsettings. We explore estimating the uncertainty of closed-source LLMs via\nmultiple rephrasings of an original base query. Specifically, we ask the model,\nmultiple rephrased questions, and use the similarity of the answers as an\nestimate of uncertainty. We diverge from previous work in i) providing rules\nfor rephrasing that are simple to memorize and use in practice ii) proposing a\ntheoretical framework for why multiple rephrased queries obtain calibrated\nuncertainty estimates. Our method demonstrates significant improvements in the\ncalibration of uncertainty estimates compared to the baseline and provides\nintuition as to how query strategies should be designed for optimal test\ncalibration.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Adam Yang",
            "Chen Chen",
            "Konstantinos Pitas"
        ],
        "published": "2024-05-22T18:28:26Z"
    },
    {
        "title": "Calibration of stochastic, agent-based neuron growth models with\n  Approximate Bayesian Computation",
        "link": "http://arxiv.org/abs/2405.13905v1",
        "abstract": "Understanding how genetically encoded rules drive and guide complex neuronal\ngrowth processes is essential to comprehending the brain's architecture, and\nagent-based models (ABMs) offer a powerful simulation approach to further\ndevelop this understanding. However, accurately calibrating these models\nremains a challenge. Here, we present a novel application of Approximate\nBayesian Computation (ABC) to address this issue. ABMs are based on\nparametrized stochastic rules that describe the time evolution of small\ncomponents -- the so-called agents -- discretizing the system, leading to\nstochastic simulations that require appropriate treatment. Mathematically, the\ncalibration defines a stochastic inverse problem. We propose to address it in a\nBayesian setting using ABC. We facilitate the repeated comparison between data\nand simulations by quantifying the morphological information of single neurons\nwith so-called morphometrics and resort to statistical distances to measure\ndiscrepancies between populations thereof. We conduct experiments on synthetic\nas well as experimental data. We find that ABC utilizing Sequential Monte Carlo\nsampling and the Wasserstein distance finds accurate posterior parameter\ndistributions for representative ABMs. We further demonstrate that these ABMs\ncapture specific features of pyramidal cells of the hippocampus (CA1). Overall,\nthis work establishes a robust framework for calibrating agent-based neuronal\ngrowth models and opens the door for future investigations using Bayesian\ntechniques for model building, verification, and adequacy assessment.",
        "subjects": [
            "cs.CE",
            "physics.bio-ph",
            "62F15, 62F25, 92-04, 92-08, 92-10, 92B05, 92C10, 92C20, 92C42",
            "I.6.4; J.2; J.3"
        ],
        "authors": [
            "Tobias Duswald",
            "Lukas Breitwieser",
            "Thomas Thorne",
            "Barbara Wohlmuth",
            "Roman Bauer"
        ],
        "published": "2024-05-22T18:25:59Z"
    },
    {
        "title": "ST-Gait++: Leveraging spatio-temporal convolutions for gait-based\n  emotion recognition on videos",
        "link": "http://arxiv.org/abs/2405.13903v1",
        "abstract": "Emotion recognition is relevant for human behaviour understanding, where\nfacial expression and speech recognition have been widely explored by the\ncomputer vision community. Literature in the field of behavioural psychology\nindicates that gait, described as the way a person walks, is an additional\nindicator of emotions. In this work, we propose a deep framework for emotion\nrecognition through the analysis of gait. More specifically, our model is\ncomposed of a sequence of spatial-temporal Graph Convolutional Networks that\nproduce a robust skeleton-based representation for the task of emotion\nclassification. We evaluate our proposed framework on the E-Gait dataset,\ncomposed of a total of 2177 samples. The results obtained represent an\nimprovement of approximately 5% in accuracy compared to the state of the art.\nIn addition, during training we observed a faster convergence of our model\ncompared to the state-of-the-art methodologies.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Maria Lu√≠sa Lima",
            "Willams de Lima Costa",
            "Estefania Talavera Martinez",
            "Veronica Teichrieb"
        ],
        "published": "2024-05-22T18:24:21Z"
    },
    {
        "title": "LOGIN: A Large Language Model Consulted Graph Neural Network Training\n  Framework",
        "link": "http://arxiv.org/abs/2405.13902v1",
        "abstract": "Recent prevailing works on graph machine learning typically follow a similar\nmethodology that involves designing advanced variants of graph neural networks\n(GNNs) to maintain the superior performance of GNNs on different graphs. In\nthis paper, we aim to streamline the GNN design process and leverage the\nadvantages of Large Language Models (LLMs) to improve the performance of GNNs\non downstream tasks. We formulate a new paradigm, coined \"LLMs-as-Consultants,\"\nwhich integrates LLMs with GNNs in an interactive manner. A framework named\nLOGIN (LLM Consulted GNN training) is instantiated, empowering the interactive\nutilization of LLMs within the GNN training process. First, we attentively\ncraft concise prompts for spotted nodes, carrying comprehensive semantic and\ntopological information, and serving as input to LLMs. Second, we refine GNNs\nby devising a complementary coping mechanism that utilizes the responses from\nLLMs, depending on their correctness. We empirically evaluate the effectiveness\nof LOGIN on node classification tasks across both homophilic and heterophilic\ngraphs. The results illustrate that even basic GNN architectures, when employed\nwithin the proposed LLMs-as-Consultants paradigm, can achieve comparable\nperformance to advanced GNNs with intricate designs. Our codes are available at\nhttps://github.com/QiaoYRan/LOGIN.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Yiran Qiao",
            "Xiang Ao",
            "Yang Liu",
            "Jiarong Xu",
            "Xiaoqian Sun",
            "Qing He"
        ],
        "published": "2024-05-22T18:17:20Z"
    },
    {
        "title": "DCT-Based Decorrelated Attention for Vision Transformers",
        "link": "http://arxiv.org/abs/2405.13901v1",
        "abstract": "Central to the Transformer architectures' effectiveness is the self-attention\nmechanism, a function that maps queries, keys, and values into a\nhigh-dimensional vector space. However, training the attention weights of\nqueries, keys, and values is non-trivial from a state of random initialization.\nIn this paper, we propose two methods. (i) We first address the initialization\nproblem of Vision Transformers by introducing a simple, yet highly innovative,\ninitialization approach utilizing Discrete Cosine Transform (DCT) coefficients.\nOur proposed DCT-based attention initialization marks a significant gain\ncompared to traditional initialization strategies; offering a robust foundation\nfor the attention mechanism. Our experiments reveal that the DCT-based\ninitialization enhances the accuracy of Vision Transformers in classification\ntasks. (ii) We also recognize that since DCT effectively decorrelates image\ninformation in the frequency domain, this decorrelation is useful for\ncompression because it allows the quantization step to discard many of the\nhigher-frequency components. Based on this observation, we propose a novel\nDCT-based compression technique for the attention function of Vision\nTransformers. Since high-frequency DCT coefficients usually correspond to\nnoise, we truncate the high-frequency DCT components of the input patches. Our\nDCT-based compression reduces the size of weight matrices for queries, keys,\nand values. While maintaining the same level of accuracy, our DCT compressed\nSwin Transformers obtain a considerable decrease in the computational overhead.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "eess.SP"
        ],
        "authors": [
            "Hongyi Pan",
            "Emadeldeen Hamdan",
            "Xin Zhu",
            "Koushik Biswas",
            "Ahmet Cetin",
            "Ulas Bagci"
        ],
        "published": "2024-05-22T18:15:42Z"
    },
    {
        "title": "Rehearsal-free Federated Domain-incremental Learning",
        "link": "http://arxiv.org/abs/2405.13900v1",
        "abstract": "We introduce a rehearsal-free federated domain incremental learning\nframework, RefFiL, based on a global prompt-sharing paradigm to alleviate\ncatastrophic forgetting challenges in federated domain-incremental learning,\nwhere unseen domains are continually learned. Typical methods for mitigating\nforgetting, such as the use of additional datasets and the retention of private\ndata from earlier tasks, are not viable in federated learning (FL) due to\ndevices' limited resources. Our method, RefFiL, addresses this by learning\ndomain-invariant knowledge and incorporating various domain-specific prompts\nfrom the domains represented by different FL participants. A key feature of\nRefFiL is the generation of local fine-grained prompts by our domain adaptive\nprompt generator, which effectively learns from local domain knowledge while\nmaintaining distinctive boundaries on a global scale. We also introduce a\ndomain-specific prompt contrastive learning loss that differentiates between\nlocally generated prompts and those from other domains, enhancing RefFiL's\nprecision and effectiveness. Compared to existing methods, RefFiL significantly\nalleviates catastrophic forgetting without requiring extra memory space, making\nit ideal for privacy-sensitive and resource-constrained devices.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Rui Sun",
            "Haoran Duan",
            "Jiahua Dong",
            "Varun Ojha",
            "Tejal Shah",
            "Rajiv Ranjan"
        ],
        "published": "2024-05-22T18:13:38Z"
    },
    {
        "title": "Symmetric Linear Bandits with Hidden Symmetry",
        "link": "http://arxiv.org/abs/2405.13899v1",
        "abstract": "High-dimensional linear bandits with low-dimensional structure have received\nconsiderable attention in recent studies due to their practical significance.\nThe most common structure in the literature is sparsity. However, it may not be\navailable in practice. Symmetry, where the reward is invariant under certain\ngroups of transformations on the set of arms, is another important inductive\nbias in the high-dimensional case that covers many standard structures,\nincluding sparsity. In this work, we study high-dimensional symmetric linear\nbandits where the symmetry is hidden from the learner, and the correct symmetry\nneeds to be learned in an online setting. We examine the structure of a\ncollection of hidden symmetry and provide a method based on model selection\nwithin the collection of low-dimensional subspaces. Our algorithm achieves a\nregret bound of $ O(d_0^{1/3} T^{2/3} \\log(d))$, where $d$ is the ambient\ndimension which is potentially very large, and $d_0$ is the dimension of the\ntrue low-dimensional subspace such that $d_0 \\ll d$. With an extra assumption\non well-separated models, we can further improve the regret to $\nO(d_0\\sqrt{T\\log(d)} )$.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Nam Phuong Tran",
            "The Anh Ta",
            "Debmalya Mandal",
            "Long Tran-Thanh"
        ],
        "published": "2024-05-22T18:11:57Z"
    },
    {
        "title": "A General Framework for Jersey Number Recognition in Sports Video",
        "link": "http://arxiv.org/abs/2405.13896v1",
        "abstract": "Jersey number recognition is an important task in sports video analysis,\npartly due to its importance for long-term player tracking. It can be viewed as\na variant of scene text recognition. However, there is a lack of published\nattempts to apply scene text recognition models on jersey number data. Here we\nintroduce a novel public jersey number recognition dataset for hockey and study\nhow scene text recognition methods can be adapted to this problem. We address\nissues of occlusions and assess the degree to which training on one sport\n(hockey) can be generalized to another (soccer). For the latter, we also\nconsider how jersey number recognition at the single-image level can be\naggregated across frames to yield tracklet-level jersey number labels. We\ndemonstrate high performance on image- and tracklet-level tasks, achieving\n91.4% accuracy for hockey images and 87.4% for soccer tracklets. Code, models,\nand data are available at https://github.com/mkoshkina/jersey-number-pipeline.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Maria Koshkina",
            "James H. Elder"
        ],
        "published": "2024-05-22T18:08:26Z"
    },
    {
        "title": "DeepNcode: Encoding-Based Protection against Bit-Flip Attacks on Neural\n  Networks",
        "link": "http://arxiv.org/abs/2405.13891v1",
        "abstract": "Fault injection attacks are a potent threat against embedded implementations\nof neural network models. Several attack vectors have been proposed, such as\nmisclassification, model extraction, and trojan/backdoor planting. Most of\nthese attacks work by flipping bits in the memory where quantized model\nparameters are stored.\n  In this paper, we introduce an encoding-based protection method against\nbit-flip attacks on neural networks, titled DeepNcode. We experimentally\nevaluate our proposal with several publicly available models and datasets, by\nusing state-of-the-art bit-flip attacks: BFA, T-BFA, and TA-LBF. Our results\nshow an increase in protection margin of up to $7.6\\times$ for $4-$bit and\n$12.4\\times$ for $8-$bit quantized networks. Memory overheads start at $50\\%$\nof the original network size, while the time overheads are negligible.\nMoreover, DeepNcode does not require retraining and does not change the\noriginal accuracy of the model.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "authors": [
            "Patrik Velƒçick√Ω",
            "Jakub Breier",
            "Xiaolu Hou",
            "Mladen Kovaƒçeviƒá"
        ],
        "published": "2024-05-22T18:01:34Z"
    },
    {
        "title": "An empirical study to understand how students use ChatGPT for writing\n  essays and how it affects their ownership",
        "link": "http://arxiv.org/abs/2405.13890v1",
        "abstract": "As large language models (LLMs) become more powerful and ubiquitous, systems\nlike ChatGPT are increasingly used by students to help them with writing tasks.\nTo better understand how these tools are used, we investigate how students\nmight use an LLM for essay writing, for example, to study the queries asked to\nChatGPT and the responses that ChatGPT gives. To that end, we plan to conduct a\nuser study that will record the user writing process and present them with the\nopportunity to use ChatGPT as an AI assistant. This study's findings will help\nus understand how these tools are used and how practitioners -- such as\neducators and essay readers -- should consider writing education and evaluation\nbased on essay writing.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Andrew Jelson",
            "Sang Won Lee"
        ],
        "published": "2024-05-22T18:01:24Z"
    },
    {
        "title": "Marrying Causal Representation Learning with Dynamical Systems for\n  Science",
        "link": "http://arxiv.org/abs/2405.13888v1",
        "abstract": "Causal representation learning promises to extend causal models to hidden\ncausal variables from raw entangled measurements. However, most progress has\nfocused on proving identifiability results in different settings, and we are\nnot aware of any successful real-world application. At the same time, the field\nof dynamical systems benefited from deep learning and scaled to countless\napplications but does not allow parameter identification. In this paper, we\ndraw a clear connection between the two and their key assumptions, allowing us\nto apply identifiable methods developed in causal representation learning to\ndynamical systems. At the same time, we can leverage scalable differentiable\nsolvers developed for differential equations to build models that are both\nidentifiable and practical. Overall, we learn explicitly controllable models\nthat isolate the trajectory-specific parameters for further downstream tasks\nsuch as out-of-distribution classification or treatment effect estimation. We\nexperiment with a wind simulator with partially known factors of variation. We\nalso apply the resulting model to real-world climate data and successfully\nanswer downstream causal questions in line with existing literature on climate\nchange.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Dingling Yao",
            "Caroline Muller",
            "Francesco Locatello"
        ],
        "published": "2024-05-22T18:00:41Z"
    },
    {
        "title": "FACT or Fiction: Can Truthful Mechanisms Eliminate Federated Free\n  Riding?",
        "link": "http://arxiv.org/abs/2405.13879v1",
        "abstract": "Standard federated learning (FL) approaches are vulnerable to the free-rider\ndilemma: participating agents can contribute little to nothing yet receive a\nwell-trained aggregated model. While prior mechanisms attempt to solve the\nfree-rider dilemma, none have addressed the issue of truthfulness. In practice,\nadversarial agents can provide false information to the server in order to\ncheat its way out of contributing to federated training. In an effort to make\nfree-riding-averse federated mechanisms truthful, and consequently less prone\nto breaking down in practice, we propose FACT. FACT is the first federated\nmechanism that: (1) eliminates federated free riding by using a penalty system,\n(2) ensures agents provide truthful information by creating a competitive\nenvironment, and (3) encourages agent participation by offering better\nperformance than training alone. Empirically, FACT avoids free-riding when\nagents are untruthful, and reduces agent loss by over 4x.",
        "subjects": [
            "cs.GT",
            "cs.DC",
            "cs.LG",
            "econ.TH"
        ],
        "authors": [
            "Marco Bornstein",
            "Amrit Singh Bedi",
            "Abdirisak Mohamed",
            "Furong Huang"
        ],
        "published": "2024-05-22T17:59:44Z"
    },
    {
        "title": "Implicit gaze research for XR systems",
        "link": "http://arxiv.org/abs/2405.13878v1",
        "abstract": "Although eye-tracking technology is being integrated into more VR and MR\nheadsets, the true potential of eye tracking in enhancing user interactions\nwithin XR settings remains relatively untapped. Presently, one of the most\nprevalent gaze applications in XR is input control; for example, using gaze to\ncontrol a cursor for pointing. However, our eyes evolved primarily for sensory\ninput and understanding of the world around us, and yet few XR applications\nhave leveraged natural gaze behavior to infer and support users' intent and\ncognitive states. Systems that can represent a user's context and interaction\nintent can better support the user by generating contextually relevant content,\nby making the user interface easier to use, by highlighting potential errors,\nand more. This mode of application is not fully taken advantage of in current\ncommercially available XR systems and yet it is likely where we'll find\nparadigm-shifting use cases for eye tracking. In this paper, we elucidate the\nstate-of-the-art applications for eye tracking and propose new research\ndirections to harness its potential fully.",
        "subjects": [
            "cs.HC",
            "cs.ET"
        ],
        "authors": [
            "Naveen Sendhilnathan",
            "Ajoy S. Fernandes",
            "Michael J. Proulx",
            "Tanya R. Jonker"
        ],
        "published": "2024-05-22T17:58:55Z"
    },
    {
        "title": "On connections between k-coloring and Euclidean k-means",
        "link": "http://arxiv.org/abs/2405.13877v1",
        "abstract": "In the Euclidean $k$-means problems we are given as input a set of $n$ points\nin $\\mathbb{R}^d$ and the goal is to find a set of $k$ points $C\\subseteq\n\\mathbb{R}^d$, so as to minimize the sum of the squared Euclidean distances\nfrom each point in $P$ to its closest center in $C$. In this paper, we formally\nexplore connections between the $k$-coloring problem on graphs and the\nEuclidean $k$-means problem. Our results are as follows:\n  $\\bullet$ For all $k\\ge 3$, we provide a simple reduction from the\n$k$-coloring problem on regular graphs to the Euclidean $k$-means problem.\nMoreover, our technique extends to enable a reduction from a structured max-cut\nproblem (which may be considered as a partial 2-coloring problem) to the\nEuclidean $2$-means problem. Thus, we have a simple and alternate proof of the\nNP-hardness of Euclidean 2-means problem.\n  $\\bullet$ In the other direction, we mimic the $O(1.7297^n)$ time algorithm\nof Williams [TCS'05] for the max-cut of problem on $n$ vertices to obtain an\nalgorithm for the Euclidean 2-means problem with the same runtime, improving on\nthe naive exhaustive search running in $2^n\\cdot \\text{poly}(n,d)$ time.\n  $\\bullet$ We prove similar results and connections as above for the Euclidean\n$k$-min-sum problem.",
        "subjects": [
            "cs.CG",
            "cs.CC",
            "cs.DS"
        ],
        "authors": [
            "Enver Aman",
            "Karthik C. S.",
            "Sharath Punna"
        ],
        "published": "2024-05-22T17:58:38Z"
    },
    {
        "title": "On the Inapproximability of Finding Minimum Monitoring Edge-Geodetic\n  Sets",
        "link": "http://arxiv.org/abs/2405.13875v1",
        "abstract": "Given an undirected connected graph $G = (V(G), E(G))$ on $n$ vertices, the\nminimum Monitoring Edge-Geodetic Set (MEG-set) problem asks to find a subset $M\n\\subseteq V(G)$ of minimum cardinality such that, for every edge $e \\in E(G)$,\nthere exist $x,y \\in M$ for which all shortest paths between $x$ and $y$ in $G$\ntraverse $e$.\n  We show that, for any constant $c < \\frac{1}{2}$, no polynomial-time $(c \\log\nn)$-approximation algorithm for the minimum MEG-set problem exists, unless\n$\\mathsf{P} = \\mathsf{NP}$.",
        "subjects": [
            "cs.CC",
            "cs.DS"
        ],
        "authors": [
            "Davide Bil√≤",
            "Giordano Colli",
            "Luca Forlizzi",
            "Stefano Leucci"
        ],
        "published": "2024-05-22T17:57:45Z"
    },
    {
        "title": "Affine-based Deformable Attention and Selective Fusion for Semi-dense\n  Matching",
        "link": "http://arxiv.org/abs/2405.13874v1",
        "abstract": "Identifying robust and accurate correspondences across images is a\nfundamental problem in computer vision that enables various downstream tasks.\nRecent semi-dense matching methods emphasize the effectiveness of fusing\nrelevant cross-view information through Transformer. In this paper, we propose\nseveral improvements upon this paradigm. Firstly, we introduce affine-based\nlocal attention to model cross-view deformations. Secondly, we present\nselective fusion to merge local and global messages from cross attention. Apart\nfrom network structure, we also identify the importance of enforcing spatial\nsmoothness in loss design, which has been omitted by previous works. Based on\nthese augmentations, our network demonstrate strong matching capacity under\ndifferent settings. The full version of our network achieves state-of-the-art\nperformance among semi-dense matching methods at a similar cost to LoFTR, while\nthe slim version reaches LoFTR baseline's performance with only 15% computation\ncost and 18% parameters.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hongkai Chen",
            "Zixin Luo",
            "Yurun Tian",
            "Xuyang Bai",
            "Ziyu Wang",
            "Lei Zhou",
            "Mingmin Zhen",
            "Tian Fang",
            "David McKinnon",
            "Yanghai Tsin",
            "Long Quan"
        ],
        "published": "2024-05-22T17:57:37Z"
    },
    {
        "title": "FiDeLiS: Faithful Reasoning in Large Language Model for Knowledge Graph\n  Question Answering",
        "link": "http://arxiv.org/abs/2405.13873v1",
        "abstract": "While large language models (LLMs) have achieved significant success in\nvarious applications, they often struggle with hallucinations, especially in\nscenarios that require deep and responsible reasoning. These issues could be\npartially mitigate by integrating external knowledge graphs (KG) in LLM\nreasoning. However, the method of their incorporation is still largely\nunexplored. In this paper, we propose a retrieval-exploration interactive\nmethod, FiDelis to handle intermediate steps of reasoning grounded by KGs.\nSpecifically, we propose Path-RAG module for recalling useful intermediate\nknowledge from KG for LLM reasoning. We incorporate the logic and common-sense\nreasoning of LLMs and topological connectivity of KGs into the knowledge\nretrieval process, which provides more accurate recalling performance.\nFurthermore, we propose to leverage deductive reasoning capabilities of LLMs as\na better criterion to automatically guide the reasoning process in a stepwise\nand generalizable manner. Deductive verification serve as precise indicators\nfor when to cease further reasoning, thus avoiding misleading the chains of\nreasoning and unnecessary computation. Extensive experiments show that our\nmethod, as a training-free method with lower computational cost and better\ngenerality outperforms the existing strong baselines in three benchmarks.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Yuan Sui",
            "Yufei He",
            "Nian Liu",
            "Xiaoxin He",
            "Kun Wang",
            "Bryan Hooi"
        ],
        "published": "2024-05-22T17:56:53Z"
    },
    {
        "title": "Image-of-Thought Prompting for Visual Reasoning Refinement in Multimodal\n  Large Language Models",
        "link": "http://arxiv.org/abs/2405.13872v1",
        "abstract": "Recent advancements in Chain-of-Thought (CoT) and related rationale-based\nworks have significantly improved the performance of Large Language Models\n(LLMs) in complex reasoning tasks. With the evolution of Multimodal Large\nLanguage Models (MLLMs), enhancing their capability to tackle complex\nmultimodal reasoning problems is a crucial frontier. However, incorporating\nmultimodal rationales in CoT has yet to be thoroughly investigated. We propose\nthe Image-of-Thought (IoT) prompting method, which helps MLLMs to extract\nvisual rationales step-by-step. Specifically, IoT prompting can automatically\ndesign critical visual information extraction operations based on the input\nimages and questions. Each step of visual information refinement identifies\nspecific visual rationales that support answers to complex visual reasoning\nquestions. Beyond the textual CoT, IoT simultaneously utilizes visual and\ntextual rationales to help MLLMs understand complex multimodal information. IoT\nprompting has improved zero-shot visual reasoning performance across various\nvisual understanding tasks in different MLLMs. Moreover, the step-by-step\nvisual feature explanations generated by IoT prompting elucidate the visual\nreasoning process, aiding in analyzing the cognitive processes of large\nmultimodal models",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "authors": [
            "Qiji Zhou",
            "Ruochen Zhou",
            "Zike Hu",
            "Panzhong Lu",
            "Siyang Gao",
            "Yue Zhang"
        ],
        "published": "2024-05-22T17:56:51Z"
    },
    {
        "title": "FreeCustom: Tuning-Free Customized Image Generation for Multi-Concept\n  Composition",
        "link": "http://arxiv.org/abs/2405.13870v1",
        "abstract": "Benefiting from large-scale pre-trained text-to-image (T2I) generative\nmodels, impressive progress has been achieved in customized image generation,\nwhich aims to generate user-specified concepts. Existing approaches have\nextensively focused on single-concept customization and still encounter\nchallenges when it comes to complex scenarios that involve combining multiple\nconcepts. These approaches often require retraining/fine-tuning using a few\nimages, leading to time-consuming training processes and impeding their swift\nimplementation. Furthermore, the reliance on multiple images to represent a\nsingular concept increases the difficulty of customization. To this end, we\npropose FreeCustom, a novel tuning-free method to generate customized images of\nmulti-concept composition based on reference concepts, using only one image per\nconcept as input. Specifically, we introduce a new multi-reference\nself-attention (MRSA) mechanism and a weighted mask strategy that enables the\ngenerated image to access and focus more on the reference concepts. In\naddition, MRSA leverages our key finding that input concepts are better\npreserved when providing images with context interactions. Experiments show\nthat our method's produced images are consistent with the given concepts and\nbetter aligned with the input text. Our method outperforms or performs on par\nwith other training-based methods in terms of multi-concept composition and\nsingle-concept customization, but is simpler. Codes can be found at\nhttps://github.com/aim-uofa/FreeCustom.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ganggui Ding",
            "Canyu Zhao",
            "Wen Wang",
            "Zhen Yang",
            "Zide Liu",
            "Hao Chen",
            "Chunhua Shen"
        ],
        "published": "2024-05-22T17:53:38Z"
    },
    {
        "title": "Automatically Identifying Local and Global Circuits with Linear\n  Computation Graphs",
        "link": "http://arxiv.org/abs/2405.13868v1",
        "abstract": "Circuit analysis of any certain model behavior is a central task in\nmechanistic interpretability. We introduce our circuit discovery pipeline with\nsparse autoencoders (SAEs) and a variant called skip SAEs. With these two\nmodules inserted into the model, the model's computation graph with respect to\nOV and MLP circuits becomes strictly linear. Our methods do not require linear\napproximation to compute the causal effect of each node. This fine-grained\ngraph enables identifying both end-to-end and local circuits accounting for\neither logits or intermediate features. We can scalably apply this pipeline\nwith a technique called Hierarchical Attribution. We analyze three kind of\ncircuits in GPT2-Small, namely bracket, induction and Indirect Object\nIdentification circuits. Our results reveal new findings underlying existing\ndiscoveries.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "authors": [
            "Xuyang Ge",
            "Fukang Zhu",
            "Wentao Shu",
            "Junxuan Wang",
            "Zhengfu He",
            "Xipeng Qiu"
        ],
        "published": "2024-05-22T17:50:04Z"
    },
    {
        "title": "Scaling-laws for Large Time-series Models",
        "link": "http://arxiv.org/abs/2405.13867v1",
        "abstract": "Scaling laws for large language models (LLMs) have provided useful guidance\non how to train ever larger models for predictable performance gains. Time\nseries forecasting shares a similar sequential structure to language, and is\namenable to large-scale transformer architectures. Here we show that\nfoundational decoder-only time series transformer models exhibit analogous\nscaling-behavior to LLMs, while architectural details (aspect ratio and number\nof heads) have a minimal effect over broad ranges. We assemble a large corpus\nof heterogenous time series data on which to train, and establish, for the\nfirst time, power-law scaling relations with respect to parameter count,\ndataset size, and training compute, spanning five orders of magnitude.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Thomas D. P. Edwards",
            "James Alvey",
            "Justin Alsing",
            "Nam H. Nguyen",
            "Benjamin D. Wandelt"
        ],
        "published": "2024-05-22T17:48:17Z"
    },
    {
        "title": "Koopcon: A new approach towards smarter and less complex learning",
        "link": "http://arxiv.org/abs/2405.13866v1",
        "abstract": "In the era of big data, the sheer volume and complexity of datasets pose\nsignificant challenges in machine learning, particularly in image processing\ntasks. This paper introduces an innovative Autoencoder-based Dataset\nCondensation Model backed by Koopman operator theory that effectively packs\nlarge datasets into compact, information-rich representations. Inspired by the\npredictive coding mechanisms of the human brain, our model leverages a novel\napproach to encode and reconstruct data, maintaining essential features and\nlabel distributions. The condensation process utilizes an autoencoder neural\nnetwork architecture, coupled with Optimal Transport theory and Wasserstein\ndistance, to minimize the distributional discrepancies between the original and\nsynthesized datasets. We present a two-stage implementation strategy: first,\ncondensing the large dataset into a smaller synthesized subset; second,\nevaluating the synthesized data by training a classifier and comparing its\nperformance with a classifier trained on an equivalent subset of the original\ndata. Our experimental results demonstrate that the classifiers trained on\ncondensed data exhibit comparable performance to those trained on the original\ndatasets, thus affirming the efficacy of our condensation model. This work not\nonly contributes to the reduction of computational resources but also paves the\nway for efficient data handling in constrained environments, marking a\nsignificant step forward in data-efficient machine learning.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Vahid Jebraeeli",
            "Bo Jiang",
            "Derya Cansever",
            "Hamid Krim"
        ],
        "published": "2024-05-22T17:47:14Z"
    },
    {
        "title": "ReVideo: Remake a Video with Motion and Content Control",
        "link": "http://arxiv.org/abs/2405.13865v1",
        "abstract": "Despite significant advancements in video generation and editing using\ndiffusion models, achieving accurate and localized video editing remains a\nsubstantial challenge. Additionally, most existing video editing methods\nprimarily focus on altering visual content, with limited research dedicated to\nmotion editing. In this paper, we present a novel attempt to Remake a Video\n(ReVideo) which stands out from existing methods by allowing precise video\nediting in specific areas through the specification of both content and motion.\nContent editing is facilitated by modifying the first frame, while the\ntrajectory-based motion control offers an intuitive user interaction\nexperience. ReVideo addresses a new task involving the coupling and training\nimbalance between content and motion control. To tackle this, we develop a\nthree-stage training strategy that progressively decouples these two aspects\nfrom coarse to fine. Furthermore, we propose a spatiotemporal adaptive fusion\nmodule to integrate content and motion control across various sampling steps\nand spatial locations. Extensive experiments demonstrate that our ReVideo has\npromising performance on several accurate video editing applications, i.e., (1)\nlocally changing video content while keeping the motion constant, (2) keeping\ncontent unchanged and customizing new motion trajectories, (3) modifying both\ncontent and motion trajectories. Our method can also seamlessly extend these\napplications to multi-area editing without specific training, demonstrating its\nflexibility and robustness.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Chong Mou",
            "Mingdeng Cao",
            "Xintao Wang",
            "Zhaoyang Zhang",
            "Ying Shan",
            "Jian Zhang"
        ],
        "published": "2024-05-22T17:46:08Z"
    },
    {
        "title": "Just rotate it! Uncertainty estimation in closed-source models via\n  multiple queries",
        "link": "http://arxiv.org/abs/2405.13864v1",
        "abstract": "We propose a simple and effective method to estimate the uncertainty of\nclosed-source deep neural network image classification models. Given a base\nimage, our method creates multiple transformed versions and uses them to query\nthe top-1 prediction of the closed-source model. We demonstrate significant\nimprovements in the calibration of uncertainty estimates compared to the naive\nbaseline of assigning 100\\% confidence to all predictions. While we initially\nexplore Gaussian perturbations, our empirical findings indicate that natural\ntransformations, such as rotations and elastic deformations, yield even\nbetter-calibrated predictions. Furthermore, through empirical results and a\nstraightforward theoretical analysis, we elucidate the reasons behind the\nsuperior performance of natural transformations over Gaussian noise. Leveraging\nthese insights, we propose a transfer learning approach that further improves\nour calibration results.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Konstantinos Pitas",
            "Julyan Arbel"
        ],
        "published": "2024-05-22T17:45:38Z"
    },
    {
        "title": "Dynamic Model Predictive Shielding for Provably Safe Reinforcement\n  Learning",
        "link": "http://arxiv.org/abs/2405.13863v1",
        "abstract": "Among approaches for provably safe reinforcement learning, Model Predictive\nShielding (MPS) has proven effective at complex tasks in continuous,\nhigh-dimensional state spaces, by leveraging a backup policy to ensure safety\nwhen the learned policy attempts to take risky actions. However, while MPS can\nensure safety both during and after training, it often hinders task progress\ndue to the conservative and task-oblivious nature of backup policies. This\npaper introduces Dynamic Model Predictive Shielding (DMPS), which optimizes\nreinforcement learning objectives while maintaining provable safety. DMPS\nemploys a local planner to dynamically select safe recovery actions that\nmaximize both short-term progress as well as long-term rewards. Crucially, the\nplanner and the neural policy play a synergistic role in DMPS. When planning\nrecovery actions for ensuring safety, the planner utilizes the neural policy to\nestimate long-term rewards, allowing it to observe beyond its short-term\nplanning horizon. Conversely, the neural policy under training learns from the\nrecovery plans proposed by the planner, converging to policies that are both\nhigh-performing and safe in practice. This approach guarantees safety during\nand after training, with bounded recovery regret that decreases exponentially\nwith planning horizon depth. Experimental results demonstrate that DMPS\nconverges to policies that rarely require shield interventions after training\nand achieve higher rewards compared to several state-of-the-art baselines.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Arko Banerjee",
            "Kia Rahmani",
            "Joydeep Biswas",
            "Isil Dillig"
        ],
        "published": "2024-05-22T17:44:07Z"
    },
    {
        "title": "Transformers Learn Temporal Difference Methods for In-Context\n  Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.13861v1",
        "abstract": "In-context learning refers to the learning ability of a model during\ninference time without adapting its parameters. The input (i.e., prompt) to the\nmodel (e.g., transformers) consists of both a context (i.e., instance-label\npairs) and a query instance. The model is then able to output a label for the\nquery instance according to the context during inference. A possible\nexplanation for in-context learning is that the forward pass of (linear)\ntransformers implements iterations of gradient descent on the instance-label\npairs in the context. In this paper, we prove by construction that transformers\ncan also implement temporal difference (TD) learning in the forward pass, a\nphenomenon we refer to as in-context TD. We demonstrate the emergence of\nin-context TD after training the transformer with a multi-task TD algorithm,\naccompanied by theoretical analysis. Furthermore, we prove that transformers\nare expressive enough to implement many other policy evaluation algorithms in\nthe forward pass, including residual gradient, TD with eligibility trace, and\naverage-reward TD.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Jiuqi Wang",
            "Ethan Blaser",
            "Hadi Daneshmand",
            "Shangtong Zhang"
        ],
        "published": "2024-05-22T17:38:16Z"
    },
    {
        "title": "MAGIC: Map-Guided Few-Shot Audio-Visual Acoustics Modeling",
        "link": "http://arxiv.org/abs/2405.13860v1",
        "abstract": "Few-shot audio-visual acoustics modeling seeks to synthesize the room impulse\nresponse in arbitrary locations with few-shot observations. To sufficiently\nexploit the provided few-shot data for accurate acoustic modeling, we present a\n*map-guided* framework by constructing acoustic-related visual semantic feature\nmaps of the scenes. Visual features preserve semantic details related to sound\nand maps provide explicit structural regularities of sound propagation, which\nare valuable for modeling environment acoustics. We thus extract pixel-wise\nsemantic features derived from observations and project them into a top-down\nmap, namely the **observation semantic map**. This map contains the relative\npositional information among points and the semantic feature information\nassociated with each point. Yet, limited information extracted by few-shot\nobservations on the map is not sufficient for understanding and modeling the\nwhole scene. We address the challenge by generating a **scene semantic map**\nvia diffusing features and anticipating the observation semantic map. The scene\nsemantic map then interacts with echo encoding by a transformer-based\nencoder-decoder to predict RIR for arbitrary speaker-listener query pairs.\nExtensive experiments on Matterport3D and Replica dataset verify the efficacy\nof our framework.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Diwei Huang",
            "Kunyang Lin",
            "Peihao Chen",
            "Qing Du",
            "Mingkui Tan"
        ],
        "published": "2024-05-22T17:35:15Z"
    },
    {
        "title": "QGait: Toward Accurate Quantization for Gait Recognition with Binarized\n  Input",
        "link": "http://arxiv.org/abs/2405.13859v1",
        "abstract": "Existing deep learning methods have made significant progress in gait\nrecognition. Typically, appearance-based models binarize inputs into silhouette\nsequences. However, mainstream quantization methods prioritize minimizing task\nloss over quantization error, which is detrimental to gait recognition with\nbinarized inputs. Minor variations in silhouette sequences can be diminished in\nthe network's intermediate layers due to the accumulation of quantization\nerrors. To address this, we propose a differentiable soft quantizer, which\nbetter simulates the gradient of the round function during backpropagation.\nThis enables the network to learn from subtle input perturbations. However, our\ntheoretical analysis and empirical studies reveal that directly applying the\nsoft quantizer can hinder network convergence. We further refine the training\nstrategy to ensure convergence while simulating quantization errors.\nAdditionally, we visualize the distribution of outputs from different samples\nin the feature space and observe significant changes compared to the full\nprecision network, which harms performance. Based on this, we propose an\nInter-class Distance-guided Distillation (IDD) strategy to preserve the\nrelative distance between the embeddings of samples with different labels.\nExtensive experiments validate the effectiveness of our approach, demonstrating\nstate-of-the-art accuracy across various settings and datasets. The code will\nbe made publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Senmao Tian",
            "Haoyu Gao",
            "Gangyi Hong",
            "Shuyun Wang",
            "JingJie Wang",
            "Xin Yu",
            "Shunli Zhang"
        ],
        "published": "2024-05-22T17:34:18Z"
    },
    {
        "title": "Carbon Connect: An Ecosystem for Sustainable Computing",
        "link": "http://arxiv.org/abs/2405.13858v1",
        "abstract": "Computing is at a moment of profound opportunity. Emerging applications --\nsuch as capable artificial intelligence, immersive virtual realities, and\npervasive sensor systems -- drive unprecedented demand for computer. Despite\nrecent advances toward net zero carbon emissions, the computing industry's\ngross energy usage continues to rise at an alarming rate, outpacing the growth\nof new energy installations and renewable energy deployments. A shift towards\nsustainability is needed to spark a transformation in how computer systems are\nmanufactured, allocated, and consumed.\n  Carbon Connect envisions coordinated research thrusts that produce design and\nmanagement strategies for sustainable, next-generation computer systems. These\nstrategies must flatten and then reverse growth trajectories for computing\npower and carbon for society's most rapidly growing applications such as\nartificial intelligence and virtual spaces. We will require accurate models for\ncarbon accounting in computing technology. For embodied carbon, we must\nre-think conventional design strategies -- over-provisioned monolithic servers,\nfrequent hardware refresh cycles, custom silicon -- and adopt life-cycle design\nstrategies that more effectively reduce, reuse and recycle hardware at scale.\nFor operational carbon, we must not only embrace renewable energy but also\ndesign systems to use that energy more efficiently. Finally, new hardware\ndesign and management strategies must be cognizant of economic policy and\nregulatory landscape, aligning private initiatives with societal goals. Many of\nthese broader goals will require computer scientists to develop deep, enduring\ncollaborations with researchers in economics, law, and industrial ecology to\nspark change in broader practice.",
        "subjects": [
            "cs.DC",
            "cs.AR",
            "cs.ET",
            "cs.LG"
        ],
        "authors": [
            "Benjamin C. Lee",
            "David Brooks",
            "Arthur van Benthem",
            "Udit Gupta",
            "Gage Hills",
            "Vincent Liu",
            "Benjamin Pierce",
            "Christopher Stewart",
            "Emma Strubell",
            "Gu-Yeon Wei",
            "Adam Wierman",
            "Yuan Yao",
            "Minlan Yu"
        ],
        "published": "2024-05-22T17:33:51Z"
    },
    {
        "title": "What Do Privacy Advertisements Communicate to Consumers?",
        "link": "http://arxiv.org/abs/2405.13857v1",
        "abstract": "When companies release marketing materials aimed at promoting their privacy\npractices or highlighting specific privacy features, what do they actually\ncommunicate to consumers? In this paper, we explore the impact of privacy\nmarketing materials on: (1) consumers' attitude towards the organizations\nproviding the campaigns, (2) overall privacy awareness, and (3) the\nactionability of suggested privacy advice. To this end, we investigated the\nimpact of four privacy advertising videos and one privacy game published by\nfive different technology companies. We conducted 24 semi-structured interviews\nwith participants randomly assigned to view one or two of the videos or play\nthe game. Our findings suggest that awareness of privacy features can\ncontribute to positive perceptions of a company or its products. The ads we\ntested were more successful in communicating the advertised privacy features\nthan the game we tested. We observed that advertising a single privacy feature\nusing a single metaphor in a short ad increased awareness of the advertised\nfeature. The game failed to communicate privacy features or motivate study\nparticipants to use the features. Our results also suggest that privacy\ncampaigns can be useful for raising awareness about privacy features and\nimproving brand image, but may not be the most effective way to teach viewers\nhow to use privacy features.",
        "subjects": [
            "cs.CR",
            "cs.CY",
            "cs.HC"
        ],
        "authors": [
            "Xiaoxin Shen",
            "Eman Alashwali",
            "Lorrie Faith Cranor"
        ],
        "published": "2024-05-22T17:32:04Z"
    },
    {
        "title": "On the dynamics of convolutional recurrent neural networks near their\n  critical point",
        "link": "http://arxiv.org/abs/2405.13854v1",
        "abstract": "We examine the dynamical properties of a single-layer convolutional recurrent\nnetwork with a smooth sigmoidal activation function, for small values of the\ninputs and when the convolution kernel is unitary, so all eigenvalues lie\nexactly at the unit circle. Such networks have a variety of hallmark\nproperties: the outputs depend on the inputs via compressive nonlinearities\nsuch as cubic roots, and both the timescales of relaxation and the\nlength-scales of signal propagation depend sensitively on the inputs as power\nlaws, both diverging as the input to 0. The basic dynamical mechanism is that\ninputs to the network generate ongoing activity, which in turn controls how\nadditional inputs or signals propagate spatially or attenuate in time. We\npresent analytical solutions for the steady states when the network is forced\nwith a single oscillation and when a background value creates a steady state of\nongoing activity, and derive the relationships shaping the value of the\ntemporal decay and spatial propagation length as a function of this background\nvalue.",
        "subjects": [
            "cond-mat.stat-mech",
            "cs.LG",
            "q-bio.NC"
        ],
        "authors": [
            "Aditi Chandra",
            "Marcelo O. Magnasco"
        ],
        "published": "2024-05-22T17:29:12Z"
    },
    {
        "title": "Predicting long time contributors with knowledge units of programming\n  languages: an empirical study",
        "link": "http://arxiv.org/abs/2405.13852v1",
        "abstract": "Predicting potential long-time contributors (LTCs) early allows project\nmaintainers to effectively allocate resources and mentoring to enhance their\ndevelopment and retention. Mapping programming language expertise to developers\nand characterizing projects in terms of how they use programming languages can\nhelp identify developers who are more likely to become LTCs. However, prior\nstudies on predicting LTCs do not consider programming language skills. This\npaper reports an empirical study on the usage of knowledge units (KUs) of the\nJava programming language to predict LTCs. A KU is a cohesive set of key\ncapabilities that are offered by one or more building blocks of a given\nprogramming language. We build a prediction model called KULTC, which leverages\nKU-based features along five different dimensions. We detect and analyze KUs\nfrom the studied 75 Java projects (353K commits and 168K pull requests) as well\nas 4,219 other Java projects in which the studied developers previously worked\n(1.7M commits). We compare the performance of KULTC with the state-of-the-art\nmodel, which we call BAOLTC. Even though KULTC focuses exclusively on the\nprogramming language perspective, KULTC achieves a median AUC of at least 0.75\nand significantly outperforms BAOLTC. Combining the features of KULTC with the\nfeatures of BAOLTC results in an enhanced model (KULTC+BAOLTC) that\nsignificantly outperforms BAOLTC with a normalized AUC improvement of 16.5%.\nOur feature importance analysis with SHAP reveals that developer expertise in\nthe studied project is the most influential feature dimension for predicting\nLTCs. Finally, we develop a cost-effective model (KULTC_DEV_EXP+BAOLTC) that\nsignificantly outperforms BAOLTC. These encouraging results can be helpful to\nresearchers who wish to further study the developers' engagement/retention to\nFLOSS projects or build models for predicting LTCs.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Md Ahasanuzzaman",
            "Gustavo A. Oliva",
            "Ahmed E. Hassan"
        ],
        "published": "2024-05-22T17:28:06Z"
    },
    {
        "title": "Enhancing lattice kinetic schemes for fluid dynamics with\n  Lattice-Equivariant Neural Networks",
        "link": "http://arxiv.org/abs/2405.13850v1",
        "abstract": "We present a new class of equivariant neural networks, hereby dubbed\nLattice-Equivariant Neural Networks (LENNs), designed to satisfy local\nsymmetries of a lattice structure. Our approach develops within a recently\nintroduced framework aimed at learning neural network-based surrogate models\nLattice Boltzmann collision operators. Whenever neural networks are employed to\nmodel physical systems, respecting symmetries and equivariance properties has\nbeen shown to be key for accuracy, numerical stability, and performance.\n  Here, hinging on ideas from group representation theory, we define trainable\nlayers whose algebraic structure is equivariant with respect to the symmetries\nof the lattice cell. Our method naturally allows for efficient implementations,\nboth in terms of memory usage and computational costs, supporting scalable\ntraining/testing for lattices in two spatial dimensions and higher, as the size\nof symmetry group grows. We validate and test our approach considering 2D and\n3D flowing dynamics, both in laminar and turbulent regimes. We compare with\ngroup averaged-based symmetric networks and with plain, non-symmetric,\nnetworks, showing how our approach unlocks the (a-posteriori) accuracy and\ntraining stability of the former models, and the train/inference speed of the\nlatter networks (LENNs are about one order of magnitude faster than\ngroup-averaged networks in 3D). Our work opens towards practical utilization of\nmachine learning-augmented Lattice Boltzmann CFD in real-world simulations.",
        "subjects": [
            "physics.comp-ph",
            "cs.LG",
            "physics.flu-dyn"
        ],
        "authors": [
            "Giulio Ortali",
            "Alessandro Gabbana",
            "Imre Atmodimedjo",
            "Alessandro Corbetta"
        ],
        "published": "2024-05-22T17:23:15Z"
    },
    {
        "title": "Maximum Manifold Capacity Representations in State Representation\n  Learning",
        "link": "http://arxiv.org/abs/2405.13848v1",
        "abstract": "The expanding research on manifold-based self-supervised learning (SSL)\nbuilds on the manifold hypothesis, which suggests that the inherent complexity\nof high-dimensional data can be unraveled through lower-dimensional manifold\nembeddings. Capitalizing on this, DeepInfomax with an unbalanced atlas (DIM-UA)\nhas emerged as a powerful tool and yielded impressive results for state\nrepresentations in reinforcement learning. Meanwhile, Maximum Manifold Capacity\nRepresentation (MMCR) presents a new frontier for SSL by optimizing class\nseparability via manifold compression. However, MMCR demands extensive input\nviews, resulting in significant computational costs and protracted pre-training\ndurations. Bridging this gap, we present an innovative integration of MMCR into\nexisting SSL methods, incorporating a discerning regularization strategy that\nenhances the lower bound of mutual information. We also propose a novel state\nrepresentation learning method extending DIM-UA, embedding a nuclear norm loss\nto enforce manifold consistency robustly. On experimentation with the Atari\nAnnotated RAM Interface, our method improves DIM-UA significantly with the same\nnumber of target encoding dimensions. The mean F1 score averaged over\ncategories is 78% compared to 75% of DIM-UA. There are also compelling gains\nwhen implementing SimCLR and Barlow Twins. This supports our SSL innovation as\na paradigm shift, enabling more nuanced high-dimensional data representations.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Li Meng",
            "Morten Goodwin",
            "Anis Yazidi",
            "Paal Engelstad"
        ],
        "published": "2024-05-22T17:19:30Z"
    },
    {
        "title": "AI-Protected Blockchain-based IoT environments: Harnessing the Future of\n  Network Security and Privacy",
        "link": "http://arxiv.org/abs/2405.13847v1",
        "abstract": "Integrating blockchain technology with the Internet of Things offers\ntransformative possibilities for enhancing network security and privacy in the\ncontemporary digital landscape, where interconnected devices and expansive\nnetworks are ubiquitous. This paper explores the pivotal role of artificial\nintelligence in bolstering blockchain-enabled IoT systems, potentially marking\na significant leap forward in safeguarding data integrity and confidentiality\nacross networks. Blockchain technology provides a decentralized and immutable\nledger, ideal for the secure management of device identities and transactions\nin IoT networks. When coupled with AI, these systems gain the ability to not\nonly automate and optimize security protocols but also adaptively respond to\nnew and evolving cyber threats. This dual capability enhances the resilience of\nnetworks against cyber-attacks, a critical consideration as IoT devices\nincreasingly permeate critical infrastructures. The synergy between AI and\nblockchain in IoT is profound. AI algorithms can analyze vast amounts of data\nfrom IoT devices to detect patterns and anomalies that may signify security\nbreaches. Concurrently, blockchain can ensure that data records are\ntamper-proof, enhancing the reliability of AI-driven security measures.\nMoreover, this research evaluates the implications of AI-enhanced blockchain\nsystems on privacy protection within IoT networks. IoT devices often collect\nsensitive personal data, making privacy a paramount concern. AI can facilitate\nthe development of new protocols that ensure data privacy and user anonymity\nwithout compromising the functionality of IoT systems. Through comprehensive\nanalysis and case studies, this paper aims to provide an in-depth understanding\nof how AI-enhanced blockchain technology can revolutionize network security and\nprivacy in IoT environments.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Ali Mohammadi Ruzbahani"
        ],
        "published": "2024-05-22T17:14:19Z"
    },
    {
        "title": "Regression Trees Know Calculus",
        "link": "http://arxiv.org/abs/2405.13846v1",
        "abstract": "Regression trees have emerged as a preeminent tool for solving real-world\nregression problems due to their ability to deal with nonlinearities,\ninteraction effects and sharp discontinuities. In this article, we rather study\nregression trees applied to well-behaved, differentiable functions, and\ndetermine the relationship between node parameters and the local gradient of\nthe function being approximated. We find a simple estimate of the gradient\nwhich can be efficiently computed using quantities exposed by popular tree\nlearning libraries. This allows the tools developed in the context of\ndifferentiable algorithms, like neural nets and Gaussian processes, to be\ndeployed to tree-based models. To demonstrate this, we study measures of model\nsensitivity defined in terms of integrals of gradients and demonstrate how to\ncompute them for regression trees using the proposed gradient estimates.\nQuantitative and qualitative numerical experiments reveal the capability of\ngradients estimated by regression trees to improve predictive analysis, solve\ntasks in uncertainty quantification, and provide interpretation of model\nbehavior.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Nathan Wycoff"
        ],
        "published": "2024-05-22T17:14:03Z"
    },
    {
        "title": "Semantic Density: Uncertainty Quantification in Semantic Space for Large\n  Language Models",
        "link": "http://arxiv.org/abs/2405.13845v1",
        "abstract": "With the widespread application of Large Language Models (LLMs) to various\ndomains, concerns regarding the trustworthiness of LLMs in safety-critical\nscenarios have been raised, due to their unpredictable tendency to hallucinate\nand generate misinformation. Existing LLMs do not have an inherent\nfunctionality to provide the users with an uncertainty metric for each response\nit generates, making it difficult to evaluate trustworthiness. Although a\nnumber of works aim to develop uncertainty quantification methods for LLMs,\nthey have fundamental limitations, such as being restricted to classification\ntasks, requiring additional training and data, considering only lexical instead\nof semantic information, and being prompt-wise but not response-wise. A new\nframework is proposed in this paper to address these issues. Semantic density\nextracts uncertainty information for each response from a probability\ndistribution perspective in semantic space. It has no restriction on task types\nand is \"off-the-shelf\" for new models and tasks. Experiments on seven\nstate-of-the-art LLMs, including the latest Llama 3 and Mixtral-8x22B models,\non four free-form question-answering benchmarks demonstrate the superior\nperformance and robustness of semantic density compared to prior approaches.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Xin Qiu",
            "Risto Miikkulainen"
        ],
        "published": "2024-05-22T17:13:49Z"
    },
    {
        "title": "Hyperspectral Image Reconstruction for Predicting Chick Embryo Mortality\n  Towards Advancing Egg and Hatchery Industry",
        "link": "http://arxiv.org/abs/2405.13843v1",
        "abstract": "As the demand for food surges and the agricultural sector undergoes a\ntransformative shift towards sustainability and efficiency, the need for\nprecise and proactive measures to ensure the health and welfare of livestock\nbecomes paramount. In the context of the broader agricultural landscape\noutlined, the application of Hyperspectral Imaging (HSI) takes on profound\nsignificance. HSI has emerged as a cutting-edge, non-destructive technique for\nfast and accurate egg quality analysis, including the detection of chick embryo\nmortality. However, the high cost and operational complexity compared to\nconventional RGB imaging are significant bottlenecks in the widespread adoption\nof HSI technology. To overcome these hurdles and unlock the full potential of\nHSI, a promising solution is hyperspectral image reconstruction from standard\nRGB images. This study aims to reconstruct hyperspectral images from RGB images\nfor non-destructive early prediction of chick embryo mortality. Firstly, the\nperformance of different image reconstruction algorithms, such as HRNET, MST++,\nRestormer, and EDSR were compared to reconstruct the hyperspectral images of\nthe eggs in the early incubation period. Later, the reconstructed spectra were\nused to differentiate live from dead chick-producing eggs using the XGBoost and\nRandom Forest classification methods. Among the reconstruction methods, HRNET\nshowed impressive reconstruction performance with MRAE of 0.0955, RMSE of\n0.0159, and PSNR of 36.79 dB. This study motivated that harnessing imaging\ntechnology integrated with smart sensors and data analytics has the potential\nto improve automation, enhance biosecurity, and optimize resource management\ntowards sustainable agriculture 4.0.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Md. Toukir Ahmed",
            "Md Wadud Ahmed",
            "Ocean Monjur",
            "Jason Lee Emmert",
            "Girish Chowdhary",
            "Mohammed Kamruzzaman"
        ],
        "published": "2024-05-22T17:12:15Z"
    },
    {
        "title": "Robot Explanation Identity",
        "link": "http://arxiv.org/abs/2405.13841v1",
        "abstract": "To bring robots into human everyday life, their capacity for social\ninteraction must increase. One way for robots to acquire social skills is by\nassigning them the concept of identity. This research focuses on the concept of\n\\textit{Explanation Identity} within the broader context of robots' roles in\nsociety, particularly their ability to interact socially and explain decisions.\nExplanation Identity refers to the combination of characteristics and\napproaches robots use to justify their actions to humans. Drawing from\ndifferent technical and social disciplines, we introduce Explanation Identity\nas a multidisciplinary concept and discuss its importance in Human-Robot\nInteraction. Our theoretical framework highlights the necessity for robots to\nadapt their explanations to the user's context, demonstrating empathy and\nethical integrity. This research emphasizes the dynamic nature of robot\nidentity and guides the integration of explanation capabilities in social\nrobots, aiming to improve user engagement and acceptance.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Amar Halilovic",
            "Senka Krivic"
        ],
        "published": "2024-05-22T17:11:19Z"
    },
    {
        "title": "Diffusing Winding Gradients (DWG): A Parallel and Scalable Method for 3D\n  Reconstruction from Unoriented Point Clouds",
        "link": "http://arxiv.org/abs/2405.13839v1",
        "abstract": "This paper presents a method for reconstructing watertight 3D surfaces from\nunoriented point clouds. Starting with randomly initialized normals, the method\niteratively refines each normal by diffusing the gradient of the generalized\nwinding number (GWN) field. Upon convergence, the target surface is extracted\nusing the standard Marching Cubes algorithm. Our method is conceptually simple,\neasy to implement, and does not require numerical solvers, which distinguishes\nit from existing approaches. Designed for parallelization and scalability, it\nefficiently handles large-scale models on both CPUs and GPUs. Experimental\nresults demonstrate that our method outperforms all existing methods in\nreconstructing from unoriented point clouds, particularly in terms of runtime\nperformance. On large-scale models with 10 to 20 million points, our CUDA\nimplementation on an NVIDIA GTX 4090 GPU is typically 30-100x faster than iPSR,\nthe leading sequential method tested on a high-end PC with an Intel i9 CPU.\nFurthermore, our approach exhibits superior robustness against noise and\neffectively handles models with thin structures, surpassing existing methods.\nWe will make the source code publicly available to encourage further research\nand applications.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Weizhou Liu",
            "Jiaze Li",
            "Xuhui Chen",
            "Fei Hou",
            "Shiqing Xin",
            "Xingce Wang",
            "Zhongke Wu",
            "Chen Qian",
            "Ying He"
        ],
        "published": "2024-05-22T17:04:54Z"
    },
    {
        "title": "Federated Learning in Healthcare: Model Misconducts, Security,\n  Challenges, Applications, and Future Research Directions -- A Systematic\n  Review",
        "link": "http://arxiv.org/abs/2405.13832v1",
        "abstract": "Data privacy has become a major concern in healthcare due to the increasing\ndigitization of medical records and data-driven medical research. Protecting\nsensitive patient information from breaches and unauthorized access is\ncritical, as such incidents can have severe legal and ethical complications.\nFederated Learning (FL) addresses this concern by enabling multiple healthcare\ninstitutions to collaboratively learn from decentralized data without sharing\nit. FL's scope in healthcare covers areas such as disease prediction, treatment\ncustomization, and clinical trial research. However, implementing FL poses\nchallenges, including model convergence in non-IID (independent and identically\ndistributed) data environments, communication overhead, and managing\nmulti-institutional collaborations. A systematic review of FL in healthcare is\nnecessary to evaluate how effectively FL can provide privacy while maintaining\nthe integrity and usability of medical data analysis. In this study, we analyze\nexisting literature on FL applications in healthcare. We explore the current\nstate of model security practices, identify prevalent challenges, and discuss\npractical applications and their implications. Additionally, the review\nhighlights promising future research directions to refine FL implementations,\nenhance data security protocols, and expand FL's use to broader healthcare\napplications, which will benefit future researchers and practitioners.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Md Shahin Ali",
            "Md Manjurul Ahsan",
            "Lamia Tasnim",
            "Sadia Afrin",
            "Koushik Biswas",
            "Md Maruf Hossain",
            "Md Mahfuz Ahmed",
            "Ronok Hashan",
            "Md Khairul Islam",
            "Shivakumar Raman"
        ],
        "published": "2024-05-22T16:59:50Z"
    },
    {
        "title": "Application of Internet of Energy in Smart Grids Using Deep\n  Reinforcement Learning and Convolutional Neural Network",
        "link": "http://arxiv.org/abs/2405.13831v1",
        "abstract": "The increasing demand for electricity, coupled with the rise in greenhouse\ngas emissions, necessitates the integration of Renewable Energy Sources (RESs)\ninto power grids. However, the fluctuating nature of RESs introduces new\nchallenges in energy management. The Internet of Energy (IoE) framework\nprovides a solution by enabling real-time monitoring, dynamic scheduling, and\nenhanced energy routing. This paper proposes a comprehensive approach to\noptimizing energy management in smart grids using Deep Reinforcement Learning\n(DRL) and Convolutional Neural Networks (CNN). The research focuses on three\nmain objectives: optimizing operation scheduling, improving energy routing, and\nenhancing cyber-physical security. A DRL-based scheduling algorithm is\ndeveloped to manage energy components effectively, while an optimized energy\nrouting algorithm ensures efficient electricity flow. Additionally, a security\nframework utilizing Long Short-Term Memory (LSTM) and CNN is proposed to detect\nFalse Data Injection (FDI) attacks and electricity theft. The proposed methods\naim to improve energy efficiency, reduce costs, and ensure the security of\nIoE-enabled power systems. This research bridges existing gaps by addressing\nthe dynamic and complex nature of modern energy networks. The integration of\nthese advanced technologies promises significant advancements in the\nreliability and efficiency of smart grids. Ultimately, this work contributes to\nthe development of a sustainable and secure energy future.",
        "subjects": [
            "cs.CE"
        ],
        "authors": [
            "Ali Mohammadi Ruzbahani"
        ],
        "published": "2024-05-22T16:59:06Z"
    },
    {
        "title": "Babysit A Language Model From Scratch: Interactive Language Learning by\n  Trials and Demonstrations",
        "link": "http://arxiv.org/abs/2405.13828v1",
        "abstract": "Humans are efficient language learners and inherently social creatures. Our\nlanguage development is largely shaped by our social interactions, for example,\nthe demonstration and feedback from caregivers. Contrary to human language\nlearning, recent advancements in large language models have primarily adopted a\nnon-interactive training paradigm, and refined pre-trained models through\nfeedback afterward. In this work, we aim to examine how corrective feedback\nfrom interactions influences neural language acquisition from the ground up\nthrough systematically controlled experiments, assessing whether it contributes\nto learning efficiency in language models. We introduce a\ntrial-and-demonstration (TnD) learning framework that incorporates three\ncomponents: student trials, teacher demonstrations, and a reward conditioned on\nlanguage competence at various developmental stages. Our experiments reveal\nthat the TnD approach accelerates word acquisition for student models of equal\nand smaller numbers of parameters, and we highlight the significance of both\ntrials and demonstrations. We further show that the teacher's choices of words\ninfluence students' word-specific learning efficiency, and a\npractice-makes-perfect effect is evident by a strong correlation between the\nfrequency of words in trials and their respective learning curves. Our findings\nsuggest that interactive language learning, with teacher demonstrations and\nstudent trials, can facilitate efficient word learning in language models.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Ziqiao Ma",
            "Zekun Wang",
            "Joyce Chai"
        ],
        "published": "2024-05-22T16:57:02Z"
    },
    {
        "title": "A Reliable Target Evolved Node B Selection Scheme in LTE-Advanced\n  Handover",
        "link": "http://arxiv.org/abs/2405.13827v1",
        "abstract": "The problem of improving the handover performance in Long Term\nEvolution-Advanced (LTE-A) networks has not been fully solved yet.\nTraditionally, the selection of the target Evolved Node B (TeNB) in the\nhandover procedure is based on the signal strength measurements, which may not\nproduce a reliable handover. A reliable handover method may reduce the\ninstances of unstable or frequent handovers that otherwise waste network\nresources. The signal strength measurement process is inherently time consuming\nas the user equipment (UE) has to measure multiple neighboring eNB (NeNB)\nfrequencies in each measurement period. An efficient handover method is\nrequired to improve the overall performance of such systems. In this paper we\npropose a reliable and fast TeNB selection scheme for LTE-A handover. The\nproposed scheme outperforms the existing LTE-A handover methods. The improved\nperformance is achieved by selecting the TeNB based on some three independent\nparameters, namely orientation matching (OM), current load (CL), and the\nreceived signal strengths. An UE essentially measures only the NeNBs\nshortlisted based on OM and CL; thus measurement time is reduced considerably\nleading to a reduction of overall handover time. The performance of the\nproposed scheme is validated by simulation.",
        "subjects": [
            "cs.ET",
            "cs.NI"
        ],
        "authors": [
            "Sayan Kumar Ray",
            "NZ Jhanjhi",
            "Akbar Hossain"
        ],
        "published": "2024-05-22T16:56:13Z"
    },
    {
        "title": "GMMFormer v2: An Uncertainty-aware Framework for Partially Relevant\n  Video Retrieval",
        "link": "http://arxiv.org/abs/2405.13824v1",
        "abstract": "Given a text query, partially relevant video retrieval (PRVR) aims to\nretrieve untrimmed videos containing relevant moments. Due to the lack of\nmoment annotations, the uncertainty lying in clip modeling and text-clip\ncorrespondence leads to major challenges. Despite the great progress, existing\nsolutions either sacrifice efficiency or efficacy to capture varying and\nuncertain video moments. What's worse, few methods have paid attention to the\ntext-clip matching pattern under such uncertainty, exposing the risk of\nsemantic collapse. To address these issues, we present GMMFormer v2, an\nuncertainty-aware framework for PRVR. For clip modeling, we improve a strong\nbaseline GMMFormer with a novel temporal consolidation module upon multi-scale\ncontextual features, which maintains efficiency and improves the perception for\nvarying moments. To achieve uncertainty-aware text-clip matching, we upgrade\nthe query diverse loss in GMMFormer to facilitate fine-grained uniformity and\npropose a novel optimal matching loss for fine-grained text-clip alignment.\nTheir collaboration alleviates the semantic collapse phenomenon and neatly\npromotes accurate correspondence between texts and moments. We conduct\nextensive experiments and ablation studies on three PRVR benchmarks,\ndemonstrating remarkable improvement of GMMFormer v2 compared to the past SOTA\ncompetitor and the versatility of uncertainty-aware text-clip matching for\nPRVR. Code is available at\n\\url{https://github.com/huangmozhi9527/GMMFormer_v2}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yuting Wang",
            "Jinpeng Wang",
            "Bin Chen",
            "Tao Dai",
            "Ruisheng Luo",
            "Shu-Tao Xia"
        ],
        "published": "2024-05-22T16:55:31Z"
    },
    {
        "title": "Normalizing Basis Functions: Approximate Stationary Models for Large\n  Spatial Data",
        "link": "http://arxiv.org/abs/2405.13821v1",
        "abstract": "In geostatistics, traditional spatial models often rely on the Gaussian\nProcess (GP) to fit stationary covariances to data. It is well known that this\napproach becomes computationally infeasible when dealing with large data\nvolumes, necessitating the use of approximate methods. A powerful class of\nmethods approximate the GP as a sum of basis functions with random\ncoefficients. Although this technique offers computational efficiency, it does\nnot inherently guarantee a stationary covariance. To mitigate this issue, the\nbasis functions can be \"normalized\" to maintain a constant marginal variance,\navoiding unwanted artifacts and edge effects. This allows for the fitting of\nnearly stationary models to large, potentially non-stationary datasets,\nproviding a rigorous base to extend to more complex problems. Unfortunately,\nthe process of normalizing these basis functions is computationally demanding.\nTo address this, we introduce two fast and accurate algorithms to the\nnormalization step, allowing for efficient prediction on fine grids. The\npractical value of these algorithms is showcased in the context of a spatial\nanalysis on a large dataset, where significant computational speedups are\nachieved. While implementation and testing are done specifically within the\nLatticeKrig framework, these algorithms can be adapted to other basis function\nmethods operating on regular grids.",
        "subjects": [
            "stat.CO",
            "cs.NA",
            "math.NA",
            "stat.AP"
        ],
        "authors": [
            "Antony Sikorski",
            "Daniel McKenzie",
            "Douglas Nychka"
        ],
        "published": "2024-05-22T16:52:29Z"
    },
    {
        "title": "Towards Comprehensive and Efficient Post Safety Alignment of Large\n  Language Models via Safety Patching",
        "link": "http://arxiv.org/abs/2405.13820v1",
        "abstract": "Safety alignment of large language models (LLMs) has been gaining increasing\nattention. However, current safety-aligned LLMs suffer from the fragile and\nimbalanced safety mechanisms, which can still be induced to generate unsafe\nresponses, exhibit over-safety by rejecting safe user inputs, and fail to\npreserve general utility after safety alignment. To this end, we propose a\nnovel post safety alignment (PSA) method to address these inherent and emerging\nsafety challenges, including safety enhancement, over-safety mitigation, and\nutility preservation. In specific, we introduce \\textsc{SafePatching}, a novel\nframework for comprehensive and efficient PSA, where two distinct safety\npatches are developed on the harmful data to enhance safety and mitigate\nover-safety concerns, and then seamlessly integrated into the target LLM\nbackbone without compromising its utility. Extensive experiments show that\n\\textsc{SafePatching} achieves a more comprehensive and efficient PSA than\nbaseline methods. It even enhances the utility of the backbone, further\noptimizing the balance between being helpful and harmless in current aligned\nLLMs. Also, \\textsc{SafePatching} demonstrates its superiority in continual PSA\nscenarios.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Weixiang Zhao",
            "Yulin Hu",
            "Zhuojun Li",
            "Yang Deng",
            "Yanyan Zhao",
            "Bing Qin",
            "Tat-Seng Chua"
        ],
        "published": "2024-05-22T16:51:07Z"
    },
    {
        "title": "Identifiability of Differential-Algebraic Systems",
        "link": "http://arxiv.org/abs/2405.13818v1",
        "abstract": "Data-driven modeling of dynamical systems often faces numerous data-related\nchallenges. A fundamental requirement is the existence of a unique set of\nparameters for a chosen model structure, an issue commonly referred to as\nidentifiability. Although this problem is well studied for ordinary\ndifferential equations (ODEs), few studies have focused on the more general\nclass of systems described by differential-algebraic equations (DAEs). Examples\nof DAEs include dynamical systems with algebraic equations representing\nconservation laws or approximating fast dynamics. This work introduces a novel\nidentifiability test for models characterized by nonlinear DAEs. Unlike\nprevious approaches, our test only requires prior knowledge of the system\nequations and does not need nonlinear transformation, index reduction, or\nnumerical integration of the DAEs. We employed our identifiability analysis\nacross a diverse range of DAE models, illustrating how system identifiability\ndepends on the choices of sensors, experimental conditions, and model\nstructures. Given the added challenges involved in identifying DAEs when\ncompared to ODEs, we anticipate that our findings will have broad applicability\nand contribute significantly to the development and validation of data-driven\nmethods for DAEs and other structure-preserving models.",
        "subjects": [
            "eess.SY",
            "cs.LG",
            "cs.SY",
            "math.DS",
            "math.OC"
        ],
        "authors": [
            "Arthur N. Montanari",
            "Fran√ßois Lamoline",
            "Robert Bereza",
            "Jorge Gon√ßalves"
        ],
        "published": "2024-05-22T16:48:47Z"
    },
    {
        "title": "Thermodynamic Natural Gradient Descent",
        "link": "http://arxiv.org/abs/2405.13817v1",
        "abstract": "Second-order training methods have better convergence properties than\ngradient descent but are rarely used in practice for large-scale training due\nto their computational overhead. This can be viewed as a hardware limitation\n(imposed by digital computers). Here we show that natural gradient descent\n(NGD), a second-order method, can have a similar computational complexity per\niteration to a first-order method, when employing appropriate hardware. We\npresent a new hybrid digital-analog algorithm for training neural networks that\nis equivalent to NGD in a certain parameter regime but avoids prohibitively\ncostly linear system solves. Our algorithm exploits the thermodynamic\nproperties of an analog system at equilibrium, and hence requires an analog\nthermodynamic computer. The training occurs in a hybrid digital-analog loop,\nwhere the gradient and Fisher information matrix (or any other positive\nsemi-definite curvature matrix) are calculated at given time intervals while\nthe analog dynamics take place. We numerically demonstrate the superiority of\nthis approach over state-of-the-art digital first- and second-order training\nmethods on classification tasks and language model fine-tuning tasks.",
        "subjects": [
            "cs.LG",
            "cs.ET"
        ],
        "authors": [
            "Kaelan Donatella",
            "Samuel Duffield",
            "Maxwell Aifer",
            "Denis Melanson",
            "Gavin Crooks",
            "Patrick J. Coles"
        ],
        "published": "2024-05-22T16:47:03Z"
    },
    {
        "title": "Large Language Models are Good Spontaneous Multilingual Learners: Is the\n  Multilingual Annotated Data Necessary?",
        "link": "http://arxiv.org/abs/2405.13816v1",
        "abstract": "Recently, Large Language Models (LLMs) have shown impressive language\ncapabilities. However, most of the existing LLMs are all English-centric, which\nhave very unstable and unbalanced performance across different languages.\nMultilingual alignment is an effective method to enhance the LLMs' multilingual\ncapabilities. In this work, we explore the multilingual alignment paradigm\nwhich utilizes translation data and comprehensively investigate the spontaneous\nmultilingual improvement of LLMs. We find that LLMs only instruction-tuned on\nquestion translation data without annotated answers are able to get significant\nmultilingual performance enhancement even across a wide range of languages\nunseen during instruction-tuning. Additionally, we utilize different settings\nand mechanistic interpretability methods to comprehensively analyze the LLM's\nperformance in the multilingual scenario.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Shimao Zhang",
            "Changjiang Gao",
            "Wenhao Zhu",
            "Jiajun Chen",
            "Xin Huang",
            "Xue Han",
            "Junlan Feng",
            "Chao Deng",
            "Shujian Huang"
        ],
        "published": "2024-05-22T16:46:19Z"
    },
    {
        "title": "Interpretable Multivariate Time Series Forecasting Using Neural Fourier\n  Transform",
        "link": "http://arxiv.org/abs/2405.13812v1",
        "abstract": "Multivariate time series forecasting is a pivotal task in several domains,\nincluding financial planning, medical diagnostics, and climate science. This\npaper presents the Neural Fourier Transform (NFT) algorithm, which combines\nmulti-dimensional Fourier transforms with Temporal Convolutional Network layers\nto improve both the accuracy and interpretability of forecasts. The Neural\nFourier Transform is empirically validated on fourteen diverse datasets,\nshowing superior performance across multiple forecasting horizons and\nlookbacks, setting new benchmarks in the field. This work advances multivariate\ntime series forecasting by providing a model that is both interpretable and\nhighly predictive, making it a valuable tool for both practitioners and\nresearchers. The code for this study is publicly available.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Noam Koren",
            "Kira Radinsky"
        ],
        "published": "2024-05-22T16:42:32Z"
    },
    {
        "title": "Diffusion-Based Cloud-Edge-Device Collaborative Learning for Next POI\n  Recommendations",
        "link": "http://arxiv.org/abs/2405.13811v1",
        "abstract": "The rapid expansion of Location-Based Social Networks (LBSNs) has highlighted\nthe importance of effective next Point-of-Interest (POI) recommendations, which\nleverage historical check-in data to predict users' next POIs to visit.\nTraditional centralized deep neural networks (DNNs) offer impressive POI\nrecommendation performance but face challenges due to privacy concerns and\nlimited timeliness. In response, on-device POI recommendations have been\nintroduced, utilizing federated learning (FL) and decentralized approaches to\nensure privacy and recommendation timeliness. However, these methods often\nsuffer from computational strain on devices and struggle to adapt to new users\nand regions. This paper introduces a novel collaborative learning framework,\nDiffusion-Based Cloud-Edge-Device Collaborative Learning for Next POI\nRecommendations (DCPR), leveraging the diffusion model known for its success\nacross various domains. DCPR operates with a cloud-edge-device architecture to\noffer region-specific and highly personalized POI recommendations while\nreducing on-device computational burdens. DCPR minimizes on-device\ncomputational demands through a unique blend of global and local learning\nprocesses. Our evaluation with two real-world datasets demonstrates DCPR's\nsuperior performance in recommendation accuracy, efficiency, and adaptability\nto new users and regions, marking a significant step forward in on-device POI\nrecommendation technology.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Jing Long",
            "Guanhua Ye",
            "Tong Chen",
            "Yang Wang",
            "Meng Wang",
            "Hongzhi Yin"
        ],
        "published": "2024-05-22T16:41:23Z"
    },
    {
        "title": "Leveraging 2D Information for Long-term Time Series Forecasting with\n  Vanilla Transformers",
        "link": "http://arxiv.org/abs/2405.13810v1",
        "abstract": "Time series prediction is crucial for understanding and forecasting complex\ndynamics in various domains, ranging from finance and economics to climate and\nhealthcare. Based on Transformer architecture, one approach involves encoding\nmultiple variables from the same timestamp into a single temporal token to\nmodel global dependencies. In contrast, another approach embeds the time points\nof individual series into separate variate tokens. The former method faces\nchallenges in learning variate-centric representations, while the latter risks\nmissing essential temporal information critical for accurate forecasting. In\nour work, we introduce GridTST, a model that combines the benefits of two\napproaches using innovative multi-directional attentions based on a vanilla\nTransformer. We regard the input time series data as a grid, where the $x$-axis\nrepresents the time steps and the $y$-axis represents the variates. A vertical\nslicing of this grid combines the variates at each time step into a\n\\textit{time token}, while a horizontal slicing embeds the individual series\nacross all time steps into a \\textit{variate token}. Correspondingly, a\n\\textit{horizontal attention mechanism} focuses on time tokens to comprehend\nthe correlations between data at various time steps, while a \\textit{vertical},\nvariate-aware \\textit{attention} is employed to grasp multivariate\ncorrelations. This combination enables efficient processing of information\nacross both time and variate dimensions, thereby enhancing the model's\nanalytical strength. % We also integrate the patch technique, segmenting time\ntokens into subseries-level patches, ensuring that local semantic information\nis retained in the embedding. The GridTST model consistently delivers\nstate-of-the-art performance across various real-world datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Xin Cheng",
            "Xiuying Chen",
            "Shuqi Li",
            "Di Luo",
            "Xun Wang",
            "Dongyan Zhao",
            "Rui Yan"
        ],
        "published": "2024-05-22T16:41:21Z"
    },
    {
        "title": "MPI Progress For All",
        "link": "http://arxiv.org/abs/2405.13807v1",
        "abstract": "The progression of communication in the Message Passing Interface (MPI) is\nnot well defined, yet it is critical for application performance, particularly\nin achieving effective computation and communication overlap. The opaque nature\nof MPI progress poses significant challenges in advancing MPI within modern\nhigh-performance computing (HPC) practices. Firstly, the lack of clarity\nhinders the development of explicit guidelines for enhancing computation and\ncommunication overlap in applications. Secondly, it prevents MPI from\nseamlessly integrating with contemporary programming paradigms, such as\ntask-based runtimes and event-driven programming. Thirdly, it limits the\nextension of MPI functionalities from the user space. In this paper, we examine\nthe role of MPI progress by analyzing the implementation details of MPI\nmessaging. We then generalize the asynchronous communication pattern and\nidentify key factors influencing application performance. Based on this\nanalysis, we propose a set of MPI extensions designed to enable users to\nexplicitly construct and manage an efficient progress engine. We provide\nexample codes to demonstrate the use of these proposed APIs in achieving\nimproved performance, adapting MPI to task-based or event-driven programming\nstyles, and constructing collective algorithms that rival the performance of\nnative implementations. Our approach is compared to previous efforts in the\nfield, highlighting its reduced complexity and increased effectiveness.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Hui Zhou",
            "Robert Latham",
            "Ken Raffenetti",
            "Yanfei Guo",
            "Rajeev Thakur"
        ],
        "published": "2024-05-22T16:36:29Z"
    },
    {
        "title": "Advancing Graph Convolutional Networks via General Spectral Wavelets",
        "link": "http://arxiv.org/abs/2405.13806v1",
        "abstract": "Spectral graph convolution, an important tool of data filtering on graphs,\nrelies on two essential decisions; selecting spectral bases for signal\ntransformation and parameterizing the kernel for frequency analysis. While\nrecent techniques mainly focus on standard Fourier transform and vector-valued\nspectral functions, they fall short in flexibility to describe specific signal\ndistribution for each node, and expressivity of spectral function. In this\npaper, we present a novel wavelet-based graph convolution network, namely\nWaveGC, which integrates multi-resolution spectral bases and a matrix-valued\nfilter kernel. Theoretically, we establish that WaveGC can effectively capture\nand decouple short-range and long-range information, providing superior\nfiltering flexibility, surpassing existing graph convolutional networks and\ngraph Transformers (GTs). To instantiate WaveGC, we introduce a novel technique\nfor learning general graph wavelets by separately combining odd and even terms\nof Chebyshev polynomials. This approach strictly satisfies wavelet\nadmissibility criteria. Our numerical experiments showcase the capabilities of\nthe new network. By replacing the Transformer part in existing architectures\nwith WaveGC, we consistently observe improvements in both short-range and\nlong-range tasks. This underscores the effectiveness of the proposed model in\nhandling different scenarios. Our code is available at\nhttps://github.com/liun-online/WaveGC.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Nian Liu",
            "Xiaoxin He",
            "Thomas Laurent",
            "Francesco Di Giovanni",
            "Michael M. Bronstein",
            "Xavier Bresson"
        ],
        "published": "2024-05-22T16:32:27Z"
    },
    {
        "title": "Perceptual Fairness in Image Restoration",
        "link": "http://arxiv.org/abs/2405.13805v1",
        "abstract": "Fairness in image restoration tasks is the desire to treat different\nsub-groups of images equally well. Existing definitions of fairness in image\nrestoration are highly restrictive. They consider a reconstruction to be a\ncorrect outcome for a group (e.g., women) only if it falls within the group's\nset of ground truth images (e.g., natural images of women); otherwise, it is\nconsidered entirely incorrect. Consequently, such definitions are prone to\ncontroversy, as errors in image restoration can manifest in various ways. In\nthis work we offer an alternative approach towards fairness in image\nrestoration, by considering the Group Perceptual Index (GPI), which we define\nas the statistical distance between the distribution of the group's ground\ntruth images and the distribution of their reconstructions. We assess the\nfairness of an algorithm by comparing the GPI of different groups, and say that\nit achieves perfect Perceptual Fairness (PF) if the GPIs of all groups are\nidentical. We motivate and theoretically study our new notion of fairness, draw\nits connection to previous ones, and demonstrate its utility on\nstate-of-the-art face image super-resolution algorithms.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Guy Ohayon",
            "Michael Elad",
            "Tomer Michaeli"
        ],
        "published": "2024-05-22T16:32:20Z"
    },
    {
        "title": "Guarding Multiple Secrets: Enhanced Summary Statistic Privacy for Data\n  Sharing",
        "link": "http://arxiv.org/abs/2405.13804v1",
        "abstract": "Data sharing enables critical advances in many research areas and business\napplications, but it may lead to inadvertent disclosure of sensitive summary\nstatistics (e.g., means or quantiles). Existing literature only focuses on\nprotecting a single confidential quantity, while in practice, data sharing\ninvolves multiple sensitive statistics. We propose a novel framework to define,\nanalyze, and protect multi-secret summary statistics privacy in data sharing.\nSpecifically, we measure the privacy risk of any data release mechanism by the\nworst-case probability of an attacker successfully inferring summary statistic\nsecrets. Given an attacker's objective spanning from inferring a subset to the\nentirety of summary statistic secrets, we systematically design and analyze\ntailored privacy metrics. Defining the distortion as the worst-case distance\nbetween the original and released data distribution, we analyze the tradeoff\nbetween privacy and distortion. Our contribution also includes designing and\nanalyzing data release mechanisms tailored for different data distributions and\nsecret types. Evaluations on real-world data demonstrate the effectiveness of\nour mechanisms in practical applications.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Shuaiqi Wang",
            "Rongzhe Wei",
            "Mohsen Ghassemi",
            "Eleonora Kreacic",
            "Vamsi K. Potluru"
        ],
        "published": "2024-05-22T16:30:34Z"
    },
    {
        "title": "Sunnie: An Anthropomorphic LLM-Based Conversational Agent for Mental\n  Well-Being Activity Recommendation",
        "link": "http://arxiv.org/abs/2405.13803v1",
        "abstract": "A longstanding challenge in mental well-being support is the reluctance of\npeople to adopt psychologically beneficial activities, often due to a lack of\nmotivation, low perceived trustworthiness, and limited personalization of\nrecommendations. Chatbots have shown promise in promoting positive mental\nhealth practices, yet their rigid interaction flows and less human-like\nconversational experiences present significant limitations. In this work, we\nexplore whether the anthropomorphic design (both LLM's persona design and\nconversational experience design) can enhance users' perception of the system\nand their willingness to adopt mental well-being activity recommendations. To\nthis end, we introduce Sunnie, an anthropomorphic LLM-based conversational\nagent designed to offer personalized guidance for mental well-being support\nthrough multi-turn conversation and activity recommendations based on positive\npsychological theory. An empirical user study comparing the user experience\nwith Sunnie and with a traditional survey-based activity recommendation system\nsuggests that the anthropomorphic characteristics of Sunnie significantly\nenhance users' perception of the system and the overall usability;\nnevertheless, users' willingness to adopt activity recommendations did not\nchange significantly.",
        "subjects": [
            "cs.HC",
            "cs.CL"
        ],
        "authors": [
            "Siyi Wu",
            "Feixue Han",
            "Bingsheng Yao",
            "Tianyi Xie",
            "Xuan Zhao",
            "Dakuo Wang"
        ],
        "published": "2024-05-22T16:30:24Z"
    },
    {
        "title": "Bayesian Inference Under Differential Privacy: Prior Selection\n  Considerations with Application to Univariate Gaussian Data and Regression",
        "link": "http://arxiv.org/abs/2405.13801v1",
        "abstract": "We describe Bayesian inference for the mean and variance of bounded data\nprotected by differential privacy and modeled as Gaussian. Using this setting,\nwe demonstrate that analysts can and should take the constraints imposed by the\nbounds into account when specifying prior distributions. Additionally, we\nprovide theoretical and empirical results regarding what classes of default\npriors produce valid inference for a differentially private release in settings\nwhere substantial prior information is not available. We discuss how these\nresults can be applied to Bayesian inference for regression with differentially\nprivate data.",
        "subjects": [
            "stat.ME",
            "cs.CR"
        ],
        "authors": [
            "Zeki Kazan",
            "Jerome P. Reiter"
        ],
        "published": "2024-05-22T16:27:20Z"
    },
    {
        "title": "Dense Connector for MLLMs",
        "link": "http://arxiv.org/abs/2405.13800v1",
        "abstract": "Do we fully leverage the potential of visual encoder in Multimodal Large\nLanguage Models (MLLMs)? The recent outstanding performance of MLLMs in\nmultimodal understanding has garnered broad attention from both academia and\nindustry. In the current MLLM rat race, the focus seems to be predominantly on\nthe linguistic side. We witness the rise of larger and higher-quality\ninstruction datasets, as well as the involvement of larger-sized LLMs. Yet,\nscant attention has been directed towards the visual signals utilized by MLLMs,\noften assumed to be the final high-level features extracted by a frozen visual\nencoder. In this paper, we introduce the Dense Connector - a simple, effective,\nand plug-and-play vision-language connector that significantly enhances\nexisting MLLMs by leveraging multi-layer visual features, with minimal\nadditional computational overhead. Furthermore, our model, trained solely on\nimages, showcases remarkable zero-shot capabilities in video understanding as\nwell. Experimental results across various vision encoders, image resolutions,\ntraining dataset scales, varying sizes of LLMs (2.7B->70B), and diverse\narchitectures of MLLMs (e.g., LLaVA and Mini-Gemini) validate the versatility\nand scalability of our approach, achieving state-of-the-art performance on\nacross 19 image and video benchmarks. We hope that this work will provide\nvaluable experience and serve as a basic module for future MLLM development.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Huanjin Yao",
            "Wenhao Wu",
            "Taojiannan Yang",
            "YuXin Song",
            "Mengxi Zhang",
            "Haocheng Feng",
            "Yifan Sun",
            "Zhiheng Li",
            "Wanli Ouyang",
            "Jingdong Wang"
        ],
        "published": "2024-05-22T16:25:03Z"
    },
    {
        "title": "Slaves to the Law of Large Numbers: An Asymptotic Equipartition Property\n  for Perplexity in Generative Language Models",
        "link": "http://arxiv.org/abs/2405.13798v1",
        "abstract": "We propose a new asymptotic equipartition property for the perplexity of a\nlarge piece of text generated by a language model and present theoretical\narguments for this property. Perplexity, defined as a inverse likelihood\nfunction, is widely used as a performance metric for training language models.\nOur main result states that the logarithmic perplexity of any large text\nproduced by a language model must asymptotically converge to the average\nentropy of its token distributions. This means that language models are\nconstrained to only produce outputs from a ``typical set\", which we show, is a\nvanishingly small subset of all possible grammatically correct outputs. We\npresent preliminary experimental results from an open-source language model to\nsupport our theoretical claims. This work has possible practical applications\nfor understanding and improving ``AI detection\" tools and theoretical\nimplications for the uniqueness, predictability and creative potential of\ngenerative models.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Raghu Mudumbai",
            "Tyler Bell"
        ],
        "published": "2024-05-22T16:23:40Z"
    },
    {
        "title": "Sparse Induced Subgraphs of Large Treewidth",
        "link": "http://arxiv.org/abs/2405.13797v1",
        "abstract": "Motivated by an induced counterpart of treewidth sparsifiers (i.e., sparse\nsubgraphs keeping the treewidth large) provided by the celebrated Grid Minor\ntheorem of Robertson and Seymour [JCTB '86] or by a classic result of Chekuri\nand Chuzhoy [SODA '15], we show that for any natural numbers $t$ and $w$, and\nreal $\\varepsilon > 0$, there is an integer $W := W(t,w,\\varepsilon)$ such that\nevery graph with treewidth at least $W$ and no $K_{t,t}$ subgraph admits a\n2-connected $n$-vertex induced subgraph with treewidth at least $w$ and at most\n$(1+\\varepsilon)n$ edges. The induced subgraph is either a subdivided wall, or\nits line graph, or a spanning supergraph of a subdivided biclique. This in\nparticular extends a result of Weissauer [JCTB '19] that graphs of large\ntreewidth have a large biclique subgraph or a long induced cycle.",
        "subjects": [
            "math.CO",
            "cs.DM",
            "cs.DS",
            "05C99, 05C69",
            "F.2.2"
        ],
        "authors": [
            "√âdouard Bonnet"
        ],
        "published": "2024-05-22T16:22:30Z"
    },
    {
        "title": "Generalizing Weather Forecast to Fine-grained Temporal Scales via\n  Physics-AI Hybrid Modeling",
        "link": "http://arxiv.org/abs/2405.13796v1",
        "abstract": "Data-driven artificial intelligence (AI) models have made significant\nadvancements in weather forecasting, particularly in medium-range and\nnowcasting. However, most data-driven weather forecasting models are black-box\nsystems that focus on learning data mapping rather than fine-grained physical\nevolution in the time dimension. Consequently, the limitations in the temporal\nscale of datasets prevent these models from forecasting at finer time scales.\nThis paper proposes a physics-AI hybrid model (i.e., WeatherGFT) which\nGeneralizes weather forecasts to Finer-grained Temporal scales beyond training\ndataset. Specifically, we employ a carefully designed PDE kernel to simulate\nphysical evolution on a small time scale (e.g., 300 seconds) and use a parallel\nneural networks with a learnable router for bias correction. Furthermore, we\nintroduce a lead time-aware training framework to promote the generalization of\nthe model at different lead times. The weight analysis of physics-AI modules\nindicates that physics conducts major evolution while AI performs corrections\nadaptively. Extensive experiments show that WeatherGFT trained on an hourly\ndataset, achieves state-of-the-art performance across multiple lead times and\nexhibits the capability to generalize 30-minute forecasts.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Wanghan Xu",
            "Fenghua Ling",
            "Wenlong Zhang",
            "Tao Han",
            "Hao Chen",
            "Wanli Ouyang",
            "Lei Bai"
        ],
        "published": "2024-05-22T16:21:02Z"
    },
    {
        "title": "Using k-medoids for distributed approximate similarity search with\n  arbitrary distances",
        "link": "http://arxiv.org/abs/2405.13795v1",
        "abstract": "This paper presents GMASK, a general algorithm for distributed approximate\nsimilarity search that accepts any arbitrary distance function. GMASK requires\na clustering algorithm that induces Voronoi regions in a dataset and returns a\nrepresentative element for each region. Then, it creates a multilevel indexing\nstructure suitable for large datasets with high dimensionality and sparsity,\nusually stored in distributed systems. Many similarity search algorithms rely\non $k$-means, typically associated with the Euclidean distance, which is\ninappropriate for specific problems. Instead, in this work we implement GMASK\nusing $k$-medoids to make it compatible with any distance and a wider range of\nproblems. Experimental results verify the applicability of this method with\nreal datasets, improving the performance of alternative algorithms for\napproximate similarity search. In addition, results confirm existing intuitions\nregarding the advantages of using certain instances of the Minkowski distance\nin high-dimensional datasets.",
        "subjects": [
            "cs.IR",
            "cs.DB"
        ],
        "authors": [
            "Elena Garcia-Morato",
            "Maria Jesus Algar",
            "Cesar Alfaro",
            "Felipe Ortega",
            "Javier Gomez",
            "Javier M. Moguerza"
        ],
        "published": "2024-05-22T16:19:52Z"
    },
    {
        "title": "Conditioning diffusion models by explicit forward-backward bridging",
        "link": "http://arxiv.org/abs/2405.13794v1",
        "abstract": "Given an unconditional diffusion model $\\pi(x, y)$, using it to perform\nconditional simulation $\\pi(x \\mid y)$ is still largely an open question and is\ntypically achieved by learning conditional drifts to the denoising SDE after\nthe fact. In this work, we express conditional simulation as an inference\nproblem on an augmented space corresponding to a partial SDE bridge. This\nperspective allows us to implement efficient and principled particle Gibbs and\npseudo-marginal samplers marginally targeting the conditional distribution\n$\\pi(x \\mid y)$. Contrary to existing methodology, our methods do not introduce\nany additional approximation to the unconditional diffusion model aside from\nthe Monte Carlo error. We showcase the benefits and drawbacks of our approach\non a series of synthetic and real data examples.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.CO",
            "stat.ME"
        ],
        "authors": [
            "Adrien Corenflos",
            "Zheng Zhao",
            "Simo S√§rkk√§",
            "Jens Sj√∂lund",
            "Thomas B. Sch√∂n"
        ],
        "published": "2024-05-22T16:17:03Z"
    },
    {
        "title": "xRAG: Extreme Context Compression for Retrieval-augmented Generation\n  with One Token",
        "link": "http://arxiv.org/abs/2405.13792v1",
        "abstract": "This paper introduces xRAG, an innovative context compression method tailored\nfor retrieval-augmented generation. xRAG reinterprets document embeddings in\ndense retrieval--traditionally used solely for retrieval--as features from the\nretrieval modality. By employing a modality fusion methodology, xRAG seamlessly\nintegrates these embeddings into the language model representation space,\neffectively eliminating the need for their textual counterparts and achieving\nan extreme compression rate. In xRAG, the only trainable component is the\nmodality bridge, while both the retriever and the language model remain frozen.\nThis design choice allows for the reuse of offline-constructed document\nembeddings and preserves the plug-and-play nature of retrieval augmentation.\nExperimental results demonstrate that xRAG achieves an average improvement of\nover 10% across six knowledge-intensive tasks, adaptable to various language\nmodel backbones, ranging from a dense 7B model to an 8x7B Mixture of Experts\nconfiguration. xRAG not only significantly outperforms previous context\ncompression methods but also matches the performance of uncompressed models on\nseveral datasets, while reducing overall FLOPs by a factor of 3.53. Our work\npioneers new directions in retrieval-augmented generation from the perspective\nof multimodality fusion, and we hope it lays the foundation for future\nefficient and scalable retrieval-augmented systems",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "authors": [
            "Xin Cheng",
            "Xun Wang",
            "Xingxing Zhang",
            "Tao Ge",
            "Si-Qing Chen",
            "Furu Wei",
            "Huishuai Zhang",
            "Dongyan Zhao"
        ],
        "published": "2024-05-22T16:15:17Z"
    },
    {
        "title": "Multi-Type Point Cloud Autoencoder: A Complete Equivariant Embedding for\n  Molecule Conformation and Pose",
        "link": "http://arxiv.org/abs/2405.13791v1",
        "abstract": "The point cloud is a flexible representation for a wide variety of data\ntypes, and is a particularly natural fit for the 3D conformations of molecules.\nExtant molecule embedding/representation schemes typically focus on internal\ndegrees of freedom, ignoring the global 3D orientation. For tasks that depend\non knowledge of both molecular conformation and 3D orientation, such as the\ngeneration of molecular dimers, clusters, or condensed phases, we require a\nrepresentation which is provably complete in the types and positions of atomic\nnuclei and roto-inversion equivariant with respect to the input point cloud. We\ndevelop, train, and evaluate a new type of autoencoder, molecular O(3) encoding\nnet (Mo3ENet), for multi-type point clouds, for which we propose a new\nreconstruction loss, capitalizing on a Gaussian mixture representation of the\ninput and output point clouds. Mo3ENet is end-to-end equivariant, meaning the\nlearned representation can be manipulated on O(3), a practical bonus for\ndownstream learning tasks. An appropriately trained Mo3ENet latent space\ncomprises a universal embedding for scalar and vector molecule property\nprediction tasks, as well as other downstream tasks incorporating the 3D\nmolecular pose.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Michael Kilgour",
            "Jutta Rogal",
            "Mark Tuckerman"
        ],
        "published": "2024-05-22T16:14:37Z"
    },
    {
        "title": "Quantum algorithm for large-scale market equilibrium computation",
        "link": "http://arxiv.org/abs/2405.13788v1",
        "abstract": "Classical algorithms for market equilibrium computation such as proportional\nresponse dynamics face scalability issues with Internet-based applications such\nas auctions, recommender systems, and fair division, despite having an almost\nlinear runtime in terms of the product of buyers and goods. In this work, we\nprovide the first quantum algorithm for market equilibrium computation with\nsub-linear performance. Our algorithm provides a polynomial runtime speedup in\nterms of the product of the number of buyers and goods while reaching the same\noptimization objective value as the classical algorithm. Numerical simulations\nof a system with 16384 buyers and goods support our theoretical results that\nour quantum algorithm provides a significant speedup.",
        "subjects": [
            "quant-ph",
            "cs.GT"
        ],
        "authors": [
            "Po-Wei Huang",
            "Patrick Rebentrost"
        ],
        "published": "2024-05-22T16:12:45Z"
    },
    {
        "title": "Disentangle Sample Size and Initialization Effect on Perfect\n  Generalization for Single-Neuron Target",
        "link": "http://arxiv.org/abs/2405.13787v1",
        "abstract": "Overparameterized models like deep neural networks have the intriguing\nability to recover target functions with fewer sampled data points than\nparameters (see arXiv:2307.08921). To gain insights into this phenomenon, we\nconcentrate on a single-neuron target recovery scenario, offering a systematic\nexamination of how initialization and sample size influence the performance of\ntwo-layer neural networks. Our experiments reveal that a smaller initialization\nscale is associated with improved generalization, and we identify a critical\nquantity called the \"initial imbalance ratio\" that governs training dynamics\nand generalization under small initialization, supported by theoretical proofs.\nAdditionally, we empirically delineate two critical thresholds in sample\nsize--termed the \"optimistic sample size\" and the \"separation sample\nsize\"--that align with the theoretical frameworks established by (see\narXiv:2307.08921 and arXiv:2309.00508). Our results indicate a transition in\nthe model's ability to recover the target function: below the optimistic sample\nsize, recovery is unattainable; at the optimistic sample size, recovery becomes\nattainable albeit with a set of initialization of zero measure. Upon reaching\nthe separation sample size, the set of initialization that can successfully\nrecover the target function shifts from zero to positive measure. These\ninsights, derived from a simplified context, provide a perspective on the\nintricate yet decipherable complexities of perfect generalization in\noverparameterized neural networks.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Jiajie Zhao",
            "Zhiwei Bai",
            "Yaoyu Zhang"
        ],
        "published": "2024-05-22T16:12:28Z"
    },
    {
        "title": "Towards Explainable Test Case Prioritisation with Learning-to-Rank\n  Models",
        "link": "http://dx.doi.org/10.1109/ICSTW58534.2023.00023",
        "abstract": "Test case prioritisation (TCP) is a critical task in regression testing to\nensure quality as software evolves. Machine learning has become a common way to\nachieve it. In particular, learning-to-rank (LTR) algorithms provide an\neffective method of ordering and prioritising test cases. However, their use\nposes a challenge in terms of explainability, both globally at the model level\nand locally for particular results. Here, we present and discuss scenarios that\nrequire different explanations and how the particularities of TCP (multiple\nbuilds over time, test case and test suite variations, etc.) could influence\nthem. We include a preliminary experiment to analyse the similarity of\nexplanations, showing that they do not only vary depending on test\ncase-specific predictions, but also on the relative ranks.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "D.2.5; I.2.6"
        ],
        "authors": [
            "Aurora Ram√≠rez",
            "Mario Berrios",
            "Jos√© Ra√∫l Romero",
            "Robert Feldt"
        ],
        "published": "2024-05-22T16:11:45Z"
    },
    {
        "title": "Efficient Two-Stage Gaussian Process Regression Via Automatic Kernel\n  Search and Subsampling",
        "link": "http://arxiv.org/abs/2405.13785v1",
        "abstract": "Gaussian Process Regression (GPR) is widely used in statistics and machine\nlearning for prediction tasks requiring uncertainty measures. Its efficacy\ndepends on the appropriate specification of the mean function, covariance\nkernel function, and associated hyperparameters. Severe misspecifications can\nlead to inaccurate results and problematic consequences, especially in\nsafety-critical applications. However, a systematic approach to handle these\nmisspecifications is lacking in the literature. In this work, we propose a\ngeneral framework to address these issues. Firstly, we introduce a flexible\ntwo-stage GPR framework that separates mean prediction and uncertainty\nquantification (UQ) to prevent mean misspecification, which can introduce bias\ninto the model. Secondly, kernel function misspecification is addressed through\na novel automatic kernel search algorithm, supported by theoretical analysis,\nthat selects the optimal kernel from a candidate set. Additionally, we propose\na subsampling-based warm-start strategy for hyperparameter initialization to\nimprove efficiency and avoid hyperparameter misspecification. With much lower\ncomputational cost, our subsampling-based strategy can yield competitive or\nbetter performance than training exclusively on the full dataset. Combining all\nthese components, we recommend two GPR methods-exact and scalable-designed to\nmatch available computational resources and specific UQ requirements. Extensive\nevaluation on real-world datasets, including UCI benchmarks and a\nsafety-critical medical case study, demonstrates the robustness and precision\nof our methods.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.PR",
            "stat.ML",
            "G.3; J.3"
        ],
        "authors": [
            "Shifan Zhao",
            "Jiaying Lu",
            "Ji Yang",
            "Edmond Chow",
            "Yuanzhe Xi"
        ],
        "published": "2024-05-22T16:11:29Z"
    },
    {
        "title": "Addressing the Elephant in the Room: Robust Animal Re-Identification\n  with Unsupervised Part-Based Feature Alignment",
        "link": "http://arxiv.org/abs/2405.13781v1",
        "abstract": "Animal Re-ID is crucial for wildlife conservation, yet it faces unique\nchallenges compared to person Re-ID. First, the scarcity and lack of diversity\nin datasets lead to background-biased models. Second, animal Re-ID depends on\nsubtle, species-specific cues, further complicated by variations in pose,\nbackground, and lighting. This study addresses background biases by proposing a\nmethod to systematically remove backgrounds in both training and evaluation\nphases. And unlike prior works that depend on pose annotations, our approach\nutilizes an unsupervised technique for feature alignment across body parts and\npose variations, enhancing practicality. Our method achieves superior results\non three key animal Re-ID datasets: ATRW, YakReID-103, and ELPephants.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yingxue Yu",
            "Vidit Vidit",
            "Andrey Davydov",
            "Martin Engilberge",
            "Pascal Fua"
        ],
        "published": "2024-05-22T16:08:06Z"
    },
    {
        "title": "Robust Disaster Assessment from Aerial Imagery Using Text-to-Image\n  Synthetic Data",
        "link": "http://arxiv.org/abs/2405.13779v1",
        "abstract": "We present a simple and efficient method to leverage emerging text-to-image\ngenerative models in creating large-scale synthetic supervision for the task of\ndamage assessment from aerial images. While significant recent advances have\nresulted in improved techniques for damage assessment using aerial or satellite\nimagery, they still suffer from poor robustness to domains where manual labeled\ndata is unavailable, directly impacting post-disaster humanitarian assistance\nin such under-resourced geographies. Our contribution towards improving domain\nrobustness in this scenario is two-fold. Firstly, we leverage the text-guided\nmask-based image editing capabilities of generative models and build an\nefficient and easily scalable pipeline to generate thousands of post-disaster\nimages from low-resource domains. Secondly, we propose a simple two-stage\ntraining approach to train robust models while using manual supervision from\ndifferent source domains along with the generated synthetic target domain data.\nWe validate the strength of our proposed framework under cross-geography domain\ntransfer setting from xBD and SKAI images in both single-source and\nmulti-source settings, achieving significant improvements over a source-only\nbaseline in each case.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Tarun Kalluri",
            "Jihyeon Lee",
            "Kihyuk Sohn",
            "Sahil Singla",
            "Manmohan Chandraker",
            "Joseph Xu",
            "Jeremiah Liu"
        ],
        "published": "2024-05-22T16:07:05Z"
    },
    {
        "title": "No Filter: Cultural and Socioeconomic Diversity in Contrastive\n  Vision-Language Models",
        "link": "http://arxiv.org/abs/2405.13777v2",
        "abstract": "We study cultural and socioeconomic diversity in contrastive vision-language\nmodels (VLMs). Using a broad range of benchmark datasets and evaluation\nmetrics, we bring to attention several important findings. First, the common\nfiltering of training data to English image-text pairs disadvantages\ncommunities of lower socioeconomic status and negatively impacts cultural\nunderstanding. Notably, this performance gap is not captured by - and even at\nodds with - the currently popular evaluation metrics derived from the\nWestern-centric ImageNet and COCO datasets. Second, pretraining with global,\nunfiltered data before fine-tuning on English content can improve cultural\nunderstanding without sacrificing performance on said popular benchmarks.\nThird, we introduce the task of geo-localization as a novel evaluation metric\nto assess cultural diversity in VLMs. Our work underscores the value of using\ndiverse data to create more inclusive multimodal systems and lays the\ngroundwork for developing VLMs that better represent global perspectives.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Ang√©line Pouget",
            "Lucas Beyer",
            "Emanuele Bugliarello",
            "Xiao Wang",
            "Andreas Peter Steiner",
            "Xiaohua Zhai",
            "Ibrahim Alabdulmohsin"
        ],
        "published": "2024-05-22T16:04:22Z"
    },
    {
        "title": "On the integrality gap of the Complete Metric Steiner Tree Problem via a\n  novel formulation",
        "link": "http://arxiv.org/abs/2405.13773v1",
        "abstract": "In this work, we compute the lower bound of the integrality gap of the Metric\nSteiner Tree Problem (MSTP) on a graph for some small values of number of nodes\nand terminals. After debating about some limitations of the most used\nformulation for the Steiner Tree Problem, namely the Bidirected Cut\nFormulation, we introduce a novel formulation, that we named Complete Metric\nformulation, tailored for the metric case. We prove some interesting properties\nof this formulation and characterize some types of vertices. Finally, we define\na linear program (LP) by adapting a method already used in the context of the\nTravelling Salesman Problem. This LP takes as input a vertex of the polytope of\nthe CM relaxation and provides an MSTP instance such that (a) the optimal\nsolution is precisely that vertex and (b) among all of the instances having\nthat vertex as its optimal solution, the selected instance is the one having\nthe highest integrality gap. We propose two heuristics for generating vertices\nto provide inputs for our procedure. In conclusion, we raise several\nconjectures and open questions.",
        "subjects": [
            "math.OC",
            "cs.DM"
        ],
        "authors": [
            "Ambrogio Maria Bernardelli",
            "Eleonora Vercesi",
            "Stefano Gualandi",
            "Monaldo Mastrolilli",
            "Luca Maria Gambardella"
        ],
        "published": "2024-05-22T16:02:36Z"
    },
    {
        "title": "Multi-Dataset Multi-Task Learning for COVID-19 Prognosis",
        "link": "http://arxiv.org/abs/2405.13771v1",
        "abstract": "In the fight against the COVID-19 pandemic, leveraging artificial\nintelligence to predict disease outcomes from chest radiographic images\nrepresents a significant scientific aim. The challenge, however, lies in the\nscarcity of large, labeled datasets with compatible tasks for training deep\nlearning models without leading to overfitting. Addressing this issue, we\nintroduce a novel multi-dataset multi-task training framework that predicts\nCOVID-19 prognostic outcomes from chest X-rays (CXR) by integrating correlated\ndatasets from disparate sources, distant from conventional multi-task learning\napproaches, which rely on datasets with multiple and correlated labeling\nschemes. Our framework hypothesizes that assessing severity scores enhances the\nmodel's ability to classify prognostic severity groups, thereby improving its\nrobustness and predictive power. The proposed architecture comprises a deep\nconvolutional network that receives inputs from two publicly available CXR\ndatasets, AIforCOVID for severity prognostic prediction and BRIXIA for severity\nscore assessment, and branches into task-specific fully connected output\nnetworks. Moreover, we propose a multi-task loss function, incorporating an\nindicator function, to exploit multi-dataset integration. The effectiveness and\nrobustness of the proposed approach are demonstrated through significant\nperformance improvements in prognosis classification tasks across 18 different\nconvolutional neural network backbones in different evaluation strategies. This\nimprovement is evident over single-task baselines and standard transfer\nlearning strategies, supported by extensive statistical analysis, showing great\napplication potential.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Filippo Ruffini",
            "Lorenzo Tronchin",
            "Zhuoru Wu",
            "Wenting Chen",
            "Paolo Soda",
            "Linlin Shen",
            "Valerio Guarrasi"
        ],
        "published": "2024-05-22T15:57:44Z"
    },
    {
        "title": "Expansion-GRR: Efficient Generation of Smooth Global Redundancy\n  Resolution Roadmaps",
        "link": "http://arxiv.org/abs/2405.13770v1",
        "abstract": "Global redundancy resolution (GRR) roadmap is a novel concept in robotics\nthat facilitates the mapping from task space paths to configuration space paths\nin a legible, predictable, and repeatable way. Such roadmaps could find\nwidespread utility in applications such as safe teleoperation, consistent path\nplanning, and factory workcell design. However, the previous methods to compute\nGRR roadmaps often necessitate a lengthy computation time and produce\nnon-smooth paths, limiting their practical efficacy. To address this challenge,\nwe introduce a novel method Expansion-GRR that leverages efficient\nconfiguration space projections and enables a rapid generation of smooth\nroadmaps that satisfy the task constraints. Additionally, we propose a simple\nmulti-seed strategy that further enhances the final quality. We conducted\nexperiments in simulation with a 5-link planar manipulator and a Kinova arm. We\nwere able to generate the GRR roadmaps up to 2 orders of magnitude faster while\nachieving higher smoothness. We also demonstrate the utility of the GRR\nroadmaps in teleoperation tasks where our method outperformed prior methods and\nreactive IK solvers in terms of success rate and solution quality.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Zhuoyun Zhong",
            "Zhi Li",
            "Constantinos Chamzas"
        ],
        "published": "2024-05-22T15:57:08Z"
    },
    {
        "title": "Do Language Models Enjoy Their Own Stories? Prompting Large Language\n  Models for Automatic Story Evaluation",
        "link": "http://arxiv.org/abs/2405.13769v1",
        "abstract": "Storytelling is an integral part of human experience and plays a crucial role\nin social interactions. Thus, Automatic Story Evaluation (ASE) and Generation\n(ASG) could benefit society in multiple ways, but they are challenging tasks\nwhich require high-level human abilities such as creativity, reasoning and deep\nunderstanding. Meanwhile, Large Language Models (LLM) now achieve\nstate-of-the-art performance on many NLP tasks. In this paper, we study whether\nLLMs can be used as substitutes for human annotators for ASE. We perform an\nextensive analysis of the correlations between LLM ratings, other automatic\nmeasures, and human annotations, and we explore the influence of prompting on\nthe results and the explainability of LLM behaviour. Most notably, we find that\nLLMs outperform current automatic measures for system-level evaluation but\nstill struggle at providing satisfactory explanations for their answers.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Cyril Chhun",
            "Fabian M. Suchanek",
            "Chlo√© Clavel"
        ],
        "published": "2024-05-22T15:56:52Z"
    },
    {
        "title": "DETAIL: Task DEmonsTration Attribution for Interpretable In-context\n  Learning",
        "link": "http://arxiv.org/abs/2405.14899v1",
        "abstract": "In-context learning (ICL) allows transformer-based language models that are\npre-trained on general text to quickly learn a specific task with a few \"task\ndemonstrations\" without updating their parameters, significantly boosting their\nflexibility and generality. ICL possesses many distinct characteristics from\nconventional machine learning, thereby requiring new approaches to interpret\nthis learning paradigm. Taking the viewpoint of recent works showing that\ntransformers learn in context by formulating an internal optimizer, we propose\nan influence function-based attribution technique, DETAIL, that addresses the\nspecific characteristics of ICL. We empirically verify the effectiveness of our\napproach for demonstration attribution while being computationally efficient.\nLeveraging the results, we then show how DETAIL can help improve model\nperformance in real-world scenarios through demonstration reordering and\ncuration. Finally, we experimentally prove the wide applicability of DETAIL by\nshowing our attribution scores obtained on white-box models are transferable to\nblack-box models in improving model performance.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Zijian Zhou",
            "Xiaoqiang Lin",
            "Xinyi Xu",
            "Alok Prakash",
            "Daniela Rus",
            "Bryan Kian Hsiang Low"
        ],
        "published": "2024-05-22T15:52:52Z"
    },
    {
        "title": "On the stability of second order gradient descent for time varying\n  convex functions",
        "link": "http://arxiv.org/abs/2405.13765v1",
        "abstract": "Gradient based optimization algorithms deployed in Machine Learning (ML)\napplications are often analyzed and compared by their convergence rates or\nregret bounds. While these rates and bounds convey valuable information they\ndon't always directly translate to stability guarantees. Stability and similar\nconcepts, like robustness, will become ever more important as we move towards\ndeploying models in real-time and safety critical systems. In this work we\nbuild upon the results in Gaudio et al. 2021 and Moreu and Annaswamy 2022 for\nsecond order gradient descent when applied to explicitly time varying cost\nfunctions and provide more general stability guarantees. These more general\nresults can aid in the design and certification of these optimization schemes\nso as to help ensure safe and reliable deployment for real-time learning\napplications. We also hope that the techniques provided here will stimulate and\ncross-fertilize the analysis that occurs on the same algorithms from the online\nlearning and stochastic optimization communities.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Travis E. Gibson",
            "Sawal Acharya",
            "Anjali Parashar",
            "Joseph E. Gaudio",
            "Anurdha M. Annaswamy"
        ],
        "published": "2024-05-22T15:50:40Z"
    },
    {
        "title": "Banded Square Root Matrix Factorization for Differentially Private Model\n  Training",
        "link": "http://arxiv.org/abs/2405.13763v1",
        "abstract": "Current state-of-the-art methods for differentially private model training\nare based on matrix factorization techniques. However, these methods suffer\nfrom high computational overhead because they require numerically solving a\ndemanding optimization problem to determine an approximately optimal\nfactorization prior to the actual model training. In this work, we present a\nnew matrix factorization approach, BSR, which overcomes this computational\nbottleneck. By exploiting properties of the standard matrix square root, BSR\nallows to efficiently handle also large-scale problems. For the key scenario of\nstochastic gradient descent with momentum and weight decay, we even derive\nanalytical expressions for BSR that render the computational overhead\nnegligible. We prove bounds on the approximation quality that hold both in the\ncentralized and in the federated learning setting. Our numerical experiments\ndemonstrate that models trained using BSR perform on par with the best existing\nmethods, while completely avoiding their computational overhead.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "authors": [
            "Nikita Kalinin",
            "Christoph Lampert"
        ],
        "published": "2024-05-22T15:47:35Z"
    },
    {
        "title": "A Versatile Diffusion Transformer with Mixture of Noise Levels for\n  Audiovisual Generation",
        "link": "http://arxiv.org/abs/2405.13762v1",
        "abstract": "Training diffusion models for audiovisual sequences allows for a range of\ngeneration tasks by learning conditional distributions of various input-output\ncombinations of the two modalities. Nevertheless, this strategy often requires\ntraining a separate model for each task which is expensive. Here, we propose a\nnovel training approach to effectively learn arbitrary conditional\ndistributions in the audiovisual space.Our key contribution lies in how we\nparameterize the diffusion timestep in the forward diffusion process. Instead\nof the standard fixed diffusion timestep, we propose applying variable\ndiffusion timesteps across the temporal dimension and across modalities of the\ninputs. This formulation offers flexibility to introduce variable noise levels\nfor various portions of the input, hence the term mixture of noise levels. We\npropose a transformer-based audiovisual latent diffusion model and show that it\ncan be trained in a task-agnostic fashion using our approach to enable a\nvariety of audiovisual generation tasks at inference time. Experiments\ndemonstrate the versatility of our method in tackling cross-modal and\nmultimodal interpolation tasks in the audiovisual space. Notably, our proposed\napproach surpasses baselines in generating temporally and perceptually\nconsistent samples conditioned on the input. Project page: avdit2024.github.io",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "cs.MM",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Gwanghyun Kim",
            "Alonso Martinez",
            "Yu-Chuan Su",
            "Brendan Jou",
            "Jos√© Lezama",
            "Agrim Gupta",
            "Lijun Yu",
            "Lu Jiang",
            "Aren Jansen",
            "Jacob Walker",
            "Krishna Somandepalli"
        ],
        "published": "2024-05-22T15:47:14Z"
    },
    {
        "title": "Enhancing Multiscale Simulations with Constitutive Relations-Aware Deep\n  Operator Networks",
        "link": "http://arxiv.org/abs/2405.13759v1",
        "abstract": "Multiscale problems are widely observed across diverse domains in physics and\nengineering. Translating these problems into numerical simulations and solving\nthem using numerical schemes, e.g. the finite element method, is costly due to\nthe demand of solving initial boundary-value problems at multiple scales. On\nthe other hand, multiscale finite element computations are commended for their\nability to integrate micro-structural properties into macroscopic computational\nanalyses using homogenization techniques. Recently, neural operator-based\nsurrogate models have shown trustworthy performance for solving a wide range of\npartial differential equations. In this work, we propose a hybrid method in\nwhich we utilize deep operator networks for surrogate modeling of the\nmicroscale physics. This allows us to embed the constitutive relations of the\nmicroscale into the model architecture and to predict microscale strains and\nstresses based on the prescribed macroscale strain inputs. Furthermore,\nnumerical homogenization is carried out to obtain the macroscale quantities of\ninterest. We apply the proposed approach to quasi-static problems of solid\nmechanics. The results demonstrate that our constitutive relations-aware\nDeepONet can yield accurate solutions even when being confronted with a\nrestricted dataset during model development.",
        "subjects": [
            "cs.LG",
            "cs.CE"
        ],
        "authors": [
            "Hamidreza Eivazi",
            "Mahyar Alikhani",
            "Jendrik-Alexander Tr√∂ger",
            "Stefan Wittek",
            "Stefan Hartmann",
            "Andreas Rausch"
        ],
        "published": "2024-05-22T15:40:05Z"
    },
    {
        "title": "Counterfactual Gradients-based Quantification of Prediction Trust in\n  Neural Networks",
        "link": "http://arxiv.org/abs/2405.13758v1",
        "abstract": "The widespread adoption of deep neural networks in machine learning calls for\nan objective quantification of esoteric trust. In this paper we propose\nGradTrust, a classification trust measure for large-scale neural networks at\ninference. The proposed method utilizes variance of counterfactual gradients,\ni.e. the required changes in the network parameters if the label were\ndifferent. We show that GradTrust is superior to existing techniques for\ndetecting misprediction rates on $50000$ images from ImageNet validation\ndataset. Depending on the network, GradTrust detects images where either the\nground truth is incorrect or ambiguous, or the classes are co-occurring. We\nextend GradTrust to Video Action Recognition on Kinetics-400 dataset. We\nshowcase results on $14$ architectures pretrained on ImageNet and $5$\narchitectures pretrained on Kinetics-400. We observe the following: (i) simple\nmethodologies like negative log likelihood and margin classifiers outperform\nstate-of-the-art uncertainty and out-of-distribution detection techniques for\nmisprediction rates, and (ii) the proposed GradTrust is in the Top-2 performing\nmethods on $37$ of the considered $38$ experimental modalities. The code is\navailable at: https://github.com/olivesgatech/GradTrust",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Mohit Prabhushankar",
            "Ghassan AlRegib"
        ],
        "published": "2024-05-22T15:39:54Z"
    },
    {
        "title": "A label-free and data-free training strategy for vasculature\n  segmentation in serial sectioning OCT data",
        "link": "http://arxiv.org/abs/2405.13757v1",
        "abstract": "Serial sectioning Optical Coherence Tomography (sOCT) is a high-throughput,\nlabel free microscopic imaging technique that is becoming increasingly popular\nto study post-mortem neurovasculature. Quantitative analysis of the vasculature\nrequires highly accurate segmentation; however, sOCT has low\nsignal-to-noise-ratio and displays a wide range of contrasts and artifacts that\ndepend on acquisition parameters. Furthermore, labeled data is scarce and\nextremely time consuming to generate. Here, we leverage synthetic datasets of\nvessels to train a deep learning segmentation model. We construct the vessels\nwith semi-realistic splines that simulate the vascular geometry and compare our\nmodel with realistic vascular labels generated by constrained constructive\noptimization. Both approaches yield similar Dice scores, although with very\ndifferent false positive and false negative rates. This method addresses the\ncomplexity inherent in OCT images and paves the way for more accurate and\nefficient analysis of neurovascular structures.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG",
            "I.4.6; I.2.10; I.2.1; I.2.6; I.6.5; J.3"
        ],
        "authors": [
            "Etienne Chollet",
            "Yael Balbastre",
            "Caroline Magnain",
            "Bruce Fischl",
            "Hui Wang"
        ],
        "published": "2024-05-22T15:39:31Z"
    },
    {
        "title": "Offline RL via Feature-Occupancy Gradient Ascent",
        "link": "http://arxiv.org/abs/2405.13755v1",
        "abstract": "We study offline Reinforcement Learning in large infinite-horizon discounted\nMarkov Decision Processes (MDPs) when the reward and transition models are\nlinearly realizable under a known feature map. Starting from the classic\nlinear-program formulation of the optimal control problem in MDPs, we develop a\nnew algorithm that performs a form of gradient ascent in the space of feature\noccupancies, defined as the expected feature vectors that can potentially be\ngenerated by executing policies in the environment. We show that the resulting\nsimple algorithm satisfies strong computational and sample complexity\nguarantees, achieved under the least restrictive data coverage assumptions\nknown in the literature. In particular, we show that the sample complexity of\nour method scales optimally with the desired accuracy level and depends on a\nweak notion of coverage that only requires the empirical feature covariance\nmatrix to cover a single direction in the feature space (as opposed to covering\na full subspace). Additionally, our method is easy to implement and requires no\nprior knowledge of the coverage ratio (or even an upper bound on it), which\naltogether make it the strongest known algorithm for this setting to date.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Gergely Neu",
            "Nneka Okolo"
        ],
        "published": "2024-05-22T15:39:05Z"
    },
    {
        "title": "Grounding Toxicity in Real-World Events across Languages",
        "link": "http://arxiv.org/abs/2405.13754v1",
        "abstract": "Social media conversations frequently suffer from toxicity, creating\nsignificant issues for users, moderators, and entire communities. Events in the\nreal world, like elections or conflicts, can initiate and escalate toxic\nbehavior online. Our study investigates how real-world events influence the\norigin and spread of toxicity in online discussions across various languages\nand regions. We gathered Reddit data comprising 4.5 million comments from 31\nthousand posts in six different languages (Dutch, English, German, Arabic,\nTurkish and Spanish). We target fifteen major social and political world events\nthat occurred between 2020 and 2023. We observe significant variations in\ntoxicity, negative sentiment, and emotion expressions across different events\nand language communities, showing that toxicity is a complex phenomenon in\nwhich many different factors interact and still need to be investigated. We\nwill release the data for further research along with our code.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Wondimagegnhue Tsegaye Tufa",
            "Ilia Markov",
            "Piek Vossen"
        ],
        "published": "2024-05-22T15:38:53Z"
    },
    {
        "title": "A Dynamic Model of Performative Human-ML Collaboration: Theory and\n  Empirical Evidence",
        "link": "http://arxiv.org/abs/2405.13753v1",
        "abstract": "Machine learning (ML) models are increasingly used in various applications,\nfrom recommendation systems in e-commerce to diagnosis prediction in\nhealthcare. In this paper, we present a novel dynamic framework for thinking\nabout the deployment of ML models in a performative, human-ML collaborative\nsystem. In our framework, the introduction of ML recommendations changes the\ndata generating process of human decisions, which are only a proxy to the\nground truth and which are then used to train future versions of the model. We\nshow that this dynamic process in principle can converge to different stable\npoints, i.e. where the ML model and the Human+ML system have the same\nperformance. Some of these stable points are suboptimal with respect to the\nactual ground truth. We conduct an empirical user study with 1,408 participants\nto showcase this process. In the study, humans solve instances of the knapsack\nproblem with the help of machine learning predictions. This is an ideal setting\nbecause we can see how ML models learn to imitate human decisions and how this\nlearning process converges to a stable point. We find that for many levels of\nML performance, humans can improve the ML predictions to dynamically reach an\nequilibrium performance that is around 92% of the maximum knapsack value. We\nalso find that the equilibrium performance could be even higher if humans\nrationally followed the ML recommendations. Finally, we test whether monetary\nincentives can increase the quality of human decisions, but we fail to find any\npositive effect. Our results have practical implications for the deployment of\nML models in contexts where human decisions may deviate from the indisputable\nground truth.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.HC",
            "econ.GN",
            "q-fin.EC",
            "68T05",
            "I.2.1; I.2.6; K.6"
        ],
        "authors": [
            "Tom S√ºhr",
            "Samira Samadi",
            "Chiara Farronato"
        ],
        "published": "2024-05-22T15:38:30Z"
    },
    {
        "title": "GameVLM: A Decision-making Framework for Robotic Task Planning Based on\n  Visual Language Models and Zero-sum Games",
        "link": "http://arxiv.org/abs/2405.13751v1",
        "abstract": "With their prominent scene understanding and reasoning capabilities,\npre-trained visual-language models (VLMs) such as GPT-4V have attracted\nincreasing attention in robotic task planning. Compared with traditional task\nplanning strategies, VLMs are strong in multimodal information parsing and code\ngeneration and show remarkable efficiency. Although VLMs demonstrate great\npotential in robotic task planning, they suffer from challenges like\nhallucination, semantic complexity, and limited context. To handle such issues,\nthis paper proposes a multi-agent framework, i.e., GameVLM, to enhance the\ndecision-making process in robotic task planning. In this study, VLM-based\ndecision and expert agents are presented to conduct the task planning.\nSpecifically, decision agents are used to plan the task, and the expert agent\nis employed to evaluate these task plans. Zero-sum game theory is introduced to\nresolve inconsistencies among different agents and determine the optimal\nsolution. Experimental results on real robots demonstrate the efficacy of the\nproposed framework, with an average success rate of 83.3%.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "authors": [
            "Aoran Mei",
            "Jianhua Wang",
            "Guo-Niu Zhu",
            "Zhongxue Gan"
        ],
        "published": "2024-05-22T15:37:28Z"
    },
    {
        "title": "Computationally Efficient Sampling-Based Algorithm for Stability\n  Analysis of Nonlinear Systems",
        "link": "http://arxiv.org/abs/2405.13750v1",
        "abstract": "For complex nonlinear systems, it is challenging to design algorithms that\nare fast, scalable, and give an accurate approximation of the stability region.\nThis paper proposes a sampling-based approach to address these challenges. By\nextending the parametrization of quadratic Lyapunov functions with the system\ndynamics and formulating an $\\ell_1$ optimization to maximize the invariant set\nover a grid of the state space, we arrive at a computationally efficient\nalgorithm that estimates the domain of attraction (DOA) of nonlinear systems\naccurately by using only linear programming. The scalability of the Lyapunov\nfunction synthesis is further improved by combining the algorithm with\nADMM-based parallelization. To resolve the inherent approximative nature of\ngrid-based techniques, a small-scale nonlinear optimization is proposed. The\nperformance of the algorithm is evaluated and compared to state-of-the-art\nsolutions on several numerical examples.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "P√©ter Antal",
            "Tam√°s P√©ni",
            "Roland T√≥th"
        ],
        "published": "2024-05-22T15:36:42Z"
    },
    {
        "title": "Monocular Gaussian SLAM with Language Extended Loop Closure",
        "link": "http://arxiv.org/abs/2405.13748v1",
        "abstract": "Recently,3DGaussianSplattinghasshowngreatpotentialin visual Simultaneous\nLocalization And Mapping (SLAM). Existing methods have achieved encouraging\nresults on RGB-D SLAM, but studies of the monocular case are still scarce.\nMoreover, they also fail to correct drift errors due to the lack of loop\nclosure and global optimization. In this paper, we present MG-SLAM, a monocular\nGaussian SLAM with a language-extended loop closure module capable of\nperforming drift-corrected tracking and high-fidelity reconstruction while\nachieving a high-level understanding of the environment. Our key idea is to\nrepresent the global map as 3D Gaussian and use it to guide the estimation of\nthe scene geometry, thus mitigating the efforts of missing depth information.\nFurther, an additional language-extended loop closure module which is based on\nCLIP feature is designed to continually perform global optimization to correct\ndrift errors accumulated as the system runs. Our system shows promising results\non multiple challenging datasets in both tracking and mapping and even\nsurpasses some existing RGB-D methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Tian Lan",
            "Qinwei Lin",
            "Haoqian Wang"
        ],
        "published": "2024-05-22T15:33:23Z"
    },
    {
        "title": "Reducing Mid-Circuit Measurements via Probabilistic Circuits",
        "link": "http://arxiv.org/abs/2405.13747v1",
        "abstract": "Mid-circuit measurements and measurement-controlled gates are supported by an\nincreasing number of quantum hardware platforms and will become more relevant\nas an essential building block for quantum error correction. However,\nmid-circuit measurements impose significant demands on the quantum hardware due\nto the required signal analysis and classical feedback loop. This work presents\na static circuit optimization algorithm that can substitute some of these\nmeasurements with an equivalent circuit with randomized gate applications. Our\nmethod uses ideas from constant propagation to classically precompute\nmeasurement outcome probabilities. Our proposed optimization is efficient, as\nits runtime scales polynomially on the number of qubits and gates of the\ncircuit.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "authors": [
            "Yanbin Chen",
            "Innocenzo Fulginiti",
            "Christian B. Mendl"
        ],
        "published": "2024-05-22T15:33:19Z"
    },
    {
        "title": "CG-FedLLM: How to Compress Gradients in Federated Fune-tuning for Large\n  Language Models",
        "link": "http://arxiv.org/abs/2405.13746v2",
        "abstract": "The success of current Large-Language Models (LLMs) hinges on extensive\ntraining data that is collected and stored centrally, called Centralized\nLearning (CL). However, such a collection manner poses a privacy threat, and\none potential solution is Federated Learning (FL), which transfers gradients,\nnot raw data, among clients. Unlike traditional networks, FL for LLMs incurs\nsignificant communication costs due to their tremendous parameters. This study\nintroduces an innovative approach to compress gradients to improve\ncommunication efficiency during LLM FL, formulating the new FL pipeline named\nCG-FedLLM. This approach integrates an encoder on the client side to acquire\nthe compressed gradient features and a decoder on the server side to\nreconstruct the gradients. We also developed a novel training strategy that\ncomprises Temporal-ensemble Gradient-Aware Pre-training (TGAP) to identify\ncharacteristic gradients of the target model and Federated AutoEncoder-Involved\nFine-tuning (FAF) to compress gradients adaptively. Extensive experiments\nconfirm that our approach reduces communication costs and improves performance\n(e.g., average 3 points increment compared with traditional CL- and FL-based\nfine-tuning with LlaMA on a well-recognized benchmark, C-Eval). This\nimprovement is because our encoder-decoder, trained via TGAP and FAF, can\nfilter gradients while selectively preserving critical features. Furthermore,\nwe present a series of experimental analyses focusing on the signal-to-noise\nratio, compression rate, and robustness within this privacy-centric framework,\nproviding insight into developing more efficient and secure LLMs.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC"
        ],
        "authors": [
            "Huiwen Wu",
            "Xiaohan Li",
            "Deyi Zhang",
            "Xiaogang Xu",
            "Jiafei Wu",
            "Puning Zhao",
            "Zhe Liu"
        ],
        "published": "2024-05-22T15:32:38Z"
    },
    {
        "title": "NeurCross: A Self-Supervised Neural Approach for Representing Cross\n  Fields in Quad Mesh Generation",
        "link": "http://arxiv.org/abs/2405.13745v1",
        "abstract": "Quadrilateral mesh generation plays a crucial role in numerical simulations\nwithin Computer-Aided Design and Engineering (CAD/E). The quality of the cross\nfield is essential for generating a quadrilateral mesh. In this paper, we\npropose a self-supervised neural representation of the cross field, named\nNeurCross, comprising two modules: one to fit the signed distance function\n(SDF) and another to predict the cross field. Unlike most existing approaches\nthat operate directly on the given polygonal surface, NeurCross takes the SDF\nas a bridge to allow for SDF overfitting and the prediction of the cross field\nto proceed simultaneously. By utilizing a neural SDF, we achieve a smooth\nrepresentation of the base surface, minimizing the impact of piecewise planar\ndiscretization and minor surface variations. Moreover, the principal curvatures\nand directions are fully encoded by the Hessian of the SDF, enabling the\nregularization of the overall cross field through minor adjustments to the SDF.\nCompared to state-of-the-art methods, NeurCross significantly improves the\nplacement of singular points and the approximation accuracy between the input\ntriangular surface and the output quad mesh, as demonstrated in the teaser\nfigure.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Qiujie Dong",
            "Huibiao Wen",
            "Rui Xu",
            "Xiaokang Yu",
            "Jiaran Zhou",
            "Shuangmin Chen",
            "Shiqing Xin",
            "Changhe Tu",
            "Wenping Wang"
        ],
        "published": "2024-05-22T15:32:34Z"
    },
    {
        "title": "A Privacy Measure Turned Upside Down? Investigating the Use of HTTP\n  Client Hints on the Web",
        "link": "http://dx.doi.org/10.1145/3664476.3664478",
        "abstract": "HTTP client hints are a set of standardized HTTP request headers designed to\nmodernize and potentially replace the traditional user agent string. While the\nuser agent string exposes a wide range of information about the client's\nbrowser and device, client hints provide a controlled and structured approach\nfor clients to selectively disclose their capabilities and preferences to\nservers. Essentially, client hints aim at more effective and privacy-friendly\ndisclosure of browser or client properties than the user agent string.\n  We present a first long-term study of the use of HTTP client hints in the\nwild. We found that despite being implemented in almost all web browsers,\nserver-side usage of client hints remains generally low. However, in the\ncontext of third-party websites, which are often linked to trackers, the\nadoption rate is significantly higher. This is concerning because client hints\nallow the retrieval of more data from the client than the user agent string\nprovides, and there are currently no mechanisms for users to detect or control\nthis potential data leakage. Our work provides valuable insights for web users,\nbrowser vendors, and researchers by exposing potential privacy violations via\nclient hints and providing help in developing remediation strategies as well as\nfurther research.",
        "subjects": [
            "cs.CR",
            "cs.NI",
            "cs.SI"
        ],
        "authors": [
            "Stephan Wiefling",
            "Marian H√∂nscheid",
            "Luigi Lo Iacono"
        ],
        "published": "2024-05-22T15:32:12Z"
    },
    {
        "title": "Mining Action Rules for Defect Reduction Planning",
        "link": "http://arxiv.org/abs/2405.13740v1",
        "abstract": "Defect reduction planning plays a vital role in enhancing software quality\nand minimizing software maintenance costs. By training a black box machine\nlearning model and \"explaining\" its predictions, explainable AI for software\nengineering aims to identify the code characteristics that impact maintenance\nrisks. However, post-hoc explanations do not always faithfully reflect what the\noriginal model computes. In this paper, we introduce CounterACT, a\nCounterfactual ACTion rule mining approach that can generate defect reduction\nplans without black-box models. By leveraging action rules, CounterACT provides\na course of action that can be considered as a counterfactual explanation for\nthe class (e.g., buggy or not buggy) assigned to a piece of code. We compare\nthe effectiveness of CounterACT with the original action rule mining algorithm\nand six established defect reduction approaches on 9 software projects. Our\nevaluation is based on (a) overlap scores between proposed code changes and\nactual developer modifications; (b) improvement scores in future releases; and\n(c) the precision, recall, and F1-score of the plans. Our results show that,\ncompared to competing approaches, CounterACT's explainable plans achieve higher\noverlap scores at the release level (median 95%) and commit level (median\n85.97%), and they offer better trade-off between precision and recall (median\nF1-score 88.12%). Finally, we venture beyond planning and explore leveraging\nLarge Language models (LLM) for generating code edits from our generated plans.\nOur results show that suggested LLM code edits supported by our plans are\nactionable and are more likely to pass relevant test cases than vanilla LLM\ncode recommendations.",
        "subjects": [
            "cs.SE",
            "cs.LG"
        ],
        "authors": [
            "Khouloud Oueslati",
            "Gabriel Laberge",
            "Maxime Lamothe",
            "Foutse Khomh"
        ],
        "published": "2024-05-22T15:31:09Z"
    },
    {
        "title": "Memory capacity of three-layer neural networks with non-polynomial\n  activations",
        "link": "http://arxiv.org/abs/2405.13738v1",
        "abstract": "The minimal number of neurons required for a feedforward neural network to\ninterpolate $n$ generic input-output pairs from $\\mathbb{R}^d\\times \\mathbb{R}$\nis $\\Theta(\\sqrt{n})$. While previous results have shown that\n$\\Theta(\\sqrt{n})$ neurons are sufficient, they have been limited to logistic,\nHeaviside, and rectified linear unit (ReLU) as the activation function. Using a\ndifferent approach, we prove that $\\Theta(\\sqrt{n})$ neurons are sufficient as\nlong as the activation function is real analytic at a point and not a\npolynomial there. Thus, the only practical activation functions that our result\ndoes not apply to are piecewise polynomials. Importantly, this means that\nactivation functions can be freely chosen in a problem-dependent manner without\nloss of interpolation power.",
        "subjects": [
            "cs.LG",
            "math.OC",
            "15A03, 26B10"
        ],
        "authors": [
            "Liam Madden"
        ],
        "published": "2024-05-22T15:29:45Z"
    },
    {
        "title": "Towards Counting Markov Equivalence Classes with Logical Constraints",
        "link": "http://arxiv.org/abs/2405.13736v1",
        "abstract": "We initiate the study of counting Markov Equivalence Classes (MEC) under\nlogical constraints. MECs are equivalence classes of Directed Acyclic Graphs\n(DAGs) that encode the same conditional independence structure among the random\nvariables of a DAG model. Observational data can only allow to infer a DAG\nmodel up to Markov Equivalence. However, Markov equivalent DAGs can represent\ndifferent causal structures, potentially super-exponentially many. Hence,\nunderstanding MECs combinatorially is critical to understanding the complexity\nof causal inference. In this paper, we focus on analysing MECs of size one,\nwith logical constraints on the graph topology. We provide a polynomial-time\nalgorithm (w.r.t. the number of nodes) for enumerating essential DAGs (the only\nmembers of an MEC of size one) with arbitrary logical constraints expressed in\nfirst-order logic with two variables and counting quantifiers (C^2). Our work\nbrings together recent developments in tractable first-order model counting and\ncombinatorics of MECs.",
        "subjects": [
            "cs.LO"
        ],
        "authors": [
            "Davide Bizzaro",
            "Luciano Serafini",
            "Sagar Malhotra"
        ],
        "published": "2024-05-22T15:29:40Z"
    },
    {
        "title": "Transfer of Safety Controllers Through Learning Deep Inverse Dynamics\n  Model",
        "link": "http://arxiv.org/abs/2405.13735v1",
        "abstract": "Control barrier certificates have proven effective in formally guaranteeing\nthe safety of the control systems. However, designing a control barrier\ncertificate is a time-consuming and computationally expensive endeavor that\nrequires expert input in the form of domain knowledge and mathematical\nmaturity. Additionally, when a system undergoes slight changes, the new\ncontroller and its correctness certificate need to be recomputed, incurring\nsimilar computational challenges as those faced during the design of the\noriginal controller. Prior approaches have utilized transfer learning to\ntransfer safety guarantees in the form of a barrier certificate while\nmaintaining the control invariant. Unfortunately, in practical settings, the\nsource and the target environments often deviate substantially in their control\ninputs, rendering the aforementioned approach impractical. To address this\nchallenge, we propose integrating \\emph{inverse dynamics} -- a neural network\nthat suggests required action given a desired successor state -- of the target\nsystem with the barrier certificate of the source system to provide formal\nproof of safety. In addition, we propose a validity condition that, when met,\nguarantees correctness of the controller. We demonstrate the effectiveness of\nour approach through three case studies.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.LG",
            "cs.SY"
        ],
        "authors": [
            "Alireza Nadali",
            "Ashutosh Trivedi",
            "Majid Zamani"
        ],
        "published": "2024-05-22T15:28:43Z"
    },
    {
        "title": "Control, Transport and Sampling: Towards Better Loss Design",
        "link": "http://arxiv.org/abs/2405.13731v1",
        "abstract": "Leveraging connections between diffusion-based sampling, optimal transport,\nand optimal stochastic control through their shared links to the Schr\\\"odinger\nbridge problem, we propose novel objective functions that can be used to\ntransport $\\nu$ to $\\mu$, consequently sample from the target $\\mu$, via\noptimally controlled dynamics. We highlight the importance of the pathwise\nperspective and the role various optimality conditions on the path measure can\nplay for the design of valid training losses, the careful choice of which offer\nnumerical advantages in practical implementation.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.CO"
        ],
        "authors": [
            "Qijia Jiang",
            "David Nabergoj"
        ],
        "published": "2024-05-22T15:24:48Z"
    },
    {
        "title": "Subspace Mixed-FEM for Real-Time Heterogeneous Elastodynamics",
        "link": "http://arxiv.org/abs/2405.13730v1",
        "abstract": "We propose a reduced space mixed finite element method (MFEM) built on a\nSkinning Eigenmode subspace and material-aware cubature scheme. Our solver is\nwell-suited for simulating scenes with large material and geometric\nheterogeneities in real-time. This mammoth geometry is composed of 98,175\nvertices and 531,565 tetrahedral elements and with a heterogenous composition\nof widely varying materials of muscles ($E= 5\\times10^5$ Pa), joints\n($E=1\\times10^5$ Pa), and bone ($E=1\\times10^{10}$ Pa). The resulting\nsimulation runs at 120 frames per second (FPS).",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Ty Trusty",
            "Otman Benchekroun",
            "Eitan Grinspun",
            "Danny M. Kaufman",
            "David I. W. Levin"
        ],
        "published": "2024-05-22T15:24:06Z"
    },
    {
        "title": "ComboStoc: Combinatorial Stochasticity for Diffusion Generative Models",
        "link": "http://arxiv.org/abs/2405.13729v2",
        "abstract": "In this paper, we study an under-explored but important factor of diffusion\ngenerative models, i.e., the combinatorial complexity. Data samples are\ngenerally high-dimensional, and for various structured generation tasks, there\nare additional attributes which are combined to associate with data samples. We\nshow that the space spanned by the combination of dimensions and attributes is\ninsufficiently sampled by existing training scheme of diffusion generative\nmodels, causing degraded test time performance. We present a simple fix to this\nproblem by constructing stochastic processes that fully exploit the\ncombinatorial structures, hence the name ComboStoc. Using this simple strategy,\nwe show that network training is significantly accelerated across diverse data\nmodalities, including images and 3D structured shapes. Moreover, ComboStoc\nenables a new way of test time generation which uses insynchronized time steps\nfor different dimensions and attributes, thus allowing for varying degrees of\ncontrol over them.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "cs.GR"
        ],
        "authors": [
            "Rui Xu",
            "Jiepeng Wang",
            "Hao Pan",
            "Yang Liu",
            "Xin Tong",
            "Shiqing Xin",
            "Changhe Tu",
            "Taku Komura",
            "Wenping Wang"
        ],
        "published": "2024-05-22T15:23:10Z"
    },
    {
        "title": "Score-based Generative Models with Adaptive Momentum",
        "link": "http://arxiv.org/abs/2405.13726v1",
        "abstract": "Score-based generative models have demonstrated significant practical success\nin data-generating tasks. The models establish a diffusion process that\nperturbs the ground truth data to Gaussian noise and then learn the reverse\nprocess to transform noise into data. However, existing denoising methods such\nas Langevin dynamic and numerical stochastic differential equation solvers\nenjoy randomness but generate data slowly with a large number of score function\nevaluations, and the ordinary differential equation solvers enjoy faster\nsampling speed but no randomness may influence the sample quality. To this end,\nmotivated by the Stochastic Gradient Descent (SGD) optimization methods and the\nhigh connection between the model sampling process with the SGD, we propose\nadaptive momentum sampling to accelerate the transforming process without\nintroducing additional hyperparameters. Theoretically, we proved our method\npromises convergence under given conditions. In addition, we empirically show\nthat our sampler can produce more faithful images/graphs in small sampling\nsteps with 2 to 5 times speed up and obtain competitive scores compared to the\nbaselines on image and graph generation tasks.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ziqing Wen",
            "Xiaoge Deng",
            "Ping Luo",
            "Tao Sun",
            "Dongsheng Li"
        ],
        "published": "2024-05-22T15:20:27Z"
    },
    {
        "title": "InstaDrag: Lightning Fast and Accurate Drag-based Image Editing Emerging\n  from Videos",
        "link": "http://arxiv.org/abs/2405.13722v1",
        "abstract": "Accuracy and speed are critical in image editing tasks. Pan et al. introduced\na drag-based image editing framework that achieves pixel-level control using\nGenerative Adversarial Networks (GANs). A flurry of subsequent studies enhanced\nthis framework's generality by leveraging large-scale diffusion models.\nHowever, these methods often suffer from inordinately long processing times\n(exceeding 1 minute per edit) and low success rates. Addressing these issues\nhead on, we present InstaDrag, a rapid approach enabling high quality\ndrag-based image editing in ~1 second. Unlike most previous methods, we\nredefine drag-based editing as a conditional generation task, eliminating the\nneed for time-consuming latent optimization or gradient-based guidance during\ninference. In addition, the design of our pipeline allows us to train our model\non large-scale paired video frames, which contain rich motion information such\nas object translations, changing poses and orientations, zooming in and out,\netc. By learning from videos, our approach can significantly outperform\nprevious methods in terms of accuracy and consistency. Despite being trained\nsolely on videos, our model generalizes well to perform local shape\ndeformations not presented in the training data (e.g., lengthening of hair,\ntwisting rainbows, etc.). Extensive qualitative and quantitative evaluations on\nbenchmark datasets corroborate the superiority of our approach. The code and\nmodel will be released at https://github.com/magic-research/InstaDrag.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yujun Shi",
            "Jun Hao Liew",
            "Hanshu Yan",
            "Vincent Y. F. Tan",
            "Jiashi Feng"
        ],
        "published": "2024-05-22T15:14:00Z"
    },
    {
        "title": "Connectivity Shapes Implicit Regularization in Matrix Factorization\n  Models for Matrix Completion",
        "link": "http://arxiv.org/abs/2405.13721v1",
        "abstract": "Matrix factorization models have been extensively studied as a valuable\ntest-bed for understanding the implicit biases of overparameterized models.\nAlthough both low nuclear norm and low rank regularization have been studied\nfor these models, a unified understanding of when, how, and why they achieve\ndifferent implicit regularization effects remains elusive. In this work, we\nsystematically investigate the implicit regularization of matrix factorization\nfor solving matrix completion problems. We empirically discover that the\nconnectivity of observed data plays a crucial role in the implicit bias, with a\ntransition from low nuclear norm to low rank as data shifts from disconnected\nto connected with increased observations. We identify a hierarchy of intrinsic\ninvariant manifolds in the loss landscape that guide the training trajectory to\nevolve from low-rank to higher-rank solutions. Based on this finding, we\ntheoretically characterize the training trajectory as following the\nhierarchical invariant manifold traversal process, generalizing the\ncharacterization of Li et al. (2020) to include the disconnected case.\nFurthermore, we establish conditions that guarantee minimum nuclear norm,\nclosely aligning with our experimental findings, and we provide a dynamics\ncharacterization condition for ensuring minimum rank. Our work reveals the\nintricate interplay between data connectivity, training dynamics, and implicit\nregularization in matrix factorization models.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Zhiwei Bai",
            "Jiajie Zhao",
            "Yaoyu Zhang"
        ],
        "published": "2024-05-22T15:12:14Z"
    },
    {
        "title": "Upper and lower memory capacity bounds of transformers for next-token\n  prediction",
        "link": "http://arxiv.org/abs/2405.13718v1",
        "abstract": "Given a sequence of tokens, such as words, the task of next-token prediction\nis to predict the next-token conditional probability distribution. Decoder-only\ntransformers have become effective models for this task, but their properties\nare still not fully understood. In particular, the largest number of distinct\ncontext sequences that a decoder-only transformer can interpolate next-token\ndistributions for has not been established. To fill this gap, we prove upper\nand lower bounds on this number, which are equal up to a multiplicative\nconstant. We prove these bounds in the general setting where next-token\ndistributions can be arbitrary as well as the empirical setting where they are\ncalculated from a finite number of document sequences. Our lower bounds are for\none-layer transformers and our proofs highlight an important injectivity\nproperty satisfied by self-attention. Furthermore, we provide numerical\nevidence that the minimal number of parameters for memorization is sufficient\nfor being able to train the model to the entropy lower bound.",
        "subjects": [
            "cs.LG",
            "math.OC",
            "15A03, 26B35"
        ],
        "authors": [
            "Liam Madden",
            "Curtis Fox",
            "Christos Thrampoulidis"
        ],
        "published": "2024-05-22T15:09:41Z"
    },
    {
        "title": "Traffic Scenario Logic: A Spatial-Temporal Logic for Modeling and\n  Reasoning of Urban Traffic Scenarios",
        "link": "http://arxiv.org/abs/2405.13715v1",
        "abstract": "Formal representations of traffic scenarios can be used to generate test\ncases for the safety verification of autonomous driving. However, most existing\nmethods are limited in highway or highly simplified intersection scenarios due\nto the intricacy and diversity of traffic scenarios. In response, we propose\nTraffic Scenario Logic (TSL), which is a spatial-temporal logic designed for\nmodeling and reasoning of urban pedestrian-free traffic scenarios. TSL provides\na formal representation of the urban road network that can be derived from\nOpenDRIVE, i.e., the de facto industry standard of high-definition maps for\nautonomous driving, enabling the representation of a broad range of traffic\nscenarios. We implemented the reasoning of TSL using Telingo, i.e., a solver\nfor temporal programs based on the Answer Set Programming, and tested it on\ndifferent urban road layouts. Demonstrations show the effectiveness of TSL in\ntest scenario generation and its potential value in areas like decision-making\nand control verification of autonomous driving.",
        "subjects": [
            "cs.LO",
            "cs.AI"
        ],
        "authors": [
            "Ruolin Wang",
            "Yuejiao Xu",
            "Jianmin Ji"
        ],
        "published": "2024-05-22T15:06:50Z"
    },
    {
        "title": "Learning Diffusion Priors from Observations by Expectation Maximization",
        "link": "http://arxiv.org/abs/2405.13712v1",
        "abstract": "Diffusion models recently proved to be remarkable priors for Bayesian inverse\nproblems. However, training these models typically requires access to large\namounts of clean data, which could prove difficult in some settings. In this\nwork, we present a novel method based on the expectation-maximization algorithm\nfor training diffusion models from incomplete and noisy observations only.\nUnlike previous works, our method leads to proper diffusion models, which is\ncrucial for downstream tasks. As part of our method, we propose and motivate a\nnew posterior sampling scheme for unconditional diffusion models. We present\nempirical evidence supporting the effectiveness of our method.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Fran√ßois Rozet",
            "G√©r√¥me Andry",
            "Fran√ßois Lanusse",
            "Gilles Louppe"
        ],
        "published": "2024-05-22T15:04:06Z"
    },
    {
        "title": "VAE-Var: Variational-Autoencoder-Enhanced Variational Assimilation",
        "link": "http://arxiv.org/abs/2405.13711v1",
        "abstract": "Data assimilation refers to a set of algorithms designed to compute the\noptimal estimate of a system's state by refining the prior prediction (known as\nbackground states) using observed data. Variational assimilation methods rely\non the maximum likelihood approach to formulate a variational cost, with the\noptimal state estimate derived by minimizing this cost. Although traditional\nvariational methods have achieved great success and have been widely used in\nmany numerical weather prediction centers, they generally assume Gaussian\nerrors in the background states, which limits the accuracy of these algorithms\ndue to the inherent inaccuracies of this assumption. In this paper, we\nintroduce VAE-Var, a novel variational algorithm that leverages a variational\nautoencoder (VAE) to model a non-Gaussian estimate of the background error\ndistribution. We theoretically derive the variational cost under the VAE\nestimation and present the general formulation of VAE-Var; we implement VAE-Var\non low-dimensional chaotic systems and demonstrate through experimental results\nthat VAE-Var consistently outperforms traditional variational assimilation\nmethods in terms of accuracy across various observational settings.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.DS",
            "physics.ao-ph"
        ],
        "authors": [
            "Yi Xiao",
            "Qilong Jia",
            "Wei Xue",
            "Lei Bai"
        ],
        "published": "2024-05-22T15:01:05Z"
    },
    {
        "title": "Optimizing Lymphocyte Detection in Breast Cancer Whole Slide Imaging\n  through Data-Centric Strategies",
        "link": "http://arxiv.org/abs/2405.13710v1",
        "abstract": "Efficient and precise quantification of lymphocytes in histopathology slides\nis imperative for the characterization of the tumor microenvironment and\nimmunotherapy response insights. We developed a data-centric optimization\npipeline that attain great lymphocyte detection performance using an\noff-the-shelf YOLOv5 model, without any architectural modifications. Our\ncontribution that rely on strategic dataset augmentation strategies, includes\nnovel biological upsampling and custom visual cohesion transformations tailored\nto the unique properties of tissue imagery, and enables to dramatically improve\nmodel performances. Our optimization reveals a pivotal realization: given\nintensive customization, standard computational pathology models can achieve\nhigh-capability biomarker development, without increasing the architectural\ncomplexity. We showcase the interest of this approach in the context of breast\ncancer where our strategies lead to good lymphocyte detection performances,\nechoing a broadly impactful paradigm shift. Furthermore, our data curation\ntechniques enable crucial histological analysis benchmarks, highlighting\nimproved generalizable potential.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Amine Marzouki",
            "Zhuxian Guo",
            "Qinghe Zeng",
            "Camille Kurtz",
            "Nicolas Lom√©nie"
        ],
        "published": "2024-05-22T14:59:50Z"
    },
    {
        "title": "Requirements are All You Need: The Final Frontier for End-User Software\n  Engineering",
        "link": "http://arxiv.org/abs/2405.13708v1",
        "abstract": "What if end users could own the software development lifecycle from\nconception to deployment using only requirements expressed in language, images,\nvideo or audio? We explore this idea, building on the capabilities that\ngenerative Artificial Intelligence brings to software generation and\nmaintenance techniques. How could designing software in this way better serve\nend users? What are the implications of this process for the future of end-user\nsoftware engineering and the software development lifecycle? We discuss the\nresearch needed to bridge the gap between where we are today and these imagined\nsystems of the future.",
        "subjects": [
            "cs.SE",
            "cs.HC"
        ],
        "authors": [
            "Diana Robinson",
            "Christian Cabrera",
            "Andrew D. Gordon",
            "Neil D. Lawrence",
            "Lars Mennen"
        ],
        "published": "2024-05-22T14:57:21Z"
    },
    {
        "title": "Rethinking and Accelerating Graph Condensation: A Training-Free Approach\n  with Class Partition",
        "link": "http://arxiv.org/abs/2405.13707v1",
        "abstract": "The increasing prevalence of large-scale graphs poses a significant challenge\nfor graph neural network training, attributed to their substantial\ncomputational requirements. In response, graph condensation (GC) emerges as a\npromising data-centric solution aiming to substitute the large graph with a\nsmall yet informative condensed graph to facilitate data-efficient GNN\ntraining. However, existing GC methods suffer from intricate optimization\nprocesses, necessitating excessive computing resources. In this paper, we\nrevisit existing GC optimization strategies and identify two pervasive issues:\n1. various GC optimization strategies converge to class-level node feature\nmatching between the original and condensed graphs, making the optimization\ntarget coarse-grained despite the complex computations; 2. to bridge the\noriginal and condensed graphs, existing GC methods rely on a Siamese graph\nnetwork architecture that requires time-consuming bi-level optimization with\niterative gradient computations. To overcome these issues, we propose a\ntraining-free GC framework termed Class-partitioned Graph Condensation (CGC),\nwhich refines the node feature matching from the class-to-class paradigm into a\nnovel class-to-node paradigm. Remarkably, this refinement also simplifies the\nGC optimization as a class partition problem, which can be efficiently solved\nby any clustering methods. Moreover, CGC incorporates a pre-defined graph\nstructure to enable a closed-form solution for condensed node features,\neliminating the back-and-forth gradient descent in existing GC approaches\nwithout sacrificing accuracy. Extensive experiments demonstrate that CGC\nachieves state-of-the-art performance with a more efficient condensation\nprocess. For instance, compared with the seminal GC method (i.e., GCond), CGC\ncondenses the largest Reddit graph within 10 seconds, achieving a 2,680X\nspeedup and a 1.4% accuracy increase.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Xinyi Gao",
            "Tong Chen",
            "Wentao Zhang",
            "Junliang Yu",
            "Guanhua Ye",
            "Quoc Viet Hung Nguyen",
            "Hongzhi Yin"
        ],
        "published": "2024-05-22T14:57:09Z"
    },
    {
        "title": "Low Fidelity Digital Twin for Automated Driving Systems: Use Cases and\n  Automatic Generation",
        "link": "http://arxiv.org/abs/2405.13705v1",
        "abstract": "Automated driving systems are an integral part of the automotive industry.\nTools such as Robot Operating System and simulators support their development.\nHowever, in the end, the developers must test their algorithms on a real\nvehicle. To better observe the difference between reality and simulation--the\nreality gap--digital twin technology offers real-time communication between the\nreal vehicle and its model. We present low fidelity digital twin generator and\ndescribe situations where automatic generation is preferable to high fidelity\nsimulation. We validated our approach of generating a virtual environment with\na vehicle model by replaying the data recorded from the real vehicle.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Jiri Vlasak",
            "Jaroslav Klap√°lek",
            "Adam Kollarƒç√≠k",
            "Michal Sojka",
            "Zdenƒõk Hanz√°lek"
        ],
        "published": "2024-05-22T14:50:05Z"
    },
    {
        "title": "Safe and Personalizable Logical Guidance for Trajectory Planning of\n  Autonomous Driving",
        "link": "http://arxiv.org/abs/2405.13704v1",
        "abstract": "Autonomous vehicles necessitate a delicate balance between safety,\nefficiency, and user preferences in trajectory planning. Existing traditional\nor learning-based methods face challenges in adequately addressing all these\naspects. In response, this paper proposes a novel component termed the Logical\nGuidance Layer (LGL), designed for seamless integration into autonomous driving\ntrajectory planning frameworks, specifically tailored for highway scenarios.\nThe LGL guides the trajectory planning with a local target area determined\nthrough scenario reasoning, scenario evaluation, and guidance area calculation.\nIntegrating the Responsibility-Sensitive Safety (RSS) model, the LGL ensures\nformal safety guarantees while accommodating various user preferences defined\nby logical formulae. Experimental validation demonstrates the effectiveness of\nthe LGL in achieving a balance between safety and efficiency, and meeting user\npreferences in autonomous highway driving scenarios.",
        "subjects": [
            "cs.RO",
            "cs.LO"
        ],
        "authors": [
            "Yuejiao Xu",
            "Ruolin Wang",
            "Chengpeng Xu",
            "Jianmin Ji"
        ],
        "published": "2024-05-22T14:49:06Z"
    },
    {
        "title": "Metabook: An Automatically Generated Augmented Reality Storybook\n  Interaction System to Improve Children's Engagement in Storytelling",
        "link": "http://arxiv.org/abs/2405.13701v1",
        "abstract": "Storytelling serves as a crucial avenue for children to acquire knowledge,\noffering numerous benefits such as enhancing children's sensitivity to various\nforms of syntax, diction, and rhetoric; recognizing patterns in language and\nhuman experience; stimulating creativity; and providing practice in\nproblem-solving, decision-making, and evaluation. However, current storytelling\nbook facing these problems:1.Traditional 3D storybooks lack flexibility in\ndealing with text changing, as adding a new story requires remaking of the 3D\nbook by artists. 2. Children often have many questions after reading stories,\nbut traditional 3D books are unable to provide answers or explanations for\nchildren.3.Children can easily feel bored when reading text, and traditional 3D\nbooks still rely on text to tell stories, thus limiting their ability to\nincrease children's enthusiasm for reading. So, we propose the Metabook: an\nautomatically generated interactive 3D storybook. Our main contributions are as\nfollows: First, we propose a story to 3D generation scheme, enabling 3D books\nto be automatically generated based on stories. Next, we introduce cartoon\nMetahumans for storytelling, utilizing lip-syncing and eye-tracking technology\nto enable facial interaction with children, enhancing the fun of reading. Last\nbut not least, we connect GPT-4 to the brain of the metahuman, which provides\nanswers and explanations to the questions children have after reading.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Yibo Wang",
            "Yuanyuan Mao",
            "Shi-ting Ni"
        ],
        "published": "2024-05-22T14:46:09Z"
    },
    {
        "title": "Uncertainty-aware Evaluation of Auxiliary Anomalies with the Expected\n  Anomaly Posterior",
        "link": "http://arxiv.org/abs/2405.13699v1",
        "abstract": "Anomaly detection is the task of identifying examples that do not behave as\nexpected. Because anomalies are rare and unexpected events, collecting real\nanomalous examples is often challenging in several applications. In addition,\nlearning an anomaly detector with limited (or no) anomalies often yields poor\nprediction performance. One option is to employ auxiliary synthetic anomalies\nto improve the model training. However, synthetic anomalies may be of poor\nquality: anomalies that are unrealistic or indistinguishable from normal\nsamples may deteriorate the detector's performance. Unfortunately, no existing\nmethods quantify the quality of auxiliary anomalies. We fill in this gap and\npropose the expected anomaly posterior (EAP), an uncertainty-based score\nfunction that measures the quality of auxiliary anomalies by quantifying the\ntotal uncertainty of an anomaly detector. Experimentally on 40 benchmark\ndatasets of images and tabular data, we show that EAP outperforms 12 adapted\ndata quality estimators in the majority of cases.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Lorenzo Perini",
            "Maja Rudolph",
            "Sabrina Schmedding",
            "Chen Qiu"
        ],
        "published": "2024-05-22T14:43:29Z"
    },
    {
        "title": "How to set AdamW's weight decay as you scale model and dataset size",
        "link": "http://arxiv.org/abs/2405.13698v1",
        "abstract": "We show that weights learned by AdamW can be understood as an exponential\nmoving average (EMA) of recent updates. This gives critical insights for how to\nset the weight decay in AdamW, and how the weight decay should scale with model\nand dataset size. In particular, the key hyperparameter for an exponential\nmoving average is the EMA timescale. Intuitively, the EMA timescale can be\nunderstood as the number of recent iterations the EMA averages over. Given a\nfixed learning rate, there is a one-to-one mapping from the EMA timescale to\nthe usual weight decay hyperparameter. Thus, choosing an EMA timescale\nimplicitly sets the weight decay. Importantly, there are natural guidelines for\nsensible values for the EMA timescale: we need to average over all datapoints,\nso the EMA timescale should not be (much) smaller than 1 epoch, and we need to\nforget early updates, so the EMA timescale should not be (much) bigger than the\ntotal number of training epochs. In our experiments, we find that optimal EMA\ntimescales are consistent with these guidelines, as are the hyperparameters\nchosen in recent large-scale LLM pretraining runs (e.g.\\ Llama 1+2 and Stable\nLM). Critically, these guidelines suggest that the optimal EMA timescale should\nnot change (much) as we scale the model and dataset. That implies that as the\ndataset size increases, the optimal weight decay should fall. Moreover, as the\nmodel size increases, the optimal weight decay should also increase (if we\nfollow the muP recommendation for scaling the learning rate).",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Xi Wang",
            "Laurence Aitchison"
        ],
        "published": "2024-05-22T14:43:02Z"
    },
    {
        "title": "The complexity of deciding characteristic formulae in van Glabbeek's\n  branching-time spectrum",
        "link": "http://arxiv.org/abs/2405.13697v1",
        "abstract": "Characteristic formulae give a complete logical description of the behaviour\nof processes modulo some chosen notion of behavioural semantics. They allow one\nto reduce equivalence or preorder checking to model checking, and are exactly\nthe formulae in the modal logics characterizing classic behavioural\nequivalences and preorders for which model checking can be reduced to\nequivalence or preorder checking.\n  This paper studies the complexity of determining whether a formula is\ncharacteristic for some finite, loop-free process in each of the logics\nproviding modal characterizations of the simulation-based semantics in van\nGlabbeek's branching-time spectrum. Since characteristic formulae in each of\nthose logics are exactly the consistent and prime ones, it presents complexity\nresults for the satisfiability and primality problems, and investigates the\nboundary between modal logics for which those problems can be solved in\npolynomial time and those for which they become computationally hard.\n  Amongst other contributions, this article also studies the complexity of\nconstructing characteristic formulae in the modal logics characterizing\nsimulation-based semantics, both when such formulae are presented in explicit\nform and via systems of equations.",
        "subjects": [
            "cs.LO"
        ],
        "authors": [
            "Luca Aceto",
            "Antonis Achilleos",
            "Aggeliki Chalki",
            "Anna Ingolfsdottir"
        ],
        "published": "2024-05-22T14:41:47Z"
    },
    {
        "title": "Total cost of ownership and evaluation of Google cloud resources for the\n  ATLAS experiment at the LHC",
        "link": "http://arxiv.org/abs/2405.13695v1",
        "abstract": "The ATLAS Google Project was established as part of an ongoing evaluation of\nthe use of commercial clouds by the ATLAS Collaboration, in anticipation of the\npotential future adoption of such resources by WLCG grid sites to fulfil or\ncomplement their computing pledges. Seamless integration of Google cloud\nresources into the worldwide ATLAS distributed computing infrastructure was\nachieved at large scale and for an extended period of time, and hence cloud\nresources are shown to be an effective mechanism to provide additional,\nflexible computing capacity to ATLAS. For the first time a total cost of\nownership analysis has been performed, to identify the dominant cost drivers\nand explore effective mechanisms for cost control. Network usage significantly\nimpacts the costs of certain ATLAS workflows, underscoring the importance of\nimplementing such mechanisms. Resource bursting has been successfully\ndemonstrated, whilst exposing the true cost of this type of activity. A\nfollow-up to the project is underway to investigate methods for improving the\nintegration of cloud resources in data-intensive distributed computing\nenvironments and reducing costs related to network connectivity, which\nrepresents the primary expense when extensively utilising cloud resources.",
        "subjects": [
            "cs.DC",
            "hep-ex"
        ],
        "authors": [
            " The ATLAS Collaboration"
        ],
        "published": "2024-05-22T14:41:38Z"
    },
    {
        "title": "Gaussian Time Machine: A Real-Time Rendering Methodology for\n  Time-Variant Appearances",
        "link": "http://arxiv.org/abs/2405.13694v1",
        "abstract": "Recent advancements in neural rendering techniques have significantly\nenhanced the fidelity of 3D reconstruction. Notably, the emergence of 3D\nGaussian Splatting (3DGS) has marked a significant milestone by adopting a\ndiscrete scene representation, facilitating efficient training and real-time\nrendering. Several studies have successfully extended the real-time rendering\ncapability of 3DGS to dynamic scenes. However, a challenge arises when training\nimages are captured under vastly differing weather and lighting conditions.\nThis scenario poses a challenge for 3DGS and its variants in achieving accurate\nreconstructions. Although NeRF-based methods (NeRF-W, CLNeRF) have shown\npromise in handling such challenging conditions, their computational demands\nhinder real-time rendering capabilities. In this paper, we present Gaussian\nTime Machine (GTM) which models the time-dependent attributes of Gaussian\nprimitives with discrete time embedding vectors decoded by a lightweight\nMulti-Layer-Perceptron(MLP). By adjusting the opacity of Gaussian primitives,\nwe can reconstruct visibility changes of objects. We further propose a\ndecomposed color model for improved geometric consistency. GTM achieved\nstate-of-the-art rendering fidelity on 3 datasets and is 100 times faster than\nNeRF-based counterparts in rendering. Moreover, GTM successfully disentangles\nthe appearance changes and renders smooth appearance interpolation.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Licheng Shen",
            "Ho Ngai Chow",
            "Lingyun Wang",
            "Tong Zhang",
            "Mengqiu Wang",
            "Yuxing Han"
        ],
        "published": "2024-05-22T14:40:42Z"
    },
    {
        "title": "Uncovering Algorithmic Discrimination: An Opportunity to Revisit the\n  Comparator",
        "link": "http://arxiv.org/abs/2405.13693v1",
        "abstract": "Causal reasoning, in particular, counterfactual reasoning plays a central\nrole in testing for discrimination. Counterfactual reasoning materializes when\ntesting for discrimination, what is known as the counterfactual model of\ndiscrimination, when we compare the discrimination comparator with the\ndiscrimination complainant, where the comparator is a similar (or similarly\nsituated) profile to that of the complainant used for testing the\ndiscrimination claim of the complainant. In this paper, we revisit the\ncomparator by presenting two kinds of comparators based on the sort of causal\nintervention we want to represent. We present the ceteris paribus and the\nmutatis mutandis comparator, where the former is the standard and the latter is\na new kind of comparator. We argue for the use of the mutatis mutandis\ncomparator, which is built on the fairness given the difference notion, for\ntesting future algorithmic discrimination cases.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Jose M. Alvarez",
            "Salvatore Ruggieri"
        ],
        "published": "2024-05-22T14:39:07Z"
    },
    {
        "title": "Challenging Gradient Boosted Decision Trees with Tabular Transformers\n  for Fraud Detection at Booking.com",
        "link": "http://arxiv.org/abs/2405.13692v1",
        "abstract": "Transformer-based neural networks, empowered by Self-Supervised Learning\n(SSL), have demonstrated unprecedented performance across various domains.\nHowever, related literature suggests that tabular Transformers may struggle to\noutperform classical Machine Learning algorithms, such as Gradient Boosted\nDecision Trees (GBDT). In this paper, we aim to challenge GBDTs with tabular\nTransformers on a typical task faced in e-commerce, namely fraud detection. Our\nstudy is additionally motivated by the problem of selection bias, often\noccurring in real-life fraud detection systems. It is caused by the production\nsystem affecting which subset of traffic becomes labeled. This issue is\ntypically addressed by sampling randomly a small part of the whole production\ndata, referred to as a Control Group. This subset follows a target distribution\nof production data and therefore is usually preferred for training\nclassification models with standard ML algorithms. Our methodology leverages\nthe capabilities of Transformers to learn transferable representations using\nall available data by means of SSL, giving it an advantage over classical\nmethods. Furthermore, we conduct large-scale experiments, pre-training tabular\nTransformers on vast amounts of data instances and fine-tuning them on smaller\ntarget datasets. The proposed approach outperforms heavily tuned GBDTs by a\nconsiderable margin of the Average Precision (AP) score. Pre-trained models\nshow more consistent performance than the ones trained from scratch when\nfine-tuning data is limited. Moreover, they require noticeably less labeled\ndata for reaching performance comparable to their GBDT competitor that utilizes\nthe whole dataset.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Sergei Krutikov",
            "Bulat Khaertdinov",
            "Rodion Kiriukhin",
            "Shubham Agrawal",
            "Kees Jan De Vries"
        ],
        "published": "2024-05-22T14:38:48Z"
    },
    {
        "title": "Neural Networks-based Random Vortex Methods for Modelling Incompressible\n  Flows",
        "link": "http://arxiv.org/abs/2405.13691v1",
        "abstract": "In this paper we introduce a novel Neural Networks-based approach for\napproximating solutions to the (2D) incompressible Navier--Stokes equations.\nOur algorithm uses a Physics-informed Neural Network, that approximates the\nvorticity based on a loss function that uses a computationally efficient\nformulation of the Random Vortex dynamics. The neural vorticity estimator is\nthen combined with traditional numerical PDE-solvers for the Poisson equation\nto compute the velocity field. The main advantage of our method compared to\nstandard Physics-informed Neural Networks is that it strictly enforces physical\nproperties, such as incompressibility or boundary conditions, which might\notherwise be hard to guarantee with purely Neural Networks-based approaches.",
        "subjects": [
            "physics.flu-dyn",
            "cs.NA",
            "math.NA",
            "math.PR",
            "stat.ML",
            "76M35, 76M23, 60H30, 65C05, 68Q10, 68T07"
        ],
        "authors": [
            "Vladislav Cherepanov",
            "Sebastian W. Ertel"
        ],
        "published": "2024-05-22T14:36:23Z"
    },
    {
        "title": "Embedding Generalized Semantic Knowledge into Few-Shot Remote Sensing\n  Segmentation",
        "link": "http://arxiv.org/abs/2405.13686v1",
        "abstract": "Few-shot segmentation (FSS) for remote sensing (RS) imagery leverages\nsupporting information from limited annotated samples to achieve query\nsegmentation of novel classes. Previous efforts are dedicated to mining\nsegmentation-guiding visual cues from a constrained set of support samples.\nHowever, they still struggle to address the pronounced intra-class differences\nin RS images, as sparse visual cues make it challenging to establish robust\nclass-specific representations. In this paper, we propose a holistic semantic\nembedding (HSE) approach that effectively harnesses general semantic knowledge,\ni.e., class description (CD) embeddings.Instead of the naive combination of CD\nembeddings and visual features for segmentation decoding, we investigate\nembedding the general semantic knowledge during the feature extraction\nstage.Specifically, in HSE, a spatial dense interaction module allows the\ninteraction of visual support features with CD embeddings along the spatial\ndimension via self-attention.Furthermore, a global content modulation module\nefficiently augments the global information of the target category in both\nsupport and query features, thanks to the transformative fusion of visual\nfeatures and CD embeddings.These two components holistically synergize general\nCD embeddings and visual cues, constructing a robust class-specific\nrepresentation.Through extensive experiments on the standard FSS benchmark, the\nproposed HSE approach demonstrates superior performance compared to peer work,\nsetting a new state-of-the-art.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yuyu Jia",
            "Wei Huang",
            "Junyu Gao",
            "Qi Wang",
            "Qiang Li"
        ],
        "published": "2024-05-22T14:26:04Z"
    },
    {
        "title": "Prompt Mixing in Diffusion Models using the Black Scholes Algorithm",
        "link": "http://arxiv.org/abs/2405.13685v1",
        "abstract": "We introduce a novel approach for prompt mixing, aiming to generate images at\nthe intersection of multiple text prompts using pre-trained text-to-image\ndiffusion models. At each time step during diffusion denoising, our algorithm\nforecasts predictions w.r.t. the generated image and makes informed text\nconditioning decisions. To do so, we leverage the connection between diffusion\nmodels (rooted in non-equilibrium thermodynamics) and the Black-Scholes model\nfor pricing options in Finance, and draw analogies between the variables in\nboth contexts to derive an appropriate algorithm for prompt mixing using the\nBlack Scholes model. Specifically, the parallels between diffusion models and\nthe Black-Scholes model enable us to leverage properties related to the\ndynamics of the Markovian model derived in the Black-Scholes algorithm. Our\nprompt-mixing algorithm is data-efficient, meaning it does not need additional\ntraining. Furthermore, it operates without human intervention or hyperparameter\ntuning. We highlight the benefits of our approach by comparing it qualitatively\nand quantitatively to other prompt mixing techniques, including linear\ninterpolation, alternating prompts, step-wise prompt switching, and CLIP-guided\nprompt selection across various scenarios such as single object per text\nprompt, multiple objects per text prompt and objects against backgrounds. Code\nis available at https://github.com/divyakraman/BlackScholesDiffusion2024.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Divya Kothandaraman",
            "Ming Lin",
            "Dinesh Manocha"
        ],
        "published": "2024-05-22T14:25:57Z"
    },
    {
        "title": "CrossCheckGPT: Universal Hallucination Ranking for Multimodal Foundation\n  Models",
        "link": "http://arxiv.org/abs/2405.13684v1",
        "abstract": "Multimodal foundation models are prone to hallucination, generating outputs\nthat either contradict the input or are not grounded by factual information.\nGiven the diversity in architectures, training data and instruction tuning\ntechniques, there can be large variations in systems' susceptibility to\nhallucinations. To assess system hallucination robustness, hallucination\nranking approaches have been developed for specific tasks such as image\ncaptioning, question answering, summarization, or biography generation.\nHowever, these approaches typically compare model outputs to gold-standard\nreferences or labels, limiting hallucination benchmarking for new domains. This\nwork proposes \"CrossCheckGPT\", a reference-free universal hallucination ranking\nfor multimodal foundation models. The core idea of CrossCheckGPT is that the\nsame hallucinated content is unlikely to be generated by different independent\nsystems, hence cross-system consistency can provide meaningful and accurate\nhallucination assessment scores. CrossCheckGPT can be applied to any model or\ntask, provided that the information consistency between outputs can be measured\nthrough an appropriate distance metric. Focusing on multimodal large language\nmodels that generate text, we explore two information consistency measures:\nCrossCheck-explicit and CrossCheck-implicit. We showcase the applicability of\nour method for hallucination ranking across various modalities, namely the\ntext, image, and audio-visual domains. Further, we propose the first\naudio-visual hallucination benchmark, \"AVHalluBench\", and illustrate the\neffectiveness of CrossCheckGPT, achieving correlations of 98% and 89% with\nhuman judgements on MHaluBench and AVHalluBench, respectively.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Guangzhi Sun",
            "Potsawee Manakul",
            "Adian Liusie",
            "Kunat Pipatanakul",
            "Chao Zhang",
            "Phil Woodland",
            "Mark Gales"
        ],
        "published": "2024-05-22T14:25:41Z"
    },
    {
        "title": "Constructive Universal Approximation Theorems for Deep Joint-Equivariant\n  Networks by Schur's Lemma",
        "link": "http://arxiv.org/abs/2405.13682v1",
        "abstract": "We present a unified constructive universal approximation theorem covering a\nwide range of learning machines including both shallow and deep neural networks\nbased on the group representation theory. Constructive here means that the\ndistribution of parameters is given in a closed-form expression (called the\nridgelet transform). Contrary to the case of shallow models, expressive power\nanalysis of deep models has been conducted in a case-by-case manner. Recently,\nSonoda et al. (2023a,b) developed a systematic method to show a constructive\napproximation theorem from scalar-valued joint-group-invariant feature maps,\ncovering a formal deep network. However, each hidden layer was formalized as an\nabstract group action, so it was not possible to cover real deep networks\ndefined by composites of nonlinear activation function. In this study, we\nextend the method for vector-valued joint-group-equivariant feature maps, so to\ncover such real networks.",
        "subjects": [
            "cs.LG",
            "math.RT",
            "stat.ML"
        ],
        "authors": [
            "Sho Sonoda",
            "Yuka Hashimoto",
            "Isao Ishikawa",
            "Masahiro Ikeda"
        ],
        "published": "2024-05-22T14:25:02Z"
    },
    {
        "title": "Integrated Sensing and Communication Exploiting Prior Information: How\n  Many Sensing Beams are Needed?",
        "link": "http://arxiv.org/abs/2405.13678v1",
        "abstract": "This paper studies an integrated sensing and communication (ISAC) system\nwhere a multi-antenna base station (BS) aims to communicate with a\nsingle-antenna user in the downlink and sense the unknown and random angle\nparameter of a target via exploiting its prior distribution information. We\nconsider a general transmit beamforming structure where the BS sends one\ncommunication beam and potentially one or multiple dedicated sensing beam(s).\nFirstly, motivated by the periodic feature of the angle parameter, we derive\nthe periodic posterior Cram\\'{e}r-Rao bound (PCRB) for quantifying a lower\nbound of the mean-cyclic error (MCE), which is more accurate than the\nconventional PCRB for bounding the mean-squared error (MSE). Then, note that\nmore sensing beams enable higher flexibility in enhancing the sensing\nperformance, while also generating extra interference to the communication\nuser. To resolve this trade-off, we formulate the transmit beamforming\noptimization problem to minimize the periodic PCRB subject to a communication\nrate requirement for the user. Despite the non-convexity of this problem, we\nderive the optimal solution by leveraging the semi-definite relaxation (SDR)\ntechnique and Lagrange duality theory. Moreover, we analytically prove that at\nmost one dedicated sensing beam is needed. Numerical results validate our\nanalysis and the advantage of having a dedicated sensing beam.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Chan Xu",
            "Shuowen Zhang"
        ],
        "published": "2024-05-22T14:21:09Z"
    },
    {
        "title": "Naturally Private Recommendations with Determinantal Point Processes",
        "link": "http://arxiv.org/abs/2405.13677v1",
        "abstract": "Often we consider machine learning models or statistical analysis methods\nwhich we endeavour to alter, by introducing a randomized mechanism, to make the\nmodel conform to a differential privacy constraint. However, certain models can\noften be implicitly differentially private or require significantly fewer\nalterations. In this work, we discuss Determinantal Point Processes (DPPs)\nwhich are dispersion models that balance recommendations based on both the\npopularity and the diversity of the content. We introduce DPPs, derive and\ndiscuss the alternations required for them to satisfy epsilon-Differential\nPrivacy and provide an analysis of their sensitivity. We conclude by proposing\nsimple alternatives to DPPs which would make them more efficient with respect\nto their privacy-utility trade-off.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "authors": [
            "Jack Fitzsimons",
            "Agust√≠n Freitas Pasqualini",
            "Robert Pisarczyk",
            "Dmitrii Usynin"
        ],
        "published": "2024-05-22T14:20:56Z"
    },
    {
        "title": "Context and Geometry Aware Voxel Transformer for Semantic Scene\n  Completion",
        "link": "http://arxiv.org/abs/2405.13675v1",
        "abstract": "Vision-based Semantic Scene Completion (SSC) has gained much attention due to\nits widespread applications in various 3D perception tasks. Existing\nsparse-to-dense approaches typically employ shared context-independent queries\nacross various input images, which fails to capture distinctions among them as\nthe focal regions of different inputs vary and may result in undirected feature\naggregation of cross-attention. Additionally, the absence of depth information\nmay lead to points projected onto the image plane sharing the same 2D position\nor similar sampling points in the feature map, resulting in depth ambiguity. In\nthis paper, we present a novel context and geometry aware voxel transformer. It\nutilizes a context aware query generator to initialize context-dependent\nqueries tailored to individual input images, effectively capturing their unique\ncharacteristics and aggregating information within the region of interest.\nFurthermore, it extend deformable cross-attention from 2D to 3D pixel space,\nenabling the differentiation of points with similar image coordinates based on\ntheir depth coordinates. Building upon this module, we introduce a neural\nnetwork named CGFormer to achieve semantic scene completion. Simultaneously,\nCGFormer leverages multiple 3D representations (i.e., voxel and TPV) to boost\nthe semantic and geometric representation abilities of the transformed 3D\nvolume from both local and global perspectives. Experimental results\ndemonstrate that CGFormer achieves state-of-the-art performance on the\nSemanticKITTI and SSCBench-KITTI-360 benchmarks, attaining a mIoU of 16.87 and\n20.05, as well as an IoU of 45.99 and 48.07, respectively. Remarkably, CGFormer\neven outperforms approaches employing temporal images as inputs or much larger\nimage backbone networks. Code for the proposed method is available at\nhttps://github.com/pkqbajng/CGFormer.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhu Yu",
            "Runming Zhang",
            "Jiacheng Ying",
            "Junchen Yu",
            "Xiaohai Hu",
            "Lun Luo",
            "Siyuan Cao",
            "Huiliang Shen"
        ],
        "published": "2024-05-22T14:16:30Z"
    },
    {
        "title": "Advancing Spiking Neural Networks towards Multiscale Spatiotemporal\n  Interaction Learning",
        "link": "http://arxiv.org/abs/2405.13672v1",
        "abstract": "Recent advancements in neuroscience research have propelled the development\nof Spiking Neural Networks (SNNs), which not only have the potential to further\nadvance neuroscience research but also serve as an energy-efficient alternative\nto Artificial Neural Networks (ANNs) due to their spike-driven characteristics.\nHowever, previous studies often neglected the multiscale information and its\nspatiotemporal correlation between event data, leading SNN models to\napproximate each frame of input events as static images. We hypothesize that\nthis oversimplification significantly contributes to the performance gap\nbetween SNNs and traditional ANNs. To address this issue, we have designed a\nSpiking Multiscale Attention (SMA) module that captures multiscale\nspatiotemporal interaction information. Furthermore, we developed a\nregularization method named Attention ZoneOut (AZO), which utilizes\nspatiotemporal attention weights to reduce the model's generalization error\nthrough pseudo-ensemble training. Our approach has achieved state-of-the-art\nresults on mainstream neural morphology datasets. Additionally, we have reached\na performance of 77.1% on the Imagenet-1K dataset using a 104-layer ResNet\narchitecture enhanced with SMA and AZO. This achievement confirms the\nstate-of-the-art performance of SNNs with non-transformer architectures and\nunderscores the effectiveness of our method in bridging the performance gap\nbetween SNN models and traditional ANN models.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yimeng Shan",
            "Malu Zhang",
            "Rui-jie Zhu",
            "Xuerui Qiu",
            "Jason K. Eshraghian",
            "Haicheng Qu"
        ],
        "published": "2024-05-22T14:16:05Z"
    },
    {
        "title": "GNN-based Anomaly Detection for Encoded Network Traffic",
        "link": "http://arxiv.org/abs/2405.13670v1",
        "abstract": "The early research report explores the possibility of using Graph Neural\nNetworks (GNNs) for anomaly detection in internet traffic data enriched with\ninformation. While recent studies have made significant progress in using GNNs\nfor anomaly detection in finance, multivariate time-series, and biochemistry\ndomains, there is limited research in the context of network flow data. In this\nreport, we explore the idea that leverages information-enriched features\nextracted from network flow packet data to improve the performance of GNN in\nanomaly detection. The idea is to utilize feature encoding (binary, numerical,\nand string) to capture the relationships between the network components,\nallowing the GNN to learn latent relationships and better identify anomalies.",
        "subjects": [
            "cs.SI",
            "cs.CR",
            "cs.LG"
        ],
        "authors": [
            "Anasuya Chattopadhyay",
            "Daniel Reti",
            "Hans D. Schotten"
        ],
        "published": "2024-05-22T14:11:10Z"
    },
    {
        "title": "Generalization Bounds for Dependent Data using Online-to-Batch\n  Conversion",
        "link": "http://arxiv.org/abs/2405.13666v1",
        "abstract": "In this work, we give generalization bounds of statistical learning\nalgorithms trained on samples drawn from a dependent data source, both in\nexpectation and with high probability, using the Online-to-Batch conversion\nparadigm. We show that the generalization error of statistical learners in the\ndependent data setting is equivalent to the generalization error of statistical\nlearners in the i.i.d. setting up to a term that depends on the decay rate of\nthe underlying mixing stochastic process and is independent of the complexity\nof the statistical learner. Our proof techniques involve defining a new notion\nof stability of online learning algorithms based on Wasserstein distances and\nemploying \"near-martingale\" concentration bounds for dependent random variables\nto arrive at appropriate upper bounds for the generalization error of\nstatistical learners trained on dependent data.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Sagnik Chatterjee",
            "Manuj Mukherjee",
            "Alhad Sethi"
        ],
        "published": "2024-05-22T14:07:25Z"
    },
    {
        "title": "Timbre Perception, Representation, and its Neuroscientific Exploration:\n  A Comprehensive Review",
        "link": "http://arxiv.org/abs/2405.13661v1",
        "abstract": "Timbre, the sound's unique \"color\", is fundamental to how we perceive and\nappreciate music. This review explores the multifaceted world of timbre\nperception and representation. It begins by tracing the word's origin, offering\nan intuitive grasp of the concept. Building upon this foundation, the article\ndelves into the complexities of defining and measuring timbre. It then explores\nthe concept and techniques of timbre space, a powerful tool for visualizing how\nwe perceive different timbres. The review further examines recent advancements\nin timbre manipulation and representation, including the increasingly utilized\nmachine learning techniques. While the underlying neural mechanisms remain\npartially understood, the article discusses current neuroimaging techniques\nused to investigate this aspect of perception. Finally, it summarizes key\ntakeaways, identifies promising future research directions, and emphasizes the\npotential applications of timbre research in music technology, assistive\ntechnologies, and our overall understanding of auditory perception.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Hong Zhang",
            "Jie Lin",
            "Shengxuan Chen"
        ],
        "published": "2024-05-22T14:06:20Z"
    },
    {
        "title": "EgoChoir: Capturing 3D Human-Object Interaction Regions from Egocentric\n  Views",
        "link": "http://arxiv.org/abs/2405.13659v1",
        "abstract": "Understanding egocentric human-object interaction (HOI) is a fundamental\naspect of human-centric perception, facilitating applications like AR/VR and\nembodied AI. For the egocentric HOI, in addition to perceiving semantics e.g.,\n''what'' interaction is occurring, capturing ''where'' the interaction\nspecifically manifests in 3D space is also crucial, which links the perception\nand operation. Existing methods primarily leverage observations of HOI to\ncapture interaction regions from an exocentric view. However, incomplete\nobservations of interacting parties in the egocentric view introduce ambiguity\nbetween visual observations and interaction contents, impairing their efficacy.\nFrom the egocentric view, humans integrate the visual cortex, cerebellum, and\nbrain to internalize their intentions and interaction concepts of objects,\nallowing for the pre-formulation of interactions and making behaviors even when\ninteraction regions are out of sight. In light of this, we propose harmonizing\nthe visual appearance, head motion, and 3D object to excavate the object\ninteraction concept and subject intention, jointly inferring 3D human contact\nand object affordance from egocentric videos. To achieve this, we present\nEgoChoir, which links object structures with interaction contexts inherent in\nappearance and head motion to reveal object affordance, further utilizing it to\nmodel human contact. Additionally, a gradient modulation is employed to adopt\nappropriate clues for capturing interaction regions across various egocentric\nscenarios. Moreover, 3D contact and affordance are annotated for egocentric\nvideos collected from Ego-Exo4D and GIMO to support the task. Extensive\nexperiments on them demonstrate the effectiveness and superiority of EgoChoir.\nCode and data will be open.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yuhang Yang",
            "Wei Zhai",
            "Chengfeng Wang",
            "Chengjun Yu",
            "Yang Cao",
            "Zheng-Jun Zha"
        ],
        "published": "2024-05-22T14:03:48Z"
    },
    {
        "title": "A Conforming virtual element approximation for the Oseen eigenvalue\n  problem",
        "link": "http://arxiv.org/abs/2405.13657v1",
        "abstract": "In this paper we analyze a conforming virtual element method to approximate\nthe eigenfunctions and eigenvalues of the two dimensional Oseen eigenvalue\nproblem. We consider the classic velocity-pressure formulation which allows us\nto consider the divergence-conforming virtual element spaces employed for the\nStokes equations. Under standard assumptions on the meshes we derive a priori\nerror estimates for the proposed method with the aid of the compact operators\ntheory. We report some numerical tests to confirm the theoretical results.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Danilo Amigo",
            "Felipe Lepe",
            "Nitesh Verma"
        ],
        "published": "2024-05-22T14:01:56Z"
    },
    {
        "title": "ConcertoRL: An Innovative Time-Interleaved Reinforcement Learning\n  Approach for Enhanced Control in Direct-Drive Tandem-Wing Vehicles",
        "link": "http://arxiv.org/abs/2405.13651v1",
        "abstract": "In control problems for insect-scale direct-drive experimental platforms\nunder tandem wing influence, the primary challenge facing existing\nreinforcement learning models is their limited safety in the exploration\nprocess and the stability of the continuous training process. We introduce the\nConcertoRL algorithm to enhance control precision and stabilize the online\ntraining process, which consists of two main innovations: a time-interleaved\nmechanism to interweave classical controllers with reinforcement learning-based\ncontrollers aiming to improve control precision in the initial stages, a policy\ncomposer organizes the experience gained from previous learning to ensure the\nstability of the online training process. This paper conducts a series of\nexperiments. First, experiments incorporating the time-interleaved mechanism\ndemonstrate a substantial performance boost of approximately 70% over scenarios\nwithout reinforcement learning enhancements and a 50% increase in efficiency\ncompared to reference controllers with doubled control frequencies. These\nresults highlight the algorithm's ability to create a synergistic effect that\nexceeds the sum of its parts.",
        "subjects": [
            "cs.AI",
            "cs.RO",
            "68T40",
            "I.2.9"
        ],
        "authors": [
            "Minghao Zhang",
            "Bifeng Song",
            "Changhao Chen",
            "Xinyu Lang"
        ],
        "published": "2024-05-22T13:53:10Z"
    },
    {
        "title": "The Jacobi Eigenvalue Algorithm for Computing the Eigenvalues of a Dual\n  Quaternion Hermitian Matrix",
        "link": "http://arxiv.org/abs/2405.13649v2",
        "abstract": "In this paper, we generalize the Jacobi eigenvalue algorithm to compute all\neigenvalues and eigenvectors of a dual quaternion Hermitian matrix and show the\nconvergence. We also propose a three-step Jacobi eigenvalue algorithm to\ncompute the eigenvalues when a dual quaternion Hermitian matrix has two\neigenvalues with identical standard parts but different dual parts and prove\nthe convergence. Numerical experiments are presented to illustrate the\nefficiency and stability of the proposed Jacobi eigenvalue algorithm compaired\nto the power method and the Rayleigh quotient iteration method.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Yongjun Chen",
            "Liping Zhang"
        ],
        "published": "2024-05-22T13:52:41Z"
    },
    {
        "title": "Enhancing Bayesian model updating in structural health monitoring via\n  learnable mappings",
        "link": "http://arxiv.org/abs/2405.13648v1",
        "abstract": "In the context of structural health monitoring (SHM), the selection and\nextraction of damage-sensitive features from raw sensor recordings represent a\ncritical step towards solving the inverse problem underlying the structural\nhealth identification. This work introduces a new way to enhance stochastic\napproaches to SHM through the use of deep neural networks. A learnable feature\nextractor and a feature-oriented surrogate model are synergistically exploited\nto evaluate a likelihood function within a Markov chain Monte Carlo sampling\nalgorithm. The feature extractor undergoes a supervised pairwise training to\nmap sensor recordings onto a low-dimensional metric space, which encapsulates\nthe sensitivity to structural health parameters. The surrogate model maps the\nstructural health parameters onto their feature description. The procedure\nenables the updating of beliefs about structural health parameters, effectively\nreplacing the need for a computationally expensive numerical (finite element)\nmodel. A preliminary offline phase involves the generation of a labeled dataset\nto train both the feature extractor and the surrogate model. Within a\nsimulation-based SHM framework, training vibration responses are\ncost-effectively generated by means of a multi-fidelity surrogate modeling\nstrategy to approximate sensor recordings under varying damage and operational\nconditions. The multi-fidelity surrogate exploits model order reduction and\nartificial neural networks to speed up the data generation phase while ensuring\nthe damage-sensitivity of the approximated signals. The proposed strategy is\nassessed through three synthetic case studies, demonstrating remarkable results\nin terms of accuracy of the estimated quantities and computational efficiency.",
        "subjects": [
            "cs.CE"
        ],
        "authors": [
            "Matteo Torzoni",
            "Andrea Manzoni",
            "Stefano Mariani"
        ],
        "published": "2024-05-22T13:51:15Z"
    },
    {
        "title": "A framework for expected capability sets",
        "link": "http://arxiv.org/abs/2405.13647v1",
        "abstract": "This paper addresses decision-aiding problems that involve multiple\nobjectives and uncertain states of the world. Inspired by the capability\napproach, we focus on cases where a policy maker chooses an act that, combined\nwith a state of the world, leads to a set of choices for citizens. While no\npreferential information is available to construct importance parameters for\nthe criteria, we can obtain likelihoods for the different states. To\neffectively support decision-aiding in this context, we propose two procedures\nthat merge the potential set of choices for each state of the world taking into\naccount their respective likelihoods. Our procedures satisfy several\nfundamental and desirable properties that characterize the outcomes.",
        "subjects": [
            "cs.CY"
        ],
        "authors": [
            "Nicolas Fayard",
            "David R√≠os Insua",
            "Alexis Tsouki√†s"
        ],
        "published": "2024-05-22T13:51:00Z"
    },
    {
        "title": "A Transformer variant for multi-step forecasting of water level and\n  hydrometeorological sensitivity analysis based on explainable artificial\n  intelligence technology",
        "link": "http://arxiv.org/abs/2405.13646v1",
        "abstract": "Understanding the combined influences of meteorological and hydrological\nfactors on water level and flood events is essential, particularly in today's\nchanging climate environments. Transformer, as one kind of the cutting-edge\ndeep learning methods, offers an effective approach to model intricate\nnonlinear processes, enables the extraction of key features and water level\npredictions. EXplainable Artificial Intelligence (XAI) methods play important\nroles in enhancing the understandings of how different factors impact water\nlevel. In this study, we propose a Transformer variant by integrating sparse\nattention mechanism and introducing nonlinear output layer for the decoder\nmodule. The variant model is utilized for multi-step forecasting of water\nlevel, by considering meteorological and hydrological factors simultaneously.\nIt is shown that the variant model outperforms traditional Transformer across\ndifferent lead times with respect to various evaluation metrics. The\nsensitivity analyses based on XAI technology demonstrate the significant\ninfluence of meteorological factors on water level evolution, in which\ntemperature is shown to be the most dominant meteorological factor. Therefore,\nincorporating both meteorological and hydrological factors is necessary for\nreliable hydrological prediction and flood prevention. In the meantime, XAI\ntechnology provides insights into certain predictions, which is beneficial for\nunderstanding the prediction results and evaluating the reasonability.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Mingyu Liu",
            "Nana Bao",
            "Xingting Yan",
            "Chenyang Li",
            "Kai Peng"
        ],
        "published": "2024-05-22T13:50:42Z"
    },
    {
        "title": "Fully automated construction of three-dimensional finite element\n  simulations from Optical Coherence Tomography",
        "link": "http://dx.doi.org/10.1016/j.compbiomed.2023.107341",
        "abstract": "Despite recent advances in diagnosis and treatment, atherosclerotic coronary\nartery diseases remain a leading cause of death worldwide. Various imaging\nmodalities and metrics can detect lesions and predict patients at risk;\nhowever, identifying unstable lesions is still difficult. Current techniques\ncannot fully capture the complex morphology-modulated mechanical responses that\naffect plaque stability, leading to catastrophic failure and mute the benefit\nof device and drug interventions. Finite Element (FE) simulations utilizing\nintravascular imaging OCT (Optical Coherence Tomography) are effective in\ndefining physiological stress distributions. However, creating 3D FE\nsimulations of coronary arteries from OCT images is challenging to fully\nautomate given OCT frame sparsity, limited material contrast, and restricted\npenetration depth. To address such limitations, we developed an algorithmic\napproach to automatically produce 3D FE-ready digital twins from labeled OCT\nimages. The 3D models are anatomically faithful and recapitulate mechanically\nrelevant tissue lesion components, automatically producing morphologies\nstructurally similar to manually constructed models whilst including more\nminute details. A mesh convergence study highlighted the ability to reach\nstress and strain convergence with average errors of just 5.9% and 1.6%\nrespectively in comparison to FE models with approximately twice the number of\nelements in areas of refinement. Such an automated procedure will enable\nanalysis of large clinical cohorts at a previously unattainable scale and opens\nthe possibility for in-silico methods for patient specific diagnoses and\ntreatment planning for coronary artery disease.",
        "subjects": [
            "cs.CE",
            "q-bio.TO"
        ],
        "authors": [
            "Ross Straughan",
            "Karim Kadry",
            "Sahil A. Parikh",
            "Elazer R. Edelman",
            "Farhad R. Nezami"
        ],
        "published": "2024-05-22T13:44:23Z"
    },
    {
        "title": "Knowledge Graph Reasoning with Self-supervised Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.13640v1",
        "abstract": "Reinforcement learning (RL) is an effective method of finding reasoning\npathways in incomplete knowledge graphs (KGs). To overcome the challenges of a\nlarge action space, a self-supervised pre-training method is proposed to warm\nup the policy network before the RL training stage. To alleviate the\ndistributional mismatch issue in general self-supervised RL (SSRL), in our\nsupervised learning (SL) stage, the agent selects actions based on the policy\nnetwork and learns from generated labels; this self-generation of labels is the\nintuition behind the name self-supervised. With this training framework, the\ninformation density of our SL objective is increased and the agent is prevented\nfrom getting stuck with the early rewarded paths. Our self-supervised RL (SSRL)\nmethod improves the performance of RL by pairing it with the wide coverage\nachieved by SL during pretraining, since the breadth of the SL objective makes\nit infeasible to train an agent with that alone. We show that our SSRL model\nmeets or exceeds current state-of-the-art results on all Hits@k and mean\nreciprocal rank (MRR) metrics on four large benchmark KG datasets. This SSRL\nmethod can be used as a plug-in for any RL architecture for a KGR task. We\nadopt two RL architectures, i.e., MINERVA and MultiHopKG as our baseline RL\nmodels and experimentally show that our SSRL model consistently outperforms\nboth baselines on all of these four KG reasoning tasks. Full code for the paper\navailable at\nhttps://github.com/owenonline/Knowledge-Graph-Reasoning-with-Self-supervised-Reinforcement-Learning.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Ying Ma",
            "Owen Burns",
            "Mingqiu Wang",
            "Gang Li",
            "Nan Du",
            "Laurent El Shafey",
            "Liqiang Wang",
            "Izhak Shafran",
            "Hagen Soltau"
        ],
        "published": "2024-05-22T13:39:33Z"
    },
    {
        "title": "On Hardware-efficient Inference in Probabilistic Circuits",
        "link": "http://arxiv.org/abs/2405.13639v1",
        "abstract": "Probabilistic circuits (PCs) offer a promising avenue to perform embedded\nreasoning under uncertainty. They support efficient and exact computation of\nvarious probabilistic inference tasks by design. Hence, hardware-efficient\ncomputation of PCs is highly interesting for edge computing applications. As\ncomputations in PCs are based on arithmetic with probability values, they are\ntypically performed in the log domain to avoid underflow. Unfortunately,\nperforming the log operation on hardware is costly. Hence, prior work has\nfocused on computations in the linear domain, resulting in high resolution and\nenergy requirements. This work proposes the first dedicated approximate\ncomputing framework for PCs that allows for low-resolution logarithm\ncomputations. We leverage Addition As Int, resulting in linear PC computation\nwith simple hardware elements. Further, we provide a theoretical approximation\nerror analysis and present an error compensation mechanism. Empirically, our\nmethod obtains up to 357x and 649x energy reduction on custom hardware for\nevidence and MAP queries respectively with little or no computational error.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Lingyun Yao",
            "Martin Trapp",
            "Jelin Leslin",
            "Gaurav Singh",
            "Peng Zhang",
            "Karthekeyan Periasamy",
            "Martin Andraud"
        ],
        "published": "2024-05-22T13:38:47Z"
    },
    {
        "title": "Curriculum Direct Preference Optimization for Diffusion and Consistency\n  Models",
        "link": "http://arxiv.org/abs/2405.13637v2",
        "abstract": "Direct Preference Optimization (DPO) has been proposed as an effective and\nefficient alternative to reinforcement learning from human feedback (RLHF). In\nthis paper, we propose a novel and enhanced version of DPO based on curriculum\nlearning for text-to-image generation. Our method is divided into two training\nstages. First, a ranking of the examples generated for each prompt is obtained\nby employing a reward model. Then, increasingly difficult pairs of examples are\nsampled and provided to a text-to-image generative (diffusion or consistency)\nmodel. Generated samples that are far apart in the ranking are considered to\nform easy pairs, while those that are close in the ranking form hard pairs. In\nother words, we use the rank difference between samples as a measure of\ndifficulty. The sampled pairs are split into batches according to their\ndifficulty levels, which are gradually used to train the generative model. Our\napproach, Curriculum DPO, is compared against state-of-the-art fine-tuning\napproaches on three benchmarks, outperforming the competing methods in terms of\ntext alignment, aesthetics and human preference. Our code is available at\nhttps://anonymous.4open.science/r/Curriculum-DPO-EE14.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Florinel-Alin Croitoru",
            "Vlad Hondru",
            "Radu Tudor Ionescu",
            "Nicu Sebe",
            "Mubarak Shah"
        ],
        "published": "2024-05-22T13:36:48Z"
    },
    {
        "title": "Audio Mamba: Pretrained Audio State Space Model For Audio Tagging",
        "link": "http://arxiv.org/abs/2405.13636v1",
        "abstract": "Audio tagging is an important task of mapping audio samples to their\ncorresponding categories. Recently endeavours that exploit transformer models\nin this field have achieved great success. However, the quadratic\nself-attention cost limits the scaling of audio transformer models and further\nconstrains the development of more universal audio models. In this paper, we\nattempt to solve this problem by proposing Audio Mamba, a self-attention-free\napproach that captures long audio spectrogram dependency with state space\nmodels. Our experimental results on two audio-tagging datasets demonstrate the\nparameter efficiency of Audio Mamba, it achieves comparable results to SOTA\naudio spectrogram transformers with one third parameters.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "authors": [
            "Jiaju Lin",
            "Haoxuan Hu"
        ],
        "published": "2024-05-22T13:35:56Z"
    },
    {
        "title": "Task agnostic continual learning with Pairwise layer architecture",
        "link": "http://arxiv.org/abs/2405.13632v1",
        "abstract": "Most of the dominant approaches to continual learning are based on either\nmemory replay, parameter isolation, or regularization techniques that require\ntask boundaries to calculate task statistics. We propose a static\narchitecture-based method that doesn't use any of these. We show that we can\nimprove the continual learning performance by replacing the final layer of our\nnetworks with our pairwise interaction layer. The pairwise interaction layer\nuses sparse representations from a Winner-take-all style activation function to\nfind the relevant correlations in the hidden layer representations. The\nnetworks using this architecture show competitive performance in MNIST and\nFashionMNIST-based continual image classification experiments. We demonstrate\nthis in an online streaming continual learning setup where the learning system\ncannot access task labels or boundaries.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Santtu Keskinen"
        ],
        "published": "2024-05-22T13:30:01Z"
    },
    {
        "title": "Maximum Entropy Reinforcement Learning via Energy-Based Normalizing Flow",
        "link": "http://arxiv.org/abs/2405.13629v1",
        "abstract": "Existing Maximum-Entropy (MaxEnt) Reinforcement Learning (RL) methods for\ncontinuous action spaces are typically formulated based on actor-critic\nframeworks and optimized through alternating steps of policy evaluation and\npolicy improvement. In the policy evaluation steps, the critic is updated to\ncapture the soft Q-function. In the policy improvement steps, the actor is\nadjusted in accordance with the updated soft Q-function. In this paper, we\nintroduce a new MaxEnt RL framework modeled using Energy-Based Normalizing\nFlows (EBFlow). This framework integrates the policy evaluation steps and the\npolicy improvement steps, resulting in a single objective training process. Our\nmethod enables the calculation of the soft value function used in the policy\nevaluation target without Monte Carlo approximation. Moreover, this design\nsupports the modeling of multi-modal action distributions while facilitating\nefficient action sampling. To evaluate the performance of our method, we\nconducted experiments on the MuJoCo benchmark suite and a number of\nhigh-dimensional robotic tasks simulated by Omniverse Isaac Gym. The evaluation\nresults demonstrate that our method achieves superior performance compared to\nwidely-adopted representative baselines.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Chen-Hao Chao",
            "Chien Feng",
            "Wei-Fang Sun",
            "Cheng-Kuang Lee",
            "Simon See",
            "Chun-Yi Lee"
        ],
        "published": "2024-05-22T13:26:26Z"
    },
    {
        "title": "Verifying feasibility of degenerate semidefinite programs",
        "link": "http://arxiv.org/abs/2405.13625v1",
        "abstract": "This paper deals with the algorithmic aspects of solving feasibility problems\nof semidefinite programming (SDP), aka linear matrix inequalities (LMI). Since\nin some SDP instances all feasible solutions have irrational entries, numerical\nsolvers that work with rational numbers can only find an approximate solution.\nWe study the following question: is it possible to certify feasibility of a\ngiven SDP using an approximate solution that is sufficiently close to some\nexact solution? Existing approaches make the assumption that there exist\nrational feasible solutions (and use techniques such as rounding and lattice\nreduction algorithms).\n  We propose an alternative approach that does not need this assumption. More\nspecifically, we show how to construct a system of polynomial equations whose\nset of real solutions is guaranteed to have an isolated correct solution\n(assuming that the target exact solution is maximum-rank). This allows, in\nparticular, to use algorithms from real algebraic geometry for solving systems\nof polynomial equations, yielding a hybrid (or symbolic-numerical) method for\nSDPs. We experimentally compare it with a pure symbolic method in [Henrion,\nNaldi, Safey El Din; SIAM J. Optim., 2016]; the hybrid method was able to\ncertify feasibility of many SDP instances on which [Henrion, Naldi, Safey El\nDin; SIAM J. Optim., 2016] failed. We argue that our approach may have other\nuses, such as refining an approximate solution using methods of numerical\nalgebraic geometry for systems of polynomial equations.",
        "subjects": [
            "math.OC",
            "cs.SC",
            "math.AG"
        ],
        "authors": [
            "Vladimir Kolmogorov",
            "Simone Naldi",
            "Jeferson Zapata"
        ],
        "published": "2024-05-22T13:23:10Z"
    },
    {
        "title": "Automated Evaluation of Retrieval-Augmented Language Models with\n  Task-Specific Exam Generation",
        "link": "http://arxiv.org/abs/2405.13622v1",
        "abstract": "We propose a new method to measure the task-specific accuracy of\nRetrieval-Augmented Large Language Models (RAG). Evaluation is performed by\nscoring the RAG on an automatically-generated synthetic exam composed of\nmultiple choice questions based on the corpus of documents associated with the\ntask. Our method is an automated, cost-efficient, interpretable, and robust\nstrategy to select the optimal components for a RAG system. We leverage Item\nResponse Theory (IRT) to estimate the quality of an exam and its\ninformativeness on task-specific accuracy. IRT also provides a natural way to\niteratively improve the exam by eliminating the exam questions that are not\nsufficiently informative about a model's ability. We demonstrate our approach\non four new open-ended Question-Answering tasks based on Arxiv abstracts,\nStackExchange questions, AWS DevOps troubleshooting guides, and SEC filings. In\naddition, our experiments reveal more general insights into factors impacting\nRAG performance like size, retrieval mechanism, prompting and fine-tuning. Most\nnotably, our findings show that choosing the right retrieval algorithms often\nleads to bigger performance gains than simply using a larger language model.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "authors": [
            "Gauthier Guinet",
            "Behrooz Omidvar-Tehrani",
            "Anoop Deoras",
            "Laurent Callot"
        ],
        "published": "2024-05-22T13:14:11Z"
    },
    {
        "title": "Building BESSER: an open-source low-code platform",
        "link": "http://arxiv.org/abs/2405.13620v2",
        "abstract": "Low-code platforms (latest reincarnation of the long tradition of\nmodel-driven engineering approaches) have the potential of saving us countless\nhours of repetitive boilerplate coding tasks. However, as software systems grow\nin complexity, low-code platforms need to adapt as well. Notably, nowadays this\nimplies adapting to the modeling and generation of smart software. At the same\ntime, if we want to broaden the userbase of this type of tools, we should also\nbe able to provide more open source alternatives that help potential users\navoid vendor lock-ins and give them the freedom to explore low-code development\napproaches (even adapting the tool to better fit their needs). To fulfil these\nneeds, we are building BESSER, an open source low-code platform for developing\n(smart) software. BESSER offers various forms (i.e., notations) for system and\ndomain specification (e.g. UML for technical users and chatbots for business\nusers) together with a number of generators. Both types of components can be\nextended and are open to contributions from the community.",
        "subjects": [
            "cs.SE",
            "D.2.2"
        ],
        "authors": [
            "Iv√°n Alfonso",
            "Aaron Conrardy",
            "Armen Sulejmani",
            "Atefeh Nirumand",
            "Fitash Ul Haq",
            "Marcos Gomez-Vazquez",
            "Jean-S√©bastien Sottet",
            "Jordi Cabot"
        ],
        "published": "2024-05-22T13:12:57Z"
    },
    {
        "title": "Waverider: Leveraging Hierarchical, Multi-Resolution Maps for Efficient\n  and Reactive Obstacle Avoidance",
        "link": "http://arxiv.org/abs/2405.13617v1",
        "abstract": "Fast and reliable obstacle avoidance is an important task for mobile robots.\nIn this work, we propose an efficient reactive system that provides\nhigh-quality obstacle avoidance while running at hundreds of hertz with minimal\nresource usage. Our approach combines wavemap, a hierarchical volumetric map\nrepresentation, with a novel hierarchical and parallelizable obstacle avoidance\nalgorithm formulated through Riemannian Motion Policies (RMP). Leveraging\nmulti-resolution obstacle avoidance policies, the proposed navigation system\nfacilitates precise, low-latency (36ms), and extremely efficient obstacle\navoidance with a very large perceptive radius (30m). We perform extensive\nstatistical evaluations on indoor and outdoor maps, verifying that the proposed\nsystem compares favorably to fixed-resolution RMP variants and CHOMP. Finally,\nthe RMP formulation allows the seamless fusion of obstacle avoidance with\nadditional objectives, such as goal-seeking, to obtain a fully-fledged\nnavigation system that is versatile and robust. We deploy the system on a Micro\nAerial Vehicle and show how it navigates through an indoor obstacle course. Our\ncomplete implementation, called waverider, is made available as open source.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Victor Reijgwart",
            "Michael Pantic",
            "Roland Siegwart",
            "Lionel Ott"
        ],
        "published": "2024-05-22T13:09:42Z"
    },
    {
        "title": "An optimal algorithm for geodesic mutual visibility on hexagonal grids",
        "link": "http://arxiv.org/abs/2405.13615v1",
        "abstract": "For a set of robots (or agents) moving in a graph, two properties are highly\ndesirable: confidentiality (i.e., a message between two agents must not pass\nthrough any intermediate agent) and efficiency (i.e., messages are delivered\nthrough shortest paths). These properties can be obtained if the\n\\textsc{Geodesic Mutual Visibility} (GMV, for short) problem is solved:\noblivious robots move along the edges of the graph, without collisions, to\noccupy some vertices that guarantee they become pairwise geodesic mutually\nvisible. This means there is a shortest path (i.e., a ``geodesic'') between\neach pair of robots along which no other robots reside. In this work, we\noptimally solve GMV on finite hexagonal grids $G_k$. This, in turn, requires\nfirst solving a graph combinatorial problem, i.e. determining the maximum\nnumber of mutually visible vertices in $G_k$.",
        "subjects": [
            "cs.DC",
            "math.CO"
        ],
        "authors": [
            "Sahar Badri",
            "Serafino Cicerone",
            "Alessia Di Fonso",
            "Gabriele Di Stefano"
        ],
        "published": "2024-05-22T13:08:19Z"
    },
    {
        "title": "Enumerating Graphlets with Amortized Time Complexity Independent of\n  Graph Size",
        "link": "http://arxiv.org/abs/2405.13613v1",
        "abstract": "Graphlets of order $k$ in a graph $G$ are connected subgraphs induced by $k$\nnodes (called $k$-graphlets) or by $k$ edges (called edge $k$-graphlets). They\nare among the interesting subgraphs in network analysis to get insights on both\nthe local and global structure of a network. While several algorithms exist for\ndiscovering and enumerating graphlets, the cost per solution of such algorithms\ntypically depends on the size of the graph $G$, or its maximum degree. In real\nnetworks, even the latter can be in the order of millions, whereas $k$ is\ntypically required to be a small value. In this paper we provide the first\nalgorithm to list all graphlets of order $k$ in a graph $G=(V,E)$ with an\namortized cost per solution depending \\emph{solely} on the order $k$,\ncontrarily to previous approaches where the cost depends \\emph{also} on the\nsize of $G$ or its maximum degree. Specifically, we show that it is possible to\nlist $k$-graphlets in $O(k^2)$ time per solution, and to list edge\n$k$-graphlets in $O(k)$ time per solution. Furthermore we show that, if the\ninput graph has bounded degree, then the cost per solution for listing\n$k$-graphlets is reduced to $O(k)$. Whenever $k = O(1)$, as it is often the\ncase in practical settings, these algorithms are the first to achieve constant\ntime per solution.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Alessio Conte",
            "Roberto Grossi",
            "Yasuaki Kobayashi",
            "Kazuhiro Kurita",
            "Davide Rucci",
            "Takeaki Uno",
            "Kunihiro Wasa"
        ],
        "published": "2024-05-22T13:07:37Z"
    },
    {
        "title": "Tackling Decision Processes with Non-Cumulative Objectives using\n  Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.13609v1",
        "abstract": "Markov decision processes (MDPs) are used to model a wide variety of\napplications ranging from game playing over robotics to finance. Their optimal\npolicy typically maximizes the expected sum of rewards given at each step of\nthe decision process. However, a large class of problems does not fit\nstraightforwardly into this framework: Non-cumulative Markov decision processes\n(NCMDPs), where instead of the expected sum of rewards, the expected value of\nan arbitrary function of the rewards is maximized. Example functions include\nthe maximum of the rewards or their mean divided by their standard deviation.\nIn this work, we introduce a general mapping of NCMDPs to standard MDPs. This\nallows all techniques developed to find optimal policies for MDPs, such as\nreinforcement learning or dynamic programming, to be directly applied to the\nlarger class of NCMDPs. Focusing on reinforcement learning, we show\napplications in a diverse set of tasks, including classical control, portfolio\noptimization in finance, and discrete optimization problems. Given our\napproach, we can improve both final performance and training time compared to\nrelying on standard MDPs.",
        "subjects": [
            "cs.LG",
            "q-fin.CP",
            "quant-ph",
            "I.2.8; I.2.6"
        ],
        "authors": [
            "Maximilian N√§gele",
            "Jan Olle",
            "Thomas F√∂sel",
            "Remmy Zen",
            "Florian Marquardt"
        ],
        "published": "2024-05-22T13:01:37Z"
    },
    {
        "title": "From the evolution of public data ecosystems to the evolving horizons of\n  the forward-looking intelligent public data ecosystem empowered by emerging\n  technologies",
        "link": "http://arxiv.org/abs/2405.13606v1",
        "abstract": "Public data ecosystems (PDEs) represent complex socio-technical systems\ncrucial for optimizing data use in the public sector and outside it.\nRecognizing their multifaceted nature, previous research pro-posed a\nsix-generation Evolutionary Model of Public Data Ecosystems (EMPDE). Designed\nas a result of a systematic literature review on the topic spanning three\ndecade, this model, while theoretically robust, necessitates empirical\nvalidation to enhance its practical applicability. This study addresses this\ngap by validating the theoretical model through a real-life examination in five\nEuropean countries - Latvia, Serbia, Czech Republic, Spain, and Poland. This\nempirical validation provides insights into PDEs dynamics and variations of\nimplementations across contexts, particularly focusing on the 6th generation of\nforward-looking PDE generation named \"Intelligent Public Data Generation\" that\nrepresents a paradigm shift driven by emerging technologies such as cloud\ncomputing, Artificial Intelligence, Natural Language Processing tools,\nGenerative AI, and Large Language Models (LLM) with potential to contribute to\nboth automation and augmentation of business processes within these ecosystems.\nBy transcending their traditional status as a mere component, evolving into\nboth an actor and a stakeholder simultaneously, these technologies catalyze\ninnovation and progress, enhancing PDE management strategies to align with\nsocietal, regulatory, and technical imperatives in the digital era.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.ET",
            "cs.HC",
            "cs.IR"
        ],
        "authors": [
            "Anastasija Nikiforova",
            "Martin Lnenicka",
            "Petar Miliƒá",
            "Mariusz Luterek",
            "Manuel Pedro Rodr√≠guez Bol√≠var"
        ],
        "published": "2024-05-22T12:58:02Z"
    },
    {
        "title": "Skills Composition Framework for Reconfigurable Cyber-Physical\n  Production Modules",
        "link": "http://arxiv.org/abs/2405.13604v1",
        "abstract": "While the benefits of reconfigurable manufacturing systems (RMS) are\nwell-known, there are still challenges to their development, including, among\nothers, a modular software architecture that enables rapid reconfiguration\nwithout much reprogramming effort. Skill-based engineering improves software\nmodularity and increases the reconfiguration potential of RMS. Nevertheless, a\nskills' composition framework with a focus on frequent and rapid software\nchanges is still missing. The Behavior trees (BTs) framework is a novel\napproach, which enables intuitive design of modular hierarchical control\nstructures. BTs have been mostly explored from the AI and robotics\nperspectives, and little work has been done in investigating their potential\nfor composing skills in the manufacturing domain. This paper proposes a\nframework for skills' composition and execution in skill-based reconfigurable\ncyber-physical production modules (RCPPMs). It is based on distributed BTs and\nprovides good integration between low-level devices' specific code and AI-based\ntask-oriented frameworks. We have implemented the provided models for the IEC\n61499-based distributed automation controllers to show the instantiation of the\nproposed framework with the specific industrial technology and enable its\nevaluation by the automation community.",
        "subjects": [
            "cs.SE",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Aleksandr Sidorenko",
            "Achim Wagner",
            "Martin Ruskowski"
        ],
        "published": "2024-05-22T12:56:05Z"
    },
    {
        "title": "COTET: Cross-view Optimal Transport for Knowledge Graph Entity Typing",
        "link": "http://arxiv.org/abs/2405.13602v1",
        "abstract": "Knowledge graph entity typing (KGET) aims to infer missing entity type\ninstances in knowledge graphs. Previous research has predominantly centered\naround leveraging contextual information associated with entities, which\nprovides valuable clues for inference. However, they have long ignored the dual\nnature of information inherent in entities, encompassing both high-level\ncoarse-grained cluster knowledge and fine-grained type knowledge. This paper\nintroduces Cross-view Optimal Transport for knowledge graph Entity Typing\n(COTET), a method that effectively incorporates the information on how types\nare clustered into the representation of entities and types. COTET comprises\nthree modules: i) Multi-view Generation and Encoder, which captures structured\nknowledge at different levels of granularity through entity-type,\nentity-cluster, and type-cluster-type perspectives; ii) Cross-view Optimal\nTransport, transporting view-specific embeddings to a unified space by\nminimizing the Wasserstein distance from a distributional alignment\nperspective; iii) Pooling-based Entity Typing Prediction, employing a mixture\npooling mechanism to aggregate prediction scores from diverse neighbors of an\nentity. Additionally, we introduce a distribution-based loss function to\nmitigate the occurrence of false negatives during training. Extensive\nexperiments demonstrate the effectiveness of COTET when compared to existing\nbaselines.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Zhiwei Hu",
            "V√≠ctor Guti√©rrez-Basulto",
            "Zhiliang Xiang",
            "Ru Li",
            "Jeff Z. Pan"
        ],
        "published": "2024-05-22T12:53:12Z"
    },
    {
        "title": "LogRCA: Log-based Root Cause Analysis for Distributed Services",
        "link": "http://arxiv.org/abs/2405.13599v1",
        "abstract": "To assist IT service developers and operators in managing their increasingly\ncomplex service landscapes, there is a growing effort to leverage artificial\nintelligence in operations. To speed up troubleshooting, log anomaly detection\nhas received much attention in particular, dealing with the identification of\nlog events that indicate the reasons for a system failure. However, faults\noften propagate extensively within systems, which can result in a large number\nof anomalies being detected by existing approaches. In this case, it can remain\nvery challenging for users to quickly identify the actual root cause of a\nfailure.\n  We propose LogRCA, a novel method for identifying a minimal set of log lines\nthat together describe a root cause. LogRCA uses a semi-supervised learning\napproach to deal with rare and unknown errors and is designed to handle noisy\ndata. We evaluated our approach on a large-scale production log data set of\n44.3 million log lines, which contains 80 failures, whose root causes were\nlabeled by experts. LogRCA consistently outperforms baselines based on deep\nlearning and statistical analysis in terms of precision and recall to detect\ncandidate root causes. In addition, we investigated the impact of our deployed\ndata balancing approach, demonstrating that it considerably improves\nperformance on rare failures.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Thorsten Wittkopp",
            "Philipp Wiesner",
            "Odej Kao"
        ],
        "published": "2024-05-22T12:50:56Z"
    },
    {
        "title": "GeoFF: Federated Serverless Workflows with Data Pre-Fetching",
        "link": "http://arxiv.org/abs/2405.13594v1",
        "abstract": "Function-as-a-Service (FaaS) is a popular cloud computing model in which\napplications are implemented as work flows of multiple independent functions.\nWhile cloud providers usually offer composition services for such workflows,\nthey do not support cross-platform workflows forcing developers to hardcode the\ncomposition logic. Furthermore, FaaS workflows tend to be slow due to cascading\ncold starts, inter-function latency, and data download latency on the critical\npath. In this paper, we propose GeoFF, a serverless choreography middleware\nthat executes FaaS workflows across different public and private FaaS\nplatforms, including ad-hoc workflow recomposition. Furthermore, GeoFF supports\nfunction pre-warming and data pre-fetching. This minimizes end-to-end workflow\nlatency by taking cold starts and data download latency off the critical path.\nIn experiments with our proof-of-concept prototype and a realistic application,\nwe were able to reduce end-to-end latency by more than 50%.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Valentin Carl",
            "Trever Schirmer",
            "Tobias Pfandzelter",
            "David Bermbach"
        ],
        "published": "2024-05-22T12:44:49Z"
    },
    {
        "title": "Almost sure convergence rates of stochastic gradient methods under\n  gradient domination",
        "link": "http://arxiv.org/abs/2405.13592v1",
        "abstract": "Stochastic gradient methods are among the most important algorithms in\ntraining machine learning problems. While classical assumptions such as strong\nconvexity allow a simple analysis they are rarely satisfied in applications. In\nrecent years, global and local gradient domination properties have shown to be\na more realistic replacement of strong convexity. They were proved to hold in\ndiverse settings such as (simple) policy gradient methods in reinforcement\nlearning and training of deep neural networks with analytic activation\nfunctions. We prove almost sure convergence rates $f(X_n)-f^*\\in o\\big(\nn^{-\\frac{1}{4\\beta-1}+\\epsilon}\\big)$ of the last iterate for stochastic\ngradient descent (with and without momentum) under global and local\n$\\beta$-gradient domination assumptions. The almost sure rates get arbitrarily\nclose to recent rates in expectation. Finally, we demonstrate how to apply our\nresults to the training task in both supervised and reinforcement learning.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Simon Weissmann",
            "Sara Klein",
            "Wa√Øss Azizian",
            "Leif D√∂ring"
        ],
        "published": "2024-05-22T12:40:57Z"
    },
    {
        "title": "Exact Gradients for Stochastic Spiking Neural Networks Driven by Rough\n  Signals",
        "link": "http://arxiv.org/abs/2405.13587v1",
        "abstract": "We introduce a mathematically rigorous framework based on rough path theory\nto model stochastic spiking neural networks (SSNNs) as stochastic differential\nequations with event discontinuities (Event SDEs) and driven by c\\`adl\\`ag\nrough paths. Our formalism is general enough to allow for potential jumps to be\npresent both in the solution trajectories as well as in the driving noise. We\nthen identify a set of sufficient conditions ensuring the existence of pathwise\ngradients of solution trajectories and event times with respect to the\nnetwork's parameters and show how these gradients satisfy a recursive relation.\nFurthermore, we introduce a general-purpose loss function defined by means of a\nnew class of signature kernels indexed on c\\`adl\\`ag rough paths and use it to\ntrain SSNNs as generative models. We provide an end-to-end autodifferentiable\nsolver for Event SDEs and make its implementation available as part of the\n$\\texttt{diffrax}$ library. Our framework is, to our knowledge, the first\nenabling gradient-based training of SSNNs with noise affecting both the spike\ntiming and the network's dynamics.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.PR"
        ],
        "authors": [
            "Christian Holberg",
            "Cristopher Salvi"
        ],
        "published": "2024-05-22T12:34:04Z"
    },
    {
        "title": "Bond Graphs for multi-physics informed Neural Networks for multi-variate\n  time series",
        "link": "http://arxiv.org/abs/2405.13586v1",
        "abstract": "In the trend of hybrid Artificial Intelligence (AI) techniques, Physic\nInformed Machine Learning has seen a growing interest. It operates mainly by\nimposing a data, learning or inductive bias with simulation data, Partial\nDifferential Equations or equivariance and invariance properties. While these\nmodels have shown great success on tasks involving one physical domain such as\nfluid dynamics, existing methods still struggle on tasks with complex\nmulti-physical and multi-domain phenomena. To address this challenge, we\npropose to leverage Bond Graphs, a multi-physics modeling approach together\nwith Graph Neural Network. We thus propose Neural Bond Graph Encoder (NBgE), a\nmodel agnostic physical-informed encoder tailored for multi-physics systems. It\nprovides an unified framework for any multi-physics informed AI with a graph\nencoder readable for any deep learning model. Our experiments on two\nchallenging multi-domain physical systems - a Direct Current Motor and the\nRespiratory system - demonstrate the effectiveness of our approach on a\nmulti-variate time series forecasting task.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Alexis-Raja Brachet",
            "Pierre-Yves Richard",
            "C√©line Hudelot"
        ],
        "published": "2024-05-22T12:30:25Z"
    },
    {
        "title": "Emulating Full Client Participation: A Long-Term Client Selection\n  Strategy for Federated Learning",
        "link": "http://arxiv.org/abs/2405.13584v1",
        "abstract": "Client selection significantly affects the system convergence efficiency and\nis a crucial problem in federated learning. Existing methods often select\nclients by evaluating each round individually and overlook the necessity for\nlong-term optimization, resulting in suboptimal performance and potential\nfairness issues. In this study, we propose a novel client selection strategy\ndesigned to emulate the performance achieved with full client participation. In\na single round, we select clients by minimizing the gradient-space estimation\nerror between the client subset and the full client set. In multi-round\nselection, we introduce a novel individual fairness constraint, which ensures\nthat clients with similar data distributions have similar frequencies of being\nselected. This constraint guides the client selection process from a long-term\nperspective. We employ Lyapunov optimization and submodular functions to\nefficiently identify the optimal subset of clients, and provide a theoretical\nanalysis of the convergence ability. Experiments demonstrate that the proposed\nstrategy significantly improves both accuracy and fairness compared to previous\nmethods while also exhibiting efficiency by incurring minimal time overhead.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "authors": [
            "Qingming Li",
            "Juzheng Miao",
            "Puning Zhao",
            "Li Zhou",
            "Shouling Ji",
            "Bowen Zhou",
            "Furui Liu"
        ],
        "published": "2024-05-22T12:27:24Z"
    },
    {
        "title": "Tools at the Frontiers of Quantitative Verification",
        "link": "http://arxiv.org/abs/2405.13583v1",
        "abstract": "The analysis of formal models that include quantitative aspects such as\ntiming or probabilistic choices is performed by quantitative verification\ntools. Broad and mature tool support is available for computing basic\nproperties such as expected rewards on basic models such as Markov chains.\nPrevious editions of QComp, the comparison of tools for the analysis of\nquantitative formal models, focused on this setting. Many application\nscenarios, however, require more advanced property types such as LTL and\nparameter synthesis queries as well as advanced models like stochastic games\nand partially observable MDPs. For these, tool support is in its infancy today.\nThis paper presents the outcomes of QComp 2023: a survey of the state of the\nart in quantitative verification tool support for advanced property types and\nmodels. With tools ranging from first research prototypes to well-supported\nintegrations into established toolsets, this report highlights today's active\nareas and tomorrow's challenges in tool-focused research for quantitative\nverification.",
        "subjects": [
            "cs.LO"
        ],
        "authors": [
            "Roman Andriushchenko",
            "Alexander Bork",
            "Carlos E. Budde",
            "Milan ƒåe≈°ka",
            "Kush Grover",
            "Ernst Moritz Hahn",
            "Arnd Hartmanns",
            "Bryant Israelsen",
            "Nils Jansen",
            "Joshua Jeppson",
            "Sebastian Junges",
            "Maximilian A. K√∂hl",
            "Bettina K√∂nighofer",
            "Jan K≈ôet√≠nsk√Ω",
            "Tobias Meggendorfer",
            "David Parker",
            "Stefan Pranger",
            "Tim Quatmann",
            "Enno Ruijters",
            "Landon Taylor",
            "Matthias Volk",
            "Maximilian Weininger",
            "Zhen Zhang"
        ],
        "published": "2024-05-22T12:24:18Z"
    },
    {
        "title": "Safety Alignment for Vision Language Models",
        "link": "http://arxiv.org/abs/2405.13581v1",
        "abstract": "Benefiting from the powerful capabilities of Large Language Models (LLMs),\npre-trained visual encoder models connected to an LLMs can realize Vision\nLanguage Models (VLMs). However, existing research shows that the visual\nmodality of VLMs is vulnerable, with attackers easily bypassing LLMs' safety\nalignment through visual modality features to launch attacks. To address this\nissue, we enhance the existing VLMs' visual modality safety alignment by adding\nsafety modules, including a safety projector, safety tokens, and a safety head,\nthrough a two-stage training process, effectively improving the model's defense\nagainst risky images. For example, building upon the LLaVA-v1.5 model, we\nachieve a safety score of 8.26, surpassing the GPT-4V on the Red Teaming Visual\nLanguage Models (RTVLM) benchmark. Our method boasts ease of use, high\nflexibility, and strong controllability, and it enhances safety while having\nminimal impact on the model's general performance. Moreover, our alignment\nstrategy also uncovers some possible risky content within commonly used\nopen-source multimodal datasets. Our code will be open sourced after the\nanonymous review.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Zhendong Liu",
            "Yuanbi Nie",
            "Yingshui Tan",
            "Xiangyu Yue",
            "Qiushi Cui",
            "Chongjun Wang",
            "Xiaoyong Zhu",
            "Bo Zheng"
        ],
        "published": "2024-05-22T12:21:27Z"
    },
    {
        "title": "AltChart: Enhancing VLM-based Chart Summarization Through Multi-Pretext\n  Tasks",
        "link": "http://arxiv.org/abs/2405.13580v1",
        "abstract": "Chart summarization is a crucial task for blind and visually impaired\nindividuals as it is their primary means of accessing and interpreting\ngraphical data. Crafting high-quality descriptions is challenging because it\nrequires precise communication of essential details within the chart without\nvision perception. Many chart analysis methods, however, produce brief,\nunstructured responses that may contain significant hallucinations, affecting\ntheir reliability for blind people. To address these challenges, this work\npresents three key contributions: (1) We introduce the AltChart dataset,\ncomprising 10,000 real chart images, each paired with a comprehensive summary\nthat features long-context, and semantically rich annotations. (2) We propose a\nnew method for pretraining Vision-Language Models (VLMs) to learn fine-grained\nchart representations through training with multiple pretext tasks, yielding a\nperformance gain with ${\\sim}2.5\\%$. (3) We conduct extensive evaluations of\nfour leading chart summarization models, analyzing how accessible their\ndescriptions are. Our dataset and codes are publicly available on our project\npage: https://github.com/moured/AltChart.",
        "subjects": [
            "cs.CV",
            "cs.HC"
        ],
        "authors": [
            "Omar Moured",
            "Jiaming Zhang",
            "M. Saquib Sarfraz",
            "Rainer Stiefelhagen"
        ],
        "published": "2024-05-22T12:18:52Z"
    },
    {
        "title": "ConTrans: Weak-to-Strong Alignment Engineering via Concept\n  Transplantation",
        "link": "http://arxiv.org/abs/2405.13578v1",
        "abstract": "Ensuring large language models (LLM) behave consistently with human goals,\nvalues, and intentions is crucial for their safety but yet computationally\nexpensive. To reduce the computational cost of alignment training of LLMs,\nespecially for those with a huge number of parameters, and to reutilize learned\nvalue alignment, we propose ConTrans, a novel framework that enables\nweak-to-strong alignment transfer via concept transplantation. From the\nperspective of representation engineering, ConTrans refines concept vectors in\nvalue alignment from a source LLM (usually a weak yet aligned LLM). The refined\nconcept vectors are then reformulated to adapt to the target LLM (usually a\nstrong yet unaligned base LLM) via affine transformation. In the third step,\nConTrans transplants the reformulated concept vectors into the residual stream\nof the target LLM. Experiments demonstrate the successful transplantation of a\nwide range of aligned concepts from 7B models to 13B and 70B models across\nmultiple LLMs and LLM families. Remarkably, ConTrans even surpasses\ninstruction-tuned models in terms of truthfulness. Experiment results validate\nthe effectiveness of both inter-LLM-family and intra-LLM-family concept\ntransplantation. Our work successfully demonstrates an alternative way to\nachieve weak-to-strong alignment generalization and control.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Weilong Dong",
            "Xinwei Wu",
            "Renren Jin",
            "Shaoyang Xu",
            "Deyi Xiong"
        ],
        "published": "2024-05-22T12:15:52Z"
    },
    {
        "title": "FlashRAG: A Modular Toolkit for Efficient Retrieval-Augmented Generation\n  Research",
        "link": "http://arxiv.org/abs/2405.13576v1",
        "abstract": "With the advent of Large Language Models (LLMs), the potential of Retrieval\nAugmented Generation (RAG) techniques have garnered considerable research\nattention. Numerous novel algorithms and models have been introduced to enhance\nvarious aspects of RAG systems. However, the absence of a standardized\nframework for implementation, coupled with the inherently intricate RAG\nprocess, makes it challenging and time-consuming for researchers to compare and\nevaluate these approaches in a consistent environment. Existing RAG toolkits\nlike LangChain and LlamaIndex, while available, are often heavy and unwieldy,\nfailing to meet the personalized needs of researchers. In response to this\nchallenge, we propose FlashRAG, an efficient and modular open-source toolkit\ndesigned to assist researchers in reproducing existing RAG methods and in\ndeveloping their own RAG algorithms within a unified framework. Our toolkit\nimplements 12 advanced RAG methods and has gathered and organized 32 benchmark\ndatasets. Our toolkit has various features, including customizable modular\nframework, rich collection of pre-implemented RAG works, comprehensive\ndatasets, efficient auxiliary pre-processing scripts, and extensive and\nstandard evaluation metrics. Our toolkit and resources are available at\nhttps://github.com/RUC-NLPIR/FlashRAG.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "authors": [
            "Jiajie Jin",
            "Yutao Zhu",
            "Xinyu Yang",
            "Chenghao Zhang",
            "Zhicheng Dou"
        ],
        "published": "2024-05-22T12:12:40Z"
    },
    {
        "title": "PDMLP: Patch-based Decomposed MLP for Long-Term Time Series Forecastin",
        "link": "http://arxiv.org/abs/2405.13575v1",
        "abstract": "Recent studies have attempted to refine the Transformer architecture to\ndemonstrate its effectiveness in Long-Term Time Series Forecasting (LTSF)\ntasks. Despite surpassing many linear forecasting models with ever-improving\nperformance, we remain skeptical of Transformers as a solution for LTSF. We\nattribute the effectiveness of these models largely to the adopted Patch\nmechanism, which enhances sequence locality to an extent yet fails to fully\naddress the loss of temporal information inherent to the permutation-invariant\nself-attention mechanism. Further investigation suggests that simple linear\nlayers augmented with the Patch mechanism may outperform complex\nTransformer-based LTSF models. Moreover, diverging from models that use channel\nindependence, our research underscores the importance of cross-variable\ninteractions in enhancing the performance of multivariate time series\nforecasting. The interaction information between variables is highly valuable\nbut has been misapplied in past studies, leading to suboptimal cross-variable\nmodels. Based on these insights, we propose a novel and simple Patch-based\nDecomposed MLP (PDMLP) for LTSF tasks. Specifically, we employ simple moving\naverages to extract smooth components and noise-containing residuals from time\nseries data, engaging in semantic information interchange through channel\nmixing and specializing in random noise with channel independence processing.\nThe PDMLP model consistently achieves state-of-the-art results on several\nreal-world datasets. We hope this surprising finding will spur new research\ndirections in the LTSF field and pave the way for more efficient and concise\nsolutions.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Peiwang Tang",
            "Weitai Zhang"
        ],
        "published": "2024-05-22T12:12:20Z"
    },
    {
        "title": "Reinforcement Learning for Adaptive MCMC",
        "link": "http://arxiv.org/abs/2405.13574v1",
        "abstract": "An informal observation, made by several authors, is that the adaptive design\nof a Markov transition kernel has the flavour of a reinforcement learning task.\nYet, to-date it has remained unclear how to actually exploit modern\nreinforcement learning technologies for adaptive MCMC. The aim of this paper is\nto set out a general framework, called Reinforcement Learning\nMetropolis--Hastings, that is theoretically supported and empirically\nvalidated. Our principal focus is on learning fast-mixing Metropolis--Hastings\ntransition kernels, which we cast as deterministic policies and optimise via a\npolicy gradient. Control of the learning rate provably ensures conditions for\nergodicity are satisfied. The methodology is used to construct a gradient-free\nsampler that out-performs a popular gradient-free adaptive Metropolis--Hastings\nalgorithm on $\\approx 90 \\%$ of tasks in the PosteriorDB benchmark.",
        "subjects": [
            "stat.CO",
            "cs.LG"
        ],
        "authors": [
            "Congye Wang",
            "Wilson Chen",
            "Heishiro Kanagawa",
            "Chris. J. Oates"
        ],
        "published": "2024-05-22T12:11:12Z"
    },
    {
        "title": "Learning Manipulation Skills through Robot Chain-of-Thought with Sparse\n  Failure Guidance",
        "link": "http://arxiv.org/abs/2405.13573v1",
        "abstract": "The acquisition of manipulation skills through language instruction remains\nan unresolved challenge. Recently, vision-language models have made significant\nprogress in teaching robots these skills. However, their performance is\nrestricted to a narrow range of simple tasks. In this paper, we propose that\nvision-language models can provide a superior source of rewards for agents. Our\nmethod decomposes complex tasks into simpler sub-goals, enabling better task\ncomprehension and avoiding potential failures with sparse failure guidance.\nEmpirical evidence demonstrates that our algorithm consistently outperforms\nbaselines such as CLIP, LIV, and RoboCLIP. Specifically, our algorithm achieves\na $5.4\\times$ higher average success rate compared to the best baseline,\nRoboCLIP, across a series of manipulation tasks. It has shown a comprehensive\nunderstanding of a wide range of robotic manipulation tasks.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Kaifeng Zhang",
            "Zhao-Heng Yin",
            "Weirui Ye",
            "Yang Gao"
        ],
        "published": "2024-05-22T12:09:40Z"
    },
    {
        "title": "Illustrating the Efficiency of Popular Evolutionary Multi-Objective\n  Algorithms Using Runtime Analysis",
        "link": "http://dx.doi.org/10.1145/3638529.3654177",
        "abstract": "Runtime analysis has recently been applied to popular evolutionary\nmulti-objective (EMO) algorithms like NSGA-II in order to establish a rigorous\ntheoretical foundation. However, most analyses showed that these algorithms\nhave the same performance guarantee as the simple (G)SEMO algorithm. To our\nknowledge, there are no runtime analyses showing an advantage of a popular EMO\nalgorithm over the simple algorithm for deterministic problems.\n  We propose such a problem and use it to showcase the superiority of popular\nEMO algorithms over (G)SEMO: OneTrapZeroTrap is a straightforward\ngeneralization of the well-known Trap function to two objectives. We prove\nthat, while GSEMO requires at least $n^n$ expected fitness evaluations to\noptimise OneTrapZeroTrap, popular EMO algorithms NSGA-II, NSGA-III and\nSMS-EMOA, all enhanced with a mild diversity mechanism of avoiding genotype\nduplication, only require $O(n \\log n)$ expected fitness evaluations. Our\nanalysis reveals the importance of the key components in each of these\nsophisticated algorithms and contributes to a better understanding of their\ncapabilities.",
        "subjects": [
            "cs.NE",
            "F.2.0; I.2.8"
        ],
        "authors": [
            "Duc-Cuong Dang",
            "Andre Opris",
            "Dirk Sudholt"
        ],
        "published": "2024-05-22T12:09:00Z"
    },
    {
        "title": "Cross-Modal Distillation in Industrial Anomaly Detection: Exploring\n  Efficient Multi-Modal IAD",
        "link": "http://arxiv.org/abs/2405.13571v1",
        "abstract": "Recent studies of multi-modal Industrial Anomaly Detection (IAD) based on\npoint clouds and RGB images indicated the importance of exploiting redundancy\nand complementarity among modalities for accurate classification and\nsegmentation. However, achieving multi-modal IAD in practical production lines\nremains a work in progress that requires consideration of the trade-offs\nbetween costs and benefits associated with introducing new modalities, while\nensuring compatibility with current processes. Combining fast in-line\ninspections with high-resolution, time-consuming, near-line characterization\ntechniques to enhance detection accuracy fits well into the existing quality\ncontrol process, but only part of the samples can be tested with expensive\nnear-line methods. Thus, the model must have the ability to leverage\nmulti-modal training and handle incomplete modalities during inference. One\nsolution is generating cross-modal hallucination to transfer knowledge among\nmodalities for missing modality issues. In this paper, we propose CMDIAD, a\nCross-Modal Distillation framework for IAD to demonstrate the feasibility of\nMulti-modal Training, Few-modal Inference pipeline. Moreover, we investigate\nreasons behind the asymmetric performance improvement using point clouds or RGB\nimages as main modality of inference. This lays the foundation of our future\nmulti-modal dataset construction for efficient IAD from manufacturing\nscenarios.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Wenbo Sui",
            "Daniel Lichau",
            "Josselin Lef√®vre",
            "Harold Phelippeau"
        ],
        "published": "2024-05-22T12:08:56Z"
    },
    {
        "title": "MetaEarth: A Generative Foundation Model for Global-Scale Remote Sensing\n  Image Generation",
        "link": "http://arxiv.org/abs/2405.13570v1",
        "abstract": "The recent advancement of generative foundational models has ushered in a new\nera of image generation in the realm of natural images, revolutionizing art\ndesign, entertainment, environment simulation, and beyond. Despite producing\nhigh-quality samples, existing methods are constrained to generating images of\nscenes at a limited scale. In this paper, we present MetaEarth, a generative\nfoundation model that breaks the barrier by scaling image generation to a\nglobal level, exploring the creation of worldwide, multi-resolution, unbounded,\nand virtually limitless remote sensing images. In MetaEarth, we propose a\nresolution-guided self-cascading generative framework, which enables the\ngenerating of images at any region with a wide range of geographical\nresolutions. To achieve unbounded and arbitrary-sized image generation, we\ndesign a novel noise sampling strategy for denoising diffusion models by\nanalyzing the generation conditions and initial noise. To train MetaEarth, we\nconstruct a large dataset comprising multi-resolution optical remote sensing\nimages with geographical information. Experiments have demonstrated the\npowerful capabilities of our method in generating global-scale images.\nAdditionally, the MetaEarth serves as a data engine that can provide\nhigh-quality and rich training data for downstream tasks. Our model opens up\nnew possibilities for constructing generative world models by simulating Earth\nvisuals from an innovative overhead perspective.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhiping Yu",
            "Chenyang Liu",
            "Liqin Liu",
            "Zhenwei Shi",
            "Zhengxia Zou"
        ],
        "published": "2024-05-22T12:07:47Z"
    },
    {
        "title": "CPE-Identifier: Automated CPE identification and CVE summaries\n  annotation with Deep Learning and NLP",
        "link": "http://arxiv.org/abs/2405.13568v1",
        "abstract": "With the drastic increase in the number of new vulnerabilities in the\nNational Vulnerability Database (NVD) every year, the workload for NVD analysts\nto associate the Common Platform Enumeration (CPE) with the Common\nVulnerabilities and Exposures (CVE) summaries becomes increasingly laborious\nand slow. The delay causes organisations, which depend on NVD for vulnerability\nmanagement and security measurement, to be more vulnerable to zero-day attacks.\nThus, it is essential to come out with a technique and tool to extract the CPEs\nin the CVE summaries accurately and quickly. In this work, we propose the\nCPE-Identifier system, an automated CPE annotating and extracting system, from\nthe CVE summaries. The system can be used as a tool to identify CPE entities\nfrom new CVE text inputs. Moreover, we also automate the data generating and\nlabeling processes using deep learning models. Due to the complexity of the CVE\ntexts, new technical terminologies appear frequently. To identify novel words\nin future CVE texts, we apply Natural Language Processing (NLP) Named Entity\nRecognition (NER), to identify new technical jargons in the text. Our proposed\nmodel achieves an F1 score of 95.48%, an accuracy score of 99.13%, a precision\nof 94.83%, and a recall of 96.14%. We show that it outperforms prior works on\nautomated CVE-CPE labeling by more than 9% on all metrics.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Wanyu Hu",
            "Vrizlynn L. L. Thing"
        ],
        "published": "2024-05-22T12:05:17Z"
    },
    {
        "title": "Bounds on the approximation error for deep neural networks applied to\n  dispersive models: Nonlinear waves",
        "link": "http://arxiv.org/abs/2405.13566v1",
        "abstract": "We present a comprehensive framework for deriving rigorous and efficient\nbounds on the approximation error of deep neural networks in PDE models\ncharacterized by branching mechanisms, such as waves, Schr\\\"odinger equations,\nand other dispersive models. This framework utilizes the probabilistic setting\nestablished by Henry-Labord\\`ere and Touzi. We illustrate this approach by\nproviding rigorous bounds on the approximation error for both linear and\nnonlinear waves in physical dimensions $d=1,2,3$, and analyze their respective\ncomputational costs starting from time zero. We investigate two key scenarios:\none involving a linear perturbative source term, and another focusing on pure\nnonlinear internal interactions.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "math.AP",
            "math.PR"
        ],
        "authors": [
            "Claudio Mu√±oz",
            "Nicol√°s Valenzuela"
        ],
        "published": "2024-05-22T12:01:13Z"
    },
    {
        "title": "AI-Assisted Assessment of Coding Practices in Modern Code Review",
        "link": "http://dx.doi.org/10.1145/3664646.3665664",
        "abstract": "Modern code review is a process in which an incremental code contribution\nmade by a code author is reviewed by one or more peers before it is committed\nto the version control system. An important element of modern code review is\nverifying that code contributions adhere to best practices. While some of these\nbest practices can be automatically verified, verifying others is commonly left\nto human reviewers. This paper reports on the development, deployment, and\nevaluation of AutoCommenter, a system backed by a large language model that\nautomatically learns and enforces coding best practices. We implemented\nAutoCommenter for four programming languages (C++, Java, Python, and Go) and\nevaluated its performance and adoption in a large industrial setting. Our\nevaluation shows that an end-to-end system for learning and enforcing coding\nbest practices is feasible and has a positive impact on the developer workflow.\nAdditionally, this paper reports on the challenges associated with deploying\nsuch a system to tens of thousands of developers and the corresponding lessons\nlearned.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "authors": [
            "Manushree Vijayvergiya",
            "Ma≈Çgorzata Salawa",
            "Ivan Budiseliƒá",
            "Dan Zheng",
            "Pascal Lamblin",
            "Marko Ivankoviƒá",
            "Juanjo Carin",
            "Mateusz Lewko",
            "Jovan Andonov",
            "Goran Petroviƒá",
            "Daniel Tarlow",
            "Petros Maniatis",
            "Ren√© Just"
        ],
        "published": "2024-05-22T11:57:18Z"
    },
    {
        "title": "Hybrid Event-triggered Control of Nonlinear System with Full State\n  Constraints and Disturbance",
        "link": "http://arxiv.org/abs/2405.13564v1",
        "abstract": "This article focuses on the problem of adaptive tracking control for a\nspecific type of nonlinear system that is subject to full-state constraints via\na hybrid event-triggered control (HETC) strategy. With the auxiliary system, we\nproposed a 'log' function to deal with the full-state constraint. Additionally,\na disturbance observer (DO) is constructed to handle the unmeasurable external\ndisturbance. Then, by employing radial basis function neural networks (RBFNNs)\nand a first-order differentiator, an opportune backstepping design procedure is\ngiven to avoid the problem of \"explosion of complexity\". The HETC strategy,\nincluding the fixed and relative threshold, is presented to provide more\nflexibility in balancing the system performances and network burdens. Finally,\nto demonstrate the effectiveness of the aforementioned control scheme, a\nsimulation example is presented to validate its effectiveness.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Ziming Wang"
        ],
        "published": "2024-05-22T11:57:04Z"
    },
    {
        "title": "Algorithmic Planning of Ventilation Systems: Optimising for Life-Cycle\n  Costs and Acoustic Comfort",
        "link": "http://arxiv.org/abs/2405.13563v1",
        "abstract": "The increasing significance of energy efficiency in the building sector\nnecessitates innovative planning to reduce energy consumption while maintaining\noccupant comfort. With the rise in mechanically ventilated buildings,\ntraditional sequential planning methods, which first ensure outdoor air supply\nbefore addressing acoustics, are being reassessed due to their risk for\nsuboptimal solutions. This study introduces a holistic algorithmic methodology\nfor ventilation system design to minimise life-cycle costs while ensuring\nacoustically feasible solutions. Utilising discrete mathematics, the approach\nmodels components' impact on airflow, acoustics, power consumption, and costs,\nacross multiple load cases, culminating in a 2-stage stochastic Mixed-Integer\nNonlinear Program. A case study demonstrates the methodology's applicability\nand the trade-off between energy efficiency and noise levels, highlighting its\npotential for more complex buildings. This integrated approach marks a\nsignificant advancement in ventilation system optimisation, promoting more\nholistic and efficient building designs while allowing for a more transparent\ndecision-making.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Julius H. P. Breuer",
            "Peter F. Pelz"
        ],
        "published": "2024-05-22T11:54:21Z"
    },
    {
        "title": "Navigating User Experience of ChatGPT-based Conversational Recommender\n  Systems: The Effects of Prompt Guidance and Recommendation Domain",
        "link": "http://arxiv.org/abs/2405.13560v1",
        "abstract": "Conversational recommender systems (CRS) enable users to articulate their\npreferences and provide feedback through natural language. With the advent of\nlarge language models (LLMs), the potential to enhance user engagement with CRS\nand augment the recommendation process with LLM-generated content has received\nincreasing attention. However, the efficacy of LLM-powered CRS is contingent\nupon the use of prompts, and the subjective perception of recommendation\nquality can differ across various recommendation domains. Therefore, we have\ndeveloped a ChatGPT-based CRS to investigate the impact of these two factors,\nprompt guidance (PG) and recommendation domain (RD), on the overall user\nexperience of the system. We conducted an online empirical study (N = 100) by\nemploying a mixed-method approach that utilized a between-subjects design for\nthe variable of PG (with vs. without) and a within-subjects design for RD (book\nrecommendations vs. job recommendations). The findings reveal that PG can\nsubstantially enhance the system's explainability, adaptability, perceived ease\nof use, and transparency. Moreover, users are inclined to perceive a greater\nsense of novelty and demonstrate a higher propensity to engage with and try\nrecommended items in the context of book recommendations as opposed to job\nrecommendations. Furthermore, the influence of PG on certain user experience\nmetrics and interactive behaviors appears to be modulated by the recommendation\ndomain, as evidenced by the interaction effects between the two examined\nfactors. This work contributes to the user-centered evaluation of ChatGPT-based\nCRS by investigating two prominent factors and offers practical design\nguidance.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Yizhe Zhang",
            "Yucheng Jin",
            "Li Chen",
            "Ting Yang"
        ],
        "published": "2024-05-22T11:49:40Z"
    },
    {
        "title": "Identification of microstructure from macroscopic measurement using\n  inverse multiscale analysis",
        "link": "http://arxiv.org/abs/2405.13559v1",
        "abstract": "Most of the tailored materials are heterogeneous at the ingredient level.\nAnalysis of those heterogeneous structures requires the knowledge of\nmicrostructure. With the knowledge of microstructure, multiscale analysis is\ncarried out with homogenization at the micro level. Second-order homogenization\nis carried out whenever the ingredient size is comparable to the structure\nsize. Therefore, knowledge of microstructure and its size is indispensable to\nanalyzing those heterogeneous structures. Again, any structural response\ncontains all the information of microstructure, like microstructure\ndistribution, volume fraction, size of ingredients, etc. Here, inverse analysis\nis carried out to identify a heterogeneous microstructure from macroscopic\nmeasurement. Two-step inverse analysis is carried out in the identification\nprocess; in the first step, the macrostructures length scale and effective\nproperties are identified from the macroscopic measurement using gradient-based\noptimization. In the second step, those effective properties and length scales\nare used to determine the microstructure in inverse second-order\nhomogenization.",
        "subjects": [
            "cs.CE"
        ],
        "authors": [
            "Anjan Mukherjee",
            "Biswanth Banerjee"
        ],
        "published": "2024-05-22T11:47:51Z"
    },
    {
        "title": "MotionCraft: Physics-based Zero-Shot Video Generation",
        "link": "http://arxiv.org/abs/2405.13557v1",
        "abstract": "Generating videos with realistic and physically plausible motion is one of\nthe main recent challenges in computer vision. While diffusion models are\nachieving compelling results in image generation, video diffusion models are\nlimited by heavy training and huge models, resulting in videos that are still\nbiased to the training dataset. In this work we propose MotionCraft, a new\nzero-shot video generator to craft physics-based and realistic videos.\nMotionCraft is able to warp the noise latent space of an image diffusion model,\nsuch as Stable Diffusion, by applying an optical flow derived from a physics\nsimulation. We show that warping the noise latent space results in coherent\napplication of the desired motion while allowing the model to generate missing\nelements consistent with the scene evolution, which would otherwise result in\nartefacts or missing content if the flow was applied in the pixel space. We\ncompare our method with the state-of-the-art Text2Video-Zero reporting\nqualitative and quantitative improvements, demonstrating the effectiveness of\nour approach to generate videos with finely-prescribed complex motion dynamics.\nProject page: https://mezzelfo.github.io/MotionCraft/",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Luca Savant Aira",
            "Antonio Montanaro",
            "Emanuele Aiello",
            "Diego Valsesia",
            "Enrico Magli"
        ],
        "published": "2024-05-22T11:44:57Z"
    },
    {
        "title": "A Perspective Analysis of Handwritten Signature Technology",
        "link": "http://dx.doi.org/10.1145/3274658",
        "abstract": "Handwritten signatures are biometric traits at the center of debate in the\nscientific community. Over the last 40 years, the interest in signature studies\nhas grown steadily, having as its main reference the application of automatic\nsignature verification, as previously published reviews in 1989, 2000, and 2008\nbear witness. Ever since, and over the last 10 years, the application of\nhandwritten signature technology has strongly evolved, and much research has\nfocused on the possibility of applying systems based on handwritten signature\nanalysis and processing to a multitude of new fields. After several years of\nhaphazard growth of this research area, it is time to assess its current\ndevelopments for their applicability in order to draw a structured way forward.\nThis perspective reports a systematic review of the last 10 years of the\nliterature on handwritten signatures with respect to the new scenario, focusing\non the most promising domains of research and trying to elicit possible future\nresearch directions in this subject.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Moises Diaz",
            "Miguel A. Ferrer",
            "Donato Impedovo",
            "Muhammad Imran Malik",
            "Giuseppe Pirlo",
            "Rejean Plamondon"
        ],
        "published": "2024-05-22T11:41:19Z"
    },
    {
        "title": "The Influencer Next Door: How Misinformation Creators Use GenAI",
        "link": "http://arxiv.org/abs/2405.13554v1",
        "abstract": "Advances in generative AI (GenAI) have raised concerns about detecting and\ndiscerning AI-generated content from human-generated content. Most existing\nliterature assumes a paradigm where 'expert' organized disinformation creators\nand flawed AI models deceive 'ordinary' users. Based on longitudinal\nethnographic research with misinformation creators and consumers between\n2022-2023, we instead find that GenAI supports bricolage work, where\nnon-experts increasingly use GenAI to remix, repackage, and (re)produce content\nto meet their personal needs and desires. This research yielded four key\nfindings: First, participants primarily used GenAI for creation, rather than\ntruth-seeking. Second, a spreading 'influencer millionaire' narrative drove\nparticipants to become content creators, using GenAI as a productivity tool to\ngenerate a volume of (often misinformative) content. Third, GenAI lowered the\nbarrier to entry for content creation across modalities, enticing consumers to\nbecome creators and significantly increasing existing creators' output.\nFinally, participants used Gen AI to learn and deploy marketing tactics to\nexpand engagement and monetize their content. We argue for shifting analysis\nfrom the public as consumers of AI content to bricoleurs who use GenAI\ncreatively, often without a detailed understanding of its underlying\ntechnology. We analyze how these understudied emergent uses of GenAI produce\nnew or accelerated misinformation harms, and their implications for AI\nproducts, platforms and policies.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Amelia Hassoun",
            "Ariel Abonizio",
            "Beth Goldberg",
            "Katy Osborn",
            "Cameron Wu"
        ],
        "published": "2024-05-22T11:40:22Z"
    },
    {
        "title": "Large Language Models are Effective Priors for Causal Graph Discovery",
        "link": "http://arxiv.org/abs/2405.13551v1",
        "abstract": "Causal structure discovery from observations can be improved by integrating\nbackground knowledge provided by an expert to reduce the hypothesis space.\nRecently, Large Language Models (LLMs) have begun to be considered as sources\nof prior information given the low cost of querying them relative to a human\nexpert. In this work, firstly, we propose a set of metrics for assessing LLM\njudgments for causal graph discovery independently of the downstream algorithm.\nSecondly, we systematically study a set of prompting designs that allows the\nmodel to specify priors about the structure of the causal graph. Finally, we\npresent a general methodology for the integration of LLM priors in graph\ndiscovery algorithms, finding that they help improve performance on\ncommon-sense benchmarks and especially when used for assessing edge\ndirectionality. Our work highlights the potential as well as the shortcomings\nof the use of LLMs in this problem space.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Victor-Alexandru Darvariu",
            "Stephen Hailes",
            "Mirco Musolesi"
        ],
        "published": "2024-05-22T11:39:11Z"
    },
    {
        "title": "Multi-Objective Optimization-Based Waveform Design for Multi-User and\n  Multi-Target MIMO-ISAC Systems",
        "link": "http://arxiv.org/abs/2405.13549v1",
        "abstract": "Integrated sensing and communication (ISAC) opens up new service\npossibilities for sixth-generation (6G) systems, where both communication and\nsensing (C&S) functionalities co-exist by sharing the same hardware platform\nand radio resource. In this paper, we investigate the waveform design problem\nin a downlink multi-user and multi-target ISAC system under different C&S\nperformance preferences. The multi-user interference (MUI) may critically\ndegrade the communication performance. To eliminate the MUI, we employ the\nconstructive interference mechanism into the ISAC system, which saves the power\nbudget for communication. However, due to the conflict between C&S metrics, it\nis intractable for the ISAC system to achieve the optimal performance of C&S\nobjective simultaneously. Therefore, it is important to strike a tradeoff\nbetween C&S objectives. By virtue of the multi-objective optimization theory,\nwe propose a weighted Tchebycheff-based transformation method to re-frame the\nC&S trade-off problem as a Pareto-optimal problem, thus effectively tackling\nthe constraints in ISAC systems. Finally, simulation results reveal the\ntrade-off relation between C&S performances, which provides insights for the\nflexible waveform design under different C&S performance preferences in\nMIMO-ISAC systems.",
        "subjects": [
            "eess.SP",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Peng Wang",
            "Dongsheng Han",
            "Yashuai Cao",
            "Wanli Ni",
            "Dusit Niyato"
        ],
        "published": "2024-05-22T11:33:40Z"
    },
    {
        "title": "ECLIPSE: Semantic Entropy-LCS for Cross-Lingual Industrial Log Parsing",
        "link": "http://arxiv.org/abs/2405.13548v2",
        "abstract": "Log parsing, a vital task for interpreting the vast and complex data produced\nwithin software architectures faces significant challenges in the transition\nfrom academic benchmarks to the industrial domain. Existing log parsers, while\nhighly effective on standardized public datasets, struggle to maintain\nperformance and efficiency when confronted with the sheer scale and diversity\nof real-world industrial logs. These challenges are two-fold: 1) massive log\ntemplates: The performance and efficiency of most existing parsers will be\nsignificantly reduced when logs of growing quantities and different lengths; 2)\nComplex and changeable semantics: Traditional template-matching algorithms\ncannot accurately match the log templates of complicated industrial logs\nbecause they cannot utilize cross-language logs with similar semantics. To\naddress these issues, we propose ECLIPSE, Enhanced Cross-Lingual Industrial log\nParsing with Semantic Entropy-LCS, since cross-language logs can robustly parse\nindustrial logs. On the one hand, it integrates two efficient data-driven\ntemplate-matching algorithms and Faiss indexing. On the other hand, driven by\nthe powerful semantic understanding ability of the Large Language Model (LLM),\nthe semantics of log keywords were accurately extracted, and the retrieval\nspace was effectively reduced. Notably, we launch a Chinese and English\ncross-platform industrial log parsing benchmark ECLIPSE- BENCH to evaluate the\nperformance of mainstream parsers in industrial scenarios. Our experimental\nresults across public benchmarks and ECLIPSE- BENCH underscore the superior\nperformance and robustness of our proposed ECLIPSE. Notably, ECLIPSE both\ndelivers state-of-the-art performance when compared to strong baselines and\npreserves a significant edge in processing efficiency.",
        "subjects": [
            "cs.SE",
            "cs.CL"
        ],
        "authors": [
            "Wei Zhang",
            "Xianfu Cheng",
            "Yi Zhang",
            "Jian Yang",
            "Hongcheng Guo",
            "Zhoujun Li",
            "Xiaolin Yin",
            "Xiangyuan Guan",
            "Xu Shi",
            "Liangfan Zheng",
            "Bo Zhang"
        ],
        "published": "2024-05-22T11:33:29Z"
    },
    {
        "title": "HighwayLLM: Decision-Making and Navigation in Highway Driving with\n  RL-Informed Language Model",
        "link": "http://arxiv.org/abs/2405.13547v1",
        "abstract": "Autonomous driving is a complex task which requires advanced decision making\nand control algorithms. Understanding the rationale behind the autonomous\nvehicles' decision is crucial to ensure their safe and effective operation on\nhighway driving. This study presents a novel approach, HighwayLLM, which\nharnesses the reasoning capabilities of large language models (LLMs) to predict\nthe future waypoints for ego-vehicle's navigation. Our approach also utilizes a\npre-trained Reinforcement Learning (RL) model to serve as a high-level planner,\nmaking decisions on appropriate meta-level actions. The HighwayLLM combines the\noutput from the RL model and the current state information to make safe,\ncollision-free, and explainable predictions for the next states, thereby\nconstructing a trajectory for the ego-vehicle. Subsequently, a PID-based\ncontroller guides the vehicle to the waypoints predicted by the LLM agent. This\nintegration of LLM with RL and PID enhances the decision-making process and\nprovides interpretability for highway autonomous driving.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "authors": [
            "Mustafa Yildirim",
            "Barkin Dagda",
            "Saber Fallah"
        ],
        "published": "2024-05-22T11:32:37Z"
    },
    {
        "title": "Knowledge-Driven Cross-Document Relation Extraction",
        "link": "http://arxiv.org/abs/2405.13546v1",
        "abstract": "Relation extraction (RE) is a well-known NLP application often treated as a\nsentence- or document-level task. However, a handful of recent efforts explore\nit across documents or in the cross-document setting (CrossDocRE). This is\ndistinct from the single document case because different documents often focus\non disparate themes, while text within a document tends to have a single goal.\nLinking findings from disparate documents to identify new relationships is at\nthe core of the popular literature-based knowledge discovery paradigm in\nbiomedicine and other domains. Current CrossDocRE efforts do not consider\ndomain knowledge, which are often assumed to be known to the reader when\ndocuments are authored. Here, we propose a novel approach, KXDocRE, that embed\ndomain knowledge of entities with input text for cross-document RE. Our\nproposed framework has three main benefits over baselines: 1) it incorporates\ndomain knowledge of entities along with documents' text; 2) it offers\ninterpretability by producing explanatory text for predicted relations between\nentities 3) it improves performance over the prior methods.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "authors": [
            "Monika Jain",
            "Raghava Mutharaju",
            "Kuldeep Singh",
            "Ramakanth Kavuluru"
        ],
        "published": "2024-05-22T11:30:59Z"
    },
    {
        "title": "Towards a Distributed Platform for Normative Reasoning and Value\n  Alignment in Multi-Agent Systems",
        "link": "http://arxiv.org/abs/2405.13543v1",
        "abstract": "This paper presents an extended version of the SPADE platform, which aims to\nempower intelligent agent systems with normative reasoning and value alignment\ncapabilities. Normative reasoning involves evaluating social norms and their\nimpact on decision-making, while value alignment ensures agents' actions are in\nline with desired principles and ethical guidelines. The extended platform\nequips agents with normative awareness and reasoning capabilities based on\ndeontic logic, allowing them to assess the appropriateness of their actions and\nmake informed decisions. By integrating normative reasoning and value\nalignment, the platform enhances agents' social intelligence and promotes\nresponsible and ethical behaviors in complex environments.",
        "subjects": [
            "cs.MA"
        ],
        "authors": [
            "Miguel Garcia-Bohigues",
            "Carmengelys Cordova",
            "Joaquin Taverner",
            "Javier Palanca",
            "Elena del Val",
            "Estefania Argente"
        ],
        "published": "2024-05-22T11:26:51Z"
    },
    {
        "title": "Towards Safe Mid-Air Drone Interception: Strategies for Tracking &\n  Capture",
        "link": "http://arxiv.org/abs/2405.13542v1",
        "abstract": "A unique approach for the mid-air autonomous aerial interception of\nnon-cooperating UAV by a flying robot equipped with a net is presented in this\npaper. A novel interception guidance method dubbed EPN is proposed, designed to\ncatch agile maneuvering targets while relying on onboard state estimation and\ntracking. The proposed method is compared with state-of-the-art approaches in\nsimulations using 100 different trajectories of the target with varying\ncomplexity comprising almost 14 hours of flight data, and EPN demonstrates the\nshortest response time and the highest number of interceptions, which are key\nparameters of agile interception. To enable robust transfer from theory and\nsimulation to a real-world implementation, we aim to avoid overfitting to\nspecific assumptions about the target, and to tackle interception of a target\nfollowing an unknown general trajectory. Furthermore, we identify several often\noverlooked problems related to tracking and estimation of the target's state\nthat can have a significant influence on the overall performance of the system.\nWe propose the use of a novel state estimation filter based on the IMM filter\nand a new measurement model. Simulated experiments show that the proposed\nsolution provides significant improvements in estimation accuracy over the\ncommonly employed KF approaches when considering general trajectories. Based on\nthese results, we employ the proposed filtering and guidance methods to\nimplement a complete autonomous interception system, which is thoroughly\nevaluated in realistic simulations and tested in real-world experiments with a\nmaneuvering target going far beyond the performance of any state-of-the-art\nsolution.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Michal Pliska",
            "Matou≈° Vrba",
            "Tom√°≈° B√°ƒça",
            "Martin Saska"
        ],
        "published": "2024-05-22T11:26:09Z"
    },
    {
        "title": "Annotation-Efficient Preference Optimization for Language Model\n  Alignment",
        "link": "http://arxiv.org/abs/2405.13541v1",
        "abstract": "Preference optimization is a standard approach to fine-tuning large language\nmodels to align with human preferences. The quality, diversity, and quantity of\nthe preference dataset are critical to the effectiveness of preference\noptimization. However, obtaining a large amount of high-quality and diverse\npreference annotations is difficult in many applications. This raises the\nquestion of how to use the limited annotation budget to create an effective\npreference dataset. To this end, we propose Annotation-Efficient Preference\nOptimization (AEPO). Instead of exhaustively annotating preference over all\navailable response texts, AEPO selects a subset of responses that maximizes\nquality and diversity from the available responses, and then annotates\npreference over the selected ones. In this way, AEPO focuses the annotation\nbudget on labeling preference over a smaller subset of responses with diversity\nand of high quality. We evaluate the performance of Direct Preference\nOptimization (DPO) using AEPO and show that it outperforms models trained using\na standard DPO with the same annotation budget. Our code is available at\nhttps://github.com/CyberAgentAILab/annotation-efficient-po",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Yuu Jinnai",
            "Ukyo Honda"
        ],
        "published": "2024-05-22T11:23:03Z"
    },
    {
        "title": "Directly Denoising Diffusion Model",
        "link": "http://arxiv.org/abs/2405.13540v1",
        "abstract": "In this paper, we present the Directly Denoising Diffusion Model (DDDM): a\nsimple and generic approach for generating realistic images with few-step\nsampling, while multistep sampling is still preserved for better performance.\nDDDMs require no delicately designed samplers nor distillation on pre-trained\ndistillation models. DDDMs train the diffusion model conditioned on an\nestimated target that was generated from previous training iterations of its\nown. To generate images, samples generated from the previous time step are also\ntaken into consideration, guiding the generation process iteratively. We\nfurther propose Pseudo-LPIPS, a novel metric loss that is more robust to\nvarious values of hyperparameter. Despite its simplicity, the proposed approach\ncan achieve strong performance in benchmark datasets. Our model achieves FID\nscores of 2.57 and 2.33 on CIFAR-10 in one-step and two-step sampling\nrespectively, surpassing those obtained from GANs and distillation-based\nmodels. By extending the sampling to 1000 steps, we further reduce FID score to\n1.79, aligning with state-of-the-art methods in the literature. For ImageNet\n64x64, our approach stands as a competitive contender against leading models.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Dan Zhang",
            "Jingjing Wang",
            "Feng Luo"
        ],
        "published": "2024-05-22T11:20:32Z"
    },
    {
        "title": "Ultra-Fast Adaptive Track Detection Network",
        "link": "http://arxiv.org/abs/2405.13538v1",
        "abstract": "Railway detection is critical for the automation of railway systems. Existing\nmodels often prioritize either speed or accuracy, but achieving both remains a\nchallenge. To address the limitations of presetting anchor groups that struggle\nwith varying track proportions from different camera angles, an ultra-fast\nadaptive track detection network is proposed in this paper. This network\ncomprises a backbone network and two specialized branches (Horizontal\nCoordinate Locator and Perspective Identifier). The Perspective Identifier\nselects the suitable anchor group from preset anchor groups, thereby\ndetermining the row coordinates of the railway track. Subsequently, the\nHorizontal Coordinate Locator provides row classification results based on\nmultiple preset anchor groups. Then, utilizing the results from the Perspective\nIdentifier, it generates the column coordinates of the railway track. This\nnetwork is evaluated on multiple datasets, with the lightweight version\nachieving an F1 score of 98.68% on the SRail dataset and a detection rate of up\nto 473 FPS. Compared to the SOTA, the proposed model is competitive in both\nspeed and accuracy. The dataset and code are available at\nhttps://github.com/idnihai/UFATD",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hai Ni",
            "Rui Wang",
            "Scarlett Liu"
        ],
        "published": "2024-05-22T11:19:26Z"
    },
    {
        "title": "Attention Mechanisms Don't Learn Additive Models: Rethinking Feature\n  Importance for Transformers",
        "link": "http://arxiv.org/abs/2405.13536v1",
        "abstract": "We address the critical challenge of applying feature attribution methods to\nthe transformer architecture, which dominates current applications in natural\nlanguage processing and beyond. Traditional attribution methods to explainable\nAI (XAI) explicitly or implicitly rely on linear or additive surrogate models\nto quantify the impact of input features on a model's output. In this work, we\nformally prove an alarming incompatibility: transformers are structurally\nincapable to align with popular surrogate models for feature attribution,\nundermining the grounding of these conventional explanation methodologies. To\naddress this discrepancy, we introduce the Softmax-Linked Additive Log-Odds\nModel (SLALOM), a novel surrogate model specifically designed to align with the\ntransformer framework. Unlike existing methods, SLALOM demonstrates the\ncapacity to deliver a range of faithful and insightful explanations across both\nsynthetic and real-world datasets. Showing that diverse explanations computed\nfrom SLALOM outperform common surrogate explanations on different tasks, we\nhighlight the need for task-specific feature attributions rather than a\none-size-fits-all approach.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Tobias Leemann",
            "Alina Fastowski",
            "Felix Pfeiffer",
            "Gjergji Kasneci"
        ],
        "published": "2024-05-22T11:14:00Z"
    },
    {
        "title": "Generalized Laplace Approximation",
        "link": "http://arxiv.org/abs/2405.13535v2",
        "abstract": "In recent years, the inconsistency in Bayesian deep learning has garnered\nincreasing attention. Tempered or generalized posterior distributions often\noffer a direct and effective solution to this issue. However, understanding the\nunderlying causes and evaluating the effectiveness of generalized posteriors\nremain active areas of research. In this study, we introduce a unified\ntheoretical framework to attribute Bayesian inconsistency to model\nmisspecification and inadequate priors. We interpret the generalization of the\nposterior with a temperature factor as a correction for misspecified models\nthrough adjustments to the joint probability model, and the recalibration of\npriors by redistributing probability mass on models within the hypothesis space\nusing data samples. Additionally, we highlight a distinctive feature of Laplace\napproximation, which ensures that the generalized normalizing constant can be\ntreated as invariant, unlike the typical scenario in general Bayesian learning\nwhere this constant varies with model parameters post-generalization. Building\non this insight, we propose the generalized Laplace approximation, which\ninvolves a simple adjustment to the computation of the Hessian matrix of the\nregularized loss function. This method offers a flexible and scalable framework\nfor obtaining high-quality posterior distributions. We assess the performance\nand properties of the generalized Laplace approximation on state-of-the-art\nneural networks and real-world datasets.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Yinsong Chen",
            "Samson S. Yu",
            "Zhong Li",
            "Chee Peng Lim"
        ],
        "published": "2024-05-22T11:11:42Z"
    },
    {
        "title": "What Makes Good Few-shot Examples for Vision-Language Models?",
        "link": "http://arxiv.org/abs/2405.13532v1",
        "abstract": "Despite the notable advancements achieved by leveraging pre-trained\nvision-language (VL) models through few-shot tuning for downstream tasks, our\ndetailed empirical study highlights a significant dependence of few-shot\nlearning outcomes on the careful selection of training examples - a facet that\nhas been previously overlooked in research. In this study, we delve into\ndevising more effective strategies for the meticulous selection of few-shot\ntraining examples, as opposed to relying on random sampling, to enhance the\npotential of existing few-shot prompt learning methodologies. To achieve this,\nwe assess the effectiveness of various Active Learning (AL) techniques for\ninstance selection, such as Entropy and Margin of Confidence, within the\ncontext of few-shot training. Furthermore, we introduce two innovative\nselection methods - Representativeness (REPRE) and Gaussian Monte Carlo\n(Montecarlo) - designed to proactively pinpoint informative examples for\nlabeling in relation to pre-trained VL models. Our findings demonstrate that\nboth REPRE and Montecarlo significantly surpass both random selection and\nAL-based strategies in few-shot training scenarios. The research also\nunderscores that these instance selection methods are model-agnostic, offering\na versatile enhancement to a wide array of few-shot training methodologies.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhaojun Guo",
            "Jinghui Lu",
            "Xuejing Liu",
            "Rui Zhao",
            "ZhenXing Qian",
            "Fei Tan"
        ],
        "published": "2024-05-22T11:03:33Z"
    },
    {
        "title": "The correlation between nativelike selection and prototypicality: a\n  multilingual onomasiological case study using semantic embedding",
        "link": "http://arxiv.org/abs/2405.13529v1",
        "abstract": "In native speakers' lexical choices, a concept can be more readily expressed\nby one expression over another grammatical one, a phenomenon known as\nnativelike selection (NLS). In previous research, arbitrary chunks such as\ncollocations have been considered crucial for this phenomenon. However, this\nstudy examines the possibility of analyzing the semantic motivation and\ndeducibility behind some NLSs by exploring the correlation between NLS and\nprototypicality, specifically the onomasiological hypothesis of Grondelaers and\nGeeraerts (2003, Towards a pragmatic model of cognitive onomasiology. In Hubert\nCuyckens, Ren\\'e Dirven & John R. Taylor (eds.), Cognitive approaches to\nlexical semantics, 67-92. Berlin: De Gruyter Mouton). They hypothesized that\n\"[a] referent is more readily named by a lexical item if it is a salient member\nof the category denoted by that item\". To provide a preliminary investigation\nof this important but rarely explored phenomenon, a series of innovative\nmethods and procedures, including the use of semantic embedding and\ninterlingual comparisons, is designed. Specifically, potential NLSs are\nefficiently discovered through an automatic exploratory analysis using topic\nmodeling techniques, and then confirmed by manual inspection through frame\nsemantics. Finally, to account for the NLS in question, cluster analysis and\nbehavioral profile analysis are conducted to uncover a language-specific\nprototype for the Chinese verb shang 'harm', providing supporting evidence for\nthe correlation between NLS and prototypicality.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Huasheng Zhang"
        ],
        "published": "2024-05-22T10:55:26Z"
    },
    {
        "title": "ElastiBench: Scalable Continuous Benchmarking on Cloud FaaS Platforms",
        "link": "http://arxiv.org/abs/2405.13528v1",
        "abstract": "Running microbenchmark suites often and early in the development process\nenables developers to identify performance issues in their application.\nMicrobenchmark suites of complex applications can comprise hundreds of\nindividual benchmarks and take multiple hours to evaluate meaningfully, making\nrunning those benchmarks as part of CI/CD pipelines infeasible. In this paper,\nwe reduce the total execution time of microbenchmark suites by leveraging the\nmassive scalability and elasticity of FaaS (Function-as-a-Service) platforms.\nWhile using FaaS enables users to quickly scale up to thousands of parallel\nfunction instances to speed up microbenchmarking, the performance variation and\nlow control over the underlying computing resources complicate reliable\nbenchmarking. We demonstrate an architecture for executing microbenchmark\nsuites on cloud FaaS platforms and evaluate it on code changes from an\nopen-source time series database. Our evaluation shows that our prototype can\nproduce reliable results (~95% of performance changes accurately detected) in a\nquarter of the time (<=15min vs.~4h) and at lower cost ($0.49 vs. ~$1.18)\ncompared to cloud-based virtual machines.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Trever Schirmer",
            "Tobias Pfandzelter",
            "David Bermbach"
        ],
        "published": "2024-05-22T10:54:20Z"
    },
    {
        "title": "End-to-End Real-World Polyphonic Piano Audio-to-Score Transcription with\n  Hierarchical Decoding",
        "link": "http://arxiv.org/abs/2405.13527v1",
        "abstract": "Piano audio-to-score transcription (A2S) is an important yet underexplored\ntask with extensive applications for music composition, practice, and analysis.\nHowever, existing end-to-end piano A2S systems faced difficulties in retrieving\nbar-level information such as key and time signatures, and have been trained\nand evaluated with only synthetic data. To address these limitations, we\npropose a sequence-to-sequence (Seq2Seq) model with a hierarchical decoder that\naligns with the hierarchical structure of musical scores, enabling the\ntranscription of score information at both the bar and note levels by\nmulti-task learning. To bridge the gap between synthetic data and recordings of\nhuman performance, we propose a two-stage training scheme, which involves\npre-training the model using an expressive performance rendering (EPR) system\non synthetic audio, followed by fine-tuning the model using recordings of human\nperformance. To preserve the voicing structure for score reconstruction, we\npropose a pre-processing method for **Kern scores in scenarios with an\nunconstrained number of voices. Experimental results support the effectiveness\nof our proposed approaches, in terms of both transcription performance on\nsynthetic audio data in comparison to the current state-of-the-art, and the\nfirst experiment on human recordings.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "authors": [
            "Wei Zeng",
            "Xian He",
            "Ye Wang"
        ],
        "published": "2024-05-22T10:52:04Z"
    },
    {
        "title": "Understanding Virtual Nodes: Oversmoothing, Oversquashing, and Node\n  Heterogeneity",
        "link": "http://arxiv.org/abs/2405.13526v1",
        "abstract": "Message passing neural networks (MPNNs) have been shown to have limitations\nin terms of expressivity and modeling long-range interactions. Augmenting MPNNs\nwith a virtual node (VN) removes the locality constraint of the layer\naggregation and has been found to improve performance on a range of benchmarks.\nWe provide a comprehensive theoretical analysis of the role of VNs and benefits\nthereof, through the lenses of oversmoothing, oversquashing, and sensitivity\nanalysis. First, in contrast to prior belief, we find that VNs typically avoid\nreplicating anti-smoothing approaches to maintain expressive power. Second, we\ncharacterize, precisely, how the improvement afforded by VNs on the mixing\nabilities of the network and hence in mitigating oversquashing, depends on the\nunderlying topology. Finally, we highlight that, unlike Graph-Transformers\n(GT), classical instantiations of the VN are often constrained to assign\nuniform importance to different nodes. Consequently, we propose a variant of VN\nwith the same computational complexity, which can have different sensitivity to\nnodes based on the graph structure. We show that this is an extremely effective\nand computationally efficient baseline on graph-level tasks.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Joshua Southern",
            "Francesco Di Giovanni",
            "Michael Bronstein",
            "Johannes F. Lutzeyer"
        ],
        "published": "2024-05-22T10:51:12Z"
    },
    {
        "title": "Beyond Trend and Periodicity: Guiding Time Series Forecasting with\n  Textual Cues",
        "link": "http://arxiv.org/abs/2405.13522v2",
        "abstract": "This work introduces a novel Text-Guided Time Series Forecasting (TGTSF)\ntask. By integrating textual cues, such as channel descriptions and dynamic\nnews, TGTSF addresses the critical limitations of traditional methods that rely\npurely on historical data. To support this task, we propose TGForecaster, a\nrobust baseline model that fuses textual cues and time series data using\ncross-attention mechanisms. We then present four meticulously curated benchmark\ndatasets to validate the proposed framework, ranging from simple periodic data\nto complex, event-driven fluctuations. Our comprehensive evaluations\ndemonstrate that TGForecaster consistently achieves state-of-the-art\nperformance, highlighting the transformative potential of incorporating textual\ninformation into time series forecasting. This work not only pioneers a novel\nforecasting task but also establishes a new benchmark for future research,\ndriving advancements in multimodal data integration for time series models.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Zhijian Xu",
            "Yuxuan Bian",
            "Jianyuan Zhong",
            "Xiangyu Wen",
            "Qiang Xu"
        ],
        "published": "2024-05-22T10:45:50Z"
    },
    {
        "title": "Network Inpainting via Optimal Transport",
        "link": "http://arxiv.org/abs/2405.13520v1",
        "abstract": "In this work, we present a novel tool for reconstructing networks from\ncorrupted images. The reconstructed network is the result of a minimization\nproblem that has a misfit term with respect to the observed data, and a\nphysics-based regularizing term coming from the theory of optimal transport.\nThrough a range of numerical tests, we demonstrate that our suggested approach\ncan effectively rebuild the primary features of damaged networks, even when\nartifacts are present.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "math.OC",
            "49-04, 49K20, 49N99, 65N21, 65N30, 65Z05"
        ],
        "authors": [
            "Enrico Facca",
            "Jan Martin Nordbotten",
            "Erik Andreas Hanson"
        ],
        "published": "2024-05-22T10:33:09Z"
    },
    {
        "title": "PerSense: Personalized Instance Segmentation in Dense Images",
        "link": "http://arxiv.org/abs/2405.13518v1",
        "abstract": "Leveraging large-scale pre-training, vision foundational models showcase\nnotable performance benefits. While recent years have witnessed significant\nadvancements in segmentation algorithms, existing models still face challenges\nto automatically segment personalized instances in dense and crowded scenarios.\nThe primary factor behind this limitation stems from bounding box-based\ndetections, which are constrained by occlusions, background clutter, and object\norientation, particularly when dealing with dense images. To this end, we\npropose PerSense, an end-to-end, training-free, and model-agnostic one-shot\nframework to address the personalized instance segmentation in dense images.\nTowards developing this framework, we make following core contributions. (a) We\npropose an Instance Detection Module (IDM) and leverage a Vision-Language\nModel, a grounding object detector, and a few-shot object counter (FSOC) to\nrealize a new baseline. (b) To tackle false positives within candidate point\nprompts, we design Point Prompt Selection Module (PPSM). Both IDM and PPSM\ntransform density maps from FSOC into personalized instance-level point prompts\nfor segmentation and offer a seamless integration in our model-agnostic\nframework. (c) We introduce a feedback mechanism which enables PerSense to\nharness the full potential of FSOC by automating the exemplar selection\nprocess. (d) To promote algorithmic advances and effective tools for this\nrelatively underexplored task, we introduce PerSense-D, a dataset exclusive to\npersonalized instance segmentation in dense images. We validate the\neffectiveness of PerSense on the task of personalized instance segmentation in\ndense images on PerSense-D and comparison with SOTA. Additionally, our\nqualitative findings demonstrate the adaptability of our framework to images\ncaptured in-the-wild.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Muhammad Ibraheem Siddiqui",
            "Muhammad Umer Sheikh",
            "Hassan Abid",
            "Muhammad Haris Khan"
        ],
        "published": "2024-05-22T10:26:44Z"
    },
    {
        "title": "WaterPool: A Watermark Mitigating Trade-offs among Imperceptibility,\n  Efficacy and Robustness",
        "link": "http://arxiv.org/abs/2405.13517v1",
        "abstract": "With the increasing use of large language models (LLMs) in daily life,\nconcerns have emerged regarding their potential misuse and societal impact.\nWatermarking is proposed to trace the usage of specific models by injecting\npatterns into their generated texts. An ideal watermark should produce outputs\nthat are nearly indistinguishable from those of the original LLM\n(imperceptibility), while ensuring a high detection rate (efficacy), even when\nthe text is partially altered (robustness). Despite many methods having been\nproposed, none have simultaneously achieved all three properties, revealing an\ninherent trade-off. This paper utilizes a key-centered scheme to unify existing\nwatermarking techniques by decomposing a watermark into two distinct modules: a\nkey module and a mark module. Through this decomposition, we demonstrate for\nthe first time that the key module significantly contributes to the trade-off\nissues observed in prior methods. Specifically, this reflects the conflict\nbetween the scale of the key sampling space during generation and the\ncomplexity of key restoration during detection. To this end, we introduce\n\\textbf{WaterPool}, a simple yet effective key module that preserves a complete\nkey sampling space required by imperceptibility while utilizing semantics-based\nsearch to improve the key restoration process. WaterPool can integrate with\nmost watermarks, acting as a plug-in. Our experiments with three well-known\nwatermarking techniques show that WaterPool significantly enhances their\nperformance, achieving near-optimal imperceptibility and markedly improving\nefficacy and robustness (+12.73\\% for KGW, +20.27\\% for EXP, +7.27\\% for ITS).",
        "subjects": [
            "cs.CR",
            "cs.CL"
        ],
        "authors": [
            "Baizhou Huang",
            "Xiaojun Wan"
        ],
        "published": "2024-05-22T10:22:20Z"
    },
    {
        "title": "LIRE: listwise reward enhancement for preference alignment",
        "link": "http://arxiv.org/abs/2405.13516v1",
        "abstract": "Recently, tremendous strides have been made to align the generation of Large\nLanguage Models (LLMs) with human values to mitigate toxic or unhelpful\ncontent. Leveraging Reinforcement Learning from Human Feedback (RLHF) proves\neffective and is widely adopted by researchers. However, implementing RLHF is\ncomplex, and its sensitivity to hyperparameters renders achieving stable\nperformance and scalability challenging. Furthermore, prevailing approaches to\npreference alignment primarily concentrate on pairwise comparisons, with\nlimited exploration into multi-response scenarios, thereby overlooking the\npotential richness within the candidate pool. For the above reasons, we propose\na new approach: Listwise Reward Enhancement for Preference Alignment (LIRE), a\ngradient-based reward optimization approach that incorporates the offline\nrewards of multiple responses into a streamlined listwise framework, thus\neliminating the need for online sampling during training. LIRE is\nstraightforward to implement, requiring minimal parameter tuning, and\nseamlessly aligns with the pairwise paradigm while naturally extending to\nmulti-response scenarios. Moreover, we introduce a self-enhancement algorithm\naimed at iteratively refining the reward during training. Our experiments\ndemonstrate that LIRE consistently outperforms existing methods across several\nbenchmarks on dialogue and summarization tasks, with good transferability to\nout-of-distribution data, assessed using proxy reward models and human\nannotators.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Mingye Zhu",
            "Yi Liu",
            "Lei Zhang",
            "Junbo Guo",
            "Zhendong Mao"
        ],
        "published": "2024-05-22T10:21:50Z"
    },
    {
        "title": "Multi-Scale Feature Fusion Quantum Depthwise Convolutional Neural\n  Networks for Text Classification",
        "link": "http://arxiv.org/abs/2405.13515v1",
        "abstract": "In recent years, with the development of quantum machine learning, quantum\nneural networks (QNNs) have gained increasing attention in the field of natural\nlanguage processing (NLP) and have achieved a series of promising results.\nHowever, most existing QNN models focus on the architectures of quantum\nrecurrent neural network (QRNN) and self-attention mechanism (QSAM). In this\nwork, we propose a novel QNN model based on quantum convolution. We develop the\nquantum depthwise convolution that significantly reduces the number of\nparameters and lowers computational complexity. We also introduce the\nmulti-scale feature fusion mechanism to enhance model performance by\nintegrating word-level and sentence-level features. Additionally, we propose\nthe quantum word embedding and quantum sentence embedding, which provide\nembedding vectors more efficiently. Through experiments on two benchmark text\nclassification datasets, we demonstrate our model outperforms a wide range of\nstate-of-the-art QNN models. Notably, our model achieves a new state-of-the-art\ntest accuracy of 96.77% on the RP dataset. We also show the advantages of our\nquantum model over its classical counterparts in its ability to improve test\naccuracy using fewer parameters. Finally, an ablation test confirms the\neffectiveness of the multi-scale feature fusion mechanism and quantum depthwise\nconvolution in enhancing model performance.",
        "subjects": [
            "quant-ph",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Yixiong Chen",
            "Weichuan Fang"
        ],
        "published": "2024-05-22T10:19:34Z"
    },
    {
        "title": "Joint Optimization of Streaming and Non-Streaming Automatic Speech\n  Recognition with Multi-Decoder and Knowledge Distillation",
        "link": "http://arxiv.org/abs/2405.13514v1",
        "abstract": "End-to-end (E2E) automatic speech recognition (ASR) can operate in two modes:\nstreaming and non-streaming, each with its pros and cons. Streaming ASR\nprocesses the speech frames in real-time as it is being received, while\nnon-streaming ASR waits for the entire speech utterance; thus, professionals\nmay have to operate in either mode to satisfy their application. In this work,\nwe present joint optimization of streaming and non-streaming ASR based on\nmulti-decoder and knowledge distillation. Primarily, we study 1) the encoder\nintegration of these ASR modules, followed by 2) separate decoders to make the\nswitching mode flexible, and enhancing performance by 3) incorporating\nsimilarity-preserving knowledge distillation between the two modular encoders\nand decoders. Evaluation results show 2.6%-5.3% relative character error rate\nreductions (CERR) on CSJ for streaming ASR, and 8.3%-9.7% relative CERRs for\nnon-streaming ASR within a single model compared to multiple standalone\nmodules.",
        "subjects": [
            "eess.AS",
            "cs.CL",
            "cs.SD"
        ],
        "authors": [
            "Muhammad Shakeel",
            "Yui Sudo",
            "Yifan Peng",
            "Shinji Watanabe"
        ],
        "published": "2024-05-22T10:17:30Z"
    },
    {
        "title": "Coverage Path Planning for Thermal Interface Materials",
        "link": "http://arxiv.org/abs/2405.13512v1",
        "abstract": "Thermal management of power electronics and Electronic Control Units is\ncrucial in times of increasing power densities and limited assembly space.\nElectric and autonomous vehicles are a prominent application field. Thermal\nInterface Materials are used to transfer heat from a semiconductor to a\nheatsink. They are applied along a dispense path onto the semiconductor and\nspread over its entire surface once the heatsink is joined. To plan this\napplication path, design engineers typically perform an iterative\ntrial-and-error procedure of elaborate simulations and manual experiments. We\npropose a fully automated optimization approach, which clearly outperforms the\ncurrent manual path planning and respects all relevant manufacturing\nconstraints. An optimum dispense path increases the reliability of the thermal\ninterface and makes the manufacturing more sustainable by reducing material\nwaste. We show results on multiple real products from automotive series\nproduction, including an experimental validation on actual series manufacturing\nequipment.",
        "subjects": [
            "cs.SY",
            "cs.LG"
        ],
        "authors": [
            "Simon Baeuerle",
            "Andreas Steimer",
            "Ralf Mikut"
        ],
        "published": "2024-05-22T10:14:47Z"
    },
    {
        "title": "Latent Space Alignment for Semantic Channel Equalization",
        "link": "http://arxiv.org/abs/2405.13511v1",
        "abstract": "We relax the constraint of a shared language between agents in a semantic and\ngoal-oriented communication system to explore the effect of language mismatch\nin distributed task solving. We propose a mathematical framework, which\nprovides a modelling and a measure of the semantic distortion introduced in the\ncommunication when agents use distinct languages. We then propose a new\napproach to semantic channel equalization with proven effectiveness through\nnumerical evaluations.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Tom√°s Huttebraucker",
            "Mohamed Sana",
            "Emilio Calvanese Strinati"
        ],
        "published": "2024-05-22T10:12:32Z"
    },
    {
        "title": "Non-Deterministic Planning for Hyperproperty Verification",
        "link": "http://arxiv.org/abs/2405.13488v1",
        "abstract": "Non-deterministic planning aims to find a policy that achieves a given\nobjective in an environment where actions have uncertain effects, and the agent\n- potentially - only observes parts of the current state. Hyperproperties are\nproperties that relate multiple paths of a system and can, e.g., capture\nsecurity and information-flow policies. Popular logics for expressing temporal\nhyperproperties - such as HyperLTL - extend LTL by offering selective\nquantification over executions of a system. In this paper, we show that\nplanning offers a powerful intermediate language for the automated verification\nof hyperproperties. Concretely, we present an algorithm that, given a HyperLTL\nverification problem, constructs a non-deterministic multi-agent planning\ninstance (in the form of a QDec-POMDP) that, when admitting a plan, implies the\nsatisfaction of the verification problem. We show that for large fragments of\nHyperLTL, the resulting planning instance corresponds to a classical, FOND, or\nPOND planning problem. We implement our encoding in a prototype verification\ntool and report on encouraging experimental results.",
        "subjects": [
            "cs.LO",
            "cs.AI",
            "cs.FL"
        ],
        "authors": [
            "Raven Beutner",
            "Bernd Finkbeiner"
        ],
        "published": "2024-05-22T09:57:49Z"
    },
    {
        "title": "Generative AI: The power of the new education",
        "link": "http://arxiv.org/abs/2405.13487v1",
        "abstract": "The effective integration of generative artificial intelligence in education\nis a fundamental aspect to prepare future generations. This study proposes an\naccelerated learning methodology in artificial intelligence, focused on its\ngenerative capacity, as a way to achieve this goal. It recognizes the challenge\nof getting teachers to engage with new technologies and adapt their methods in\nall subjects, not just those related to AI. This methodology not only promotes\ninterest in science, technology, engineering and mathematics, but also\nfacilitates student understanding of the ethical uses and risks associated with\nAI. Students' perceptions of generative AI are examined, addressing their\nemotions towards its evolution, evaluation of its ethical implications, and\neveryday use of AI tools. In addition, AI applications commonly used by\nstudents and their integration into other disciplines are investigated. The\nstudy aims to provide educators with a deeper understanding of students'\nperceptions of AI and its relevance in society and in their future career\npaths.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.HC"
        ],
        "authors": [
            "Sergio Altares-L√≥pez",
            "Jos√© M. Bengochea-Guevara",
            "Carlos Ranz",
            "H√©ctor Montes",
            "Angela Ribeiro"
        ],
        "published": "2024-05-22T09:56:05Z"
    },
    {
        "title": "Distributed Indirect Source Coding with Decoder Side Information",
        "link": "http://arxiv.org/abs/2405.13483v1",
        "abstract": "This paper studies a variant of the rate-distortion problem motivated by\ntask-oriented semantic communication and distributed learning problems, where\n$M$ correlated sources are independently encoded for a central decoder. The\ndecoder has access to a correlated side information in addition to the messages\nreceived from the encoders, and aims to recover a latent random variable\ncorrelated with the sources observed by the encoders within a given distortion\nconstraint rather than recovering the sources themselves. We provide bounds on\nthe rate-distortion region for this scenario in general, and characterize the\nrate-distortion function exactly when the sources are conditionally independent\ngiven the side information.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Jiancheng Tang",
            "Qianqian Yang",
            "Deniz G√ºnd√ºz"
        ],
        "published": "2024-05-22T09:48:21Z"
    },
    {
        "title": "Continual Learning in Medical Imaging from Theory to Practice: A Survey\n  and Practical Analysis",
        "link": "http://arxiv.org/abs/2405.13482v1",
        "abstract": "Deep Learning has shown great success in reshaping medical imaging, yet it\nfaces numerous challenges hindering widespread application. Issues like\ncatastrophic forgetting and distribution shifts in the continuously evolving\ndata stream increase the gap between research and applications. Continual\nLearning offers promise in addressing these hurdles by enabling the sequential\nacquisition of new knowledge without forgetting previous learnings in neural\nnetworks. In this survey, we comprehensively review the recent literature on\ncontinual learning in the medical domain, highlight recent trends, and point\nout the practical issues. Specifically, we survey the continual learning\nstudies on classification, segmentation, detection, and other tasks in the\nmedical domain. Furthermore, we develop a taxonomy for the reviewed studies,\nidentify the challenges, and provide insights to overcome them. We also\ncritically discuss the current state of continual learning in medical imaging,\nincluding identifying open problems and outlining promising future directions.\nWe hope this survey will provide researchers with a useful overview of the\ndevelopments in the field and will further increase interest in the community.\nTo keep up with the fast-paced advancements in this field, we plan to routinely\nupdate the repository with the latest relevant papers at\nhttps://github.com/BioMedIA-MBZUAI/awesome-cl-in-medical .",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Mohammad Areeb Qazi",
            "Anees Ur Rehman Hashmi",
            "Santosh Sanjeev",
            "Ibrahim Almakky",
            "Numan Saeed",
            "Mohammad Yaqub"
        ],
        "published": "2024-05-22T09:48:04Z"
    },
    {
        "title": "Locally Private Estimation with Public Features",
        "link": "http://arxiv.org/abs/2405.13481v1",
        "abstract": "We initiate the study of locally differentially private (LDP) learning with\npublic features. We define semi-feature LDP, where some features are publicly\navailable while the remaining ones, along with the label, require protection\nunder local differential privacy. Under semi-feature LDP, we demonstrate that\nthe mini-max convergence rate for non-parametric regression is significantly\nreduced compared to that of classical LDP. Then we propose HistOfTree, an\nestimator that fully leverages the information contained in both public and\nprivate features. Theoretically, HistOfTree reaches the mini-max optimal\nconvergence rate. Empirically, HistOfTree achieves superior performance on both\nsynthetic and real data. We also explore scenarios where users have the\nflexibility to select features for protection manually. In such cases, we\npropose an estimator and a data-driven parameter tuning strategy, leading to\nanalogous theoretical and empirical results.",
        "subjects": [
            "stat.ML",
            "cs.CR",
            "cs.LG"
        ],
        "authors": [
            "Yuheng Ma",
            "Ke Jia",
            "Hanfang Yang"
        ],
        "published": "2024-05-22T09:47:54Z"
    },
    {
        "title": "What is a typical signalized intersection in a city? A pipeline for\n  intersection data imputation from OpenStreetMap",
        "link": "http://arxiv.org/abs/2405.13480v1",
        "abstract": "Signalized intersections, arguably the most complicated type of traffic\nscenario, are essential to urban mobility systems. With recent advancements in\nintelligent transportation technologies, signalized intersections have great\nprospects for making transportation greener, safer, and faster. Several studies\nhave been conducted focusing on intersection-level control and optimization.\nHowever, arbitrarily structured signalized intersections that are often used do\nnot represent the ground-truth distribution, and there is no standardized way\nthat exists to extract information about real-world signalized intersections.\nAs the largest open-source map in the world, OpenStreetMap (OSM) has been used\nby many transportation researchers for a variety of studies, including\nintersection-level research such as adaptive traffic signal control and\neco-driving. However, the quality of OSM data has been a serious concern.\n  In this paper, we propose a pipeline for effectively extracting information\nabout signalized intersections from OSM and constructing a comprehensive\ndataset. We thoroughly discuss challenges related to this task and we propose\nour solution for each challenge. We also use Salt Lake City as an example to\ndemonstrate the performance of our methods. The pipeline has been published as\nan open-source Python library so everyone can freely download and use it to\nfacilitate their research. Hopefully, this paper can serve as a starting point\nthat inspires more efforts to build a standardized and systematic data pipeline\nfor various types of transportation problems.",
        "subjects": [
            "physics.soc-ph",
            "cs.CY"
        ],
        "authors": [
            "Ao Qu",
            "Anirudh Valiveru",
            "Catherine Tang",
            "Vindula Jayawardana",
            "Baptiste Freydt",
            "Cathy Wu"
        ],
        "published": "2024-05-22T09:47:44Z"
    },
    {
        "title": "A Near-Real-Time Processing Ego Speech Filtering Pipeline Designed for\n  Speech Interruption During Human-Robot Interaction",
        "link": "http://arxiv.org/abs/2405.13477v1",
        "abstract": "With current state-of-the-art automatic speech recognition (ASR) systems, it\nis not possible to transcribe overlapping speech audio streams separately.\nConsequently, when these ASR systems are used as part of a social robot like\nPepper for interaction with a human, it is common practice to close the robot's\nmicrophone while it is talking itself. This prevents the human users to\ninterrupt the robot, which limits speech-based human-robot interaction. To\nenable a more natural interaction which allows for such interruptions, we\npropose an audio processing pipeline for filtering out robot's ego speech using\nonly a single-channel microphone. This pipeline takes advantage of the\npossibility to feed the robot ego speech signal, generated by a text-to-speech\nAPI, as training data into a machine learning model. The proposed pipeline\ncombines a convolutional neural network and spectral subtraction to extract\noverlapping human speech from the audio recorded by the robot-embedded\nmicrophone. When evaluating on a held-out test set, we find that this pipeline\noutperforms our previous approach to this task, as well as state-of-the-art\ntarget speech extraction systems that were retrained on the same dataset. We\nhave also integrated the proposed pipeline into a lightweight robot software\ndevelopment framework to make it available for broader use. As a step towards\ndemonstrating the feasibility of deploying our pipeline, we use this framework\nto evaluate the effectiveness of the pipeline in a small lab-based feasibility\npilot using the social robot Pepper. Our results show that when participants\ninterrupt the robot, the pipeline can extract the participant's speech from\none-second streaming audio buffers received by the robot-embedded\nsingle-channel microphone, hence in near-real time.",
        "subjects": [
            "cs.HC",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Yue Li",
            "Florian A. Kunneman",
            "Koen V. Hindriks"
        ],
        "published": "2024-05-22T09:39:09Z"
    },
    {
        "title": "Restricting Voltage Deviation of DC Microgrids with Critical and\n  Ordinary Nodes",
        "link": "http://arxiv.org/abs/2405.13476v1",
        "abstract": "Restricting bus voltage deviation is crucial for normal operation of\nmulti-bus DC microgrids, yet it has received insufficient attention due to the\nconflict between two main control objectives in DC microgrids, i.e., voltage\nregulation and current sharing. By revealing a necessary and sufficient\ncondition for achieving these two objectives, this paper proposes a compromised\ndistributed control algorithm, which regulates the voltage deviation of all\nbuses by relaxing the accuracy of current sharing. Moreover, for a class of DC\nMicrogrids consisting of both critical nodes and ordinary nodes, this paper\nproposes a distributed control algorithm that restricts the voltage deviation\nof critical nodes and simultaneously keeps the current sharing of ordinary\nnodes. This algorithm also works under plug-and-play settings. Simulations\nillustrate our theory.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Handong Bai",
            "Peng Li",
            "Hongwei Zhang"
        ],
        "published": "2024-05-22T09:36:52Z"
    },
    {
        "title": "Why do explanations fail? A typology and discussion on failures in XAI",
        "link": "http://arxiv.org/abs/2405.13474v1",
        "abstract": "As Machine Learning (ML) models achieve unprecedented levels of performance,\nthe XAI domain aims at making these models understandable by presenting\nend-users with intelligible explanations. Yet, some existing XAI approaches\nfail to meet expectations: several issues have been reported in the literature,\ngenerally pointing out either technical limitations or misinterpretations by\nusers. In this paper, we argue that the resulting harms arise from a complex\noverlap of multiple failures in XAI, which existing ad-hoc studies fail to\ncapture. This work therefore advocates for a holistic perspective, presenting a\nsystematic investigation of limitations of current XAI methods and their impact\non the interpretation of explanations. By distinguishing between\nsystem-specific and user-specific failures, we propose a typological framework\nthat helps revealing the nuanced complexities of explanation failures.\nLeveraging this typology, we also discuss some research directions to help AI\npractitioners better understand the limitations of XAI systems and enhance the\nquality of ML explanations.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.HC"
        ],
        "authors": [
            "Clara Bove",
            "Thibault Laugel",
            "Marie-Jeanne Lesot",
            "Charles Tijus",
            "Marcin Detyniecki"
        ],
        "published": "2024-05-22T09:32:24Z"
    },
    {
        "title": "Class-Conditional self-reward mechanism for improved Text-to-Image\n  models",
        "link": "http://arxiv.org/abs/2405.13473v1",
        "abstract": "Self-rewarding have emerged recently as a powerful tool in the field of\nNatural Language Processing (NLP), allowing language models to generate\nhigh-quality relevant responses by providing their own rewards during training.\nThis innovative technique addresses the limitations of other methods that rely\non human preferences. In this paper, we build upon the concept of\nself-rewarding models and introduce its vision equivalent for Text-to-Image\ngenerative AI models. This approach works by fine-tuning diffusion model on a\nself-generated self-judged dataset, making the fine-tuning more automated and\nwith better data quality. The proposed mechanism makes use of other pre-trained\nmodels such as vocabulary based-object detection, image captioning and is\nconditioned by the a set of object for which the user might need to improve\ngenerated data quality. The approach has been implemented, fine-tuned and\nevaluated on stable diffusion and has led to a performance that has been\nevaluated to be at least 60\\% better than existing commercial and research\nText-to-image models. Additionally, the built self-rewarding mechanism allowed\na fully automated generation of images, while increasing the visual quality of\nthe generated images and also more efficient following of prompt instructions.\nThe code used in this work is freely available on\nhttps://github.com/safouaneelg/SRT2I.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Safouane El Ghazouali",
            "Arnaud Gucciardi",
            "Umberto Michelucci"
        ],
        "published": "2024-05-22T09:28:43Z"
    },
    {
        "title": "Machine learning for exoplanet detection in high-contrast spectroscopy\n  Combining cross correlation maps and deep learning on medium-resolution\n  integral-field spectra",
        "link": "http://arxiv.org/abs/2405.13468v1",
        "abstract": "The advent of high-contrast imaging instruments combined with\nmedium-resolution spectrographs allows spectral and temporal dimensions to be\ncombined with spatial dimensions to detect and potentially characterize\nexoplanets with higher sensitivity. We develop a new method to effectively\nleverage the spectral and spatial dimensions in integral-field spectroscopy\n(IFS) datasets using a supervised deep-learning algorithm to improve the\ndetection sensitivity to high-contrast exoplanets. We begin by applying a data\ntransform whereby the IFS datasets are replaced by cross-correlation\ncoefficient tensors obtained by cross-correlating our data with young gas giant\nspectral template spectra. This transformed data is then used to train machine\nlearning (ML) algorithms. We train a 2D CNN and 3D LSTM with our data. We\ncompare the ML models with a non-ML algorithm, based on the STIM map of\narXiv:1810.06895. We test our algorithms on simulated young gas giants in a\ndataset that contains no known exoplanet, and explore the sensitivity of\nalgorithms to detect these exoplanets at contrasts ranging from 1e-3 to 1e-4 at\ndifferent radial separations. We quantify the sensitivity using modified\nreceiver operating characteristic curves (mROC). We discover that the ML\nalgorithms produce fewer false positives and have a higher true positive rate\nthan the STIM-based algorithm, and the true positive rate of ML algorithms is\nless impacted by changing radial separation. We discover that the velocity\ndimension is an important differentiating factor. Through this paper, we\ndemonstrate that ML techniques have the potential to improve the detection\nlimits and reduce false positives for directly imaged planets in IFS datasets,\nafter transforming the spectral dimension into a radial velocity dimension\nthrough a cross-correlation operation.",
        "subjects": [
            "astro-ph.EP",
            "astro-ph.IM",
            "cs.LG",
            "physics.app-ph",
            "physics.data-an"
        ],
        "authors": [
            "Rakesh Nath-Ranga",
            "Olivier Absil",
            "Valentin Christiaens",
            "Emily O. Garvin"
        ],
        "published": "2024-05-22T09:25:58Z"
    },
    {
        "title": "Machine Learning for Exoplanet Detection in High-Contrast Spectroscopy:\n  Revealing Exoplanets by Leveraging Hidden Molecular Signatures in\n  Cross-Correlated Spectra with Convolutional Neural Networks",
        "link": "http://arxiv.org/abs/2405.13469v1",
        "abstract": "The new generation of observatories and instruments (VLT/ERIS, JWST, ELT)\nmotivate the development of robust methods to detect and characterise faint and\nclose-in exoplanets. Molecular mapping and cross-correlation for spectroscopy\nuse molecular templates to isolate a planet's spectrum from its host star.\nHowever, reliance on signal-to-noise ratio (S/N) metrics can lead to missed\ndiscoveries, due to strong assumptions of Gaussian independent and identically\ndistributed noise. We introduce machine learning for cross-correlation\nspectroscopy (MLCCS); the method aims to leverage weak assumptions on exoplanet\ncharacterisation, such as the presence of specific molecules in atmospheres, to\nimprove detection sensitivity for exoplanets. MLCCS methods, including a\nperceptron and unidimensional convolutional neural networks, operate in the\ncross-correlated spectral dimension, in which patterns from molecules can be\nidentified. We test on mock datasets of synthetic planets inserted into real\nnoise from SINFONI at K-band. The results from MLCCS show outstanding\nimprovements. The outcome on a grid of faint synthetic gas giants shows that\nfor a false discovery rate up to 5%, a perceptron can detect about 26 times the\namount of planets compared to an S/N metric. This factor increases up to 77\ntimes with convolutional neural networks, with a statistical sensitivity shift\nfrom 0.7% to 55.5%. In addition, MLCCS methods show a drastic improvement in\ndetection confidence and conspicuity on imaging spectroscopy. Once trained,\nMLCCS methods offer sensitive and rapid detection of exoplanets and their\nmolecular species in the spectral dimension. They handle systematic noise and\nchallenging seeing conditions, can adapt to many spectroscopic instruments and\nmodes, and are versatile regarding atmospheric characteristics, which can\nenable identification of various planets in archival and future data.",
        "subjects": [
            "astro-ph.EP",
            "astro-ph.IM",
            "cs.LG",
            "stat.AP"
        ],
        "authors": [
            "Emily O. Garvin",
            "Markus J. Bonse",
            "Jean Hayoz",
            "Gabriele Cugno",
            "Jonas Spiller",
            "Polychronis A. Patapis",
            "Dominique Petit Dit de la Roche",
            "Rakesh Nath-Ranga",
            "Olivier Absil",
            "Nicolai F. Meinshausen",
            "Sascha P. Quanz"
        ],
        "published": "2024-05-22T09:25:58Z"
    },
    {
        "title": "AdaFedFR: Federated Face Recognition with Adaptive Inter-Class\n  Representation Learning",
        "link": "http://arxiv.org/abs/2405.13467v1",
        "abstract": "With the growing attention on data privacy and communication security in face\nrecognition applications, federated learning has been introduced to learn a\nface recognition model with decentralized datasets in a privacy-preserving\nmanner. However, existing works still face challenges such as unsatisfying\nperformance and additional communication costs, limiting their applicability in\nreal-world scenarios. In this paper, we propose a simple yet effective\nfederated face recognition framework called AdaFedFR, by devising an adaptive\ninter-class representation learning algorithm to enhance the generalization of\nthe generic face model and the efficiency of federated training under strict\nprivacy-preservation. In particular, our work delicately utilizes feature\nrepresentations of public identities as learnable negative knowledge to\noptimize the local objective within the feature space, which further encourages\nthe local model to learn powerful representations and optimize personalized\nmodels for clients. Experimental results demonstrate that our method\noutperforms previous approaches on several prevalent face recognition\nbenchmarks within less than 3 communication rounds, which shows\ncommunication-friendly and great efficiency.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Di Qiu",
            "Xinyang Lin",
            "Kaiye Wang",
            "Xiangxiang Chu",
            "Pengfei Yan"
        ],
        "published": "2024-05-22T09:19:25Z"
    },
    {
        "title": "Designing for Rich Collocated Social Interactions in the Age of\n  Smartphones",
        "link": "http://arxiv.org/abs/2405.13465v1",
        "abstract": "The quality of social interaction is crucial for psychological and\nphysiological health. Previous research shows that smartphones can negatively\nimpact face-to-face social interactions. Many HCI studies have addressed this\nby limiting smartphone use during social interactions. While these studies show\na decrease in smartphone use, restrictive approaches have their drawbacks.\nUsers need high levels of self-regulation to follow them, and they may cause\nunintended effects like withdrawal symptoms. Given the impact of smartphones on\nsocial interactions, both positive and negative, new solutions are needed to\nreduce the negative effects of excessive smartphone use without resorting to\nrestrictive methods. This thesis aims to explore smartphone use behavior in the\ncontext of social interactions and relationships using various data collection\ntechniques to understand how this behavior hinders and supports social\ninteractions. We began with in situ observations and focus group sessions.\nBased on insights from these steps, we developed two research prototypes to\nimprove social interactions without restricting smartphone use. We gathered\nuser feedback, reactions, and concerns about these prototypes through user\nstudies. Finally, we evaluated how these prototypes affected conversation\nquality in social interactions through an experimental user study. This thesis\ncontributes to the field of digital well-being by offering user insights,\ndesign implications, and approaches that can guide the creation of solutions to\nenhance social interactions in the presence of smartphones.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "H√ºseyin Uƒüur Gen√ß"
        ],
        "published": "2024-05-22T09:17:01Z"
    },
    {
        "title": "Blockchain and Artificial Intelligence: Synergies and Conflicts",
        "link": "http://arxiv.org/abs/2405.13462v1",
        "abstract": "Blockchain technology and Artificial Intelligence (AI) have emerged as\ntransformative forces in their respective domains. This paper explores\nsynergies and challenges between these two technologies. Our research analyses\nthe biggest projects combining blockchain and AI, based on market\ncapitalization, and derives a novel framework to categorize contemporary and\nfuture use cases. Despite the theoretical compatibility, current real-world\napplications combining blockchain and AI remain in their infancy.",
        "subjects": [
            "cs.AI",
            "cs.CY"
        ],
        "authors": [
            "Leon Witt",
            "Armando Teles Fortes",
            "Kentaroh Toyoda",
            "Wojciech Samek",
            "Dan Li"
        ],
        "published": "2024-05-22T09:04:52Z"
    },
    {
        "title": "Analogical proportions II",
        "link": "http://arxiv.org/abs/2405.13461v1",
        "abstract": "Analogical reasoning is the ability to detect parallels between two seemingly\ndistant objects or situations, a fundamental human capacity used for example in\ncommonsense reasoning, learning, and creativity which is believed by many\nresearchers to be at the core of human and artificial general intelligence.\nAnalogical proportions are expressions of the form ``$a$ is to $b$ what $c$ is\nto $d$'' at the core of analogical reasoning. The author has recently\nintroduced an abstract algebraic framework of analogical proportions within the\ngeneral setting of universal algebra. It is the purpose of this paper to\nfurther develop the mathematical theory of analogical proportions within that\nframework as motivated by the fact that it has already been successfully\napplied to logic program synthesis in artificial intelligence.",
        "subjects": [
            "cs.LO",
            "cs.AI",
            "cs.DM",
            "math.LO"
        ],
        "authors": [
            "Christian Antiƒá"
        ],
        "published": "2024-05-22T09:02:12Z"
    },
    {
        "title": "Adapting Multi-modal Large Language Model to Concept Drift in the\n  Long-tailed Open World",
        "link": "http://arxiv.org/abs/2405.13459v1",
        "abstract": "Real-world data often exhibit extreme imbalances and out-of-distribution\n(OOD) instances, which significantly biases the model training. While it has\nbeen extensively studied in vision and language domains separately, the impact\nof long-tailed open worlds on multi-modal large language models (MLLMs) has\nbeen largely overlooked. In this paper, we first demonstrate the susceptibility\nand vulnerability of vision-language models to significant biases caused by\ntail drift and out-of-distribution (OOD) drift during both the pre-training and\nfine-tuning stages. To eliminate the bias from different sources, we integrate\nthe tailed drift adaptation and OOD drift detection into a unified framework by\nextending the concept drift theory to multi-modal. Specifically, a\nT-distribution-based drift adapter is proposed to effectively mitigate the bias\ninduced by the long-tailed problem, which also facilitates the model in\ndistinguishing OOD data through explicit distribution modelling. Extensive\nexperiments show significant improvements in our model's ability to adapt to\ntailed drift and OOD drift. Moreover, it enhances the efficiency and accuracy\nof image-text alignment in vision language model pre-training, particularly in\nthe long-tail open world scenario. Furthermore, we create a set of multi-modal\ndatasets called OpenMMlo, specifically tailored for the long-tailed open world\nscenario, to validate our findings. To foster the development of the\nmulti-modal community, we have made both OpenMMlo datasets and our code\npublicly available at: https://github.com/Anonymous0Knight/ConceptDriftMLLMs.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xiaoyu Yang",
            "Jie Lu",
            "En Yu"
        ],
        "published": "2024-05-22T09:01:56Z"
    },
    {
        "title": "New Tight Wavelet Frame Constructions Sharing Responsibility",
        "link": "http://arxiv.org/abs/2405.13458v1",
        "abstract": "Tight wavelet frames (TWFs) in $L^2(\\mathbb{R}^n)$ are versatile and\npractical structures that provide the perfect reconstruction property.\nNevertheless, existing TWF construction methods exhibit limitations, including\na lack of specific methods for generating mother wavelets in extension-based\nconstruction, and the necessity to address the sum of squares (SOS) problem\neven when specific methods for generating mother wavelets are provided in\nSOS-based construction. It is a common practice for current TWF constructions\nto begin with a given refinable function. However, this approach places the\nentire burden on finding suitable mother wavelets. In this paper, we introduce\nTWF construction methods that spread the burden between both types of\nfunctions: refinable functions and mother wavelets. These construction methods\noffer an alternative approach to circumvent the SOS problem while providing\nspecific techniques for generating mother wavelets. We present examples to\nillustrate our construction methods.",
        "subjects": [
            "math.FA",
            "cs.NA",
            "math.NA",
            "42C40, 42C15"
        ],
        "authors": [
            "Youngmi Hur",
            "Hyojae Lim"
        ],
        "published": "2024-05-22T09:00:55Z"
    },
    {
        "title": "Deep linear networks for regression are implicitly regularized towards\n  flat minima",
        "link": "http://arxiv.org/abs/2405.13456v1",
        "abstract": "The largest eigenvalue of the Hessian, or sharpness, of neural networks is a\nkey quantity to understand their optimization dynamics. In this paper, we study\nthe sharpness of deep linear networks for overdetermined univariate regression.\nMinimizers can have arbitrarily large sharpness, but not an arbitrarily small\none. Indeed, we show a lower bound on the sharpness of minimizers, which grows\nlinearly with depth. We then study the properties of the minimizer found by\ngradient flow, which is the limit of gradient descent with vanishing learning\nrate. We show an implicit regularization towards flat minima: the sharpness of\nthe minimizer is no more than a constant times the lower bound. The constant\ndepends on the condition number of the data covariance matrix, but not on width\nor depth. This result is proven both for a small-scale initialization and a\nresidual initialization. Results of independent interest are shown in both\ncases. For small-scale initialization, we show that the learned weight matrices\nare approximately rank-one and that their singular vectors align. For residual\ninitialization, convergence of the gradient flow for a Gaussian initialization\nof the residual network is proven. Numerical experiments illustrate our results\nand connect them to gradient descent with non-vanishing learning rate.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Pierre Marion",
            "L√©na√Øc Chizat"
        ],
        "published": "2024-05-22T08:58:51Z"
    },
    {
        "title": "A Huber Loss Minimization Approach to Mean Estimation under User-level\n  Differential Privacy",
        "link": "http://arxiv.org/abs/2405.13453v1",
        "abstract": "Privacy protection of users' entire contribution of samples is important in\ndistributed systems. The most effective approach is the two-stage scheme, which\nfinds a small interval first and then gets a refined estimate by clipping\nsamples into the interval. However, the clipping operation induces bias, which\nis serious if the sample distribution is heavy-tailed. Besides, users with\nlarge local sample sizes can make the sensitivity much larger, thus the method\nis not suitable for imbalanced users. Motivated by these challenges, we propose\na Huber loss minimization approach to mean estimation under user-level\ndifferential privacy. The connecting points of Huber loss can be adaptively\nadjusted to deal with imbalanced users. Moreover, it avoids the clipping\noperation, thus significantly reducing the bias compared with the two-stage\napproach. We provide a theoretical analysis of our approach, which gives the\nnoise strength needed for privacy protection, as well as the bound of mean\nsquared error. The result shows that the new method is much less sensitive to\nthe imbalance of user-wise sample sizes and the tail of sample distributions.\nFinally, we perform numerical experiments to validate our theoretical analysis.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "authors": [
            "Puning Zhao",
            "Lifeng Lai",
            "Li Shen",
            "Qingming Li",
            "Jiafei Wu",
            "Zhe Liu"
        ],
        "published": "2024-05-22T08:46:45Z"
    },
    {
        "title": "A Label Propagation Strategy for CutMix in Multi-Label Remote Sensing\n  Image Classification",
        "link": "http://arxiv.org/abs/2405.13451v1",
        "abstract": "The development of supervised deep learning-based methods for multi-label\nscene classification (MLC) is one of the prominent research directions in\nremote sensing (RS). Yet, collecting annotations for large RS image archives is\ntime-consuming and costly. To address this issue, several data augmentation\nmethods have been introduced in RS. Among others, the data augmentation\ntechnique CutMix, which combines parts of two existing training images to\ngenerate an augmented image, stands out as a particularly effective approach.\nHowever, the direct application of CutMix in RS MLC can lead to the erasure or\naddition of class labels (i.e., label noise) in the augmented (i.e., combined)\ntraining image. To address this problem, we introduce a label propagation (LP)\nstrategy that allows the effective application of CutMix in the context of MLC\nproblems in RS without being affected by label noise. To this end, our proposed\nLP strategy exploits pixel-level class positional information to update the\nmulti-label of the augmented training image. We propose to access such class\npositional information from reference maps associated to each training image\n(e.g., thematic products) or from class explanation masks provided by an\nexplanation method if no reference maps are available. Similarly to pairing two\ntraining images, our LP strategy carries out a pairing operation on the\nassociated pixel-level class positional information to derive the updated\nmulti-label for the augmented image. Experimental results show the\neffectiveness of our LP strategy in general and its robustness in the case of\nvarious simulated and real scenarios with noisy class positional information in\nparticular.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Tom Burgert",
            "Tim Siebert",
            "Kai Norman Clasen",
            "Beg√ºm Demir"
        ],
        "published": "2024-05-22T08:45:03Z"
    },
    {
        "title": "Cascading-Tree Algorithm for the 0-1 Knapsack Problem (In Memory of\n  Heiner M{√º}ller-Merbach, a Former President of IFORS)",
        "link": "http://arxiv.org/abs/2405.13450v1",
        "abstract": "In operations research, the Knapsack Problem (KP) is one of the classical\noptimization problems that has been widely studied. The KP has several variants\nand, in this paper, we address the binary KP, where for a given knapsack (with\nlimited capacity) as well as a number of items, each of them has its own weight\n(volume or cost) and value, the objective consists in finding a selection of\nitems such that the total value of the selected items is maximized and the\ncapacity limit of the knapsack is respected. In this paper, in memorial of\nProf. Dr. Heiner M{\\\"u}ller-Merbach, a former president of IFORS, we address\nthe binary KP and revisit a classical algorithm, named cascading-tree\nbranch-and-bound algorithm, that was originally introduced by him in 1978.\nHowever, the algorithm is surprisingly absent from the scientific literature\nbecause the paper was published in a German journal. We carried out\ncomputational experiments in order to compare the algorithm versus some classic\nmethods. The numerical results show the effectiveness of the interesting idea\nused in the cascading-tree algorithm.",
        "subjects": [
            "cs.DS",
            "math.OC"
        ],
        "authors": [
            "Mahdi Moeini",
            "Daniel Schermer",
            "Oliver Wendt"
        ],
        "published": "2024-05-22T08:41:36Z"
    },
    {
        "title": "Input Guided Multiple Deconstruction Single Reconstruction neural\n  network models for Matrix Factorization",
        "link": "http://arxiv.org/abs/2405.13449v1",
        "abstract": "Referring back to the original text in the course of hierarchical learning is\na common human trait that ensures the right direction of learning. The models\ndeveloped based on the concept of Non-negative Matrix Factorization (NMF), in\nthis paper are inspired by this idea. They aim to deal with high-dimensional\ndata by discovering its low rank approximation by determining a unique pair of\nfactor matrices. The model, named Input Guided Multiple Deconstruction Single\nReconstruction neural network for Non-negative Matrix Factorization\n(IG-MDSR-NMF), ensures the non-negativity constraints of both factors. Whereas\nInput Guided Multiple Deconstruction Single Reconstruction neural network for\nRelaxed Non-negative Matrix Factorization (IG-MDSR-RNMF) introduces a novel\nidea of factorization with only the basis matrix adhering to the non-negativity\ncriteria. This relaxed version helps the model to learn more enriched low\ndimensional embedding of the original data matrix. The competency of preserving\nthe local structure of data in its low rank embedding produced by both the\nmodels has been appropriately verified. The superiority of low dimensional\nembedding over that of the original data justifying the need for dimension\nreduction has been established. The primacy of both the models has also been\nvalidated by comparing their performances separately with that of nine other\nestablished dimension reduction algorithms on five popular datasets. Moreover,\ncomputational complexity of the models and convergence analysis have also been\npresented testifying to the supremacy of the models.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Prasun Dutta",
            "Rajat K. De"
        ],
        "published": "2024-05-22T08:41:32Z"
    },
    {
        "title": "Distilling Instruction-following Abilities of Large Language Models with\n  Task-aware Curriculum Planning",
        "link": "http://arxiv.org/abs/2405.13448v1",
        "abstract": "The process of instruction tuning aligns pre-trained large language models\n(LLMs) with open-domain instructions and human-preferred responses. While\nseveral studies have explored autonomous approaches to distilling and\nannotating instructions from more powerful proprietary LLMs, such as ChatGPT,\nthey often neglect the impact of task distributions and the varying difficulty\nof instructions of the training sets. This oversight can lead to imbalanced\nknowledge capabilities and poor generalization powers of small student LLMs. To\naddress this challenge, we introduce Task-Aware Curriculum Planning for\nInstruction Refinement (TAPIR), a multi-round distillation framework with\nbalanced task distributions and dynamic difficulty adjustment. This approach\nutilizes an oracle LLM to select instructions that are difficult for a student\nLLM to follow and distill instructions with balanced task distributions. By\nincorporating curriculum planning, our approach systematically escalates the\ndifficulty levels, progressively enhancing the student LLM's capabilities. We\nrigorously evaluate TAPIR using two widely recognized benchmarks, including\nAlpacaEval 2.0 and MT-Bench. The empirical results demonstrate that the student\nLLMs, trained with our method and less training data, outperform larger\ninstruction-tuned models and strong distillation baselines. The improvement is\nparticularly notable in complex tasks, such as logical reasoning and code\ngeneration.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yuanhao Yue",
            "Chengyu Wang",
            "Jun Huang",
            "Peng Wang"
        ],
        "published": "2024-05-22T08:38:26Z"
    },
    {
        "title": "Task-agnostic Decision Transformer for Multi-type Agent Control with\n  Federated Split Training",
        "link": "http://arxiv.org/abs/2405.13445v1",
        "abstract": "With the rapid advancements in artificial intelligence, the development of\nknowledgeable and personalized agents has become increasingly prevalent.\nHowever, the inherent variability in state variables and action spaces among\npersonalized agents poses significant aggregation challenges for traditional\nfederated learning algorithms. To tackle these challenges, we introduce the\nFederated Split Decision Transformer (FSDT), an innovative framework designed\nexplicitly for AI agent decision tasks. The FSDT framework excels at navigating\nthe intricacies of personalized agents by harnessing distributed data for\ntraining while preserving data privacy. It employs a two-stage training\nprocess, with local embedding and prediction models on client agents and a\nglobal transformer decoder model on the server. Our comprehensive evaluation\nusing the benchmark D4RL dataset highlights the superior performance of our\nalgorithm in federated split learning for personalized agents, coupled with\nsignificant reductions in communication and computational overhead compared to\ntraditional centralized training approaches. The FSDT framework demonstrates\nstrong potential for enabling efficient and privacy-preserving collaborative\nlearning in applications such as autonomous driving decision systems. Our\nfindings underscore the efficacy of the FSDT framework in effectively\nleveraging distributed offline reinforcement learning data to enable powerful\nmulti-type agent decision systems.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Zhiyuan Wang",
            "Bokui Chen",
            "Xiaoyang Qu",
            "Zhenhou Hong",
            "Jing Xiao",
            "Jianzong Wang"
        ],
        "published": "2024-05-22T08:37:37Z"
    },
    {
        "title": "An all Mach number semi-implicit hybrid Finite Volume/Virtual Element\n  method for compressible viscous flows on Voronoi meshes",
        "link": "http://arxiv.org/abs/2405.13441v1",
        "abstract": "We present a novel high order semi-implicit hybrid finite volume/virtual\nelement numerical scheme for the solution of compressible flows on Voronoi\ntessellations. The method relies on the flux splitting of the compressible\nNavier-Stokes equations into three sub-systems: a convective sub-system solved\nexplicitly using a finite volume (FV) scheme, and the viscous and pressure\nsub-systems which are discretized implicitly at the aid of a virtual element\nmethod (VEM). Consequently, the time step restriction of the overall algorithm\ndepends only on the mean flow velocity and not on the fast pressure waves nor\non the viscous eigenvalues. As such, the proposed methodology is well suited\nfor the solution of low Mach number flows at all Reynolds numbers. Moreover,\nthe scheme is proven to be globally energy conserving so that shock capturing\nproperties are retrieved in high Mach number flows. To reach high order of\naccuracy in time and space, an IMEX Runge-Kutta time stepping strategy is\nemployed together with high order spatial reconstructions in terms of CWENO\npolynomials and virtual element space basis functions. The chosen\ndiscretization techniques allow the use of general polygonal grids, a useful\ntool when dealing with complex domain configurations. The new scheme is\ncarefully validated in both the incompressible limit and the high Mach number\nregime through a large set of classical benchmarks for fluid dynamics,\nassessing robustness and accuracy.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "physics.flu-dyn",
            "65M08, 65M60, 76N06"
        ],
        "authors": [
            "Walter Boscheri",
            "Saray Busto",
            "Michael Dumbser"
        ],
        "published": "2024-05-22T08:34:42Z"
    },
    {
        "title": "Dynamically enhanced static handwriting representation for Parkinson's\n  disease detection",
        "link": "http://dx.doi.org/10.1016/j.patrec.2019.08.018",
        "abstract": "Computer aided diagnosis systems can provide non-invasive, low-cost tools to\nsupport clinicians. These systems have the potential to assist the diagnosis\nand monitoring of neurodegenerative disorders, in particular Parkinson's\ndisease (PD). Handwriting plays a special role in the context of PD assessment.\nIn this paper, the discriminating power of \"dynamically enhanced\" static images\nof handwriting is investigated. The enhanced images are synthetically generated\nby exploiting simultaneously the static and dynamic properties of handwriting.\nSpecifically, we propose a static representation that embeds dynamic\ninformation based on: (i) drawing the points of the samples, instead of linking\nthem, so as to retain temporal/velocity information; and (ii) adding pen-ups\nfor the same purpose. To evaluate the effectiveness of the new handwriting\nrepresentation, a fair comparison between this approach and state-of-the-art\nmethods based on static and dynamic handwriting is conducted on the same\ndataset, i.e. PaHaW. The classification workflow employs transfer learning to\nextract meaningful features from multiple representations of the input data. An\nensemble of different classifiers is used to achieve the final predictions.\nDynamically enhanced static handwriting is able to outperform the results\nobtained by using static and dynamic handwriting separately.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Moises Diaz",
            "Miguel Angel Ferrer",
            "Donato Impedovo",
            "Giuseppe Pirlo",
            "Gennaro Vessio"
        ],
        "published": "2024-05-22T08:28:42Z"
    },
    {
        "title": "On the approximation of the von Neumann equation in the semi-classical\n  limit. Part I : numerical algorithm",
        "link": "http://arxiv.org/abs/2405.13436v1",
        "abstract": "We propose a new approach to discretize the von Neumann equation, which is\nefficient in the semi-classical limit. This method is first based on the so\ncalled Weyl's variables to address the stiffness associated with the equation.\nThen, by applying a truncated Hermite expansion of the density operator, we\nsuccessfully handle this stiffness. Additionally, we develop a finite volume\napproximation for practical implementation and conduct numerical simulations to\nillustrate the efficiency of our approach. This asymptotic preserving numerical\napproximation, combined with the use of Hermite polynomials, provides an\nefficient tool for solving the von Neumann equation in all regimes, near\nclassical or not.",
        "subjects": [
            "math.AP",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Francis Filbet",
            "Fran√ßois Golse"
        ],
        "published": "2024-05-22T08:25:26Z"
    },
    {
        "title": "A Coherence Construction for the Propositional Universe",
        "link": "http://arxiv.org/abs/2405.13435v1",
        "abstract": "We record a particularly simple construction on top of Lumsdaine's local\nuniverses that allows for a Coquand-style universe of propositions with\npropositional extensionality to be interpreted in a category with subobject\nclassifiers.",
        "subjects": [
            "cs.LO",
            "03B38",
            "F.3.2; F.4.1"
        ],
        "authors": [
            "Xu Huang"
        ],
        "published": "2024-05-22T08:24:27Z"
    },
    {
        "title": "Towards Exploratory Quality Diversity Landscape Analysis",
        "link": "http://arxiv.org/abs/2405.13433v1",
        "abstract": "This work is a preliminary study on using Exploratory Landscape Analysis\n(ELA) for Quality Diversity (QD) problems. We seek to understand whether ELA\nfeatures can potentially be used to characterise QD problems paving the way for\nautomating QD algorithm selection. Our results demonstrate that ELA features\nare affected by QD optimisation differently than random sampling, and more\nspecifically, by the choice of variation operator, behaviour function, archive\nsize and problem dimensionality.",
        "subjects": [
            "cs.NE"
        ],
        "authors": [
            "Kyriacos Mosphilis",
            "Vassilis Vassiliades"
        ],
        "published": "2024-05-22T08:19:55Z"
    },
    {
        "title": "Disperse-Then-Merge: Pushing the Limits of Instruction Tuning via\n  Alignment Tax Reduction",
        "link": "http://arxiv.org/abs/2405.13432v1",
        "abstract": "Supervised fine-tuning (SFT) on instruction-following corpus is a crucial\napproach toward the alignment of large language models (LLMs). However, the\nperformance of LLMs on standard knowledge and reasoning benchmarks tends to\nsuffer from deterioration at the latter stage of the SFT process, echoing the\nphenomenon of alignment tax. Through our pilot study, we put a hypothesis that\nthe data biases are probably one cause behind the phenomenon. To address the\nissue, we introduce a simple disperse-then-merge framework. To be concrete, we\ndisperse the instruction-following data into portions and train multiple\nsub-models using different data portions. Then we merge multiple models into a\nsingle one via model merging techniques. Despite its simplicity, our framework\noutperforms various sophisticated methods such as data curation and training\nregularization on a series of standard knowledge and reasoning benchmarks.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Tingchen Fu",
            "Deng Cai",
            "Lemao Liu",
            "Shuming Shi",
            "Rui Yan"
        ],
        "published": "2024-05-22T08:18:19Z"
    },
    {
        "title": "The Unisolvence of Lagrange Interpolation with Symmetric Interpolation\n  Space and Nodes in High Dimension",
        "link": "http://arxiv.org/abs/2405.13430v1",
        "abstract": "High-dimensional Lagrange interpolation plays a pivotal role in finite\nelement methods, where ensuring the unisolvence and symmetry of its\ninterpolation space and nodes set is crucial. In this paper, we leverage group\naction and group representation theories to precisely delineate the conditions\nfor unisolvence. We establish a necessary condition for unisolvence: the\nsymmetry of the interpolation nodes set is determined by the given\ninterpolation space. Our findings not only contribute to a deeper theoretical\nunderstanding but also promise practical benefits by reducing the computational\noverhead associated with identifying appropriate interpolation nodes.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "65D05"
        ],
        "authors": [
            "Yulin Xie",
            "Yifa Tang"
        ],
        "published": "2024-05-22T08:17:20Z"
    },
    {
        "title": "Ambisonizer: Neural Upmixing as Spherical Harmonics Generation",
        "link": "http://arxiv.org/abs/2405.13428v1",
        "abstract": "Neural upmixing, the task of generating immersive music with an increased\nnumber of channels from fewer input channels, has been an active research area,\nwith mono-to-stereo and stereo-to-surround upmixing treated as separate\nproblems. In this paper, we propose a unified approach to neural upmixing by\nformulating it as spherical harmonics - more specifically, Ambisonic\ngeneration. We explicitly formulate mono upmixing as unconditional generation\nand stereo upmixing as conditional generation, where the stereo signals serve\nas conditions. We provide evidence that our proposed methodology, when decoded\nto stereo, matches a strong commercial stereo widener in subjective ratings.\nOverall, our work presents direct upmixing to Ambisonic format as a strong and\npromising approach to neural upmixing. A discussion on limitations is also\nprovided.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Yongyi Zang",
            "Yifan Wang",
            "Minglun Lee"
        ],
        "published": "2024-05-22T08:16:24Z"
    },
    {
        "title": "Adaptive Fuzzy C-Means with Graph Embedding",
        "link": "http://arxiv.org/abs/2405.13427v1",
        "abstract": "Fuzzy clustering algorithms can be roughly categorized into two main groups:\nFuzzy C-Means (FCM) based methods and mixture model based methods. However, for\nalmost all existing FCM based methods, how to automatically selecting proper\nmembership degree hyper-parameter values remains a challenging and unsolved\nproblem. Mixture model based methods, while circumventing the difficulty of\nmanually adjusting membership degree hyper-parameters inherent in FCM based\nmethods, often have a preference for specific distributions, such as the\nGaussian distribution. In this paper, we propose a novel FCM based clustering\nmodel that is capable of automatically learning an appropriate membership\ndegree hyper-parameter value and handling data with non-Gaussian clusters.\nMoreover, by removing the graph embedding regularization, the proposed FCM\nmodel can degenerate into the simplified generalized Gaussian mixture model.\nTherefore, the proposed FCM model can be also seen as the generalized Gaussian\nmixture model with graph embedding. Extensive experiments are conducted on both\nsynthetic and real-world datasets to demonstrate the effectiveness of the\nproposed model.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Qiang Chen",
            "Weizhong Yu",
            "Feiping Nie",
            "Xuelong Li"
        ],
        "published": "2024-05-22T08:15:50Z"
    },
    {
        "title": "A New Era in Human Factors Engineering: A Survey of the Applications and\n  Prospects of Large Multimodal Models",
        "link": "http://arxiv.org/abs/2405.13426v1",
        "abstract": "In recent years, the potential applications of Large Multimodal Models (LMMs)\nin fields such as healthcare, social psychology, and industrial design have\nattracted wide research attention, providing new directions for human factors\nresearch. For instance, LMM-based smart systems have become novel research\nsubjects of human factors studies, and LMM introduces new research paradigms\nand methodologies to this field. Therefore, this paper aims to explore the\napplications, challenges, and future prospects of LMM in the domain of human\nfactors and ergonomics through an expert-LMM collaborated literature review.\nSpecifically, a novel literature review method is proposed, and research\nstudies of LMM-based accident analysis, human modelling and intervention design\nare introduced. Subsequently, the paper discusses future trends of the research\nparadigm and challenges of human factors and ergonomics studies in the era of\nLMMs. It is expected that this study can provide a valuable perspective and\nserve as a reference for integrating human factors with artificial\nintelligence.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Li Fan",
            "Lee Ching-Hung",
            "Han Su",
            "Feng Shanshan",
            "Jiang Zhuoxuan",
            "Sun Zhu"
        ],
        "published": "2024-05-22T08:14:40Z"
    },
    {
        "title": "A weak Galerkin finite element method for solving the asymptotic lower\n  bound of Maxwell eigenvalue problem",
        "link": "http://arxiv.org/abs/2405.13423v1",
        "abstract": "In this paper, we propose a weak Galerkin (WG) finite element method for the\nMaxwell eigenvalue problem. By restricting subspaces, we transform the mixed\nform of Maxwell eigenvalue problem into simple elliptic equation. Then we give\nthe WG numerical scheme for the Maxwell eigenvalue problem. Furthermore, we\nobtain the optimal error estimates of arbitrarily high convergence order and\nprove the lower bound property of numerical solutions for eigenvalues.\nNumerical experiments show the accuracy of theoretical analysis and the\nproperty of lower bound.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Shusheng Li",
            "Qilong Zhai"
        ],
        "published": "2024-05-22T08:12:09Z"
    },
    {
        "title": "Recovering short generators via negative moments of Dirichlet\n  $L$-functions",
        "link": "http://arxiv.org/abs/2405.13420v1",
        "abstract": "In 2016, Cramer, Ducas, Peikert and, Regev proposed an efficient algorithm\nfor recovering short generators of principal ideals in $q$-th cyclotomic fields\nwith $q$ being a prime power. In this paper, we improve their analysis of the\ndual basis of the log-cyclotomic-unit lattice under the Generalised Riemann\nHypothesis and in the case that $q$ is a prime number by the negative square\nmoment of Dirichlet $L$-functions at $s=1$. As an implication, we obtain a\nbetter lower bound on the success probability for the algorithm in this special\ncase. In order to prove our main result, we also give an analysis of the\nbehaviour of negative $2k$-th moments of Dirichlet $L$-functions at $s=1$.",
        "subjects": [
            "math.NT",
            "cs.DS"
        ],
        "authors": [
            "Iu-Iong Ng",
            "Yuichiro Toma"
        ],
        "published": "2024-05-22T07:58:35Z"
    },
    {
        "title": "Source-level reasoning for quantitative information flow",
        "link": "http://arxiv.org/abs/2405.13416v1",
        "abstract": "We present a novel formal system for proving quantitative-leakage properties\nof programs. Based on a theory of Quantitative Information Flow (QIF) that\nmodels information leakage as a noisy communication channel, it uses\n\"gain-functions\" for the description and measurement of expected leaks.\n  We use a small imperative programming language, augmented with leakage\nfeatures, and with it express adversaries' activities in the style of, but more\ngenerally than, the Hoare triples or expectation transformers that\ntraditionally express deterministic or probabilistic correctness but without\ninformation flow.\n  The programs are annotated with \"gain-expressions\" that capture simple\nadversarial settings such as \"Guess the secret in one try.\" but also much more\ngeneral ones; and our formal syntax and logic -based framework enables us to\ntransform such gain-expressions that apply after a program has finished to ones\nthat equivalently apply before the program has begun.\n  In that way we enable a formal proof-based reasoning system for QIF at the\nsource level. We apply it to the %programming language we have chosen, and\ndemonstrate its effectiveness in a number of small but sometimes intricate\nsituations.",
        "subjects": [
            "cs.LO"
        ],
        "authors": [
            "Chris Chen",
            "Annabelle McIver",
            "Carroll Morgan"
        ],
        "published": "2024-05-22T07:50:43Z"
    },
    {
        "title": "Boosted Neural Decoders: Achieving Extreme Reliability of LDPC Codes for\n  6G Networks",
        "link": "http://arxiv.org/abs/2405.13413v1",
        "abstract": "Ensuring extremely high reliability is essential for channel coding in 6G\nnetworks. The next-generation of ultra-reliable and low-latency communications\n(xURLLC) scenario within 6G networks requires a frame error rate (FER) below\n10-9. However, low-density parity-check (LDPC) codes, the standard in 5G new\nradio (NR), encounter a challenge known as the error floor phenomenon, which\nhinders to achieve such low rates. To tackle this problem, we introduce an\ninnovative solution: boosted neural min-sum (NMS) decoder. This decoder\noperates identically to conventional NMS decoders, but is trained by novel\ntraining methods including: i) boosting learning with uncorrected vectors, ii)\nblock-wise training schedule to address the vanishing gradient issue, iii)\ndynamic weight sharing to minimize the number of trainable weights, iv)\ntransfer learning to reduce the required sample count, and v) data augmentation\nto expedite the sampling process. Leveraging these training strategies, the\nboosted NMS decoder achieves the state-of-the art performance in reducing the\nerror floor as well as superior waterfall performance. Remarkably, we fulfill\nthe 6G xURLLC requirement for 5G LDPC codes without the severe error floor.\nAdditionally, the boosted NMS decoder, once its weights are trained, can\nperform decoding without additional modules, making it highly practical for\nimmediate application.",
        "subjects": [
            "cs.IT",
            "cs.LG",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Hee-Youl Kwak",
            "Dae-Young Yun",
            "Yongjune Kim",
            "Sang-Hyo Kim",
            "Jong-Seon No"
        ],
        "published": "2024-05-22T07:48:24Z"
    },
    {
        "title": "Specular Polynomials",
        "link": "http://arxiv.org/abs/2405.13409v1",
        "abstract": "Finding valid light paths that involve specular vertices in Monte Carlo\nrendering requires solving many non-linear, transcendental equations in\nhigh-dimensional space. Existing approaches heavily rely on Newton iterations\nin path space, which are limited to obtaining at most a single solution each\ntime and easily diverge when initialized with improper seeds.\n  We propose specular polynomials, a Newton iteration-free methodology for\nfinding a complete set of admissible specular paths connecting two arbitrary\nendpoints in a scene. The core is a reformulation of specular constraints into\npolynomial systems, which makes it possible to reduce the task to a univariate\nroot-finding problem. We first derive bivariate systems utilizing rational\ncoordinate mapping between the coordinates of consecutive vertices.\nSubsequently, we adopt the hidden variable resultant method for variable\nelimination, converting the problem into finding zeros of the determinant of\nunivariate matrix polynomials. This can be effectively solved through Laplacian\nexpansion for one bounce and a bisection solver for more bounces.\n  Our solution is generic, completely deterministic, accurate for the case of\none bounce, and GPU-friendly. We develop efficient CPU and GPU implementations\nand apply them to challenging glints and caustic rendering. Experiments on\nvarious scenarios demonstrate the superiority of specular polynomial-based\nsolutions compared to Newton iteration-based counterparts.",
        "subjects": [
            "cs.GR",
            "I.3.3"
        ],
        "authors": [
            "Zhimin Fan",
            "Jie Guo",
            "Yiming Wang",
            "Tianyu Xiao",
            "Hao Zhang",
            "Chenxi Zhou",
            "Zhenyu Chen",
            "Pengpei Hong",
            "Yanwen Guo",
            "Ling-Qi Yan"
        ],
        "published": "2024-05-22T07:40:31Z"
    },
    {
        "title": "Dynamic Context Adaptation and Information Flow Control in Transformers:\n  Introducing the Evaluator Adjuster Unit and Gated Residual Connections",
        "link": "http://arxiv.org/abs/2405.13407v1",
        "abstract": "Transformers have revolutionized various domains of artificial intelligence\ndue to their unique ability to model long-range dependencies in data. However,\nthey lack in nuanced, context-dependent modulation of features and information\nflow. This paper introduces two significant enhancements to the transformer\narchitecture - the Evaluator Adjuster Unit (EAU) and Gated Residual Connections\n(GRC) - designed to address these limitations. The EAU dynamically modulates\nattention outputs based on the relevance of the input context, allowing for\nmore adaptive response patterns. Concurrently, the GRC modifies the\ntransformer's residual connections through a gating mechanism that selectively\ncontrols the information flow, thereby enhancing the network's ability to focus\non contextually important features. We evaluate the performance of these\nenhancements across several benchmarks in natural language processing. Our\nresults demonstrate improved adaptability and efficiency, suggesting that these\nmodifications could set new standards for designing flexible and context-aware\ntransformer models.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Sahil Rajesh Dhayalkar"
        ],
        "published": "2024-05-22T07:33:24Z"
    },
    {
        "title": "Adaptive Wireless Image Semantic Transmission and Over-The-Air Testing",
        "link": "http://arxiv.org/abs/2405.13403v1",
        "abstract": "Semantic communication has undergone considerable evolution due to the recent\nrapid development of artificial intelligence (AI), significantly enhancing both\ncommunication robustness and efficiency. Despite these advancements, most\ncurrent semantic communication methods for image transmission pay little\nattention to the differing importance of objects and backgrounds in images. To\naddress this issue, we propose a novel scheme named ASCViT-JSCC, which utilizes\nvision transformers (ViTs) integrated with an orthogonal frequency division\nmultiplexing (OFDM) system. This scheme adaptively allocates bandwidth for\nobjects and backgrounds in images according to the importance order of\ndifferent parts determined by object detection of you only look once version 5\n(YOLOv5) and feature points detection of scale invariant feature transform\n(SIFT). Furthermore, the proposed scheme adheres to digital modulation\nstandards by incorporating quantization modules. We validate this approach\nthrough an over-the-air (OTA) testbed named intelligent communication prototype\nvalidation platform (ICP) based on a software-defined radio (SDR) and NVIDIA\nembedded kits. Our findings from both simulations and practical measurements\nshow that ASCViT-JSCC significantly preserves objects in images and enhances\nreconstruction quality compared to existing methods.",
        "subjects": [
            "eess.IV",
            "cs.MM"
        ],
        "authors": [
            "Jiarun Ding",
            "Peiwen Jiang",
            "Chao-Kai Wen",
            "Shi Jin"
        ],
        "published": "2024-05-22T07:24:20Z"
    },
    {
        "title": "TrojanRAG: Retrieval-Augmented Generation Can Be Backdoor Driver in\n  Large Language Models",
        "link": "http://arxiv.org/abs/2405.13401v2",
        "abstract": "Large language models (LLMs) have raised concerns about potential security\nthreats despite performing significantly in Natural Language Processing (NLP).\nBackdoor attacks initially verified that LLM is doing substantial harm at all\nstages, but the cost and robustness have been criticized. Attacking LLMs is\ninherently risky in security review, while prohibitively expensive. Besides,\nthe continuous iteration of LLMs will degrade the robustness of backdoors. In\nthis paper, we propose TrojanRAG, which employs a joint backdoor attack in the\nRetrieval-Augmented Generation, thereby manipulating LLMs in universal attack\nscenarios. Specifically, the adversary constructs elaborate target contexts and\ntrigger sets. Multiple pairs of backdoor shortcuts are orthogonally optimized\nby contrastive learning, thus constraining the triggering conditions to a\nparameter subspace to improve the matching. To improve the recall of the RAG\nfor the target contexts, we introduce a knowledge graph to construct structured\ndata to achieve hard matching at a fine-grained level. Moreover, we normalize\nthe backdoor scenarios in LLMs to analyze the real harm caused by backdoors\nfrom both attackers' and users' perspectives and further verify whether the\ncontext is a favorable tool for jailbreaking models. Extensive experimental\nresults on truthfulness, language understanding, and harmfulness show that\nTrojanRAG exhibits versatility threats while maintaining retrieval capabilities\non normal queries.",
        "subjects": [
            "cs.CR",
            "cs.CL"
        ],
        "authors": [
            "Pengzhou Cheng",
            "Yidong Ding",
            "Tianjie Ju",
            "Zongru Wu",
            "Wei Du",
            "Ping Yi",
            "Zhuosheng Zhang",
            "Gongshen Liu"
        ],
        "published": "2024-05-22T07:21:32Z"
    },
    {
        "title": "Multi Player Tracking in Ice Hockey with Homographic Projections",
        "link": "http://arxiv.org/abs/2405.13397v1",
        "abstract": "Multi Object Tracking (MOT) in ice hockey pursues the combined task of\nlocalizing and associating players across a given sequence to maintain their\nidentities. Tracking players from monocular broadcast feeds is an important\ncomputer vision problem offering various downstream analytics and enhanced\nviewership experience. However, existing trackers encounter significant\ndifficulties in dealing with occlusions, blurs, and agile player movements\nprevalent in telecast feeds. In this work, we propose a novel tracking approach\nby formulating MOT as a bipartite graph matching problem infused with\nhomography. We disentangle the positional representations of occluded and\noverlapping players in broadcast view, by mapping their foot keypoints to an\noverhead rink template, and encode these projected positions into the graph\nnetwork. This ensures reliable spatial context for consistent player tracking\nand unfragmented tracklet prediction. Our results show considerable\nimprovements in both the IDsw and IDF1 metrics on the two available broadcast\nice hockey datasets.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Harish Prakash",
            "Jia Cheng Shang",
            "Ken M. Nsiempba",
            "Yuhao Chen",
            "David A. Clausi",
            "John S. Zelek"
        ],
        "published": "2024-05-22T07:14:55Z"
    },
    {
        "title": "Why In-Context Learning Transformers are Tabular Data Classifiers",
        "link": "http://arxiv.org/abs/2405.13396v1",
        "abstract": "The recently introduced TabPFN pretrains an In-Context Learning (ICL)\ntransformer on synthetic data to perform tabular data classification. As\nsynthetic data does not share features or labels with real-world data, the\nunderlying mechanism that contributes to the success of this method remains\nunclear. This study provides an explanation by demonstrating that\nICL-transformers acquire the ability to create complex decision boundaries\nduring pretraining. To validate our claim, we develop a novel forest dataset\ngenerator which creates datasets that are unrealistic, but have complex\ndecision boundaries. Our experiments confirm the effectiveness of\nICL-transformers pretrained on this data. Furthermore, we create TabForestPFN,\nthe ICL-transformer pretrained on both the original TabPFN synthetic dataset\ngenerator and our forest dataset generator. By fine-tuning this model, we reach\nthe current state-of-the-art on tabular data classification. Code is available\nat https://github.com/FelixdenBreejen/TabForestPFN.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Felix den Breejen",
            "Sangmin Bae",
            "Stephen Cha",
            "Se-Young Yun"
        ],
        "published": "2024-05-22T07:13:55Z"
    },
    {
        "title": "A theory of neural emulators",
        "link": "http://arxiv.org/abs/2405.13394v1",
        "abstract": "A central goal in neuroscience is to provide explanations for how animal\nnervous systems can generate actions and cognitive states such as consciousness\nwhile artificial intelligence (AI) and machine learning (ML) seek to provide\nmodels that are increasingly better at prediction. Despite many decades of\nresearch we have made limited progress on providing neuroscience explanations\nyet there is an increased use of AI and ML methods in neuroscience for\nprediction of behavior and even cognitive states. Here we propose emulator\ntheory (ET) and neural emulators as circuit- and scale-independent predictive\nmodels of biological brain activity and emulator theory (ET) as an alternative\nresearch paradigm in neuroscience. ET proposes that predictive models trained\nsolely on neural dynamics and behaviors can generate functionally\nindistinguishable systems from their sources. That is, compared to the\nbiological organisms which they model, emulators may achieve indistinguishable\nbehavior and cognitive states - including consciousness - without any\nmechanistic explanations. We posit ET via several conjectures, discuss the\nnature of endogenous and exogenous activation of neural circuits, and discuss\nneural causality of phenomenal states. ET provides the conceptual and empirical\nframework for prediction-based models of neural dynamics and behavior without\nexplicit representations of idiosyncratically evolved nervous systems.",
        "subjects": [
            "q-bio.NC",
            "cs.AI"
        ],
        "authors": [
            "Catalin C. Mitelut"
        ],
        "published": "2024-05-22T07:12:03Z"
    },
    {
        "title": "NFCL: Simply interpretable neural networks for a short-term multivariate\n  forecasting",
        "link": "http://arxiv.org/abs/2405.13393v1",
        "abstract": "Multivariate time-series forecasting (MTSF) stands as a compelling field\nwithin the machine learning community. Diverse neural network based\nmethodologies deployed in MTSF applications have demonstrated commendable\nefficacy. Despite the advancements in model performance, comprehending the\nrationale behind the model's behavior remains an enigma. Our proposed model,\nthe Neural ForeCasting Layer (NFCL), employs a straightforward amalgamation of\nneural networks. This uncomplicated integration ensures that each neural\nnetwork contributes inputs and predictions independently, devoid of\ninterference from other inputs. Consequently, our model facilitates a\ntransparent explication of forecast results. This paper introduces NFCL along\nwith its diverse extensions. Empirical findings underscore NFCL's superior\nperformance compared to nine benchmark models across 15 available open\ndatasets. Notably, NFCL not only surpasses competitors but also provides\nelucidation for its predictions. In addition, Rigorous experimentation\ninvolving diverse model structures bolsters the justification of NFCL's unique\nconfiguration.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "I.2.1; I.5.4"
        ],
        "authors": [
            "Wonkeun Jo",
            "Dongil Kim"
        ],
        "published": "2024-05-22T07:08:27Z"
    },
    {
        "title": "Local convergence of min-max algorithms to differentiable equilibrium on\n  Riemannian manifold",
        "link": "http://arxiv.org/abs/2405.13392v1",
        "abstract": "We study min-max algorithms to solve zero-sum differentiable games on\nRiemannian manifold. The notions of differentiable Stackelberg equilibrium and\ndifferentiable Nash equilibrium in Euclidean space are generalized to\nRiemannian manifold, through an intrinsic definition which does not depend on\nthe choice of local coordinate chart of manifold. We then provide sufficient\nconditions for the local convergence of the deterministic simultaneous\nalgorithms $\\tau$-GDA and $\\tau$-SGA near such equilibrium, using a general\nmethodology based on spectral analysis. These algorithms are extended with\nstochastic gradients and applied to the training of Wasserstein GAN. The\ndiscriminator of GAN is constructed from Lipschitz-continuous functions based\non Stiefel manifold. We show numerically how the insights obtained from the\nlocal convergence analysis may lead to an improvement of GAN models.",
        "subjects": [
            "cs.LG",
            "math.OC",
            "stat.ML"
        ],
        "authors": [
            "Sixin Zhang"
        ],
        "published": "2024-05-22T07:07:22Z"
    },
    {
        "title": "Convergence analysis of kernel learning FBSDE filter",
        "link": "http://arxiv.org/abs/2405.13390v1",
        "abstract": "Kernel learning forward backward SDE filter is an iterative and adaptive\nmeshfree approach to solve the nonlinear filtering problem. It builds from\nforward backward SDE for Fokker-Planker equation, which defines evolving\ndensity for the state variable, and employs KDE to approximate density. This\nalgorithm has shown more superior performance than mainstream particle filter\nmethod, in both convergence speed and efficiency of solving high dimension\nproblems.\n  However, this method has only been shown to converge empirically. In this\npaper, we present a rigorous analysis to demonstrate its local and global\nconvergence, and provide theoretical support for its empirical results.",
        "subjects": [
            "cs.LG",
            "cs.NA",
            "math.NA",
            "q-fin.MF"
        ],
        "authors": [
            "Yunzheng Lyu",
            "Feng Bao"
        ],
        "published": "2024-05-22T07:02:35Z"
    },
    {
        "title": "HR-INR: Continuous Space-Time Video Super-Resolution via Event Camera",
        "link": "http://arxiv.org/abs/2405.13389v1",
        "abstract": "Continuous space-time video super-resolution (C-STVSR) aims to simultaneously\nenhance video resolution and frame rate at an arbitrary scale. Recently,\nimplicit neural representation (INR) has been applied to video restoration,\nrepresenting videos as implicit fields that can be decoded at an arbitrary\nscale. However, the highly ill-posed nature of C-STVSR limits the effectiveness\nof current INR-based methods: they assume linear motion between frames and use\ninterpolation or feature warping to generate features at arbitrary\nspatiotemporal positions with two consecutive frames. This restrains C-STVSR\nfrom capturing rapid and nonlinear motion and long-term dependencies (involving\nmore than two frames) in complex dynamic scenes. In this paper, we propose a\nnovel C-STVSR framework, called HR-INR, which captures both holistic\ndependencies and regional motions based on INR. It is assisted by an event\ncamera, a novel sensor renowned for its high temporal resolution and low\nlatency. To fully utilize the rich temporal information from events, we design\na feature extraction consisting of (1) a regional event feature extractor -\ntaking events as inputs via the proposed event temporal pyramid representation\nto capture the regional nonlinear motion and (2) a holistic event-frame feature\nextractor for long-term dependence and continuity motion. We then propose a\nnovel INR-based decoder with spatiotemporal embeddings to capture long-term\ndependencies with a larger temporal perception field. We validate the\neffectiveness and generalization of our method on four datasets (both simulated\nand real data), showing the superiority of our method.",
        "subjects": [
            "cs.CV",
            "cs.MM",
            "cs.RO"
        ],
        "authors": [
            "Yunfan Lu",
            "Zipeng Wang",
            "Yusheng Wang",
            "Hui Xiong"
        ],
        "published": "2024-05-22T06:51:32Z"
    },
    {
        "title": "Unsupervised Pre-training with Language-Vision Prompts for Low-Data\n  Instance Segmentation",
        "link": "http://arxiv.org/abs/2405.13388v1",
        "abstract": "In recent times, following the paradigm of DETR (DEtection TRansformer),\nquery-based end-to-end instance segmentation (QEIS) methods have exhibited\nsuperior performance compared to CNN-based models, particularly when trained on\nlarge-scale datasets. Nevertheless, the effectiveness of these QEIS methods\ndiminishes significantly when confronted with limited training data. This\nlimitation arises from their reliance on substantial data volumes to\neffectively train the pivotal queries/kernels that are essential for acquiring\nlocalization and shape priors. To address this problem, we propose a novel\nmethod for unsupervised pre-training in low-data regimes. Inspired by the\nrecently successful prompting technique, we introduce a new method,\nUnsupervised Pre-training with Language-Vision Prompts (UPLVP), which improves\nQEIS models' instance segmentation by bringing language-vision prompts to\nqueries/kernels. Our method consists of three parts: (1) Masks Proposal:\nUtilizes language-vision models to generate pseudo masks based on unlabeled\nimages. (2) Prompt-Kernel Matching: Converts pseudo masks into prompts and\ninjects the best-matched localization and shape features to their corresponding\nkernels. (3) Kernel Supervision: Formulates supervision for pre-training at the\nkernel level to ensure robust learning. With the help of our pre-training\nmethod, QEIS models can converge faster and perform better than CNN-based\nmodels in low-data regimes. Experimental evaluations conducted on MS COCO,\nCityscapes, and CTW1500 datasets indicate that the QEIS models' performance can\nbe significantly improved when pre-trained with our method. Code will be\navailable at: https://github.com/lifuguan/UPLVP.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Dingwen Zhang",
            "Hao Li",
            "Diqi He",
            "Nian Liu",
            "Lechao Cheng",
            "Jingdong Wang",
            "Junwei Han"
        ],
        "published": "2024-05-22T06:48:43Z"
    },
    {
        "title": "360Zhinao Technical Report",
        "link": "http://arxiv.org/abs/2405.13386v1",
        "abstract": "We present 360Zhinao models with 7B parameter size and context lengths\nspanning 4K, 32K and 360K, all available at\nhttps://github.com/Qihoo360/360zhinao. For rapid development in pretraining, we\nestablish a stable and sensitive ablation environment to evaluate and compare\nexperiment runs with minimal model size. Under such guidance, we perfect our\ndata cleaning and composition strategies to pretrain\n$\\texttt{360Zhinao-7B-Base}$ on 3.4T tokens. We also mainly emphasize data\nduring alignment, where we strive to balance quantity and quality with\nfiltering and reformatting. With tailored data, 360Zhinao-7B's context window\nis easily extended to 32K and 360K. RMs and RLHF are trained following SFT and\ncredibly applied to specific tasks. All together these contributions lead to\n360Zhinao-7B's competitive performance among models of similar size.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            " 360Zhinao Team"
        ],
        "published": "2024-05-22T06:45:38Z"
    },
    {
        "title": "Elastic-gap free strain gradient crystal plasticity model that\n  effectively account for plastic slip gradient and grain boundary dissipation",
        "link": "http://arxiv.org/abs/2405.13384v1",
        "abstract": "This paper proposes an elastic-gap free strain gradient crystal plasticity\nmodel that addresses dissipation caused by plastic slip gradient and grain\nboundary (GB) Burger tensor. The model involves splitting plastic slip gradient\nand GB Burger tensor into energetic dissipative quantities. Unlike conventional\nmodels, the bulk and GB defect energy are considered to be a quadratic\nfunctional of the energetic portion of slip gradient and GB Burgers tensor. The\nhigher-order stresses for each individual slip systems and GB stresses are\nderived from the defect energy, following a similar evolution as the\nArmstrong-Frederick type backstress model in classical plasticity. The\nevolution equations consist of a hardening and a relaxation term. The\nrelaxation term brings the nonlinearity in hardening and causes an additional\ndissipation. The applicability of the proposed model is numerically established\nwith the help of two-dimensional finite element implementation. Specifically,\nthe bulk and GB relaxation coefficients are critically evaluated based on\nvarious circumstances, considering single crystal infinite shear layer,\nperiodic bicrystal shearing, and bicrystal tension problem. In contrast to the\nGurtin-type model, the proposed model smoothly captures the apparent\nstrengthening at saturation without causing any abrupt stress jump under\nnon-proportional loading conditions. Moreover, when subjected to cyclic\nloading, the stress-strain curve maintains its curvature during reverse\nloading. The numerical simulation reveals that the movement of geometrically\nnecessary dislocation (GND) towards the GB is influenced by the bulk recovery\ncoefficient, while the dissipation and amount of accumulation of GND near the\nGB are controlled by the GB recovery coefficient.",
        "subjects": [
            "cs.CE"
        ],
        "authors": [
            "Anjan Mukherjee",
            "Biswanath Banerjee"
        ],
        "published": "2024-05-22T06:38:51Z"
    },
    {
        "title": "Gradient Projection For Parameter-Efficient Continual Learning",
        "link": "http://arxiv.org/abs/2405.13383v1",
        "abstract": "Catastrophic forgetting poses the primary challenge in the continual\nlearning. Nowadays, methods based on parameter-efficient tuning (PET) have\ndemonstrated impressive performance in continual learning. However, these\nmethods are still confronted with a common problem: fine-tuning on consecutive\ndistinct tasks can disrupt the existing parameter distribution and lead to\nforgetting. Recent progress mainly focused in empirically designing efficient\ntuning engineering, lacking investigation of forgetting generation mechanism,\nanti-forgetting criteria and providing theoretical support. Additionally, the\nunresolved trade-off between learning new content and protecting old knowledge\nfurther complicates these challenges. The gradient projection methodology\nrestricts gradient updates to the orthogonal direction of the old feature\nspace, preventing distribution of the parameters from being damaged during\nupdating and significantly suppressing forgetting. Developing on it, in this\npaper, we reformulate Adapter, LoRA, Prefix, and Prompt to continual learning\nsetting from the perspective of gradient projection, and propose a unified\nframework called Parameter Efficient Gradient Projection (PEGP). Based on the\nhypothesis that old tasks should have the same results after model updated, we\nintroduce orthogonal gradient projection into different PET paradigms and\ntheoretically demonstrate that the orthogonal condition for the gradient can\neffectively resist forgetting in PET-based continual methods. Notably, PEGP is\nthe first unified method to provide an anti-forgetting mechanism with\nmathematical demonstration for different tuning paradigms. We extensively\nevaluate our method with different backbones on diverse datasets, and\nexperiments demonstrate its efficiency in reducing forgetting in various\nincremental settings.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Jingyang Qiao",
            "Zhizhong Zhang",
            "Xin Tan",
            "Yanyun Qu",
            "Wensheng Zhang",
            "Yuan Xie"
        ],
        "published": "2024-05-22T06:33:48Z"
    },
    {
        "title": "VTG-LLM: Integrating Timestamp Knowledge into Video LLMs for Enhanced\n  Video Temporal Grounding",
        "link": "http://arxiv.org/abs/2405.13382v1",
        "abstract": "Video Temporal Grounding (VTG) focuses on accurately identifying event\ntimestamps within a particular video based on a linguistic query, playing a\nvital role in downstream tasks such as video browsing and editing. While Video\nLarge Language Models (video LLMs) have made significant progress in\nunderstanding video content, they often face challenges in accurately\npinpointing timestamps within videos, which limits their performance on VTG\ntasks. Therefore, to improve video LLMs' ability to effectively locate\ntimestamps, we argue that two critical aspects need to be enhanced. First, it\nis essential to have high-quality instructional tuning datasets that encompass\nmainstream VTG tasks. Second, directly incorporating timestamp knowledge into\nvideo LLMs is crucial, as it enables models to efficiently comprehend timestamp\ninformation. To address these needs, we first introduce VTG-IT-120K, a\nhigh-quality and comprehensive instruction tuning dataset that covers VTG tasks\nsuch as moment retrieval, dense video captioning, video summarization, and\nvideo highlight detection. Furthermore, we propose a specially designed video\nLLM model for VTG tasks, VTG-LLM, which (1) effectively integrates timestamp\nknowledge into visual tokens; (2) incorporates absolute-time tokens that\nspecifically handle timestamp knowledge, thereby avoiding concept shifts; and\n(3) introduces a lightweight, high-performance slot-based token compression\nmethod to facilitate the sampling of more video frames. Comprehensive\nexperiments showcase the superior performance of VTG-LLM in comparison to other\nvideo LLM methods across various VTG tasks. Our code and datasets are available\nat \\url{https://github.com/gyxxyg/VTG-LLM}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yongxin Guo",
            "Jingyu Liu",
            "Mingda Li",
            "Xiaoying Tang",
            "Xi Chen",
            "Bo Zhao"
        ],
        "published": "2024-05-22T06:31:42Z"
    },
    {
        "title": "Optimizing Search Advertising Strategies: Integrating Reinforcement\n  Learning with Generalized Second-Price Auctions for Enhanced Ad Ranking and\n  Bidding",
        "link": "http://arxiv.org/abs/2405.13381v1",
        "abstract": "This paper explores the integration of strategic optimization methods in\nsearch advertising, focusing on ad ranking and bidding mechanisms within\nE-commerce platforms. By employing a combination of reinforcement learning and\nevolutionary strategies, we propose a dynamic model that adjusts to varying\nuser interactions and optimizes the balance between advertiser cost, user\nrelevance, and platform revenue. Our results suggest significant improvements\nin ad placement accuracy and cost efficiency, demonstrating the model's\napplicability in real-world scenarios.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Chang Zhou",
            "Yang Zhao",
            "Jin Cao",
            "Yi Shen",
            "Jing Gao",
            "Xiaoling Cui",
            "Chiyu Cheng",
            "Hao Liu"
        ],
        "published": "2024-05-22T06:30:55Z"
    },
    {
        "title": "The Illusion of Anonymity: Uncovering the Impact of User Actions on\n  Privacy in Web3 Social Ecosystems",
        "link": "http://arxiv.org/abs/2405.13380v1",
        "abstract": "The rise of Web3 social ecosystems signifies the dawn of a new chapter in\ndigital interaction, offering significant prospects for user engagement and\nfinancial advancement. Nonetheless, this progress is shadowed by potential\nprivacy concessions, especially as these platforms frequently merge with\nexisting Web2.0 social media accounts, amplifying data privacy risks for users.\n  In this study, we investigate the nuanced dynamics between user engagement on\nWeb3 social platforms and the consequent privacy concerns. We scrutinize the\nwidespread phenomenon of fabricated activities, which encompasses the\nestablishment of bogus accounts aimed at mimicking popularity and the\ndeliberate distortion of social interactions by some individuals to gain\nfinancial rewards. Such deceptive maneuvers not only distort the true measure\nof the active user base but also amplify privacy threats for all members of the\nuser community. We also find that, notwithstanding their attempts to limit\nsocial exposure, users remain entangled in privacy vulnerabilities. The actions\nof those highly engaged users, albeit often a minority group, can inadvertently\nbreach the privacy of the larger collective.\n  By casting light on the delicate interplay between user engagement, financial\nmotives, and privacy issues, we offer a comprehensive examination of the\nintrinsic challenges and hazards present in the Web3 social milieu. We\nhighlight the urgent need for more stringent privacy measures and ethical\nprotocols to navigate the complex web of social exchanges and financial\nambitions in the rapidly evolving Web3.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Bin Wang",
            "Tianjian Liu",
            "Wenqi Wang",
            "Yuan Weng",
            "Chao Li",
            "Guangquan Xu",
            "Meng Shen",
            "Sencun Zhu",
            "Wei Wang"
        ],
        "published": "2024-05-22T06:26:15Z"
    },
    {
        "title": "You don't understand me!: Comparing ASR results for L1 and L2 speakers\n  of Swedish",
        "link": "http://arxiv.org/abs/2405.13379v1",
        "abstract": "The performance of Automatic Speech Recognition (ASR) systems has constantly\nincreased in state-of-the-art development. However, performance tends to\ndecrease considerably in more challenging conditions (e.g., background noise,\nmultiple speaker social conversations) and with more atypical speakers (e.g.,\nchildren, non-native speakers or people with speech disorders), which signifies\nthat general improvements do not necessarily transfer to applications that rely\non ASR, e.g., educational software for younger students or language learners.\nIn this study, we focus on the gap in performance between recognition results\nfor native and non-native, read and spontaneous, Swedish utterances transcribed\nby different ASR services. We compare the recognition results using Word Error\nRate and analyze the linguistic factors that may generate the observed\ntranscription errors.",
        "subjects": [
            "cs.CL",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Ronald Cumbal",
            "Birger Moell",
            "Jose Lopes",
            "Olof Engwall"
        ],
        "published": "2024-05-22T06:24:55Z"
    },
    {
        "title": "FedCache 2.0: Exploiting the Potential of Distilled Data in Knowledge\n  Cache-driven Federated Learning",
        "link": "http://arxiv.org/abs/2405.13378v1",
        "abstract": "Federated Edge Learning (FEL) has emerged as a promising approach for\nenabling edge devices to collaboratively train machine learning models while\npreserving data privacy. Despite its advantages, practical FEL deployment faces\nsignificant challenges related to device constraints and device-server\ninteractions, necessitating heterogeneous, user-adaptive model training with\nlimited and uncertain communication. In this paper, we introduce FedCache 2.0,\na novel personalized FEL architecture that simultaneously addresses these\nchallenges. FedCache 2.0 incorporates the benefits of both dataset distillation\nand knowledge cache-driven federated learning by storing and organizing\ndistilled data as knowledge in the server-side knowledge cache. Moreover, a\ndevice-centric cache sampling strategy is introduced to tailor transferred\nknowledge for individual devices within controlled communication bandwidth.\nExtensive experiments on five datasets covering image recognition, audio\nunderstanding, and mobile sensor data mining tasks demonstrate that (1)\nFedCache 2.0 significantly outperforms state-of-the-art methods regardless of\nmodel structures, data distributions, and modalities. (2) FedCache 2.0 can\ntrain splendid personalized on-device models with at least $\\times$28.6\nimprovement in communication efficiency.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Quyang Pan",
            "Sheng Sun",
            "Zhiyuan Wu",
            "Yuwei Wang",
            "Min Liu",
            "Bo Gao"
        ],
        "published": "2024-05-22T06:19:43Z"
    },
    {
        "title": "Kinematics of Abdominal Aortic Aneurysms",
        "link": "http://arxiv.org/abs/2405.13377v1",
        "abstract": "A search in Scopus within \"Article title, Abstract, Keywords\" unveils 2,444\ndocuments focused on the biomechanics of Abdominal Aortic Aneurysm (AAA),\nmostly on AAA wall stress. Only 24 documents investigated AAA kinematics, an\nimportant topic that could potentially offer insights into the biomechanics of\nAAA. In this paper, we present an image-based approach for patient-specific, in\nvivo, and non-invasive AAA kinematic analysis using patient's time-resolved 3D\ncomputed tomography angiography (4D CTA) images. Our approach relies on\nregularized deformable image registration for estimating wall displacement,\nestimation of the local wall strain as the ratio of its normal displacement to\nits local radius of curvature, and local surface fitting with non-deterministic\noutlier detection for estimating the wall radius of curvature. We verified our\napproach against synthetic ground truth image data created by warping a 3D CTA\nimage of AAA using a realistic displacement field obtained from a finite\nelement biomechanical model. We applied our approach to assess AAA wall\ndisplacements and strains in ten patients. Our kinematic analysis results\nindicated that the 99th percentile of circumferential wall strain, among all\npatients, ranged from 3.16% to 7.31%, with an average of 5.36% and a standard\ndeviation of 1.28%.",
        "subjects": [
            "cs.CE"
        ],
        "authors": [
            "Mostafa Jamshidian",
            "Adam Wittek",
            "Saeideh Sekhavat",
            "Karol Miller"
        ],
        "published": "2024-05-22T06:19:42Z"
    },
    {
        "title": "Markerless retro-identification complements re-identification of\n  individual insect subjects in archived image data of biological experiments",
        "link": "http://arxiv.org/abs/2405.13376v1",
        "abstract": "This study introduces markerless retro-identification of animals, a novel\nconcept and practical technique to identify past occurrences of organisms in\narchived data, that complements traditional forward-looking chronological\nre-identification methods in longitudinal behavioural research. Identification\nof a key individual among multiple subjects may occur late in an experiment if\nit reveals itself through interesting behaviour after a period of\nundifferentiated performance. Often, longitudinal studies also encounter\nsubject attrition during experiments. Effort invested in training software\nmodels to recognise and track such individuals is wasted if they fail to\ncomplete the experiment. Ideally, we would be able to select individuals who\nboth complete an experiment and/or differentiate themselves via interesting\nbehaviour, prior to investing computational resources in training image\nclassification software to recognise them. We propose retro-identification for\nmodel training to achieve this aim. This reduces manual annotation effort and\ncomputational resources by identifying subjects only after they differentiate\nthemselves late, or at an experiment's conclusion. Our study dataset comprises\nobservations made of morphologically similar reed bees (\\textit{Exoneura\nrobusta}) over five days. We evaluated model performance by training on final\nday five data, testing on the sequence of preceding days, and comparing results\nto the usual chronological evaluation from day one. Results indicate no\nsignificant accuracy difference between models. This underscores\nretro-identification's value in improving resource efficiency in longitudinal\nanimal studies.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Asaduz Zaman",
            "Vanessa Kellermann",
            "Alan Dorin"
        ],
        "published": "2024-05-22T06:19:22Z"
    },
    {
        "title": "Adaptive Data Analysis for Growing Data",
        "link": "http://arxiv.org/abs/2405.13375v1",
        "abstract": "Reuse of data in adaptive workflows poses challenges regarding overfitting\nand the statistical validity of results. Previous work has demonstrated that\ninteracting with data via differentially private algorithms can mitigate\noverfitting, achieving worst-case generalization guarantees with asymptotically\noptimal data requirements. However, such past work assumes data is static and\ncannot accommodate situations where data grows over time. In this paper we\naddress this gap, presenting the first generalization bounds for adaptive\nanalysis in the dynamic data setting. We allow the analyst to adaptively\nschedule their queries conditioned on the current size of the data, in addition\nto previous queries and responses. We also incorporate time-varying empirical\naccuracy bounds and mechanisms, allowing for tighter guarantees as data\naccumulates. In a batched query setting, the asymptotic data requirements of\nour bound grows with the square-root of the number of adaptive queries,\nmatching prior works' improvement over data splitting for the static setting.\nWe instantiate our bound for statistical queries with the clipped Gaussian\nmechanism, where it empirically outperforms baselines composed from static\nbounds.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Neil G. Marchant",
            "Benjamin I. P. Rubinstein"
        ],
        "published": "2024-05-22T06:17:58Z"
    },
    {
        "title": "Collaboration of Teachers for Semi-supervised Object Detection",
        "link": "http://arxiv.org/abs/2405.13374v1",
        "abstract": "Recent semi-supervised object detection (SSOD) has achieved remarkable\nprogress by leveraging unlabeled data for training. Mainstream SSOD methods\nrely on Consistency Regularization methods and Exponential Moving Average\n(EMA), which form a cyclic data flow. However, the EMA updating training\napproach leads to weight coupling between the teacher and student models. This\ncoupling in a cyclic data flow results in a decrease in the utilization of\nunlabeled data information and the confirmation bias on low-quality or\nerroneous pseudo-labels. To address these issues, we propose the Collaboration\nof Teachers Framework (CTF), which consists of multiple pairs of teacher and\nstudent models for training. In the learning process of CTF, the Data\nPerformance Consistency Optimization module (DPCO) informs the best pair of\nteacher models possessing the optimal pseudo-labels during the past training\nprocess, and these most reliable pseudo-labels generated by the best performing\nteacher would guide the other student models. As a consequence, this framework\ngreatly improves the utilization of unlabeled data and prevents the positive\nfeedback cycle of unreliable pseudo-labels. The CTF achieves outstanding\nresults on numerous SSOD datasets, including a 0.71% mAP improvement on the 10%\nannotated COCO dataset and a 0.89% mAP improvement on the VOC dataset compared\nto LabelMatch and converges significantly faster. Moreover, the CTF is\nplug-and-play and can be integrated with other mainstream SSOD methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Liyu Chen",
            "Huaao Tang",
            "Yi Wen",
            "Hanting Chen",
            "Wei Li",
            "Junchao Liu",
            "Jie Hu"
        ],
        "published": "2024-05-22T06:17:50Z"
    },
    {
        "title": "Ada-HGNN: Adaptive Sampling for Scalable Hypergraph Neural Networks",
        "link": "http://arxiv.org/abs/2405.13372v1",
        "abstract": "Hypergraphs serve as an effective model for depicting complex connections in\nvarious real-world scenarios, from social to biological networks. The\ndevelopment of Hypergraph Neural Networks (HGNNs) has emerged as a valuable\nmethod to manage the intricate associations in data, though scalability is a\nnotable challenge due to memory limitations. In this study, we introduce a new\nadaptive sampling strategy specifically designed for hypergraphs, which tackles\ntheir unique complexities in an efficient manner. We also present a Random\nHyperedge Augmentation (RHA) technique and an additional Multilayer Perceptron\n(MLP) module to improve the robustness and generalization capabilities of our\napproach. Thorough experiments with real-world datasets have proven the\neffectiveness of our method, markedly reducing computational and memory demands\nwhile maintaining performance levels akin to conventional HGNNs and other\nbaseline models. This research paves the way for improving both the scalability\nand efficacy of HGNNs in extensive applications. We will also make our codebase\npublicly accessible.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Shuai Wang",
            "David W. Zhang",
            "Jia-Hong Huang",
            "Stevan Rudinac",
            "Monika Kackovic",
            "Nachoem Wijnberg",
            "Marcel Worring"
        ],
        "published": "2024-05-22T06:15:50Z"
    },
    {
        "title": "Faster Vizing and Near-Vizing Edge Coloring Algorithms",
        "link": "http://arxiv.org/abs/2405.13371v1",
        "abstract": "Vizing's celebrated theorem states that every simple graph with maximum\ndegree $\\Delta$ admits a $(\\Delta+1)$ edge coloring which can be found in $O(m\n\\cdot n)$ time on $n$-vertex $m$-edge graphs. This is just one color more than\nthe trivial lower bound of $\\Delta$ colors needed in any proper edge coloring.\nAfter a series of simplifications and variations, this running time was\neventually improved by Gabow, Nishizeki, Kariv, Leven, and Terada in 1985 to\n$O(m\\sqrt{n\\log{n}})$ time. This has effectively remained the state-of-the-art\nmodulo an $O(\\sqrt{\\log{n}})$-factor improvement by Sinnamon in 2019.\n  As our main result, we present a novel randomized algorithm that computes a\n$\\Delta+O(\\log{n})$ coloring of any given simple graph in $O(m\\log{\\Delta})$\nexpected time; in other words, a near-linear time randomized algorithm for a\n``near''-Vizing's coloring.\n  As a corollary of this algorithm, we also obtain the following results:\n  * A randomized algorithm for $(\\Delta+1)$ edge coloring in $O(n^2\\log{n})$\nexpected time. This is near-linear in the input size for dense graphs and\npresents the first polynomial time improvement over the longstanding bounds of\nGabow et.al. for Vizing's theorem in almost four decades.\n  * A randomized algorithm for $(1+\\varepsilon) \\Delta$ edge coloring in\n$O(m\\log{(1/\\varepsilon)})$ expected time for any $\\varepsilon =\n\\omega(\\log{n}/\\Delta)$. The dependence on $\\varepsilon$ exponentially improves\nupon a series of recent results that obtain algorithms with runtime of\n$\\Omega(m/\\varepsilon)$ for this problem.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Sepehr Assadi"
        ],
        "published": "2024-05-22T06:14:59Z"
    },
    {
        "title": "Low-Resolution Chest X-ray Classification via Knowledge Distillation and\n  Multi-task Learning",
        "link": "http://arxiv.org/abs/2405.13370v1",
        "abstract": "This research addresses the challenges of diagnosing chest X-rays (CXRs) at\nlow resolutions, a common limitation in resource-constrained healthcare\nsettings. High-resolution CXR imaging is crucial for identifying small but\ncritical anomalies, such as nodules or opacities. However, when images are\ndownsized for processing in Computer-Aided Diagnosis (CAD) systems, vital\nspatial details and receptive fields are lost, hampering diagnosis accuracy. To\naddress this, this paper presents the Multilevel Collaborative Attention\nKnowledge (MLCAK) method. This approach leverages the self-attention mechanism\nof Vision Transformers (ViT) to transfer critical diagnostic knowledge from\nhigh-resolution images to enhance the diagnostic efficacy of low-resolution\nCXRs. MLCAK incorporates local pathological findings to boost model\nexplainability, enabling more accurate global predictions in a multi-task\nframework tailored for low-resolution CXR analysis. Our research, utilizing the\nVindr CXR dataset, shows a considerable enhancement in the ability to diagnose\ndiseases from low-resolution images (e.g. 28 x 28), suggesting a critical\ntransition from the traditional reliance on high-resolution imaging (e.g. 224 x\n224).",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Yasmeena Akhter",
            "Rishabh Ranjan",
            "Richa Singh",
            "Mayank Vatsa"
        ],
        "published": "2024-05-22T06:10:54Z"
    },
    {
        "title": "Static Deep Q-learning for Green Downlink C-RAN",
        "link": "http://arxiv.org/abs/2405.13368v1",
        "abstract": "Power saving is a main pillar in the operation of wireless communication\nsystems. In this paper, we investigate cloud radio access network (C-RAN)\ncapability to reduce power consumption based on the user equipment (UE)\nrequirement. Aiming to save the long-term C-RAN energy consumption, an\noptimization problem is formulated to manage the downlink power without\ndegrading the UE requirement by designing the power offset parameter.\nConsidering stochastic traffic arrivals at UEs, we first formulate the problem\nas a Markov decision process (MDP) and then set up a dual objective\noptimization problem in terms of the downlink throughput and power. To solve\nthis optimization problem, we develop a novel static deep Q-learning (SDQL)\nalgorithm to maximize the downlink throughput and minimize the downlink power.\nIn our proposed algorithm, we design multi-Q-tables to simultaneously optimize\npower reductions of activated RRHs by assigning one Q-table for each UE. To\nmaximize the accumulative reward in terms of the downlink throughput loss and\npower reduction, our proposed algorithm performs power reductions of activated\nRRHs through continuous environmental interactions. Simulation results1 show\nthat our proposed algorithm enjoys a superior average power reduction compared\nto the activation and sleep schemes, and enjoys a low computational complexity.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Yuchao Chang",
            "Hongli Wang",
            "Wen Chen",
            "Yonghui Li",
            "Naofal Al-Dhahir"
        ],
        "published": "2024-05-22T05:56:54Z"
    },
    {
        "title": "Anticipating Optical Availability in Hybrid RF/FSO Links Using RF\n  Beacons and Deep Learning",
        "link": "http://arxiv.org/abs/2405.13366v1",
        "abstract": "Radio frequency (RF) communications offer reliable but low data rates and\nenergy-inefficient satellite links, while free-space optical (FSO) promises\nhigh bandwidth but struggles with disturbances imposed by atmospheric effects.\nA hybrid RF/FSO architecture aims to achieve optimal reliability along with\nhigh data rates for space communications. Accurate prediction of dynamic\nground-to-satellite FSO link availability is critical for routing decisions in\nlow-earth orbit constellations. In this paper, we propose a system leveraging\nubiquitous RF links to proactively forecast FSO link degradation prior to\nsignal drops below threshold levels. This enables pre-calculation of rerouting\nto maximally maintain high data rate FSO links throughout the duration of\nweather effects. We implement a supervised learning model to anticipate FSO\nattenuation based on the analysis of RF patterns. Through the simulation of a\ndense lower earth orbit (LEO) satellite constellation, we demonstrate the\nefficacy of our approach in a simulated satellite network, highlighting the\nbalance between predictive accuracy and prediction duration. An emulated cloud\nattenuation model is proposed which provides insight into the temporal profiles\nof RF signals and their correlation to FSO channel dynamics. Our investigation\nsheds light on the trade-offs between prediction horizon and accuracy arising\nfrom RF beacon proximity, achieving a prediction accuracy of 86\\% with 16 RF\nbeacons.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Mostafa Ibrahim",
            "Arsalan Ahmad",
            "Sabit Ekin",
            "Peter LoPresti",
            "Serhat Altunc",
            "Obadiah Kegege",
            "John F. O'Hara"
        ],
        "published": "2024-05-22T05:52:56Z"
    },
    {
        "title": "Clipped Uniform Quantizers for Communication-Efficient Federated\n  Learning",
        "link": "http://arxiv.org/abs/2405.13365v1",
        "abstract": "This paper introduces an approach to employ clipped uniform quantization in\nfederated learning settings, aiming to enhance model efficiency by reducing\ncommunication overhead without compromising accuracy. By employing optimal\nclipping thresholds and adaptive quantization schemes, our method significantly\ncurtails the bit requirements for model weight transmissions between clients\nand the server. We explore the implications of symmetric clipping and uniform\nquantization on model performance, highlighting the utility of stochastic\nquantization to mitigate quantization artifacts and improve model robustness.\nThrough extensive simulations on the MNIST dataset, our results demonstrate\nthat the proposed method achieves near full-precision performance while\nensuring substantial communication savings. Specifically, our approach\nfacilitates efficient weight averaging based on quantization errors,\neffectively balancing the trade-off between communication efficiency and model\naccuracy. The comparative analysis with conventional quantization methods\nfurther confirms the superiority of our technique.",
        "subjects": [
            "cs.LG",
            "cs.MA",
            "eess.SP"
        ],
        "authors": [
            "Zavareh Bozorgasl",
            "Hao Chen"
        ],
        "published": "2024-05-22T05:48:25Z"
    },
    {
        "title": "LucidRaster: GPU Software Rasterizer for Exact Order-Independent\n  Transparency",
        "link": "http://arxiv.org/abs/2405.13364v1",
        "abstract": "Transparency rendering is problematic and can be considered an open problem\nin real-time graphics. There are many different algorithms currently available,\nbut handling complex scenes and achieving accurate, glitch-free results is\nstill costly.\n  This paper describes LucidRaster: a software rasterizer running on a GPU\nwhich allows for efficient exact rendering of complex transparent scenes. It\nuses a new two-stage sorting technique and sample accumulation method. On\naverage it's faster than high-quality OIT approximations and only about 3x\nslower than hardware alpha blending. It can be very efficient especially when\nrendering scenes with high triangle density or high depth complexity.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Krzysztof Jakubowski"
        ],
        "published": "2024-05-22T05:46:14Z"
    },
    {
        "title": "Lusifer: LLM-based User SImulated Feedback Environment for online\n  Recommender systems",
        "link": "http://arxiv.org/abs/2405.13362v1",
        "abstract": "Training reinforcement learning-based recommender systems are often hindered\nby the lack of dynamic and realistic user interactions. Lusifer, a novel\nenvironment leveraging Large Language Models (LLMs), addresses this limitation\nby generating simulated user feedback. It synthesizes user profiles and\ninteraction histories to simulate responses and behaviors toward recommended\nitems. In addition, user profiles are updated after each rating to reflect\nevolving user characteristics. Using the MovieLens100K dataset as proof of\nconcept, Lusifer demonstrates accurate emulation of user behavior and\npreferences. This paper presents Lusifer's operational pipeline, including\nprompt generation and iterative user profile updates. While validating\nLusifer's ability to produce realistic dynamic feedback, future research could\nutilize this environment to train reinforcement learning systems, offering a\nscalable and adjustable framework for user simulation in online recommender\nsystems.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "authors": [
            "Danial Ebrat",
            "Luis Rueda"
        ],
        "published": "2024-05-22T05:43:15Z"
    },
    {
        "title": "How to Trace Latent Generative Model Generated Images without Artificial\n  Watermark?",
        "link": "http://arxiv.org/abs/2405.13360v1",
        "abstract": "Latent generative models (e.g., Stable Diffusion) have become more and more\npopular, but concerns have arisen regarding potential misuse related to images\ngenerated by these models. It is, therefore, necessary to analyze the origin of\nimages by inferring if a particular image was generated by a specific latent\ngenerative model. Most existing methods (e.g., image watermark and model\nfingerprinting) require extra steps during training or generation. These\nrequirements restrict their usage on the generated images without such extra\noperations, and the extra required operations might compromise the quality of\nthe generated images. In this work, we ask whether it is possible to\neffectively and efficiently trace the images generated by a specific latent\ngenerative model without the aforementioned requirements. To study this\nproblem, we design a latent inversion based method called LatentTracer to trace\nthe generated images of the inspected model by checking if the examined images\ncan be well-reconstructed with an inverted latent input. We leverage gradient\nbased latent inversion and identify a encoder-based initialization critical to\nthe success of our approach. Our experiments on the state-of-the-art latent\ngenerative models, such as Stable Diffusion, show that our method can\ndistinguish the images generated by the inspected model and other images with a\nhigh accuracy and efficiency. Our findings suggest the intriguing possibility\nthat today's latent generative generated images are naturally watermarked by\nthe decoder used in the source models. Code:\nhttps://github.com/ZhentingWang/LatentTracer.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Zhenting Wang",
            "Vikash Sehwag",
            "Chen Chen",
            "Lingjuan Lyu",
            "Dimitris N. Metaxas",
            "Shiqing Ma"
        ],
        "published": "2024-05-22T05:33:47Z"
    },
    {
        "title": "AdpQ: A Zero-shot Calibration Free Adaptive Post Training Quantization\n  Method for LLMs",
        "link": "http://arxiv.org/abs/2405.13358v1",
        "abstract": "The ever-growing computational complexity of Large Language Models (LLMs)\nnecessitates efficient deployment strategies. The current state-of-the-art\napproaches for Post-training Quantization (PTQ) often require calibration to\nachieve the desired accuracy. This paper presents AdpQ, a novel zero-shot\nadaptive PTQ method for LLMs that achieves the state-of-the-art performance in\nlow-precision quantization (e.g. 3-bit) without requiring any calibration data.\nInspired by Adaptive LASSO regression model, our proposed approach tackles the\nchallenge of outlier activations by separating salient weights using an\nadaptive soft-thresholding method. Guided by Adaptive LASSO, this method\nensures that the quantized weights distribution closely follows the originally\ntrained weights and eliminates the need for calibration data entirely, setting\nour method apart from popular approaches such as SpQR and AWQ. Furthermore, our\nmethod offers an additional benefit in terms of privacy preservation by\neliminating any calibration or training data. We also delve deeper into the\ninformation-theoretic underpinnings of the proposed method. We demonstrate that\nit leverages the Adaptive LASSO to minimize the Kullback-Leibler divergence\nbetween the quantized weights and the originally trained weights. This\nminimization ensures the quantized model retains the Shannon information\ncontent of the original model to a great extent, guaranteeing efficient\ndeployment without sacrificing accuracy or information. Our results achieve the\nsame accuracy as the existing methods on various LLM benchmarks while the\nquantization time is reduced by at least 10x, solidifying our contribution to\nefficient and privacy-preserving LLM deployment.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Alireza Ghaffari",
            "Sharareh Younesian",
            "Vahid Partovi Nia",
            "Boxing Chen",
            "Masoud Asgharian"
        ],
        "published": "2024-05-22T05:32:11Z"
    },
    {
        "title": "Enhanced Creativity and Ideation through Stable Video Synthesis",
        "link": "http://arxiv.org/abs/2405.13357v1",
        "abstract": "This paper explores the innovative application of Stable Video Diffusion\n(SVD), a diffusion model that revolutionizes the creation of dynamic video\ncontent from static images. As digital media and design industries accelerate,\nSVD emerges as a powerful generative tool that enhances productivity and\nintroduces novel creative possibilities. The paper examines the technical\nunderpinnings of diffusion models, their practical effectiveness, and potential\nfuture developments, particularly in the context of video generation. SVD\noperates on a probabilistic framework, employing a gradual denoising process to\ntransform random noise into coherent video frames. It addresses the challenges\nof visual consistency, natural movement, and stylistic reflection in generated\nvideos, showcasing high generalization capabilities. The integration of SVD in\ndesign tasks promises enhanced creativity, rapid prototyping, and significant\ntime and cost efficiencies. It is particularly impactful in areas requiring\nframe-to-frame consistency, natural motion capture, and creative diversity,\nsuch as animation, visual effects, advertising, and educational content\ncreation. The paper concludes that SVD is a catalyst for design innovation,\noffering a wide array of applications and a promising avenue for future\nresearch and development in the field of digital media and design.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Elijah Miller",
            "Thomas Dupont",
            "Mingming Wang"
        ],
        "published": "2024-05-22T05:23:14Z"
    },
    {
        "title": "Large Language Models (LLMs) Assisted Wireless Network Deployment in\n  Urban Settings",
        "link": "http://arxiv.org/abs/2405.13356v1",
        "abstract": "The advent of Large Language Models (LLMs) has revolutionized language\nunderstanding and human-like text generation, drawing interest from many other\nfields with this question in mind: What else are the LLMs capable of? Despite\ntheir widespread adoption, ongoing research continues to explore new ways to\nintegrate LLMs into diverse systems.\n  This paper explores new techniques to harness the power of LLMs for 6G (6th\nGeneration) wireless communication technologies, a domain where automation and\nintelligent systems are pivotal. The inherent adaptability of LLMs to\ndomain-specific tasks positions them as prime candidates for enhancing wireless\nsystems in the 6G landscape.\n  We introduce a novel Reinforcement Learning (RL) based framework that\nleverages LLMs for network deployment in wireless communications. Our approach\ninvolves training an RL agent, utilizing LLMs as its core, in an urban setting\nto maximize coverage. The agent's objective is to navigate the complexities of\nurban environments and identify the network parameters for optimal area\ncoverage. Additionally, we integrate LLMs with Convolutional Neural Networks\n(CNNs) to capitalize on their strengths while mitigating their limitations. The\nDeep Deterministic Policy Gradient (DDPG) algorithm is employed for training\npurposes. The results suggest that LLM-assisted models can outperform CNN-based\nmodels in some cases while performing at least as well in others.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Nurullah Sevim",
            "Mostafa Ibrahim",
            "Sabit Ekin"
        ],
        "published": "2024-05-22T05:19:51Z"
    },
    {
        "title": "\"Turing Tests\" For An AI Scientist",
        "link": "http://arxiv.org/abs/2405.13352v1",
        "abstract": "While LLMs have shown impressive capabilities in solving math or coding\nproblems, the ability to make scientific discoveries remains a distinct\nchallenge. This paper proposes a \"Turing test for an AI scientist\" to assess\nwhether an AI agent can conduct scientific research independently, without\nrelying on human-generated knowledge. Drawing inspiration from the historical\ndevelopment of science, we propose seven benchmark tests that evaluate an AI\nagent's ability to make groundbreaking discoveries in various scientific\ndomains. These tests include inferring the heliocentric model from celestial\nobservations, discovering the laws of motion in a simulated environment,\nderiving the differential equation governing vibrating strings, inferring\nMaxwell's equations from electrodynamics simulations, inventing numerical\nmethods for initial value problems, discovering Huffman coding for data\ncompression, and developing efficient sorting algorithms. To ensure the\nvalidity of these tests, the AI agent is provided with interactive libraries or\ndatasets specific to each problem, without access to human knowledge that could\npotentially contain information about the target discoveries. The ultimate goal\nis to create an AI scientist capable of making novel and impactful scientific\ndiscoveries, surpassing the best human experts in their respective fields.\nThese \"Turing tests\" serve as intermediate milestones, assessing the AI agent's\nability to make discoveries that were groundbreaking in their time. If an AI\nagent can pass the majority of these seven tests, it would indicate significant\nprogress towards building an AI scientist, paving the way for future\nadvancements in autonomous scientific discovery. This paper aims to establish a\nbenchmark for the capabilities of AI in scientific research and to stimulate\nfurther research in this exciting field.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Xiaoxin Yin"
        ],
        "published": "2024-05-22T05:14:27Z"
    },
    {
        "title": "Quantum (Inspired) $D^2$-sampling with Applications",
        "link": "http://arxiv.org/abs/2405.13351v1",
        "abstract": "$D^2$-sampling is a fundamental component of sampling-based clustering\nalgorithms such as $k$-means++. Given a dataset $V \\subset \\mathbb{R}^d$ with\n$N$ points and a center set $C \\subset \\mathbb{R}^d$, $D^2$-sampling refers to\npicking a point from $V$ where the sampling probability of a point is\nproportional to its squared distance from the nearest center in $C$. Starting\nwith empty $C$ and iteratively $D^2$-sampling and updating $C$ in $k$ rounds is\nprecisely $k$-means++ seeding that runs in $O(Nkd)$ time and gives\n$O(\\log{k})$-approximation in expectation for the $k$-means problem. We give a\nquantum algorithm for (approximate) $D^2$-sampling in the QRAM model that\nresults in a quantum implementation of $k$-means++ that runs in time\n$\\tilde{O}(\\zeta^2 k^2)$. Here $\\zeta$ is the aspect ratio (i.e., largest to\nsmallest interpoint distance), and $\\tilde{O}$ hides polylogarithmic factors in\n$N, d, k$. It can be shown through a robust approximation analysis of\n$k$-means++ that the quantum version preserves its $O(\\log{k})$ approximation\nguarantee. Further, we show that our quantum algorithm for $D^2$-sampling can\nbe 'dequantized' using the sample-query access model of Tang (PhD Thesis, Ewin\nTang, University of Washington, 2023). This results in a fast quantum-inspired\nclassical implementation of $k$-means++, which we call QI-$k$-means++, with a\nrunning time $O(Nd) + \\tilde{O}(\\zeta^2k^2d)$, where the $O(Nd)$ term is for\nsetting up the sample-query access data structure. Experimental investigations\nshow promising results for QI-$k$-means++ on large datasets with bounded aspect\nratio. Finally, we use our quantum $D^2$-sampling with the known $\nD^2$-sampling-based classical approximation scheme (i.e.,\n$(1+\\varepsilon)$-approximation for any given $\\varepsilon>0$) to obtain the\nfirst quantum approximation scheme for the $k$-means problem with\npolylogarithmic running time dependence on $N$.",
        "subjects": [
            "quant-ph",
            "cs.DS"
        ],
        "authors": [
            "Ragesh Jaiswal",
            "Poojan Shah"
        ],
        "published": "2024-05-22T05:13:28Z"
    },
    {
        "title": "Efficacy of ByteT5 in Multilingual Translation of Biblical Texts for\n  Underrepresented Languages",
        "link": "http://arxiv.org/abs/2405.13350v1",
        "abstract": "This study presents the development and evaluation of a ByteT5-based\nmultilingual translation model tailored for translating the Bible into\nunderrepresented languages. Utilizing the comprehensive Johns Hopkins\nUniversity Bible Corpus, we trained the model to capture the intricate nuances\nof character-based and morphologically rich languages. Our results, measured by\nthe BLEU score and supplemented with sample translations, suggest the model can\nimprove accessibility to sacred texts. It effectively handles the distinctive\nbiblical lexicon and structure, thus bridging the linguistic divide. The study\nalso discusses the model's limitations and suggests pathways for future\nenhancements, focusing on expanding access to sacred literature across\nlinguistic boundaries.",
        "subjects": [
            "cs.CL",
            "cs.LG",
            "I.2.7"
        ],
        "authors": [
            "Corinne Aars",
            "Lauren Adams",
            "Xiaokan Tian",
            "Zhaoyu Wang",
            "Colton Wismer",
            "Jason Wu",
            "Pablo Rivas",
            "Korn Sooksatra",
            "Matthew Fendt"
        ],
        "published": "2024-05-22T05:12:35Z"
    },
    {
        "title": "Building a Verifiable Logical Clock for P2P Networks",
        "link": "http://arxiv.org/abs/2405.13349v1",
        "abstract": "Logical clocks are a fundamental tool to establish causal ordering of events\nin a distributed system. They have been applied in weakly consistent storage\nsystems, causally ordered broadcast, distributed snapshots, deadlock detection,\nand distributed system debugging. However, prior logical clock constructs fail\nto work in an open network with Byzantine participants. In this work, we\npresent Chrono, a novel logical clock system that targets such challenging\nenvironment. We first redefine causality properties among distributed processes\nunder the Byzantine failure model. To enforce these properties, Chrono defines\na new validator abstraction for building fault-tolerant logical clocks.\nFurthermore, our validator abstraction is customizable: Chrono includes\nmultiple backend implementations for the abstraction, each with different\nsecurity-performance trade-offs. We have applied Chrono to build two\ndecentralized applications, a mutual exclusive service and a weakly consistent\nkey-value store. Chrono adds only marginal overhead compared to systems that\ntolerate no Byzantine faults. It also out-performs state-of-the-art BFT total\norder protocols by significant margins.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Guangda Sun",
            "Tianyang Tao",
            "Yanpei Guo",
            "Michael Yiqing Hu",
            "Jialin Li"
        ],
        "published": "2024-05-22T05:10:59Z"
    },
    {
        "title": "On the Challenges of Creating Datasets for Analyzing Commercial Sex\n  Advertisements to Assess Human Trafficking Risk and Organized Activity",
        "link": "http://arxiv.org/abs/2405.13348v1",
        "abstract": "Our study addresses the challenges of building datasets to understand the\nrisks associated with organized activities and human trafficking through\ncommercial sex advertisements. These challenges include data scarcity, rapid\nobsolescence, and privacy concerns. Traditional approaches, which are not\nautomated and are difficult to reproduce, fall short in addressing these\nissues. We have developed a reproducible and automated methodology to analyze\nfive million advertisements. In the process, we identified further challenges\nin dataset creation within this sensitive domain. This paper presents a\nstreamlined methodology to assist researchers in constructing effective\ndatasets for combating organized crime, allowing them to focus on advancing\ndetection technologies.",
        "subjects": [
            "cs.LG",
            "I.2.7"
        ],
        "authors": [
            "Pablo Rivas",
            "Tomas Cerny",
            "Alejandro Rodriguez Perez",
            "Javier Turek",
            "Laurie Giddens",
            "Gisela Bichler",
            "Stacie Petter"
        ],
        "published": "2024-05-22T05:10:13Z"
    },
    {
        "title": "Time-Series Forecasting and Sequence Learning Using Memristor-based\n  Reservoir System",
        "link": "http://arxiv.org/abs/2405.13347v1",
        "abstract": "Pushing the frontiers of time-series information processing in ever-growing\nedge devices with stringent resources has been impeded by the system's ability\nto process information and learn locally on the device. Local processing and\nlearning typically demand intensive computations and massive storage as the\nprocess involves retrieving information and tuning hundreds of parameters back\nin time. In this work, we developed a memristor-based echo state network\naccelerator that features efficient temporal data processing and in-situ online\nlearning. The proposed design is benchmarked using various datasets involving\nreal-world tasks, such as forecasting the load energy consumption and weather\nconditions. The experimental results illustrate that the hardware model\nexperiences a marginal degradation (~4.8%) in performance as compared to the\nsoftware model. This is mainly attributed to the limited precision and dynamic\nrange of network parameters when emulated using memristor devices. The proposed\nsystem is evaluated for lifespan, robustness, and energy-delay product. It is\nobserved that the system demonstrates a reasonable robustness for device\nfailure below 10%, which may occur due to stuck-at faults. Furthermore, 246X\nreduction in energy consumption is achieved when compared to a custom CMOS\ndigital design implemented at the same technology node.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.AR"
        ],
        "authors": [
            "Abdullah M. Zyarah",
            "Dhireesha Kudithipudi"
        ],
        "published": "2024-05-22T05:07:56Z"
    },
    {
        "title": "Autonomous Algorithm for Training Autonomous Vehicles with Minimal Human\n  Intervention",
        "link": "http://arxiv.org/abs/2405.13345v1",
        "abstract": "Reinforcement learning (RL) provides a compelling framework for enabling\nautonomous vehicles to continue to learn and improve diverse driving behaviors\non their own. However, training real-world autonomous vehicles with current RL\nalgorithms presents several challenges. One critical challenge, often\noverlooked in these algorithms, is the need to reset a driving environment\nbetween every episode. While resetting an environment after each episode is\ntrivial in simulated settings, it demands significant human intervention in the\nreal world. In this paper, we introduce a novel autonomous algorithm that\nallows off-the-shelf RL algorithms to train an autonomous vehicle with minimal\nhuman intervention. Our algorithm takes into account the learning progress of\nthe autonomous vehicle to determine when to abort episodes before it enters\nunsafe states and where to reset it for subsequent episodes in order to gather\ninformative transitions. The learning progress is estimated based on the\nnovelty of both current and future states. We also take advantage of rule-based\nautonomous driving algorithms to safely reset an autonomous vehicle to an\ninitial state. We evaluate our algorithm against baselines on diverse urban\ndriving tasks. The experimental results show that our algorithm is\ntask-agnostic and achieves better driving performance with fewer manual resets\nthan baselines.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "authors": [
            "Sang-Hyun Lee",
            "Daehyeok Kwon",
            "Seung-Woo Seo"
        ],
        "published": "2024-05-22T05:04:44Z"
    },
    {
        "title": "Contextualized Automatic Speech Recognition with Dynamic Vocabulary",
        "link": "http://arxiv.org/abs/2405.13344v1",
        "abstract": "Deep biasing (DB) improves the performance of end-to-end automatic speech\nrecognition (E2E-ASR) for rare words or contextual phrases using a bias list.\nHowever, most existing methods treat bias phrases as sequences of subwords in a\npredefined static vocabulary, which can result in ineffective learning of the\ndependencies between subwords. More advanced techniques address this problem by\nincorporating additional text data, which increases the overall workload. This\npaper proposes a dynamic vocabulary where phrase-level bias tokens can be added\nduring the inference phase. Each bias token represents an entire bias phrase\nwithin a single token, thereby eliminating the need to learn the dependencies\nbetween the subwords within the bias phrases. This method can be applied to\nvarious architectures because it only extends the embedding and output layers\nin common E2E-ASR architectures. Experimental results demonstrate that the\nproposed method improves the performance of bias phrases on English and\nJapanese datasets.",
        "subjects": [
            "eess.AS",
            "cs.CL",
            "cs.SD"
        ],
        "authors": [
            "Yui Sudo",
            "Yosuke Fukumoto",
            "Muhammad Shakeel",
            "Yifan Peng",
            "Shinji Watanabe"
        ],
        "published": "2024-05-22T05:03:39Z"
    },
    {
        "title": "Average sensitivity of the Knapsack Problem",
        "link": "http://arxiv.org/abs/2405.13343v1",
        "abstract": "In resource allocation, we often require that the output allocation of an\nalgorithm is stable against input perturbation because frequent reallocation is\ncostly and untrustworthy. Varma and Yoshida (SODA'21) formalized this\nrequirement for algorithms as the notion of average sensitivity. Here, the\naverage sensitivity of an algorithm on an input instance is, roughly speaking,\nthe average size of the symmetric difference of the output for the instance and\nthat for the instance with one item deleted, where the average is taken over\nthe deleted item.\n  In this work, we consider the average sensitivity of the knapsack problem, a\nrepresentative example of a resource allocation problem. We first show a\n$(1-\\epsilon)$-approximation algorithm for the knapsack problem with average\nsensitivity $O(\\epsilon^{-1}\\log \\epsilon^{-1})$. Then, we complement this\nresult by showing that any $(1-\\epsilon)$-approximation algorithm has average\nsensitivity $\\Omega(\\epsilon^{-1})$. As an application of our algorithm, we\nconsider the incremental knapsack problem in the random-order setting, where\nthe goal is to maintain a good solution while items arrive one by one in a\nrandom order. Specifically, we show that for any $\\epsilon > 0$, there exists a\n$(1-\\epsilon)$-approximation algorithm with amortized recourse\n$O(\\epsilon^{-1}\\log \\epsilon^{-1})$ and amortized update time $O(\\log\nn+f_\\epsilon)$, where $n$ is the total number of items and $f_\\epsilon>0$ is a\nvalue depending on $\\epsilon$.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Soh Kumabe",
            "Yuichi Yoshida"
        ],
        "published": "2024-05-22T04:59:53Z"
    },
    {
        "title": "Wealth inequality and utility: Effect evaluation of redistribution and\n  consumption morals using macro-econophysical coupled approach",
        "link": "http://arxiv.org/abs/2405.13341v1",
        "abstract": "Reducing wealth inequality and increasing utility are critical issues. This\nstudy reveals the effects of redistribution and consumption morals on wealth\ninequality and utility. To this end, we present a novel approach that couples\nthe dynamic model of capital, consumption, and utility in macroeconomics with\nthe interaction model of joint business and redistribution in econophysics.\nWith this approach, we calculate the capital (wealth), the utility based on\nconsumption, and the Gini index of these inequality using redistribution and\nconsumption thresholds as moral parameters. The results show that:\nunder-redistribution and waste exacerbate inequality; conversely,\nover-redistribution and stinginess reduce utility; and a balanced moderate\nmoral leads to achieve both reduced inequality and increased utility. These\nfindings provide renewed economic and numerical support for the moral\nimportance known from philosophy, anthropology, and religion. The revival of\nredistribution and consumption morals should promote the transformation to a\nhuman mutual-aid economy, as indicated by philosopher and anthropologist,\ninstead of the capitalist economy that has produced the current inequality. The\npractical challenge is to implement bottom-up social business, on a foothold of\nworker coops and platform cooperatives as a community against the state and the\nmarket, with moral consensus and its operation.",
        "subjects": [
            "econ.GN",
            "cs.MA",
            "physics.soc-ph",
            "q-fin.EC",
            "91B64, 91B24, 91B55, 91B43",
            "J.4"
        ],
        "authors": [
            "Takeshi Kato",
            "Mohammad Rezoanul Hoque"
        ],
        "published": "2024-05-22T04:53:21Z"
    },
    {
        "title": "Randomized block coordinate descent method for linear ill-posed problems",
        "link": "http://arxiv.org/abs/2405.13340v1",
        "abstract": "Consider the linear ill-posed problems of the form $\\sum_{i=1}^{b} A_i x_i\n=y$, where, for each $i$, $A_i$ is a bounded linear operator between two\nHilbert spaces $X_i$ and ${\\mathcal Y}$. When $b$ is huge, solving the problem\nby an iterative method using the full gradient at each iteration step is both\ntime-consuming and memory insufficient. Although randomized block coordinate\ndecent (RBCD) method has been shown to be an efficient method for well-posed\nlarge-scale optimization problems with a small amount of memory, there still\nlacks a convergence analysis on the RBCD method for solving ill-posed problems.\nIn this paper, we investigate the convergence property of the RBCD method with\nnoisy data under either {\\it a priori} or {\\it a posteriori} stopping rules. We\nprove that the RBCD method combined with an {\\it a priori} stopping rule yields\na sequence that converges weakly to a solution of the problem almost surely. We\nalso consider the early stopping of the RBCD method and demonstrate that the\ndiscrepancy principle can terminate the iteration after finite many steps\nalmost surely. For a class of ill-posed problems with special tensor product\nform, we obtain strong convergence results on the RBCD method. Furthermore, we\nconsider incorporating the convex regularization terms into the RBCD method to\nenhance the detection of solution features. To illustrate the theory and the\nperformance of the method, numerical simulations from the imaging modalities in\ncomputed tomography and compressive temporal imaging are reported.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "math.OC",
            "65J20, 65J22, 65J10, 94A08"
        ],
        "authors": [
            "Qinian Jin",
            "Duo Liu"
        ],
        "published": "2024-05-22T04:52:44Z"
    },
    {
        "title": "Semantic Equitable Clustering: A Simple, Fast and Effective Strategy for\n  Vision Transformer",
        "link": "http://arxiv.org/abs/2405.13337v1",
        "abstract": "The Vision Transformer (ViT) has gained prominence for its superior\nrelational modeling prowess. However, its global attention mechanism's\nquadratic complexity poses substantial computational burdens. A common remedy\nspatially groups tokens for self-attention, reducing computational\nrequirements. Nonetheless, this strategy neglects semantic information in\ntokens, possibly scattering semantically-linked tokens across distinct groups,\nthus compromising the efficacy of self-attention intended for modeling\ninter-token dependencies. Motivated by these insights, we introduce a fast and\nbalanced clustering method, named \\textbf{S}emantic \\textbf{E}quitable\n\\textbf{C}lustering (SEC). SEC clusters tokens based on their global semantic\nrelevance in an efficient, straightforward manner. In contrast to traditional\nclustering methods requiring multiple iterations, our method achieves token\nclustering in a single pass. Additionally, SEC regulates the number of tokens\nper cluster, ensuring a balanced distribution for effective parallel processing\non current computational platforms without necessitating further optimization.\nCapitalizing on SEC, we propose a versatile vision backbone, SecViT.\nComprehensive experiments in image classification, object detection, instance\nsegmentation, and semantic segmentation validate to the effectiveness of\nSecViT. Remarkably, SecViT attains an impressive \\textbf{84.2\\%} image\nclassification accuracy with only \\textbf{27M} parameters and \\textbf{4.4G}\nFLOPs, without the need for for additional supervision or data. Code will be\navailable at \\url{https://github.com/qhfan/SecViT}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Qihang Fan",
            "Huaibo Huang",
            "Mingrui Chen",
            "Ran He"
        ],
        "published": "2024-05-22T04:49:00Z"
    },
    {
        "title": "SIGGesture: Generalized Co-Speech Gesture Synthesis via Semantic\n  Injection with Large-Scale Pre-Training Diffusion Models",
        "link": "http://arxiv.org/abs/2405.13336v1",
        "abstract": "The automated synthesis of high-quality 3D gestures from speech is of\nsignificant value in virtual humans and gaming. Previous methods focus on\nsynthesizing gestures that are synchronized with speech rhythm, yet they\nfrequently overlook the inclusion of semantic gestures. These are sparse and\nfollow a long-tailed distribution across the gesture sequence, making them\ndifficult to learn in an end-to-end manner. Moreover, generating gestures,\nrhythmically aligned with speech, faces a significant issue that cannot be\ngeneralized to in-the-wild speeches. To address these issues, we introduce\nSIGGesture, a novel diffusion-based approach for synthesizing realistic\ngestures that are of both high quality and semantically pertinent.\nSpecifically, we firstly build a strong diffusion-based foundation model for\nrhythmical gesture synthesis by pre-training it on a collected large-scale\ndataset with pseudo labels. Secondly, we leverage the powerful generalization\ncapabilities of Large Language Models (LLMs) to generate proper semantic\ngestures for the various speech content. Finally, we propose a semantic\ninjection module to infuse semantic information into the synthesized results\nduring diffusion reverse process. Extensive experiments demonstrate that the\nproposed SIGGesture significantly outperforms existing baselines and shows\nexcellent generalization and controllability.",
        "subjects": [
            "cs.HC",
            "I.2.6"
        ],
        "authors": [
            "Qingrong Cheng",
            "Xu Li",
            "Xinghui Fu"
        ],
        "published": "2024-05-22T04:47:49Z"
    },
    {
        "title": "Vision Transformer with Sparse Scan Prior",
        "link": "http://arxiv.org/abs/2405.13335v1",
        "abstract": "In recent years, Transformers have achieved remarkable progress in computer\nvision tasks. However, their global modeling often comes with substantial\ncomputational overhead, in stark contrast to the human eye's efficient\ninformation processing. Inspired by the human eye's sparse scanning mechanism,\nwe propose a \\textbf{S}parse \\textbf{S}can \\textbf{S}elf-\\textbf{A}ttention\nmechanism ($\\rm{S}^3\\rm{A}$). This mechanism predefines a series of Anchors of\nInterest for each token and employs local attention to efficiently model the\nspatial information around these anchors, avoiding redundant global modeling\nand excessive focus on local information. This approach mirrors the human eye's\nfunctionality and significantly reduces the computational load of vision\nmodels. Building on $\\rm{S}^3\\rm{A}$, we introduce the \\textbf{S}parse\n\\textbf{S}can \\textbf{Vi}sion \\textbf{T}ransformer (SSViT). Extensive\nexperiments demonstrate the outstanding performance of SSViT across a variety\nof tasks. Specifically, on ImageNet classification, without additional\nsupervision or training data, SSViT achieves top-1 accuracies of\n\\textbf{84.4\\%/85.7\\%} with \\textbf{4.4G/18.2G} FLOPs. SSViT also excels in\ndownstream tasks such as object detection, instance segmentation, and semantic\nsegmentation. Its robustness is further validated across diverse datasets. Code\nwill be available at \\url{https://github.com/qhfan/SSViT}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Qihang Fan",
            "Huaibo Huang",
            "Mingrui Chen",
            "Ran He"
        ],
        "published": "2024-05-22T04:34:36Z"
    },
    {
        "title": "Service Mesh: Architectures, Applications, and Implementations",
        "link": "http://arxiv.org/abs/2405.13333v1",
        "abstract": "The scalability and flexibility of microservice architecture have led to\nmajor changes in cloud-native application architectures. However, the\ncomplexity of managing thousands of small services written in different\nlanguages and handling the exchange of data between them have caused\nsignificant management challenges. Service mesh is a promising solution that\ncould mitigate these problems by introducing an overlay layer on top of the\nservices. In this paper, we first study the architecture and components of\nservice mesh architecture. Then, we review two important service mesh\nimplementations and discuss how the service mesh could be helpful in other\nareas, including 5G.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Behrooz Farkiani",
            "Raj Jain"
        ],
        "published": "2024-05-22T04:27:36Z"
    },
    {
        "title": "Comparative Analysis of Hyperspectral Image Reconstruction Using Deep\n  Learning for Agricultural and Biological Applications",
        "link": "http://arxiv.org/abs/2405.13331v1",
        "abstract": "Hyperspectral imaging (HSI) has become a key technology for non-invasive\nquality evaluation in various fields, offering detailed insights through\nspatial and spectral data. Despite its efficacy, the complexity and high cost\nof HSI systems have hindered their widespread adoption. This study addressed\nthese challenges by exploring deep learning-based hyperspectral image\nreconstruction from RGB (Red, Green, Blue) images, particularly for\nagricultural products. Specifically, different hyperspectral reconstruction\nalgorithms, such as Hyperspectral Convolutional Neural Network - Dense\n(HSCNN-D), High-Resolution Network (HRNET), and Multi-Scale Transformer Plus\nPlus (MST++), were compared to assess the dry matter content of sweet potatoes.\nAmong the tested reconstruction methods, HRNET demonstrated superior\nperformance, achieving the lowest mean relative absolute error (MRAE) of 0.07,\nroot mean square error (RMSE) of 0.03, and the highest peak signal-to-noise\nratio (PSNR) of 32.28 decibels (dB). Some key features were selected using the\ngenetic algorithm (GA), and their importance was interpreted using explainable\nartificial intelligence (XAI). Partial least squares regression (PLSR) models\nwere developed using the RGB, reconstructed, and ground truth (GT) data. The\nvisual and spectra quality of these reconstructed methods was compared with GT\ndata, and predicted maps were generated. The results revealed the prospect of\ndeep learning-based hyperspectral image reconstruction as a cost-effective and\nefficient quality assessment tool for agricultural and biological applications.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Md. Toukir Ahmed",
            "Mohammed Kamruzzaman"
        ],
        "published": "2024-05-22T04:20:30Z"
    },
    {
        "title": "High Performance P300 Spellers Using GPT2 Word Prediction With\n  Cross-Subject Training",
        "link": "http://arxiv.org/abs/2405.13329v1",
        "abstract": "Amyotrophic lateral sclerosis (ALS) severely impairs patients' ability to\ncommunicate, often leading to a decline in their quality of life within a few\nyears of diagnosis. The P300 speller brain-computer interface (BCI) offers an\nalternative communication method by interpreting a subject's EEG response to\ncharacters presented on a grid interface.\n  This paper addresses the common speed limitations encountered in training\nefficient P300-based multi-subject classifiers by introducing innovative\n\"across-subject\" classifiers. We leverage a combination of the\nsecond-generation Generative Pre-Trained Transformer (GPT2) and Dijkstra's\nalgorithm to optimize stimuli and suggest word completion choices based on\ntyping history. Additionally, we employ a multi-layered smoothing technique to\naccommodate out-of-vocabulary (OOV) words.\n  Through extensive simulations involving random sampling of EEG data from\nsubjects, we demonstrate significant speed enhancements in typing passages\ncontaining rare and OOV words. These optimizations result in approximately 10%\nimprovement in character-level typing speed and up to 40% improvement in\nmulti-word prediction. We demonstrate that augmenting standard row/column\nhighlighting techniques with layered word prediction yields close-to-optimal\nperformance.\n  Furthermore, we explore both \"within-subject\" and \"across-subject\" training\ntechniques, showing that speed improvements are consistent across both\napproaches.",
        "subjects": [
            "cs.CL",
            "cs.HC",
            "cs.SY",
            "eess.SP",
            "eess.SY"
        ],
        "authors": [
            "Nithin Parthasarathy",
            "James Soetedjo",
            "Saarang Panchavati",
            "Nitya Parthasarathy",
            "Corey Arnold",
            "Nader Pouratian",
            "William Speier"
        ],
        "published": "2024-05-22T04:15:41Z"
    },
    {
        "title": "Mosaic IT: Enhancing Instruction Tuning with Data Mosaics",
        "link": "http://arxiv.org/abs/2405.13326v1",
        "abstract": "Finetuning large language models with a variety of instruction-response pairs\nhas enhanced their capability to understand and follow instructions. Current\ninstruction tuning primarily relies on teacher models or human intervention to\ngenerate and refine the instructions and responses, which are costly,\nnon-sustainable, and may lack diversity. In this paper, we introduce Mosaic\nInstruction Tuning (Mosaic-IT), a human/model-free method that can efficiently\ncreate rich and diverse augmentations from existing instruction tuning data to\nenhance the finetuned LLM.Mosaic-IT randomly concatenates multiple instruction\ndata into one and trains the model to produce the corresponding responses with\npredefined higher-level meta-instructions to strengthen its multi-step\ninstruction-following and format-following skills. Our extensive evaluations\ndemonstrate a superior performance and training efficiency of Mosaic-IT, which\nachieves consistent performance improvements over various benchmarks and an 80%\nreduction in training costs compared with original instruction tuning. Our\ncodes and data are available at https://github.com/tianyi-lab/Mosaic-IT.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Ming Li",
            "Pei Chen",
            "Chenguang Wang",
            "Hongyu Zhao",
            "Yijun Liang",
            "Yupeng Hou",
            "Fuxiao Liu",
            "Tianyi Zhou"
        ],
        "published": "2024-05-22T04:08:20Z"
    },
    {
        "title": "DEGAP: Dual Event-Guided Adaptive Prefixes for Templated-Based Event\n  Argument Extraction Model with Slot Querying",
        "link": "http://arxiv.org/abs/2405.13325v1",
        "abstract": "Recent advancements in event argument extraction (EAE) involve incorporating\nbeneficial auxiliary information into models during training and inference,\nsuch as retrieved instances and event templates. Additionally, some studies\nintroduce learnable prefix vectors to models. These methods face three\nchallenges: (1) insufficient utilization of relevant event instances due to\ndeficiencies in retrieval; (2) neglect of important information provided by\nrelevant event templates; (3) the advantages of prefixes are constrained due to\ntheir inability to meet the specific informational needs of EAE. In this work,\nwe propose DEGAP, which addresses the above challenges through two simple yet\neffective components: (1) dual prefixes, where the instance-oriented prefix and\ntemplate-oriented prefix are trained to learn information from different event\ninstances and templates, respectively, and then provide relevant information as\ncues to EAE model without retrieval; (2) event-guided adaptive gating\nmechanism, which guides the prefixes based on the target event to fully\nleverage their advantages. Extensive experiments demonstrate that our method\nachieves new state-of-the-art performance on four datasets (ACE05, RAMS,\nWIKIEVENTS, and MLEE). Further analysis verifies the importance of the proposed\ndesign and the effectiveness of the main components.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "authors": [
            "Guanghui Wang",
            "Dexi Liu",
            "Qizhi Wan",
            "Xiping Liu",
            "Wanlong Liu"
        ],
        "published": "2024-05-22T03:56:55Z"
    },
    {
        "title": "Adversarial Training via Adaptive Knowledge Amalgamation of an Ensemble\n  of Teachers",
        "link": "http://arxiv.org/abs/2405.13324v1",
        "abstract": "Adversarial training (AT) is a popular method for training robust deep neural\nnetworks (DNNs) against adversarial attacks. Yet, AT suffers from two\nshortcomings: (i) the robustness of DNNs trained by AT is highly intertwined\nwith the size of the DNNs, posing challenges in achieving robustness in smaller\nmodels; and (ii) the adversarial samples employed during the AT process exhibit\npoor generalization, leaving DNNs vulnerable to unforeseen attack types. To\naddress these dual challenges, this paper introduces adversarial training via\nadaptive knowledge amalgamation of an ensemble of teachers (AT-AKA). In\nparticular, we generate a diverse set of adversarial samples as the inputs to\nan ensemble of teachers; and then, we adaptively amalgamate the logtis of these\nteachers to train a generalized-robust student. Through comprehensive\nexperiments, we illustrate the superior efficacy of AT-AKA over existing AT\nmethods and adversarial robustness distillation techniques against cutting-edge\nattacks, including AutoAttack.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Shayan Mohajer Hamidi",
            "Linfeng Ye"
        ],
        "published": "2024-05-22T03:47:55Z"
    },
    {
        "title": "Self-dual 2-quasi Negacyclic Codes over Finite Fields",
        "link": "http://arxiv.org/abs/2405.13320v1",
        "abstract": "In this paper, we investigate the existence and asymptotic property of\nself-dual $2$-quasi negacyclic codes of length $2n$ over a finite field of\ncardinality $q$. When $n$ is odd, we show that the $q$-ary self-dual $2$-quasi\nnegacyclic codes exist if and only if $q\\,{\\not\\equiv}-\\!1~({\\rm mod}~4)$. When\n$n$ is even, we prove that the $q$-ary self-dual $2$-quasi negacyclic codes\nalways exist. By using the technique introduced in this paper, we prove that\n$q$-ary self-dual $2$-quasi negacyclic codes are asymptotically good.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Yun Fan",
            "Yue Leng"
        ],
        "published": "2024-05-22T03:26:15Z"
    },
    {
        "title": "''You should probably read this'': Hedge Detection in Text",
        "link": "http://arxiv.org/abs/2405.13319v1",
        "abstract": "Humans express ideas, beliefs, and statements through language. The manner of\nexpression can carry information indicating the author's degree of confidence\nin their statement. Understanding the certainty level of a claim is crucial in\nareas such as medicine, finance, engineering, and many others where errors can\nlead to disastrous results. In this work, we apply a joint model that leverages\nwords and part-of-speech tags to improve hedge detection in text and achieve a\nnew top score on the CoNLL-2010 Wikipedia corpus.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Denys Katerenchuk",
            "Rivka Levitan"
        ],
        "published": "2024-05-22T03:25:35Z"
    },
    {
        "title": "BenchNav: Simulation Platform for Benchmarking Off-road Navigation\n  Algorithms with Probabilistic Traversability",
        "link": "http://arxiv.org/abs/2405.13318v1",
        "abstract": "As robotic navigation techniques in perception and planning advance, mobile\nrobots increasingly venture into off-road environments involving complex\ntraversability. However, selecting suitable planning methods remains a\nchallenge due to their algorithmic diversity, as each offers unique benefits.\nTo aid in algorithm design, we introduce BenchNav, an open-source PyTorch-based\nsimulation platform for benchmarking off-road navigation with uncertain\ntraversability. Built upon Gymnasium, BenchNav provides three key features: 1)\na data generation pipeline for preparing synthetic natural environments, 2)\nbuilt-in machine learning models for traversability prediction, and 3)\nconsistent execution of path and motion planning across different algorithms.\nWe show BenchNav's versatility through simulation examples in off-road\nenvironments, employing three representative planning algorithms from different\ndomains. https://github.com/masafumiendo/benchnav",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Masafumi Endo",
            "Kohei Honda",
            "Genya Ishigami"
        ],
        "published": "2024-05-22T03:23:10Z"
    },
    {
        "title": "Iterative Detection and Decoding Schemes with LLR Refinements in\n  Cell-Free Massive MIMO Networks",
        "link": "http://arxiv.org/abs/2405.13312v1",
        "abstract": "In this paper, we propose low-complexity local detectors and log-likelihood\nratio (LLR) refinement techniques for a coded cell-free massive multiple input\nmultiple output (CF- mMIMO) systems, where an iterative detection and decoding\n(IDD) scheme is applied using parallel interference cancellation (PIC) and\naccess point (AP) selection. In particular, we propose three LLR processing\nschemes based on the individual processing of the LLRs of each AP, LLR\ncensoring, and a linear combination of LLRs by assuming statistical\nindependence. We derive new closed-form expressions for the local soft minimum\nmean square error (MMSE)-PIC detector and receive matched filter (RMF). We also\nexamine the system performance as the number of iterations increases.\nSimulations assess the performance of the proposed techniques against existing\napproaches.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "T. Ssettumba",
            "Z. Shao",
            "L. Landau",
            "R. C. de Lamare"
        ],
        "published": "2024-05-22T03:06:14Z"
    },
    {
        "title": "Bytes to Schlep? Use a FEP: Hiding Protocol Metadata with Fully\n  Encrypted Protocols",
        "link": "http://arxiv.org/abs/2405.13310v1",
        "abstract": "Fully Encrypted Protocols (FEPs) have arisen in practice as a technique to\navoid network censorship. Such protocols are designed to produce messages that\nappear completely random. This design hides communications metadata, such as\nversion and length fields, and makes it difficult to even determine what\nprotocol is being used. Moreover, these protocols frequently support padding to\nhide the length of protocol fields and the contained message. These techniques\nhave relevance well beyond censorship circumvention, as protecting protocol\nmetadata has security and privacy benefits for all Internet communications. The\nsecurity of FEP designs depends on cryptographic assumptions, but neither\nsecurity definitions nor proofs exist for them. We provide novel security\ndefinitions that capture the metadata-protection goals of FEPs. Our definitions\nare given in both the datastream and datagram settings, which model the\nubiquitous TCP and UDP interfaces available to protocol designers. We prove\nrelations among these new notions and existing security definitions. We further\npresent new FEP constructions and prove their security. Finally, we survey\nexisting FEP candidates and characterize the extent to which they satisfy FEP\nsecurity. We identify novel ways in which these protocols are identifiable,\nincluding their responses to the introduction of data errors and the sizes of\ntheir smallest protocol messages.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Ellis Fenske",
            "Aaron Johnson"
        ],
        "published": "2024-05-22T03:05:33Z"
    },
    {
        "title": "Deep Learning-Driven State Correction: A Hybrid Architecture for\n  Radar-Based Dynamic Occupancy Grid Mapping",
        "link": "http://arxiv.org/abs/2405.13307v1",
        "abstract": "This paper introduces a novel hybrid architecture that enhances radar-based\nDynamic Occupancy Grid Mapping (DOGM) for autonomous vehicles, integrating deep\nlearning for state-classification. Traditional radar-based DOGM often faces\nchallenges in accurately distinguishing between static and dynamic objects. Our\napproach addresses this limitation by introducing a neural network-based DOGM\nstate correction mechanism, designed as a semantic segmentation task, to refine\nthe accuracy of the occupancy grid. Additionally a heuristic fusion approach is\nproposed which allows to enhance performance without compromising on safety. We\nextensively evaluate this hybrid architecture on the NuScenes Dataset, focusing\non its ability to improve dynamic object detection as well grid quality. The\nresults show clear improvements in the detection capabilities of dynamic\nobjects, highlighting the effectiveness of the deep learning-enhanced state\ncorrection in radar-based DOGM.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Max Peter Ronecker",
            "Xavier Diaz",
            "Michael Karner",
            "Daniel Watzenig"
        ],
        "published": "2024-05-22T02:57:45Z"
    },
    {
        "title": "Hybrid Multihead Attentive Unet-3D for Brain Tumor Segmentation",
        "link": "http://arxiv.org/abs/2405.13304v1",
        "abstract": "Brain tumor segmentation is a critical task in medical image analysis, aiding\nin the diagnosis and treatment planning of brain tumor patients. The importance\nof automated and accurate brain tumor segmentation cannot be overstated. It\nenables medical professionals to precisely delineate tumor regions, assess\ntumor growth or regression, and plan targeted treatments. Various deep\nlearning-based techniques proposed in the literature have made significant\nprogress in this field, however, they still face limitations in terms of\naccuracy due to the complex and variable nature of brain tumor morphology. In\nthis research paper, we propose a novel Hybrid Multihead Attentive U-Net\narchitecture, to address the challenges in accurate brain tumor segmentation,\nand to capture complex spatial relationships and subtle tumor boundaries. The\nU-Net architecture has proven effective in capturing contextual information and\nfeature representations, while attention mechanisms enhance the model's ability\nto focus on informative regions and refine the segmentation boundaries. By\nintegrating these two components, our proposed architecture improves accuracy\nin brain tumor segmentation. We test our proposed model on the BraTS 2020\nbenchmark dataset and compare its performance with the state-of-the-art\nwell-known SegNet, FCN-8s, and Dense121 U-Net architectures. The results show\nthat our proposed model outperforms the others in terms of the evaluated\nperformance metrics.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Muhammad Ansab Butt",
            "Absaar Ul Jabbar"
        ],
        "published": "2024-05-22T02:46:26Z"
    },
    {
        "title": "Accelerated Evaluation of Ollivier-Ricci Curvature Lower Bounds:\n  Bridging Theory and Computation",
        "link": "http://arxiv.org/abs/2405.13302v1",
        "abstract": "Curvature serves as a potent and descriptive invariant, with its efficacy\nvalidated both theoretically and practically within graph theory. We employ a\ndefinition of generalized Ricci curvature proposed by Ollivier, which Lin and\nYau later adapted to graph theory, known as Ollivier-Ricci curvature (ORC). ORC\nmeasures curvature using the Wasserstein distance, thereby integrating\ngeometric concepts with probability theory and optimal transport. Jost and Liu\npreviously discussed the lower bound of ORC by showing the upper bound of the\nWasserstein distance. We extend the applicability of these bounds to discrete\nspaces with metrics on integers, specifically hypergraphs. Compared to prior\nwork on ORC in hypergraphs by Coupette, Dalleiger, and Rieck, which faced\ncomputational challenges, our method introduces a simplified approach with\nlinear computational complexity, making it particularly suitable for analyzing\nlarge-scale networks. Through extensive simulations and application to\nsynthetic and real-world datasets, we demonstrate the significant improvements\nour method offers in evaluating ORC.",
        "subjects": [
            "stat.ML",
            "cs.DM",
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Wonwoo Kang",
            "Heehyun Park"
        ],
        "published": "2024-05-22T02:44:46Z"
    },
    {
        "title": "FAITH: Frequency-domain Attention In Two Horizons for Time Series\n  Forecasting",
        "link": "http://arxiv.org/abs/2405.13300v1",
        "abstract": "Time Series Forecasting plays a crucial role in various fields such as\nindustrial equipment maintenance, meteorology, energy consumption, traffic flow\nand financial investment. However, despite their considerable advantages over\ntraditional statistical approaches, current deep learning-based predictive\nmodels often exhibit a significant deviation between their forecasting outcomes\nand the ground truth. This discrepancy is largely due to an insufficient\nemphasis on extracting the sequence's latent information, particularly its\nglobal information within the frequency domain and the relationship between\ndifferent variables. To address this issue, we propose a novel model\nFrequency-domain Attention In Two Horizons, which decomposes time series into\ntrend and seasonal components using a multi-scale sequence adaptive\ndecomposition and fusion architecture, and processes them separately. FAITH\nutilizes Frequency Channel feature Extraction Module and Frequency Temporal\nfeature Extraction Module to capture inter-channel relationships and temporal\nglobal information in the sequence, significantly improving its ability to\nhandle long-term dependencies and complex patterns. Furthermore, FAITH achieves\ntheoretically linear complexity by modifying the time-frequency domain\ntransformation method, effectively reducing computational costs. Extensive\nexperiments on 6 benchmarks for long-term forecasting and 3 benchmarks for\nshort-term forecasting demonstrate that FAITH outperforms existing models in\nmany fields, such as electricity, weather and traffic, proving its\neffectiveness and superiority both in long-term and short-term time series\nforecasting tasks. Our codes and data are available at\nhttps://github.com/LRQ577/FAITH.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Ruiqi Li",
            "Maowei Jiang",
            "Kai Wang",
            "Kaiduo Feng",
            "Quangao Liu",
            "Yue Sun",
            "Xiufang Zhou"
        ],
        "published": "2024-05-22T02:37:02Z"
    },
    {
        "title": "An Efficient Approach for Solving Expensive Constrained Multiobjective\n  Optimization Problems",
        "link": "http://arxiv.org/abs/2405.13298v1",
        "abstract": "To solve real-world expensive constrained multi-objective optimization\nproblems (ECMOPs), surrogate/approximation models are commonly incorporated in\nevolutionary algorithms to pre-select promising candidate solutions for\nevaluation. However, the performance of existing approaches are highly\ndependent on the relative position of unconstrained and constrained Pareto\nfronts (UPF and CPF, respectively). In addition, the uncertainty information of\nsurrogate models is often ignored, which can misguide the search. To mitigate\nthese key issues (among others), an efficient probabilistic selection based\nconstrained multi-objective EA is proposed, referred to as PSCMOEA. It\ncomprises novel elements such as (a) an adaptive search bound identification\nscheme based on the feasibility and convergence status of evaluated solutions\n(b) a probabilistic selection method backed by theoretical formulations of\nmodel mean and uncertainties to conduct search in the predicted space to\nidentify promising solutions (c) an efficient single infill sampling approach\nto balance feasibility, convergence and diversity across different stages of\nthe search and (d) an adaptive switch to unconstrained search based on certain\nsearch conditions. Numerical experiments are conducted on an extensive range of\nchallenging constrained problems using low evaluation budgets to simulate\nECMOPs. The performance of PSCMOEA is benchmarked against five competitive\nstate-of-the-art algorithms, to demonstrate its competitive and consistent\nperformance.",
        "subjects": [
            "cs.NE"
        ],
        "authors": [
            "Kamrul Hasan Rahi"
        ],
        "published": "2024-05-22T02:32:58Z"
    },
    {
        "title": "Dialects for CoAP-like Messaging Protocols",
        "link": "http://arxiv.org/abs/2405.13295v1",
        "abstract": "Messaging protocols for resource limited systems such as distributed IoT\nsystems are often vulnerable to attacks due to security choices made to\nconserve resources such as time, memory, or bandwidth. For example, use of\nsecure layers such as DTLS are resource expensive and can sometimes cause\nservice disruption. Protocol dialects are intended as a light weight, modular\nmechanism to provide selected security guarantees, such as authentication. In\nthis report we study the CoAP messaging protocol and define two attack models\nformalizing different vulnerabilities. We propose a generic dialect for CoAP\nmessaging. The CoAP protocol, dialect, and attack models are formalized in the\nrewriting logic system Maude. A number of case studies are reported\nillustrating vulnerabilities and effects of applying the dialect. We also prove\n(stuttering) bisimulations between CoAP messaging applications and dialected\nversions, thus ensuring that dialecting preserves LTL properties (without Next)\nof CoAP applications.",
        "subjects": [
            "cs.CR",
            "I.6.4"
        ],
        "authors": [
            "Carolyn Talcott"
        ],
        "published": "2024-05-22T02:25:27Z"
    },
    {
        "title": "Metadata Integration for Spam Reviews Detection on Vietnamese E-commerce\n  Websites",
        "link": "http://arxiv.org/abs/2405.13292v1",
        "abstract": "The problem of detecting spam reviews (opinions) has received significant\nattention in recent years, especially with the rapid development of e-commerce.\nSpam reviews are often classified based on comment content, but in some cases,\nit is insufficient for models to accurately determine the review label. In this\nwork, we introduce the ViSpamReviews v2 dataset, which includes metadata of\nreviews with the objective of integrating supplementary attributes for spam\nreview classification. We propose a novel approach to simultaneously integrate\nboth textual and categorical attributes into the classification model. In our\nexperiments, the product category proved effective when combined with deep\nneural network (DNN) models, while text features performed well on both DNN\nmodels and the model achieved state-of-the-art performance in the problem of\ndetecting spam reviews on Vietnamese e-commerce websites, namely PhoBERT.\nSpecifically, the PhoBERT model achieves the highest accuracy when combined\nwith product description features generated from the SPhoBert model, which is\nthe combination of PhoBERT and SentenceBERT. Using the macro-averaged F1 score,\nthe task of classifying spam reviews achieved 87.22% (an increase of 1.64%\ncompared to the baseline), while the task of identifying the type of spam\nreviews achieved an accuracy of 73.49% (an increase of 1.93% compared to the\nbaseline).",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Co Van Dinh",
            "Son T. Luu"
        ],
        "published": "2024-05-22T02:19:13Z"
    },
    {
        "title": "Theoretical Analysis of Meta Reinforcement Learning: Generalization\n  Bounds and Convergence Guarantees",
        "link": "http://arxiv.org/abs/2405.13290v1",
        "abstract": "This research delves deeply into Meta Reinforcement Learning (Meta RL)\nthrough a exploration focusing on defining generalization limits and ensuring\nconvergence. By employing a approach this article introduces an innovative\ntheoretical framework to meticulously assess the effectiveness and performance\nof Meta RL algorithms. We present an explanation of generalization limits\nmeasuring how well these algorithms can adapt to learning tasks while\nmaintaining consistent results. Our analysis delves into the factors that\nimpact the adaptability of Meta RL revealing the relationship, between\nalgorithm design and task complexity. Additionally we establish convergence\nassurances by proving conditions under which Meta RL strategies are guaranteed\nto converge towards solutions. We examine the convergence behaviors of Meta RL\nalgorithms across scenarios providing a comprehensive understanding of the\ndriving forces behind their long term performance. This exploration covers both\nconvergence and real time efficiency offering a perspective, on the\ncapabilities of these algorithms.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Cangqing Wang",
            "Mingxiu Sui",
            "Dan Sun",
            "Zecheng Zhang",
            "Yan Zhou"
        ],
        "published": "2024-05-22T02:09:22Z"
    },
    {
        "title": "AUGlasses: Continuous Action Unit based Facial Reconstruction with\n  Low-power IMUs on Smart Glasses",
        "link": "http://arxiv.org/abs/2405.13289v1",
        "abstract": "Recent advancements in augmented reality (AR) have enabled the use of various\nsensors on smart glasses for applications like facial reconstruction, which is\nvital to improve AR experiences for virtual social activities. However, the\nsize and power constraints of smart glasses demand a miniature and low-power\nsensing solution. AUGlasses achieves unobtrusive low-power facial\nreconstruction by placing inertial measurement units (IMU) against the temporal\narea on the face to capture the skin deformations, which are caused by facial\nmuscle movements. These IMU signals, along with historical data on facial\naction units (AUs), are processed by a transformer-based deep learning model to\nestimate AU intensities in real-time, which are then used for facial\nreconstruction. Our results show that AUGlasses accurately predicts the\nstrength (0-5 scale) of 14 key AUs with a cross-user mean absolute error (MAE)\nof 0.187 (STD = 0.025) and achieves facial reconstruction with a cross-user MAE\nof 1.93 mm (STD = 0.353). We also integrated various preprocessing and training\ntechniques to ensure robust performance for continuous sensing. Micro-benchmark\ntests indicate that our system consistently performs accurate continuous facial\nreconstruction with a fine-tuned cross-user model, achieving an AU MAE of 0.35.",
        "subjects": [
            "cs.HC",
            "cs.CV"
        ],
        "authors": [
            "Yanrong Li",
            "Tengxiang Zhang",
            "Xin Zeng",
            "Yuntao Wang",
            "Haotian Zhang",
            "Yiqiang Chen"
        ],
        "published": "2024-05-22T02:07:56Z"
    },
    {
        "title": "Remarks on Loss Function of Threshold Method for Ordinal Regression\n  Problem",
        "link": "http://arxiv.org/abs/2405.13288v1",
        "abstract": "Threshold methods are popular for ordinal regression problems, which are\nclassification problems for data with a natural ordinal relation. They learn a\none-dimensional transformation (1DT) of observations of the explanatory\nvariable, and then assign label predictions to the observations by thresholding\ntheir 1DT values. In this paper, we study the influence of the underlying data\ndistribution and of the learning procedure of the 1DT on the classification\nperformance of the threshold method via theoretical considerations and\nnumerical experiments. Consequently, for example, we found that threshold\nmethods based on typical learning procedures may perform poorly when the\nprobability distribution of the target variable conditioned on an observation\nof the explanatory variable tends to be non-unimodal. Another instance of our\nfindings is that learned 1DT values are concentrated at a few points under the\nlearning procedure based on a piecewise-linear loss function, which can make\ndifficult to classify data well.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ryoya Yamasaki",
            "Toshiyuki Tanaka"
        ],
        "published": "2024-05-22T02:03:12Z"
    },
    {
        "title": "Enhancing Active Learning for Sentinel 2 Imagery through Contrastive\n  Learning and Uncertainty Estimation",
        "link": "http://arxiv.org/abs/2405.13285v1",
        "abstract": "In this paper, we introduce a novel method designed to enhance label\nefficiency in satellite imagery analysis by integrating semi-supervised\nlearning (SSL) with active learning strategies. Our approach utilizes\ncontrastive learning together with uncertainty estimations via Monte Carlo\nDropout (MC Dropout), with a particular focus on Sentinel-2 imagery analyzed\nusing the Eurosat dataset. We explore the effectiveness of our method in\nscenarios featuring both balanced and unbalanced class distributions. Our\nresults show that for unbalanced classes, our method is superior to the random\napproach, enabling significant savings in labeling effort while maintaining\nhigh classification accuracy. These findings highlight the potential of our\napproach to facilitate scalable and cost-effective satellite image analysis,\nparticularly advantageous for extensive environmental monitoring and land use\nclassification tasks. Note on preliminary results: This paper presents a new\nmethod for active learning and includes results from an initial experiment\ncomparing random selection with our proposed method. We acknowledge that these\nresults are preliminary. We are currently conducting further experiments and\nwill update this paper with additional findings, including comparisons with\nother methods, in the coming weeks.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "David Pogorzelski",
            "Peter Arlinghaus"
        ],
        "published": "2024-05-22T01:54:51Z"
    },
    {
        "title": "Single color virtual H&E staining with In-and-Out Net",
        "link": "http://arxiv.org/abs/2405.13278v1",
        "abstract": "Virtual staining streamlines traditional staining procedures by digitally\ngenerating stained images from unstained or differently stained images. While\nconventional staining methods involve time-consuming chemical processes,\nvirtual staining offers an efficient and low infrastructure alternative.\nLeveraging microscopy-based techniques, such as confocal microscopy,\nresearchers can expedite tissue analysis without the need for physical\nsectioning. However, interpreting grayscale or pseudo-color microscopic images\nremains a challenge for pathologists and surgeons accustomed to traditional\nhistologically stained images. To fill this gap, various studies explore\ndigitally simulating staining to mimic targeted histological stains. This paper\nintroduces a novel network, In-and-Out Net, specifically designed for virtual\nstaining tasks. Based on Generative Adversarial Networks (GAN), our model\nefficiently transforms Reflectance Confocal Microscopy (RCM) images into\nHematoxylin and Eosin (H&E) stained images. We enhance nuclei contrast in RCM\nimages using aluminum chloride preprocessing for skin tissues. Training the\nmodel with virtual H\\&E labels featuring two fluorescence channels eliminates\nthe need for image registration and provides pixel-level ground truth. Our\ncontributions include proposing an optimal training strategy, conducting a\ncomparative analysis demonstrating state-of-the-art performance, validating the\nmodel through an ablation study, and collecting perfectly matched input and\nground truth images without registration. In-and-Out Net showcases promising\nresults, offering a valuable tool for virtual staining tasks and advancing the\nfield of histological image analysis.",
        "subjects": [
            "cs.CV",
            "physics.med-ph"
        ],
        "authors": [
            "Mengkun Chen",
            "Yen-Tung Liu",
            "Fadeel Sher Khan",
            "Matthew C. Fox",
            "Jason S. Reichenberg",
            "Fabiana C. P. S. Lopes",
            "Katherine R. Sebastian",
            "Mia K. Markey",
            "James W. Tunnell"
        ],
        "published": "2024-05-22T01:17:27Z"
    },
    {
        "title": "DiffNorm: Self-Supervised Normalization for Non-autoregressive\n  Speech-to-speech Translation",
        "link": "http://arxiv.org/abs/2405.13274v1",
        "abstract": "Non-autoregressive Transformers (NATs) are recently applied in direct\nspeech-to-speech translation systems, which convert speech across different\nlanguages without intermediate text data. Although NATs generate high-quality\noutputs and offer faster inference than autoregressive models, they tend to\nproduce incoherent and repetitive results due to complex data distribution\n(e.g., acoustic and linguistic variations in speech). In this work, we\nintroduce DiffNorm, a diffusion-based normalization strategy that simplifies\ndata distributions for training NAT models. After training with a\nself-supervised noise estimation objective, DiffNorm constructs normalized\ntarget data by denoising synthetically corrupted speech features. Additionally,\nwe propose to regularize NATs with classifier-free guidance, improving model\nrobustness and translation quality by randomly dropping out source information\nduring training. Our strategies result in a notable improvement of about +7\nASR-BLEU for English-Spanish (En-Es) and +2 ASR-BLEU for English-French (En-Fr)\ntranslations on the CVSS benchmark, while attaining over 14x speedup for En-Es\nand 5x speedup for En-Fr translations compared to autoregressive baselines.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Weiting Tan",
            "Jingyu Zhang",
            "Lingfeng Shen",
            "Daniel Khashabi",
            "Philipp Koehn"
        ],
        "published": "2024-05-22T01:10:39Z"
    },
    {
        "title": "Dequantizability from inputs",
        "link": "http://arxiv.org/abs/2405.13273v1",
        "abstract": "By comparing constructions of block encoding given by [1-4], we propose a way\nto extract dequantizability from advancements in dequantization techniques that\nhave been led by Tang, as in [5]. Then we apply this notion to the\nsparse-access input model that is known to be BQP-complete in general, thereby\nconceived to be un-dequantizable. Our goal is to break down this belief by\nexamining the sparse-access input model's instances, particularly their input\nmatrices. In conclusion, this paper forms a dequantizability-verifying scheme\nthat can be applied whenever an input is given.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "cs.DS"
        ],
        "authors": [
            "Tae-Won Kim",
            "Byung-Soo Choi"
        ],
        "published": "2024-05-22T01:08:54Z"
    },
    {
        "title": "A Multilingual Similarity Dataset for News Article Frame",
        "link": "http://arxiv.org/abs/2405.13272v1",
        "abstract": "Understanding the writing frame of news articles is vital for addressing\nsocial issues, and thus has attracted notable attention in the fields of\ncommunication studies. Yet, assessing such news article frames remains a\nchallenge due to the absence of a concrete and unified standard dataset that\nconsiders the comprehensive nuances within news content.\n  To address this gap, we introduce an extended version of a large labeled news\narticle dataset with 16,687 new labeled pairs. Leveraging the pairwise\ncomparison of news articles, our method frees the work of manual identification\nof frame classes in traditional news frame analysis studies. Overall we\nintroduce the most extensive cross-lingual news article similarity dataset\navailable to date with 26,555 labeled news article pairs across 10 languages.\nEach data point has been meticulously annotated according to a codebook\ndetailing eight critical aspects of news content, under a human-in-the-loop\nframework. Application examples demonstrate its potential in unearthing country\ncommunities within global news coverage, exposing media bias among news\noutlets, and quantifying the factors related to news creation. We envision that\nthis news similarity dataset will broaden our understanding of the media\necosystem in terms of news coverage of events and perspectives across\ncountries, locations, languages, and other social constructs. By doing so, it\ncan catalyze advancements in social science research and applied methodologies,\nthereby exerting a profound impact on our society.",
        "subjects": [
            "cs.CL",
            "cs.CY"
        ],
        "authors": [
            "Xi Chen",
            "Mattia Samory",
            "Scott Hale",
            "David Jurgens",
            "Przemyslaw A. Grabowicz"
        ],
        "published": "2024-05-22T01:01:04Z"
    },
    {
        "title": "Verifying Lock-free Search Structure Templates",
        "link": "http://arxiv.org/abs/2405.13271v1",
        "abstract": "We present and verify template algorithms for lock-free concurrent search\nstructures that cover a broad range of existing implementations based on lists\nand skiplists. Our linearizability proofs are fully mechanized in the\nconcurrent separation logic Iris. The proofs are modular and cover the broader\ndesign space of the underlying algorithms by parameterizing the verification\nover aspects such as the low-level representation of nodes and the style of\ndata structure maintenance. As a further technical contribution, we present a\nmechanization of a recently proposed method for reasoning about\nfuture-dependent linearization points using hindsight arguments. The\nmechanization builds on Iris' support for prophecy reasoning and user-defined\nghost resources. We demonstrate that the method can help to reduce the proof\neffort compared to direct prophecy-based proofs.",
        "subjects": [
            "cs.PL",
            "cs.LO"
        ],
        "authors": [
            "Nisarg Patel",
            "Dennis Shasha",
            "Thomas Wies"
        ],
        "published": "2024-05-22T00:51:38Z"
    },
    {
        "title": "Analysis of reconstruction from noisy discrete generalized Radon data",
        "link": "http://arxiv.org/abs/2405.13269v1",
        "abstract": "We consider a wide class of generalized Radon transforms $\\mathcal R$, which\nact in $\\mathbb{R}^n$ for any $n\\ge 2$ and integrate over submanifolds of any\ncodimension $N$, $1\\le N\\le n-1$. Also, we allow for a fairly general\nreconstruction operator $\\mathcal A$. The main requirement is that $\\mathcal A$\nbe a Fourier integral operator with a phase function, which is linear in the\nphase variable. We consider the task of image reconstruction from discrete data\n$g_{j,k} = (\\mathcal R f)_{j,k} + \\eta_{j,k}$. We show that the reconstruction\nerror $N_\\epsilon^{\\text{rec}}=\\mathcal A \\eta_{j,k}$ satisfies\n$N^{\\text{rec}}(\\check\nx;x_0)=\\lim_{\\epsilon\\to0}N_\\epsilon^{\\text{rec}}(x_0+\\epsilon\\check x)$,\n$\\check x\\in D$. Here $x_0$ is a fixed point, $D\\subset\\mathbb{R}^n$ is a\nbounded domain, and $\\eta_{j,k}$ are independent, but not necessarily\nidentically distributed, random variables. $N^{\\text{rec}}$ and\n$N_\\epsilon^{\\text{rec}}$ are viewed as continuous random functions of the\nargument $\\check x$ (random fields), and the limit is understood in the sense\nof probability distributions. Under some conditions on the first three moments\nof $\\eta_{j,k}$ (and some other not very restrictive conditions on $x_0$ and\n$\\mathcal A$), we prove that $N^{\\text{rec}}$ is a zero mean Gaussian random\nfield and explicitly compute its covariance. We also present a numerical\nexperiment with a cone beam transform in $\\mathbb{R}^3$, which shows an\nexcellent match between theoretical predictions and simulated reconstructions.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "math.PR"
        ],
        "authors": [
            "Alexander Katsevich"
        ],
        "published": "2024-05-22T00:46:38Z"
    },
    {
        "title": "Stochastic Online Conformal Prediction with Semi-Bandit Feedback",
        "link": "http://arxiv.org/abs/2405.13268v1",
        "abstract": "Conformal prediction has emerged as an effective strategy for uncertainty\nquantification by modifying a model to output sets of labels instead of a\nsingle label. These prediction sets come with the guarantee that they contain\nthe true label with high probability. However, conformal prediction typically\nrequires a large calibration dataset of i.i.d. examples. We consider the online\nlearning setting, where examples arrive over time, and the goal is to construct\nprediction sets dynamically. Departing from existing work, we assume\nsemi-bandit feedback, where we only observe the true label if it is contained\nin the prediction set. For instance, consider calibrating a document retrieval\nmodel to a new domain; in this setting, a user would only be able to provide\nthe true label if the target document is in the prediction set of retrieved\ndocuments. We propose a novel conformal prediction algorithm targeted at this\nsetting, and prove that it obtains sublinear regret compared to the optimal\nconformal predictor. We evaluate our algorithm on a retrieval task and an image\nclassification task, and demonstrate that it empirically achieves good\nperformance.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Haosen Ge",
            "Hamsa Bastani",
            "Osbert Bastani"
        ],
        "published": "2024-05-22T00:42:49Z"
    },
    {
        "title": "FLARE up your data: Diffusion-based Augmentation Method in Astronomical\n  Imaging",
        "link": "http://arxiv.org/abs/2405.13267v1",
        "abstract": "The intersection of Astronomy and AI encounters significant challenges\nrelated to issues such as noisy backgrounds, lower resolution (LR), and the\nintricate process of filtering and archiving images from advanced telescopes\nlike the James Webb. Given the dispersion of raw images in feature space, we\nhave proposed a \\textit{two-stage augmentation framework} entitled as\n\\textbf{FLARE} based on \\underline{f}eature \\underline{l}earning and\n\\underline{a}ugmented \\underline{r}esolution \\underline{e}nhancement. We first\napply lower (LR) to higher resolution (HR) conversion followed by standard\naugmentations. Secondly, we integrate a diffusion approach to synthetically\ngenerate samples using class-concatenated prompts. By merging these two stages\nusing weighted percentiles, we realign the feature space distribution, enabling\na classification model to establish a distinct decision boundary and achieve\nsuperior generalization on various in-domain and out-of-domain tasks. We\nconducted experiments on several downstream cosmos datasets and on our\noptimally distributed \\textbf{SpaceNet} dataset across 8-class fine-grained and\n4-class macro classification tasks. FLARE attains the highest performance gain\nof 20.78\\% for fine-grained tasks compared to similar baselines, while across\ndifferent classification models, FLARE shows a consistent increment of an\naverage of +15\\%. This outcome underscores the effectiveness of the FLARE\nmethod in enhancing the precision of image classification, ultimately\nbolstering the reliability of astronomical research outcomes. % Our code and\nSpaceNet dataset will be released to the public soon. Our code and SpaceNet\ndataset is available at\n\\href{https://github.com/Razaimam45/PlanetX_Dxb}{\\textit{https://github.com/Razaimam45/PlanetX\\_Dxb}}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Mohammed Talha Alam",
            "Raza Imam",
            "Mohsen Guizani",
            "Fakhri Karray"
        ],
        "published": "2024-05-22T00:40:37Z"
    },
    {
        "title": "Part-based Quantitative Analysis for Heatmaps",
        "link": "http://arxiv.org/abs/2405.13264v1",
        "abstract": "Heatmaps have been instrumental in helping understand deep network decisions,\nand are a common approach for Explainable AI (XAI). While significant progress\nhas been made in enhancing the informativeness and accessibility of heatmaps,\nheatmap analysis is typically very subjective and limited to domain experts. As\nsuch, developing automatic, scalable, and numerical analysis methods to make\nheatmap-based XAI more objective, end-user friendly, and cost-effective is\nvital. In addition, there is a need for comprehensive evaluation metrics to\nassess heatmap quality at a granular level.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Osman Tursun",
            "Sinan Kalkan",
            "Simon Denman",
            "Sridha Sridharan",
            "Clinton Fookes"
        ],
        "published": "2024-05-22T00:24:17Z"
    },
    {
        "title": "Traffic control using intelligent timing of traffic lights with\n  reinforcement learning technique and real-time processing of surveillance\n  camera images",
        "link": "http://arxiv.org/abs/2405.13256v1",
        "abstract": "Optimal management of traffic light timing is one of the most effective\nfactors in reducing urban traffic. In most old systems, fixed timing was used\nalong with human factors to control traffic, which is not very efficient in\nterms of time and cost. Nowadays, methods in the field of traffic management\nare based on the use of artificial intelligence. In this method, by using\nreal-time processing of video surveillance camera images along with\nreinforcement learning, the optimal timing of traffic lights is determined and\napplied according to several parameters. In the research, deep learning methods\nwere used in vehicle detection using the YOLOv9-C model to estimate the number\nand other characteristics of vehicles such as speed. Finally, by modeling\nvehicles in an urban environment simulator at OpenAI Gym using multi-factor\nreinforcement learning and the DQN Rainbow algorithm, timing is applied to\ntraffic lights at intersections. Additionally, the use of transfer learning\nalong with retraining the model on images of Iranian cars has increased the\naccuracy of the model. The results of the proposed method show a model that is\nreasonably accurate in both parts of analyzing surveillance cameras and finding\nthe optimal timing, and it has been observed that it has better accuracy than\nprevious research.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Mahdi Jamebozorg",
            "Mohsen Hami",
            "Sajjad Deh Deh Jani"
        ],
        "published": "2024-05-22T00:04:32Z"
    }
]