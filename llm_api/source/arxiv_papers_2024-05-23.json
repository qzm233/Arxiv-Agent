[
    {
        "title": "Is Algorithmic Stability Testable? A Unified Framework under\n  Computational Constraints",
        "link": "http://arxiv.org/abs/2405.15107v1",
        "abstract": "Algorithmic stability is a central notion in learning theory that quantifies\nthe sensitivity of an algorithm to small changes in the training data. If a\nlearning algorithm satisfies certain stability properties, this leads to many\nimportant downstream implications, such as generalization, robustness, and\nreliable predictive inference. Verifying that stability holds for a particular\nalgorithm is therefore an important and practical question. However, recent\nresults establish that testing the stability of a black-box algorithm is\nimpossible, given limited data from an unknown distribution, in settings where\nthe data lies in an uncountably infinite space (such as real-valued data). In\nthis work, we extend this question to examine a far broader range of settings,\nwhere the data may lie in any space -- for example, categorical data. We\ndevelop a unified framework for quantifying the hardness of testing algorithmic\nstability, which establishes that across all settings, if the available data is\nlimited then exhaustive search is essentially the only universally valid\nmechanism for certifying algorithmic stability. Since in practice, any test of\nstability would naturally be subject to computational constraints, exhaustive\nsearch is impossible and so this implies fundamental limits on our ability to\ntest the stability property for a black-box algorithm.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST",
            "stat.TH"
        ],
        "authors": [
            "Yuetian Luo",
            "Rina Foygel Barber"
        ],
        "published": "2024-05-23T23:51:25Z"
    },
    {
        "title": "Conformal Classification with Equalized Coverage for Adaptively Selected\n  Groups",
        "link": "http://arxiv.org/abs/2405.15106v1",
        "abstract": "This paper introduces a conformal inference method to evaluate uncertainty in\nclassification by generating prediction sets with valid coverage conditional on\nadaptively chosen features. These features are carefully selected to reflect\npotential model limitations or biases. This can be useful to find a practical\ncompromise between efficiency -- by providing informative predictions -- and\nalgorithmic fairness -- by ensuring equalized coverage for the most sensitive\ngroups. We demonstrate the validity and effectiveness of this method on\nsimulated and real data sets.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Yanfei Zhou",
            "Matteo Sesia"
        ],
        "published": "2024-05-23T23:32:37Z"
    },
    {
        "title": "Certified Inventory Control of Critical Resources",
        "link": "http://arxiv.org/abs/2405.15105v1",
        "abstract": "Inventory control is subject to service-level requirements, in which\nsufficient stock levels must be maintained despite an unknown demand. We\npropose a data-driven order policy that certifies any prescribed service level\nunder minimal assumptions on the unknown demand process. The policy achieves\nthis using any online learning method along with integral action. We further\npropose an inference method that is valid in finite samples. The properties and\ntheoretical guarantees of the method are illustrated using both synthetic and\nreal-world data.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Ludvig Hult",
            "Dave Zachariah",
            "Petre Stoica"
        ],
        "published": "2024-05-23T23:27:38Z"
    },
    {
        "title": "The Rarity of Musical Audio Signals Within the Space of Possible Audio\n  Generation",
        "link": "http://arxiv.org/abs/2405.15103v1",
        "abstract": "A white noise signal can access any possible configuration of values, though\nstatistically over many samples tends to a uniform spectral distribution, and\nis highly unlikely to produce intelligible sound. But how unlikely? The\nprobability that white noise generates a music-like signal over different\ndurations is analyzed, based on some necessary features observed in real music\naudio signals such as mostly proximate movement and zero crossing rate. Given\nthe mathematical results, the rarity of music as a signal is considered\noverall. The applicability of this study is not just to show that music has a\nprecious rarity value, but that examination of the size of music relative to\nthe overall size of audio signal space provides information to inform new\ngenerations of algorithmic music system (which are now often founded on audio\nsignal generation directly, and may relate to white noise via such machine\nlearning processes as diffusion). Estimated upper bounds on the rarity of music\nto the size of various physical and musical spaces are compared, to better\nunderstand the magnitude of the results (pun intended). Underlying the research\nare the questions `how much music is still out there?' and `how much music\ncould a machine learning process actually reach?'.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "authors": [
            "Nick Collins"
        ],
        "published": "2024-05-23T23:25:46Z"
    },
    {
        "title": "Social Zone as a Barrier Function for Socially-Compliant Robot\n  Navigation",
        "link": "http://arxiv.org/abs/2405.15101v1",
        "abstract": "This study addresses the challenge of integrating social norms into robot\nnavigation, which is essential for ensuring that robots operate safely and\nefficiently in human-centric environments. Social norms, often unspoken and\nimplicitly understood among people, are difficult to explicitly define and\nimplement in robotic systems. To overcome this, we derive these norms from real\nhuman trajectory data, utilizing the comprehensive ATC dataset to identify the\nminimum social zones humans and robots must respect. These zones are integrated\ninto the robot' navigation system by applying barrier functions, ensuring the\nrobot consistently remains within the designated safety set. Simulation results\ndemonstrate that our system effectively mimics human-like navigation\nstrategies, such as passing on the right side and adjusting speed or pausing in\nconstrained spaces. The proposed framework is versatile, easily comprehensible,\nand tunable, demonstrating the potential to advance the development of robots\ndesigned to navigate effectively in human-centric environments.",
        "subjects": [
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Junwoo Jang",
            "Maani Ghaffari"
        ],
        "published": "2024-05-23T23:21:10Z"
    },
    {
        "title": "Mobile Robot Sensory Coverage in 2-D Environments: An Optimization\n  Approach with Efficiency Bounds",
        "link": "http://arxiv.org/abs/2405.15100v1",
        "abstract": "This paper considers three related mobile robot multi-target sensory coverage\nand inspection planning problems in 2-D environments. In the first problem, a\nmobile robot must find the shortest path to observe multiple targets with a\nlimited range sensor in an obstacle free environment. In the second problem,\nthe mobile robot must efficiently observe multiple targets while taking\nadvantage of multi-target views in an obstacle free environment. The third\nproblem considers multi-target sensory coverage in the presence of obstacles\nthat obstruct sensor views of the targets. We show how all three problems can\nbe formulated in a MINLP optimization framework. Because exact solutions to\nthese problems are NP-hard, we introduce polynomial time approximation\nalgorithms for each problem. These algorithms combine polynomial-time methods\nto approximate the optimal target sensing order, combined with efficient convex\noptimization methods that incorporate the constraints posed by the robot sensor\nfootprint and obstacles in the environment. Importantly, we develop bounds that\nlimit the gap between the exact and approximate solutions. Algorithms for all\nproblems are fully implemented and illustrated with examples. Beyond the\nutility of our algorithms, the bounds derived in the paper contribute to the\ntheory of optimal coverage planning algorithms.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "E. Fourney",
            "J. W. Burdick",
            "E. D. Rimon"
        ],
        "published": "2024-05-23T23:19:50Z"
    },
    {
        "title": "Stability analysis of nonlinear stochastic flexibility function in smart\n  energy systems",
        "link": "http://arxiv.org/abs/2405.15099v1",
        "abstract": "Demand-side management provides a great potential for improving the\nefficiency and reliability of energy systems. This requires a mechanism to\nconnect the market level and the demand side. The flexibility function is a\nnovel approach that bridges the gap between the markets and the dynamics of\nphysical assets at the lower levels of the energy systems and activates\ndemand-side flexibility with the purpose of decision-making as well as for\noffering a new framework for balancing and grid services. Employing this\nfunction as a key for many decision-making and control algorithms reveals that\na mathematically rigorous stability analysis is required for it. In this paper,\nwe investigate the stability properties of two nonlinear flexibility functions,\nas a dynamic mapping between electricity price and power consumption.\nSpecifically, we analyze the stability of a deterministic flexibility function\nand an It\\^{o} stochastic flexibility function. Simulation results are also\nprovided to demonstrate the dynamics of the flexibility functions and to show\nthat the analytical results hold.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Seyed Shahabaldin Tohidi",
            "Tobias K. S. Ritschel",
            "Georgios Tsaousoglou",
            "Uffe Høgsbro Thygesen",
            "Henrik Madsen"
        ],
        "published": "2024-05-23T23:13:35Z"
    },
    {
        "title": "Magnetic Resonance Image Processing Transformer for General\n  Reconstruction",
        "link": "http://arxiv.org/abs/2405.15098v1",
        "abstract": "Purpose: To develop and evaluate a deep learning model for general\naccelerated MRI reconstruction.\n  Materials and Methods: This retrospective study built a magnetic resonance\nimage processing transformer (MR-IPT) which includes multi-head-tails and a\nsingle shared window transformer main body. Three mutations of MR-IPT with\ndifferent transformer structures were implemented to guide the design of our\nMR-IPT model. Pre-trained on the MRI set of RadImageNet including 672675 images\nwith multiple anatomy categories, the model was further migrated and evaluated\non fastMRI knee dataset with 25012 images for downstream reconstruction tasks.\nWe performed comparison studies with three CNN-based conventional networks in\nzero- and few-shot learning scenarios. Transfer learning process was conducted\non both MR-IPT and CNN networks to further validate the generalizability of\nMR-IPT. To study the model performance stability, we evaluated our model with\nvarious downstream dataset sizes ranging from 10 to 2500 images.\n  Result: The MR-IPT model provided superior performance in multiple downstream\ntasks compared to conventional CNN networks. MR-IPT achieved a PSNR/SSIM of\n26.521/0.6102 (4-fold) and 24.861/0.4996 (8-fold) in 10-epoch learning,\nsurpassing UNet128 at 25.056/0.5832 (4-fold) and 22.984/0.4637 (8-fold). With\nthe same large-scale pre-training, MR-IPT provided a 5% performance boost\ncompared to UNet128 in zero-shot learning in 8-fold and 3% in 4-fold.\n  Conclusion: MR-IPT framework benefits from its transformer-based structure\nand large-scale pre-training and can serve as a solid backbone in other\ndownstream tasks with zero- and few-shot learning.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG",
            "physics.med-ph"
        ],
        "authors": [
            "Guoyao Shen",
            "Mengyu Li",
            "Stephan Anderson",
            "Chad W. Farris",
            "Xin Zhang"
        ],
        "published": "2024-05-23T23:13:02Z"
    },
    {
        "title": "Contrastive and Consistency Learning for Neural Noisy-Channel Model in\n  Spoken Language Understanding",
        "link": "http://arxiv.org/abs/2405.15097v1",
        "abstract": "Recently, deep end-to-end learning has been studied for intent classification\nin Spoken Language Understanding (SLU). However, end-to-end models require a\nlarge amount of speech data with intent labels, and highly optimized models are\ngenerally sensitive to the inconsistency between the training and evaluation\nconditions. Therefore, a natural language understanding approach based on\nAutomatic Speech Recognition (ASR) remains attractive because it can utilize a\npre-trained general language model and adapt to the mismatch of the speech\ninput environment. Using this module-based approach, we improve a noisy-channel\nmodel to handle transcription inconsistencies caused by ASR errors. We propose\na two-stage method, Contrastive and Consistency Learning (CCL), that correlates\nerror patterns between clean and noisy ASR transcripts and emphasizes the\nconsistency of the latent features of the two transcripts. Experiments on four\nbenchmark datasets show that CCL outperforms existing methods and improves the\nASR robustness in various noisy environments. Code is available at\nhttps://github.com/syoung7388/CCL.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Suyoung Kim",
            "Jiyeon Hwang",
            "Ho-Young Jung"
        ],
        "published": "2024-05-23T23:10:23Z"
    },
    {
        "title": "Music Genre Classification: Training an AI model",
        "link": "http://arxiv.org/abs/2405.15096v1",
        "abstract": "Music genre classification is an area that utilizes machine learning models\nand techniques for the processing of audio signals, in which applications range\nfrom content recommendation systems to music recommendation systems. In this\nresearch I explore various machine learning algorithms for the purpose of music\ngenre classification, using features extracted from audio signals.The systems\nare namely, a Multilayer Perceptron (built from scratch), a k-Nearest\nNeighbours (also built from scratch), a Convolutional Neural Network and lastly\na Random Forest wide model. In order to process the audio signals, feature\nextraction methods such as Short-Time Fourier Transform, and the extraction of\nMel Cepstral Coefficients (MFCCs), is performed. Through this extensive\nresearch, I aim to asses the robustness of machine learning models for genre\nclassification, and to compare their results.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "authors": [
            "Keoikantse Mogonediwa"
        ],
        "published": "2024-05-23T23:07:01Z"
    },
    {
        "title": "Compilation for Dynamically Field-Programmable Qubit Arrays with\n  Efficient and Provably Near-Optimal Scheduling",
        "link": "http://arxiv.org/abs/2405.15095v1",
        "abstract": "Dynamically field-programmable qubit arrays based on neutral atoms have high\nfidelity and highly parallel gates for quantum computing. However, it is\nchallenging for compilers to fully leverage the novel flexibility offered by\nsuch hardware while respecting its various constraints. In this study, we break\ndown the compilation for this architecture into three tasks: scheduling,\nplacement, and routing. We formulate these three problems and present efficient\nsolutions to them. Notably, our scheduling based on graph edge coloring is\nprovably near-optimal in terms of two-qubit gate stage count (at most one more\nthan the optimum), the fidelity bottleneck of this platform. As a result, our\ncompiler, Enola, produces higher fidelity results compared to existing works,\ne.g., 3.7X stage reduction and 5.9X fidelity improvement on the benchmark set\nused by OLSQ-DPQA, the current state of the art. Additionally, Enola is highly\nscalable, e.g., within 30 minutes, it can compile circuits with 10,000 qubits,\na scale sufficient for the current era of quantum computing. Enola is open\nsource at https://github.com/UCLA-VAST/Enola",
        "subjects": [
            "cs.ET",
            "quant-ph"
        ],
        "authors": [
            "Daniel Bochen Tan",
            "Wan-Hsuan Lin",
            "Jason Cong"
        ],
        "published": "2024-05-23T22:57:49Z"
    },
    {
        "title": "ULTRA-MC: A Unified Approach to Learning Mixtures of Markov Chains via\n  Hitting Times",
        "link": "http://arxiv.org/abs/2405.15094v1",
        "abstract": "This study introduces a novel approach for learning mixtures of Markov\nchains, a critical process applicable to various fields, including healthcare\nand the analysis of web users. Existing research has identified a clear divide\nin methodologies for learning mixtures of discrete and continuous-time Markov\nchains, while the latter presents additional complexities for recovery accuracy\nand efficiency.\n  We introduce a unifying strategy for learning mixtures of discrete and\ncontinuous-time Markov chains, focusing on hitting times, which are well\ndefined for both types. Specifically, we design a reconstruction algorithm that\noutputs a mixture which accurately reflects the estimated hitting times and\ndemonstrates resilience to noise. We introduce an efficient gradient-descent\napproach, specifically tailored to manage the computational complexity and\nnon-symmetric characteristics inherent in the calculation of hitting time\nderivatives. Our approach is also of significant interest when applied to a\nsingle Markov chain, thus extending the methodologies previously established by\nHoskins et al. and Wittmann et al. We complement our theoretical work with\nexperiments conducted on synthetic and real-world datasets, providing a\ncomprehensive evaluation of our methodology.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Fabian Spaeh",
            "Konstantinos Sotiropoulos",
            "Charalampos E. Tsourakakis"
        ],
        "published": "2024-05-23T22:57:15Z"
    },
    {
        "title": "Dissociation of Faithful and Unfaithful Reasoning in LLMs",
        "link": "http://arxiv.org/abs/2405.15092v1",
        "abstract": "Large language models (LLMs) improve their performance in downstream tasks\nwhen they generate Chain of Thought reasoning text before producing an answer.\nOur research investigates how LLMs recover from errors in Chain of Thought,\nreaching the correct final answer despite mistakes in the reasoning text.\nThrough analysis of these error recovery behaviors, we find evidence for\nunfaithfulness in Chain of Thought, but we also identify many clear examples of\nfaithful error recovery behaviors. We identify factors that shift LLM recovery\nbehavior: LLMs recover more frequently from obvious errors and in contexts that\nprovide more evidence for the correct answer. However, unfaithful recoveries\nshow the opposite behavior, occurring more frequently for more difficult error\npositions. Our results indicate that there are distinct mechanisms driving\nfaithful and unfaithful error recoveries. Our results challenge the view that\nLLM reasoning is a uniform, coherent process.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Evelyn Yee",
            "Alice Li",
            "Chenyu Tang",
            "Yeon Ho Jung",
            "Ramamohan Paturi",
            "Leon Bergen"
        ],
        "published": "2024-05-23T22:38:58Z"
    },
    {
        "title": "Pure Exploration for Constrained Best Mixed Arm Identification with a\n  Fixed Budget",
        "link": "http://arxiv.org/abs/2405.15090v1",
        "abstract": "In this paper, we introduce the constrained best mixed arm identification\n(CBMAI) problem with a fixed budget. This is a pure exploration problem in a\nstochastic finite armed bandit model. Each arm is associated with a reward and\nmultiple types of costs from unknown distributions. Unlike the unconstrained\nbest arm identification problem, the optimal solution for the CBMAI problem may\nbe a randomized mixture of multiple arms. The goal thus is to find the best\nmixed arm that maximizes the expected reward subject to constraints on the\nexpected costs with a given learning budget $N$. We propose a novel,\nparameter-free algorithm, called the Score Function-based Successive Reject\n(SFSR) algorithm, that combines the classical successive reject framework with\na novel score-function-based rejection criteria based on linear programming\ntheory to identify the optimal support. We provide a theoretical upper bound on\nthe mis-identification (of the the support of the best mixed arm) probability\nand show that it decays exponentially in the budget $N$ and some constants that\ncharacterize the hardness of the problem instance. We also develop an\ninformation theoretic lower bound on the error probability that shows that\nthese constants appropriately characterize the problem difficulty. We validate\nthis empirically on a number of average and hard instances.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Dengwang Tang",
            "Rahul Jain",
            "Ashutosh Nayyar",
            "Pierluigi Nuzzo"
        ],
        "published": "2024-05-23T22:35:11Z"
    },
    {
        "title": "Targeted Nakamoto: A Bitcoin Protocol to Balance Network Security and\n  Energy Consumption",
        "link": "http://arxiv.org/abs/2405.15089v1",
        "abstract": "In a Proof-of-Work blockchain such as Bitcoin mining hashrate is increasing\nin the block reward. An increase in hashrate reduces network vulnerability to\nattack (a reduction in security cost) while increasing carbon emissions and\nelectricity cost (an increase in externalities cost). This implies a tradeoff\nin total cost at different levels of hashrate and the existence of a hashrate\ninterval where total cost is minimized. Targeted Nakamoto is a Proof-of-Work\nprotocol augmentation that incentivizes miners to hone in on a target hashrate\ninterval. When hashrate is above target a ceiling is placed on the block reward\na miner can receive. When hashrate is below target a floor is placed underneath\nthe miner's block reward. Monetary neutrality is maintained by a proportional\nincrease in spending potential among addresses holding UTXO's to match a\ndeduction from total block reward when the ceiling is operative and a\nproportional reduction in spending potential among addresses holding UTXO's to\nmatch an increase over the total block reward when the floor is binding.",
        "subjects": [
            "cs.CR",
            "C.2.1; C.2.2; C.2.4"
        ],
        "authors": [
            "Daniel Aronoff"
        ],
        "published": "2024-05-23T22:26:25Z"
    },
    {
        "title": "Adaptive Dynamic Bitvectors",
        "link": "http://arxiv.org/abs/2405.15088v1",
        "abstract": "While operations \\emph{rank} and \\emph{select} on static bitvectors can be\nsupported in constant time, lower bounds show that supporting updates raises\nthe cost per operation to $\\Theta(\\log n/ \\log\\log n)$. This is a shame in\nscenarios where updates are possible but uncommon. We develop a representation\nof bitvectors that, if there are $q = \\Omega(\\log^2 n)$ queries per update,\nsupports all the operations in $O(\\log(n/q))$ amortized time. Our experimental\nresults support the theoretical findings, displaying speedups of orders of\nmagnitude compared to standard dynamic implementations.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Gonzalo Navarro"
        ],
        "published": "2024-05-23T22:22:02Z"
    },
    {
        "title": "Acoustical Features as Knee Health Biomarkers: A Critical Analysis",
        "link": "http://arxiv.org/abs/2405.15085v1",
        "abstract": "Acoustical knee health assessment has long promised an alternative to\nclinically available medical imaging tools, but this modality has yet to be\nadopted in medical practice. The field is currently led by machine learning\nmodels processing acoustical features, which have presented promising\ndiagnostic performances. However, these methods overlook the intricate\nmulti-source nature of audio signals and the underlying mechanisms at play. By\naddressing this critical gap, the present paper introduces a novel causal\nframework for validating knee acoustical features. We argue that current\nmachine learning methodologies for acoustical knee diagnosis lack the required\nassurances and thus cannot be used to classify acoustic features as biomarkers.\nOur framework establishes a set of essential theoretical guarantees necessary\nto validate this claim. We apply our methodology to three real-world\nexperiments investigating the effect of researchers' expectations, the\nexperimental protocol and the wearable employed sensor. This investigation\nreveals latent issues such as underlying shortcut learning and performance\ninflation. This study is the first independent result reproduction study in the\nfield of acoustical knee health evaluation. We conclude with actionable\ninsights from our findings, offering valuable guidance to navigate these\ncrucial limitations in future research.",
        "subjects": [
            "eess.SP",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Christodoulos Kechris",
            "Jerome Thevenot",
            "Tomas Teijeiro",
            "Vincent A. Stadelmann",
            "Nicola A. Maffiuletti",
            "David Atienza"
        ],
        "published": "2024-05-23T22:14:50Z"
    },
    {
        "title": "Efficient Certificates of Anti-Concentration Beyond Gaussians",
        "link": "http://arxiv.org/abs/2405.15084v1",
        "abstract": "A set of high dimensional points $X=\\{x_1, x_2,\\ldots, x_n\\} \\subset R^d$ in\nisotropic position is said to be $\\delta$-anti concentrated if for every\ndirection $v$, the fraction of points in $X$ satisfying $|\\langle x_i,v \\rangle\n|\\leq \\delta$ is at most $O(\\delta)$. Motivated by applications to\nlist-decodable learning and clustering, recent works have considered the\nproblem of constructing efficient certificates of anti-concentration in the\naverage case, when the set of points $X$ corresponds to samples from a Gaussian\ndistribution. Their certificates played a crucial role in several subsequent\nworks in algorithmic robust statistics on list-decodable learning and settling\nthe robust learnability of arbitrary Gaussian mixtures, yet remain limited to\nrotationally invariant distributions.\n  This work presents a new (and arguably the most natural) formulation for\nanti-concentration. Using this formulation, we give quasi-polynomial time\nverifiable sum-of-squares certificates of anti-concentration that hold for a\nwide class of non-Gaussian distributions including anti-concentrated bounded\nproduct distributions and uniform distributions over $L_p$ balls (and their\naffine transformations). Consequently, our method upgrades and extends results\nin algorithmic robust statistics e.g., list-decodable learning and clustering,\nto such distributions. Our approach constructs a canonical integer program for\nanti-concentration and analysis a sum-of-squares relaxation of it, independent\nof the intended application. We rely on duality and analyze a\npseudo-expectation on large subsets of the input points that take a small value\nin some direction. Our analysis uses the method of polynomial reweightings to\nreduce the problem to analyzing only analytically dense or sparse directions.",
        "subjects": [
            "cs.DS",
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Ainesh Bakshi",
            "Pravesh Kothari",
            "Goutham Rajendran",
            "Madhur Tulsiani",
            "Aravindan Vijayaraghavan"
        ],
        "published": "2024-05-23T22:13:44Z"
    },
    {
        "title": "MuDreamer: Learning Predictive World Models without Reconstruction",
        "link": "http://arxiv.org/abs/2405.15083v1",
        "abstract": "The DreamerV3 agent recently demonstrated state-of-the-art performance in\ndiverse domains, learning powerful world models in latent space using a pixel\nreconstruction loss. However, while the reconstruction loss is essential to\nDreamer's performance, it also necessitates modeling unnecessary information.\nConsequently, Dreamer sometimes fails to perceive crucial elements which are\nnecessary for task-solving when visual distractions are present in the\nobservation, significantly limiting its potential. In this paper, we present\nMuDreamer, a robust reinforcement learning agent that builds upon the DreamerV3\nalgorithm by learning a predictive world model without the need for\nreconstructing input signals. Rather than relying on pixel reconstruction,\nhidden representations are instead learned by predicting the environment value\nfunction and previously selected actions. Similar to predictive self-supervised\nmethods for images, we find that the use of batch normalization is crucial to\nprevent learning collapse. We also study the effect of KL balancing between\nmodel posterior and prior losses on convergence speed and learning stability.\nWe evaluate MuDreamer on the commonly used DeepMind Visual Control Suite and\ndemonstrate stronger robustness to visual distractions compared to DreamerV3\nand other reconstruction-free approaches, replacing the environment background\nwith task-irrelevant real-world videos. Our method also achieves comparable\nperformance on the Atari100k benchmark while benefiting from faster training.",
        "subjects": [
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Maxime Burchi",
            "Radu Timofte"
        ],
        "published": "2024-05-23T22:09:01Z"
    },
    {
        "title": "ETA-INIT: Enhancing the Translation Accuracy for Stereo Visual-Inertial\n  SLAM Initialization",
        "link": "http://arxiv.org/abs/2405.15082v1",
        "abstract": "As the current initialization method in the state-of-the-art Stereo\nVisual-Inertial SLAM framework, ORB-SLAM3 has limitations. Its success depends\non the performance of the pure stereo SLAM system and is based on the\nunderlying assumption that pure visual SLAM can accurately estimate the camera\ntrajectory, which is essential for inertial parameter estimation. Meanwhile,\nthe further improved initialization method for ORB-SLAM3, known as Stereo-NEC,\nis time-consuming due to applying keypoint tracking to estimate gyroscope bias\nwith normal epipolar constraints. To address the limitations of previous\nmethods, this paper proposes a method aimed at enhancing translation accuracy\nduring the initialization stage. The fundamental concept of our method is to\nimprove the translation estimate with a 3 Degree-of-Freedom (DoF) Bundle\nAdjustment (BA), independently, while the rotation estimate is fixed, instead\nof using ORB-SLAM3's 6-DoF BA. Additionally, the rotation estimate will be\nupdated by considering IMU measurements and gyroscope bias, unlike ORB-SLAM3's\nrotation, which is directly obtained from stereo visual odometry and may yield\ninferior results when operating in challenging scenarios. We also conduct\nextensive evaluations on the public benchmark, the EuRoC dataset, demonstrating\nthat our method excels in accuracy.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Han Song",
            "Zhongche Qu",
            "Zhi Zhang",
            "Zihan Ye",
            "Cong Liu"
        ],
        "published": "2024-05-23T22:08:38Z"
    },
    {
        "title": "Distributed Harmonization: Federated Clustered Batch Effect Adjustment\n  and Generalization",
        "link": "http://arxiv.org/abs/2405.15081v1",
        "abstract": "Independent and identically distributed (i.i.d.) data is essential to many\ndata analysis and modeling techniques. In the medical domain, collecting data\nfrom multiple sites or institutions is a common strategy that guarantees\nsufficient clinical diversity, determined by the decentralized nature of\nmedical data. However, data from various sites are easily biased by the local\nenvironment or facilities, thereby violating the i.i.d. rule. A common strategy\nis to harmonize the site bias while retaining important biological information.\nThe ComBat is among the most popular harmonization approaches and has recently\nbeen extended to handle distributed sites. However, when faced with situations\ninvolving newly joined sites in training or evaluating data from unknown/unseen\nsites, ComBat lacks compatibility and requires retraining with data from all\nthe sites. The retraining leads to significant computational and logistic\noverhead that is usually prohibitive. In this work, we develop a novel Cluster\nComBat harmonization algorithm, which leverages cluster patterns of the data in\ndifferent sites and greatly advances the usability of ComBat harmonization. We\nuse extensive simulation and real medical imaging data from ADNI to demonstrate\nthe superiority of the proposed approach.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Bao Hoang",
            "Yijiang Pang",
            "Siqi Liang",
            "Liang Zhan",
            "Paul Thompson",
            "Jiayu Zhou"
        ],
        "published": "2024-05-23T22:07:54Z"
    },
    {
        "title": "Constructing Interlocking Assemblies with Crystallographic Symmetries",
        "link": "http://arxiv.org/abs/2405.15080v1",
        "abstract": "This work presents a construction method for interlocking assemblies based on\nplanar crystallographic symmetries. Planar crystallographic groups, also known\nas wallpaper groups, correspond to tessellations of the plane with a tile,\ncalled a fundamental domain, such that the action of the group can be used to\ntessellate the plane with the given tile. The main idea of this method is to\nextend the action of a wallpaper group so that it acts on three-dimensional\nspace and places two fundamental domains into parallel planes. Next, we\ninterpolate between these domains to obtain a block that serves as a candidate\nfor interlocking assemblies. We show that the resulting blocks can be\ntriangulated, and we can also approximate blocks with smooth surfaces using\nthis approach. Finally, we show that there exists a family of blocks derived\nfrom this construction that can be tiled in multiple ways, characterised by\ngeneralised Truchet tiles. The assemblies of one block in this family, which we\ncall RhomBlock, correspond to tessellations with lozenges.",
        "subjects": [
            "cs.CG",
            "math.CO"
        ],
        "authors": [
            "Tom Goertzen"
        ],
        "published": "2024-05-23T22:05:01Z"
    },
    {
        "title": "A Survey of Distributed Learning in Cloud, Mobile, and Edge Settings",
        "link": "http://arxiv.org/abs/2405.15079v1",
        "abstract": "In the era of deep learning (DL), convolutional neural networks (CNNs), and\nlarge language models (LLMs), machine learning (ML) models are becoming\nincreasingly complex, demanding significant computational resources for both\ninference and training stages. To address this challenge, distributed learning\nhas emerged as a crucial approach, employing parallelization across various\ndevices and environments. This survey explores the landscape of distributed\nlearning, encompassing cloud and edge settings. We delve into the core concepts\nof data and model parallelism, examining how models are partitioned across\ndifferent dimensions and layers to optimize resource utilization and\nperformance. We analyze various partitioning schemes for different layer types,\nincluding fully connected, convolutional, and recurrent layers, highlighting\nthe trade-offs between computational efficiency, communication overhead, and\nmemory constraints. This survey provides valuable insights for future research\nand development in this rapidly evolving field by comparing and contrasting\ndistributed learning approaches across diverse contexts.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Madison Threadgill",
            "Andreas Gerstlauer"
        ],
        "published": "2024-05-23T22:00:38Z"
    },
    {
        "title": "Eliciting Informative Text Evaluations with Large Language Models",
        "link": "http://arxiv.org/abs/2405.15077v1",
        "abstract": "Peer prediction mechanisms motivate high-quality feedback with provable\nguarantees. However, current methods only apply to rather simple reports, like\nmultiple-choice or scalar numbers. We aim to broaden these techniques to the\nlarger domain of text-based reports, drawing on the recent developments in\nlarge language models. This vastly increases the applicability of peer\nprediction mechanisms as textual feedback is the norm in a large variety of\nfeedback channels: peer reviews, e-commerce customer reviews, and comments on\nsocial media.\n  We introduce two mechanisms, the Generative Peer Prediction Mechanism (GPPM)\nand the Generative Synopsis Peer Prediction Mechanism (GSPPM). These mechanisms\nutilize LLMs as predictors, mapping from one agent's report to a prediction of\nher peer's report. Theoretically, we show that when the LLM prediction is\nsufficiently accurate, our mechanisms can incentivize high effort and\ntruth-telling as an (approximate) Bayesian Nash equilibrium. Empirically, we\nconfirm the efficacy of our mechanisms through experiments conducted on two\nreal datasets: the Yelp review dataset and the ICLR OpenReview dataset. We\nhighlight the results that on the ICLR dataset, our mechanisms can\ndifferentiate three quality levels -- human-written reviews, GPT-4-generated\nreviews, and GPT-3.5-generated reviews in terms of expected scores.\nAdditionally, GSPPM penalizes LLM-generated reviews more effectively than GPPM.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.GT"
        ],
        "authors": [
            "Yuxuan Lu",
            "Shengwei Xu",
            "Yichi Zhang",
            "Yuqing Kong",
            "Grant Schoenebeck"
        ],
        "published": "2024-05-23T21:56:12Z"
    },
    {
        "title": "4+3 Phases of Compute-Optimal Neural Scaling Laws",
        "link": "http://arxiv.org/abs/2405.15074v1",
        "abstract": "We consider the three parameter solvable neural scaling model introduced by\nMaloney, Roberts, and Sully. The model has three parameters: data complexity,\ntarget complexity, and model-parameter-count. We use this neural scaling model\nto derive new predictions about the compute-limited, infinite-data scaling law\nregime. To train the neural scaling model, we run one-pass stochastic gradient\ndescent on a mean-squared loss. We derive a representation of the loss curves\nwhich holds over all iteration counts and improves in accuracy as the model\nparameter count grows. We then analyze the compute-optimal\nmodel-parameter-count, and identify 4 phases (+3 subphases) in the\ndata-complexity/target-complexity phase-plane. The phase boundaries are\ndetermined by the relative importance of model capacity, optimizer noise, and\nembedding of the features. We furthermore derive, with mathematical proof and\nextensive numerical evidence, the scaling-law exponents in all of these phases,\nin particular computing the optimal model-parameter-count as a function of\nfloating point operation budget.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.OC",
            "math.PR",
            "math.ST",
            "stat.TH"
        ],
        "authors": [
            "Elliot Paquette",
            "Courtney Paquette",
            "Lechao Xiao",
            "Jeffrey Pennington"
        ],
        "published": "2024-05-23T21:50:54Z"
    },
    {
        "title": "Temporal Stamp Classifier: Classifying Short Sequences of Astronomical\n  Alerts",
        "link": "http://arxiv.org/abs/2405.15073v1",
        "abstract": "In this work, we propose a deep learning-based classification model of\nastronomical objects using alerts reported by the Zwicky Transient Facility\n(ZTF) survey. The model takes as inputs sequences of stamp images and metadata\ncontained in each alert, as well as features from the All-WISE catalog. The\nproposed model, called temporal stamp classifier, is able to discriminate\nbetween three classes of astronomical objects: Active Galactic Nuclei (AGN),\nSuper-Novae (SNe) and Variable Stars (VS), with an accuracy of approximately\n98% in the test set, when using 2 to 5 detections. The results show that the\nmodel performance improves with the addition of more detections. Simple\nrecurrence models obtain competitive results with those of more complex models\nsuch as LSTM.We also propose changes to the original stamp classifier model,\nwhich only uses the first detection. The performance of the latter model\nimproves with changes in the architecture and the addition of random rotations,\nachieving a 1.46% increase in test accuracy.",
        "subjects": [
            "astro-ph.IM",
            "cs.AI"
        ],
        "authors": [
            "Daniel Neira O.",
            "Pablo A. Estévez",
            "Francisco Förster"
        ],
        "published": "2024-05-23T21:49:32Z"
    },
    {
        "title": "Grokked Transformers are Implicit Reasoners: A Mechanistic Journey to\n  the Edge of Generalization",
        "link": "http://arxiv.org/abs/2405.15071v1",
        "abstract": "We study whether transformers can learn to implicitly reason over parametric\nknowledge, a skill that even the most capable language models struggle with.\nFocusing on two representative reasoning types, composition and comparison, we\nconsistently find that transformers can learn implicit reasoning, but only\nthrough grokking, i.e., extended training far beyond overfitting. The levels of\ngeneralization also vary across reasoning types: when faced with\nout-of-distribution examples, transformers fail to systematically generalize\nfor composition but succeed for comparison. We delve into the model's internals\nthroughout training, conducting analytical experiments that reveal: 1) the\nmechanism behind grokking, such as the formation of the generalizing circuit\nand its relation to the relative efficiency of generalizing and memorizing\ncircuits, and 2) the connection between systematicity and the configuration of\nthe generalizing circuit. Our findings guide data and training setup to better\ninduce implicit reasoning and suggest potential improvements to the transformer\narchitecture, such as encouraging cross-layer knowledge sharing. Furthermore,\nwe demonstrate that for a challenging reasoning task with a large search space,\nGPT-4-Turbo and Gemini-1.5-Pro based on non-parametric memory fail badly\nregardless of prompting styles or retrieval augmentation, while a fully grokked\ntransformer can achieve near-perfect accuracy, showcasing the power of\nparametric memory for complex reasoning.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Boshi Wang",
            "Xiang Yue",
            "Yu Su",
            "Huan Sun"
        ],
        "published": "2024-05-23T21:42:19Z"
    },
    {
        "title": "Optimizing example selection for retrieval-augmented machine translation\n  with translation memories",
        "link": "http://arxiv.org/abs/2405.15070v1",
        "abstract": "Retrieval-augmented machine translation leverages examples from a translation\nmemory by retrieving similar instances. These examples are used to condition\nthe predictions of a neural decoder. We aim to improve the upstream retrieval\nstep and consider a fixed downstream edit-based model: the multi-Levenshtein\nTransformer. The task consists of finding a set of examples that maximizes the\noverall coverage of the source sentence. To this end, we rely on the theory of\nsubmodular functions and explore new algorithms to optimize this coverage. We\nevaluate the resulting performance gains for the machine translation task.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Maxime Bouthors",
            "Josep Crego",
            "François Yvon"
        ],
        "published": "2024-05-23T21:42:03Z"
    },
    {
        "title": "Promoting Constructive Deliberation: Reframing for Receptiveness",
        "link": "http://arxiv.org/abs/2405.15067v1",
        "abstract": "To promote constructive discussion of controversial topics online, we propose\nautomatic reframing of disagreeing responses to signal receptiveness while\npreserving meaning. Drawing on research from psychology, communications, and\nlinguistics, we identify six strategies for reframing. We automatically reframe\nreplies according to each strategy, using a dataset of Reddit comments and\nreplies. Through human-centered experiments, we find that the replies generated\nwith our framework are perceived to be significantly more receptive than the\noriginal replies, as well as a generic receptiveness baseline. We analyze and\ndiscuss the implications of our results and highlight applications to content\nmoderation. Overall, we illustrate how transforming receptiveness, a particular\nsocial science construct, into a computational framework, can make LLM\ngenerations more aligned with human perceptions.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Gauri Kambhatla",
            "Matthew Lease",
            "Ashwin Rajadesingan"
        ],
        "published": "2024-05-23T21:35:22Z"
    },
    {
        "title": "Agile Culture Clash: Unveiling Challenges in Cultivating an Agile\n  Mindset in Organizations",
        "link": "http://arxiv.org/abs/2405.15066v1",
        "abstract": "Context: In agile transformations, there are many challenges such as\nalignment between agile practices and the organizational goals and strategies\nor issues with shifts in how work is organized and executed. One very important\nchallenge but less considered and treated in research are cultural challenges\nassociated with an agile mindset. Although research shows that cultural clashes\nand general organizational resistance to change are part of the most\nsignificant agile adoption barriers. Objective: We identify challenges that\narise from the interplay between agile culture and organizational culture. In\ndoing so, we tackle this field and come up with important contributions for\nfurther research regarding a problem that practitioners face today. Method:\nThis is done with a mixed-method research approach. First, we gathered\nqualitative data among our network of agile practitioners and derived in sum 15\nchallenges with agile culture. Then, we conducted quantitative data by means of\na questionnaire study with 92 participants. Results: We identified 7 key\nchallenges out of the 15 challenges with agile culture. These key challenges\nrefer to the technical agility (doing agile) and the cultural agility (being\nagile). The results are presented in type of a conceptual model named the Agile\nCultural Challenges (ACuCa). Conclusion: Based on our results, we started\nderiving future work aspects to do more detailed research on the topic of\ncultural challenges while transitioning or using agile methods in software\ndevelopment and beyond.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Michael Neumann",
            "Thorben Kuchel",
            "Philipp Diebold",
            "Eva-Maria Schön"
        ],
        "published": "2024-05-23T21:33:38Z"
    },
    {
        "title": "Direct Preference Optimization With Unobserved Preference Heterogeneity",
        "link": "http://arxiv.org/abs/2405.15065v1",
        "abstract": "RLHF has emerged as a pivotal step in aligning language models with human\nobjectives and values. It typically involves learning a reward model from human\npreference data and then using reinforcement learning to update the generative\nmodel accordingly. Conversely, Direct Preference Optimization (DPO) directly\noptimizes the generative model with preference data, skipping reinforcement\nlearning. However, both RLHF and DPO assume uniform preferences, overlooking\nthe reality of diverse human annotators. This paper presents a new method to\nalign generative models with varied human preferences. We propose an\nExpectation-Maximization adaptation to DPO, generating a mixture of models\nbased on latent preference types of the annotators. We then introduce a min-max\nregret ensemble learning model to produce a single generative method to\nminimize worst-case regret among annotator subgroups with similar latent\nfactors. Our algorithms leverage the simplicity of DPO while accommodating\ndiverse preferences. Experimental results validate the effectiveness of our\napproach in producing equitable generative policies.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Keertana Chidambaram",
            "Karthik Vinay Seetharaman",
            "Vasilis Syrgkanis"
        ],
        "published": "2024-05-23T21:25:20Z"
    },
    {
        "title": "Reframing Spatial Reasoning Evaluation in Language Models: A Real-World\n  Simulation Benchmark for Qualitative Reasoning",
        "link": "http://arxiv.org/abs/2405.15064v1",
        "abstract": "Spatial reasoning plays a vital role in both human cognition and machine\nintelligence, prompting new research into language models' (LMs) capabilities\nin this regard. However, existing benchmarks reveal shortcomings in evaluating\nqualitative spatial reasoning (QSR). These benchmarks typically present\noversimplified scenarios or unclear natural language descriptions, hindering\neffective evaluation. We present a novel benchmark for assessing QSR in LMs,\nwhich is grounded in realistic 3D simulation data, offering a series of diverse\nroom layouts with various objects and their spatial relationships. This\napproach provides a more detailed and context-rich narrative for spatial\nreasoning evaluation, diverging from traditional, toy-task-oriented scenarios.\nOur benchmark encompasses a broad spectrum of qualitative spatial\nrelationships, including topological, directional, and distance relations.\nThese are presented with different viewing points, varied granularities, and\ndensity of relation constraints to mimic real-world complexities. A key\ncontribution is our logic-based consistency-checking tool, which enables the\nassessment of multiple plausible solutions, aligning with real-world scenarios\nwhere spatial relationships are often open to interpretation. Our benchmark\nevaluation of advanced LMs reveals their strengths and limitations in spatial\nreasoning. They face difficulties with multi-hop spatial reasoning and\ninterpreting a mix of different view descriptions, pointing to areas for future\nimprovement.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.DB"
        ],
        "authors": [
            "Fangjun Li",
            "David C. Hogg",
            "Anthony G. Cohn"
        ],
        "published": "2024-05-23T21:22:00Z"
    },
    {
        "title": "A classification model based on a population of hypergraphs",
        "link": "http://arxiv.org/abs/2405.15063v1",
        "abstract": "This paper introduces a novel hypergraph classification algorithm. The use of\nhypergraphs in this framework has been widely studied. In previous work,\nhypergraph models are typically constructed using distance or attribute based\nmethods. That is, hyperedges are generated by connecting a set of samples which\nare within a certain distance or have a common attribute. These methods\nhowever, do not often focus on multi-way interactions directly. The algorithm\nprovided in this paper looks to address this problem by constructing\nhypergraphs which explore multi-way interactions of any order. We also increase\nthe performance and robustness of the algorithm by using a population of\nhypergraphs. The algorithm is evaluated on two datasets, demonstrating\npromising performance compared to a generic random forest classification\nalgorithm.",
        "subjects": [
            "cs.LG",
            "math.CO"
        ],
        "authors": [
            "Samuel Barton",
            "Adelle Coster",
            "Diane Donovan",
            "James Lefevre"
        ],
        "published": "2024-05-23T21:21:59Z"
    },
    {
        "title": "Model-Agnostic Utility-Preserving Biometric Information Anonymization",
        "link": "http://arxiv.org/abs/2405.15062v1",
        "abstract": "The recent rapid advancements in both sensing and machine learning\ntechnologies have given rise to the universal collection and utilization of\npeople's biometrics, such as fingerprints, voices, retina/facial scans, or\ngait/motion/gestures data, enabling a wide range of applications including\nauthentication, health monitoring, or much more sophisticated analytics. While\nproviding better user experiences and deeper business insights, the use of\nbiometrics has raised serious privacy concerns due to their intrinsic sensitive\nnature and the accompanying high risk of leaking sensitive information such as\nidentity or medical conditions.\n  In this paper, we propose a novel modality-agnostic data transformation\nframework that is capable of anonymizing biometric data by suppressing its\nsensitive attributes and retaining features relevant to downstream machine\nlearning-based analyses that are of research and business values. We carried\nout a thorough experimental evaluation using publicly available facial, voice,\nand motion datasets. Results show that our proposed framework can achieve a\n\\highlight{high suppression level for sensitive information}, while at the same\ntime retain underlying data utility such that subsequent analyses on the\nanonymized biometric data could still be carried out to yield satisfactory\naccuracy.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Chun-Fu Chen",
            "Bill Moriarty",
            "Shaohan Hu",
            "Sean Moran",
            "Marco Pistoia",
            "Vincenzo Piuri",
            "Pierangela Samarati"
        ],
        "published": "2024-05-23T21:21:40Z"
    },
    {
        "title": "Message-Passing Monte Carlo: Generating low-discrepancy point sets via\n  Graph Neural Networks",
        "link": "http://arxiv.org/abs/2405.15059v1",
        "abstract": "Discrepancy is a well-known measure for the irregularity of the distribution\nof a point set. Point sets with small discrepancy are called low-discrepancy\nand are known to efficiently fill the space in a uniform manner.\nLow-discrepancy points play a central role in many problems in science and\nengineering, including numerical integration, computer vision, machine\nperception, computer graphics, machine learning, and simulation. In this work,\nwe present the first machine learning approach to generate a new class of\nlow-discrepancy point sets named Message-Passing Monte Carlo (MPMC) points.\nMotivated by the geometric nature of generating low-discrepancy point sets, we\nleverage tools from Geometric Deep Learning and base our model on Graph Neural\nNetworks. We further provide an extension of our framework to higher\ndimensions, which flexibly allows the generation of custom-made points that\nemphasize the uniformity in specific dimensions that are primarily important\nfor the particular problem at hand. Finally, we demonstrate that our proposed\nmodel achieves state-of-the-art performance superior to previous methods by a\nsignificant margin. In fact, MPMC points are empirically shown to be either\noptimal or near-optimal with respect to the discrepancy for every dimension and\nthe number of points for which the optimal discrepancy can be determined.",
        "subjects": [
            "cs.LG",
            "cs.NA",
            "math.NA",
            "stat.ML"
        ],
        "authors": [
            "T. Konstantin Rusch",
            "Nathan Kirk",
            "Michael M. Bronstein",
            "Christiane Lemieux",
            "Daniela Rus"
        ],
        "published": "2024-05-23T21:17:20Z"
    },
    {
        "title": "ElastoGen: 4D Generative Elastodynamics",
        "link": "http://arxiv.org/abs/2405.15056v1",
        "abstract": "We present ElastoGen, a knowledge-driven model that generates physically\naccurate and coherent 4D elastodynamics. Instead of relying on petabyte-scale\ndata-driven learning, ElastoGen leverages the principles of physics-in-the-loop\nand learns from established physical knowledge, such as partial differential\nequations and their numerical solutions. The core idea of ElastoGen is\nconverting the global differential operator, corresponding to the nonlinear\nelastodynamic equations, into iterative local convolution-like operations,\nwhich naturally fit modern neural networks. Each network module is specifically\ndesigned to support this goal rather than functioning as a black box. As a\nresult, ElastoGen is exceptionally lightweight in terms of both training\nrequirements and network scale. Additionally, due to its alignment with\nphysical procedures, ElastoGen efficiently generates accurate dynamics for a\nwide range of hyperelastic materials and can be easily integrated with upstream\nand downstream deep modules to enable end-to-end 4D generation.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "cs.GR"
        ],
        "authors": [
            "Yutao Feng",
            "Yintong Shang",
            "Xiang Feng",
            "Lei Lan",
            "Shandian Zhe",
            "Tianjia Shao",
            "Hongzhi Wu",
            "Kun Zhou",
            "Hao Su",
            "Chenfanfu Jiang",
            "Yin Yang"
        ],
        "published": "2024-05-23T21:09:36Z"
    },
    {
        "title": "CCBNet: Confidential Collaborative Bayesian Networks Inference",
        "link": "http://arxiv.org/abs/2405.15055v1",
        "abstract": "Effective large-scale process optimization in manufacturing industries\nrequires close cooperation between different human expert parties who encode\ntheir knowledge of related domains as Bayesian network models. For instance,\nBayesian networks for domains such as lithography equipment, processes, and\nauxiliary tools must be conjointly used to effectively identify process\noptimizations in the semiconductor industry. However, business confidentiality\nacross domains hinders such collaboration, and encourages alternatives to\ncentralized inference. We propose CCBNet, the first Confidentiality-preserving\nCollaborative Bayesian Network inference framework. CCBNet leverages secret\nsharing to securely perform analysis on the combined knowledge of party models\nby joining two novel subprotocols: (i) CABN, which augments probability\ndistributions for features across parties by modeling them into secret shares\nof their normalized combination; and (ii) SAVE, which aggregates party\ninference result shares through distributed variable elimination. We\nextensively evaluate CCBNet via 9 public Bayesian networks. Our results show\nthat CCBNet achieves predictive quality that is similar to the ones of\ncentralized methods while preserving model confidentiality. We further\ndemonstrate that CCBNet scales to challenging manufacturing use cases that\ninvolve 16-128 parties in large networks of 223-1003 features, and decreases,\non average, computational overhead by 23%, while communicating 71k values per\nrequest. Finally, we showcase possible attacks and mitigations for partially\nreconstructing party networks in the two subprotocols.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Abele Mălan",
            "Jérémie Decouchant",
            "Thiago Guzella",
            "Lydia Chen"
        ],
        "published": "2024-05-23T21:05:08Z"
    },
    {
        "title": "Controlling Behavioral Diversity in Multi-Agent Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.15054v1",
        "abstract": "The study of behavioral diversity in Multi-Agent Reinforcement Learning\n(MARL) is a nascent yet promising field. In this context, the present work\ndeals with the question of how to control the diversity of a multi-agent\nsystem. With no existing approaches to control diversity to a set value,\ncurrent solutions focus on blindly promoting it via intrinsic rewards or\nadditional loss functions, effectively changing the learning objective and\nlacking a principled measure for it. To address this, we introduce Diversity\nControl (DiCo), a method able to control diversity to an exact value of a given\nmetric by representing policies as the sum of a parameter-shared component and\ndynamically scaled per-agent components. By applying constraints directly to\nthe policy architecture, DiCo leaves the learning objective unchanged, enabling\nits applicability to any actor-critic MARL algorithm. We theoretically prove\nthat DiCo achieves the desired diversity, and we provide several experiments,\nboth in cooperative and competitive tasks, that show how DiCo can be employed\nas a novel paradigm to increase performance and sample efficiency in MARL.\nMultimedia results are available on the paper's website:\nhttps://sites.google.com/view/dico-marl.",
        "subjects": [
            "cs.MA",
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ],
        "authors": [
            "Matteo Bettini",
            "Ryan Kortvelesy",
            "Amanda Prorok"
        ],
        "published": "2024-05-23T21:03:33Z"
    },
    {
        "title": "Revisiting MoE and Dense Speed-Accuracy Comparisons for LLM Training",
        "link": "http://arxiv.org/abs/2405.15052v1",
        "abstract": "Mixture-of-Experts (MoE) enjoys performance gain by increasing model capacity\nwhile keeping computation cost constant. When comparing MoE to dense models,\nprior work typically adopt the following setting: 1) use FLOPs or activated\nparameters as a measure of model complexity; 2) train all models to the same\nnumber of tokens. We argue that this setting favors MoE as FLOPs and activated\nparameters do not accurately measure the communication overhead in sparse\nlayers, leading to a larger actual training budget for MoE. In this work, we\nrevisit the settings by adopting step time as a more accurate measure of model\ncomplexity, and by determining the total compute budget under the Chinchilla\ncompute-optimal settings. To efficiently run MoE on modern accelerators, we\nadopt a 3D sharding method that keeps the dense-to-MoE step time increase\nwithin a healthy range. We evaluate MoE and dense LLMs on a set of nine 0-shot\nand two 1-shot English tasks, as well as MMLU 5-shot and GSM8K 8-shot across\nthree model scales at 6.4B, 12.6B, and 29.6B. Experimental results show that\neven under these settings, MoE consistently outperform dense LLMs on the\nspeed-accuracy trade-off curve with meaningful gaps. Our full model\nimplementation and sharding strategy will be released\nat~\\url{https://github.com/apple/axlearn}",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Xianzhi Du",
            "Tom Gunter",
            "Xiang Kong",
            "Mark Lee",
            "Zirui Wang",
            "Aonan Zhang",
            "Nan Du",
            "Ruoming Pang"
        ],
        "published": "2024-05-23T21:00:53Z"
    },
    {
        "title": "From Explainable to Interactive AI: A Literature Review on Current\n  Trends in Human-AI Interaction",
        "link": "http://arxiv.org/abs/2405.15051v1",
        "abstract": "AI systems are increasingly being adopted across various domains and\napplication areas. With this surge, there is a growing research focus and\nsocietal concern for actively involving humans in developing, operating, and\nadopting these systems. Despite this concern, most existing literature on AI\nand Human-Computer Interaction (HCI) primarily focuses on explaining how AI\nsystems operate and, at times, allowing users to contest AI decisions. Existing\nstudies often overlook more impactful forms of user interaction with AI\nsystems, such as giving users agency beyond contestability and enabling them to\nadapt and even co-design the AI's internal mechanics. In this survey, we aim to\nbridge this gap by reviewing the state-of-the-art in Human-Centered AI\nliterature, the domain where AI and HCI studies converge, extending past\nExplainable and Contestable AI, delving into the Interactive AI and beyond. Our\nanalysis contributes to shaping the trajectory of future Interactive AI design\nand advocates for a more user-centric approach that provides users with greater\nagency, fostering not only their understanding of AI's workings but also their\nactive engagement in its development and evolution.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Muhammad Raees",
            "Inge Meijerink",
            "Ioanna Lykourentzou",
            "Vassilis-Javed Khan",
            "Konstantinos Papangelis"
        ],
        "published": "2024-05-23T20:59:20Z"
    },
    {
        "title": "Provably Efficient Reinforcement Learning for Infinite-Horizon\n  Average-Reward Linear MDPs",
        "link": "http://arxiv.org/abs/2405.15050v1",
        "abstract": "We resolve the open problem of designing a computationally efficient\nalgorithm for infinite-horizon average-reward linear Markov Decision Processes\n(MDPs) with $\\widetilde{O}(\\sqrt{T})$ regret. Previous approaches with\n$\\widetilde{O}(\\sqrt{T})$ regret either suffer from computational inefficiency\nor require strong assumptions on dynamics, such as ergodicity. In this paper,\nwe approximate the average-reward setting by the discounted setting and show\nthat running an optimistic value iteration-based algorithm for learning the\ndiscounted setting achieves $\\widetilde{O}(\\sqrt{T})$ regret when the\ndiscounting factor $\\gamma$ is tuned appropriately. The challenge in the\napproximation approach is to get a regret bound with a sharp dependency on the\neffective horizon $1 / (1 - \\gamma)$. We use a computationally efficient\nclipping operator that constrains the span of the optimistic state value\nfunction estimate to achieve a sharp regret bound in terms of the effective\nhorizon, which leads to $\\widetilde{O}(\\sqrt{T})$ regret.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Kihyuk Hong",
            "Yufan Zhang",
            "Ambuj Tewari"
        ],
        "published": "2024-05-23T20:58:33Z"
    },
    {
        "title": "Credal Wrapper of Model Averaging for Uncertainty Estimation on\n  Out-Of-Distribution Detection",
        "link": "http://arxiv.org/abs/2405.15047v1",
        "abstract": "This paper presents an innovative approach, called credal wrapper, to\nformulating a credal set representation of model averaging for Bayesian neural\nnetworks (BNNs) and deep ensembles, capable of improving uncertainty estimation\nin classification tasks. Given a finite collection of single distributions\nderived from BNNs or deep ensembles, the proposed approach extracts an upper\nand a lower probability bound per class, acknowledging the epistemic\nuncertainty due to the availability of a limited amount of sampled predictive\ndistributions. Such probability intervals over classes can be mapped on a\nconvex set of probabilities (a 'credal set') from which, in turn, a unique\nprediction can be obtained using a transformation called 'intersection\nprobability transformation'. In this article, we conduct extensive experiments\non multiple out-of-distribution (OOD) detection benchmarks, encompassing\nvarious dataset pairs (CIFAR10/100 vs SVHN/Tiny-ImageNet, CIFAR10 vs CIFAR10-C,\nCIFAR100 vs CIFAR100-C and ImageNet vs ImageNet-O) and using different network\narchitectures (such as VGG16, Res18/50, EfficientNet B2, and ViT Base).\nCompared to BNN and deep ensemble baselines, the proposed credal representation\nmethodology exhibits superior performance in uncertainty estimation and\nachieves lower expected calibration error on OOD samples.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Kaizheng Wang",
            "Fabio Cuzzolin",
            "Keivan Shariatmadar",
            "David Moens",
            "Hans Hallez"
        ],
        "published": "2024-05-23T20:51:22Z"
    },
    {
        "title": "On the minimum spectral radius of connected graphs of given order and\n  size",
        "link": "http://arxiv.org/abs/2405.15046v1",
        "abstract": "In this paper, we study a question of Hong from 1993 related to the minimum\nspectral radii of the adjacency matrices of connected graphs of given order and\nsize. Hong asked if it is true that among all connected graphs of given number\nof vertices $n$ and number of edges $e$, the graphs having minimum spectral\nradius (the minimizer graphs) must be almost regular, meaning that the\ndifference between their maximum degree and their minimum degree is at most\none. In this paper, we answer Hong's question positively for various values of\n$n$ and $e$ and in several cases, we determined the graphs with minimum\nspectral radius.",
        "subjects": [
            "math.CO",
            "cs.DM",
            "05C50, 15A18"
        ],
        "authors": [
            "Sebastian M. Cioabă",
            "Vishal Gupta",
            "Celso Marques"
        ],
        "published": "2024-05-23T20:46:04Z"
    },
    {
        "title": "CEEBERT: Cross-Domain Inference in Early Exit BERT",
        "link": "http://arxiv.org/abs/2405.15039v1",
        "abstract": "Pre-trained Language Models (PLMs), like BERT, with self-supervision\nobjectives exhibit remarkable performance and generalization across various\ntasks. However, they suffer in inference latency due to their large size. To\naddress this issue, side branches are attached at intermediate layers, enabling\nearly inference of samples without requiring them to pass through all layers.\nHowever, the challenge is to decide which layer to infer and exit each sample\nso that the accuracy and latency are balanced. Moreover, the distribution of\nthe samples to be inferred may differ from that used for training necessitating\ncross-domain adaptation. We propose an online learning algorithm named\nCross-Domain Inference in Early Exit BERT (CeeBERT) that dynamically determines\nearly exits of samples based on the level of confidence at each exit point.\nCeeBERT learns optimal thresholds from domain-specific confidence observed at\nintermediate layers on the fly, eliminating the need for labeled data.\nExperimental results on five distinct datasets with BERT and ALBERT models\ndemonstrate CeeBERT's ability to improve latency by reducing unnecessary\ncomputations with minimal drop in performance. By adapting to the threshold\nvalues, CeeBERT can speed up the BERT/ALBERT models by $2\\times$ - $3.5\\times$\nwith minimal drop in accuracy.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Divya Jyoti Bajpai",
            "Manjesh Kumar Hanawal"
        ],
        "published": "2024-05-23T20:36:10Z"
    },
    {
        "title": "\"This really lets us see the entire world:\" Designing a conversational\n  telepresence robot for homebound older adults",
        "link": "http://dx.doi.org/10.1145/3643834.3660710",
        "abstract": "In this paper, we explore the design and use of conversational telepresence\nrobots to help homebound older adults interact with the external world. An\ninitial needfinding study (N=8) using video vignettes revealed older adults'\nexperiential needs for robot-mediated remote experiences such as exploration,\nreminiscence and social participation. We then designed a prototype system to\nsupport these goals and conducted a technology probe study (N=11) to garner a\ndeeper understanding of user preferences for remote experiences. The study\nrevealed user interactive patterns in each desired experience, highlighting the\nneed of robot guidance, social engagements with the robot and the remote\nbystanders. Our work identifies a novel design space where conversational\ntelepresence robots can be used to foster meaningful interactions in the remote\nphysical environment. We offer design insights into the robot's proactive role\nin providing guidance and using dialogue to create personalized, contextualized\nand meaningful experiences.",
        "subjects": [
            "cs.HC",
            "cs.RO",
            "68-06"
        ],
        "authors": [
            "Yaxin Hu",
            "Laura Stegner",
            "Yasmine Kotturi",
            "Caroline Zhang",
            "Yi-Hao Peng",
            "Faria Huq",
            "Yuhang Zhao",
            "Jeffrey P. Bigham",
            "Bilge Mutlu"
        ],
        "published": "2024-05-23T20:15:48Z"
    },
    {
        "title": "Input-driven circuit reconfiguration in critical recurrent neural\n  networks.Marcelo O. Magnasco",
        "link": "http://arxiv.org/abs/2405.15036v1",
        "abstract": "Changing a circuit dynamically, without actually changing the hardware\nitself, is called reconfiguration, and is of great importance due to its\nmanifold technological applications. Circuit reconfiguration appears to be a\nfeature of the cerebral cortex, and hence understanding the neuroarchitectural\nand dynamical features underlying self-reconfiguration may prove key to\nelucidate brain function. We present a very simple single-layer recurrent\nnetwork, whose signal pathways can be reconfigured \"on the fly\" using only its\ninputs, with no changes to its synaptic weights. We use the low spatio-temporal\nfrequencies of the input to landscape the ongoing activity, which in turn\npermits or denies the propagation of traveling waves. This mechanism uses the\ninherent properties of dynamically-critical systems, which we guarantee through\nunitary convolution kernels. We show this network solves the classical\nconnectedness problem, by allowing signal propagation only along the regions to\nbe evaluated for connectedness and forbidding it elsewhere.",
        "subjects": [
            "cond-mat.stat-mech",
            "cs.LG",
            "q-bio.NC"
        ],
        "authors": [
            "Marcelo O. Magnasco"
        ],
        "published": "2024-05-23T20:15:23Z"
    },
    {
        "title": "NeCGS: Neural Compression for 3D Geometry Sets",
        "link": "http://arxiv.org/abs/2405.15034v1",
        "abstract": "This paper explores the problem of effectively compressing 3D geometry sets\ncontaining diverse categories. We make \\textit{the first} attempt to tackle\nthis fundamental and challenging problem and propose NeCGS, a neural\ncompression paradigm, which can compress hundreds of detailed and diverse 3D\nmesh models (~684 MB) by about 900 times (0.76 MB) with high accuracy and\npreservation of detailed geometric details. Specifically, we first represent\neach irregular mesh model/shape in a regular representation that implicitly\ndescribes the geometry structure of the model using a 4D regular volume, called\nTSDF-Def volume. Such a regular representation can not only capture local\nsurfaces more effectively but also facilitate the subsequent process. Then we\nconstruct a quantization-aware auto-decoder network architecture to regress\nthese 4D volumes, which can summarize the similarity of local geometric\nstructures within a model and across different models for redundancy\nlimination, resulting in more compact representations, including an embedded\nfeature of a smaller size associated with each model and a network parameter\nset shared by all models. We finally encode the resulting features and network\nparameters into bitstreams through entropy coding. After decompressing the\nfeatures and network parameters, we can reconstruct the TSDF-Def volumes, where\nthe 3D surfaces can be extracted through the deformable marching\ncubes.Extensive experiments and ablation studies demonstrate the significant\nadvantages of our NeCGS over state-of-the-art methods both quantitatively and\nqualitatively.",
        "subjects": [
            "cs.CG"
        ],
        "authors": [
            "Siyu Ren",
            "Junhui Hou",
            "Wenping Wang"
        ],
        "published": "2024-05-23T20:11:37Z"
    },
    {
        "title": "Generating camera failures as a class of physics-based adversarial\n  examples",
        "link": "http://arxiv.org/abs/2405.15033v1",
        "abstract": "While there has been extensive work on generating physics-based adversarial\nsamples recently, an overlooked class of such samples come from physical\nfailures in the camera. Camera failures can occur as a result of an external\nphysical process, i.e. breakdown of a component due to stress, or an internal\ncomponent failure. In this work, we develop a simulated physical process for\ngenerating broken lens as a class of physics-based adversarial samples. We\ncreate a stress-based physical simulation by generating particles constrained\nin a mesh and apply stress at a random point and at a random angle. We perform\nstress propagation through the mesh and the end result of the mesh is a\ncorresponding image which simulates the broken lens pattern. We also develop a\nneural emulator which learns the non-linear mapping between the mesh as a graph\nand the stress propagation using constrained propagation setup. We can then\nstatistically compare the difference between the generated adversarial samples\nwith real, simulated and emulated adversarial examples using the detection\nfailure rate of the different classes and in between the samples using the\nFrechet Inception distance. Our goal through this work is to provide a robust\nphysics based process for generating adversarial samples.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "eess.IV"
        ],
        "authors": [
            "Manav Prabhakar",
            "Jwalandhar Girnar",
            "Arpan Kusari"
        ],
        "published": "2024-05-23T20:11:20Z"
    },
    {
        "title": "Aya 23: Open Weight Releases to Further Multilingual Progress",
        "link": "http://arxiv.org/abs/2405.15032v1",
        "abstract": "This technical report introduces Aya 23, a family of multilingual language\nmodels. Aya 23 builds on the recent release of the Aya model (\\\"Ust\\\"un et al.,\n2024), focusing on pairing a highly performant pre-trained model with the\nrecently released Aya collection (Singh et al., 2024). The result is a powerful\nmultilingual large language model serving 23 languages, expanding state-of-art\nlanguage modeling capabilities to approximately half of the world's population.\nThe Aya model covered 101 languages whereas Aya 23 is an experiment in depth vs\nbreadth, exploring the impact of allocating more capacity to fewer languages\nthat are included during pre-training. Aya 23 outperforms both previous\nmassively multilingual models like Aya 101 for the languages it covers, as well\nas widely used models like Gemma, Mistral and Mixtral on an extensive range of\ndiscriminative and generative tasks. We release the open weights for both the\n8B and 35B models as part of our continued commitment for expanding access to\nmultilingual progress.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Viraat Aryabumi",
            "John Dang",
            "Dwarak Talupuru",
            "Saurabh Dash",
            "David Cairuz",
            "Hangyu Lin",
            "Bharat Venkitesh",
            "Madeline Smith",
            "Kelly Marchisio",
            "Sebastian Ruder",
            "Acyr Locatelli",
            "Julia Kreutzer",
            "Nick Frosst",
            "Phil Blunsom",
            "Marzieh Fadaee",
            "Ahmet Üstün",
            "Sara Hooker"
        ],
        "published": "2024-05-23T20:10:38Z"
    },
    {
        "title": "Amortized nonmyopic active search via deep imitation learning",
        "link": "http://arxiv.org/abs/2405.15031v1",
        "abstract": "Active search formalizes a specialized active learning setting where the goal\nis to collect members of a rare, valuable class. The state-of-the-art algorithm\napproximates the optimal Bayesian policy in a budget-aware manner, and has been\nshown to achieve impressive empirical performance in previous work. However,\neven this approximate policy has a superlinear computational complexity with\nrespect to the size of the search problem, rendering its application\nimpractical in large spaces or in real-time systems where decisions must be\nmade quickly. We study the amortization of this policy by training a neural\nnetwork to learn to search. To circumvent the difficulty of learning from\nscratch, we appeal to imitation learning techniques to mimic the behavior of\nthe expert, expensive-to-compute policy. Our policy network, trained on\nsynthetic data, learns a beneficial search strategy that yields nonmyopic\ndecisions carefully balancing exploration and exploitation. Extensive\nexperiments demonstrate our policy achieves competitive performance at\nreal-world tasks that closely approximates the expert's at a fraction of the\ncost, while outperforming cheaper baselines.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Quan Nguyen",
            "Anindya Sarkar",
            "Roman Garnett"
        ],
        "published": "2024-05-23T20:10:29Z"
    },
    {
        "title": "AGRaME: Any-Granularity Ranking with Multi-Vector Embeddings",
        "link": "http://arxiv.org/abs/2405.15028v1",
        "abstract": "Ranking is a fundamental and popular problem in search. However, existing\nranking algorithms usually restrict the granularity of ranking to full passages\nor require a specific dense index for each desired level of granularity. Such\nlack of flexibility in granularity negatively affects many applications that\ncan benefit from more granular ranking, such as sentence-level ranking for\nopen-domain question-answering, or proposition-level ranking for attribution.\nIn this work, we introduce the idea of any-granularity ranking, which leverages\nmulti-vector embeddings to rank at varying levels of granularity while\nmaintaining encoding at a single (coarser) level of granularity. We propose a\nmulti-granular contrastive loss for training multi-vector approaches, and\nvalidate its utility with both sentences and propositions as ranking units.\nFinally, we demonstrate the application of proposition-level ranking to\npost-hoc citation addition in retrieval-augmented generation, surpassing the\nperformance of prompt-driven citation generation.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "authors": [
            "Revanth Gangi Reddy",
            "Omar Attia",
            "Yunyao Li",
            "Heng Ji",
            "Saloni Potdar"
        ],
        "published": "2024-05-23T20:04:54Z"
    },
    {
        "title": "Enhancing Student Feedback Using Predictive Models in Visual Literacy\n  Courses",
        "link": "http://arxiv.org/abs/2405.15026v1",
        "abstract": "Peer review is a popular feedback mechanism in higher education that actively\nengages students and provides researchers with a means to assess student\nengagement. However, there is little empirical support for the durability of\npeer review, particularly when using data predictive modeling to analyze\nstudent comments. This study uses Na\\\"ive Bayes modeling to analyze peer review\ndata obtained from an undergraduate visual literacy course over five years. We\nexpand on the research of Friedman and Rosen and Beasley et al. by focusing on\nthe Na\\\"ive Bayes model of students' remarks. Our findings highlight the\nutility of Na\\\"ive Bayes modeling, particularly in the analysis of student\ncomments based on parts of speech, where nouns emerged as the prominent\ncategory. Additionally, when examining students' comments using the visual peer\nreview rubric, the lie factor emerged as the predominant factor. Comparing\nNa\\\"ive Bayes model to Beasley's approach, we found both help instructors map\ndirections taken in the class, but the Na\\\"ive Bayes model provides a more\nspecific outline for forecasting with a more detailed framework for identifying\ncore topics within the course, enhancing the forecasting of educational\ndirections. Through the application of the Holdout Method and $\\mathrm{k}$-fold\ncross-validation with continuity correction, we have validated the model's\npredictive accuracy, underscoring its effectiveness in offering deep insights\ninto peer review mechanisms. Our study findings suggest that using predictive\nmodeling to assess student comments can provide a new way to better serve the\nstudents' classroom comments on their visual peer work. This can benefit\ncourses by inspiring changes to course content, reinforcement of course\ncontent, modification of projects, or modifications to the rubric itself.",
        "subjects": [
            "cs.MM",
            "cs.CY"
        ],
        "authors": [
            "Alon Friedman",
            "Kevin Hawley",
            "Paul Rosen",
            "Md Dilshadur Rahman"
        ],
        "published": "2024-05-23T20:02:36Z"
    },
    {
        "title": "OAC: Output-adaptive Calibration for Accurate Post-training Quantization",
        "link": "http://arxiv.org/abs/2405.15025v1",
        "abstract": "Deployment of Large Language Models (LLMs) has major computational costs, due\nto their rapidly expanding size. Compression of LLMs reduces the memory\nfootprint, latency, and energy required for their inference. Post-training\nQuantization (PTQ) techniques have been developed to compress LLMs while\navoiding expensive re-training. Most PTQ approaches formulate the quantization\nerror based on a layer-wise $\\ell_2$ loss, ignoring the model output. Then,\neach layer is calibrated using its layer-wise Hessian to update the weights\ntowards minimizing the $\\ell_2$ quantization error. The Hessian is also used\nfor detecting the most salient weights to quantization. Such PTQ approaches are\nprone to accuracy drop in low-precision quantization. We propose\nOutput-adaptive Calibration (OAC) to incorporate the model output in the\ncalibration process. We formulate the quantization error based on the\ndistortion of the output cross-entropy loss. OAC approximates the\noutput-adaptive Hessian for each layer under reasonable assumptions to reduce\nthe computational complexity. The output-adaptive Hessians are used to update\nthe weight matrices and detect the salient weights towards maintaining the\nmodel output. Our proposed method outperforms the state-of-the-art baselines\nsuch as SpQR and BiLLM, especially, at extreme low-precision (2-bit and binary)\nquantization.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "authors": [
            "Ali Edalati",
            "Alireza Ghaffari",
            "Masoud Asgharian",
            "Lu Hou",
            "Boxing Chen",
            "Vahid Partovi Nia"
        ],
        "published": "2024-05-23T20:01:17Z"
    },
    {
        "title": "ROB 204: Introduction to Human-Robot Systems at the University of\n  Michigan, Ann Arbor",
        "link": "http://arxiv.org/abs/2405.15023v1",
        "abstract": "The University of Michigan Robotics program focuses on the study of embodied\nintelligence that must sense, reason, act, and work with people to improve\nquality of life and productivity equitably across society. ROB 204, part of the\ncore curriculum towards the undergraduate degree in Robotics, introduces\nstudents to topics that enable conceptually designing a robotic system to\naddress users' needs from a sociotechnical context. Students are introduced to\nhuman-robot interaction (HRI) concepts and the process for socially-engaged\ndesign with a Learn-Reinforce-Integrate approach. In this paper, we discuss the\ncourse topics and our teaching methodology, and provide recommendations for\ndelivering this material. Overall, students leave the course with a new\nunderstanding and appreciation for how human capabilities can inform\nrequirements for a robotics system, how humans can interact with a robot, and\nhow to assess the usability of robotic systems.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Leia Stirling",
            "Joseph Montgomery",
            "Mark Draelos",
            "Christoforos Mavrogiannis",
            "Lionel P. Robert Jr.",
            "Odest Chadwicke Jenkins"
        ],
        "published": "2024-05-23T19:59:34Z"
    },
    {
        "title": "AdjointDEIS: Efficient Gradients for Diffusion Models",
        "link": "http://arxiv.org/abs/2405.15020v1",
        "abstract": "The optimization of the latents and parameters of diffusion models with\nrespect to some differentiable metric defined on the output of the model is a\nchallenging and complex problem. The sampling for diffusion models is done by\nsolving either the probability flow ODE or diffusion SDE wherein a neural\nnetwork approximates the score function or related quantity, allowing a\nnumerical ODE/SDE solver to be used. However, na\\\"ive backpropagation\ntechniques are memory intensive, requiring the storage of all intermediate\nstates, and face additional complexity in handling the injected noise from the\ndiffusion term of the diffusion SDE. We propose a novel method based on the\nstochastic adjoint sensitivity method to calculate the gradientwith respect to\nthe initial noise, conditional information, and model parameters by solving an\nadditional SDE whose solution is the gradient of the diffusion SDE. We exploit\nthe unique construction of diffusion SDEs to further simplify the formulation\nof the adjoint diffusion SDE and use a change-of-variables to simplify the\nsolution to an exponentially weighted integral. Using this formulation we\nderive a custom solver for the adjoint SDE as well as the simpler adjoint ODE.\nThe proposed adjoint diffusion solvers can efficiently compute the gradients\nfor both the probability flow ODE and diffusion SDE for latents and parameters\nof the model. Lastly, we demonstrate the effectiveness of the adjoint diffusion\nsolvers onthe face morphing problem.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Zander W. Blasingame",
            "Chen Liu"
        ],
        "published": "2024-05-23T19:51:33Z"
    },
    {
        "title": "Agentic Skill Discovery",
        "link": "http://arxiv.org/abs/2405.15019v1",
        "abstract": "Language-conditioned robotic skills make it possible to apply the high-level\nreasoning of Large Language Models (LLMs) to low-level robotic control. A\nremaining challenge is to acquire a diverse set of fundamental skills. Existing\napproaches either manually decompose a complex task into atomic robotic actions\nin a top-down fashion, or bootstrap as many combinations as possible in a\nbottom-up fashion to cover a wider range of task possibilities. These\ndecompositions or combinations, however, require an initial skill library. For\nexample, a \"grasping\" capability can never emerge from a skill library\ncontaining only diverse \"pushing\" skills. Existing skill discovery techniques\nwith reinforcement learning acquire skills by an exhaustive exploration but\noften yield non-meaningful behaviors. In this study, we introduce a novel\nframework for skill discovery that is entirely driven by LLMs. The framework\nbegins with an LLM generating task proposals based on the provided scene\ndescription and the robot's configurations, aiming to incrementally acquire new\nskills upon task completion. For each proposed task, a series of reinforcement\nlearning processes are initiated, utilizing reward and success determination\nfunctions sampled by the LLM to develop the corresponding policy. The\nreliability and trustworthiness of learned behaviors are further ensured by an\nindependent vision-language model. We show that starting with zero skill, the\nASD skill library emerges and expands to more and more meaningful and reliable\nskills, enabling the robot to efficiently further propose and complete advanced\ntasks. The project page can be found at:\nhttps://agentic-skill-discovery.github.io.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Xufeng Zhao",
            "Cornelius Weber",
            "Stefan Wermter"
        ],
        "published": "2024-05-23T19:44:03Z"
    },
    {
        "title": "What Variables Affect Out-Of-Distribution Generalization in Pretrained\n  Models?",
        "link": "http://arxiv.org/abs/2405.15018v1",
        "abstract": "Embeddings produced by pre-trained deep neural networks (DNNs) are widely\nused; however, their efficacy for downstream tasks can vary widely. We study\nthe factors influencing out-of-distribution (OOD) generalization of pre-trained\nDNN embeddings through the lens of the tunnel effect hypothesis, which suggests\ndeeper DNN layers compress representations and hinder OOD performance. Contrary\nto earlier work, we find the tunnel effect is not universal. Based on 10,584\nlinear probes, we study the conditions that mitigate the tunnel effect by\nvarying DNN architecture, training dataset, image resolution, and\naugmentations. We quantify each variable's impact using a novel SHAP analysis.\nOur results emphasize the danger of generalizing findings from toy datasets to\nbroader contexts.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Md Yousuf Harun",
            "Kyungbok Lee",
            "Jhair Gallardo",
            "Giri Krishnan",
            "Christopher Kanan"
        ],
        "published": "2024-05-23T19:43:45Z"
    },
    {
        "title": "Fast Transaction Scheduling in Blockchain Sharding",
        "link": "http://arxiv.org/abs/2405.15015v1",
        "abstract": "Sharding is a promising technique for addressing the scalability issues of\nblockchain. It divides the $n$ participating nodes into $s$ disjoint groups\ncalled shards, where each shard processes transactions in parallel. We\ninvestigate scheduling algorithms for the blockchain sharding systems, where\neach transaction resides in a shard of the communication graph and attempts to\naccess accounts at possibly remote shards. We examine batch scheduling problems\non the shard graph $G_s$, where given a set of transactions, we aim to find\nefficient schedules to execute them as fast as possible. First, we present a\ncentralized scheduler where one of the shards has global knowledge of\ntransactions to be processed. For general graphs, where the transaction and its\naccessing objects are arbitrarily far from each other with a maximum distance\n$d$, the centralized scheduler provides $O(kd)$ approximation to the optimal\nschedule, where $k$ is the maximum number of shards each transaction accesses.\nConsequently, for a Clique graph where shards are at a unit distance from each\nother, we obtain $O(k)$ approximation to the optimal schedule. We also get $O(k\n\\log s)$ approximation for Hypercube, Butterfly, and $g$-dimensional Grid,\nwhere $g=O(\\log s)$. Next, we provide a centralized scheduler with a bucketing\napproach that offers improved bounds for special cases. Finally, we provide a\ndistributed scheduler where shards do not require global transaction\ninformation. We achieve this by using a hierarchical clustering of the shards\nand using the centralized scheduler in each cluster. We show that the\ndistributed scheduler has a competitive ratio of $O(\\mathcal{A_\\mathcal{CS}}\n\\log ^2 s)$, where $\\mathcal{A_\\mathcal{CS}}$ is the approximation ratio of the\ncentralized scheduler. To our knowledge, we are the first to give provably fast\ntransaction scheduling algorithms for blockchain sharding systems.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Ramesh Adhikari",
            "Costas Busch",
            "Miroslav Popovic"
        ],
        "published": "2024-05-23T19:40:25Z"
    },
    {
        "title": "Make Inference Faster: Efficient GPU Memory Management for Butterfly\n  Sparse Matrix Multiplication",
        "link": "http://arxiv.org/abs/2405.15013v1",
        "abstract": "This paper is the first to assess the state of existing sparse matrix\nmultiplication algorithms on GPU for the butterfly structure, a promising form\nof sparsity. This is achieved through a comprehensive benchmark that can be\neasily modified to add a new implementation. The goal is to provide a simple\ntool for users to select the optimal implementation based on their settings.\nUsing this benchmark, we find that existing implementations spend up to 50% of\ntheir total runtime on memory rewriting operations. We show that these memory\noperations can be optimized by introducing a new CUDA kernel that minimizes the\ntransfers between the different levels of GPU memory, achieving a median\nspeed-up factor of x1.4 while also reducing energy consumption (median of\nx0.85). We also demonstrate the broader significance of our results by showing\nhow the new kernel can speed up the inference of neural networks.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Antoine Gonon",
            "Léon Zheng",
            "Pascal Carrivain",
            "Quoc-Tung Le"
        ],
        "published": "2024-05-23T19:36:10Z"
    },
    {
        "title": "Extracting Prompts by Inverting LLM Outputs",
        "link": "http://arxiv.org/abs/2405.15012v1",
        "abstract": "We consider the problem of language model inversion: given outputs of a\nlanguage model, we seek to extract the prompt that generated these outputs. We\ndevelop a new black-box method, output2prompt, that learns to extract prompts\nwithout access to the model's logits and without adversarial or jailbreaking\nqueries. In contrast to previous work, output2prompt only needs outputs of\nnormal user queries. To improve memory efficiency, output2prompt employs a new\nsparse encoding techique. We measure the efficacy of output2prompt on a variety\nof user and system prompts and demonstrate zero-shot transferability across\ndifferent LLMs.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Collin Zhang",
            "John X. Morris",
            "Vitaly Shmatikov"
        ],
        "published": "2024-05-23T19:35:03Z"
    },
    {
        "title": "Polyak Meets Parameter-free Clipped Gradient Descent",
        "link": "http://arxiv.org/abs/2405.15010v1",
        "abstract": "Gradient descent and its variants are de facto standard algorithms for\ntraining machine learning models. As gradient descent is sensitive to its\nhyperparameters, we need to tune the hyperparameters carefully using a grid\nsearch, but it is time-consuming, especially when multiple hyperparameters\nexist. Recently, parameter-free methods that adjust the hyperparameters on the\nfly have been studied. However, the existing work only studied parameter-free\nmethods for the stepsize, and parameter-free methods for other hyperparameters\nhave not been explored. For instance, the gradient clipping threshold is also a\ncrucial hyperparameter in addition to the stepsize to prevent gradient\nexplosion issues, but none of the existing studies investigated the\nparameter-free methods for clipped gradient descent. In this work, we study the\nparameter-free methods for clipped gradient descent. Specifically, we propose\nInexact Polyak Stepsize, which converges to the optimal solution without any\nhyperparameters tuning, and its convergence rate is asymptotically independent\nof L under L-smooth and $(L_0, L_1)$-smooth assumptions of the loss function as\nthat of clipped gradient descent with well-tuned hyperparameters. We\nnumerically validated our convergence results using a synthetic function and\ndemonstrated the effectiveness of our proposed methods using LSTM, Nano-GPT,\nand T5.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Yuki Takezawa",
            "Han Bao",
            "Ryoma Sato",
            "Kenta Niwa",
            "Makoto Yamada"
        ],
        "published": "2024-05-23T19:29:38Z"
    },
    {
        "title": "An Empirical Study on the Characteristics of Database Access Bugs in\n  Java Applications",
        "link": "http://arxiv.org/abs/2405.15008v1",
        "abstract": "Database-backed applications rely on the database access code to interact\nwith the underlying database management systems (DBMSs). Although many prior\nstudies aim at database access issues like SQL anti-patterns or SQL code\nsmells, there is a lack of study of database access bugs during the maintenance\nof database-backed applications. In this paper, we empirically investigate 423\ndatabase access bugs collected from seven large-scale Java open source\napplications that use relational database management systems (e.g., MySQL or\nPostgreSQL). We study the characteristics (e.g., occurrence and root causes) of\nthe bugs by manually examining the bug reports and commit histories. We find\nthat the number of reported database and non-database access bugs share a\nsimilar trend but their modified files in bug fixing commits are different.\nAdditionally, we generalize categories of the root causes of database access\nbugs, containing five main categories (SQL queries, Schema, API, Configuration,\nSQL query result) and 25 unique root causes. We find that the bugs pertaining\nto SQL queries, Schema, and API cover 84.2% of database access bugs across all\nstudied applications. In particular, SQL queries bug (54%) and API bug (38.7%)\nare the most frequent issues when using JDBC and Hibernate, respectively.\nFinally, we provide a discussion on the implications of our findings for\ndevelopers and researchers.",
        "subjects": [
            "cs.SE",
            "cs.DB"
        ],
        "authors": [
            "Wei Liu",
            "Shouvick Mondal",
            "Tse-Hsun Chen"
        ],
        "published": "2024-05-23T19:26:29Z"
    },
    {
        "title": "RE-Adapt: Reverse Engineered Adaptation of Large Language Models",
        "link": "http://arxiv.org/abs/2405.15007v1",
        "abstract": "We introduce RE-Adapt, an approach to fine-tuning large language models on\nnew domains without degrading any pre-existing instruction-tuning. We reverse\nengineer an adapter which isolates what an instruction-tuned model has learned\nbeyond its corresponding pretrained base model. Importantly, this requires no\nadditional data or training. We can then fine-tune the base model on a new\ndomain and readapt it to instruction following with the reverse engineered\nadapter. RE-Adapt and our low-rank variant LoRE-Adapt both outperform other\nmethods of fine-tuning, across multiple popular LLMs and datasets, even when\nthe models are used in conjunction with retrieval-augmented generation.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "William Fleshman",
            "Benjamin Van Durme"
        ],
        "published": "2024-05-23T19:23:40Z"
    },
    {
        "title": "Path-metrics, pruning, and generalization",
        "link": "http://arxiv.org/abs/2405.15006v1",
        "abstract": "Analyzing the behavior of ReLU neural networks often hinges on understanding\nthe relationships between their parameters and the functions they implement.\nThis paper proves a new bound on function distances in terms of the so-called\npath-metrics of the parameters. Since this bound is intrinsically invariant\nwith respect to the rescaling symmetries of the networks, it sharpens\npreviously known bounds. It is also, to the best of our knowledge, the first\nbound of its kind that is broadly applicable to modern networks such as\nResNets, VGGs, U-nets, and many more. In contexts such as network pruning and\nquantization, the proposed path-metrics can be efficiently computed using only\ntwo forward passes. Besides its intrinsic theoretical interest, the bound\nyields not only novel theoretical generalization bounds, but also a promising\nproof of concept for rescaling-invariant pruning.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Antoine Gonon",
            "Nicolas Brisebarre",
            "Elisa Riccietti",
            "Rémi Gribonval"
        ],
        "published": "2024-05-23T19:23:09Z"
    },
    {
        "title": "ReachBot Field Tests in a Mojave Desert Lava Tube as a Martian Analog",
        "link": "http://arxiv.org/abs/2405.15005v1",
        "abstract": "ReachBot is a robot concept for the planetary exploration of caves and lava\ntubes, which are often inaccessible with traditional robot locomotion methods.\nIt uses extendable booms as appendages, with grippers mounted at the end, to\ngrasp irregular rock surfaces and traverse these difficult terrains. We have\nbuilt a partial ReachBot prototype consisting of a single boom and gripper,\nmounted on a tripod. We present the details on the design and field test of\nthis partial ReachBot prototype in a lava tube in the Mojave Desert. The\ntechnical requirements of the field testing, implementation details, and grasp\nperformance results are discussed. The planning and preparation of the field\ntest and lessons learned are also given.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Tony G. Chen",
            "Julia Di",
            "Stephanie Newdick",
            "Mathieu Lapotre",
            "Marco Pavone",
            "Mark R. Cutkosky"
        ],
        "published": "2024-05-23T19:22:59Z"
    },
    {
        "title": "Private Regression via Data-Dependent Sufficient Statistic Perturbation",
        "link": "http://arxiv.org/abs/2405.15002v1",
        "abstract": "Sufficient statistic perturbation (SSP) is a widely used method for\ndifferentially private linear regression. SSP adopts a data-independent\napproach where privacy noise from a simple distribution is added to sufficient\nstatistics. However, sufficient statistics can often be expressed as linear\nqueries and better approximated by data-dependent mechanisms. In this paper we\nintroduce data-dependent SSP for linear regression based on post-processing\nprivately released marginals, and find that it outperforms state-of-the-art\ndata-independent SSP. We extend this result to logistic regression by\ndeveloping an approximate objective that can be expressed in terms of\nsufficient statistics, resulting in a novel and highly competitive SSP approach\nfor logistic regression. We also make a connection to synthetic data for\nmachine learning: for models with sufficient statistics, training on synthetic\ndata corresponds to data-dependent SSP, with the overall utility determined by\nhow well the mechanism answers these linear queries.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Cecilia Ferrando",
            "Daniel Sheldon"
        ],
        "published": "2024-05-23T19:09:50Z"
    },
    {
        "title": "Lower Bound on the Greedy Approximation Ratio for Adaptive Submodular\n  Cover",
        "link": "http://arxiv.org/abs/2405.14995v1",
        "abstract": "We show that the greedy algorithm for adaptive-submodular cover has\napproximation ratio at least 1.3*(1+ln Q). Moreover, the instance demonstrating\nthis gap has Q=1. So, it invalidates a prior result in the paper ``Adaptive\nSubmodularity: A New Approach to Active Learning and Stochastic Optimization''\nby Golovin-Krause, that claimed a (1+ln Q)^2 approximation ratio for the same\nalgorithm.",
        "subjects": [
            "cs.DS",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Blake Harris",
            "Viswanath Nagarajan"
        ],
        "published": "2024-05-23T18:56:46Z"
    },
    {
        "title": "SoK: A Defense-Oriented Evaluation of Software Supply Chain Security",
        "link": "http://arxiv.org/abs/2405.14993v1",
        "abstract": "The software supply chain comprises a highly complex set of operations,\nprocesses, tools, institutions and human factors involved in creating a piece\nof software. A number of high-profile attacks that exploit a weakness in this\ncomplex ecosystem have spurred research in identifying classes of supply chain\nattacks. Yet, practitioners often lack the necessary information to understand\ntheir security posture and implement suitable defenses against these attacks.\nWe argue that the next stage of software supply chain security research and\ndevelopment will benefit greatly from a defense-oriented approach that focuses\non holistic bottom-up solutions. To this end, this paper introduces the AStRA\nmodel, a framework for representing fundamental software supply chain elements\nand their causal relationships. Using this model, we identify software supply\nchain security objectives that are needed to mitigate common attacks and\nsystematize knowledge on recent and well-established security techniques for\ntheir ability to meet these objectives. We validate our model against prior\nattacks and taxonomies. Finally, we identify emergent research gaps and propose\nopportunities to develop novel software development tools and systems that are\nsecure-by-design.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Eman Abu Ishgair",
            "Marcela S. Melara",
            "Santiago Torres-Arias"
        ],
        "published": "2024-05-23T18:53:48Z"
    },
    {
        "title": "Linking In-context Learning in Transformers to Human Episodic Memory",
        "link": "http://arxiv.org/abs/2405.14992v1",
        "abstract": "Understanding the connections between artificial and biological intelligent\nsystems can reveal fundamental principles underlying general intelligence.\nWhile many artificial intelligence (AI) models have a neuroscience counterpart,\nsuch connections are largely missing in Transformer models and the\nself-attention mechanism. Here, we examine the relationship between attention\nheads and human episodic memory. We focus on the induction heads, which\ncontribute to the in-context learning capabilities of Transformer-based large\nlanguage models (LLMs). We demonstrate that induction heads are behaviorally,\nfunctionally, and mechanistically similar to the contextual maintenance and\nretrieval (CMR) model of human episodic memory. Our analyses of LLMs\npre-trained on extensive text data show that CMR-like heads often emerge in the\nintermediate model layers and that their behavior qualitatively mirrors the\nmemory biases seen in humans. Our findings uncover a parallel between the\ncomputational mechanisms of LLMs and human memory, offering valuable insights\ninto both research fields.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Li Ji-An",
            "Corey Y. Zhou",
            "Marcus K. Benna",
            "Marcelo G. Mattar"
        ],
        "published": "2024-05-23T18:51:47Z"
    },
    {
        "title": "Dynamically Sharded Ledgers on a Distributed Hash Table",
        "link": "http://arxiv.org/abs/2405.14991v1",
        "abstract": "Distributed ledger technology such as blockchain is considered essential for\nsupporting large numbers of micro-transactions in the Machine Economy, which is\nenvisioned to involve billions of connected heterogeneous and decentralized\ncyber-physical systems. This stresses the need for performance and scalability\nof distributed ledger technologies. Sharding divides the blockchain network\ninto multiple committees and is a common approach to improve scalability.\nHowever, with current sharding approaches, costly cross-shard verification is\nneeded to prevent double-spending. This paper proposes a novel and more\nscalable distributed ledger method named ScaleGraph that implements dynamic\nsharding by using routing and logical proximity concepts from distributed hash\ntables. ScaleGraph addresses cyber security in terms of integrity,\navailability, and trust, to support frequent micro-transactions between\nautonomous devices. Benefits of ScaleGraph include a total storage space\ncomplexity of O(t), where t is the global number of transactions (assuming a\nconstant replication degree). This space is sharded over n nodes so that each\nnode needs O(t/n) storage, which provides a high level of concurrency and data\nlocalization as compared to other delegated consensus proposals. ScaleGraph\nallows for a dynamic grouping of validators which are selected based on a\ndistance metric. We analyze the consensus requirements in such a dynamic\nsetting and show that a synchronous consensus protocol allows shards to be\nsmaller than an asynchronous one, and likely yields better performance.\nMoreover, we provide an experimental analysis of security aspects regarding the\nrequired size of the consensus groups with ScaleGraph. Our analysis shows that\ndynamic sharding based on proximity concepts brings attractive scalability\nproperties in general, especially when the fraction of corrupt nodes is small.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Christoffer Fink",
            "Olov Schelén",
            "Ulf Bodin"
        ],
        "published": "2024-05-23T18:50:06Z"
    },
    {
        "title": "Simultaneous quantum identity authentication scheme utilizing\n  entanglement swapping with secret key preservation",
        "link": "http://arxiv.org/abs/2405.14987v1",
        "abstract": "Unconditional security in quantum key distribution (QKD) relies on\nauthenticating the identities of users involved in key distribution. While\nclassical identity authentication schemes were initially utilized in QKD\nimplementations, concerns regarding their vulnerability have prompted the\nexploration of quantum identity authentication (QIA) protocols. In this study,\nwe introduce a new protocol for QIA, derived from the concept of controlled\nsecure direct quantum communication. Our proposed scheme facilitates\nsimultaneous authentication between two users, Alice and Bob, leveraging Bell\nstates with the assistance of a third party, Charlie. Through rigorous security\nanalysis, we demonstrate that the proposed protocol withstands various known\nattacks, including impersonation, intercept and resend and impersonated\nfraudulent attacks. Additionally, we establish the relevance of the proposed\nprotocol by comparing it with the existing protocols of similar type.",
        "subjects": [
            "quant-ph",
            "cs.CR"
        ],
        "authors": [
            "Arindam Dutta",
            "Anirban Pathak"
        ],
        "published": "2024-05-23T18:40:15Z"
    },
    {
        "title": "Hand bone age estimation using divide and conquer strategy and\n  lightweight convolutional neural networks",
        "link": "http://dx.doi.org/10.1016/j.engappai.2023.105935",
        "abstract": "Estimating the Bone Age of children is very important for diagnosing growth\ndefects, and related diseases, and estimating the final height that children\nreach after maturity. For this reason, it is widely used in different\ncountries. Traditional methods for estimating bone age are performed by\ncomparing atlas images and radiographic images of the left hand, which is\ntime-consuming and error-prone. To estimate bone age using deep neural network\nmodels, a lot of research has been done, our effort has been to improve the\naccuracy and speed of this process by using the introduced approach. After\ncreating and analyzing our initial model, we focused on preprocessing and made\nthe inputs smaller, and increased their quality. we selected small regions of\nhand radiographs and estimated the age of the bone only according to these\nregions. by doing this we improved bone age estimation accuracy even further\nthan what was achieved in related works, without increasing the required\ncomputational resource. We reached a Mean Absolute Error (MAE) of 3.90 months\nin the range of 0-20 years and an MAE of 3.84 months in the range of 1-18 years\non the RSNA test set.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Amin Ahmadi Kasani",
            "Hedieh Sajedi"
        ],
        "published": "2024-05-23T18:39:33Z"
    },
    {
        "title": "Implicit degree bias in the link prediction task",
        "link": "http://arxiv.org/abs/2405.14985v1",
        "abstract": "Link prediction -- a task of distinguishing actual hidden edges from random\nunconnected node pairs -- is one of the quintessential tasks in graph machine\nlearning. Despite being widely accepted as a universal benchmark and a\ndownstream task for representation learning, the validity of the link\nprediction benchmark itself has been rarely questioned. Here, we show that the\ncommon edge sampling procedure in the link prediction task has an implicit bias\ntoward high-degree nodes and produces a highly skewed evaluation that favors\nmethods overly dependent on node degree, to the extent that a ``null'' link\nprediction method based solely on node degree can yield nearly optimal\nperformance. We propose a degree-corrected link prediction task that offers a\nmore reasonable assessment that aligns better with the performance in the\nrecommendation task. Finally, we demonstrate that the degree-corrected\nbenchmark can more effectively train graph machine-learning models by reducing\noverfitting to node degrees and facilitating the learning of relevant\nstructures in graphs.",
        "subjects": [
            "cs.SI",
            "physics.soc-ph"
        ],
        "authors": [
            "Rachith Aiyappa",
            "Xin Wang",
            "Munjung Kim",
            "Ozgur Can Seckin",
            "Jisung Yoon",
            "Yong-Yeol Ahn",
            "Sadamori Kojaku"
        ],
        "published": "2024-05-23T18:38:42Z"
    },
    {
        "title": "In-context Time Series Predictor",
        "link": "http://arxiv.org/abs/2405.14982v1",
        "abstract": "Recent Transformer-based large language models (LLMs) demonstrate in-context\nlearning ability to perform various functions based solely on the provided\ncontext, without updating model parameters. To fully utilize the in-context\ncapabilities in time series forecasting (TSF) problems, unlike previous\nTransformer-based or LLM-based time series forecasting methods, we reformulate\n\"time series forecasting tasks\" as input tokens by constructing a series of\n(lookback, future) pairs within the tokens. This method aligns more closely\nwith the inherent in-context mechanisms, and is more parameter-efficient\nwithout the need of using pre-trained LLM parameters. Furthermore, it addresses\nissues such as overfitting in existing Transformer-based TSF models,\nconsistently achieving better performance across full-data, few-shot, and\nzero-shot settings compared to previous architectures.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "stat.ML"
        ],
        "authors": [
            "Jiecheng Lu",
            "Yan Sun",
            "Shihao Yang"
        ],
        "published": "2024-05-23T18:37:00Z"
    },
    {
        "title": "MaSS: Multi-attribute Selective Suppression for Utility-preserving Data\n  Transformation from an Information-theoretic Perspective",
        "link": "http://arxiv.org/abs/2405.14981v1",
        "abstract": "The growing richness of large-scale datasets has been crucial in driving the\nrapid advancement and wide adoption of machine learning technologies. The\nmassive collection and usage of data, however, pose an increasing risk for\npeople's private and sensitive information due to either inadvertent\nmishandling or malicious exploitation. Besides legislative solutions, many\ntechnical approaches have been proposed towards data privacy protection.\nHowever, they bear various limitations such as leading to degraded data\navailability and utility, or relying on heuristics and lacking solid\ntheoretical bases. To overcome these limitations, we propose a formal\ninformation-theoretic definition for this utility-preserving privacy protection\nproblem, and design a data-driven learnable data transformation framework that\nis capable of selectively suppressing sensitive attributes from target datasets\nwhile preserving the other useful attributes, regardless of whether or not they\nare known in advance or explicitly annotated for preservation. We provide\nrigorous theoretical analyses on the operational bounds for our framework, and\ncarry out comprehensive experimental evaluations using datasets of a variety of\nmodalities, including facial images, voice audio clips, and human activity\nmotion sensor signals. Results demonstrate the effectiveness and\ngeneralizability of our method under various configurations on a multitude of\ntasks.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yizhuo Chen",
            "Chun-Fu Chen",
            "Hsiang Hsu",
            "Shaohan Hu",
            "Marco Pistoia",
            "Tarek Abdelzaher"
        ],
        "published": "2024-05-23T18:35:46Z"
    },
    {
        "title": "CraftsMan: High-fidelity Mesh Generation with 3D Native Generation and\n  Interactive Geometry Refiner",
        "link": "http://arxiv.org/abs/2405.14979v1",
        "abstract": "We present a novel generative 3D modeling system, coined CraftsMan, which can\ngenerate high-fidelity 3D geometries with highly varied shapes, regular mesh\ntopologies, and detailed surfaces, and, notably, allows for refining the\ngeometry in an interactive manner. Despite the significant advancements in 3D\ngeneration, existing methods still struggle with lengthy optimization\nprocesses, irregular mesh topologies, noisy surfaces, and difficulties in\naccommodating user edits, consequently impeding their widespread adoption and\nimplementation in 3D modeling software. Our work is inspired by the craftsman,\nwho usually roughs out the holistic figure of the work first and elaborates the\nsurface details subsequently. Specifically, we employ a 3D native diffusion\nmodel, which operates on latent space learned from latent set-based 3D\nrepresentations, to generate coarse geometries with regular mesh topology in\nseconds. In particular, this process takes as input a text prompt or a\nreference image and leverages a powerful multi-view (MV) diffusion model to\ngenerate multiple views of the coarse geometry, which are fed into our\nMV-conditioned 3D diffusion model for generating the 3D geometry, significantly\nimproving robustness and generalizability. Following that, a normal-based\ngeometry refiner is used to significantly enhance the surface details. This\nrefinement can be performed automatically, or interactively with user-supplied\nedits. Extensive experiments demonstrate that our method achieves high efficacy\nin producing superior-quality 3D assets compared to existing methods. HomePage:\nhttps://craftsman3d.github.io/, Code: https://github.com/wyysf-98/CraftsMan",
        "subjects": [
            "cs.GR",
            "cs.CV"
        ],
        "authors": [
            "Weiyu Li",
            "Jiarui Liu",
            "Rui Chen",
            "Yixun Liang",
            "Xuelin Chen",
            "Ping Tan",
            "Xiaoxiao Long"
        ],
        "published": "2024-05-23T18:30:12Z"
    },
    {
        "title": "Analog or Digital In-memory Computing? Benchmarking through Quantitative\n  Modeling",
        "link": "http://dx.doi.org/10.1109/ICCAD57390.2023.10323763",
        "abstract": "In-Memory Computing (IMC) has emerged as a promising paradigm for\nenergy-efficient, throughput-efficient and area-efficient machine learning at\nthe edge. However, the differences in hardware architectures, array dimensions,\nand fabrication technologies among published IMC realizations have made it\ndifficult to grasp their relative strengths. Moreover, previous studies have\nprimarily focused on exploring and benchmarking the peak performance of a\nsingle IMC macro rather than full system performance on real workloads. This\npaper aims to address the lack of a quantitative comparison of Analog In-Memory\nComputing (AIMC) and Digital In-Memory Computing (DIMC) processor\narchitectures. We propose an analytical IMC performance model that is validated\nagainst published implementations and integrated into a system-level\nexploration framework for comprehensive performance assessments on different\nworkloads with varying IMC configurations. Our experiments show that while DIMC\ngenerally has higher computational density than AIMC, AIMC with large macro\nsizes may have better energy efficiency than DIMC on convolutional-layers and\npointwise-layers, which can exploit high spatial unrolling. On the other hand,\nDIMC with small macro size outperforms AIMC on depthwise-layers, which feature\nlimited spatial unrolling opportunities inside a macro.",
        "subjects": [
            "eess.SP",
            "cs.AR",
            "eess.IV"
        ],
        "authors": [
            "Jiacong Sun",
            "Pouya Houshmand",
            "Marian Verhelst"
        ],
        "published": "2024-05-23T18:27:19Z"
    },
    {
        "title": "A Lost Opportunity for Vision-Language Models: A Comparative Study of\n  Online Test-time Adaptation for Vision-Language Models",
        "link": "http://arxiv.org/abs/2405.14977v1",
        "abstract": "In the realm of deep learning, maintaining model robustness against\ndistribution shifts is critical. This paper investigates test-time adaptation\nstrategies for vision-language models, with a specific focus on CLIP and its\nvariants. Through a systematic exploration of prompt-based techniques and\nexisting test-time adaptation methods, the study aims to enhance the\nadaptability and robustness of vision-language models in diverse real-world\nscenarios. The investigation includes an analysis of prompt engineering\nstrategies, such as hand-crafted prompts, prompt ensembles, and prompt learning\ntechniques. We introduce a vision-text-space ensemble that significantly boosts\nthe average performance compared to a text-space-only ensemble. Additionally,\nour comparative study delves into leveraging existing test-time adaptation\nmethods originally designed for image classification tasks. Experimental\nevaluations conducted across various datasets and model architectures\ndemonstrate the efficacy of different adaptation strategies. We further give\ninsights into the importance of updating the vision encoder and whether it is\nbeneficial to update the text encoder. Code is available at\nhttps://github.com/mariodoebler/test-time-adaptation",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Mario Döbler",
            "Robert A. Marsden",
            "Tobias Raichle",
            "Bin Yang"
        ],
        "published": "2024-05-23T18:27:07Z"
    },
    {
        "title": "Impact of Network Geometry on Large Networks with Intelligent Reflecting\n  Surfaces",
        "link": "http://arxiv.org/abs/2405.14976v1",
        "abstract": "In wireless networks assisted by intelligent reflecting surfaces (IRSs),\njointly modeling the signal received over the direct and indirect (reflected)\npaths is a difficult problem. In this work, we show that the network geometry\n(locations of serving base station, IRS, and user) can be captured using the\nso-called triangle parameter $\\Delta$. We introduce a decomposition of the\neffect of the combined link into a signal amplification factor and an effective\nchannel power coefficient $G$. The amplification factor is monotonically\nincreasing with both the number of IRS elements $N$ and $\\Delta$. For $G$,\nsince an exact characterization of the distribution seems unfeasible, we\npropose three approximations depending on the value of the product $N\\Delta$\nfor Nakagami fading and the special case of Rayleigh fading. For two relevant\nmodels of IRS placement, we prove that their performance is identical if\n$\\Delta$ is the same given an $N$. We also show that no gains are achieved from\nIRS deployment if $N$ and $\\Delta$ are both small. We further compute bounds on\nthe diversity gain to quantify the channel hardening effect of IRSs. Hence only\nwith a judicious selection of IRS placement and other network parameters,\nnon-trivial gains can be obtained.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Konpal Shaukat Ali",
            "Martin Haenggi",
            "Arafat Al-Dweik",
            "Marwa Chafii"
        ],
        "published": "2024-05-23T18:24:48Z"
    },
    {
        "title": "Surveilling the Masses with Wi-Fi-Based Positioning Systems",
        "link": "http://arxiv.org/abs/2405.14975v1",
        "abstract": "Wi-Fi-based Positioning Systems (WPSes) are used by modern mobile devices to\nlearn their position using nearby Wi-Fi access points as landmarks. In this\nwork, we show that Apple's WPS can be abused to create a privacy threat on a\nglobal scale. We present an attack that allows an unprivileged attacker to\namass a worldwide snapshot of Wi-Fi BSSID geolocations in only a matter of\ndays. Our attack makes few assumptions, merely exploiting the fact that there\nare relatively few dense regions of allocated MAC address space. Applying this\ntechnique over the course of a year, we learned the precise locations of over 2\nbillion BSSIDs around the world.\n  The privacy implications of such massive datasets become more stark when\ntaken longitudinally, allowing the attacker to track devices' movements. While\nmost Wi-Fi access points do not move for long periods of time, many devices --\nlike compact travel routers -- are specifically designed to be mobile. We\npresent several case studies that demonstrate the types of attacks on privacy\nthat Apple's WPS enables: We track devices moving in and out of war zones\n(specifically Ukraine and Gaza), the effects of natural disasters (specifically\nthe fires in Maui), and the possibility of targeted individual tracking by\nproxy -- all by remotely geolocating wireless access points. We provide\nrecommendations to WPS operators and Wi-Fi access point manufacturers to\nenhance the privacy of hundreds of millions of users worldwide. Finally, we\ndetail our efforts at responsibly disclosing this privacy vulnerability, and\noutline some mitigations that Apple and Wi-Fi access point manufacturers have\nimplemented both independently and as a result of our work.",
        "subjects": [
            "cs.CR",
            "cs.NI"
        ],
        "authors": [
            "Erik Rye",
            "Dave Levin"
        ],
        "published": "2024-05-23T18:22:12Z"
    },
    {
        "title": "LOVA3: Learning to Visual Question Answering, Asking and Assessment",
        "link": "http://arxiv.org/abs/2405.14974v1",
        "abstract": "Question answering, asking, and assessment are three innate human traits\ncrucial for understanding the world and acquiring knowledge. By enhancing these\ncapabilities, humans can more effectively utilize data, leading to better\ncomprehension and learning outcomes. However, current Multimodal Large Language\nModels (MLLMs) primarily focus on question answering, often neglecting the full\npotential of questioning and assessment skills. In this study, we introduce\nLOVA3, an innovative framework named ``Learning tO Visual Question Answering,\nAsking and Assessment,'' designed to equip MLLMs with these additional\ncapabilities. Our approach involves the creation of two supplementary training\ntasks GenQA and EvalQA, aiming at fostering the skills of asking and assessing\nquestions in the context of images. To develop the questioning ability, we\ncompile a comprehensive set of multimodal foundational tasks. For assessment,\nwe introduce a new benchmark called EvalQABench, comprising 64,000 training\nsamples (split evenly between positive and negative samples) and 5,000 testing\nsamples. We posit that enhancing MLLMs with the capabilities to answer, ask,\nand assess questions will improve their multimodal comprehension and lead to\nbetter performance. We validate our hypothesis by training an MLLM using the\nLOVA3 framework and testing it on 10 multimodal benchmarks. The results\ndemonstrate consistent performance improvements, thereby confirming the\nefficacy of our approach.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Henry Hengyuan Zhao",
            "Pan Zhou",
            "Difei Gao",
            "Mike Zheng Shou"
        ],
        "published": "2024-05-23T18:21:59Z"
    },
    {
        "title": "Two-Stage ML-Guided Decision Rules for Sequential Decision Making under\n  Uncertainty",
        "link": "http://arxiv.org/abs/2405.14973v1",
        "abstract": "Sequential Decision Making under Uncertainty (SDMU) is ubiquitous in many\ndomains such as energy, finance, and supply chains. Some SDMU applications are\nnaturally modeled as Multistage Stochastic Optimization Problems (MSPs), but\nthe resulting optimizations are notoriously challenging from a computational\nstandpoint. Under assumptions of convexity and stage-wise independence of the\nuncertainty, the resulting optimization can be solved efficiently using\nStochastic Dual Dynamic Programming (SDDP). Two-stage Linear Decision Rules\n(TS-LDRs) have been proposed to solve MSPs without the stage-wise independence\nassumption. TS-LDRs are computationally tractable, but using a policy that is a\nlinear function of past observations is typically not suitable for non-convex\nenvironments arising, for example, in energy systems. This paper introduces a\nnovel approach, Two-Stage General Decision Rules (TS-GDR), to generalize the\npolicy space beyond linear functions, making them suitable for non-convex\nenvironments. TS-GDR is a self-supervised learning algorithm that trains the\nnonlinear decision rules using stochastic gradient descent (SGD); its forward\npasses solve the policy implementation optimization problems, and the backward\npasses leverage duality theory to obtain closed-form gradients. The\neffectiveness of TS-GDR is demonstrated through an instantiation using Deep\nRecurrent Neural Networks named Two-Stage Deep Decision Rules (TS-DDR). The\nmethod inherits the flexibility and computational performance of Deep Learning\nmethodologies to solve SDMU problems generally tackled through large-scale\noptimization techniques. Applied to the Long-Term Hydrothermal Dispatch (LTHD)\nproblem using actual power system data from Bolivia, the TS-DDR not only\nenhances solution quality but also significantly reduces computation times by\nseveral orders of magnitude.",
        "subjects": [
            "cs.LG",
            "math.OC",
            "49M37"
        ],
        "authors": [
            "Andrew Rosemberg",
            "Alexandre Street",
            "Davi M. Valladão",
            "Pascal Van Hentenryck"
        ],
        "published": "2024-05-23T18:19:47Z"
    },
    {
        "title": "P4Control: Line-Rate Cross-Host Attack Prevention via In-Network\n  Information Flow Control Enabled by Programmable Switches and eBPF",
        "link": "http://dx.doi.org/10.1109/SP54263.2024.00147",
        "abstract": "Modern targeted attacks such as Advanced Persistent Threats use multiple\nhosts as stepping stones and move laterally across them to gain deeper access\nto the network. However, existing defenses lack end-to-end information flow\nvisibility across hosts and cannot block cross-host attack traffic in real\ntime. In this paper, we propose P4Control, a network defense system that\nprecisely confines end-to-end information flows in a network and prevents\ncross-host attacks at line rate. P4Control introduces a novel in-network\ndecentralized information flow control (DIFC) mechanism and is the first work\nthat enforces DIFC at the network level at network line rate. This is achieved\nthrough: (1) an in-network primitive based on programmable switches for\ntracking inter-host information flows and enforcing line-rate DIFC policies;\n(2) a lightweight eBPF-based primitive deployed on hosts for tracking\nintra-host information flows. P4Control also provides an expressive policy\nframework for specifying DIFC policies against different attack scenarios. We\nconduct extensive evaluations to show that P4Control can effectively prevent\ncross-host attacks in real time, while maintaining line-rate network\nperformance and imposing minimal overhead on the network and host machines. It\nis also noteworthy that P4Control can facilitate the realization of a zero\ntrust architecture through its fine-grained least-privilege network access\ncontrol.",
        "subjects": [
            "cs.CR",
            "cs.NI"
        ],
        "authors": [
            "Osama Bajaber",
            "Bo Ji",
            "Peng Gao"
        ],
        "published": "2024-05-23T18:19:10Z"
    },
    {
        "title": "Creativity and Markov Decision Processes",
        "link": "http://arxiv.org/abs/2405.14966v1",
        "abstract": "Creativity is already regularly attributed to AI systems outside specialised\ncomputational creativity (CC) communities. However, the evaluation of\ncreativity in AI at large typically lacks grounding in creativity theory, which\ncan promote inappropriate attributions and limit the analysis of creative\nbehaviour. While CC researchers have translated psychological theory into\nformal models, the value of these models is limited by a gap to common AI\nframeworks. To mitigate this limitation, we identify formal mappings between\nBoden's process theory of creativity and Markov Decision Processes (MDPs),\nusing the Creative Systems Framework as a stepping stone. We study three out of\neleven mappings in detail to understand which types of creative processes,\nopportunities for (aberrations), and threats to creativity (uninspiration)\ncould be observed in an MDP. We conclude by discussing quality criteria for the\nselection of such mappings for future work and applications.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Joonas Lahikainen",
            "Nadia M. Ady",
            "Christian Guckelsberger"
        ],
        "published": "2024-05-23T18:16:42Z"
    },
    {
        "title": "Black Start Operation of Grid-Forming Converters Based on Generalized\n  Three-phase Droop Control Under Unbalanced Conditions",
        "link": "http://arxiv.org/abs/2405.14964v1",
        "abstract": "This paper focuses on the challenging task of bottom-up restoration in a\ncomplete blackout system using Grid-forming (GFM) converters. Challenges arise\ndue to the limited current capability of power converters, resulting in\ndistinct dynamic responses and fault current characteristics compared to\nsynchronous generators. Additionally, GFM control needs to address the presence\nof unbalanced conditions commonly found in distribution systems. To address\nthese challenges, this paper explores the black start capability of GFM\nconverters with a generalized three-phase GFM droop control. This approach\nintegrates GFM controls individually for each phase, incorporating\nphase-balancing feedback and enabling current limiting for each phase during\nunbalanced faults or overloading. The introduction of a phase-balancing gain\nprovides flexibility to trade-off between voltage and power imbalances. The\nstudy further investigates bottom-up black start operations using GFM\nconverters, incorporating advanced load relays into breakers for gradual load\nenergization without central coordination. The effectiveness of bottom-up black\nstart operations with GFM converters, utilizing the generalized three-phase GFM\ndroop, is evaluated through electromagnetic transient (EMT) simulations in\nMATLAB/Simulink. The results confirm the performance and effectiveness of this\napproach in achieving successful black start operations under unbalanced\nconditions.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Zexian Zeng",
            "Prajwal Bhagwat",
            "Maryam Saeedifard",
            "Dominic Groß"
        ],
        "published": "2024-05-23T18:16:02Z"
    },
    {
        "title": "Data Augmentation Method Utilizing Template Sentences for Variable\n  Definition Extraction",
        "link": "http://arxiv.org/abs/2405.14962v1",
        "abstract": "The extraction of variable definitions from scientific and technical papers\nis essential for understanding these documents. However, the characteristics of\nvariable definitions, such as the length and the words that make up the\ndefinition, differ among fields, which leads to differences in the performance\nof existing extraction methods across fields. Although preparing training data\nspecific to each field can improve the performance of the methods, it is costly\nto create high-quality training data. To address this challenge, this study\nproposes a new method that generates new definition sentences from template\nsentences and variable-definition pairs in the training data. The proposed\nmethod has been tested on papers about chemical processes, and the results show\nthat the model trained with the definition sentences generated by the proposed\nmethod achieved a higher accuracy of 89.6%, surpassing existing models.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Kotaro Nagayama",
            "Shota Kato",
            "Manabu Kano"
        ],
        "published": "2024-05-23T18:14:05Z"
    },
    {
        "title": "SFDDM: Single-fold Distillation for Diffusion models",
        "link": "http://arxiv.org/abs/2405.14961v1",
        "abstract": "While diffusion models effectively generate remarkable synthetic images, a\nkey limitation is the inference inefficiency, requiring numerous sampling\nsteps. To accelerate inference and maintain high-quality synthesis,\nteacher-student distillation is applied to compress the diffusion models in a\nprogressive and binary manner by retraining, e.g., reducing the 1024-step model\nto a 128-step model in 3 folds. In this paper, we propose a single-fold\ndistillation algorithm, SFDDM, which can flexibly compress the teacher\ndiffusion model into a student model of any desired step, based on\nreparameterization of the intermediate inputs from the teacher model. To train\nthe student diffusion, we minimize not only the output distance but also the\ndistribution of the hidden variables between the teacher and student model.\nExtensive experiments on four datasets demonstrate that our student model\ntrained by the proposed SFDDM is able to sample high-quality data with steps\nreduced to as little as approximately 1%, thus, trading off inference time. Our\nremarkable performance highlights that SFDDM effectively transfers knowledge in\nsingle-fold distillation, achieving semantic consistency and meaningful image\ninterpolation.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Chi Hong",
            "Jiyue Huang",
            "Robert Birke",
            "Dick Epema",
            "Stefanie Roos",
            "Lydia Y. Chen"
        ],
        "published": "2024-05-23T18:11:14Z"
    },
    {
        "title": "EvGGS: A Collaborative Learning Framework for Event-based Generalizable\n  Gaussian Splatting",
        "link": "http://arxiv.org/abs/2405.14959v1",
        "abstract": "Event cameras offer promising advantages such as high dynamic range and low\nlatency, making them well-suited for challenging lighting conditions and\nfast-moving scenarios. However, reconstructing 3D scenes from raw event streams\nis difficult because event data is sparse and does not carry absolute color\ninformation. To release its potential in 3D reconstruction, we propose the\nfirst event-based generalizable 3D reconstruction framework, called EvGGS,\nwhich reconstructs scenes as 3D Gaussians from only event input in a\nfeedforward manner and can generalize to unseen cases without any retraining.\nThis framework includes a depth estimation module, an intensity reconstruction\nmodule, and a Gaussian regression module. These submodules connect in a\ncascading manner, and we collaboratively train them with a designed joint loss\nto make them mutually promote. To facilitate related studies, we build a novel\nevent-based 3D dataset with various material objects and calibrated labels of\ngrayscale images, depth maps, camera poses, and silhouettes. Experiments show\nmodels that have jointly trained significantly outperform those trained\nindividually. Our approach performs better than all baselines in reconstruction\nquality, and depth/intensity predictions with satisfactory rendering speed.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Jiaxu Wang",
            "Junhao He",
            "Ziyi Zhang",
            "Mingyuan Sun",
            "Jingkai Sun",
            "Renjing Xu"
        ],
        "published": "2024-05-23T18:10:26Z"
    },
    {
        "title": "Understanding the dynamics of the frequency bias in neural networks",
        "link": "http://arxiv.org/abs/2405.14957v1",
        "abstract": "Recent works have shown that traditional Neural Network (NN) architectures\ndisplay a marked frequency bias in the learning process. Namely, the NN first\nlearns the low-frequency features before learning the high-frequency ones. In\nthis study, we rigorously develop a partial differential equation (PDE) that\nunravels the frequency dynamics of the error for a 2-layer NN in the Neural\nTangent Kernel regime. Furthermore, using this insight, we explicitly\ndemonstrate how an appropriate choice of distributions for the initialization\nweights can eliminate or control the frequency bias. We focus our study on the\nFourier Features model, an NN where the first layer has sine and cosine\nactivation functions, with frequencies sampled from a prescribed distribution.\nIn this setup, we experimentally validate our theoretical results and compare\nthe NN dynamics to the solution of the PDE using the finite element method.\nFinally, we empirically show that the same principle extends to multi-layer\nNNs.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Juan Molina",
            "Mircea Petrache",
            "Francisco Sahli Costabal",
            "Matías Courdurier"
        ],
        "published": "2024-05-23T18:09:16Z"
    },
    {
        "title": "Interpretable and Editable Programmatic Tree Policies for Reinforcement\n  Learning",
        "link": "http://arxiv.org/abs/2405.14956v1",
        "abstract": "Deep reinforcement learning agents are prone to goal misalignments. The\nblack-box nature of their policies hinders the detection and correction of such\nmisalignments, and the trust necessary for real-world deployment. So far,\nsolutions learning interpretable policies are inefficient or require many human\npriors. We propose INTERPRETER, a fast distillation method producing\nINTerpretable Editable tRee Programs for ReinforcEmenT lEaRning. We empirically\ndemonstrate that INTERPRETER compact tree programs match oracles across a\ndiverse set of sequential decision tasks and evaluate the impact of our design\nchoices on interpretability and performances. We show that our policies can be\ninterpreted and edited to correct misalignments on Atari games and to explain\nreal farming strategies.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Hector Kohler",
            "Quentin Delfosse",
            "Riad Akrour",
            "Kristian Kersting",
            "Philippe Preux"
        ],
        "published": "2024-05-23T18:07:38Z"
    },
    {
        "title": "Mallows-DPO: Fine-Tune Your LLM with Preference Dispersions",
        "link": "http://arxiv.org/abs/2405.14953v1",
        "abstract": "Direct Preference Optimization (DPO) has recently emerged as a popular\napproach to improve reinforcement learning with human feedback (RLHF), leading\nto better techniques to fine-tune large language models (LLM). A weakness of\nDPO, however, lies in its lack of capability to characterize the diversity of\nhuman preferences. Inspired by Mallows' theory of preference ranking, we\ndevelop in this paper a new approach, the Mallows-DPO. A distinct feature of\nthis approach is a dispersion index, which reflects the dispersion of human\npreference to prompts. We show that existing DPO models can be reduced to\nspecial cases of this dispersion index, thus unified with Mallows-DPO. More\nimportantly, we demonstrate (empirically) how to use this dispersion index to\nenhance the performance of DPO in a broad array of benchmark tasks, from\nsynthetic bandit selection to controllable generations and dialogues, while\nmaintaining great generalization capabilities.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Haoxian Chen",
            "Hanyang Zhao",
            "Henry Lam",
            "David Yao",
            "Wenpin Tang"
        ],
        "published": "2024-05-23T18:01:11Z"
    },
    {
        "title": "Operational Framework for a Quantum Database",
        "link": "http://arxiv.org/abs/2405.14947v1",
        "abstract": "Databases are an essential component of modern computing infrastructures and\nallow efficient access to data stored persistently. Their structure depends on\nthe type and relationships of the stored data elements and on the access\npattern. Extending the concept of databases to the quantum domain is expected\nto increase both the storage efficiency and the access parallelism through\nquantum superposition. In addition, quantum databases may be seen as the result\nof a prior state preparation ready to be used by quantum algorithms when\nneeded. On the other hand, limiting factors exist and include entanglement\ncreation, the impossibility of perfect copying due to the no-cloning theorem,\nand the impossibility of coherently erasing a quantum state. In this work, we\nintroduce quantum databases within the broader context of data structures using\nclassical and quantum data and indexing. In particular, we are interested in\nquantum databases practical implementation and usability, focusing on the\ndefinition of the basic operations needed to create and manipulate data stored\nin a superposition state. Specifically, we address the case of quantum indexing\nin combination with classical data. For this scenario, we define the operations\nfor database preparation, extension, removal of indices, writing, and read-out\nof data, as well as index permutation. We present their algorithmic\nimplementation and highlight their advantages and limitations. Finally, we\nintroduce steps toward defining the same operations in the more general context\nof quantum indexing and quantum data.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "authors": [
            "Carla Rieger",
            "Michele Grossi",
            "Gian Giacomo Guerreschi",
            "Sofia Vallecorsa",
            "Martin Werner"
        ],
        "published": "2024-05-23T18:00:20Z"
    },
    {
        "title": "Universal Robustness via Median Randomized Smoothing for Real-World\n  Super-Resolution",
        "link": "http://arxiv.org/abs/2405.14934v1",
        "abstract": "Most of the recent literature on image Super-Resolution (SR) can be\nclassified into two main approaches. The first one involves learning a\ncorruption model tailored to a specific dataset, aiming to mimic the noise and\ncorruption in low-resolution images, such as sensor noise. However, this\napproach is data-specific, tends to lack adaptability, and its accuracy\ndiminishes when faced with unseen types of image corruptions. A second and more\nrecent approach, referred to as Robust Super-Resolution (RSR), proposes to\nimprove real-world SR by harnessing the generalization capabilities of a model\nby making it robust to adversarial attacks. To delve further into this second\napproach, our paper explores the universality of various methods for enhancing\nthe robustness of deep learning SR models. In other words, we inquire: \"Which\nrobustness method exhibits the highest degree of adaptability when dealing with\na wide range of adversarial attacks ?\". Our extensive experimentation on both\nsynthetic and real-world images empirically demonstrates that median randomized\nsmoothing (MRS) is more general in terms of robustness compared to adversarial\nlearning techniques, which tend to focus on specific types of attacks.\nFurthermore, as expected, we also illustrate that the proposed universal robust\nmethod enables the SR model to handle standard corruptions more effectively,\nsuch as blur and Gaussian noise, and notably, corruptions naturally present in\nreal-world images. These results support the significance of shifting the\nparadigm in the development of real-world SR methods towards RSR, especially\nvia MRS.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Zakariya Chaouai",
            "Mohamed Tamaazousti"
        ],
        "published": "2024-05-23T18:00:01Z"
    },
    {
        "title": "AstroPT: Scaling Large Observation Models for Astronomy",
        "link": "http://arxiv.org/abs/2405.14930v1",
        "abstract": "This work presents AstroPT, an autoregressive pretrained transformer\ndeveloped with astronomical use-cases in mind. The AstroPT models presented\nhere have been pretrained on 8.6 million $512 \\times 512$ pixel $grz$-band\ngalaxy postage stamp observations from the DESI Legacy Survey DR8. We train a\nselection of foundation models of increasing size from 1 million to 2.1 billion\nparameters, and find that AstroPT follows a similar saturating log-log scaling\nlaw to textual models. We also find that the models' performances on downstream\ntasks as measured by linear probing improves with model size up to the model\nparameter saturation point. We believe that collaborative community development\npaves the best route towards realising an open source `Large Observation Model'\n-- a model trained on data taken from the observational sciences at the scale\nseen in natural language processing. To this end, we release the source code,\nweights, and dataset for AstroPT under the MIT license, and invite potential\ncollaborators to join us in collectively building and researching these models.",
        "subjects": [
            "astro-ph.IM",
            "astro-ph.GA",
            "cs.LG"
        ],
        "authors": [
            "Michael J. Smith",
            "Ryan J. Roberts",
            "Eirini Angeloudi",
            "Marc Huertas-Company"
        ],
        "published": "2024-05-23T18:00:00Z"
    },
    {
        "title": "Fast Inference Using Automatic Differentiation and Neural Transport in\n  Astroparticle Physics",
        "link": "http://arxiv.org/abs/2405.14932v1",
        "abstract": "Multi-dimensional parameter spaces are commonly encountered in astroparticle\nphysics theories that attempt to capture novel phenomena. However, they often\npossess complicated posterior geometries that are expensive to traverse using\ntechniques traditional to this community. Effectively sampling these spaces is\ncrucial to bridge the gap between experiment and theory. Several recent\ninnovations, which are only beginning to make their way into this field, have\nmade navigating such complex posteriors possible. These include GPU\nacceleration, automatic differentiation, and neural-network-guided\nreparameterization. We apply these advancements to astroparticle physics\nexperimental results in the context of novel neutrino physics and benchmark\ntheir performances against traditional nested sampling techniques. Compared to\nnested sampling alone, we find that these techniques increase performance for\nboth nested sampling and Hamiltonian Monte Carlo, accelerating inference by\nfactors of $\\sim 100$ and $\\sim 60$, respectively. As nested sampling also\nevaluates the Bayesian evidence, these advancements can be exploited to improve\nmodel comparison performance while retaining compatibility with existing\nimplementations that are widely used in the natural sciences.",
        "subjects": [
            "cs.LG",
            "hep-ph",
            "stat.ML"
        ],
        "authors": [
            "Dorian W. P. Amaral",
            "Shixiao Liang",
            "Juehang Qin",
            "Christopher Tunnell"
        ],
        "published": "2024-05-23T18:00:00Z"
    },
    {
        "title": "Federated Online Adaptation for Deep Stereo",
        "link": "http://arxiv.org/abs/2405.14873v1",
        "abstract": "We introduce a novel approach for adapting deep stereo networks in a\ncollaborative manner. By building over principles of federated learning, we\ndevelop a distributed framework allowing for demanding the optimization process\nto a number of clients deployed in different environments. This makes it\npossible, for a deep stereo network running on resourced-constrained devices,\nto capitalize on the adaptation process carried out by other instances of the\nsame architecture, and thus improve its accuracy in challenging environments\neven when it cannot carry out adaptation on its own. Experimental results show\nhow federated adaptation performs equivalently to on-device adaptation, and\neven better when dealing with challenging environments.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Matteo Poggi",
            "Fabio Tosi"
        ],
        "published": "2024-05-23T17:59:58Z"
    },
    {
        "title": "An Empirical Study of Training State-of-the-Art LiDAR Segmentation\n  Models",
        "link": "http://arxiv.org/abs/2405.14870v1",
        "abstract": "In the rapidly evolving field of autonomous driving, precise segmentation of\nLiDAR data is crucial for understanding complex 3D environments. Traditional\napproaches often rely on disparate, standalone codebases, hindering unified\nadvancements and fair benchmarking across models. To address these challenges,\nwe introduce MMDetection3D-lidarseg, a comprehensive toolbox designed for the\nefficient training and evaluation of state-of-the-art LiDAR segmentation\nmodels. We support a wide range of segmentation models and integrate advanced\ndata augmentation techniques to enhance robustness and generalization.\nAdditionally, the toolbox provides support for multiple leading sparse\nconvolution backends, optimizing computational efficiency and performance. By\nfostering a unified framework, MMDetection3D-lidarseg streamlines development\nand benchmarking, setting new standards for research and application. Our\nextensive benchmark experiments on widely-used datasets demonstrate the\neffectiveness of the toolbox. The codebase and trained models have been\npublicly available, promoting further research and innovation in the field of\nLiDAR segmentation for autonomous driving.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Jiahao Sun",
            "Xiang Xu",
            "Lingdong Kong",
            "Youquan Liu",
            "Li Li",
            "Chenming Zhu",
            "Jingwei Zhang",
            "Zeqi Xiao",
            "Runnan Chen",
            "Tai Wang",
            "Wenwei Zhang",
            "Kai Chen",
            "Chunmei Qing"
        ],
        "published": "2024-05-23T17:59:57Z"
    },
    {
        "title": "NeRF-Casting: Improved View-Dependent Appearance with Consistent\n  Reflections",
        "link": "http://arxiv.org/abs/2405.14871v1",
        "abstract": "Neural Radiance Fields (NeRFs) typically struggle to reconstruct and render\nhighly specular objects, whose appearance varies quickly with changes in\nviewpoint. Recent works have improved NeRF's ability to render detailed\nspecular appearance of distant environment illumination, but are unable to\nsynthesize consistent reflections of closer content. Moreover, these techniques\nrely on large computationally-expensive neural networks to model outgoing\nradiance, which severely limits optimization and rendering speed. We address\nthese issues with an approach based on ray tracing: instead of querying an\nexpensive neural network for the outgoing view-dependent radiance at points\nalong each camera ray, our model casts reflection rays from these points and\ntraces them through the NeRF representation to render feature vectors which are\ndecoded into color using a small inexpensive network. We demonstrate that our\nmodel outperforms prior methods for view synthesis of scenes containing shiny\nobjects, and that it is the only existing NeRF method that can synthesize\nphotorealistic specular appearance and reflections in real-world scenes, while\nrequiring comparable optimization time to current state-of-the-art view\nsynthesis models.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "authors": [
            "Dor Verbin",
            "Pratul P. Srinivasan",
            "Peter Hedman",
            "Ben Mildenhall",
            "Benjamin Attal",
            "Richard Szeliski",
            "Jonathan T. Barron"
        ],
        "published": "2024-05-23T17:59:57Z"
    },
    {
        "title": "PuzzleAvatar: Assembling 3D Avatars from Personal Albums",
        "link": "http://arxiv.org/abs/2405.14869v1",
        "abstract": "Generating personalized 3D avatars is crucial for AR/VR. However, recent\ntext-to-3D methods that generate avatars for celebrities or fictional\ncharacters, struggle with everyday people. Methods for faithful reconstruction\ntypically require full-body images in controlled settings. What if a user could\njust upload their personal \"OOTD\" (Outfit Of The Day) photo collection and get\na faithful avatar in return? The challenge is that such casual photo\ncollections contain diverse poses, challenging viewpoints, cropped views, and\nocclusion (albeit with a consistent outfit, accessories and hairstyle). We\naddress this novel \"Album2Human\" task by developing PuzzleAvatar, a novel model\nthat generates a faithful 3D avatar (in a canonical pose) from a personal OOTD\nalbum, while bypassing the challenging estimation of body and camera pose. To\nthis end, we fine-tune a foundational vision-language model (VLM) on such\nphotos, encoding the appearance, identity, garments, hairstyles, and\naccessories of a person into (separate) learned tokens and instilling these\ncues into the VLM. In effect, we exploit the learned tokens as \"puzzle pieces\"\nfrom which we assemble a faithful, personalized 3D avatar. Importantly, we can\ncustomize avatars by simply inter-changing tokens. As a benchmark for this new\ntask, we collect a new dataset, called PuzzleIOI, with 41 subjects in a total\nof nearly 1K OOTD configurations, in challenging partial photos with paired\nground-truth 3D bodies. Evaluation shows that PuzzleAvatar not only has high\nreconstruction accuracy, outperforming TeCH and MVDreamBooth, but also a unique\nscalability to album photos, and strong robustness. Our model and data will be\npublic.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR"
        ],
        "authors": [
            "Yuliang Xiu",
            "Yufei Ye",
            "Zhen Liu",
            "Dimitrios Tzionas",
            "Michael J. Black"
        ],
        "published": "2024-05-23T17:59:56Z"
    },
    {
        "title": "Generative Camera Dolly: Extreme Monocular Dynamic Novel View Synthesis",
        "link": "http://arxiv.org/abs/2405.14868v1",
        "abstract": "Accurate reconstruction of complex dynamic scenes from just a single\nviewpoint continues to be a challenging task in computer vision. Current\ndynamic novel view synthesis methods typically require videos from many\ndifferent camera viewpoints, necessitating careful recording setups, and\nsignificantly restricting their utility in the wild as well as in terms of\nembodied AI applications. In this paper, we propose $\\textbf{GCD}$, a\ncontrollable monocular dynamic view synthesis pipeline that leverages\nlarge-scale diffusion priors to, given a video of any scene, generate a\nsynchronous video from any other chosen perspective, conditioned on a set of\nrelative camera pose parameters. Our model does not require depth as input, and\ndoes not explicitly model 3D scene geometry, instead performing end-to-end\nvideo-to-video translation in order to achieve its goal efficiently. Despite\nbeing trained on synthetic multi-view video data only, zero-shot real-world\ngeneralization experiments show promising results in multiple domains,\nincluding robotics, object permanence, and driving environments. We believe our\nframework can potentially unlock powerful applications in rich dynamic scene\nunderstanding, perception for robotics, and interactive 3D video viewing\nexperiences for virtual reality.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ],
        "authors": [
            "Basile Van Hoorick",
            "Rundi Wu",
            "Ege Ozguroglu",
            "Kyle Sargent",
            "Ruoshi Liu",
            "Pavel Tokmakov",
            "Achal Dave",
            "Changxi Zheng",
            "Carl Vondrick"
        ],
        "published": "2024-05-23T17:59:52Z"
    },
    {
        "title": "Improved Distribution Matching Distillation for Fast Image Synthesis",
        "link": "http://arxiv.org/abs/2405.14867v2",
        "abstract": "Recent approaches have shown promises distilling diffusion models into\nefficient one-step generators. Among them, Distribution Matching Distillation\n(DMD) produces one-step generators that match their teacher in distribution,\nwithout enforcing a one-to-one correspondence with the sampling trajectories of\ntheir teachers. However, to ensure stable training, DMD requires an additional\nregression loss computed using a large set of noise-image pairs generated by\nthe teacher with many steps of a deterministic sampler. This is costly for\nlarge-scale text-to-image synthesis and limits the student's quality, tying it\ntoo closely to the teacher's original sampling paths. We introduce DMD2, a set\nof techniques that lift this limitation and improve DMD training. First, we\neliminate the regression loss and the need for expensive dataset construction.\nWe show that the resulting instability is due to the fake critic not estimating\nthe distribution of generated samples accurately and propose a two time-scale\nupdate rule as a remedy. Second, we integrate a GAN loss into the distillation\nprocedure, discriminating between generated samples and real images. This lets\nus train the student model on real data, mitigating the imperfect real score\nestimation from the teacher model, and enhancing quality. Lastly, we modify the\ntraining procedure to enable multi-step sampling. We identify and address the\ntraining-inference input mismatch problem in this setting, by simulating\ninference-time generator samples during training time. Taken together, our\nimprovements set new benchmarks in one-step image generation, with FID scores\nof 1.28 on ImageNet-64x64 and 8.35 on zero-shot COCO 2014, surpassing the\noriginal teacher despite a 500X reduction in inference cost. Further, we show\nour approach can generate megapixel images by distilling SDXL, demonstrating\nexceptional visual quality among few-step methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Tianwei Yin",
            "Michaël Gharbi",
            "Taesung Park",
            "Richard Zhang",
            "Eli Shechtman",
            "Fredo Durand",
            "William T. Freeman"
        ],
        "published": "2024-05-23T17:59:49Z"
    },
    {
        "title": "Tele-Aloha: A Low-budget and High-authenticity Telepresence System Using\n  Sparse RGB Cameras",
        "link": "http://arxiv.org/abs/2405.14866v1",
        "abstract": "In this paper, we present a low-budget and high-authenticity bidirectional\ntelepresence system, Tele-Aloha, targeting peer-to-peer communication\nscenarios. Compared to previous systems, Tele-Aloha utilizes only four sparse\nRGB cameras, one consumer-grade GPU, and one autostereoscopic screen to achieve\nhigh-resolution (2048x2048), real-time (30 fps), low-latency (less than 150ms)\nand robust distant communication. As the core of Tele-Aloha, we propose an\nefficient novel view synthesis algorithm for upper-body. Firstly, we design a\ncascaded disparity estimator for obtaining a robust geometry cue. Additionally\na neural rasterizer via Gaussian Splatting is introduced to project latent\nfeatures onto target view and to decode them into a reduced resolution.\nFurther, given the high-quality captured data, we leverage weighted blending\nmechanism to refine the decoded image into the final resolution of 2K.\nExploiting world-leading autostereoscopic display and low-latency iris\ntracking, users are able to experience a strong three-dimensional sense even\nwithout any wearable head-mounted display device. Altogether, our telepresence\nsystem demonstrates the sense of co-presence in real-life experiments,\ninspiring the next generation of communication.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hanzhang Tu",
            "Ruizhi Shao",
            "Xue Dong",
            "Shunyuan Zheng",
            "Hao Zhang",
            "Lili Chen",
            "Meili Wang",
            "Wenyu Li",
            "Siyan Ma",
            "Shengping Zhang",
            "Boyao Zhou",
            "Yebin Liu"
        ],
        "published": "2024-05-23T17:59:45Z"
    },
    {
        "title": "Video Diffusion Models are Training-free Motion Interpreter and\n  Controller",
        "link": "http://arxiv.org/abs/2405.14864v1",
        "abstract": "Video generation primarily aims to model authentic and customized motion\nacross frames, making understanding and controlling the motion a crucial topic.\nMost diffusion-based studies on video motion focus on motion customization with\ntraining-based paradigms, which, however, demands substantial training\nresources and necessitates retraining for diverse models. Crucially, these\napproaches do not explore how video diffusion models encode cross-frame motion\ninformation in their features, lacking interpretability and transparency in\ntheir effectiveness. To answer this question, this paper introduces a novel\nperspective to understand, localize, and manipulate motion-aware features in\nvideo diffusion models. Through analysis using Principal Component Analysis\n(PCA), our work discloses that robust motion-aware feature already exists in\nvideo diffusion models. We present a new MOtion FeaTure (MOFT) by eliminating\ncontent correlation information and filtering motion channels. MOFT provides a\ndistinct set of benefits, including the ability to encode comprehensive motion\ninformation with clear interpretability, extraction without the need for\ntraining, and generalizability across diverse architectures. Leveraging MOFT,\nwe propose a novel training-free video motion control framework. Our method\ndemonstrates competitive performance in generating natural and faithful motion,\nproviding architecture-agnostic insights and applicability in a variety of\ndownstream tasks.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zeqi Xiao",
            "Yifan Zhou",
            "Shuai Yang",
            "Xingang Pan"
        ],
        "published": "2024-05-23T17:59:40Z"
    },
    {
        "title": "A Nurse is Blue and Elephant is Rugby: Cross Domain Alignment in Large\n  Language Models Reveal Human-like Patterns",
        "link": "http://arxiv.org/abs/2405.14863v1",
        "abstract": "Cross-domain alignment refers to the task of mapping a concept from one\ndomain to another. For example, ``If a \\textit{doctor} were a \\textit{color},\nwhat color would it be?''. This seemingly peculiar task is designed to\ninvestigate how people represent concrete and abstract concepts through their\nmappings between categories and their reasoning processes over those mappings.\nIn this paper, we adapt this task from cognitive science to evaluate the\nconceptualization and reasoning abilities of large language models (LLMs)\nthrough a behavioral study. We examine several LLMs by prompting them with a\ncross-domain mapping task and analyzing their responses at both the population\nand individual levels. Additionally, we assess the models' ability to reason\nabout their predictions by analyzing and categorizing their explanations for\nthese mappings. The results reveal several similarities between humans' and\nmodels' mappings and explanations, suggesting that models represent concepts\nsimilarly to humans. This similarity is evident not only in the model\nrepresentation but also in their behavior. Furthermore, the models mostly\nprovide valid explanations and deploy reasoning paths that are similar to those\nof humans.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Asaf Yehudai",
            "Taelin Karidi",
            "Gabriel Stanovsky",
            "Ariel Goldstein",
            "Omri Abend"
        ],
        "published": "2024-05-23T17:59:26Z"
    },
    {
        "title": "Bitune: Bidirectional Instruction-Tuning",
        "link": "http://arxiv.org/abs/2405.14862v1",
        "abstract": "We introduce Bitune, a method that improves instruction-tuning of pretrained\ndecoder-only large language models, leading to consistent gains on downstream\ntasks. Bitune applies both causal and bidirectional attention to the prompt, to\nobtain a better representation of the query or instruction. We realize this by\nintroducing two sets of parameters, for which we apply parameter-efficient\nfinetuning techniques. These causal and bidirectional features are then\ncombined into a weighted average with trainable coefficients, which is\nsubsequently used to generate new tokens. We demonstrate significant\nimprovements in zero-shot performance on commonsense reasoning, arithmetic, and\nlanguage understanding tasks, while extensive ablation studies validate the\nrole of each component and demonstrate the method's agnosticism to different\nPEFT techniques.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Dawid J. Kopiczko",
            "Tijmen Blankevoort",
            "Yuki M. Asano"
        ],
        "published": "2024-05-23T17:59:22Z"
    },
    {
        "title": "Adapting to Unknown Low-Dimensional Structures in Score-Based Diffusion\n  Models",
        "link": "http://arxiv.org/abs/2405.14861v1",
        "abstract": "This paper investigates score-based diffusion models when the underlying\ntarget distribution is concentrated on or near low-dimensional manifolds within\nthe higher-dimensional space in which they formally reside, a common\ncharacteristic of natural image distributions. Despite previous efforts to\nunderstand the data generation process of diffusion models, existing\ntheoretical support remains highly suboptimal in the presence of\nlow-dimensional structure, which we strengthen in this paper. For the popular\nDenoising Diffusion Probabilistic Model (DDPM), we find that the dependency of\nthe error incurred within each denoising step on the ambient dimension $d$ is\nin general unavoidable. We further identify a unique design of coefficients\nthat yields a converges rate at the order of $O(k^{2}/\\sqrt{T})$ (up to log\nfactors), where $k$ is the intrinsic dimension of the target distribution and\n$T$ is the number of steps. This represents the first theoretical demonstration\nthat the DDPM sampler can adapt to unknown low-dimensional structures in the\ntarget distribution, highlighting the critical importance of coefficient\ndesign. All of this is achieved by a novel set of analysis tools that\ncharacterize the algorithmic dynamics in a more deterministic manner.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.ST",
            "stat.ML",
            "stat.TH"
        ],
        "authors": [
            "Gen Li",
            "Yuling Yan"
        ],
        "published": "2024-05-23T17:59:10Z"
    },
    {
        "title": "Not All Language Model Features Are Linear",
        "link": "http://arxiv.org/abs/2405.14860v1",
        "abstract": "Recent work has proposed the linear representation hypothesis: that language\nmodels perform computation by manipulating one-dimensional representations of\nconcepts (\"features\") in activation space. In contrast, we explore whether some\nlanguage model representations may be inherently multi-dimensional. We begin by\ndeveloping a rigorous definition of irreducible multi-dimensional features\nbased on whether they can be decomposed into either independent or\nnon-co-occurring lower-dimensional features. Motivated by these definitions, we\ndesign a scalable method that uses sparse autoencoders to automatically find\nmulti-dimensional features in GPT-2 and Mistral 7B. These auto-discovered\nfeatures include strikingly interpretable examples, e.g. circular features\nrepresenting days of the week and months of the year. We identify tasks where\nthese exact circles are used to solve computational problems involving modular\narithmetic in days of the week and months of the year. Finally, we provide\nevidence that these circular features are indeed the fundamental unit of\ncomputation in these tasks with intervention experiments on Mistral 7B and\nLlama 3 8B, and we find further circular representations by breaking down the\nhidden states for these tasks into interpretable components.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Joshua Engels",
            "Isaac Liao",
            "Eric J. Michaud",
            "Wes Gurnee",
            "Max Tegmark"
        ],
        "published": "2024-05-23T17:59:04Z"
    },
    {
        "title": "Mamba-R: Vision Mamba ALSO Needs Registers",
        "link": "http://arxiv.org/abs/2405.14858v1",
        "abstract": "Similar to Vision Transformers, this paper identifies artifacts also present\nwithin the feature maps of Vision Mamba. These artifacts, corresponding to\nhigh-norm tokens emerging in low-information background areas of images, appear\nmuch more severe in Vision Mamba -- they exist prevalently even with the\ntiny-sized model and activate extensively across background regions. To\nmitigate this issue, we follow the prior solution of introducing register\ntokens into Vision Mamba. To better cope with Mamba blocks' uni-directional\ninference paradigm, two key modifications are introduced: 1) evenly inserting\nregisters throughout the input token sequence, and 2) recycling registers for\nfinal decision predictions. We term this new architecture Mamba-R. Qualitative\nobservations suggest, compared to vanilla Vision Mamba, Mamba-R's feature maps\nappear cleaner and more focused on semantically meaningful regions.\nQuantitatively, Mamba-R attains stronger performance and scales better. For\nexample, on the ImageNet benchmark, our base-size Mamba-R attains 82.9%\naccuracy, significantly outperforming Vim-B's 81.8%; furthermore, we provide\nthe first successful scaling to the large model size (i.e., with 341M\nparameters), attaining a competitive accuracy of 83.2% (84.5% if finetuned with\n384x384 inputs). Additional validation on the downstream semantic segmentation\ntask also supports Mamba-R's efficacy.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Feng Wang",
            "Jiahao Wang",
            "Sucheng Ren",
            "Guoyizhe Wei",
            "Jieru Mei",
            "Wei Shao",
            "Yuyin Zhou",
            "Alan Yuille",
            "Cihang Xie"
        ],
        "published": "2024-05-23T17:58:43Z"
    },
    {
        "title": "PILOT: Equivariant diffusion for pocket conditioned de novo ligand\n  generation with multi-objective guidance via importance sampling",
        "link": "http://arxiv.org/abs/2405.14925v1",
        "abstract": "The generation of ligands that both are tailored to a given protein pocket\nand exhibit a range of desired chemical properties is a major challenge in\nstructure-based drug design. Here, we propose an in-silico approach for the\n$\\textit{de novo}$ generation of 3D ligand structures using the equivariant\ndiffusion model PILOT, combining pocket conditioning with a large-scale\npre-training and property guidance. Its multi-objective trajectory-based\nimportance sampling strategy is designed to direct the model towards molecules\nthat not only exhibit desired characteristics such as increased binding\naffinity for a given protein pocket but also maintains high synthetic\naccessibility. This ensures the practicality of sampled molecules, thus\nmaximizing their potential for the drug discovery pipeline. PILOT significantly\noutperforms existing methods across various metrics on the common benchmark\ndataset CrossDocked2020. Moreover, we employ PILOT to generate novel ligands\nfor unseen protein pockets from the Kinodata-3D dataset, which encompasses a\nsubstantial portion of the human kinome. The generated structures exhibit\npredicted $IC_{50}$ values indicative of potent biological activity, which\nhighlights the potential of PILOT as a powerful tool for structure-based drug\ndesign.",
        "subjects": [
            "q-bio.BM",
            "cs.AI",
            "cs.CE",
            "cs.LG"
        ],
        "authors": [
            "Julian Cremer",
            "Tuan Le",
            "Frank Noé",
            "Djork-Arné Clevert",
            "Kristof T. Schütt"
        ],
        "published": "2024-05-23T17:58:28Z"
    },
    {
        "title": "Semantica: An Adaptable Image-Conditioned Diffusion Model",
        "link": "http://arxiv.org/abs/2405.14857v1",
        "abstract": "We investigate the task of adapting image generative models to different\ndatasets without finetuneing. To this end, we introduce Semantica, an\nimage-conditioned diffusion model capable of generating images based on the\nsemantics of a conditioning image. Semantica is trained exclusively on\nweb-scale image pairs, that is it receives a random image from a webpage as\nconditional input and models another random image from the same webpage. Our\nexperiments highlight the expressivity of pretrained image encoders and\nnecessity of semantic-based data filtering in achieving high-quality image\ngeneration. Once trained, it can adaptively generate new images from a dataset\nby simply using images from that dataset as input. We study the transfer\nproperties of Semantica on ImageNet, LSUN Churches, LSUN Bedroom and SUN397.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Manoj Kumar",
            "Neil Houlsby",
            "Emiel Hoogeboom"
        ],
        "published": "2024-05-23T17:58:03Z"
    },
    {
        "title": "Synergistic Global-space Camera and Human Reconstruction from Videos",
        "link": "http://arxiv.org/abs/2405.14855v1",
        "abstract": "Remarkable strides have been made in reconstructing static scenes or human\nbodies from monocular videos. Yet, the two problems have largely been\napproached independently, without much synergy. Most visual SLAM methods can\nonly reconstruct camera trajectories and scene structures up to scale, while\nmost HMR methods reconstruct human meshes in metric scale but fall short in\nreasoning with cameras and scenes. This work introduces Synergistic Camera and\nHuman Reconstruction (SynCHMR) to marry the best of both worlds. Specifically,\nwe design Human-aware Metric SLAM to reconstruct metric-scale camera poses and\nscene point clouds using camera-frame HMR as a strong prior, addressing depth,\nscale, and dynamic ambiguities. Conditioning on the dense scene recovered, we\nfurther learn a Scene-aware SMPL Denoiser to enhance world-frame HMR by\nincorporating spatio-temporal coherency and dynamic scene constraints.\nTogether, they lead to consistent reconstructions of camera trajectories, human\nmeshes, and dense scene point clouds in a common world frame. Project page:\nhttps://paulchhuang.github.io/synchmr",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Yizhou Zhao",
            "Tuanfeng Y. Wang",
            "Bhiksha Raj",
            "Min Xu",
            "Jimei Yang",
            "Chun-Hao Paul Huang"
        ],
        "published": "2024-05-23T17:57:50Z"
    },
    {
        "title": "TerDiT: Ternary Diffusion Models with Transformers",
        "link": "http://arxiv.org/abs/2405.14854v1",
        "abstract": "Recent developments in large-scale pre-trained text-to-image diffusion models\nhave significantly improved the generation of high-fidelity images,\nparticularly with the emergence of diffusion models based on transformer\narchitecture (DiTs). Among these diffusion models, diffusion transformers have\ndemonstrated superior image generation capabilities, boosting lower FID scores\nand higher scalability. However, deploying large-scale DiT models can be\nexpensive due to their extensive parameter numbers. Although existing research\nhas explored efficient deployment techniques for diffusion models such as model\nquantization, there is still little work concerning DiT-based models. To tackle\nthis research gap, in this paper, we propose TerDiT, a quantization-aware\ntraining (QAT) and efficient deployment scheme for ternary diffusion models\nwith transformers. We focus on the ternarization of DiT networks and scale\nmodel sizes from 600M to 4.2B. Our work contributes to the exploration of\nefficient deployment strategies for large-scale DiT models, demonstrating the\nfeasibility of training extremely low-bit diffusion transformer models from\nscratch while maintaining competitive image generation capacities compared to\nfull-precision models. Code will be available at\nhttps://github.com/Lucky-Lance/TerDiT.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Xudong Lu",
            "Aojun Zhou",
            "Ziyi Lin",
            "Qi Liu",
            "Yuhui Xu",
            "Renrui Zhang",
            "Yafei Wen",
            "Shuai Ren",
            "Peng Gao",
            "Junchi Yan",
            "Hongsheng Li"
        ],
        "published": "2024-05-23T17:57:24Z"
    },
    {
        "title": "Privileged Sensing Scaffolds Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.14853v1",
        "abstract": "We need to look at our shoelaces as we first learn to tie them but having\nmastered this skill, can do it from touch alone. We call this phenomenon\n\"sensory scaffolding\": observation streams that are not needed by a master\nmight yet aid a novice learner. We consider such sensory scaffolding setups for\ntraining artificial agents. For example, a robot arm may need to be deployed\nwith just a low-cost, robust, general-purpose camera; yet its performance may\nimprove by having privileged training-time-only access to informative albeit\nexpensive and unwieldy motion capture rigs or fragile tactile sensors. For\nthese settings, we propose \"Scaffolder\", a reinforcement learning approach\nwhich effectively exploits privileged sensing in critics, world models, reward\nestimators, and other such auxiliary components that are only used at training\ntime, to improve the target policy. For evaluating sensory scaffolding agents,\nwe design a new \"S3\" suite of ten diverse simulated robotic tasks that explore\na wide range of practical sensor setups. Agents must use privileged camera\nsensing to train blind hurdlers, privileged active visual perception to help\nrobot arms overcome visual occlusions, privileged touch sensors to train robot\nhands, and more. Scaffolder easily outperforms relevant prior baselines and\nfrequently performs comparably even to policies that have test-time access to\nthe privileged sensors. Website: https://penn-pal-lab.github.io/scaffolder/",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.RO"
        ],
        "authors": [
            "Edward S. Hu",
            "James Springer",
            "Oleh Rybkin",
            "Dinesh Jayaraman"
        ],
        "published": "2024-05-23T17:57:14Z"
    },
    {
        "title": "PV-Tuning: Beyond Straight-Through Estimation for Extreme LLM\n  Compression",
        "link": "http://arxiv.org/abs/2405.14852v1",
        "abstract": "There has been significant interest in \"extreme\" compression of large\nlanguage models (LLMs), i.e., to 1-2 bits per parameter, which allows such\nmodels to be executed efficiently on resource-constrained devices. Existing\nwork focused on improved one-shot quantization techniques and weight\nrepresentations; yet, purely post-training approaches are reaching diminishing\nreturns in terms of the accuracy-vs-bit-width trade-off. State-of-the-art\nquantization methods such as QuIP# and AQLM include fine-tuning (part of) the\ncompressed parameters over a limited amount of calibration data; however, such\nfine-tuning techniques over compressed weights often make exclusive use of\nstraight-through estimators (STE), whose performance is not well-understood in\nthis setting. In this work, we question the use of STE for extreme LLM\ncompression, showing that it can be sub-optimal, and perform a systematic study\nof quantization-aware fine-tuning strategies for LLMs. We propose PV-Tuning - a\nrepresentation-agnostic framework that generalizes and improves upon existing\nfine-tuning strategies, and provides convergence guarantees in restricted\ncases. On the practical side, when used for 1-2 bit vector quantization,\nPV-Tuning outperforms prior techniques for highly-performant models such as\nLlama and Mistral. Using PV-Tuning, we achieve the first Pareto-optimal\nquantization for Llama 2 family models at 2 bits per parameter.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Vladimir Malinovskii",
            "Denis Mazur",
            "Ivan Ilin",
            "Denis Kuznedelev",
            "Konstantin Burlachenko",
            "Kai Yi",
            "Dan Alistarh",
            "Peter Richtarik"
        ],
        "published": "2024-05-23T17:57:04Z"
    },
    {
        "title": "Domain Wall Magnetic Tunnel Junction Reliable Integrate and Fire Neuron",
        "link": "http://arxiv.org/abs/2405.14851v1",
        "abstract": "In spiking neural networks, neuron dynamics are described by the biologically\nrealistic integrate-and-fire model that captures membrane potential\naccumulation and above-threshold firing behaviors. Among the hardware\nimplementations of integrate-and-fire neuron devices, one important feature,\nreset, has been largely ignored. Here, we present the design and fabrication of\na magnetic domain wall and magnetic tunnel junction based artificial\nintegrate-and-fire neuron device that achieves reliable reset at the end of the\nintegrate-fire cycle. We demonstrate the domain propagation in the domain wall\nracetrack (integration), reading using a magnetic tunnel junction (fire), and\nreset as the domain is ejected from the racetrack, showing the artificial\nneuron can be operated continuously over 100 integrate-fire-reset cycles. Both\npulse amplitude and pulse number encoding is demonstrated. The device data is\napplied on an image classification task using a spiking neural network and\nshown to have comparable performance to an ideal leaky, integrate-and-fire\nneural network. These results achieve the first demonstration of reliable\nintegrate-fire-reset in domain wall-magnetic tunnel junction-based neuron\ndevices and shows the promise of spintronics for neuromorphic computing.",
        "subjects": [
            "cs.NE",
            "cond-mat.mes-hall"
        ],
        "authors": [
            "Can Cui1",
            "Sam Liu",
            "Jaesuk Kwon",
            "Jean Anne C. Incorvia"
        ],
        "published": "2024-05-23T17:56:52Z"
    },
    {
        "title": "Novel $H^\\mathrm{dev}(\\mathrm{Curl})$-conforming elements on regular\n  triangulations and Clough--Tocher splits for the planar relaxed micromorphic\n  model",
        "link": "http://arxiv.org/abs/2405.14849v1",
        "abstract": "In this work we present a consistent reduction of the relaxed micromorphic\nmodel to its corresponding two-dimensional planar model, such that its capacity\nto capture discontinuous dilatation fields is preserved. As a direct\nconsequence of our approach, new conforming finite elements for\n$H^\\mathrm{dev}(\\mathrm{Curl},A)$ become necessary. We present two novel\n$H^\\mathrm{dev}(\\mathrm{Curl},A)$-conforming finite element spaces, of which\none is a macro element based on Clough--Tocher splits, as well as primal and\nmixed variational formulations of the planar relaxed micromorphic model.\nFinally, we demonstrate the effectiveness of our approach with two numerical\nexamples.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Adam Sky",
            "Michael Neunteufel",
            "Peter Lewintan",
            "Panos Gourgiotis",
            "Andreas Zilian",
            "Patrizio Neff"
        ],
        "published": "2024-05-23T17:56:44Z"
    },
    {
        "title": "Local Causal Discovery for Structural Evidence of Direct Discrimination",
        "link": "http://arxiv.org/abs/2405.14848v1",
        "abstract": "Fairness is a critical objective in policy design and algorithmic\ndecision-making. Identifying the causal pathways of unfairness requires\nknowledge of the underlying structural causal model, which may be incomplete or\nunavailable. This limits the practicality of causal fairness analysis in\ncomplex or low-knowledge domains. To mitigate this practicality gap, we\nadvocate for developing efficient causal discovery methods for fairness\napplications. To this end, we introduce local discovery for direct\ndiscrimination (LD3): a polynomial-time algorithm that recovers structural\nevidence of direct discrimination. LD3 performs a linear number of conditional\nindependence tests with respect to variable set size. Moreover, we propose a\ngraphical criterion for identifying the weighted controlled direct effect\n(CDE), a qualitative measure of direct discrimination. We prove that this\ncriterion is satisfied by the knowledge returned by LD3, increasing the\naccessibility of the weighted CDE as a causal fairness measure. Taking liver\ntransplant allocation as a case study, we highlight the potential impact of LD3\nfor modeling fairness in complex decision systems. Results on real-world data\ndemonstrate more plausible causal relations than baselines, which took 197x to\n5870x longer to execute.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Jacqueline Maasch",
            "Kyra Gan",
            "Violet Chen",
            "Agni Orfanoudaki",
            "Nil-Jana Akpinar",
            "Fei Wang"
        ],
        "published": "2024-05-23T17:56:38Z"
    },
    {
        "title": "Neural Directional Encoding for Efficient and Accurate View-Dependent\n  Appearance Modeling",
        "link": "http://arxiv.org/abs/2405.14847v1",
        "abstract": "Novel-view synthesis of specular objects like shiny metals or glossy paints\nremains a significant challenge. Not only the glossy appearance but also global\nillumination effects, including reflections of other objects in the\nenvironment, are critical components to faithfully reproduce a scene. In this\npaper, we present Neural Directional Encoding (NDE), a view-dependent\nappearance encoding of neural radiance fields (NeRF) for rendering specular\nobjects. NDE transfers the concept of feature-grid-based spatial encoding to\nthe angular domain, significantly improving the ability to model high-frequency\nangular signals. In contrast to previous methods that use encoding functions\nwith only angular input, we additionally cone-trace spatial features to obtain\na spatially varying directional encoding, which addresses the challenging\ninterreflection effects. Extensive experiments on both synthetic and real\ndatasets show that a NeRF model with NDE (1) outperforms the state of the art\non view synthesis of specular objects, and (2) works with small networks to\nallow fast (real-time) inference. The project webpage and source code are\navailable at: \\url{https://lwwu2.github.io/nde/}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Liwen Wu",
            "Sai Bi",
            "Zexiang Xu",
            "Fujun Luan",
            "Kai Zhang",
            "Iliyan Georgiev",
            "Kalyan Sunkavalli",
            "Ravi Ramamoorthi"
        ],
        "published": "2024-05-23T17:56:34Z"
    },
    {
        "title": "Learning to Detect and Segment Mobile Objects from Unlabeled Videos",
        "link": "http://arxiv.org/abs/2405.14841v1",
        "abstract": "Embodied agents must detect and localize objects of interest, e.g. traffic\nparticipants for self-driving cars. Supervision in the form of bounding boxes\nfor this task is extremely expensive. As such, prior work has looked at\nunsupervised object segmentation, but in the absence of annotated boxes, it is\nunclear how pixels must be grouped into objects and which objects are of\ninterest. This results in over- / under-segmentation and irrelevant objects.\nInspired both by the human visual system and by practical applications, we\nposit that the key missing cue is motion: objects of interest are typically\nmobile objects. We propose MOD-UV, a Mobile Object Detector learned from\nUnlabeled Videos only. We begin with pseudo-labels derived from motion\nsegmentation, but introduce a novel training paradigm to progressively discover\nsmall objects and static-but-mobile objects that are missed by motion\nsegmentation. As a result, though only learned from unlabeled videos, MOD-UV\ncan detect and segment mobile objects from a single static image. Empirically,\nwe achieve state-of-the-art performance in unsupervised mobile object detection\non Waymo Open, nuScenes, and KITTI Dataset without using any external data or\nsupervised models. Code is publicly available at\nhttps://github.com/YihongSun/MOD-UV.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yihong Sun",
            "Bharath Hariharan"
        ],
        "published": "2024-05-23T17:55:11Z"
    },
    {
        "title": "Differentiable Annealed Importance Sampling Minimizes The Jensen-Shannon\n  Divergence Between Initial and Target Distribution",
        "link": "http://arxiv.org/abs/2405.14840v1",
        "abstract": "Differentiable annealed importance sampling (DAIS), proposed by Geffner &\nDomke (2021) and Zhang et al. (2021), allows optimizing, among others, over the\ninitial distribution of AIS. In this paper, we show that, in the limit of many\ntransitions, DAIS minimizes the symmetrized KL divergence (Jensen-Shannon\ndivergence) between the initial and target distribution. Thus, DAIS can be seen\nas a form of variational inference (VI) in that its initial distribution is a\nparametric fit to an intractable target distribution. We empirically evaluate\nthe usefulness of the initial distribution as a variational distribution on\nsynthetic and real-world data, observing that it often provides more accurate\nuncertainty estimates than standard VI (optimizing the reverse KL divergence),\nimportance weighted VI, and Markovian score climbing (optimizing the forward KL\ndivergence).",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Johannes Zenn",
            "Robert Bamler"
        ],
        "published": "2024-05-23T17:55:09Z"
    },
    {
        "title": "A Textbook Remedy for Domain Shifts: Knowledge Priors for Medical Image\n  Analysis",
        "link": "http://arxiv.org/abs/2405.14839v1",
        "abstract": "While deep networks have achieved broad success in analyzing natural images,\nwhen applied to medical scans, they often fail in unexcepted situations. We\ninvestigate this challenge and focus on model sensitivity to domain shifts,\nsuch as data sampled from different hospitals or data confounded by demographic\nvariables such as sex, race, etc, in the context of chest X-rays and skin\nlesion images. A key finding we show empirically is that existing visual\nbackbones lack an appropriate prior from the architecture for reliable\ngeneralization in these settings. Taking inspiration from medical training, we\npropose giving deep networks a prior grounded in explicit medical knowledge\ncommunicated in natural language. To this end, we introduce Knowledge-enhanced\nBottlenecks (KnoBo), a class of concept bottleneck models that incorporates\nknowledge priors that constrain it to reason with clinically relevant factors\nfound in medical textbooks or PubMed. KnoBo uses retrieval-augmented language\nmodels to design an appropriate concept space paired with an automatic training\nprocedure for recognizing the concept. We evaluate different resources of\nknowledge and recognition architectures on a broad range of domain shifts\nacross 20 datasets. In our comprehensive evaluation with two imaging\nmodalities, KnoBo outperforms fine-tuned models on confounded datasets by 32.4%\non average. Finally, evaluations reveal that PubMed is a promising resource for\nmaking medical models less sensitive to domain shift, outperforming other\nresources on both diversity of information and final prediction performance.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "authors": [
            "Yue Yang",
            "Mona Gandhi",
            "Yufei Wang",
            "Yifan Wu",
            "Michael S. Yao",
            "Chris Callison-Burch",
            "James C. Gee",
            "Mark Yatskar"
        ],
        "published": "2024-05-23T17:55:02Z"
    },
    {
        "title": "From Explicit CoT to Implicit CoT: Learning to Internalize CoT Step by\n  Step",
        "link": "http://arxiv.org/abs/2405.14838v1",
        "abstract": "When leveraging language models for reasoning tasks, generating explicit\nchain-of-thought (CoT) steps often proves essential for achieving high accuracy\nin final outputs. In this paper, we investigate if models can be taught to\ninternalize these CoT steps. To this end, we propose a simple yet effective\nmethod for internalizing CoT steps: starting with a model trained for explicit\nCoT reasoning, we gradually remove the intermediate steps and finetune the\nmodel. This process allows the model to internalize the intermediate reasoning\nsteps, thus simplifying the reasoning process while maintaining high\nperformance. Our approach enables a GPT-2 Small model to solve 9-by-9\nmultiplication with up to 99% accuracy, whereas standard training cannot solve\nbeyond 4-by-4 multiplication. Furthermore, our method proves effective on\nlarger language models, such as Mistral 7B, achieving over 50% accuracy on\nGSM8K without producing any intermediate steps.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Yuntian Deng",
            "Yejin Choi",
            "Stuart Shieber"
        ],
        "published": "2024-05-23T17:54:14Z"
    },
    {
        "title": "How Does Bayes Error Limit Probabilistic Robust Accuracy",
        "link": "http://arxiv.org/abs/2405.14923v1",
        "abstract": "Adversarial examples pose a security threat to many critical systems built on\nneural networks. Given that deterministic robustness often comes with\nsignificantly reduced accuracy, probabilistic robustness (i.e., the probability\nof having the same label with a vicinity is $\\ge 1-\\kappa$) has been proposed\nas a promising way of achieving robustness whilst maintaining accuracy.\nHowever, existing training methods for probabilistic robustness still\nexperience non-trivial accuracy loss. It is unclear whether there is an upper\nbound on the accuracy when optimising towards probabilistic robustness, and\nwhether there is a certain relationship between $\\kappa$ and this bound. This\nwork studies these problems from a Bayes error perspective. We find that while\nBayes uncertainty does affect probabilistic robustness, its impact is smaller\nthan that on deterministic robustness. This reduced Bayes uncertainty allows a\nhigher upper bound on probabilistic robust accuracy than that on deterministic\nrobust accuracy. Further, we prove that with optimal probabilistic robustness,\neach probabilistically robust input is also deterministically robust in a\nsmaller vicinity. We also show that voting within the vicinity always improves\nprobabilistic robust accuracy and the upper bound of probabilistic robust\naccuracy monotonically increases as $\\kappa$ grows. Our empirical findings also\nalign with our results.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ruihan Zhang",
            "Jun Sun"
        ],
        "published": "2024-05-23T17:51:36Z"
    },
    {
        "title": "Analysis of Atom-level pretraining with QM data for Graph Neural\n  Networks Molecular property models",
        "link": "http://arxiv.org/abs/2405.14837v1",
        "abstract": "Despite the rapid and significant advancements in deep learning for\nQuantitative Structure-Activity Relationship (QSAR) models, the challenge of\nlearning robust molecular representations that effectively generalize in\nreal-world scenarios to novel compounds remains an elusive and unresolved task.\nThis study examines how atom-level pretraining with quantum mechanics (QM) data\ncan mitigate violations of assumptions regarding the distributional similarity\nbetween training and test data and therefore improve performance and\ngeneralization in downstream tasks. In the public dataset Therapeutics Data\nCommons (TDC), we show how pretraining on atom-level QM improves performance\noverall and makes the activation of the features distributes more Gaussian-like\nwhich results in a representation that is more robust to distribution shifts.\nTo the best of our knowledge, this is the first time that hidden state\nmolecular representations are analyzed to compare the effects of molecule-level\nand atom-level pretraining on QM data.",
        "subjects": [
            "cs.LG",
            "physics.chem-ph",
            "quant-ph"
        ],
        "authors": [
            "Jose Arjona-Medina",
            "Ramil Nugmanov"
        ],
        "published": "2024-05-23T17:51:05Z"
    },
    {
        "title": "First Order Logic of Sparse Graphs with Given Degree Sequences",
        "link": "http://arxiv.org/abs/2405.14836v1",
        "abstract": "We consider limit probabilities of first order properties in random graphs\nwith a given degree sequence. Under mild conditions on the degree sequence, we\nshow that the closure set of limit probabilities is a finite union of closed\nintervals. Moreover, we characterize the degree sequences for which this\nclosure set is the interval $[0,1]$, a property that is intimately related with\nthe probability that the random graph is acyclic. As a side result, we compile\na full description of the cycle distribution of random graphs and study their\nfragment (disjoint union of unicyclic components) in the subcritical regime.\nFinally, we amend the proof of the existence of limit probabilities for first\norder properties in random graphs with a given degree sequence; this result was\nalready claimed by Lynch~[IEEE LICS 2003] but his proof contained some\ninaccuracies.",
        "subjects": [
            "math.CO",
            "cs.DM",
            "math.LO",
            "math.PR",
            "cc:05C80 (Primary), cc:03C13 (Secondary)"
        ],
        "authors": [
            "Alberto Larrauri",
            "Guillem Perarnau"
        ],
        "published": "2024-05-23T17:50:38Z"
    },
    {
        "title": "Polynomial Pass Semi-Streaming Lower Bounds for K-Cores and Degeneracy",
        "link": "http://arxiv.org/abs/2405.14835v1",
        "abstract": "The following question arises naturally in the study of graph streaming\nalgorithms:\n  \"Is there any graph problem which is \"not too hard\", in that it can be solved\nefficiently with total communication (nearly) linear in the number $n$ of\nvertices, and for which, nonetheless, any streaming algorithm with\n$\\tilde{O}(n)$ space (i.e., a semi-streaming algorithm) needs a polynomial\n$n^{\\Omega(1)}$ number of passes?\"\n  Assadi, Chen, and Khanna [STOC 2019] were the first to prove that this is\nindeed the case. However, the lower bounds that they obtained are for rather\nnon-standard graph problems.\n  Our first main contribution is to present the first polynomial-pass lower\nbounds for natural \"not too hard\" graph problems studied previously in the\nstreaming model: $k$-cores and degeneracy. We devise a novel communication\nprotocol for both problems with near-linear communication, thus showing that\n$k$-cores and degeneracy are natural examples of \"not too hard\" problems.\nIndeed, previous work have developed single-pass semi-streaming algorithms for\napproximating these problems. In contrast, we prove that any semi-streaming\nalgorithm for exactly solving these problems requires (almost)\n$\\Omega(n^{1/3})$ passes.\n  Our second main contribution is improved round-communication lower bounds for\nthe underlying communication problems at the basis of these reductions:\n  * We improve the previous lower bound of Assadi, Chen, and Khanna for hidden\npointer chasing (HPC) to achieve optimal bounds.\n  * We observe that all current reductions from HPC can also work with a\ngeneralized version of this problem that we call MultiHPC, and prove an even\nstronger and optimal lower bound for this generalization.\n  These two results collectively allow us to improve the resulting pass lower\nbounds for semi-streaming algorithms by a polynomial factor, namely, from\n$n^{1/5}$ to $n^{1/3}$ passes.",
        "subjects": [
            "cs.DS",
            "cs.CC"
        ],
        "authors": [
            "Sepehr Assadi",
            "Prantar Ghosh",
            "Bruno Loff",
            "Parth Mittal",
            "Sagnik Mukhopadhyay"
        ],
        "published": "2024-05-23T17:50:34Z"
    },
    {
        "title": "Direct3D: Scalable Image-to-3D Generation via 3D Latent Diffusion\n  Transformer",
        "link": "http://arxiv.org/abs/2405.14832v1",
        "abstract": "Generating high-quality 3D assets from text and images has long been\nchallenging, primarily due to the absence of scalable 3D representations\ncapable of capturing intricate geometry distributions. In this work, we\nintroduce Direct3D, a native 3D generative model scalable to in-the-wild input\nimages, without requiring a multiview diffusion model or SDS optimization. Our\napproach comprises two primary components: a Direct 3D Variational Auto-Encoder\n(D3D-VAE) and a Direct 3D Diffusion Transformer (D3D-DiT). D3D-VAE efficiently\nencodes high-resolution 3D shapes into a compact and continuous latent triplane\nspace. Notably, our method directly supervises the decoded geometry using a\nsemi-continuous surface sampling strategy, diverging from previous methods\nrelying on rendered images as supervision signals. D3D-DiT models the\ndistribution of encoded 3D latents and is specifically designed to fuse\npositional information from the three feature maps of the triplane latent,\nenabling a native 3D generative model scalable to large-scale 3D datasets.\nAdditionally, we introduce an innovative image-to-3D generation pipeline\nincorporating semantic and pixel-level image conditions, allowing the model to\nproduce 3D shapes consistent with the provided conditional image input.\nExtensive experiments demonstrate the superiority of our large-scale\npre-trained Direct3D over previous image-to-3D approaches, achieving\nsignificantly better generation quality and generalization ability, thus\nestablishing a new state-of-the-art for 3D content creation. Project page:\nhttps://nju-3dv.github.io/projects/Direct3D/.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Shuang Wu",
            "Youtian Lin",
            "Feihu Zhang",
            "Yifei Zeng",
            "Jingxi Xu",
            "Philip Torr",
            "Xun Cao",
            "Yao Yao"
        ],
        "published": "2024-05-23T17:49:37Z"
    },
    {
        "title": "HippoRAG: Neurobiologically Inspired Long-Term Memory for Large Language\n  Models",
        "link": "http://arxiv.org/abs/2405.14831v1",
        "abstract": "In order to thrive in hostile and ever-changing natural environments,\nmammalian brains evolved to store large amounts of knowledge about the world\nand continually integrate new information while avoiding catastrophic\nforgetting. Despite the impressive accomplishments, large language models\n(LLMs), even with retrieval-augmented generation (RAG), still struggle to\nefficiently and effectively integrate a large amount of new experiences after\npre-training. In this work, we introduce HippoRAG, a novel retrieval framework\ninspired by the hippocampal indexing theory of human long-term memory to enable\ndeeper and more efficient knowledge integration over new experiences. HippoRAG\nsynergistically orchestrates LLMs, knowledge graphs, and the Personalized\nPageRank algorithm to mimic the different roles of neocortex and hippocampus in\nhuman memory. We compare HippoRAG with existing RAG methods on multi-hop\nquestion answering and show that our method outperforms the state-of-the-art\nmethods remarkably, by up to 20%. Single-step retrieval with HippoRAG achieves\ncomparable or better performance than iterative retrieval like IRCoT while\nbeing 10-30 times cheaper and 6-13 times faster, and integrating HippoRAG into\nIRCoT brings further substantial gains. Finally, we show that our method can\ntackle new types of scenarios that are out of reach of existing methods. Code\nand data are available at https://github.com/OSU-NLP-Group/HippoRAG.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Bernal Jiménez Gutiérrez",
            "Yiheng Shu",
            "Yu Gu",
            "Michihiro Yasunaga",
            "Yu Su"
        ],
        "published": "2024-05-23T17:47:55Z"
    },
    {
        "title": "Deep learning lattice gauge theories",
        "link": "http://arxiv.org/abs/2405.14830v1",
        "abstract": "Monte Carlo methods have led to profound insights into the strong-coupling\nbehaviour of lattice gauge theories and produced remarkable results such as\nfirst-principles computations of hadron masses. Despite tremendous progress\nover the last four decades, fundamental challenges such as the sign problem and\nthe inability to simulate real-time dynamics remain. Neural network quantum\nstates have emerged as an alternative method that seeks to overcome these\nchallenges. In this work, we use gauge-invariant neural network quantum states\nto accurately compute the ground state of $\\mathbb{Z}_N$ lattice gauge theories\nin $2+1$ dimensions. Using transfer learning, we study the distinct topological\nphases and the confinement phase transition of these theories. For\n$\\mathbb{Z}_2$, we identify a continuous transition and compute critical\nexponents, finding excellent agreement with existing numerics for the expected\nIsing universality class. In the $\\mathbb{Z}_3$ case, we observe a weakly\nfirst-order transition and identify the critical coupling. Our findings suggest\nthat neural network quantum states are a promising method for precise studies\nof lattice gauge theory.",
        "subjects": [
            "hep-lat",
            "cond-mat.dis-nn",
            "cond-mat.str-el",
            "cs.LG",
            "hep-th"
        ],
        "authors": [
            "Anuj Apte",
            "Anthony Ashmore",
            "Clay Cordova",
            "Tzu-Chen Huang"
        ],
        "published": "2024-05-23T17:46:49Z"
    },
    {
        "title": "Good Seed Makes a Good Crop: Discovering Secret Seeds in Text-to-Image\n  Diffusion Models",
        "link": "http://arxiv.org/abs/2405.14828v1",
        "abstract": "Recent advances in text-to-image (T2I) diffusion models have facilitated\ncreative and photorealistic image synthesis. By varying the random seeds, we\ncan generate various images for a fixed text prompt. Technically, the seed\ncontrols the initial noise and, in multi-step diffusion inference, the noise\nused for reparameterization at intermediate timesteps in the reverse diffusion\nprocess. However, the specific impact of the random seed on the generated\nimages remains relatively unexplored. In this work, we conduct a large-scale\nscientific study into the impact of random seeds during diffusion inference.\nRemarkably, we reveal that the best 'golden' seed achieved an impressive FID of\n21.60, compared to the worst 'inferior' seed's FID of 31.97. Additionally, a\nclassifier can predict the seed number used to generate an image with over\n99.9% accuracy in just a few epochs, establishing that seeds are highly\ndistinguishable based on generated images. Encouraged by these findings, we\nexamined the influence of seeds on interpretable visual dimensions. We find\nthat certain seeds consistently produce grayscale images, prominent sky\nregions, or image borders. Seeds also affect image composition, including\nobject location, size, and depth. Moreover, by leveraging these 'golden' seeds,\nwe demonstrate improved image generation such as high-fidelity inference and\ndiversified sampling. Our investigation extends to inpainting tasks, where we\nuncover some seeds that tend to insert unwanted text artifacts. Overall, our\nextensive analyses highlight the importance of selecting good seeds and offer\npractical utility for image generation.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Katherine Xu",
            "Lingzhi Zhang",
            "Jianbo Shi"
        ],
        "published": "2024-05-23T17:46:23Z"
    },
    {
        "title": "An augmented Lagrangian trust-region method with inexact gradient\n  evaluations to accelerate constrained optimization problems using model\n  hyperreduction",
        "link": "http://arxiv.org/abs/2405.14827v1",
        "abstract": "We present an augmented Lagrangian trust-region method to efficiently solve\nconstrained optimization problems governed by large-scale nonlinear systems\nwith application to partial differential equation-constrained optimization. At\neach major augmented Lagrangian iteration, the expensive optimization\nsubproblem involving the full nonlinear system is replaced by an empirical\nquadrature-based hyperreduced model constructed on-the-fly. To ensure\nconvergence of these inexact augmented Lagrangian subproblems, we develop a\nbound-constrained trust-region method that allows for inexact gradient\nevaluations, and specialize it to our specific setting that leverages\nhyperreduced models. This approach circumvents a traditional training phase\nbecause the models are built on-the-fly in accordance with the requirements of\nthe trust-region convergence theory. Two numerical experiments (constrained\naerodynamic shape design) demonstrate the convergence and efficiency of the\nproposed work. A speedup of 12.7x (for all computational costs, even costs\ntraditionally considered \"offline\" such as snapshot collection and data\ncompression) relative to a standard optimization approach that does not\nleverage model reduction is shown.",
        "subjects": [
            "math.OC",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Tianshu Wen",
            "Matthew J. Zahr"
        ],
        "published": "2024-05-23T17:44:02Z"
    },
    {
        "title": "Camera Relocalization in Shadow-free Neural Radiance Fields",
        "link": "http://arxiv.org/abs/2405.14824v1",
        "abstract": "Camera relocalization is a crucial problem in computer vision and robotics.\nRecent advancements in neural radiance fields (NeRFs) have shown promise in\nsynthesizing photo-realistic images. Several works have utilized NeRFs for\nrefining camera poses, but they do not account for lighting changes that can\naffect scene appearance and shadow regions, causing a degraded pose\noptimization process. In this paper, we propose a two-staged pipeline that\nnormalizes images with varying lighting and shadow conditions to improve camera\nrelocalization. We implement our scene representation upon a hash-encoded NeRF\nwhich significantly boosts up the pose optimization process. To account for the\nnoisy image gradient computing problem in grid-based NeRFs, we further propose\na re-devised truncated dynamic low-pass filter (TDLF) and a numerical gradient\naveraging technique to smoothen the process. Experimental results on several\ndatasets with varying lighting conditions demonstrate that our method achieves\nstate-of-the-art results in camera relocalization under varying lighting\nconditions. Code and data will be made publicly available.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Shiyao Xu",
            "Caiyun Liu",
            "Yuantao Chen",
            "Zhenxin Zhu",
            "Zike Yan",
            "Yongliang Shi",
            "Hao Zhao",
            "Guyue Zhou"
        ],
        "published": "2024-05-23T17:41:15Z"
    },
    {
        "title": "On Robust Controlled Invariants for Continuous-time Monotone Systems",
        "link": "http://arxiv.org/abs/2405.14920v1",
        "abstract": "This paper delves into the problem of computing robust controlled invariants\nfor monotone continuous-time systems, with a specific focus on lower-closed\nspecifications. We consider the classes of state monotone (SM) and\ncontrol-state monotone (CSM) systems, we provide the structural properties of\nrobust controlled invariants for these classes of systems and show how these\nclasses significantly impact the computation of invariants. Additionally, we\nintroduce a notion of feasible points, demonstrating that their existence is\nsufficient to characterize robust controlled invariants for the considered\nclass of systems. The study further investigates the necessity of reducing the\nfeasibility condition for CSM and Lipschitz systems, unveiling conditions that\nguide this reduction. Leveraging these insights, we construct an algorithm for\nthe computation of robust controlled invariants. To demonstrate the\npracticality of our approach, we applied the developed algorithm to the coupled\ntank problem.",
        "subjects": [
            "eess.SY",
            "cs.SY",
            "math.OC"
        ],
        "authors": [
            "Emmanuel Junior Wafo Wembe",
            "Adnane Saoud"
        ],
        "published": "2024-05-23T17:40:22Z"
    },
    {
        "title": "PaGoDA: Progressive Growing of a One-Step Generator from a\n  Low-Resolution Diffusion Teacher",
        "link": "http://arxiv.org/abs/2405.14822v1",
        "abstract": "To accelerate sampling, diffusion models (DMs) are often distilled into\ngenerators that directly map noise to data in a single step. In this approach,\nthe resolution of the generator is fundamentally limited by that of the teacher\nDM. To overcome this limitation, we propose Progressive Growing of Diffusion\nAutoencoder (PaGoDA), a technique to progressively grow the resolution of the\ngenerator beyond that of the original teacher DM. Our key insight is that a\npre-trained, low-resolution DM can be used to deterministically encode\nhigh-resolution data to a structured latent space by solving the PF-ODE forward\nin time (data-to-noise), starting from an appropriately down-sampled image.\nUsing this frozen encoder in an auto-encoder framework, we train a decoder by\nprogressively growing its resolution. From the nature of progressively growing\ndecoder, PaGoDA avoids re-training teacher/student models when we upsample the\nstudent model, making the whole training pipeline much cheaper. In experiments,\nwe used our progressively growing decoder to upsample from the pre-trained\nmodel's 64x64 resolution to generate 512x512 samples, achieving 2x faster\ninference compared to single-step distilled Stable Diffusion like LCM. PaGoDA\nalso achieved state-of-the-art FIDs on ImageNet across all resolutions from\n64x64 to 512x512. Additionally, we demonstrated PaGoDA's effectiveness in\nsolving inverse problems and enabling controllable generation.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Dongjun Kim",
            "Chieh-Hsin Lai",
            "Wei-Hsiang Liao",
            "Yuhta Takida",
            "Naoki Murata",
            "Toshimitsu Uesaka",
            "Yuki Mitsufuji",
            "Stefano Ermon"
        ],
        "published": "2024-05-23T17:39:09Z"
    },
    {
        "title": "Evaluating Vulnerability of Chiplet-Based Systems to Contactless Probing\n  Techniques",
        "link": "http://arxiv.org/abs/2405.14821v1",
        "abstract": "Driven by a need for ever increasing chip performance and inclusion of\ninnovative features, a growing number of semiconductor companies are opting for\nall-inclusive System-on-Chip (SoC) architectures. Although Moore's Law has been\nable to keep up with the demand for more complex logic, manufacturing large\ndies still poses a challenge. Increasingly the solution adopted to minimize the\nimpact of silicon defects on manufacturing yield has been to split a design\ninto multiple smaller dies called chiplets which are then brought together on a\nsilicon interposer. Advanced 2.5D and 3D packaging techniques that enable this\nkind of integration also promise increased power efficiency and opportunities\nfor heterogeneous integration.\n  However, despite their advantages, chiplets are not without issues. Apart\nfrom manufacturing challenges that come with new packaging techniques,\ndisaggregating a design into multiple logically and physically separate dies\nintroduces new threats, including the possibility of tampering with and probing\nexposed data lines. In this paper we evaluate the exposure of chiplets to\nprobing by applying laser contactless probing techniques to a chiplet-based\nAMD/Xilinx VU9P FPGA. First, we identify and map interposer wire drivers and\nshow that probing them is easier compared to probing internal nodes. Lastly, we\ndemonstrate that delay-based sensors, which can be used to protect against\nphysical probes, are insufficient to protect against laser probing as the delay\nchange due to laser probing is only 0.792ps even at 100\\% laser power.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Aleksa Deric",
            "Kyle Mitard",
            "Shahin Tajik",
            "Daniel Holcomb"
        ],
        "published": "2024-05-23T17:38:13Z"
    },
    {
        "title": "Designing A Sustainable Marine Debris Clean-up Framework without Human\n  Labels",
        "link": "http://arxiv.org/abs/2405.14815v1",
        "abstract": "Marine debris poses a significant ecological threat to birds, fish, and other\nanimal life. Traditional methods for assessing debris accumulation involve\nlabor-intensive and costly manual surveys. This study introduces a framework\nthat utilizes aerial imagery captured by drones to conduct remote trash\nsurveys. Leveraging computer vision techniques, our approach detects,\nclassifies, and maps marine debris distributions. The framework uses Grounding\nDINO, a transformer-based zero-shot object detector, and CLIP, a\nvision-language model for zero-shot object classification, enabling the\ndetection and classification of debris objects based on material type without\nthe need for training labels. To mitigate over-counting due to different views\nof the same object, Scale-Invariant Feature Transform (SIFT) is employed for\nduplicate matching using local object features. Additionally, we have developed\na user-friendly web application that facilitates end-to-end analysis of drone\nimages, including object detection, classification, and visualization on a map\nto support cleanup efforts. Our method achieves competitive performance in\ndetection (0.69 mean IoU) and classification (0.74 F1 score) across seven\ndebris object classes without labeled data, comparable to state-of-the-art\nsupervised methods. This framework has the potential to streamline automated\ntrash sampling surveys, fostering efficient and sustainable community-led\ncleanup initiatives.",
        "subjects": [
            "cs.CV",
            "I.4; H.4; J.6"
        ],
        "authors": [
            "Raymond Wang",
            "Nicholas R. Record",
            "D. Whitney King",
            "Tahiya Chowdhury"
        ],
        "published": "2024-05-23T17:28:23Z"
    },
    {
        "title": "Scalable Optimization in the Modular Norm",
        "link": "http://arxiv.org/abs/2405.14813v1",
        "abstract": "To improve performance in contemporary deep learning, one is interested in\nscaling up the neural network in terms of both the number and the size of the\nlayers. When ramping up the width of a single layer, graceful scaling of\ntraining has been linked to the need to normalize the weights and their updates\nin the \"natural norm\" particular to that layer. In this paper, we significantly\ngeneralize this idea by defining the modular norm, which is the natural norm on\nthe full weight space of any neural network architecture. The modular norm is\ndefined recursively in tandem with the network architecture itself. We show\nthat the modular norm has several promising applications. On the practical\nside, the modular norm can be used to normalize the updates of any base\noptimizer so that the learning rate becomes transferable across width and\ndepth. This means that the user does not need to compute optimizer-specific\nscale factors in order to scale training. On the theoretical side, we show that\nfor any neural network built from \"well-behaved\" atomic modules, the gradient\nof the network is Lipschitz-continuous in the modular norm, with the Lipschitz\nconstant admitting a simple recursive formula. This characterization opens the\ndoor to porting standard ideas in optimization theory over to deep learning. We\nhave created a Python package called Modula that automatically normalizes\nweight updates in the modular norm of the architecture. The package is\navailable via \"pip install modula\" with source code at\nhttps://github.com/jxbz/modula.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Tim Large",
            "Yang Liu",
            "Minyoung Huh",
            "Hyojin Bahng",
            "Phillip Isola",
            "Jeremy Bernstein"
        ],
        "published": "2024-05-23T17:23:30Z"
    },
    {
        "title": "As an AI Language Model, \"Yes I Would Recommend Calling the Police'':\n  Norm Inconsistency in LLM Decision-Making",
        "link": "http://arxiv.org/abs/2405.14812v1",
        "abstract": "We investigate the phenomenon of norm inconsistency: where LLMs apply\ndifferent norms in similar situations. Specifically, we focus on the high-risk\napplication of deciding whether to call the police in Amazon Ring home\nsurveillance videos. We evaluate the decisions of three state-of-the-art LLMs\n-- GPT-4, Gemini 1.0, and Claude 3 Sonnet -- in relation to the activities\nportrayed in the videos, the subjects' skin-tone and gender, and the\ncharacteristics of the neighborhoods where the videos were recorded. Our\nanalysis reveals significant norm inconsistencies: (1) a discordance between\nthe recommendation to call the police and the actual presence of criminal\nactivity, and (2) biases influenced by the racial demographics of the\nneighborhoods. These results highlight the arbitrariness of model decisions in\nthe surveillance context and the limitations of current bias detection and\nmitigation strategies in normative decision-making.",
        "subjects": [
            "cs.CY"
        ],
        "authors": [
            "Shomik Jain",
            "D Calacci",
            "Ashia Wilson"
        ],
        "published": "2024-05-23T17:22:02Z"
    },
    {
        "title": "Implicit Personalization in Language Models: A Systematic Study",
        "link": "http://arxiv.org/abs/2405.14808v1",
        "abstract": "Implicit Personalization (IP) is a phenomenon of language models inferring a\nuser's background from the implicit cues in the input prompts and tailoring the\nresponse based on this inference. While previous work has touched upon various\ninstances of this problem, there lacks a unified framework to study this\nbehavior. This work systematically studies IP through a rigorous mathematical\nformulation, a multi-perspective moral reasoning framework, and a set of case\nstudies. Our theoretical foundation for IP relies on a structural causal model\nand introduces a novel method, indirect intervention, to estimate the causal\neffect of a mediator variable that cannot be directly intervened upon. Beyond\nthe technical approach, we also introduce a set of moral reasoning principles\nbased on three schools of moral philosophy to study when IP may or may not be\nethically appropriate. Equipped with both mathematical and ethical insights, we\npresent three diverse case studies illustrating the varied nature of the IP\nproblem and offer recommendations for future research. Our code and data are at\nhttps://github.com/jiarui-liu/IP.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CY",
            "cs.HC",
            "cs.LG"
        ],
        "authors": [
            "Zhijing Jin",
            "Nils Heil",
            "Jiarui Liu",
            "Shehzaad Dhuliawala",
            "Yahang Qi",
            "Bernhard Schölkopf",
            "Rada Mihalcea",
            "Mrinmaya Sachan"
        ],
        "published": "2024-05-23T17:18:46Z"
    },
    {
        "title": "Lorentz-Equivariant Geometric Algebra Transformers for High-Energy\n  Physics",
        "link": "http://arxiv.org/abs/2405.14806v1",
        "abstract": "Extracting scientific understanding from particle-physics experiments\nrequires solving diverse learning problems with high precision and good data\nefficiency. We propose the Lorentz Geometric Algebra Transformer (L-GATr), a\nnew multi-purpose architecture for high-energy physics. L-GATr represents\nhigh-energy data in a geometric algebra over four-dimensional space-time and is\nequivariant under Lorentz transformations, the symmetry group of relativistic\nkinematics. At the same time, the architecture is a Transformer, which makes it\nversatile and scalable to large systems. L-GATr is first demonstrated on\nregression and classification tasks from particle physics. We then construct\nthe first Lorentz-equivariant generative model: a continuous normalizing flow\nbased on an L-GATr network, trained with Riemannian flow matching. Across our\nexperiments, L-GATr is on par with or outperforms strong domain-specific\nbaselines.",
        "subjects": [
            "physics.data-an",
            "cs.LG",
            "hep-ph",
            "stat.ML"
        ],
        "authors": [
            "Jonas Spinner",
            "Victor Bresó",
            "Pim de Haan",
            "Tilman Plehn",
            "Jesse Thaler",
            "Johann Brehmer"
        ],
        "published": "2024-05-23T17:15:41Z"
    },
    {
        "title": "AnalogCoder: Analog Circuit Design via Training-Free Code Generation",
        "link": "http://arxiv.org/abs/2405.14918v1",
        "abstract": "Analog circuit design is a significant task in modern chip technology,\nfocusing on the selection of component types, connectivity, and parameters to\nensure proper circuit functionality. Despite advances made by Large Language\nModels (LLMs) in digital circuit design, the complexity and scarcity of data in\nanalog circuitry pose significant challenges. To mitigate these issues, we\nintroduce AnalogCoder, the first training-free LLM agent for designing analog\ncircuits through Python code generation. Firstly, AnalogCoder incorporates a\nfeedback-enhanced flow with tailored domain-specific prompts, enabling the\nautomated and self-correcting design of analog circuits with a high success\nrate. Secondly, it proposes a circuit tool library to archive successful\ndesigns as reusable modular sub-circuits, simplifying composite circuit\ncreation. Thirdly, extensive experiments on a benchmark designed to cover a\nwide range of analog circuit tasks show that AnalogCoder outperforms other\nLLM-based methods. It has successfully designed 20 circuits, 5 more than\nstandard GPT-4o. We believe AnalogCoder can significantly improve the\nlabor-intensive chip design process, enabling non-experts to design analog\ncircuits efficiently. Codes and the benchmark are provided at\nhttps://github.com/anonyanalog/AnalogCoder.",
        "subjects": [
            "cs.LG",
            "cs.ET"
        ],
        "authors": [
            "Yao Lai",
            "Sungyoung Lee",
            "Guojin Chen",
            "Souradip Poddar",
            "Mengkang Hu",
            "David Z. Pan",
            "Ping Luo"
        ],
        "published": "2024-05-23T17:13:52Z"
    },
    {
        "title": "Can LLMs Solve longer Math Word Problems Better?",
        "link": "http://arxiv.org/abs/2405.14804v1",
        "abstract": "Math Word Problems (MWPs) are crucial for evaluating the capability of Large\nLanguage Models (LLMs), with current research primarily focusing on questions\nwith concise contexts. However, as real-world math problems often involve\ncomplex circumstances, LLMs' ability to solve long MWPs is vital for their\napplications in these scenarios, yet remains under-explored. This study\npioneers the exploration of Context Length Generalizability (CoLeG), the\nability of LLMs to solve long MWPs. We introduce Extended Grade-School Math\n(E-GSM), a collection of MWPs with lengthy narratives. Two novel metrics are\nproposed to assess the efficacy and resilience of LLMs in solving these\nproblems. Our examination of existing zero-shot prompting techniques and both\nproprietary and open-source LLMs reveals a general deficiency in CoLeG. To\nalleviate these challenges, we propose distinct approaches for different\ncategories of LLMs. For proprietary LLMs, a new instructional prompt is\nproposed to mitigate the influence of long context. For open-source LLMs, a new\ndata augmentation task is developed to improve CoLeG. Our comprehensive results\ndemonstrate the effectiveness of our proposed methods, showing not only\nimproved performance on E-GSM but also generalizability across several other\nMWP benchmarks. Our findings pave the way for future research in employing LLMs\nfor complex, real-world applications, offering practical solutions to current\nlimitations and opening avenues for further exploration of model\ngeneralizability and training methodologies.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Xin Xu",
            "Tong Xiao",
            "Zitong Chao",
            "Zhenya Huang",
            "Can Yang",
            "Yang Wang"
        ],
        "published": "2024-05-23T17:13:50Z"
    },
    {
        "title": "Fast-DDPM: Fast Denoising Diffusion Probabilistic Models for Medical\n  Image-to-Image Generation",
        "link": "http://arxiv.org/abs/2405.14802v2",
        "abstract": "Denoising diffusion probabilistic models (DDPMs) have achieved unprecedented\nsuccess in computer vision. However, they remain underutilized in medical\nimaging, a field crucial for disease diagnosis and treatment planning. This is\nprimarily due to the high computational cost associated with (1) the use of\nlarge number of time steps (e.g., 1,000) in diffusion processes and (2) the\nincreased dimensionality of medical images, which are often 3D or 4D. Training\na diffusion model on medical images typically takes days to weeks, while\nsampling each image volume takes minutes to hours. To address this challenge,\nwe introduce Fast-DDPM, a simple yet effective approach capable of improving\ntraining speed, sampling speed, and generation quality simultaneously. Unlike\nDDPM, which trains the image denoiser across 1,000 time steps, Fast-DDPM trains\nand samples using only 10 time steps. The key to our method lies in aligning\nthe training and sampling procedures to optimize time-step utilization.\nSpecifically, we introduced two efficient noise schedulers with 10 time steps:\none with uniform time step sampling and another with non-uniform sampling. We\nevaluated Fast-DDPM across three medical image-to-image generation tasks:\nmulti-image super-resolution, image denoising, and image-to-image translation.\nFast-DDPM outperformed DDPM and current state-of-the-art methods based on\nconvolutional networks and generative adversarial networks in all tasks.\nAdditionally, Fast-DDPM reduced the training time to 0.2x and the sampling time\nto 0.01x compared to DDPM. Our code is publicly available at:\nhttps://github.com/mirthAI/Fast-DDPM.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Hongxu Jiang",
            "Muhammad Imran",
            "Linhai Ma",
            "Teng Zhang",
            "Yuyin Zhou",
            "Muxuan Liang",
            "Kuang Gong",
            "Wei Shao"
        ],
        "published": "2024-05-23T17:12:22Z"
    },
    {
        "title": "Membership Inference on Text-to-Image Diffusion Models via Conditional\n  Likelihood Discrepancy",
        "link": "http://arxiv.org/abs/2405.14800v1",
        "abstract": "Text-to-image diffusion models have achieved tremendous success in the field\nof controllable image generation, while also coming along with issues of\nprivacy leakage and data copyrights. Membership inference arises in these\ncontexts as a potential auditing method for detecting unauthorized data usage.\nWhile some efforts have been made on diffusion models, they are not applicable\nto text-to-image diffusion models due to the high computation overhead and\nenhanced generalization capabilities. In this paper, we first identify a\nconditional overfitting phenomenon in text-to-image diffusion models,\nindicating that these models tend to overfit the conditional distribution of\nimages given the text rather than the marginal distribution of images. Based on\nthis observation, we derive an analytical indicator, namely Conditional\nLikelihood Discrepancy (CLiD), to perform membership inference. This indicator\nreduces the stochasticity in estimating the memorization of individual samples.\nExperimental results demonstrate that our method significantly outperforms\nprevious methods across various data distributions and scales. Additionally,\nour method shows superior resistance to overfitting mitigation strategies such\nas early stopping and data augmentation.",
        "subjects": [
            "cs.CR",
            "cs.CV"
        ],
        "authors": [
            "Shengfang Zhai",
            "Huanran Chen",
            "Yinpeng Dong",
            "Jiajun Li",
            "Qingni Shen",
            "Yansong Gao",
            "Hang Su",
            "Yang Liu"
        ],
        "published": "2024-05-23T17:09:51Z"
    },
    {
        "title": "Generative Plant Growth Simulation from Sequence-Informed Environmental\n  Conditions",
        "link": "http://arxiv.org/abs/2405.14796v1",
        "abstract": "A plant growth simulation can be characterized as a reconstructed visual\nrepresentation of a plant or plant system. The phenotypic characteristics and\nplant structures are controlled by the scene environment and other contextual\nattributes. Considering the temporal dependencies and compounding effects of\nvarious factors on growth trajectories, we formulate a probabilistic approach\nto the simulation task by solving a frame synthesis and pattern recognition\nproblem. We introduce a Sequence-Informed Plant Growth Simulation framework\n(SI-PGS) that employs a conditional generative model to implicitly learn a\ndistribution of possible plant representations within a dynamic scene from a\nfusion of low dimensional temporal sensor and context data. Methods such as\ncontrolled latent sampling and recurrent output connections are used to improve\ncoherence in plant structures between frames of predictions. In this work, we\ndemonstrate that SI-PGS is able to capture temporal dependencies and\ncontinuously generate realistic frames of a plant scene.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "q-bio.QM"
        ],
        "authors": [
            "Mohamed Debbagh",
            "Yixue Liu",
            "Zhouzhou Zheng",
            "Xintong Jiang",
            "Shangpeng Sun",
            "Mark Lefsrud"
        ],
        "published": "2024-05-23T17:06:46Z"
    },
    {
        "title": "RetAssist: Facilitating Vocabulary Learners with Generative Images in\n  Story Retelling Practices",
        "link": "http://dx.doi.org/10.1145/3643834.3661581",
        "abstract": "Reading and repeatedly retelling a short story is a common and effective\napproach to learning the meanings and usages of target words. However, learners\noften struggle with comprehending, recalling, and retelling the story contexts\nof these target words. Inspired by the Cognitive Theory of Multimedia Learning,\nwe propose a computational workflow to generate relevant images paired with\nstories. Based on the workflow, we work with learners and teachers to\niteratively design an interactive vocabulary learning system named RetAssist.\nIt can generate sentence-level images of a story to facilitate the\nunderstanding and recall of the target words in the story retelling practices.\nOur within-subjects study (N=24) shows that compared to a baseline system\nwithout generative images, RetAssist significantly improves learners' fluency\nin expressing with target words. Participants also feel that RetAssist eases\ntheir learning workload and is more useful. We discuss insights into leveraging\ntext-to-image generative models to support learning tasks.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Qiaoyi Chen",
            "Siyu Liu",
            "Kaihui Huang",
            "Xingbo Wang",
            "Xiaojuan Ma",
            "Junkai Zhu",
            "Zhenhui Peng"
        ],
        "published": "2024-05-23T17:05:13Z"
    },
    {
        "title": "SEA-RAFT: Simple, Efficient, Accurate RAFT for Optical Flow",
        "link": "http://arxiv.org/abs/2405.14793v1",
        "abstract": "We introduce SEA-RAFT, a more simple, efficient, and accurate RAFT for\noptical flow. Compared with RAFT, SEA-RAFT is trained with a new loss (mixture\nof Laplace). It directly regresses an initial flow for faster convergence in\niterative refinements and introduces rigid-motion pre-training to improve\ngeneralization. SEA-RAFT achieves state-of-the-art accuracy on the Spring\nbenchmark with a 3.69 endpoint-error (EPE) and a 0.36 1-pixel outlier rate\n(1px), representing 22.9% and 17.8% error reduction from best published\nresults. In addition, SEA-RAFT obtains the best cross-dataset generalization on\nKITTI and Spring. With its high efficiency, SEA-RAFT operates at least 2.3x\nfaster than existing methods while maintaining competitive performance. The\ncode is publicly available at https://github.com/princeton-vl/SEA-RAFT.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yihan Wang",
            "Lahav Lipson",
            "Jia Deng"
        ],
        "published": "2024-05-23T17:04:04Z"
    },
    {
        "title": "Recurrent Early Exits for Federated Learning with Heterogeneous Clients",
        "link": "http://arxiv.org/abs/2405.14791v1",
        "abstract": "Federated learning (FL) has enabled distributed learning of a model across\nmultiple clients in a privacy-preserving manner. One of the main challenges of\nFL is to accommodate clients with varying hardware capacities; clients have\ndiffering compute and memory requirements. To tackle this challenge, recent\nstate-of-the-art approaches leverage the use of early exits. Nonetheless, these\napproaches fall short of mitigating the challenges of joint learning multiple\nexit classifiers, often relying on hand-picked heuristic solutions for\nknowledge distillation among classifiers and/or utilizing additional layers for\nweaker classifiers. In this work, instead of utilizing multiple classifiers, we\npropose a recurrent early exit approach named ReeFL that fuses features from\ndifferent sub-models into a single shared classifier. Specifically, we use a\ntransformer-based early-exit module shared among sub-models to i) better\nexploit multi-layer feature representations for task-specific prediction and\nii) modulate the feature representation of the backbone model for subsequent\npredictions. We additionally present a per-client self-distillation approach\nwhere the best sub-model is automatically selected as the teacher of the other\nsub-models at each client. Our experiments on standard image and speech\nclassification benchmarks across various emerging federated fine-tuning\nbaselines demonstrate ReeFL's effectiveness over previous works.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "cs.DC"
        ],
        "authors": [
            "Royson Lee",
            "Javier Fernandez-Marques",
            "Shell Xu Hu",
            "Da Li",
            "Stefanos Laskaridis",
            "Łukasz Dudziak",
            "Timothy Hospedales",
            "Ferenc Huszár",
            "Nicholas D. Lane"
        ],
        "published": "2024-05-23T17:01:53Z"
    },
    {
        "title": "DIDI: Diffusion-Guided Diversity for Offline Behavioral Generation",
        "link": "http://arxiv.org/abs/2405.14790v1",
        "abstract": "In this paper, we propose a novel approach called DIffusion-guided DIversity\n(DIDI) for offline behavioral generation. The goal of DIDI is to learn a\ndiverse set of skills from a mixture of label-free offline data. We achieve\nthis by leveraging diffusion probabilistic models as priors to guide the\nlearning process and regularize the policy. By optimizing a joint objective\nthat incorporates diversity and diffusion-guided regularization, we encourage\nthe emergence of diverse behaviors while maintaining the similarity to the\noffline data. Experimental results in four decision-making domains (Push,\nKitchen, Humanoid, and D4RL tasks) show that DIDI is effective in discovering\ndiverse and discriminative skills. We also introduce skill stitching and skill\ninterpolation, which highlight the generalist nature of the learned skill\nspace. Further, by incorporating an extrinsic reward function, DIDI enables\nreward-guided behavior generation, facilitating the learning of diverse and\noptimal behaviors from sub-optimal data.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Jinxin Liu",
            "Xinghong Guo",
            "Zifeng Zhuang",
            "Donglin Wang"
        ],
        "published": "2024-05-23T17:00:15Z"
    },
    {
        "title": "Masked Image Modelling for retinal OCT understanding",
        "link": "http://arxiv.org/abs/2405.14788v1",
        "abstract": "This work explores the effectiveness of masked image modelling for learning\nrepresentations of retinal OCT images. To this end, we leverage Masked\nAutoencoders (MAE), a simple and scalable method for self-supervised learning,\nto obtain a powerful and general representation for OCT images by training on\n700K OCT images from 41K patients collected under real world clinical settings.\nWe also provide the first extensive evaluation for a model of OCT on a\nchallenging battery of 6 downstream tasks. Our model achieves strong\nperformance when fully finetuned but can also serve as a versatile frozen\nfeature extractor for many tasks using lightweight adapters. Furthermore, we\npropose an extension of the MAE pretraining to fuse OCT with an auxiliary\nmodality, namely, IR fundus images and learn a joint model for both. We\ndemonstrate our approach improves performance on a multimodal downstream\napplication. Our experiments utilize most publicly available OCT datasets, thus\nenabling future comparisons. Our code and model weights are publicly available\nhttps://github.com/TheoPis/MIM_OCT.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Theodoros Pissas",
            "Pablo Márquez-Neila",
            "Sebastian Wolf",
            "Martin Zinkernagel",
            "Raphael Sznitman"
        ],
        "published": "2024-05-23T16:57:54Z"
    },
    {
        "title": "Non-diffusive neural network method for hyperbolic conservation laws",
        "link": "http://arxiv.org/abs/2405.15559v1",
        "abstract": "In this paper we develop a non-diffusive neural network (NDNN) algorithm for\naccurately solving weak solutions to hyperbolic conservation laws. The\nprinciple is to construct these weak solutions by computing smooth local\nsolutions in subdomains bounded by discontinuity lines (DLs), the latter\ndefined from the Rankine-Hugoniot jump conditions. The proposed approach allows\nto efficiently consider an arbitrary number of entropic shock waves, shock wave\ngeneration, as well as wave interactions. Some numerical experiments are\npresented to illustrate the strengths and properties of the algorithms.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "35A35, 35L02, 35L65, 35D30, 65M55"
        ],
        "authors": [
            "Emmanuel Lorin",
            "Arian Novruzi"
        ],
        "published": "2024-05-23T16:56:07Z"
    },
    {
        "title": "EditWorld: Simulating World Dynamics for Instruction-Following Image\n  Editing",
        "link": "http://arxiv.org/abs/2405.14785v1",
        "abstract": "Diffusion models have significantly improved the performance of image\nediting. Existing methods realize various approaches to achieve high-quality\nimage editing, including but not limited to text control, dragging operation,\nand mask-and-inpainting. Among these, instruction-based editing stands out for\nits convenience and effectiveness in following human instructions across\ndiverse scenarios. However, it still focuses on simple editing operations like\nadding, replacing, or deleting, and falls short of understanding aspects of\nworld dynamics that convey the realistic dynamic nature in the physical world.\nTherefore, this work, EditWorld, introduces a new editing task, namely\nworld-instructed image editing, which defines and categorizes the instructions\ngrounded by various world scenarios. We curate a new image editing dataset with\nworld instructions using a set of large pretrained models (e.g., GPT-3.5,\nVideo-LLava and SDXL). To enable sufficient simulation of world dynamics for\nimage editing, our EditWorld trains model in the curated dataset, and improves\ninstruction-following ability with designed post-edit strategy. Extensive\nexperiments demonstrate our method significantly outperforms existing editing\nmethods in this new task. Our dataset and code will be available at\nhttps://github.com/YangLing0818/EditWorld",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ling Yang",
            "Bohan Zeng",
            "Jiaming Liu",
            "Hong Li",
            "Minghao Xu",
            "Wentao Zhang",
            "Shuicheng Yan"
        ],
        "published": "2024-05-23T16:54:17Z"
    },
    {
        "title": "Low-Energy Line Codes for On-Chip Networks",
        "link": "http://arxiv.org/abs/2405.14783v1",
        "abstract": "Energy is a primary constraint in processor design, and much of that energy\nis consumed in on-chip communication. Communication can be intra-core (e.g.,\nfrom a register file to an ALU) or inter-core (e.g., over the on-chip network).\nIn this paper, we use the on-chip network (OCN) as a case study for saving\non-chip communication energy. We have identified a new way to reduce the OCN's\nlink energy consumption by using line coding, a longstanding technique in\ninformation theory. Our line codes, called Low-Energy Line Codes (LELCs),\nreduce energy by reducing the frequency of voltage transitions of the links,\nand they achieve a range of energy/performance trade-offs.",
        "subjects": [
            "cs.HC",
            "C.1.2"
        ],
        "authors": [
            "Beyza Dabak",
            "Major Glenn",
            "Jingyang Liu",
            "Alexander Buck",
            "Siyi Yang",
            "Robert Calderbank",
            "Natalie Enright Jerger",
            "Daniel J. Sorin"
        ],
        "published": "2024-05-23T16:52:14Z"
    },
    {
        "title": "Lessons from the Trenches on Reproducible Evaluation of Language Models",
        "link": "http://arxiv.org/abs/2405.14782v1",
        "abstract": "Effective evaluation of language models remains an open challenge in NLP.\nResearchers and engineers face methodological issues such as the sensitivity of\nmodels to evaluation setup, difficulty of proper comparisons across methods,\nand the lack of reproducibility and transparency. In this paper we draw on\nthree years of experience in evaluating large language models to provide\nguidance and lessons for researchers. First, we provide an overview of common\nchallenges faced in language model evaluation. Second, we delineate best\npractices for addressing or lessening the impact of these challenges on\nresearch. Third, we present the Language Model Evaluation Harness (lm-eval): an\nopen source library for independent, reproducible, and extensible evaluation of\nlanguage models that seeks to address these issues. We describe the features of\nthe library as well as case studies in which the library has been used to\nalleviate these methodological concerns.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Stella Biderman",
            "Hailey Schoelkopf",
            "Lintang Sutawika",
            "Leo Gao",
            "Jonathan Tow",
            "Baber Abbasi",
            "Alham Fikri Aji",
            "Pawan Sasanka Ammanamanchi",
            "Sidney Black",
            "Jordan Clive",
            "Anthony DiPofi",
            "Julen Etxaniz",
            "Benjamin Fattori",
            "Jessica Zosa Forde",
            "Charles Foster",
            "Mimansa Jaiswal",
            "Wilson Y. Lee",
            "Haonan Li",
            "Charles Lovering",
            "Niklas Muennighoff",
            "Ellie Pavlick",
            "Jason Phang",
            "Aviya Skowron",
            "Samson Tan",
            "Xiangru Tang",
            "Kevin A. Wang",
            "Genta Indra Winata",
            "François Yvon",
            "Andy Zou"
        ],
        "published": "2024-05-23T16:50:49Z"
    },
    {
        "title": "Unified Neural Backdoor Removal with Only Few Clean Samples through\n  Unlearning and Relearning",
        "link": "http://arxiv.org/abs/2405.14781v1",
        "abstract": "The application of deep neural network models in various security-critical\napplications has raised significant security concerns, particularly the risk of\nbackdoor attacks. Neural backdoors pose a serious security threat as they allow\nattackers to maliciously alter model behavior. While many defenses have been\nexplored, existing approaches are often bounded by model-specific constraints,\nor necessitate complex alterations to the training process, or fall short\nagainst diverse backdoor attacks. In this work, we introduce a novel method for\ncomprehensive and effective elimination of backdoors, called ULRL (short for\nUnLearn and ReLearn for backdoor removal). ULRL requires only a small set of\nclean samples and works effectively against all kinds of backdoors. It first\napplies unlearning for identifying suspicious neurons and then targeted neural\nweight tuning for backdoor mitigation (i.e., by promoting significant weight\ndeviation on the suspicious neurons). Evaluated against 12 different types of\nbackdoors, ULRL is shown to significantly outperform state-of-the-art methods\nin eliminating backdoors whilst preserving the model utility.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "authors": [
            "Nay Myat Min",
            "Long H. Pham",
            "Jun Sun"
        ],
        "published": "2024-05-23T16:49:09Z"
    },
    {
        "title": "Metric Flow Matching for Smooth Interpolations on the Data Manifold",
        "link": "http://arxiv.org/abs/2405.14780v1",
        "abstract": "Matching objectives underpin the success of modern generative models and rely\non constructing conditional paths that transform a source distribution into a\ntarget distribution. Despite being a fundamental building block, conditional\npaths have been designed principally under the assumption of Euclidean\ngeometry, resulting in straight interpolations. However, this can be\nparticularly restrictive for tasks such as trajectory inference, where straight\npaths might lie outside the data manifold, thus failing to capture the\nunderlying dynamics giving rise to the observed marginals. In this paper, we\npropose Metric Flow Matching (MFM), a novel simulation-free framework for\nconditional flow matching where interpolants are approximate geodesics learned\nby minimizing the kinetic energy of a data-induced Riemannian metric. This way,\nthe generative model matches vector fields on the data manifold, which\ncorresponds to lower uncertainty and more meaningful interpolations. We\nprescribe general metrics to instantiate MFM, independent of the task, and test\nit on a suite of challenging problems including LiDAR navigation, unpaired\nimage translation, and modeling cellular dynamics. We observe that MFM\noutperforms the Euclidean baselines, particularly achieving SOTA on single-cell\ntrajectory prediction.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Kacper Kapusniak",
            "Peter Potaptchik",
            "Teodora Reu",
            "Leo Zhang",
            "Alexander Tong",
            "Michael Bronstein",
            "Avishek Joey Bose",
            "Francesco Di Giovanni"
        ],
        "published": "2024-05-23T16:48:06Z"
    },
    {
        "title": "Smart Bilingual Focused Crawling of Parallel Documents",
        "link": "http://arxiv.org/abs/2405.14779v1",
        "abstract": "Crawling parallel texts $\\unicode{x2014}$texts that are mutual\ntranslations$\\unicode{x2014}$ from the Internet is usually done following a\nbrute-force approach: documents are massively downloaded in an unguided\nprocess, and only a fraction of them end up leading to actual parallel content.\nIn this work we propose a smart crawling method that guides the crawl towards\nfinding parallel content more rapidly. Our approach builds on two different\nmodels: one that infers the language of a document from its URL, and another\nthat infers whether a pair of URLs link to parallel documents. We evaluate both\nmodels in isolation and their integration into a crawling tool. The results\ndemonstrate the individual effectiveness of both models and highlight that\ntheir combination enables the early discovery of parallel content during\ncrawling, leading to a reduction in the amount of downloaded documents deemed\nuseless, and yielding a greater quantity of parallel documents compared to\nconventional crawling approaches.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Cristian García-Romero",
            "Miquel Esplà-Gomis",
            "Felipe Sánchez-Martínez"
        ],
        "published": "2024-05-23T16:45:59Z"
    },
    {
        "title": "Optimal Rates for Vector-Valued Spectral Regularization Learning\n  Algorithms",
        "link": "http://arxiv.org/abs/2405.14778v1",
        "abstract": "We study theoretical properties of a broad class of regularized algorithms\nwith vector-valued output. These spectral algorithms include kernel ridge\nregression, kernel principal component regression, various implementations of\ngradient descent and many more. Our contributions are twofold. First, we\nrigorously confirm the so-called saturation effect for ridge regression with\nvector-valued output by deriving a novel lower bound on learning rates; this\nbound is shown to be suboptimal when the smoothness of the regression function\nexceeds a certain level. Second, we present the upper bound for the finite\nsample risk general vector-valued spectral algorithms, applicable to both\nwell-specified and misspecified scenarios (where the true regression function\nlies outside of the hypothesis space) which is minimax optimal in various\nregimes. All of our results explicitly allow the case of infinite-dimensional\noutput variables, proving consistency of recent practical applications.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Dimitri Meunier",
            "Zikai Shen",
            "Mattes Mollenhauer",
            "Arthur Gretton",
            "Zhu Li"
        ],
        "published": "2024-05-23T16:45:52Z"
    },
    {
        "title": "Kinetics of orbital ordering in cooperative Jahn-Teller models:\n  Machine-learning enabled large-scale simulations",
        "link": "http://arxiv.org/abs/2405.14776v1",
        "abstract": "We present a scalable machine learning (ML) force-field model for the\nadiabatic dynamics of cooperative Jahn-Teller (JT) systems. Large scale\ndynamical simulations of the JT model also shed light on the orbital ordering\ndynamics in colossal magnetoresistance manganites. The JT effect in these\nmaterials describes the distortion of local oxygen octahedra driven by a\ncoupling to the orbital degrees of freedom of $e_g$ electrons. An effective\nelectron-mediated interaction between the local JT modes leads to a structural\ntransition and the emergence of long-range orbital order at low temperatures.\nAssuming the principle of locality, a deep-learning neural-network model is\ndeveloped to accurately and efficiently predict the electron-induced forces\nthat drive the dynamical evolution of JT phonons. A group-theoretical method is\nutilized to develop a descriptor that incorporates the combined orbital and\nlattice symmetry into the ML model. Large-scale Langevin dynamics simulations,\nenabled by the ML force-field models, are performed to investigate the\ncoarsening dynamics of the composite JT distortion and orbital order after a\nthermal quench. The late-stage coarsening of orbital domains exhibits\npronounced freezing behaviors which are likely related to the unusual\nmorphology of the domain structures. Our work highlights a promising avenue for\nmulti-scale dynamical modeling of correlated electron systems.",
        "subjects": [
            "cond-mat.str-el",
            "cond-mat.mtrl-sci",
            "cs.LG"
        ],
        "authors": [
            "Supriyo Ghosh",
            "Sheng Zhang",
            "Chen Cheng",
            "Gia-Wei Chern"
        ],
        "published": "2024-05-23T16:44:29Z"
    },
    {
        "title": "Vortex-capturing multiscale spaces for the Ginzburg-Landau equation",
        "link": "http://arxiv.org/abs/2405.14772v1",
        "abstract": "This paper considers minimizers of the Ginzburg-Landau energy functional in\nparticular multiscale spaces which are based on finite elements. The spaces are\nconstructed by localized orthogonal decomposition techniques and their usage\nfor solving the Ginzburg-Landau equation was first suggested in [D\\\"orich,\nHenning, SINUM 2024]. In this work we further explore their approximation\nproperties and give an analytical explanation for why vortex structures of\nenergy minimizers can be captured more accurately in these spaces. We quantify\nthe necessary mesh resolution in terms of the Ginzburg-Landau parameter\n$\\kappa$ and a stabilization parameter $\\beta \\ge 0$ that is used in the\nconstruction of the multiscale spaces. Furthermore, we analyze how $\\kappa$\naffects the necessary locality of the multiscale basis functions and we prove\nthat the choice $\\beta=0$ yields typically the highest accuracy. Our findings\nare supported by numerical experiments.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Maria Blum",
            "Christian Döding",
            "Patrick Henning"
        ],
        "published": "2024-05-23T16:40:26Z"
    },
    {
        "title": "Pragmatic Feature Preferences: Learning Reward-Relevant Preferences from\n  Human Input",
        "link": "http://arxiv.org/abs/2405.14769v1",
        "abstract": "Humans use social context to specify preferences over behaviors, i.e. their\nreward functions. Yet, algorithms for inferring reward models from preference\ndata do not take this social learning view into account. Inspired by pragmatic\nhuman communication, we study how to extract fine-grained data regarding why an\nexample is preferred that is useful for learning more accurate reward models.\nWe propose to enrich binary preference queries to ask both (1) which features\nof a given example are preferable in addition to (2) comparisons between\nexamples themselves. We derive an approach for learning from these\nfeature-level preferences, both for cases where users specify which features\nare reward-relevant, and when users do not. We evaluate our approach on linear\nbandit settings in both vision- and language-based domains. Results support the\nefficiency of our approach in quickly converging to accurate rewards with fewer\ncomparisons vs. example-only labels. Finally, we validate the real-world\napplicability with a behavioral experiment on a mushroom foraging task. Our\nfindings suggest that incorporating pragmatic feature preferences is a\npromising approach for more efficient user-aligned reward learning.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "authors": [
            "Andi Peng",
            "Yuying Sun",
            "Tianmin Shu",
            "David Abel"
        ],
        "published": "2024-05-23T16:36:16Z"
    },
    {
        "title": "WISE: Rethinking the Knowledge Memory for Lifelong Model Editing of\n  Large Language Models",
        "link": "http://arxiv.org/abs/2405.14768v1",
        "abstract": "Large language models (LLMs) need knowledge updates to meet the ever-growing\nworld facts and correct the hallucinated responses, facilitating the methods of\nlifelong model editing. Where the updated knowledge resides in memories is a\nfundamental question for model editing. In this paper, we find that editing\neither long-term memory (direct model parameters) or working memory\n(non-parametric knowledge of neural network activations/representations by\nretrieval) will result in an impossible triangle -- reliability,\ngeneralization, and locality can not be realized together in the lifelong\nediting settings. For long-term memory, directly editing the parameters will\ncause conflicts with irrelevant pretrained knowledge or previous edits (poor\nreliability and locality). For working memory, retrieval-based activations can\nhardly make the model understand the edits and generalize (poor\ngeneralization). Therefore, we propose WISE to bridge the gap between memories.\nIn WISE, we design a dual parametric memory scheme, which consists of the main\nmemory for the pretrained knowledge and a side memory for the edited knowledge.\nWe only edit the knowledge in the side memory and train a router to decide\nwhich memory to go through when given a query. For continual editing, we devise\na knowledge-sharding mechanism where different sets of edits reside in distinct\nsubspaces of parameters, and are subsequently merged into a shared memory\nwithout conflicts. Extensive experiments show that WISE can outperform previous\nmodel editing methods and overcome the impossible triangle under lifelong model\nediting of question answering, hallucination, and out-of-distribution settings\nacross trending LLM architectures, e.g., GPT, LLaMA, and Mistral. Code will be\nreleased at https://github.com/zjunlp/EasyEdit.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV",
            "cs.IR",
            "cs.LG"
        ],
        "authors": [
            "Peng Wang",
            "Zexi Li",
            "Ningyu Zhang",
            "Ziwen Xu",
            "Yunzhi Yao",
            "Yong Jiang",
            "Pengjun Xie",
            "Fei Huang",
            "Huajun Chen"
        ],
        "published": "2024-05-23T16:35:52Z"
    },
    {
        "title": "FinRobot: An Open-Source AI Agent Platform for Financial Applications\n  using Large Language Models",
        "link": "http://arxiv.org/abs/2405.14767v1",
        "abstract": "As financial institutions and professionals increasingly incorporate Large\nLanguage Models (LLMs) into their workflows, substantial barriers, including\nproprietary data and specialized knowledge, persist between the finance sector\nand the AI community. These challenges impede the AI community's ability to\nenhance financial tasks effectively. Acknowledging financial analysis's\ncritical role, we aim to devise financial-specialized LLM-based toolchains and\ndemocratize access to them through open-source initiatives, promoting wider AI\nadoption in financial decision-making.\n  In this paper, we introduce FinRobot, a novel open-source AI agent platform\nsupporting multiple financially specialized AI agents, each powered by LLM.\nSpecifically, the platform consists of four major layers: 1) the Financial AI\nAgents layer that formulates Financial Chain-of-Thought (CoT) by breaking\nsophisticated financial problems down into logical sequences; 2) the Financial\nLLM Algorithms layer dynamically configures appropriate model application\nstrategies for specific tasks; 3) the LLMOps and DataOps layer produces\naccurate models by applying training/fine-tuning techniques and using\ntask-relevant data; 4) the Multi-source LLM Foundation Models layer that\nintegrates various LLMs and enables the above layers to access them directly.\nFinally, FinRobot provides hands-on for both professional-grade analysts and\nlaypersons to utilize powerful AI techniques for advanced financial analysis.\nWe open-source FinRobot at\n\\url{https://github.com/AI4Finance-Foundation/FinRobot}.",
        "subjects": [
            "q-fin.ST",
            "cs.CL",
            "cs.LG",
            "q-fin.TR"
        ],
        "authors": [
            "Hongyang Yang",
            "Boyu Zhang",
            "Neng Wang",
            "Cheng Guo",
            "Xiaoli Zhang",
            "Likun Lin",
            "Junlin Wang",
            "Tianyu Zhou",
            "Mao Guan",
            "Runjia Zhang",
            "Christina Dan Wang"
        ],
        "published": "2024-05-23T16:35:20Z"
    },
    {
        "title": "Evaluating Large Language Models for Public Health Classification and\n  Extraction Tasks",
        "link": "http://arxiv.org/abs/2405.14766v1",
        "abstract": "Advances in Large Language Models (LLMs) have led to significant interest in\ntheir potential to support human experts across a range of domains, including\npublic health. In this work we present automated evaluations of LLMs for public\nhealth tasks involving the classification and extraction of free text. We\ncombine six externally annotated datasets with seven new internally annotated\ndatasets to evaluate LLMs for processing text related to: health burden,\nepidemiological risk factors, and public health interventions. We initially\nevaluate five open-weight LLMs (7-70 billion parameters) across all tasks using\nzero-shot in-context learning. We find that Llama-3-70B-Instruct is the highest\nperforming model, achieving the best results on 15/17 tasks (using micro-F1\nscores). We see significant variation across tasks with all open-weight LLMs\nscoring below 60% micro-F1 on some challenging tasks, such as Contact\nClassification, while all LLMs achieve greater than 80% micro-F1 on others,\nsuch as GI Illness Classification. For a subset of 12 tasks, we also evaluate\nGPT-4 and find comparable results to Llama-3-70B-Instruct, which scores equally\nor outperforms GPT-4 on 6 of the 12 tasks. Overall, based on these initial\nresults we find promising signs that LLMs may be useful tools for public health\nexperts to extract information from a wide variety of free text sources, and\nsupport public health surveillance, research, and interventions.",
        "subjects": [
            "cs.CL",
            "cs.LG",
            "68T50"
        ],
        "authors": [
            "Joshua Harris",
            "Timothy Laurence",
            "Leo Loman",
            "Fan Grayson",
            "Toby Nonnenmacher",
            "Harry Long",
            "Loes WalsGriffith",
            "Amy Douglas",
            "Holly Fountain",
            "Stelios Georgiou",
            "Jo Hardstaff",
            "Kathryn Hopkins",
            "Y-Ling Chi",
            "Galena Kuyumdzhieva",
            "Lesley Larkin",
            "Samuel Collins",
            "Hamish Mohammed",
            "Thomas Finnie",
            "Luke Hounsome",
            "Steven Riley"
        ],
        "published": "2024-05-23T16:33:18Z"
    },
    {
        "title": "A Quantum Speed-Up for Approximating the Top Eigenvectors of a Matrix",
        "link": "http://arxiv.org/abs/2405.14765v1",
        "abstract": "Finding a good approximation of the top eigenvector of a given $d\\times d$\nmatrix $A$ is a basic and important computational problem, with many\napplications. We give two different quantum algorithms that, given query access\nto the entries of a Hermitian matrix $A$ and assuming a constant eigenvalue\ngap, output a classical description of a good approximation of the top\neigenvector: one algorithm with time complexity $\\mathcal{\\tilde{O}}(d^{1.75})$\nand one with time complexity $d^{1.5+o(1)}$ (the first algorithm has a slightly\nbetter dependence on the $\\ell_2$-error of the approximating vector than the\nsecond, and uses different techniques of independent interest). Both of our\nquantum algorithms provide a polynomial speed-up over the best-possible\nclassical algorithm, which needs $\\Omega(d^2)$ queries to entries of $A$, and\nhence $\\Omega(d^2)$ time. We extend this to a quantum algorithm that outputs a\nclassical description of the subspace spanned by the top-$q$ eigenvectors in\ntime $qd^{1.5+o(1)}$. We also prove a nearly-optimal lower bound of\n$\\tilde{\\Omega}(d^{1.5})$ on the quantum query complexity of approximating the\ntop eigenvector.\n  Our quantum algorithms run a version of the classical power method that is\nrobust to certain benign kinds of errors, where we implement each matrix-vector\nmultiplication with small and well-behaved error on a quantum computer, in\ndifferent ways for the two algorithms. Our first algorithm estimates the\nmatrix-vector product one entry at a time, using a new ``Gaussian phase\nestimation'' procedure. Our second algorithm uses block-encoding techniques to\ncompute the matrix-vector product as a quantum state, from which we obtain a\nclassical description by a new time-efficient unbiased pure-state tomography\nprocedure.",
        "subjects": [
            "quant-ph",
            "cs.DS"
        ],
        "authors": [
            "Yanlin Chen",
            "András Gilyén",
            "Ronald de Wolf"
        ],
        "published": "2024-05-23T16:33:13Z"
    },
    {
        "title": "Structure preserving finite element schemes for the\n  Navier-Stokes-Cahn-Hilliard system with degenerate mobility",
        "link": "http://arxiv.org/abs/2405.14763v1",
        "abstract": "In this work we present two new numerical schemes to approximate the\nNavier-Stokes-Cahn-Hilliard system with degenerate mobility using finite\ndifferences in time and finite elements in space. The proposed schemes are\nconservative, energy-stable and preserve the maximum principle approximately\n(the amount of the phase variable being outside of the interval [0,1] goes to\nzero in terms of a truncation parameter). Additionally, we present several\nnumerical results to illustrate the accuracy and the well behavior of the\nproposed schemes, as well as a comparison with the behavior of the\nNavier-Stokes-Cahn-Hilliard model with constant mobility.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Francisco Guillén-González",
            "Giordano Tierra"
        ],
        "published": "2024-05-23T16:32:06Z"
    },
    {
        "title": "Neural Pfaffians: Solving Many Many-Electron Schrödinger Equations",
        "link": "http://arxiv.org/abs/2405.14762v1",
        "abstract": "Neural wave functions accomplished unprecedented accuracies in approximating\nthe ground state of many-electron systems, though at a high computational cost.\nRecent works proposed amortizing the cost by learning generalized wave\nfunctions across different structures and compounds instead of solving each\nproblem independently. Enforcing the permutation antisymmetry of electrons in\nsuch generalized neural wave functions remained challenging as existing methods\nrequire discrete orbital selection via non-learnable hand-crafted algorithms.\nThis work tackles the problem by defining overparametrized, fully learnable\nneural wave functions suitable for generalization across molecules. We achieve\nthis by relying on Pfaffians rather than Slater determinants. The Pfaffian\nallows us to enforce the antisymmetry on arbitrary electronic systems without\nany constraint on electronic spin configurations or molecular structure. Our\nempirical evaluation finds that a single neural Pfaffian calculates the ground\nstate and ionization energies with chemical accuracy across various systems. On\nthe TinyMol dataset, we outperform the `gold-standard' CCSD(T) CBS reference\nenergies by 1.9m$E_h$ and reduce energy errors compared to previous generalized\nneural wave functions by up to an order of magnitude.",
        "subjects": [
            "cs.LG",
            "physics.chem-ph",
            "physics.comp-ph",
            "quant-ph"
        ],
        "authors": [
            "Nicholas Gao",
            "Stephan Günnemann"
        ],
        "published": "2024-05-23T16:30:51Z"
    },
    {
        "title": "Fault Tolerant ML: Efficient Meta-Aggregation and Synchronous Training",
        "link": "http://arxiv.org/abs/2405.14759v1",
        "abstract": "In this paper, we investigate the challenging framework of Byzantine-robust\ntraining in distributed machine learning (ML) systems, focusing on enhancing\nboth efficiency and practicality. As distributed ML systems become integral for\ncomplex ML tasks, ensuring resilience against Byzantine failures-where workers\nmay contribute incorrect updates due to malice or error-gains paramount\nimportance. Our first contribution is the introduction of the Centered Trimmed\nMeta Aggregator (CTMA), an efficient meta-aggregator that upgrades baseline\naggregators to optimal performance levels, while requiring low computational\ndemands. Additionally, we propose harnessing a recently developed gradient\nestimation technique based on a double-momentum strategy within the Byzantine\ncontext. Our paper highlights its theoretical and practical advantages for\nByzantine-robust training, especially in simplifying the tuning process and\nreducing the reliance on numerous hyperparameters. The effectiveness of this\ntechnique is supported by theoretical insights within the stochastic convex\noptimization (SCO) framework.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Tehila Dahan",
            "Kfir Y. Levy"
        ],
        "published": "2024-05-23T16:29:30Z"
    },
    {
        "title": "Axioms for AI Alignment from Human Feedback",
        "link": "http://arxiv.org/abs/2405.14758v1",
        "abstract": "In the context of reinforcement learning from human feedback (RLHF), the\nreward function is generally derived from maximum likelihood estimation of a\nrandom utility model based on pairwise comparisons made by humans. The problem\nof learning a reward function is one of preference aggregation that, we argue,\nlargely falls within the scope of social choice theory. From this perspective,\nwe can evaluate different aggregation methods via established axioms, examining\nwhether these methods meet or fail well-known standards. We demonstrate that\nboth the Bradley-Terry-Luce Model and its broad generalizations fail to meet\nbasic axioms. In response, we develop novel rules for learning reward functions\nwith strong axiomatic guarantees. A key innovation from the standpoint of\nsocial choice is that our problem has a linear structure, which greatly\nrestricts the space of feasible rules and leads to a new paradigm that we call\nlinear social choice.",
        "subjects": [
            "cs.GT",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Luise Ge",
            "Daniel Halpern",
            "Evi Micha",
            "Ariel D. Procaccia",
            "Itai Shapira",
            "Yevgeniy Vorobeychik",
            "Junlin Wu"
        ],
        "published": "2024-05-23T16:29:29Z"
    },
    {
        "title": "Large language models can be zero-shot anomaly detectors for time\n  series?",
        "link": "http://arxiv.org/abs/2405.14755v1",
        "abstract": "Recent studies have shown the ability of large language models to perform a\nvariety of tasks, including time series forecasting. The flexible nature of\nthese models allows them to be used for many applications. In this paper, we\npresent a novel study of large language models used for the challenging task of\ntime series anomaly detection. This problem entails two aspects novel for LLMs:\nthe need for the model to identify part of the input sequence (or multiple\nparts) as anomalous; and the need for it to work with time series data rather\nthan the traditional text input. We introduce sigllm, a framework for time\nseries anomaly detection using large language models. Our framework includes a\ntime-series-to-text conversion module, as well as end-to-end pipelines that\nprompt language models to perform time series anomaly detection. We investigate\ntwo paradigms for testing the abilities of large language models to perform the\ndetection task. First, we present a prompt-based detection method that directly\nasks a language model to indicate which elements of the input are anomalies.\nSecond, we leverage the forecasting capability of a large language model to\nguide the anomaly detection process. We evaluated our framework on 11 datasets\nspanning various sources and 10 pipelines. We show that the forecasting method\nsignificantly outperformed the prompting method in all 11 datasets with respect\nto the F1 score. Moreover, while large language models are capable of finding\nanomalies, state-of-the-art deep learning models are still superior in\nperformance, achieving results 30% better than large language models.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Sarah Alnegheimish",
            "Linh Nguyen",
            "Laure Berti-Equille",
            "Kalyan Veeramachaneni"
        ],
        "published": "2024-05-23T16:21:57Z"
    },
    {
        "title": "Applied Machine Learning to Anomaly Detection in Enterprise Purchase\n  Processes",
        "link": "http://arxiv.org/abs/2405.14754v1",
        "abstract": "In a context of a continuous digitalisation of processes, organisations must\ndeal with the challenge of detecting anomalies that can reveal suspicious\nactivities upon an increasing volume of data. To pursue this goal, audit\nengagements are carried out regularly, and internal auditors and purchase\nspecialists are constantly looking for new methods to automate these processes.\nThis work proposes a methodology to prioritise the investigation of the cases\ndetected in two large purchase datasets from real data. The goal is to\ncontribute to the effectiveness of the companies' control efforts and to\nincrease the performance of carrying out such tasks. A comprehensive\nExploratory Data Analysis is carried out before using unsupervised Machine\nLearning techniques addressed to detect anomalies. A univariate approach has\nbeen applied through the z-Score index and the DBSCAN algorithm, while a\nmultivariate analysis is implemented with the k-Means and Isolation Forest\nalgorithms, and the Silhouette index, resulting in each method having a\ntransaction candidates' proposal to be reviewed. An ensemble prioritisation of\nthe candidates is provided jointly with a proposal of explicability methods\n(LIME, Shapley, SHAP) to help the company specialists in their understanding.",
        "subjects": [
            "cs.CE",
            "cs.LG"
        ],
        "authors": [
            "A. Herreros-Martínez",
            "R. Magdalena-Benedicto",
            "J. Vila-Francés",
            "A. J. Serrano-López",
            "S. Pérez-Díaz"
        ],
        "published": "2024-05-23T16:21:51Z"
    },
    {
        "title": "SliM-LLM: Salience-Driven Mixed-Precision Quantization for Large\n  Language Models",
        "link": "http://arxiv.org/abs/2405.14917v1",
        "abstract": "Large language models (LLMs) achieve remarkable performance in natural\nlanguage understanding but require substantial computation and memory\nresources. Post-training quantization (PTQ) is a powerful compression technique\nextensively investigated in LLMs. However, existing PTQ methods are still not\nideal in terms of accuracy and efficiency, especially with below 4 bit-widths.\nStandard PTQ methods using group-wise quantization suffer difficulties in\nquantizing LLMs accurately to such low-bit, but advanced methods remaining\nhigh-precision weights element-wisely are hard to realize their theoretical\nhardware efficiency. This paper presents a Salience-Driven Mixed-Precision\nQuantization scheme for LLMs, namely SliM-LLM. The scheme exploits the salience\ndistribution of weights to determine optimal bit-width and quantizers for\naccurate LLM quantization, while aligning bit-width partition to groups for\ncompact memory usage and fast integer inference. Specifically, the proposed\nSliM-LLM mainly relies on two novel techniques: (1) Salience-Determined Bit\nAllocation utilizes the clustering characteristics of salience distribution to\nallocate the bit-widths of each group, increasing the accuracy of quantized\nLLMs and maintaining the inference efficiency; (2) Salience-Weighted Quantizer\nCalibration optimizes the parameters of the quantizer by considering the\nelement-wise salience within the group, balancing the maintenance of salient\ninformation and minimization of errors. Comprehensive experiments show that\nSliM-LLM significantly improves the accuracy of LLMs at ultra-low bits, e.g.,\n2-bit LLaMA-7B achieves a 5.5-times memory-saving than original model on NVIDIA\nA800 GPUs, and 48% decrease of perplexity compared to the state-of-the-art\ngradient-free PTQ method. Moreover, SliM-LLM+, which is integrated from the\nextension of SliM-LLM with gradient-based quantizers, further reduces\nperplexity by 35.1%.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "authors": [
            "Wei Huang",
            "Haotong Qin",
            "Yangdong Liu",
            "Yawei Li",
            "Xianglong Liu",
            "Luca Benini",
            "Michele Magno",
            "Xiaojuan Qi"
        ],
        "published": "2024-05-23T16:21:48Z"
    },
    {
        "title": "A Transformer-Based Approach for Smart Invocation of Automatic Code\n  Completion",
        "link": "http://dx.doi.org/10.1145/3664646.3664760",
        "abstract": "Transformer-based language models are highly effective for code completion,\nwith much research dedicated to enhancing the content of these completions.\nDespite their effectiveness, these models come with high operational costs and\ncan be intrusive, especially when they suggest too often and interrupt\ndevelopers who are concentrating on their work. Current research largely\noverlooks how these models interact with developers in practice and neglects to\naddress when a developer should receive completion suggestions. To tackle this\nissue, we developed a machine learning model that can accurately predict when\nto invoke a code completion tool given the code context and available telemetry\ndata.\n  To do so, we collect a dataset of 200k developer interactions with our\ncross-IDE code completion plugin and train several invocation filtering models.\nOur results indicate that our small-scale transformer model significantly\noutperforms the baseline while maintaining low enough latency. We further\nexplore the search space for integrating additional telemetry data into a\npre-trained transformer directly and obtain promising results. To further\ndemonstrate our approach's practical potential, we deployed the model in an\nonline environment with 34 developers and provided real-world insights based on\n74k actual invocations.",
        "subjects": [
            "cs.SE",
            "cs.AI",
            "cs.HC",
            "cs.LG"
        ],
        "authors": [
            "Aral de Moor",
            "Arie van Deursen",
            "Maliheh Izadi"
        ],
        "published": "2024-05-23T16:19:32Z"
    },
    {
        "title": "AGILE: A Novel Framework of LLM Agents",
        "link": "http://arxiv.org/abs/2405.14751v1",
        "abstract": "We introduce a novel framework of LLM agents named AGILE (AGent that\nInteracts and Learns from Environments) designed to perform complex\nconversational tasks with users, leveraging LLMs, memory, tools, and\ninteractions with experts. The agent's abilities include not only conversation\nbut also reflection, utilization of tools, and consultation with experts. We\nformulate the construction of such an LLM agent as a reinforcement learning\nproblem, in which the LLM serves as the policy model. We fine-tune the LLM\nusing labeled data of actions and the PPO algorithm. We focus on question\nanswering and release a dataset for agents called ProductQA, comprising\nchallenging questions in online shopping. Our extensive experiments on\nProductQA and MedMCQA show that AGILE agents based on 13B and 7B LLMs trained\nwith PPO can outperform GPT-4 agents. Our ablation study highlights the\nindispensability of memory, tools, consultation, reflection, and reinforcement\nlearning in achieving the agent's strong performance.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Peiyuan Feng",
            "Yichen He",
            "Guanhua Huang",
            "Yuan Lin",
            "Hanchong Zhang",
            "Yuchen Zhang",
            "Hang Li"
        ],
        "published": "2024-05-23T16:17:44Z"
    },
    {
        "title": "Extreme Solar Flare Prediction Using Residual Networks with HMI\n  Magnetograms and Intensitygrams",
        "link": "http://arxiv.org/abs/2405.14750v1",
        "abstract": "Solar flares, especially C, M, and X class, pose significant risks to\nsatellite operations, communication systems, and power grids. We present a\nnovel approach for predicting extreme solar flares using HMI intensitygrams and\nmagnetograms. By detecting sunspots from intensitygrams and extracting magnetic\nfield patches from magnetograms, we train a Residual Network (ResNet) to\nclassify extreme class flares. Our model demonstrates high accuracy, offering a\nrobust tool for predicting extreme solar flares and improving space weather\nforecasting. Additionally, we show that HMI magnetograms provide more useful\ndata for deep learning compared to other SDO AIA images by better capturing\nfeatures critical for predicting flare magnitudes. This study underscores the\nimportance of identifying magnetic fields in solar flare prediction, marking a\nsignificant advancement in solar activity prediction with practical\nimplications for mitigating space weather impacts.",
        "subjects": [
            "astro-ph.SR",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Juyoung Yun",
            "Jungmin Shin"
        ],
        "published": "2024-05-23T16:17:16Z"
    },
    {
        "title": "Policy Gradient Methods for Risk-Sensitive Distributional Reinforcement\n  Learning with Provable Convergence",
        "link": "http://arxiv.org/abs/2405.14749v1",
        "abstract": "Risk-sensitive reinforcement learning (RL) is crucial for maintaining\nreliable performance in many high-stakes applications. While most RL methods\naim to learn a point estimate of the random cumulative cost, distributional RL\n(DRL) seeks to estimate the entire distribution of it. The distribution\nprovides all necessary information about the cost and leads to a unified\nframework for handling various risk measures in a risk-sensitive setting.\nHowever, developing policy gradient methods for risk-sensitive DRL is\ninherently more complex as it pertains to finding the gradient of a probability\nmeasure. This paper introduces a policy gradient method for risk-sensitive DRL\nwith general coherent risk measures, where we provide an analytical form of the\nprobability measure's gradient. We further prove the local convergence of the\nproposed algorithm under mild smoothness assumptions. For practical use, we\nalso design a categorical distributional policy gradient algorithm (CDPG) based\non categorical distributional policy evaluation and trajectory-based gradient\nestimation. Through experiments on a stochastic cliff-walking environment, we\nillustrate the benefits of considering a risk-sensitive setting in DRL.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.OC"
        ],
        "authors": [
            "Minheng Xiao",
            "Xian Yu",
            "Lei Ying"
        ],
        "published": "2024-05-23T16:16:58Z"
    },
    {
        "title": "MultiCast: Zero-Shot Multivariate Time Series Forecasting Using LLMs",
        "link": "http://arxiv.org/abs/2405.14748v1",
        "abstract": "Predicting future values in multivariate time series is vital across various\ndomains. This work explores the use of large language models (LLMs) for this\ntask. However, LLMs typically handle one-dimensional data. We introduce\nMultiCast, a zero-shot LLM-based approach for multivariate time series\nforecasting. It allows LLMs to receive multivariate time series as input,\nthrough three novel token multiplexing solutions that effectively reduce\ndimensionality while preserving key repetitive patterns. Additionally, a\nquantization scheme helps LLMs to better learn these patterns, while\nsignificantly reducing token use for practical applications. We showcase the\nperformance of our approach in terms of RMSE and execution time against\nstate-of-the-art approaches on three real-world datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Georgios Chatzigeorgakidis",
            "Konstantinos Lentzos",
            "Dimitrios Skoutas"
        ],
        "published": "2024-05-23T16:16:00Z"
    },
    {
        "title": "TopoLogic: An Interpretable Pipeline for Lane Topology Reasoning on\n  Driving Scenes",
        "link": "http://arxiv.org/abs/2405.14747v1",
        "abstract": "As an emerging task that integrates perception and reasoning, topology\nreasoning in autonomous driving scenes has recently garnered widespread\nattention. However, existing work often emphasizes \"perception over reasoning\":\nthey typically boost reasoning performance by enhancing the perception of lanes\nand directly adopt MLP to learn lane topology from lane query. This paradigm\noverlooks the geometric features intrinsic to the lanes themselves and are\nprone to being influenced by inherent endpoint shifts in lane detection.\n  To tackle this issue, we propose an interpretable method for lane topology\nreasoning based on lane geometric distance and lane query similarity, named\nTopoLogic.\n  This method mitigates the impact of endpoint shifts in geometric space, and\nintroduces explicit similarity calculation in semantic space as a complement.\nBy integrating results from both spaces, our methods provides more\ncomprehensive information for lane topology.\n  Ultimately, our approach significantly outperforms the existing\nstate-of-the-art methods on the mainstream benchmark OpenLane-V2 (23.9 v.s.\n10.9 in TOP$_{ll}$ and 44.1 v.s. 39.8 in OLS on subset_A. Additionally, our\nproposed geometric distance topology reasoning method can be incorporated into\nwell-trained models without re-training, significantly boost the performance of\nlane topology reasoning. The code is released at\nhttps://github.com/Franpin/TopoLogic.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Yanping Fu",
            "Wenbin Liao",
            "Xinyuan Liu",
            "Hang xu",
            "Yike Ma",
            "Feng Dai",
            "Yucheng Zhang"
        ],
        "published": "2024-05-23T16:15:17Z"
    },
    {
        "title": "AnyLoss: Transforming Classification Metrics into Loss Functions",
        "link": "http://arxiv.org/abs/2405.14745v1",
        "abstract": "Many evaluation metrics can be used to assess the performance of models in\nbinary classification tasks. However, most of them are derived from a confusion\nmatrix in a non-differentiable form, making it very difficult to generate a\ndifferentiable loss function that could directly optimize them. The lack of\nsolutions to bridge this challenge not only hinders our ability to solve\ndifficult tasks, such as imbalanced learning, but also requires the deployment\nof computationally expensive hyperparameter search processes in model\nselection. In this paper, we propose a general-purpose approach that transforms\nany confusion matrix-based metric into a loss function, \\textit{AnyLoss}, that\nis available in optimization processes. To this end, we use an approximation\nfunction to make a confusion matrix represented in a differentiable form, and\nthis approach enables any confusion matrix-based metric to be directly used as\na loss function. The mechanism of the approximation function is provided to\nensure its operability and the differentiability of our loss functions is\nproved by suggesting their derivatives. We conduct extensive experiments under\ndiverse neural networks with many datasets, and we demonstrate their general\navailability to target any confusion matrix-based metrics. Our method,\nespecially, shows outstanding achievements in dealing with imbalanced datasets,\nand its competitive learning speed, compared to multiple baseline models,\nunderscores its efficiency.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Doheon Han",
            "Nuno Moniz",
            "Nitesh V Chawla"
        ],
        "published": "2024-05-23T16:14:16Z"
    },
    {
        "title": "Exploring Prosocial Irrationality for LLM Agents: A Social Cognition\n  View",
        "link": "http://arxiv.org/abs/2405.14744v1",
        "abstract": "Large language models (LLMs) have been shown to face hallucination issues due\nto the data they trained on often containing human bias; whether this is\nreflected in the decision-making process of LLM agents remains under-explored.\nAs LLM Agents are increasingly employed in intricate social environments, a\npressing and natural question emerges: Can LLM Agents leverage hallucinations\nto mirror human cognitive biases, thus exhibiting irrational social\nintelligence? In this paper, we probe the irrational behavior among\ncontemporary LLM agents by melding practical social science experiments with\ntheoretical insights. Specifically, We propose CogMir, an open-ended Multi-LLM\nAgents framework that utilizes hallucination properties to assess and enhance\nLLM Agents' social intelligence through cognitive biases. Experimental results\non CogMir subsets show that LLM Agents and humans exhibit high consistency in\nirrational and prosocial decision-making under uncertain conditions,\nunderscoring the prosociality of LLM Agents as social entities, and\nhighlighting the significance of hallucination properties. Additionally, CogMir\nframework demonstrates its potential as a valuable platform for encouraging\nmore research into the social intelligence of LLM Agents.",
        "subjects": [
            "cs.CY"
        ],
        "authors": [
            "Xuan Liu",
            "Jie Zhang",
            "Song Guo",
            "Haoyang Shang",
            "Chengxu Yang",
            "Quanyan Zhu"
        ],
        "published": "2024-05-23T16:13:33Z"
    },
    {
        "title": "Iterative Causal Segmentation: Filling the Gap between Market\n  Segmentation and Marketing Strategy",
        "link": "http://arxiv.org/abs/2405.14743v1",
        "abstract": "The field of causal Machine Learning (ML) has made significant strides in\nrecent years. Notable breakthroughs include methods such as meta learners\n(arXiv:1706.03461v6) and heterogeneous doubly robust estimators\n(arXiv:2004.14497) introduced in the last five years. Despite these\nadvancements, the field still faces challenges, particularly in managing\ntightly coupled systems where both the causal treatment variable and a\nconfounding covariate must serve as key decision-making indicators. This\nscenario is common in applications of causal ML for marketing, such as\nmarketing segmentation and incremental marketing uplift. In this work, we\npresent our formally proven algorithm, iterative causal segmentation, to\naddress this issue.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Kaihua Ding",
            "Jingsong Cui",
            "Mohammad Soltani",
            "Jing Jin"
        ],
        "published": "2024-05-23T16:12:33Z"
    },
    {
        "title": "HC-GAE: The Hierarchical Cluster-based Graph Auto-Encoder for Graph\n  Representation Learning",
        "link": "http://arxiv.org/abs/2405.14742v1",
        "abstract": "Graph Auto-Encoders (GAEs) are powerful tools for graph representation\nlearning. In this paper, we develop a novel Hierarchical Cluster-based GAE\n(HC-GAE), that can learn effective structural characteristics for graph data\nanalysis. To this end, during the encoding process, we commence by utilizing\nthe hard node assignment to decompose a sample graph into a family of separated\nsubgraphs. We compress each subgraph into a coarsened node, transforming the\noriginal graph into a coarsened graph. On the other hand, during the decoding\nprocess, we adopt the soft node assignment to reconstruct the original graph\nstructure by expanding the coarsened nodes. By hierarchically performing the\nabove compressing procedure during the decoding process as well as the\nexpanding procedure during the decoding process, the proposed HC-GAE can\neffectively extract bidirectionally hierarchical structural features of the\noriginal sample graph. Furthermore, we re-design the loss function that can\nintegrate the information from either the encoder or the decoder. Since the\nassociated graph convolution operation of the proposed HC-GAE is restricted in\neach individual separated subgraph and cannot propagate the node information\nbetween different subgraphs, the proposed HC-GAE can significantly reduce the\nover-smoothing problem arising in the classical convolution-based GAEs. The\nproposed HC-GAE can generate effective representations for either node\nclassification or graph classification, and the experiments demonstrate the\neffectiveness on real-world datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Zhuo Xu",
            "Lu Bai",
            "Lixin Cui",
            "Ming Li",
            "Yue Wang",
            "Edwin R. Hancock"
        ],
        "published": "2024-05-23T16:08:04Z"
    },
    {
        "title": "Bagging Improves Generalization Exponentially",
        "link": "http://arxiv.org/abs/2405.14741v1",
        "abstract": "Bagging is a popular ensemble technique to improve the accuracy of machine\nlearning models. It hinges on the well-established rationale that, by\nrepeatedly retraining on resampled data, the aggregated model exhibits lower\nvariance and hence higher stability, especially for discontinuous base\nlearners. In this paper, we provide a new perspective on bagging: By suitably\naggregating the base learners at the parametrization instead of the output\nlevel, bagging improves generalization performances exponentially, a strength\nthat is significantly more powerful than variance reduction. More precisely, we\nshow that for general stochastic optimization problems that suffer from slowly\n(i.e., polynomially) decaying generalization errors, bagging can effectively\nreduce these errors to an exponential decay. Moreover, this power of bagging is\nagnostic to the solution schemes, including common empirical risk minimization,\ndistributionally robust optimization, and various regularizations. We\ndemonstrate how bagging can substantially improve generalization performances\nin a range of examples involving heavy-tailed data that suffer from\nintrinsically slow rates.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "authors": [
            "Huaqian Jie",
            "Donghao Ying",
            "Henry Lam",
            "Wotao Yin"
        ],
        "published": "2024-05-23T16:05:10Z"
    },
    {
        "title": "A Duty-Cycle-Efficient Synchronization Protocol for Slotted-Aloha in\n  LoRaWAN",
        "link": "http://arxiv.org/abs/2405.14740v1",
        "abstract": "In the current context of massive IoT, the Pure-Aloha scheme used in LoRaWAN\nis reaching its limit, and Slotted-Aloha is being considered as an alternative,\nas it offers twice Pure-Aloha's packet success rate. It however requires\nsynchronization across the nodes. In this paper, we propose a new slot\nstructure adapted to devices with low quality clock, and a duty-cycle efficient\nsynchronization protocol for LoRaWAN class A devices with the lowest overhead\nto date. We discuss the conditions of its integration into LoRaWAN. The\nexperimental results confirm that it succeeds in tracking each device's\nsynchronization state, identifying the exact moment they desynchronize and\nresynchronizing them. The proposed protocol is also proven to be more\nduty-cycle efficient than existing fixed-rate synchronization solutions.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Amavi Dossa",
            "El Mehdi Amhoud"
        ],
        "published": "2024-05-23T16:04:50Z"
    },
    {
        "title": "FLoRA: Low-Rank Core Space for N-dimension",
        "link": "http://arxiv.org/abs/2405.14739v1",
        "abstract": "Adapting pre-trained foundation models for various downstream tasks has been\nprevalent in artificial intelligence. Due to the vast number of tasks and high\ncosts, adjusting all parameters becomes unfeasible. To mitigate this, several\nfine-tuning techniques have been developed to update the pre-trained model\nweights in a more resource-efficient manner, such as through low-rank\nadjustments. Yet, almost all of these methods focus on linear weights,\nneglecting the intricacies of parameter spaces in higher dimensions like 4D.\nAlternatively, some methods can be adapted for high-dimensional parameter space\nby compressing changes in the original space into two dimensions and then\nemploying low-rank matrix decomposition. However, these approaches destructs\nthe structural integrity of the involved high-dimensional spaces. To tackle the\ndiversity of dimensional spaces across different foundation models and provide\na more precise representation of the changes within these spaces, this paper\nintroduces a generalized parameter-efficient fine-tuning framework, FLoRA,\ndesigned for various dimensional parameter space. Specifically, utilizing\nTucker decomposition, FLoRA asserts that changes in each dimensional parameter\nspace are based on a low-rank core space which maintains the consistent\ntopological structure with the original space. It then models the changes\nthrough this core space alongside corresponding weights to reconstruct\nalterations in the original space. FLoRA effectively preserves the structural\nintegrity of the change of original N-dimensional parameter space, meanwhile\ndecomposes it via low-rank tensor decomposition. Extensive experiments on\ncomputer vision, natural language processing and multi-modal tasks validate\nFLoRA's effectiveness. Codes are available at\nhttps://github.com/SJTU-DeepVisionLab/FLoRA.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Chongjie Si",
            "Xuehui Wang",
            "Xue Yang",
            "Zhengqin Xu",
            "Qingyun Li",
            "Jifeng Dai",
            "Yu Qiao",
            "Xiaokang Yang",
            "Wei Shen"
        ],
        "published": "2024-05-23T16:04:42Z"
    },
    {
        "title": "CLIPScope: Enhancing Zero-Shot OOD Detection with Bayesian Scoring",
        "link": "http://arxiv.org/abs/2405.14737v1",
        "abstract": "Detection of out-of-distribution (OOD) samples is crucial for safe real-world\ndeployment of machine learning models. Recent advances in vision language\nfoundation models have made them capable of detecting OOD samples without\nrequiring in-distribution (ID) images. However, these zero-shot methods often\nunderperform as they do not adequately consider ID class likelihoods in their\ndetection confidence scoring. Hence, we introduce CLIPScope, a zero-shot OOD\ndetection approach that normalizes the confidence score of a sample by class\nlikelihoods, akin to a Bayesian posterior update. Furthermore, CLIPScope\nincorporates a novel strategy to mine OOD classes from a large lexical\ndatabase. It selects class labels that are farthest and nearest to ID classes\nin terms of CLIP embedding distance to maximize coverage of OOD samples. We\nconduct extensive ablation studies and empirical evaluations, demonstrating\nstate of the art performance of CLIPScope across various OOD detection\nbenchmarks.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hao Fu",
            "Naman Patel",
            "Prashanth Krishnamurthy",
            "Farshad Khorrami"
        ],
        "published": "2024-05-23T16:03:55Z"
    },
    {
        "title": "GIFT: Unlocking Full Potential of Labels in Distilled Dataset at\n  Near-zero Cost",
        "link": "http://arxiv.org/abs/2405.14736v1",
        "abstract": "Recent advancements in dataset distillation have demonstrated the significant\nbenefits of employing soft labels generated by pre-trained teacher models. In\nthis paper, we introduce a novel perspective by emphasizing the full\nutilization of labels. We first conduct a comprehensive comparison of various\nloss functions for soft label utilization in dataset distillation, revealing\nthat the model trained on the synthetic dataset exhibits high sensitivity to\nthe choice of loss function for soft label utilization. This finding highlights\nthe necessity of a universal loss function for training models on synthetic\ndatasets. Building on these insights, we introduce an extremely simple yet\nsurprisingly effective plug-and-play approach, GIFT, which encompasses soft\nlabel refinement and a cosine similarity-based loss function to efficiently\nleverage full label information. Extensive experiments demonstrate that GIFT\nconsistently enhances the state-of-the-art dataset distillation methods across\nvarious scales datasets without incurring additional computational costs. For\ninstance, on ImageNet-1K with IPC = 10, GIFT improves the SOTA method RDED by\n3.9% and 1.8% on ConvNet and ResNet-18, respectively. Code:\nhttps://github.com/LINs-lab/GIFT.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Xinyi Shang",
            "Peng Sun",
            "Tao Lin"
        ],
        "published": "2024-05-23T16:02:30Z"
    },
    {
        "title": "SimPO: Simple Preference Optimization with a Reference-Free Reward",
        "link": "http://arxiv.org/abs/2405.14734v1",
        "abstract": "Direct Preference Optimization (DPO) is a widely used offline preference\noptimization algorithm that reparameterizes reward functions in reinforcement\nlearning from human feedback (RLHF) to enhance simplicity and training\nstability. In this work, we propose SimPO, a simpler yet more effective\napproach. The effectiveness of SimPO is attributed to a key design: using the\naverage log probability of a sequence as the implicit reward. This reward\nformulation better aligns with model generation and eliminates the need for a\nreference model, making it more compute and memory efficient. Additionally, we\nintroduce a target reward margin to the Bradley-Terry objective to encourage a\nlarger margin between the winning and losing responses, further enhancing the\nalgorithm's performance. We compare SimPO to DPO and its latest variants across\nvarious state-of-the-art training setups, including both base and\ninstruction-tuned models like Mistral and Llama3. We evaluated on extensive\ninstruction-following benchmarks, including AlpacaEval 2, MT-Bench, and the\nrecent challenging Arena-Hard benchmark. Our results demonstrate that SimPO\nconsistently and significantly outperforms existing approaches without\nsubstantially increasing response length. Specifically, SimPO outperforms DPO\nby up to 6.4 points on AlpacaEval 2 and by up to 7.5 points on Arena-Hard. Our\ntop-performing model, built on Llama3-8B-Instruct, achieves a remarkable 44.7\nlength-controlled win rate on AlpacaEval 2 -- surpassing Claude 3 Opus on the\nleaderboard, and a 33.8 win rate on Arena-Hard -- making it the strongest 8B\nopen-source model.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Yu Meng",
            "Mengzhou Xia",
            "Danqi Chen"
        ],
        "published": "2024-05-23T16:01:46Z"
    },
    {
        "title": "CoPeD-Advancing Multi-Robot Collaborative Perception: A Comprehensive\n  Dataset in Real-World Environments",
        "link": "http://arxiv.org/abs/2405.14731v1",
        "abstract": "In the past decade, although single-robot perception has made significant\nadvancements, the exploration of multi-robot collaborative perception remains\nlargely unexplored. This involves fusing compressed, intermittent, limited,\nheterogeneous, and asynchronous environmental information across multiple\nrobots to enhance overall perception, despite challenges like sensor noise,\nocclusions, and sensor failures. One major hurdle has been the lack of\nreal-world datasets. This paper presents a pioneering and comprehensive\nreal-world multi-robot collaborative perception dataset to boost research in\nthis area. Our dataset leverages the untapped potential of air-ground robot\ncollaboration featuring distinct spatial viewpoints, complementary robot\nmobilities, coverage ranges, and sensor modalities. It features raw sensor\ninputs, pose estimation, and optional high-level perception annotation, thus\naccommodating diverse research interests. Compared to existing datasets\npredominantly designed for Simultaneous Localization and Mapping (SLAM), our\nsetup ensures a diverse range and adequate overlap of sensor views to\nfacilitate the study of multi-robot collaborative perception algorithms. We\ndemonstrate the value of this dataset qualitatively through multiple\ncollaborative perception tasks. We believe this work will unlock the potential\nresearch of high-level scene understanding through multi-modal collaborative\nperception in multi-robot settings.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "authors": [
            "Yang Zhou",
            "Long Quang",
            "Carlos Nieto-Granda",
            "Giuseppe Loianno"
        ],
        "published": "2024-05-23T15:59:48Z"
    },
    {
        "title": "Embedding Compression for Efficient Re-Identification",
        "link": "http://arxiv.org/abs/2405.14730v1",
        "abstract": "Real world re-identfication (ReID) algorithms aim to map new observations of\nan object to previously recorded instances. These systems are often constrained\nby quantity and size of the stored embeddings. To combat this scaling problem,\nwe attempt to shrink the size of these vectors by using a variety of\ncompression techniques. In this paper, we benchmark quantization-aware-training\nalong with three different dimension reduction methods: iterative structured\npruning, slicing the embeddings at initialize, and using low rank embeddings.\nWe find that ReID embeddings can be compressed by up to 96x with minimal drop\nin performance. This implies that modern re-identification paradigms do not\nfully leverage the high dimensional latent space, opening up further research\nto increase the capabilities of these systems.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Luke McDermott"
        ],
        "published": "2024-05-23T15:57:11Z"
    },
    {
        "title": "Intervention and Conditioning in Causal Bayesian Networks",
        "link": "http://arxiv.org/abs/2405.14728v1",
        "abstract": "Causal models are crucial for understanding complex systems and identifying\ncausal relationships among variables. Even though causal models are extremely\npopular, conditional probability calculation of formulas involving\ninterventions pose significant challenges. In case of Causal Bayesian Networks\n(CBNs), Pearl assumes autonomy of mechanisms that determine interventions to\ncalculate a range of probabilities. We show that by making simple yet often\nrealistic independence assumptions, it is possible to uniquely estimate the\nprobability of an interventional formula (including the well-studied notions of\nprobability of sufficiency and necessity). We discuss when these assumptions\nare appropriate. Importantly, in many cases of interest, when the assumptions\nare appropriate, these probability estimates can be evaluated using\nobservational data, which carries immense significance in scenarios where\nconducting experiments is impractical or unfeasible.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Sainyam Galhotra",
            "Joseph Y. Halpern"
        ],
        "published": "2024-05-23T15:55:38Z"
    },
    {
        "title": "Distilling Vision-Language Pretraining for Efficient Cross-Modal\n  Retrieval",
        "link": "http://arxiv.org/abs/2405.14726v1",
        "abstract": "``Learning to hash'' is a practical solution for efficient retrieval,\noffering fast search speed and low storage cost. It is widely applied in\nvarious applications, such as image-text cross-modal search. In this paper, we\nexplore the potential of enhancing the performance of learning to hash with the\nproliferation of powerful large pre-trained models, such as Vision-Language\nPre-training (VLP) models. We introduce a novel method named Distillation for\nCross-Modal Quantization (DCMQ), which leverages the rich semantic knowledge of\nVLP models to improve hash representation learning. Specifically, we use the\nVLP as a `teacher' to distill knowledge into a `student' hashing model equipped\nwith codebooks. This process involves the replacement of supervised labels,\nwhich are composed of multi-hot vectors and lack semantics, with the rich\nsemantics of VLP. In the end, we apply a transformation termed Normalization\nwith Paired Consistency (NPC) to achieve a discriminative target for\ndistillation. Further, we introduce a new quantization method, Product\nQuantization with Gumbel (PQG) that promotes balanced codebook learning,\nthereby improving the retrieval performance. Extensive benchmark testing\ndemonstrates that DCMQ consistently outperforms existing supervised cross-modal\nhashing approaches, showcasing its significant potential.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Young Kyun Jang",
            "Donghyun Kim",
            "Ser-nam Lim"
        ],
        "published": "2024-05-23T15:54:59Z"
    },
    {
        "title": "A Systematic and Formal Study of the Impact of Local Differential\n  Privacy on Fairness: Preliminary Results",
        "link": "http://arxiv.org/abs/2405.14725v1",
        "abstract": "Machine learning (ML) algorithms rely primarily on the availability of\ntraining data, and, depending on the domain, these data may include sensitive\ninformation about the data providers, thus leading to significant privacy\nissues. Differential privacy (DP) is the predominant solution for\nprivacy-preserving ML, and the local model of DP is the preferred choice when\nthe server or the data collector are not trusted. Recent experimental studies\nhave shown that local DP can impact ML prediction for different subgroups of\nindividuals, thus affecting fair decision-making. However, the results are\nconflicting in the sense that some studies show a positive impact of privacy on\nfairness while others show a negative one. In this work, we conduct a\nsystematic and formal study of the effect of local DP on fairness.\nSpecifically, we perform a quantitative study of how the fairness of the\ndecisions made by the ML model changes under local DP for different levels of\nprivacy and data distributions. In particular, we provide bounds in terms of\nthe joint distributions and the privacy level, delimiting the extent to which\nlocal DP can impact the fairness of the model. We characterize the cases in\nwhich privacy reduces discrimination and those with the opposite effect. We\nvalidate our theoretical findings on synthetic and real-world datasets. Our\nresults are preliminary in the sense that, for now, we study only the case of\none sensitive attribute, and only statistical disparity, conditional\nstatistical disparity, and equal opportunity difference.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "authors": [
            "Karima Makhlouf",
            "Tamara Stefanovic",
            "Heber H. Arcolezi",
            "Catuscia Palamidessi"
        ],
        "published": "2024-05-23T15:54:03Z"
    },
    {
        "title": "Learning-Based Intermittent CSI Estimation with Adaptive Intervals in\n  Integrated Sensing and Communication Systems",
        "link": "http://arxiv.org/abs/2405.14724v1",
        "abstract": "Due to the distinct objectives and multipath utilization mechanisms between\nthe communication module and radar module, the system design of integrated\nsensing and communication (ISAC) necessitates two types of channel state\ninformation (CSI), i.e., communication CSI representing the whole channel gain\nand phase shifts, and radar CSI exclusively focused on target mobility and\nposition information. However, current ISAC systems apply an identical\nmechanism to estimate both types of CSI at the same predetermined estimation\ninterval, leading to significant overhead and compromised performances.\nTherefore, this paper proposes an intermittent communication and radar CSI\nestimation scheme with adaptive intervals for individual users/targets, where\nboth types of CSI can be predicted using channel temporal correlations for cost\nreduction or re-estimated via training signal transmission for improved\nestimation accuracy. Specifically, we jointly optimize the binary CSI\nre-estimation/prediction decisions and transmit beamforming matrices for\nindividual users/targets to maximize communication transmission rates and\nminimize radar tracking errors and costs in a multiple-input single-output\n(MISO) ISAC system. Unfortunately, this problem has causality issues because it\nrequires comparing system performances under re-estimated CSI and predicted CSI\nduring the optimization. Additionally, the binary decision makes the joint\ndesign a mixed integer nonlinear programming (MINLP) problem, resulting in high\ncomplexity when using conventional optimization algorithms. Therefore, we\npropose a deep reinforcement online learning (DROL) framework that first\nimplements an online deep neural network (DNN) to learn the binary CSI updating\ndecisions from the experiences. Given the learned decisions, we propose an\nefficient algorithm to solve the remaining beamforming design problem\nefficiently.",
        "subjects": [
            "eess.SP",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Jie Chen",
            "Xianbin Wang"
        ],
        "published": "2024-05-23T15:53:55Z"
    },
    {
        "title": "CAPE: Context-Adaptive Positional Encoding for Length Extrapolation",
        "link": "http://arxiv.org/abs/2405.14722v1",
        "abstract": "Positional encoding plays a crucial role in transformers, significantly\nimpacting model performance and length generalization. Prior research has\nintroduced absolute positional encoding (APE) and relative positional encoding\n(RPE) to distinguish token positions in given sequences. However, both APE and\nRPE remain fixed after model training regardless of input data, limiting their\nadaptability and flexibility. Hence, we expect that the desired positional\nencoding should be context-adaptive and can be dynamically adjusted with the\ngiven attention. In this paper, we propose a Context-Adaptive Positional\nEncoding (CAPE) method, which dynamically and semantically adjusts based on\ninput context and learned fixed priors. Experimental validation on real-world\ndatasets (Arxiv, Books3, and CHE) demonstrates that CAPE enhances model\nperformances in terms of trained length and length generalization, where the\nimprovements are statistically significant. The model visualization suggests\nthat our model can keep both local and anti-local information. Finally, we\nsuccessfully train the model on sequence length 128 and achieve better\nperformance at evaluation sequence length 8192, compared with other static\npositional encoding methods, revealing the benefit of the adaptive positional\nencoding method.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Chuanyang Zheng",
            "Yihang Gao",
            "Han Shi",
            "Minbin Huang",
            "Jingyao Li",
            "Jing Xiong",
            "Xiaozhe Ren",
            "Michael Ng",
            "Xin Jiang",
            "Zhenguo Li",
            "Yu Li"
        ],
        "published": "2024-05-23T15:51:24Z"
    },
    {
        "title": "Convolutional Neural Network Model Observers Discount Signal-like\n  Anatomical Structures During Search in Virtual Digital Breast Tomosynthesis\n  Phantoms",
        "link": "http://arxiv.org/abs/2405.14720v1",
        "abstract": "Model observers are computational tools to evaluate and optimize task-based\nmedical image quality. Linear model observers, such as the Channelized\nHotelling Observer (CHO), predict human accuracy in detection tasks with a few\npossible signal locations in clinical phantoms or real anatomic backgrounds. In\nrecent years, Convolutional Neural Networks (CNNs) have been proposed as a new\ntype of model observer. What is not well understood is what CNNs add over the\nmore common linear model observer approaches. We compare the CHO and CNN\ndetection accuracy to the radiologist's accuracy in searching for two types of\nsignals (mass and microcalcification) embedded in 2D/3D breast tomosynthesis\nphantoms (DBT). We show that the CHO model's accuracy is comparable to the\nCNN's performance for a location-known-exactly detection task. However, for the\nsearch task with 2D/3D DBT phantoms, the CHO's detection accuracy was\nsignificantly lower than the CNN accuracy. A comparison to the radiologist's\naccuracy showed that the CNN but not the CHO could match or exceed the\nradiologist's accuracy in the 2D microcalcification and 3D mass search\nconditions. An analysis of the eye position showed that radiologists fixated\nmore often and longer at the locations corresponding to CNN false positives.\nMost CHO false positives were the phantom's normal anatomy and were not fixated\nby radiologists. In conclusion, we show that CNNs can be used as an\nanthropomorphic model observer for the search task for which traditional linear\nmodel observers fail due to their inability to discount false positives arising\nfrom the anatomical backgrounds.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Aditya Jonnalagadda",
            "Bruno B. Barufaldi",
            "Andrew D. A. Maidment",
            "Susan P. Weinstein",
            "Craig K. Abbey",
            "Miguel P. Eckstein"
        ],
        "published": "2024-05-23T15:49:42Z"
    },
    {
        "title": "Decision-Focused Forecasting: Decision Losses for Multistage\n  Optimisation",
        "link": "http://arxiv.org/abs/2405.14719v1",
        "abstract": "Decision-focused learning has emerged as a promising approach for decision\nmaking under uncertainty by training the upstream predictive aspect of the\npipeline with respect to the quality of the downstream decisions. Most existing\nwork has focused on single stage problems. Many real-world decision problems\nare more appropriately modelled using multistage optimisation as contextual\ninformation such as prices or demand is revealed over time and decisions now\nhave a bearing on future decisions. We propose decision-focused forecasting, a\nmultiple-implicitlayer model which in its training accounts for the\nintertemporal decision effects of forecasts using differentiable optimisation.\nThe recursive model reflects a fully differentiable multistage optimisation\napproach. We present an analysis of the gradients produced by this model\nshowing the adjustments made to account for the state-path caused by\nforecasting. We demonstrate an application of the model to an energy storage\narbitrage task and report that our model outperforms existing approaches.",
        "subjects": [
            "math.OC",
            "cs.AI",
            "cs.LG",
            "I.2.8"
        ],
        "authors": [
            "Egon Peršak",
            "Miguel F. Anjos"
        ],
        "published": "2024-05-23T15:48:46Z"
    },
    {
        "title": "StyleX: A Trainable Metric for X-ray Style Distances",
        "link": "http://arxiv.org/abs/2405.14718v1",
        "abstract": "The progression of X-ray technology introduces diverse image styles that need\nto be adapted to the preferences of radiologists. To support this task, we\nintroduce a novel deep learning-based metric that quantifies style differences\nof non-matching image pairs. At the heart of our metric is an encoder capable\nof generating X-ray image style representations. This encoder is trained\nwithout any explicit knowledge of style distances by exploiting Simple Siamese\nlearning. During inference, the style representations produced by the encoder\nare used to calculate a distance metric for non-matching image pairs. Our\nexperiments investigate the proposed concept for a disclosed reproducible and a\nproprietary image processing pipeline along two dimensions: First, we use a\nt-distributed stochastic neighbor embedding (t-SNE) analysis to illustrate that\nthe encoder outputs provide meaningful and discriminative style\nrepresentations. Second, the proposed metric calculated from the encoder\noutputs is shown to quantify style distances for non-matching pairs in good\nalignment with the human perception. These results confirm that our proposed\nmethod is a promising technique to quantify style differences, which can be\nused for guided style selection as well as automatic optimization of image\npipeline parameters.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Dominik Eckert",
            "Christopher Syben",
            "Christian Hümmer",
            "Ludwig Ritschl",
            "Steffen Kappler",
            "Sebastian Stober"
        ],
        "published": "2024-05-23T15:48:38Z"
    },
    {
        "title": "HTN-Based Tutors: A New Intelligent Tutoring Framework Based on\n  Hierarchical Task Networks",
        "link": "http://dx.doi.org/10.1145/3657604",
        "abstract": "Intelligent tutors have shown success in delivering a personalized and\nadaptive learning experience. However, there exist challenges regarding the\ngranularity of knowledge in existing frameworks and the resulting instructions\nthey can provide. To address these issues, we propose HTN-based tutors, a new\nintelligent tutoring framework that represents expert models using Hierarchical\nTask Networks (HTNs). Like other tutoring frameworks, it allows flexible\nencoding of different problem-solving strategies while providing the additional\nbenefit of a hierarchical knowledge organization. We leverage the latter to\ncreate tutors that can adapt the granularity of their scaffolding. This\norganization also aligns well with the compositional nature of skills.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "authors": [
            "Momin N. Siddiqui",
            "Adit Gupta",
            "Jennifer M. Reddig",
            "Christopher J. MacLellan"
        ],
        "published": "2024-05-23T15:46:42Z"
    },
    {
        "title": "Towards Cross-modal Backward-compatible Representation Learning for\n  Vision-Language Models",
        "link": "http://arxiv.org/abs/2405.14715v1",
        "abstract": "Modern retrieval systems often struggle with upgrading to new and more\npowerful models due to the incompatibility of embeddings between the old and\nnew models. This necessitates a costly process known as backfilling, which\ninvolves re-computing the embeddings for a large number of data samples. In\nvision, Backward-compatible Training (BT) has been proposed to ensure that the\nnew model aligns with the old model's embeddings. This paper extends the\nconcept of vision-only BT to the field of cross-modal retrieval, marking the\nfirst attempt to address Cross-modal BT (XBT). Our goal is to achieve\nbackward-compatibility between Vision-Language Pretraining (VLP) models, such\nas CLIP, for the cross-modal retrieval task. To address XBT challenges, we\npropose an efficient solution: a projection module that maps the new model's\nembeddings to those of the old model. This module, pretrained solely with text\ndata, significantly reduces the number of image-text pairs required for XBT\nlearning, and, once it is pretrained, it avoids using the old model during\ntraining. Furthermore, we utilize parameter-efficient training strategies that\nimprove efficiency and preserve the off-the-shelf new model's knowledge by\navoiding any modifications. Experimental results on cross-modal retrieval\ndatasets demonstrate the effectiveness of XBT and its potential to enable\nbackfill-free upgrades when a new VLP model emerges.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Young Kyun Jang",
            "Ser-nam Lim"
        ],
        "published": "2024-05-23T15:46:35Z"
    },
    {
        "title": "Defining error accumulation in ML atmospheric simulators",
        "link": "http://arxiv.org/abs/2405.14714v1",
        "abstract": "Machine learning (ML) has recently shown significant promise in modelling\natmospheric systems, such as the weather. Many of these ML models are\nautoregressive, and error accumulation in their forecasts is a key problem.\nHowever, there is no clear definition of what `error accumulation' actually\nentails. In this paper, we propose a definition and an associated metric to\nmeasure it. Our definition distinguishes between errors which are due to model\ndeficiencies, which we may hope to fix, and those due to the intrinsic\nproperties of atmospheric systems (chaos, unobserved variables), which are not\nfixable. We illustrate the usefulness of this definition by proposing a simple\nregularization loss penalty inspired by it. This approach shows performance\nimprovements (according to RMSE and spread/skill) in a selection of atmospheric\nsystems, including the real-world weather prediction task.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Raghul Parthipan",
            "Mohit Anand",
            "Hannah M. Christensen",
            "J. Scott Hosking",
            "Damon J. Wischik"
        ],
        "published": "2024-05-23T15:46:34Z"
    },
    {
        "title": "Towards Educator-Driven Tutor Authoring: Generative AI Approaches for\n  Creating Intelligent Tutor Interfaces",
        "link": "http://dx.doi.org/10.1145/3657604.3664694",
        "abstract": "Intelligent Tutoring Systems (ITSs) have shown great potential in delivering\npersonalized and adaptive education, but their widespread adoption has been\nhindered by the need for specialized programming and design skills. Existing\napproaches overcome the programming limitations with no-code authoring through\ndrag and drop, however they assume that educators possess the necessary skills\nto design effective and engaging tutor interfaces. To address this assumption\nwe introduce generative AI capabilities to assist educators in creating tutor\ninterfaces that meet their needs while adhering to design principles. Our\napproach leverages Large Language Models (LLMs) and prompt engineering to\ngenerate tutor layout and contents based on high-level requirements provided by\neducators as inputs. However, to allow them to actively participate in the\ndesign process, rather than relying entirely on AI-generated solutions, we\nallow generation both at the entire interface level and at the individual\ncomponent level. The former provides educators with a complete interface that\ncan be refined using direct manipulation, while the latter offers the ability\nto create specific elements to be added to the tutor interface. A small-scale\ncomparison shows the potential of our approach to enhance the efficiency of\ntutor interface design. Moving forward, we raise critical questions for\nassisting educators with generative AI capabilities to create personalized,\neffective, and engaging tutors, ultimately enhancing their adoption.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Tommaso Calo",
            "Christopher J. MacLellan"
        ],
        "published": "2024-05-23T15:46:10Z"
    },
    {
        "title": "Evolution and learning in differentiable robots",
        "link": "http://arxiv.org/abs/2405.14712v1",
        "abstract": "The automatic design of robots has existed for 30 years but has been\nconstricted by serial non-differentiable design evaluations, premature\nconvergence to simple bodies or clumsy behaviors, and a lack of sim2real\ntransfer to physical machines. Thus, here we employ massively-parallel\ndifferentiable simulations to rapidly and simultaneously optimize individual\nneural control of behavior across a large population of candidate body plans\nand return a fitness score for each design based on the performance of its\nfully optimized behavior. Non-differentiable changes to the mechanical\nstructure of each robot in the population -- mutations that rearrange, combine,\nadd, or remove body parts -- were applied by a genetic algorithm in an outer\nloop of search, generating a continuous flow of novel morphologies with\nhighly-coordinated and graceful behaviors honed by gradient descent. This\nenabled the exploration of several orders-of-magnitude more designs than all\nprevious methods, despite the fact that robots here have the potential to be\nmuch more complex, in terms of number of independent motors, than those in\nprior studies. We found that evolution reliably produces ``increasingly\ndifferentiable'' robots: body plans that smooth the loss landscape in which\nlearning operates and thereby provide better training paths toward performant\nbehaviors. Finally, one of the highly differentiable morphologies discovered in\nsimulation was realized as a physical robot and shown to retain its optimized\nbehavior. This provides a cyberphysical platform to investigate the\nrelationship between evolution and learning in biological systems and broadens\nour understanding of how a robot's physical structure can influence the ability\nto train policies for it. Videos and code at\nhttps://sites.google.com/view/eldir.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "authors": [
            "Luke Strgar",
            "David Matthews",
            "Tyler Hummer",
            "Sam Kriegman"
        ],
        "published": "2024-05-23T15:45:43Z"
    },
    {
        "title": "OpFlowTalker: Realistic and Natural Talking Face Generation via Optical\n  Flow Guidance",
        "link": "http://arxiv.org/abs/2405.14709v1",
        "abstract": "Creating realistic, natural, and lip-readable talking face videos remains a\nformidable challenge. Previous research primarily concentrated on generating\nand aligning single-frame images while overlooking the smoothness of\nframe-to-frame transitions and temporal dependencies. This often compromised\nvisual quality and effects in practical settings, particularly when handling\ncomplex facial data and audio content, which frequently led to semantically\nincongruent visual illusions. Specifically, synthesized videos commonly\nfeatured disorganized lip movements, making them difficult to understand and\nrecognize. To overcome these limitations, this paper introduces the application\nof optical flow to guide facial image generation, enhancing inter-frame\ncontinuity and semantic consistency. We propose \"OpFlowTalker\", a novel\napproach that utilizes predicted optical flow changes from audio inputs rather\nthan direct image predictions. This method smooths image transitions and aligns\nchanges with semantic content. Moreover, it employs a sequence fusion technique\nto replace the independent generation of single frames, thus preserving\ncontextual information and maintaining temporal coherence. We also developed an\noptical flow synchronization module that regulates both full-face and lip\nmovements, optimizing visual synthesis by balancing regional dynamics.\nFurthermore, we introduce a Visual Text Consistency Score (VTCS) that\naccurately measures lip-readability in synthesized videos. Extensive empirical\nevidence validates the effectiveness of our approach.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "authors": [
            "Shuheng Ge",
            "Haoyu Xing",
            "Li Zhang",
            "Xiangqian Wu"
        ],
        "published": "2024-05-23T15:42:34Z"
    },
    {
        "title": "Artificial Intelligence (AI) in Legal Data Mining",
        "link": "http://arxiv.org/abs/2405.14707v1",
        "abstract": "Despite the availability of vast amounts of data, legal data is often\nunstructured, making it difficult even for law practitioners to ingest and\ncomprehend the same. It is important to organise the legal information in a way\nthat is useful for practitioners and downstream automation tasks. The word\nontology was used by Greek philosophers to discuss concepts of existence,\nbeing, becoming and reality. Today, scientists use this term to describe the\nrelation between concepts, data, and entities. A great example for a working\nontology was developed by Dhani and Bhatt. This ontology deals with Indian\ncourt cases on intellectual property rights (IPR) The future of legal\nontologies is likely to be handled by computer experts and legal experts alike.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Aniket Deroy",
            "Naksatra Kumar Bailung",
            "Kripabandhu Ghosh",
            "Saptarshi Ghosh",
            "Abhijnan Chakraborty"
        ],
        "published": "2024-05-23T15:41:35Z"
    },
    {
        "title": "Learning Multi-dimensional Human Preference for Text-to-Image Generation",
        "link": "http://arxiv.org/abs/2405.14705v1",
        "abstract": "Current metrics for text-to-image models typically rely on statistical\nmetrics which inadequately represent the real preference of humans. Although\nrecent work attempts to learn these preferences via human annotated images,\nthey reduce the rich tapestry of human preference to a single overall score.\nHowever, the preference results vary when humans evaluate images with different\naspects. Therefore, to learn the multi-dimensional human preferences, we\npropose the Multi-dimensional Preference Score (MPS), the first\nmulti-dimensional preference scoring model for the evaluation of text-to-image\nmodels. The MPS introduces the preference condition module upon CLIP model to\nlearn these diverse preferences. It is trained based on our Multi-dimensional\nHuman Preference (MHP) Dataset, which comprises 918,315 human preference\nchoices across four dimensions (i.e., aesthetics, semantic alignment, detail\nquality and overall assessment) on 607,541 images. The images are generated by\na wide range of latest text-to-image models. The MPS outperforms existing\nscoring methods across 3 datasets in 4 dimensions, enabling it a promising\nmetric for evaluating and improving text-to-image generation.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Sixian Zhang",
            "Bohan Wang",
            "Junqiang Wu",
            "Yan Li",
            "Tingting Gao",
            "Di Zhang",
            "Zhongyuan Wang"
        ],
        "published": "2024-05-23T15:39:43Z"
    },
    {
        "title": "G3: An Effective and Adaptive Framework for Worldwide Geolocalization\n  Using Large Multi-Modality Models",
        "link": "http://arxiv.org/abs/2405.14702v1",
        "abstract": "Worldwide geolocalization aims to locate the precise location at the\ncoordinate level of photos taken anywhere on the Earth. It is very challenging\ndue to 1) the difficulty of capturing subtle location-aware visual semantics,\nand 2) the heterogeneous geographical distribution of image data. As a result,\nexisting studies have clear limitations when scaled to a worldwide context.\nThey may easily confuse distant images with similar visual contents, or cannot\nadapt to various locations worldwide with different amounts of relevant data.\nTo resolve these limitations, we propose G3, a novel framework based on\nRetrieval-Augmented Generation (RAG). In particular, G3 consists of three\nsteps, i.e., Geo-alignment, Geo-diversification, and Geo-verification to\noptimize both retrieval and generation phases of worldwide geolocalization.\nDuring Geo-alignment, our solution jointly learns expressive multi-modal\nrepresentations for images, GPS and textual descriptions, which allows us to\ncapture location-aware semantics for retrieving nearby images for a given\nquery. During Geo-diversification, we leverage a prompt ensembling method that\nis robust to inconsistent retrieval performance for different image queries.\nFinally, we combine both retrieved and generated GPS candidates in\nGeo-verification for location prediction. Experiments on two well-established\ndatasets IM2GPS3k and YFCC4k verify the superiority of G3 compared to other\nstate-of-the-art methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Pengyue Jia",
            "Yiding Liu",
            "Xiaopeng Li",
            "Xiangyu Zhao",
            "Yuhao Wang",
            "Yantong Du",
            "Xiao Han",
            "Xuetao Wei",
            "Shuaiqiang Wang",
            "Dawei Yin"
        ],
        "published": "2024-05-23T15:37:06Z"
    },
    {
        "title": "High Fidelity Scene Text Synthesis",
        "link": "http://arxiv.org/abs/2405.14701v1",
        "abstract": "Scene text synthesis involves rendering specified texts onto arbitrary\nimages. Current methods typically formulate this task in an end-to-end manner\nbut lack effective character-level guidance during training. Besides, their\ntext encoders, pre-trained on a single font type, struggle to adapt to the\ndiverse font styles encountered in practical applications. Consequently, these\nmethods suffer from character distortion, repetition, and absence, particularly\nin polystylistic scenarios. To this end, this paper proposes DreamText for\nhigh-fidelity scene text synthesis. Our key idea is to reconstruct the\ndiffusion training process, introducing more refined guidance tailored to this\ntask, to expose and rectify the model's attention at the character level and\nstrengthen its learning of text regions. This transformation poses a hybrid\noptimization challenge, involving both discrete and continuous variables. To\neffectively tackle this challenge, we employ a heuristic alternate optimization\nstrategy. Meanwhile, we jointly train the text encoder and generator to\ncomprehensively learn and utilize the diverse font present in the training\ndataset. This joint training is seamlessly integrated into the alternate\noptimization process, fostering a synergistic relationship between learning\ncharacter embedding and re-estimating character attention. Specifically, in\neach step, we first encode potential character-generated position information\nfrom cross-attention maps into latent character masks. These masks are then\nutilized to update the representation of specific characters in the current\nstep, which, in turn, enables the generator to correct the character's\nattention in the subsequent steps. Both qualitative and quantitative results\ndemonstrate the superiority of our method to the state of the art.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Yibin Wang",
            "Weizhong Zhang",
            "Jianwei Zheng",
            "Cheng Jin"
        ],
        "published": "2024-05-23T15:35:48Z"
    },
    {
        "title": "Sparse-Tuning: Adapting Vision Transformers with Efficient Fine-tuning\n  and Inference",
        "link": "http://arxiv.org/abs/2405.14700v1",
        "abstract": "Parameter-efficient fine-tuning (PEFT) has emerged as a popular approach for\nadapting pre-trained Vision Transformer (ViT) models to downstream\napplications. While current PEFT methods achieve parameter efficiency, they\noverlook GPU memory and time efficiency during both fine-tuning and inference,\ndue to the repeated computation of redundant tokens in the ViT architecture.\nThis falls short of practical requirements for downstream task adaptation. In\nthis paper, we propose \\textbf{Sparse-Tuning}, a novel tuning paradigm that\nsubstantially enhances both fine-tuning and inference efficiency for\npre-trained ViT models. Sparse-Tuning efficiently fine-tunes the pre-trained\nViT by sparsely preserving the informative tokens and merging redundant ones,\nenabling the ViT to focus on the foreground while reducing computational costs\non background regions in the images. To accurately distinguish informative\ntokens from uninformative ones, we introduce a tailored Dense Adapter, which\nestablishes dense connections across different encoder layers in the ViT,\nthereby enhancing the representational capacity and quality of token\nsparsification. Empirical results on VTAB-1K, three complete image datasets,\nand two complete video datasets demonstrate that Sparse-Tuning reduces the\nGFLOPs to \\textbf{62\\%-70\\%} of the original ViT-B while achieving\nstate-of-the-art performance. Source code is available at\n\\url{https://github.com/liuting20/Sparse-Tuning}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ting Liu",
            "Xuyang Liu",
            "Liangtao Shi",
            "Zunnan Xu",
            "Siteng Huang",
            "Yi Xin",
            "Quanjun Yin"
        ],
        "published": "2024-05-23T15:34:53Z"
    },
    {
        "title": "A Declarative System for Optimizing AI Workloads",
        "link": "http://arxiv.org/abs/2405.14696v1",
        "abstract": "Modern AI models provide the key to a long-standing dream: processing\nanalytical queries about almost any kind of data. Until recently, it was\ndifficult and expensive to extract facts from company documents, data from\nscientific papers, or insights from image and video corpora. Today's models can\naccomplish these tasks with high accuracy. However, a programmer who wants to\nanswer a substantive AI-powered query must orchestrate large numbers of models,\nprompts, and data operations. For even a single query, the programmer has to\nmake a vast number of decisions such as the choice of model, the right\ninference method, the most cost-effective inference hardware, the ideal prompt\ndesign, and so on. The optimal set of decisions can change as the query changes\nand as the rapidly-evolving technical landscape shifts. In this paper we\npresent Palimpzest, a system that enables anyone to process AI-powered\nanalytical queries simply by defining them in a declarative language. The\nsystem uses its cost optimization framework -- which explores the search space\nof AI models, prompting techniques, and related foundation model optimizations\n-- to implement the query with the best trade-offs between runtime, financial\ncost, and output data quality. We describe the workload of AI-powered analytics\ntasks, the optimization methods that Palimpzest uses, and the prototype system\nitself. We evaluate Palimpzest on tasks in Legal Discovery, Real Estate Search,\nand Medical Schema Matching. We show that even our simple prototype offers a\nrange of appealing plans, including one that is 3.3x faster, 2.9x cheaper, and\noffers better data quality than the baseline method. With parallelism enabled,\nPalimpzest can produce plans with up to a 90.3x speedup at 9.1x lower cost\nrelative to a single-threaded GPT-4 baseline, while obtaining an F1-score\nwithin 83.5% of the baseline. These require no additional work by the user.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.DB",
            "H.2.3; I.2.5"
        ],
        "authors": [
            "Chunwei Liu",
            "Matthew Russo",
            "Michael Cafarella",
            "Lei Cao",
            "Peter Baille Chen",
            "Zui Chen",
            "Michael Franklin",
            "Tim Kraska",
            "Samuel Madden",
            "Gerardo Vitagliano"
        ],
        "published": "2024-05-23T15:31:18Z"
    },
    {
        "title": "CityGPT: Towards Urban IoT Learning, Analysis and Interaction with\n  Multi-Agent System",
        "link": "http://arxiv.org/abs/2405.14691v1",
        "abstract": "The spatiotemporal data generated by massive sensors in the Internet of\nThings (IoT) is extremely dynamic, heterogeneous, large scale and\ntime-dependent. It poses great challenges (e.g. accuracy, reliability, and\nstability) in real-time analysis and decision making for different IoT\napplications. The complexity of IoT data prevents the common people from\ngaining a deeper understanding of it. Agentized systems help address the lack\nof data insight for the common people. We propose a generic framework, namely\nCityGPT, to facilitate the learning and analysis of IoT time series with an\nend-to-end paradigm. CityGPT employs three agents to accomplish the\nspatiotemporal analysis of IoT data. The requirement agent facilitates user\ninputs based on natural language. Then, the analysis tasks are decomposed into\ntemporal and spatial analysis processes, completed by corresponding data\nanalysis agents (temporal and spatial agents). Finally, the spatiotemporal\nfusion agent visualizes the system's analysis results by receiving analysis\nresults from data analysis agents and invoking sub-visualization agents, and\ncan provide corresponding textual descriptions based on user demands. To\nincrease the insight for common people using our framework, we have agnentized\nthe framework, facilitated by a large language model (LLM), to increase the\ndata comprehensibility. Our evaluation results on real-world data with\ndifferent time dependencies show that the CityGPT framework can guarantee\nrobust performance in IoT computing.",
        "subjects": [
            "cs.AI",
            "cs.MA"
        ],
        "authors": [
            "Qinghua Guan",
            "Jinhui Ouyang",
            "Di Wu",
            "Weiren Yu"
        ],
        "published": "2024-05-23T15:27:18Z"
    },
    {
        "title": "Cascade of phase transitions in the training of Energy-based models",
        "link": "http://arxiv.org/abs/2405.14689v1",
        "abstract": "In this paper, we investigate the feature encoding process in a prototypical\nenergy-based generative model, the Restricted Boltzmann Machine (RBM). We start\nwith an analytical investigation using simplified architectures and data\nstructures, and end with numerical analysis of real trainings on real datasets.\nOur study tracks the evolution of the model's weight matrix through its\nsingular value decomposition, revealing a series of phase transitions\nassociated to a progressive learning of the principal modes of the empirical\nprobability distribution. The model first learns the center of mass of the\nmodes and then progressively resolve all modes through a cascade of phase\ntransitions. We first describe this process analytically in a controlled setup\nthat allows us to study analytically the training dynamics. We then validate\nour theoretical results by training the Bernoulli-Bernoulli RBM on real data\nsets. By using data sets of increasing dimension, we show that learning indeed\nleads to sharp phase transitions in the high-dimensional limit. Moreover, we\npropose and test a mean-field finite-size scaling hypothesis. This shows that\nthe first phase transition is in the same universality class of the one we\nstudied analytically, and which is reminiscent of the mean-field\nparamagnetic-to-ferromagnetic phase transition.",
        "subjects": [
            "cs.LG",
            "cond-mat.dis-nn",
            "cond-mat.stat-mech"
        ],
        "authors": [
            "Dimitrios Bachtis",
            "Giulio Biroli",
            "Aurélien Decelle",
            "Beatriz Seoane"
        ],
        "published": "2024-05-23T15:25:56Z"
    },
    {
        "title": "Efficient Robot Learning for Perception and Mapping",
        "link": "http://arxiv.org/abs/2405.14688v1",
        "abstract": "Holistic scene understanding poses a fundamental contribution to the\nautonomous operation of a robotic agent in its environment. Key ingredients\ninclude a well-defined representation of the surroundings to capture its\nspatial structure as well as assigning semantic meaning while delineating\nindividual objects. Classic components from the toolbox of roboticists to\naddress these tasks are simultaneous localization and mapping (SLAM) and\npanoptic segmentation. Although recent methods demonstrate impressive advances,\nmostly due to employing deep learning, they commonly utilize in-domain training\non large datasets. Since following such a paradigm substantially limits their\nreal-world application, my research investigates how to minimize human effort\nin deploying perception-based robotic systems to previously unseen\nenvironments. In particular, I focus on leveraging continual learning and\nreducing human annotations for efficient learning. An overview of my work can\nbe found at https://vniclas.github.io.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Niclas Vödisch"
        ],
        "published": "2024-05-23T15:25:30Z"
    },
    {
        "title": "Recursive PAC-Bayes: A Frequentist Approach to Sequential Prior Updates\n  with No Information Loss",
        "link": "http://arxiv.org/abs/2405.14681v1",
        "abstract": "PAC-Bayesian analysis is a frequentist framework for incorporating prior\nknowledge into learning. It was inspired by Bayesian learning, which allows\nsequential data processing and naturally turns posteriors from one processing\nstep into priors for the next. However, despite two and a half decades of\nresearch, the ability to update priors sequentially without losing confidence\ninformation along the way remained elusive for PAC-Bayes. While PAC-Bayes\nallows construction of data-informed priors, the final confidence intervals\ndepend only on the number of points that were not used for the construction of\nthe prior, whereas confidence information in the prior, which is related to the\nnumber of points used to construct the prior, is lost. This limits the\npossibility and benefit of sequential prior updates, because the final bounds\ndepend only on the size of the final batch.\n  We present a novel and, in retrospect, surprisingly simple and powerful\nPAC-Bayesian procedure that allows sequential prior updates with no information\nloss. The procedure is based on a novel decomposition of the expected loss of\nrandomized classifiers. The decomposition rewrites the loss of the posterior as\nan excess loss relative to a downscaled loss of the prior plus the downscaled\nloss of the prior, which is bounded recursively. As a side result, we also\npresent a generalization of the split-kl and PAC-Bayes-split-kl inequalities to\ndiscrete random variables, which we use for bounding the excess losses, and\nwhich can be of independent interest. In empirical evaluation the new procedure\nsignificantly outperforms state-of-the-art.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Yi-Shan Wu",
            "Yijie Zhang",
            "Badr-Eddine Chérief-Abdellatif",
            "Yevgeny Seldin"
        ],
        "published": "2024-05-23T15:15:17Z"
    },
    {
        "title": "Leveraging Electric Guitar Tones and Effects to Improve Robustness in\n  Guitar Tablature Transcription Modeling",
        "link": "http://arxiv.org/abs/2405.14679v1",
        "abstract": "Guitar tablature transcription (GTT) aims at automatically generating\nsymbolic representations from real solo guitar performances. Due to its\napplications in education and musicology, GTT has gained traction in recent\nyears. However, GTT robustness has been limited due to the small size of\navailable datasets. Researchers have recently used synthetic data that\nsimulates guitar performances using pre-recorded or computer-generated tones\nand can be automatically generated at large scales. The present study\ncomplements these efforts by demonstrating that GTT robustness can be improved\nby including synthetic training data created using recordings of real guitar\ntones played with different audio effects. We evaluate our approach on a new\nevaluation dataset with professional solo guitar performances that we composed\nand collected, featuring a wide array of tones, chords, and scales.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Hegel Pedroza Wallace Abreu",
            "Ryan Corey",
            "Iran Roman"
        ],
        "published": "2024-05-23T15:13:40Z"
    },
    {
        "title": "Measuring data types",
        "link": "http://arxiv.org/abs/2405.14678v1",
        "abstract": "In this article, we combine Sweedler's classic theory of measuring coalgebras\n-- by which $k$-algebras are enriched in $k$-coalgebras for $k$ a field -- with\nthe theory of W-types -- by which the categorical semantics of inductive data\ntypes in functional programming languages are understood. In our main theorem,\nwe find that under some hypotheses, algebras of an endofunctor are enriched in\ncoalgebras of the same endofunctor, and we find polynomial endofunctors provide\nmany interesting examples of this phenomenon. We then generalize the notion of\ninitial algebra of an endofunctor using this enrichment, thus generalizing the\nnotion of W-type. This article is an extended version of arXiv:2303.16793, it\nadds expository introductions to the original theories of measuring coalgebras\nand W-types along with some improvements to the main theory and many explicitly\nworked examples.",
        "subjects": [
            "math.CT",
            "cs.LO",
            "math.AT",
            "Primary: 18C50, 68Q25, 16T15. Secondary: 18D20, 03B70"
        ],
        "authors": [
            "Lukas Mulder",
            "Paige Randall North",
            "Maximilien Péroux"
        ],
        "published": "2024-05-23T15:13:33Z"
    },
    {
        "title": "RectifID: Personalizing Rectified Flow with Anchored Classifier Guidance",
        "link": "http://arxiv.org/abs/2405.14677v1",
        "abstract": "Customizing diffusion models to generate identity-preserving images from\nuser-provided reference images is an intriguing new problem. The prevalent\napproaches typically require training on extensive domain-specific images to\nachieve identity preservation, which lacks flexibility across different use\ncases. To address this issue, we exploit classifier guidance, a training-free\ntechnique that steers diffusion models using an existing classifier, for\npersonalized image generation. Our study shows that based on a recent rectified\nflow framework, the major limitation of vanilla classifier guidance in\nrequiring a special classifier can be resolved with a simple fixed-point\nsolution, allowing flexible personalization with off-the-shelf image\ndiscriminators. Moreover, its solving procedure proves to be stable when\nanchored to a reference flow trajectory, with a convergence guarantee. The\nderived method is implemented on rectified flow with different off-the-shelf\nimage discriminators, delivering advantageous personalization results for human\nfaces, live subjects, and certain objects. Code is available at\nhttps://github.com/feifeiobama/RectifID.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Zhicheng Sun",
            "Zhenhao Yang",
            "Yang Jin",
            "Haozhe Chi",
            "Kun Xu",
            "Kun Xu",
            "Liwei Chen",
            "Hao Jiang",
            "Di Zhang",
            "Yang Song",
            "Kun Gai",
            "Yadong Mu"
        ],
        "published": "2024-05-23T15:12:15Z"
    },
    {
        "title": "Drones Help Drones: A Collaborative Framework for Multi-Drone Object\n  Trajectory Prediction and Beyond",
        "link": "http://arxiv.org/abs/2405.14674v1",
        "abstract": "Collaborative trajectory prediction can comprehensively forecast the future\nmotion of objects through multi-view complementary information. However, it\nencounters two main challenges in multi-drone collaboration settings. The\nexpansive aerial observations make it difficult to generate precise Bird's Eye\nView (BEV) representations. Besides, excessive interactions can not meet\nreal-time prediction requirements within the constrained drone-based\ncommunication bandwidth. To address these problems, we propose a novel\nframework named \"Drones Help Drones\" (DHD). Firstly, we incorporate the ground\npriors provided by the drone's inclined observation to estimate the distance\nbetween objects and drones, leading to more precise BEV generation. Secondly,\nwe design a selective mechanism based on the local feature discrepancy to\nprioritize the critical information contributing to prediction tasks during\ninter-drone interactions. Additionally, we create the first dataset for\nmulti-drone collaborative prediction, named \"Air-Co-Pred\", and conduct\nquantitative and qualitative experiments to validate the effectiveness of our\nDHD framework.The results demonstrate that compared to state-of-the-art\napproaches, DHD reduces position deviation in BEV representations by over 20%\nand requires only a quarter of the transmission ratio for interactions while\nachieving comparable prediction performance. Moreover, DHD also shows promising\ngeneralization to the collaborative 3D object detection in CoPerception-UAVs.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhechao Wang",
            "Peirui Cheng",
            "Mingxin Chen",
            "Pengju Tian",
            "Zhirui Wang",
            "Xinming Li",
            "Xue Yang",
            "Xian Sun"
        ],
        "published": "2024-05-23T15:11:23Z"
    },
    {
        "title": "Towards Imperceptible Backdoor Attack in Self-supervised Learning",
        "link": "http://arxiv.org/abs/2405.14672v1",
        "abstract": "Self-supervised learning models are vulnerable to backdoor attacks. Existing\nbackdoor attacks that are effective in self-supervised learning often involve\nnoticeable triggers, like colored patches, which are vulnerable to human\ninspection. In this paper, we propose an imperceptible and effective backdoor\nattack against self-supervised models. We first find that existing\nimperceptible triggers designed for supervised learning are not as effective in\ncompromising self-supervised models. We then identify this ineffectiveness is\nattributed to the overlap in distributions between the backdoor and augmented\nsamples used in self-supervised learning. Building on this insight, we design\nan attack using optimized triggers that are disentangled to the augmented\ntransformation in the self-supervised learning, while also remaining\nimperceptible to human vision. Experiments on five datasets and seven SSL\nalgorithms demonstrate our attack is highly effective and stealthy. It also has\nstrong resistance to existing backdoor defenses. Our code can be found at\nhttps://github.com/Zhang-Henry/IMPERATIVE.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hanrong Zhang",
            "Zhenting Wang",
            "Tingxu Han",
            "Mingyu Jin",
            "Chenlu Zhan",
            "Mengnan Du",
            "Hongwei Wang",
            "Shiqing Ma"
        ],
        "published": "2024-05-23T15:08:31Z"
    },
    {
        "title": "Overcoming the Challenges of Batch Normalization in Federated Learning",
        "link": "http://arxiv.org/abs/2405.14670v1",
        "abstract": "Batch normalization has proven to be a very beneficial mechanism to\naccelerate the training and improve the accuracy of deep neural networks in\ncentralized environments. Yet, the scheme faces significant challenges in\nfederated learning, especially under high data heterogeneity. Essentially, the\nmain challenges arise from external covariate shifts and inconsistent\nstatistics across clients. We introduce in this paper Federated BatchNorm\n(FBN), a novel scheme that restores the benefits of batch normalization in\nfederated learning. Essentially, FBN ensures that the batch normalization\nduring training is consistent with what would be achieved in a centralized\nexecution, hence preserving the distribution of the data, and providing running\nstatistics that accurately approximate the global statistics. FBN thereby\nreduces the external covariate shift and matches the evaluation performance of\nthe centralized setting. We also show that, with a slight increase in\ncomplexity, we can robustify FBN to mitigate erroneous statistics and\npotentially adversarial attacks.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Rachid Guerraoui",
            "Rafael Pinot",
            "Geovani Rizk",
            "John Stephan",
            "François Taiani"
        ],
        "published": "2024-05-23T15:07:21Z"
    },
    {
        "title": "Efficiency for Free: Ideal Data Are Transportable Representations",
        "link": "http://arxiv.org/abs/2405.14669v1",
        "abstract": "Data, the seminal opportunity and challenge in modern machine learning,\ncurrently constrains the scalability of representation learning and impedes the\npace of model evolution. Existing paradigms tackle the issue of learning\nefficiency over massive datasets from the perspective of self-supervised\nlearning and dataset distillation independently, while neglecting the untapped\npotential of accelerating representation learning from an intermediate\nstandpoint. In this work, we delve into defining the ideal data properties from\nboth optimization and generalization perspectives. We propose that\nmodel-generated representations, despite being trained on diverse tasks and\narchitectures, converge to a shared linear space, facilitating effective linear\ntransport between models. Furthermore, we demonstrate that these\nrepresentations exhibit properties conducive to the formation of ideal data.\nThe theoretical/empirical insights therein inspire us to propose a\nRepresentation Learning Accelerator (ReLA), which leverages a task- and\narchitecture-agnostic, yet publicly available, free model to form a dynamic\ndata subset and thus accelerate (self-)supervised learning. For instance,\nemploying a CLIP ViT B/16 as a prior model for dynamic data generation,\nReLA-aided BYOL can train a ResNet-50 from scratch with 50% of ImageNet-1K,\nyielding performance surpassing that of training on the full dataset.\nAdditionally, employing a ResNet-18 pre-trained on CIFAR-10 can enhance\nResNet-50 training on 10% of ImageNet-1K, resulting in a 7.7% increase in\naccuracy.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Peng Sun",
            "Yi Jiang",
            "Tao Lin"
        ],
        "published": "2024-05-23T15:06:02Z"
    },
    {
        "title": "Fisher Flow Matching for Generative Modeling over Discrete Data",
        "link": "http://arxiv.org/abs/2405.14664v1",
        "abstract": "Generative modeling over discrete data has recently seen numerous success\nstories, with applications spanning language modeling, biological sequence\ndesign, and graph-structured molecular data. The predominant generative\nmodeling paradigm for discrete data is still autoregressive, with more recent\nalternatives based on diffusion or flow-matching falling short of their\nimpressive performance in continuous data settings, such as image or video\ngeneration. In this work, we introduce Fisher-Flow, a novel flow-matching model\nfor discrete data. Fisher-Flow takes a manifestly geometric perspective by\nconsidering categorical distributions over discrete data as points residing on\na statistical manifold equipped with its natural Riemannian metric: the\n$\\textit{Fisher-Rao metric}$. As a result, we demonstrate discrete data itself\ncan be continuously reparameterised to points on the positive orthant of the\n$d$-hypersphere $\\mathbb{S}^d_+$, which allows us to define flows that map any\nsource distribution to target in a principled manner by transporting mass along\n(closed-form) geodesics of $\\mathbb{S}^d_+$. Furthermore, the learned flows in\nFisher-Flow can be further bootstrapped by leveraging Riemannian optimal\ntransport leading to improved training dynamics. We prove that the gradient\nflow induced by Fisher-Flow is optimal in reducing the forward KL divergence.\n  We evaluate Fisher-Flow on an array of synthetic and diverse real-world\nbenchmarks, including designing DNA Promoter, and DNA Enhancer sequences.\nEmpirically, we find that Fisher-Flow improves over prior diffusion and\nflow-matching models on these benchmarks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Oscar Davis",
            "Samuel Kessler",
            "Mircea Petrache",
            "{İ}smail {İ}lkan Ceylan",
            "Avishek Joey Bose"
        ],
        "published": "2024-05-23T15:02:11Z"
    },
    {
        "title": "Implicit In-context Learning",
        "link": "http://arxiv.org/abs/2405.14660v1",
        "abstract": "In-context Learning (ICL) empowers large language models (LLMs) to adapt to\nunseen tasks during inference by prefixing a few demonstration examples prior\nto test queries. Despite its versatility, ICL incurs substantial computational\nand memory overheads compared to zero-shot learning and is susceptible to the\nselection and order of demonstration examples. In this work, we introduce\nImplicit In-context Learning (I2CL), an innovative paradigm that addresses the\nchallenges associated with traditional ICL by absorbing demonstration examples\nwithin the activation space. I2CL first generates a condensed vector\nrepresentation, namely a context vector, from the demonstration examples. It\nthen integrates the context vector during inference by injecting a linear\ncombination of the context vector and query activations into the model's\nresidual streams. Empirical evaluation on nine real-world tasks across three\nmodel architectures demonstrates that I2CL achieves few-shot performance with\nzero-shot cost and exhibits robustness against the variation of demonstration\nexamples. Furthermore, I2CL facilitates a novel representation of \"task-ids\",\nenhancing task similarity detection and enabling effective transfer learning.\nWe provide a comprehensive analysis of I2CL, offering deeper insights into its\nmechanisms and broader implications for ICL. The source code is available at:\nhttps://github.com/LzVv123456/I2CL.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Zhuowei Li",
            "Zihao Xu",
            "Ligong Han",
            "Yunhe Gao",
            "Song Wen",
            "Di Liu",
            "Hao Wang",
            "Dimitris N. Metaxas"
        ],
        "published": "2024-05-23T14:57:52Z"
    },
    {
        "title": "Heteroscedastic Preferential Bayesian Optimization with Informative\n  Noise Distributions",
        "link": "http://arxiv.org/abs/2405.14657v1",
        "abstract": "Preferential Bayesian optimization (PBO) is a sample-efficient framework for\nlearning human preferences between candidate designs. PBO classically relies on\nhomoscedastic noise models to represent human aleatoric uncertainty. Yet, such\nnoise fails to accurately capture the varying levels of human aleatoric\nuncertainty, particularly when the user possesses partial knowledge among\ndifferent pairs of candidates. For instance, a chemist with solid expertise in\nglucose-related molecules may easily compare two compounds from that family\nwhile struggling to compare alcohol-related molecules. Currently, PBO overlooks\nthis uncertainty during the search for a new candidate through the maximization\nof the acquisition function, consequently underestimating the risk associated\nwith human uncertainty. To address this issue, we propose a heteroscedastic\nnoise model to capture human aleatoric uncertainty. This model adaptively\nassigns noise levels based on the distance of a specific input to a predefined\nset of reliable inputs known as anchors provided by the human. Anchors\nencapsulate partial knowledge and offer insight into the comparative difficulty\nof evaluating different candidate pairs. Such a model can be seamlessly\nintegrated into the acquisition function, thus leading to candidate design\npairs that elegantly trade informativeness and ease of comparison for the human\nexpert. We perform an extensive empirical evaluation of the proposed approach,\ndemonstrating a consistent improvement over homoscedastic PBO.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Marshal Arijona Sinaga",
            "Julien Martinelli",
            "Vikas Garg",
            "Samuel Kaski"
        ],
        "published": "2024-05-23T14:55:18Z"
    },
    {
        "title": "Multi-turn Reinforcement Learning from Preference Human Feedback",
        "link": "http://arxiv.org/abs/2405.14655v1",
        "abstract": "Reinforcement Learning from Human Feedback (RLHF) has become the standard\napproach for aligning Large Language Models (LLMs) with human preferences,\nallowing LLMs to demonstrate remarkable abilities in various tasks. Existing\nmethods work by emulating the preferences at the single decision (turn) level,\nlimiting their capabilities in settings that require planning or multi-turn\ninteractions to achieve a long-term goal. In this paper, we address this issue\nby developing novel methods for Reinforcement Learning (RL) from preference\nfeedback between two full multi-turn conversations. In the tabular setting, we\npresent a novel mirror-descent-based policy optimization algorithm for the\ngeneral multi-turn preference-based RL problem, and prove its convergence to\nNash equilibrium. To evaluate performance, we create a new environment,\nEducation Dialogue, where a teacher agent guides a student in learning a random\ntopic, and show that a deep RL variant of our algorithm outperforms RLHF\nbaselines. Finally, we show that in an environment with explicit rewards, our\nalgorithm recovers the same performance as a reward-based RL baseline, despite\nrelying solely on a weaker preference signal.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Lior Shani",
            "Aviv Rosenberg",
            "Asaf Cassel",
            "Oran Lang",
            "Daniele Calandriello",
            "Avital Zipori",
            "Hila Noga",
            "Orgad Keller",
            "Bilal Piot",
            "Idan Szpektor",
            "Avinatan Hassidim",
            "Yossi Matias",
            "Rémi Munos"
        ],
        "published": "2024-05-23T14:53:54Z"
    },
    {
        "title": "Efficient Medical Question Answering with Knowledge-Augmented Question\n  Generation",
        "link": "http://arxiv.org/abs/2405.14654v1",
        "abstract": "In the expanding field of language model applications, medical knowledge\nrepresentation remains a significant challenge due to the specialized nature of\nthe domain. Large language models, such as GPT-4, obtain reasonable scores on\nmedical question answering tasks, but smaller models are far behind. In this\nwork, we introduce a method to improve the proficiency of a small language\nmodel in the medical domain by employing a two-fold approach. We first\nfine-tune the model on a corpus of medical textbooks. Then, we use GPT-4 to\ngenerate questions similar to the downstream task, prompted with textbook\nknowledge, and use them to fine-tune the model. Additionally, we introduce\nECN-QA, a novel medical question answering dataset containing ``progressive\nquestions'' composed of related sequential questions. We show the benefits of\nour training strategy on this dataset. The study's findings highlight the\npotential of small language models in the medical domain when appropriately\nfine-tuned. The code and weights are available at\nhttps://github.com/raidium-med/MQG.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Julien Khlaut",
            "Corentin Dancette",
            "Elodie Ferreres",
            "Alaedine Bennani",
            "Paul Hérent",
            "Pierre Manceron"
        ],
        "published": "2024-05-23T14:53:52Z"
    },
    {
        "title": "Total Radiated Power Measurements of a mmWave Phased Array in a\n  Reverberation Chamber",
        "link": "http://dx.doi.org/10.1109/ISAP57493.2023.10388794",
        "abstract": "This paper explores the use of reverberation chambers for TRP measurements of\nbeamformed radiation by phased arrays at mmWave frequencies. First, the\nreceived power was verified by the one-sample K-S GoF test to follow the\nexponential probability distribution. Different numbers of samples and\nstirrers' positions were considered. Second, we showed that the effective\nnumber of independent samples is different depending on the number of samples\nand stirrers' positions. Third, the beamforming TRP estimates are presented for\nall beams, analyzing the statistical significance of the observed differences\nwith a selection of samplings.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Alejandro Antón Ruiz",
            "Samar Hosseinzadegan",
            "John Kvarnstrand",
            "Klas Arvidsson",
            "Andrés Alayón Glazunov"
        ],
        "published": "2024-05-23T14:52:35Z"
    },
    {
        "title": "PhiNets: Brain-inspired Non-contrastive Learning Based on Temporal\n  Prediction Hypothesis",
        "link": "http://arxiv.org/abs/2405.14650v1",
        "abstract": "SimSiam is a prominent self-supervised learning method that achieves\nimpressive results in various vision tasks under static environments. However,\nit has two critical issues: high sensitivity to hyperparameters, especially\nweight decay, and unsatisfactory performance in online and continual learning,\nwhere neuroscientists believe that powerful memory functions are necessary, as\nin brains. In this paper, we propose PhiNet, inspired by a hippocampal model\nbased on the temporal prediction hypothesis. Unlike SimSiam, which aligns two\naugmented views of the original image, PhiNet integrates an additional\npredictor block that estimates the original image representation to imitate the\nCA1 region in the hippocampus. Moreover, we model the neocortex inspired by the\nComplementary Learning Systems theory with a momentum encoder block as a slow\nlearner, which works as long-term memory. We demonstrate through analysing the\nlearning dynamics that PhiNet benefits from the additional predictor to prevent\nthe complete collapse of learned representations, a notorious challenge in\nnon-contrastive learning. This dynamics analysis may partially corroborate why\nthis hippocampal model is biologically plausible. Experimental results\ndemonstrate that PhiNet is more robust to weight decay and performs better than\nSimSiam in memory-intensive tasks like online and continual learning.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Satoki Ishikawa",
            "Makoto Yamada",
            "Han Bao",
            "Yuki Takezawa"
        ],
        "published": "2024-05-23T14:50:59Z"
    },
    {
        "title": "The integration of heterogeneous resources in the CMS Submission\n  Infrastructure for the LHC Run 3 and beyond",
        "link": "http://dx.doi.org/10.1051/epjconf/202429504046",
        "abstract": "While the computing landscape supporting LHC experiments is currently\ndominated by x86 processors at WLCG sites, this configuration will evolve in\nthe coming years. LHC collaborations will be increasingly employing HPC and\nCloud facilities to process the vast amounts of data expected during the LHC\nRun 3 and the future HL-LHC phase. These facilities often feature diverse\ncompute resources, including alternative CPU architectures like ARM and IBM\nPower, as well as a variety of GPU specifications. Using these heterogeneous\nresources efficiently is thus essential for the LHC collaborations reaching\ntheir future scientific goals. The Submission Infrastructure (SI) is a central\nelement in CMS Computing, enabling resource acquisition and exploitation by CMS\ndata processing, simulation and analysis tasks. The SI must therefore be\nadapted to ensure access and optimal utilization of this heterogeneous compute\ncapacity. Some steps in this evolution have been already taken, as CMS is\ncurrently using opportunistically a small pool of GPU slots provided mainly at\nthe CMS WLCG sites. Additionally, Power9 processors have been validated for CMS\nproduction at the Marconi-100 cluster at CINECA. This note will describe the\nupdated capabilities of the SI to continue ensuring the efficient allocation\nand use of computing resources by CMS, despite their increasing diversity. The\nnext steps towards a full integration and support of heterogeneous resources\naccording to CMS needs will also be reported.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Antonio Perez-Calero Yzquierdo",
            "Marco Mascheroni",
            "Edita Kizinevic",
            "Farrukh Aftab Khan",
            "Hyunwoo Kim",
            "Maria Acosta Flechas",
            "Nikos Tsipinakis",
            "Saqib Haleem"
        ],
        "published": "2024-05-23T14:48:23Z"
    },
    {
        "title": "Unveiling the Achilles' Heel of NLG Evaluators: A Unified Adversarial\n  Framework Driven by Large Language Models",
        "link": "http://arxiv.org/abs/2405.14646v1",
        "abstract": "The automatic evaluation of natural language generation (NLG) systems\npresents a long-lasting challenge. Recent studies have highlighted various\nneural metrics that align well with human evaluations. Yet, the robustness of\nthese evaluators against adversarial perturbations remains largely\nunder-explored due to the unique challenges in obtaining adversarial data for\ndifferent NLG evaluation tasks. To address the problem, we introduce AdvEval, a\nnovel black-box adversarial framework against NLG evaluators. AdvEval is\nspecially tailored to generate data that yield strong disagreements between\nhuman and victim evaluators. Specifically, inspired by the recent success of\nlarge language models (LLMs) in text generation and evaluation, we adopt strong\nLLMs as both the data generator and gold evaluator. Adversarial data are\nautomatically optimized with feedback from the gold and victim evaluator. We\nconduct experiments on 12 victim evaluators and 11 NLG datasets, spanning tasks\nincluding dialogue, summarization, and question evaluation. The results show\nthat AdvEval can lead to significant performance degradation of various victim\nmetrics, thereby validating its efficacy.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yiming Chen",
            "Chen Zhang",
            "Danqing Luo",
            "Luis Fernando D'Haro",
            "Robby T. Tan",
            "Haizhou Li"
        ],
        "published": "2024-05-23T14:48:15Z"
    },
    {
        "title": "Lagrangian Neural Networks for Reversible Dissipative Evolution",
        "link": "http://arxiv.org/abs/2405.14645v1",
        "abstract": "There is a growing attention given to utilizing Lagrangian and Hamiltonian\nmechanics with network training in order to incorporate physics into the\nnetwork. Most commonly, conservative systems are modeled, in which there are no\nfrictional losses, so the system may be run forward and backward in time\nwithout requiring regularization. This work addresses systems in which the\nreverse direction is ill-posed because of the dissipation that occurs in\nforward evolution. The novelty is the use of Morse-Feshbach Lagrangian, which\nmodels dissipative dynamics by doubling the number of dimensions of the system\nin order to create a mirror latent representation that would counterbalance the\ndissipation of the observable system, making it a conservative system, albeit\nembedded in a larger space. We start with their formal approach by redefining a\nnew Dissipative Lagrangian, such that the unknown matrices in the\nEuler-Lagrange's equations arise as partial derivatives of the Lagrangian with\nrespect to only the observables. We then train a network from simulated\ntraining data for dissipative systems such as Fickian diffusion that arise in\nmaterials sciences. It is shown by experiments that the systems can be evolved\nin both forward and reverse directions without regularization beyond that\nprovided by the Morse-Feshbach Lagrangian. Experiments of dissipative systems,\nsuch as Fickian diffusion, demonstrate the degree to which dynamics can be\nreversed.",
        "subjects": [
            "cs.LG",
            "cond-mat.mtrl-sci"
        ],
        "authors": [
            "Veera Sundararaghavan",
            "Megna N. Shah",
            "Jeff P. Simmons"
        ],
        "published": "2024-05-23T14:47:07Z"
    },
    {
        "title": "Adoption of a token-based authentication model for the CMS Submission\n  Infrastructure",
        "link": "http://dx.doi.org/10.1051/epjconf/202429504003",
        "abstract": "The CMS Submission Infrastructure (SI) is the main computing resource\nprovisioning system for CMS workloads. A number of HTCondor pools are employed\nto manage this infrastructure, which aggregates geographically distributed\nresources from the WLCG and other providers. Historically, the model of\nauthentication among the diverse components of this infrastructure has relied\non the Grid Security Infrastructure (GSI), based on identities and X509\ncertificates. In contrast, commonly used modern authentication standards are\nbased on capabilities and tokens. The WLCG has identified this trend and aims\nat a transparent replacement of GSI for all its workload management, data\ntransfer and storage access operations, to be completed during the current LHC\nRun 3. As part of this effort, and within the context of CMS computing, the\nSubmission Infrastructure group is in the process of phasing out the GSI part\nof its authentication layers, in favor of IDTokens and Scitokens. The use of\ntokens is already well integrated into the HTCondor Software Suite, which has\nallowed us to fully migrate the authentication between internal components of\nSI. Additionally, recent versions of the HTCondor-CE support tokens as well,\nenabling CMS resource requests to Grid sites employing this CE technology to be\ngranted by means of token exchange. After a rollout campaign to sites,\nsuccessfully completed by the third quarter of 2022, the totality of HTCondor\nCEs in use by CMS are already receiving Scitoken-based pilot jobs. On the ARC\nCE side, a parallel campaign was launched to foster the adoption of the REST\ninterface at CMS sites (required to enable token-based job submission via\nHTCondor-G), which is nearing completion as well. In this contribution, the\nnewly adopted authentication model will be described. We will then report on\nthe migration status and final steps towards complete GSI phase out in the CMS\nSI.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Antonio Perez-Calero Yzquierdo",
            "Marco Mascheroni",
            "Edita Kizinevic",
            "Farrukh Aftab Khan",
            "Hyunwoo Kim",
            "Maria Acosta Flechas",
            "Nikos Tsipinakis",
            "Saqib Haleem",
            "Frank Wurthwein"
        ],
        "published": "2024-05-23T14:46:10Z"
    },
    {
        "title": "GPU Implementations for Midsize Integer Addition and Multiplication",
        "link": "http://arxiv.org/abs/2405.14642v1",
        "abstract": "This paper explores practical aspects of using a high-level functional\nlanguage for GPU-based arithmetic on ``midsize'' integers. By this we mean\nintegers of up to about a quarter million bits, which is sufficient for most\npractical purposes. The goal is to understand whether it is possible to support\nefficient nested-parallel programs with a small, flexible code base. We report\non GPU implementations for addition and multiplication of integers that fit in\none CUDA block, thus leveraging temporal reuse from scratchpad memories. Our\nkey contribution resides in the simplicity of the proposed solutions: We\nrecognize that addition is a straightforward application of scan, which is\nknown to allow efficient GPU implementation. For quadratic multiplication we\nemploy a simple work-partitioning strategy that offers good temporal locality.\nFor FFT multiplication, we efficiently map the computation in the domain of\nintegral fields by finding ``good'' primes that enable almost-full utilization\nof machine words. In comparison, related work uses complex tiling strategies --\nwhich feel too big a hammer for the job -- or uses the computational domain of\nreals, which may degrade the magnitude of the base in which the computation is\ncarried. We evaluate the performance in comparison to the state-of-the-art CGBN\nlibrary, authored by NvidiaLab, and report that our CUDA prototype outperforms\nCGBN for integer sizes higher than 32K bits, while offering comparable\nperformance for smaller sizes. Moreover, we are, to our knowledge, the first to\nreport that FFT multiplication outperforms the classical one on the larger\nsizes that still fit in a CUDA block. Finally, we examine Futhark's strengths\nand weaknesses for efficiently supporting such computations and find out that a\ncompiler pass aimed at efficient sequentialization of excess parallelism would\nsignificantly improve performance.",
        "subjects": [
            "cs.DC",
            "cs.MS",
            "cs.PL"
        ],
        "authors": [
            "Cosmin E. Oancea",
            "Stephen M. Watt"
        ],
        "published": "2024-05-23T14:44:49Z"
    },
    {
        "title": "K-factor Evaluation in a Hybrid Reverberation Chamber plus CATR OTA\n  Testing Setup",
        "link": "http://dx.doi.org/10.23919/EuCAP60739.2024.10501142",
        "abstract": "This paper investigates achieving diverse K-factors using a Reverberation\nChamber (RC) with a Compact Antenna Test Range (CATR) system. It explores six\nhybrid \"RC plus CATR\" configurations involving different excitations of the\nRich Isotropic Multipath (RIMP) field and CATR-generated plane waves, with some\nsetups including absorbers. A fixed horn antenna points towards the CATR in all\nconfigurations. The study found that the null hypothesis of Rayleigh or Rician\nprobability distributions for the received signal envelope could not be\nrejected, with RIMP setups primarily conforming to Rayleigh distribution and\nall setups showing Rician distribution. Various K-factors were obtained, but no\ngeneralizable method for achieving the desired K-factor was identified. The\npaper also estimates the K-factor as a function of frequency in the 24.25-29.5\nGHz band. Smaller K-factors exhibit larger fluctuations, while larger K-factors\nremain relatively stable, with consistent fluctuations across the frequency\nrange.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Alejandro Antón Ruiz",
            "Samar Hosseinzadegan",
            "John Kvarnstrand",
            "Klas Arvidsson",
            "Andrés Alayón Glazunov"
        ],
        "published": "2024-05-23T14:43:05Z"
    },
    {
        "title": "Repurposing of the Run 2 CMS High Level Trigger Infrastructure as a\n  Cloud Resource for Offline Computing",
        "link": "http://dx.doi.org/10.1051/epjconf/202429503036",
        "abstract": "The former CMS Run 2 High Level Trigger (HLT) farm is one of the largest\ncontributors to CMS compute resources, providing about 25k job slots for\noffline computing. This CPU farm was initially employed as an opportunistic\nresource, exploited during inter-fill periods, in the LHC Run 2. Since then, it\nhas become a nearly transparent extension of the CMS capacity at CERN, being\nlocated on-site at the LHC interaction point 5 (P5), where the CMS detector is\ninstalled. This resource has been configured to support the execution of\ncritical CMS tasks, such as prompt detector data reconstruction. It can\ntherefore be used in combination with the dedicated Tier 0 capacity at CERN, in\norder to process and absorb peaks in the stream of data coming from the CMS\ndetector. The initial configuration for this resource, based on statically\nconfigured VMs, provided the required level of functionality. However, regular\noperations of this cluster revealed certain limitations compared to the\nresource provisioning and use model employed in the case of WLCG sites. A new\nconfiguration, based on a vacuum-like model, has been implemented for this\nresource in order to solve the detected shortcomings. This paper reports about\nthis redeployment work on the permanent cloud for an enhanced support to CMS\noffline computing, comparing the former and new models' respective\nfunctionalities, along with the commissioning effort for the new setup.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Marco Mascheroni",
            "Antonio Perez-Calero Yzquierdo",
            "Edita Kizinevic",
            "Farrukh Aftab Khan",
            "Hyunwoo Kim",
            "Maria Acosta Flechas",
            "Nikos Tsipinakis",
            "Saqib Haleem",
            "Damiele Spiga",
            "Christoph Wissing",
            "Frank Wurthwein"
        ],
        "published": "2024-05-23T14:42:37Z"
    },
    {
        "title": "PerLLM: Personalized Inference Scheduling with Edge-Cloud Collaboration\n  for Diverse LLM Services",
        "link": "http://arxiv.org/abs/2405.14636v1",
        "abstract": "With the rapid growth in the number of large language model (LLM) users, it\nis difficult for bandwidth-constrained cloud servers to simultaneously process\nmassive LLM services in real-time. Recently, edge-cloud infrastructures have\nbeen used to improve the processing efficiency of large-scale LLM services.\nHowever, the diversity of task requirements and the dynamics of resources pose\ngreat challenges to inference scheduling, leading to the wastage of many\nresources. In this paper, we present PerLLM, a personalized inference\nscheduling framework with edge-cloud collaboration designed for diverse LLM\nservices. For the complexity of multiple constraints and the decision-making\nprocess of edge-cloud collaboration, we integrate the upper confidence bound\nalgorithm based on the constraint satisfaction mechanism in PerLLM. For diverse\nLLM services, PerLLM can optimize service scheduling and resource allocation\nsolutions within the edge-cloud infrastructure to meet processing time\nrequirements while minimizing energy costs. Experimental results from different\nmodel deployments show that PerLLM can effectively meet the processing time\nrequirements of personalized services. Compared to other methods, PerLLM\nachieves 2.2x, 2.1x, and 1.6x throughput and reduces the energy cost by more\nthan 50%.",
        "subjects": [
            "cs.DC",
            "cs.NI"
        ],
        "authors": [
            "Zheming Yang",
            "Yuanhao Yang",
            "Chang Zhao",
            "Qi Guo",
            "Wenkai He",
            "Wen Ji"
        ],
        "published": "2024-05-23T14:41:22Z"
    },
    {
        "title": "Flatten Anything: Unsupervised Neural Surface Parameterization",
        "link": "http://arxiv.org/abs/2405.14633v1",
        "abstract": "Surface parameterization plays an essential role in numerous computer\ngraphics and geometry processing applications. Traditional parameterization\napproaches are designed for high-quality meshes laboriously created by\nspecialized 3D modelers, thus unable to meet the processing demand for the\ncurrent explosion of ordinary 3D data. Moreover, their working mechanisms are\ntypically restricted to certain simple topologies, thus relying on cumbersome\nmanual efforts (e.g., surface cutting, part segmentation) for pre-processing.\nIn this paper, we introduce the Flatten Anything Model (FAM), an unsupervised\nneural architecture to achieve global free-boundary surface parameterization\nvia learning point-wise mappings between 3D points on the target geometric\nsurface and adaptively-deformed UV coordinates within the 2D parameter domain.\nTo mimic the actual physical procedures, we ingeniously construct\ngeometrically-interpretable sub-networks with specific functionalities of\nsurface cutting, UV deforming, unwrapping, and wrapping, which are assembled\ninto a bi-directional cycle mapping framework. Compared with previous methods,\nour FAM directly operates on discrete surface points without utilizing\nconnectivity information, thus significantly reducing the strict requirements\nfor mesh quality and even applicable to unstructured point cloud data. More\nimportantly, our FAM is fully-automated without the need for pre-cutting and\ncan deal with highly-complex topologies, since its learning process adaptively\nfinds reasonable cutting seams and UV boundaries. Extensive experiments\ndemonstrate the universality, superiority, and inspiring potential of our\nproposed neural surface parameterization paradigm. The code will be publicly\navailable.",
        "subjects": [
            "cs.CV",
            "cs.CG"
        ],
        "authors": [
            "Qijian Zhang",
            "Junhui Hou",
            "Wenping Wang",
            "Ying He"
        ],
        "published": "2024-05-23T14:39:52Z"
    },
    {
        "title": "Reinforcement Learning for Fine-tuning Text-to-speech Diffusion Models",
        "link": "http://arxiv.org/abs/2405.14632v1",
        "abstract": "Recent advancements in generative models have sparked significant interest\nwithin the machine learning community. Particularly, diffusion models have\ndemonstrated remarkable capabilities in synthesizing images and speech. Studies\nsuch as those by Lee et al. [19], Black et al. [4], Wang et al. [36], and Fan\net al. [8] illustrate that Reinforcement Learning with Human Feedback (RLHF)\ncan enhance diffusion models for image synthesis. However, due to architectural\ndifferences between these models and those employed in speech synthesis, it\nremains uncertain whether RLHF could similarly benefit speech synthesis models.\nIn this paper, we explore the practical application of RLHF to diffusion-based\ntext-to-speech synthesis, leveraging the mean opinion score (MOS) as predicted\nby UTokyo-SaruLab MOS prediction system [29] as a proxy loss. We introduce\ndiffusion model loss-guided RL policy optimization (DLPO) and compare it\nagainst other RLHF approaches, employing the NISQA speech quality and\nnaturalness assessment model [21] and human preference experiments for further\nevaluation. Our results show that RLHF can enhance diffusion-based\ntext-to-speech synthesis models, and, moreover, DLPO can better improve\ndiffusion models in generating natural and high quality speech audios.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Jingyi Chen",
            "Ju-Seung Byun",
            "Micha Elsner",
            "Andrew Perrault"
        ],
        "published": "2024-05-23T14:39:35Z"
    },
    {
        "title": "HPC resources for CMS offline computing: An integration and scalability\n  challenge for the Submission Infrastructure",
        "link": "http://dx.doi.org/10.1051/epjconf/202429501035",
        "abstract": "The computing resource needs of LHC experiments are expected to continue\ngrowing significantly during the Run 3 and into the HL-LHC era. The landscape\nof available resources will also evolve, as High Performance Computing (HPC)\nand Cloud resources will provide a comparable, or even dominant, fraction of\nthe total compute capacity. The future years present a challenge for the\nexperiments' resource provisioning models, both in terms of scalability and\nincreasing complexity. The CMS Submission Infrastructure (SI) provisions\ncomputing resources for CMS workflows. This infrastructure is built on a set of\nfederated HTCondor pools, currently aggregating 400k CPU cores distributed\nworldwide and supporting the simultaneous execution of over 200k computing\ntasks. Incorporating HPC resources into CMS computing represents firstly an\nintegration challenge, as HPC centers are much more diverse compared to Grid\nsites. Secondly, evolving the present SI, dimensioned to harness the current\nCMS computing capacity, to reach the resource scales required for the HLLHC\nphase, while maintaining global flexibility and efficiency, will represent an\nadditional challenge for the SI. To preventively address future potential\nscalability limits, the SI team regularly runs tests to explore the maximum\nreach of our infrastructure. In this note, the integration of HPC resources\ninto CMS offline computing is summarized, the potential concerns for the SI\nderived from the increased scale of operations are described, and the most\nrecent results of scalability test on the CMS SI are reported.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Antonio Perez-Calero Yzquierdo",
            "Marco Mascheroni",
            "Edita Kizinevic",
            "Farrukh Aftab Khan",
            "Hyunwoo Kim",
            "Maria Acosta Flechas",
            "Nikos Tsipinakis",
            "Saqib Haleem"
        ],
        "published": "2024-05-23T14:36:59Z"
    },
    {
        "title": "Bounds for the smallest eigenvalue of the NTK for arbitrary spherical\n  data of arbitrary dimension",
        "link": "http://arxiv.org/abs/2405.14630v1",
        "abstract": "Bounds on the smallest eigenvalue of the neural tangent kernel (NTK) are a\nkey ingredient in the analysis of neural network optimization and memorization.\nHowever, existing results require distributional assumptions on the data and\nare limited to a high-dimensional setting, where the input dimension $d_0$\nscales at least logarithmically in the number of samples $n$. In this work we\nremove both of these requirements and instead provide bounds in terms of a\nmeasure of the collinearity of the data: notably these bounds hold with high\nprobability even when $d_0$ is held constant versus $n$. We prove our results\nthrough a novel application of the hemisphere transform.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Kedar Karhadkar",
            "Michael Murray",
            "Guido Montúfar"
        ],
        "published": "2024-05-23T14:36:52Z"
    },
    {
        "title": "Which Experiences Are Influential for RL Agents? Efficiently Estimating\n  The Influence of Experiences",
        "link": "http://arxiv.org/abs/2405.14629v1",
        "abstract": "In reinforcement learning (RL) with experience replay, experiences stored in\na replay buffer influence the RL agent's performance. Information about the\ninfluence of these experiences is valuable for various purposes, such as\nidentifying experiences that negatively influence poorly performing RL agents.\nOne method for estimating the influence of experiences is the leave-one-out\n(LOO) method. However, this method is usually computationally prohibitive. In\nthis paper, we present Policy Iteration with Turn-over Dropout (PIToD), which\nefficiently estimates the influence of experiences. We evaluate how accurately\nPIToD estimates the influence of experiences and its efficiency compared to\nLOO. We then apply PIToD to amend poorly performing RL agents, i.e., we use\nPIToD to estimate negatively influential experiences for the RL agents and to\ndelete the influence of these experiences. We show that RL agents' performance\nis significantly improved via amendments with PIToD.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Takuya Hiraoka",
            "Guanquan Wang",
            "Takashi Onishi",
            "Yoshimasa Tsuruoka"
        ],
        "published": "2024-05-23T14:35:56Z"
    },
    {
        "title": "Event-based dataset for the detection and classification of\n  manufacturing assembly tasks",
        "link": "http://dx.doi.org/10.1016/j.dib.2024.110340",
        "abstract": "The featured dataset, the Event-based Dataset of Assembly Tasks (EDAT24),\nshowcases a selection of manufacturing primitive tasks (idle, pick, place, and\nscrew), which are basic actions performed by human operators in any\nmanufacturing assembly. The data were captured using a DAVIS240C event camera,\nan asynchronous vision sensor that registers events when changes in light\nintensity value occur. Events are a lightweight data format for conveying\nvisual information and are well-suited for real-time detection and analysis of\nhuman motion. Each manufacturing primitive has 100 recorded samples of\nDAVIS240C data, including events and greyscale frames, for a total of 400\nsamples. In the dataset, the user interacts with objects from the open-source\nCT-Benchmark in front of the static DAVIS event camera. All data are made\navailable in raw form (.aedat) and in pre-processed form (.npy). Custom-built\nPython code is made available together with the dataset to aid researchers to\nadd new manufacturing primitives or extend the dataset with more samples.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Laura Duarte",
            "Pedro Neto"
        ],
        "published": "2024-05-23T14:32:52Z"
    },
    {
        "title": "U-TELL: Unsupervised Task Expert Lifelong Learning",
        "link": "http://arxiv.org/abs/2405.14623v1",
        "abstract": "Continual learning (CL) models are designed to learn new tasks arriving\nsequentially without re-training the network. However, real-world ML\napplications have very limited label information and these models suffer from\ncatastrophic forgetting. To address these issues, we propose an unsupervised CL\nmodel with task experts called Unsupervised Task Expert Lifelong Learning\n(U-TELL) to continually learn the data arriving in a sequence addressing\ncatastrophic forgetting. During training of U-TELL, we introduce a new expert\non arrival of a new task. Our proposed architecture has task experts, a\nstructured data generator and a task assigner. Each task expert is composed of\n3 blocks; i) a variational autoencoder to capture the task distribution and\nperform data abstraction, ii) a k-means clustering module, and iii) a structure\nextractor to preserve latent task data signature. During testing, task assigner\nselects a suitable expert to perform clustering. U-TELL does not store or\nreplay task samples, instead, we use generated structured samples to train the\ntask assigner. We compared U-TELL with five SOTA unsupervised CL methods.\nU-TELL outperformed all baselines on seven benchmarks and one industry dataset\nfor various CL scenarios with a training time over 6 times faster than the best\nperforming baseline.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Indu Solomon",
            "Aye Phyu Phyu Aung",
            "Uttam Kumar",
            "Senthilnath Jayavelu"
        ],
        "published": "2024-05-23T14:31:53Z"
    },
    {
        "title": "Calibrated Self-Rewarding Vision Language Models",
        "link": "http://arxiv.org/abs/2405.14622v1",
        "abstract": "Large Vision-Language Models (LVLMs) have made substantial progress by\nintegrating pre-trained large language models (LLMs) and vision models through\ninstruction tuning. Despite these advancements, LVLMs often exhibit the\nhallucination phenomenon, where generated text responses appear linguistically\nplausible but contradict the input image, indicating a misalignment between\nimage and text pairs. This misalignment arises because the model tends to\nprioritize textual information over visual input, even when both the language\nmodel and visual representations are of high quality. Existing methods leverage\nadditional models or human annotations to curate preference data and enhance\nmodality alignment through preference optimization. These approaches may not\neffectively reflect the target LVLM's preferences, making the curated\npreferences easily distinguishable. Our work addresses these challenges by\nproposing the Calibrated Self-Rewarding (CSR) approach, which enables the model\nto self-improve by iteratively generating candidate responses, evaluating the\nreward for each response, and curating preference data for fine-tuning. In the\nreward modeling, we employ a step-wise strategy and incorporate visual\nconstraints into the self-rewarding process to place greater emphasis on visual\ninput. Empirical results demonstrate that CSR enhances performance and reduces\nhallucinations across ten benchmarks and tasks, achieving substantial\nimprovements over existing methods by 7.62%. Our empirical results are further\nsupported by rigorous theoretical analysis, under mild assumptions, verifying\nthe effectiveness of introducing visual constraints into the self-rewarding\nparadigm. Additionally, CSR shows compatibility with different vision-language\nmodels and the ability to incrementally improve performance through iterative\nfine-tuning. Our data and code are available at\nhttps://github.com/YiyangZhou/CSR.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.CV"
        ],
        "authors": [
            "Yiyang Zhou",
            "Zhiyuan Fan",
            "Dongjie Cheng",
            "Sihan Yang",
            "Zhaorun Chen",
            "Chenhang Cui",
            "Xiyao Wang",
            "Yun Li",
            "Linjun Zhang",
            "Huaxiu Yao"
        ],
        "published": "2024-05-23T14:30:33Z"
    },
    {
        "title": "Closed-form Symbolic Solutions: A New Perspective on Solving Partial\n  Differential Equations",
        "link": "http://arxiv.org/abs/2405.14620v1",
        "abstract": "Solving partial differential equations (PDEs) in Euclidean space with\nclosed-form symbolic solutions has long been a dream for mathematicians.\nInspired by deep learning, Physics-Informed Neural Networks (PINNs) have shown\ngreat promise in numerically solving PDEs. However, since PINNs essentially\napproximate solutions within the continuous function space, their numerical\nsolutions fall short in both precision and interpretability compared to\nsymbolic solutions. This paper proposes a novel framework: a closed-form\n\\textbf{Sym}bolic framework for \\textbf{PDE}s (SymPDE), exploring the use of\ndeep reinforcement learning to directly obtain symbolic solutions for PDEs.\nSymPDE alleviates the challenges PINNs face in fitting high-frequency and\nsteeply changing functions. To our knowledge, no prior work has implemented\nthis approach. Experiments on solving the Poisson's equation and heat equation\nin time-independent and spatiotemporal dynamical systems respectively\ndemonstrate that SymPDE can provide accurate closed-form symbolic solutions for\nvarious types of PDEs.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Shu Wei",
            "Yanjie Li",
            "Lina Yu",
            "Min Wu",
            "Weijun Li",
            "Meilan Hao",
            "Wenqiang Li",
            "Jingyi Liu",
            "Yusong Deng"
        ],
        "published": "2024-05-23T14:29:15Z"
    },
    {
        "title": "Generating Exceptional Behavior Tests with Reasoning Augmented Large\n  Language Models",
        "link": "http://arxiv.org/abs/2405.14619v2",
        "abstract": "Many popular programming languages, including C#, Java, and Python, support\nexceptions. Exceptions are thrown during program execution if an unwanted event\nhappens, e.g., a method is invoked with an illegal argument value. Software\ndevelopers write exceptional behavior tests (EBTs) to check that their code\ndetects unwanted events and throws appropriate exceptions. Prior research\nstudies have shown the importance of EBTs, but those studies also highlighted\nthat developers put most of their efforts on \"happy paths\", e.g., paths without\nunwanted events. To help developers fill the gap, we present the first\nframework, dubbed exLong, that automatically generates EBTs. exLong is a large\nlanguage model instruction-tuned from CodeLlama and embeds reasoning about\ntraces that lead to throw statements, conditional expressions that guard throw\nstatements, and non-exceptional behavior tests that execute similar traces. We\ncompare exLong with the state-of-the-art models for test generation (CAT-LM)\nand one of the strongest foundation models (GPT3.5), as well as with\nanalysis-based tools for test generation (Randoop and EvoSuite). Our results\nshow that exLong outperforms existing models and tools. Furthermore, we\ncontributed several pull requests to open-source projects and 23 EBTs generated\nby exLong were already accepted.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Jiyang Zhang",
            "Yu Liu",
            "Pengyu Nie",
            "Junyi Jessy Li",
            "Milos Gligoric"
        ],
        "published": "2024-05-23T14:28:41Z"
    },
    {
        "title": "TimeMixer: Decomposable Multiscale Mixing for Time Series Forecasting",
        "link": "http://arxiv.org/abs/2405.14616v1",
        "abstract": "Time series forecasting is widely used in extensive applications, such as\ntraffic planning and weather forecasting. However, real-world time series\nusually present intricate temporal variations, making forecasting extremely\nchallenging. Going beyond the mainstream paradigms of plain decomposition and\nmultiperiodicity analysis, we analyze temporal variations in a novel view of\nmultiscale-mixing, which is based on an intuitive but important observation\nthat time series present distinct patterns in different sampling scales. The\nmicroscopic and the macroscopic information are reflected in fine and coarse\nscales respectively, and thereby complex variations can be inherently\ndisentangled. Based on this observation, we propose TimeMixer as a fully\nMLP-based architecture with Past-Decomposable-Mixing (PDM) and\nFuture-Multipredictor-Mixing (FMM) blocks to take full advantage of\ndisentangled multiscale series in both past extraction and future prediction\nphases. Concretely, PDM applies the decomposition to multiscale series and\nfurther mixes the decomposed seasonal and trend components in fine-to-coarse\nand coarse-to-fine directions separately, which successively aggregates the\nmicroscopic seasonal and macroscopic trend information. FMM further ensembles\nmultiple predictors to utilize complementary forecasting capabilities in\nmultiscale observations. Consequently, TimeMixer is able to achieve consistent\nstate-of-the-art performances in both long-term and short-term forecasting\ntasks with favorable run-time efficiency.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Shiyu Wang",
            "Haixu Wu",
            "Xiaoming Shi",
            "Tengge Hu",
            "Huakun Luo",
            "Lintao Ma",
            "James Y. Zhang",
            "Jun Zhou"
        ],
        "published": "2024-05-23T14:27:07Z"
    },
    {
        "title": "Push and Pull: A Framework for Measuring Attentional Agency",
        "link": "http://arxiv.org/abs/2405.14614v1",
        "abstract": "We propose a framework for measuring attentional agency - the ability to\nallocate one's attention according to personal desires, goals, and intentions -\non digital platforms. Platforms extend people's limited powers of attention by\nextrapolating their preferences to large collections of previously unconsidered\ninformational objects. However, platforms typically also allow people to\ninfluence one another's attention. We introduce a formal framework for\nmeasuring how much a given platform empowers people to both pull information\ninto their own attentional field and push information into the attentional\nfields of others. We also use these definitions to shed light on the\nimplications of generative foundation models, which enable users to bypass the\nimplicit \"attentional bargain\" that underlies embedded advertising and other\nmethods for capturing economic value from informational goods. We conclude with\na set of policy strategies that can be used to understand and reshape the\ndistribution of attentional agency online.",
        "subjects": [
            "cs.CY",
            "cs.ET",
            "cs.IR"
        ],
        "authors": [
            "Zachary Wojtowicz",
            "Shrey Jain",
            "Nicholas Vincent"
        ],
        "published": "2024-05-23T14:26:04Z"
    },
    {
        "title": "Explaining Multi-modal Large Language Models by Analyzing their Vision\n  Perception",
        "link": "http://arxiv.org/abs/2405.14612v1",
        "abstract": "Multi-modal Large Language Models (MLLMs) have demonstrated remarkable\ncapabilities in understanding and generating content across various modalities,\nsuch as images and text. However, their interpretability remains a challenge,\nhindering their adoption in critical applications. This research proposes a\nnovel approach to enhance the interpretability of MLLMs by focusing on the\nimage embedding component. We combine an open-world localization model with a\nMLLM, thus creating a new architecture able to simultaneously produce text and\nobject localization outputs from the same vision embedding. The proposed\narchitecture greatly promotes interpretability, enabling us to design a novel\nsaliency map to explain any output token, to identify model hallucinations, and\nto assess model biases through semantic adversarial perturbations.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Loris Giulivi",
            "Giacomo Boracchi"
        ],
        "published": "2024-05-23T14:24:23Z"
    },
    {
        "title": "ShapeFormer: Shapelet Transformer for Multivariate Time Series\n  Classification",
        "link": "http://arxiv.org/abs/2405.14608v1",
        "abstract": "Multivariate time series classification (MTSC) has attracted significant\nresearch attention due to its diverse real-world applications. Recently,\nexploiting transformers for MTSC has achieved state-of-the-art performance.\nHowever, existing methods focus on generic features, providing a comprehensive\nunderstanding of data, but they ignore class-specific features crucial for\nlearning the representative characteristics of each class. This leads to poor\nperformance in the case of imbalanced datasets or datasets with similar overall\npatterns but differing in minor class-specific details. In this paper, we\npropose a novel Shapelet Transformer (ShapeFormer), which comprises\nclass-specific and generic transformer modules to capture both of these\nfeatures. In the class-specific module, we introduce the discovery method to\nextract the discriminative subsequences of each class (i.e. shapelets) from the\ntraining set. We then propose a Shapelet Filter to learn the difference\nfeatures between these shapelets and the input time series. We found that the\ndifference feature for each shapelet contains important class-specific\nfeatures, as it shows a significant distinction between its class and others.\nIn the generic module, convolution filters are used to extract generic features\nthat contain information to distinguish among all classes. For each module, we\nemploy the transformer encoder to capture the correlation between their\nfeatures. As a result, the combination of two transformer modules allows our\nmodel to exploit the power of both types of features, thereby enhancing the\nclassification performance. Our experiments on 30 UEA MTSC datasets demonstrate\nthat ShapeFormer has achieved the highest accuracy ranking compared to\nstate-of-the-art methods. The code is available at\nhttps://github.com/xuanmay2701/shapeformer.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Xuan-May Le",
            "Ling Luo",
            "Uwe Aickelin",
            "Minh-Tuan Tran"
        ],
        "published": "2024-05-23T14:21:35Z"
    },
    {
        "title": "Logical Characterizations of Recurrent Graph Neural Networks with Reals\n  and Floats",
        "link": "http://arxiv.org/abs/2405.14606v1",
        "abstract": "In pioneering work from 2019, Barcel\\'o and coauthors identified logics that\nprecisely match the expressive power of constant iteration-depth graph neural\nnetworks (GNNs) relative to properties definable in first-order logic. In this\narticle, we give exact logical characterizations of recurrent GNNs in two\nscenarios: (1) in the setting with floating-point numbers and (2) with reals.\nFor floats, the formalism matching recurrent GNNs is a rule-based modal logic\nwith counting, while for reals we use a suitable infinitary modal logic, also\nwith counting. These results give exact matches between logics and GNNs in the\nrecurrent setting without relativising to a background logic in either case,\nbut using some natural assumptions about floating-point arithmetic. Applying\nour characterizations, we also prove that, relative to graph properties\ndefinable in monadic second-order logic (MSO), our infinitary and rule-based\nlogics are equally expressive. This implies that recurrent GNNs with reals and\nfloats have the same expressive power over MSO-definable properties and shows\nthat, for such properties, also recurrent GNNs with reals are characterized by\na (finitary!) rule-based modal logic. In the general case, in contrast, the\nexpressive power with floats is weaker than with reals. In addition to\nlogic-oriented results, we also characterize recurrent GNNs, with both reals\nand floats, via distributed automata, drawing links to distributed computing\nmodels.",
        "subjects": [
            "cs.LO",
            "cs.AI",
            "F.4.1; F.1.1; I.2.0"
        ],
        "authors": [
            "Veeti Ahvonen",
            "Damian Heiman",
            "Antti Kuusisto",
            "Carsten Lutz"
        ],
        "published": "2024-05-23T14:19:21Z"
    },
    {
        "title": "Spectral analysis of block preconditioners for double saddle-point\n  linear systems with application to PDE-constrained optimization",
        "link": "http://arxiv.org/abs/2405.14605v2",
        "abstract": "In this paper, we describe and analyze the spectral properties of a symmetric\npositive definite inexact block preconditioner for a class of symmetric, double\nsaddle-point linear systems.\n  We develop a spectral analysis of the preconditioned matrix, showing that its\neigenvalues can be described in terms of the roots of a cubic polynomial with\nreal coefficients.\n  We illustrate the efficiency of the proposed preconditioners, and verify the\ntheoretical bounds, in solving large-scale PDE-constrained optimization\nproblems.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Luca Bergamaschi",
            "Angeles Martinez",
            "John Pearson",
            "Andreas Potschka"
        ],
        "published": "2024-05-23T14:17:33Z"
    },
    {
        "title": "A Watermark for Low-entropy and Unbiased Generation in Large Language\n  Models",
        "link": "http://arxiv.org/abs/2405.14604v1",
        "abstract": "Recent advancements in large language models (LLMs) have highlighted the risk\nof misuse, raising concerns about accurately detecting LLM-generated content. A\nviable solution for the detection problem is to inject imperceptible\nidentifiers into LLMs, known as watermarks. Previous work demonstrates that\nunbiased watermarks ensure unforgeability and preserve text quality by\nmaintaining the expectation of the LLM output probability distribution.\nHowever, previous unbiased watermarking methods are impractical for local\ndeployment because they rely on accesses to white-box LLMs and input prompts\nduring detection. Moreover, these methods fail to provide statistical\nguarantees for the type II error of watermark detection. This study proposes\nthe Sampling One Then Accepting (STA-1) method, an unbiased watermark that does\nnot require access to LLMs nor prompts during detection and has statistical\nguarantees for the type II error. Moreover, we propose a novel tradeoff between\nwatermark strength and text quality in unbiased watermarks. We show that in\nlow-entropy scenarios, unbiased watermarks face a tradeoff between watermark\nstrength and the risk of unsatisfactory outputs. Experimental results on\nlow-entropy and high-entropy datasets demonstrate that STA-1 achieves text\nquality and watermark strength comparable to existing unbiased watermarks, with\na low risk of unsatisfactory outputs. Implementation codes for this study are\navailable online.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Minjia Mao",
            "Dongjun Wei",
            "Zeyu Chen",
            "Xiao Fang",
            "Michael Chau"
        ],
        "published": "2024-05-23T14:17:29Z"
    },
    {
        "title": "Controllable Continual Test-Time Adaptation",
        "link": "http://arxiv.org/abs/2405.14602v1",
        "abstract": "Continual Test-Time Adaptation (CTTA) is an emerging and challenging task\nwhere a model trained in a source domain must adapt to continuously changing\nconditions during testing, without access to the original source data. CTTA is\nprone to error accumulation due to uncontrollable domain shifts, leading to\nblurred decision boundaries between categories. Existing CTTA methods primarily\nfocus on suppressing domain shifts, which proves inadequate during the\nunsupervised test phase. In contrast, we introduce a novel approach that guides\nrather than suppresses these shifts. Specifically, we propose\n$\\textbf{C}$ontrollable $\\textbf{Co}$ntinual $\\textbf{T}$est-$\\textbf{T}$ime\n$\\textbf{A}$daptation (C-CoTTA), which explicitly prevents any single category\nfrom encroaching on others, thereby mitigating the mutual influence between\ncategories caused by uncontrollable shifts. Moreover, our method reduces the\nsensitivity of model to domain transformations, thereby minimizing the\nmagnitude of category shifts. Extensive quantitative experiments demonstrate\nthe effectiveness of our method, while qualitative analyses, such as t-SNE\nplots, confirm the theoretical validity of our approach.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ziqi Shi",
            "Fan Lyu",
            "Ye Liu",
            "Fanhua Shang",
            "Fuyuan Hu",
            "Wei Feng",
            "Zhang Zhang",
            "Liang Wang"
        ],
        "published": "2024-05-23T14:17:01Z"
    },
    {
        "title": "A FAIR and Free Prompt-based Research Assistant",
        "link": "http://arxiv.org/abs/2405.14601v1",
        "abstract": "This demo will present the Research Assistant (RA) tool developed to assist\nwith six main types of research tasks defined as standardized instruction\ntemplates, instantiated with user input, applied finally as prompts to\nwell-known--for their sophisticated natural language processing abilities--AI\ntools, such as ChatGPT (https://chat.openai.com/) and Gemini\n(https://gemini.google.com/app). The six research tasks addressed by RA are:\ncreating FAIR research comparisons, ideating research topics, drafting grant\napplications, writing scientific blogs, aiding preliminary peer reviews, and\nformulating enhanced literature search queries. RA's reliance on generative AI\ntools like ChatGPT or Gemini means the same research task assistance can be\noffered in any scientific discipline. We demonstrate its versatility by sharing\nRA outputs in Computer Science, Virology, and Climate Science, where the output\nwith the RA tool assistance mirrored that from a domain expert who performed\nthe same research task.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Mahsa Shamsabadi",
            "Jennifer D'Souza"
        ],
        "published": "2024-05-23T14:16:46Z"
    },
    {
        "title": "Discretization of continuous input spaces in the hippocampal autoencoder",
        "link": "http://arxiv.org/abs/2405.14600v1",
        "abstract": "The hippocampus has been associated with both spatial cognition and episodic\nmemory formation, but integrating these functions into a unified framework\nremains challenging. Here, we demonstrate that forming discrete memories of\nvisual events in sparse autoencoder neurons can produce spatial tuning similar\nto hippocampal place cells. We then show that the resulting very\nhigh-dimensional code enables neurons to discretize and tile the underlying\nimage space with minimal overlap. Additionally, we extend our results to the\nauditory domain, showing that neurons similarly tile the frequency space in an\nexperience-dependent manner. Lastly, we show that reinforcement learning agents\ncan effectively perform various visuo-spatial cognitive tasks using these\nsparse, very high-dimensional representations.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "q-bio.NC"
        ],
        "authors": [
            "Adrian F. Amil",
            "Ismael T. Freire",
            "Paul F. M. J. Verschure"
        ],
        "published": "2024-05-23T14:16:44Z"
    },
    {
        "title": "Neuroexplicit Diffusion Models for Inpainting of Optical Flow Fields",
        "link": "http://arxiv.org/abs/2405.14599v1",
        "abstract": "Deep learning has revolutionized the field of computer vision by introducing\nlarge scale neural networks with millions of parameters. Training these\nnetworks requires massive datasets and leads to intransparent models that can\nfail to generalize. At the other extreme, models designed from partial\ndifferential equations (PDEs) embed specialized domain knowledge into\nmathematical equations and usually rely on few manually chosen hyperparameters.\nThis makes them transparent by construction and if designed and calibrated\ncarefully, they can generalize well to unseen scenarios. In this paper, we show\nhow to bring model- and data-driven approaches together by combining the\nexplicit PDE-based approaches with convolutional neural networks to obtain the\nbest of both worlds. We illustrate a joint architecture for the task of\ninpainting optical flow fields and show that the combination of model- and\ndata-driven modeling leads to an effective architecture. Our model outperforms\nboth fully explicit and fully data-driven baselines in terms of reconstruction\nquality, robustness and amount of required training data. Averaging the\nendpoint error across different mask densities, our method outperforms the\nexplicit baselines by 11-27%, the GAN baseline by 47% and the Probabilisitic\nDiffusion baseline by 42%. With that, our method sets a new state of the art\nfor inpainting of optical flow fields from random masks.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Tom Fischer",
            "Pascal Peter",
            "Joachim Weickert",
            "Eddy Ilg"
        ],
        "published": "2024-05-23T14:14:27Z"
    },
    {
        "title": "Visual Echoes: A Simple Unified Transformer for Audio-Visual Generation",
        "link": "http://arxiv.org/abs/2405.14598v2",
        "abstract": "In recent years, with the realistic generation results and a wide range of\npersonalized applications, diffusion-based generative models gain huge\nattention in both visual and audio generation areas. Compared to the\nconsiderable advancements of text2image or text2audio generation, research in\naudio2visual or visual2audio generation has been relatively slow. The recent\naudio-visual generation methods usually resort to huge large language model or\ncomposable diffusion models. Instead of designing another giant model for\naudio-visual generation, in this paper we take a step back showing a simple and\nlightweight generative transformer, which is not fully investigated in\nmulti-modal generation, can achieve excellent results on image2audio\ngeneration. The transformer operates in the discrete audio and visual\nVector-Quantized GAN space, and is trained in the mask denoising manner. After\ntraining, the classifier-free guidance could be deployed off-the-shelf\nachieving better performance, without any extra training or modification. Since\nthe transformer model is modality symmetrical, it could also be directly\ndeployed for audio2image generation and co-generation. In the experiments, we\nshow that our simple method surpasses recent image2audio generation methods.\nGenerated audio samples can be found at\nhttps://docs.google.com/presentation/d/1ZtC0SeblKkut4XJcRaDsSTuCRIXB3ypxmSi7HTY3IyQ/",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "cs.MM",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Shiqi Yang",
            "Zhi Zhong",
            "Mengjie Zhao",
            "Shusuke Takahashi",
            "Masato Ishii",
            "Takashi Shibuya",
            "Yuki Mitsufuji"
        ],
        "published": "2024-05-23T14:13:16Z"
    },
    {
        "title": "Integer Scale: A Free Lunch for Faster Fine-grained Quantization of LLMs",
        "link": "http://arxiv.org/abs/2405.14597v1",
        "abstract": "We introduce Integer Scale, a novel post-training quantization scheme for\nlarge language models that effectively resolves the inference bottleneck in\ncurrent fine-grained quantization approaches while maintaining similar\naccuracies. Integer Scale is a free lunch as it requires no extra calibration\nor fine-tuning which will otherwise incur additional costs. It can be used\nplug-and-play for most fine-grained quantization methods. Its integration\nresults in at most 1.85x end-to-end speed boost over the original counterpart\nwith comparable accuracy. Additionally, due to the orchestration of the\nproposed Integer Scale and fine-grained quantization, we resolved the\nquantization difficulty for Mixtral-8x7B and LLaMA-3 models with negligible\nperformance degradation, and it comes with an end-to-end speed boost of 2.13x,\nand 2.31x compared with their FP16 versions respectively.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Qingyuan Li",
            "Ran Meng",
            "Yiduo Li",
            "Bo Zhang",
            "Yifan Lu",
            "Yerui Sun",
            "Lin Ma",
            "Yuchen Xie"
        ],
        "published": "2024-05-23T14:12:58Z"
    },
    {
        "title": "Linear Mode Connectivity in Differentiable Tree Ensembles",
        "link": "http://arxiv.org/abs/2405.14596v1",
        "abstract": "Linear Mode Connectivity (LMC) refers to the phenomenon that performance\nremains consistent for linearly interpolated models in the parameter space. For\nindependently optimized model pairs from different random initializations,\nachieving LMC is considered crucial for validating the stable success of the\nnon-convex optimization in modern machine learning models and for facilitating\npractical parameter-based operations such as model merging. While LMC has been\nachieved for neural networks by considering the permutation invariance of\nneurons in each hidden layer, its attainment for other models remains an open\nquestion. In this paper, we first achieve LMC for soft tree ensembles, which\nare tree-based differentiable models extensively used in practice. We show the\nnecessity of incorporating two invariances: subtree flip invariance and\nsplitting order invariance, which do not exist in neural networks but are\ninherent to tree architectures, in addition to permutation invariance of trees.\nMoreover, we demonstrate that it is even possible to exclude such additional\ninvariances while keeping LMC by designing decision list-based tree\narchitectures, where such invariances do not exist by definition. Our findings\nindicate the significance of accounting for architecture-specific invariances\nin achieving LMC.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ryuichi Kanoh",
            "Mahito Sugiyama"
        ],
        "published": "2024-05-23T14:11:26Z"
    },
    {
        "title": "Elastic Locomotion with Mixed Second-order Differentiation",
        "link": "http://arxiv.org/abs/2405.14595v1",
        "abstract": "We present a framework of elastic locomotion, which allows users to enliven\nan elastic body to produce interesting locomotion by prescribing its high-level\nkinematics. We formulate this problem as an inverse simulation problem and seek\nthe optimal muscle activations to drive the body to complete the desired\nactions. We employ the interior-point method to model wide-area contacts\nbetween the body and the environment with logarithmic barrier penalties. The\ncore of our framework is a mixed second-order differentiation algorithm. By\ncombining both analytic differentiation and numerical differentiation\nmodalities, a general-purpose second-order differentiation scheme is made\npossible. Specifically, we augment complex-step finite difference (CSFD) with\nreverse automatic differentiation (AD). We treat AD as a generic function,\nmapping a computing procedure to its derivative w.r.t. output loss, and promote\nCSFD along the AD computation. To this end, we carefully implement all the\narithmetics used in elastic locomotion, from elementary functions to linear\nalgebra and matrix operation for CSFD promotion. With this novel\ndifferentiation tool, elastic locomotion can directly exploit Newton's method\nand use its strong second-order convergence to find the needed activations at\nmuscle fibers. This is not possible with existing first-order inverse or\ndifferentiable simulation techniques. We showcase a wide range of interesting\nlocomotions of soft bodies and creatures to validate our method.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Siyuan Shen",
            "Tianjia Shao",
            "Kun Zhou",
            "Chenfanfu Jiang",
            "Sheldon Andrews",
            "Victor Zordan",
            "Yin Yang"
        ],
        "published": "2024-05-23T14:11:03Z"
    },
    {
        "title": "Data Augmentation Techniques for Process Extraction from Scientific\n  Publications",
        "link": "http://arxiv.org/abs/2405.14594v1",
        "abstract": "We present data augmentation techniques for process extraction tasks in\nscientific publications. We cast the process extraction task as a sequence\nlabeling task where we identify all the entities in a sentence and label them\naccording to their process-specific roles. The proposed method attempts to\ncreate meaningful augmented sentences by utilizing (1) process-specific\ninformation from the original sentence, (2) role label similarity, and (3)\nsentence similarity. We demonstrate that the proposed methods substantially\nimprove the performance of the process extraction model trained on chemistry\ndomain datasets, up to 12.3 points improvement in performance accuracy\n(F-score). The proposed methods could potentially reduce overfitting as well,\nespecially when training on small datasets or in a low-resource setting such as\nin chemistry and other scientific domains.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "authors": [
            "Yuni Susanti"
        ],
        "published": "2024-05-23T14:09:02Z"
    },
    {
        "title": "Base of RoPE Bounds Context Length",
        "link": "http://arxiv.org/abs/2405.14591v1",
        "abstract": "Position embedding is a core component of current Large Language Models\n(LLMs). Rotary position embedding (RoPE), a technique that encodes the position\ninformation with a rotation matrix, has been the de facto choice for position\nembedding in many LLMs, such as the Llama series. RoPE has been further\nutilized to extend long context capability, which is roughly based on adjusting\nthe \\textit{base} parameter of RoPE to mitigate out-of-distribution (OOD)\nproblems in position embedding. However, in this paper, we find that LLMs may\nobtain a superficial long-context ability based on the OOD theory. We revisit\nthe role of RoPE in LLMs and propose a novel property of long-term decay, we\nderive that the \\textit{base of RoPE bounds context length}: there is an\nabsolute lower bound for the base value to obtain certain context length\ncapability. Our work reveals the relationship between context length and RoPE\nbase both theoretically and empirically, which may shed light on future long\ncontext training.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Xin Men",
            "Mingyu Xu",
            "Bingning Wang",
            "Qingyu Zhang",
            "Hongyu Lin",
            "Xianpei Han",
            "Weipeng Chen"
        ],
        "published": "2024-05-23T14:03:31Z"
    },
    {
        "title": "MAMOC: MRI Motion Correction via Masked Autoencoding",
        "link": "http://arxiv.org/abs/2405.14590v1",
        "abstract": "The presence of motion artifacts in magnetic resonance imaging (MRI) scans\nposes a significant challenge, where even minor patient movements can lead to\nartifacts that may compromise the scan's utility. This paper introduces Masked\nMotion Correction (MAMOC), a novel method designed to address the issue of\nRetrospective Artifact Correction (RAC) in motion-affected MRI brain scans.\nMAMOC uses masked autoencoding self-supervision and test-time prediction to\nefficiently remove motion artifacts, producing state-of-the-art, native\nresolution scans. Until recently, realistic data to evaluate retrospective\nmotion correction methods did not exist, motion artifacts had to be simulated.\nLeveraging the MR-ART dataset, this work is the first to evaluate motion\ncorrection in MRI scans using real motion data, showing the superiority of\nMAMOC to existing motion correction (MC) methods.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Lennart Alexander Van der Goten",
            "Jingyu Guo",
            "Kevin Smith"
        ],
        "published": "2024-05-23T14:01:22Z"
    },
    {
        "title": "Top-Down Partitioning for Efficient List-Wise Ranking",
        "link": "http://arxiv.org/abs/2405.14589v1",
        "abstract": "Large Language Models (LLMs) have significantly impacted many facets of\nnatural language processing and information retrieval. Unlike previous\nencoder-based approaches, the enlarged context window of these generative\nmodels allows for ranking multiple documents at once, commonly called list-wise\nranking. However, there are still limits to the number of documents that can be\nranked in a single inference of the model, leading to the broad adoption of a\nsliding window approach to identify the k most relevant items in a ranked list.\nWe argue that the sliding window approach is not well-suited for list-wise\nre-ranking because it (1) cannot be parallelized in its current form, (2) leads\nto redundant computational steps repeatedly re-scoring the best set of\ndocuments as it works its way up the initial ranking, and (3) prioritizes the\nlowest-ranked documents for scoring rather than the highest-ranked documents by\ntaking a bottom-up approach. Motivated by these shortcomings and an initial\nstudy that shows list-wise rankers are biased towards relevant documents at the\nstart of their context window, we propose a novel algorithm that partitions a\nranking to depth k and processes documents top-down. Unlike sliding window\napproaches, our algorithm is inherently parallelizable due to the use of a\npivot element, which can be compared to documents down to an arbitrary depth\nconcurrently. In doing so, we reduce the number of expected inference calls by\naround 33% when ranking at depth 100 while matching the performance of prior\napproaches across multiple strong re-rankers.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Andrew Parry",
            "Sean MacAvaney",
            "Debasis Ganguly"
        ],
        "published": "2024-05-23T14:00:26Z"
    },
    {
        "title": "SE3D: A Framework For Saliency Method Evaluation In 3D Imaging",
        "link": "http://arxiv.org/abs/2405.14584v1",
        "abstract": "For more than a decade, deep learning models have been dominating in various\n2D imaging tasks. Their application is now extending to 3D imaging, with 3D\nConvolutional Neural Networks (3D CNNs) being able to process LIDAR, MRI, and\nCT scans, with significant implications for fields such as autonomous driving\nand medical imaging. In these critical settings, explaining the model's\ndecisions is fundamental. Despite recent advances in Explainable Artificial\nIntelligence, however, little effort has been devoted to explaining 3D CNNs,\nand many works explain these models via inadequate extensions of 2D saliency\nmethods.\n  One fundamental limitation to the development of 3D saliency methods is the\nlack of a benchmark to quantitatively assess them on 3D data. To address this\nissue, we propose SE3D: a framework for Saliency method Evaluation in 3D\nimaging. We propose modifications to ShapeNet, ScanNet, and BraTS datasets, and\nevaluation metrics to assess saliency methods for 3D CNNs. We evaluate both\nstate-of-the-art saliency methods designed for 3D data and extensions of\npopular 2D saliency methods to 3D. Our experiments show that 3D saliency\nmethods do not provide explanations of sufficient quality, and that there is\nmargin for future improvements and safer applications of 3D CNNs in critical\nfields.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Mariusz Wiśniewski",
            "Loris Giulivi",
            "Giacomo Boracchi"
        ],
        "published": "2024-05-23T13:55:11Z"
    },
    {
        "title": "PoseCrafter: One-Shot Personalized Video Synthesis Following Flexible\n  Pose Control",
        "link": "http://arxiv.org/abs/2405.14582v2",
        "abstract": "In this paper, we introduce PoseCrafter, a one-shot method for personalized\nvideo generation following the control of flexible poses. Built upon Stable\nDiffusion and ControlNet, we carefully design an inference process to produce\nhigh-quality videos without the corresponding ground-truth frames. First, we\nselect an appropriate reference frame from the training video and invert it to\ninitialize all latent variables for generation. Then, we insert the\ncorresponding training pose into the target pose sequences to enhance\nfaithfulness through a trained temporal attention module. Furthermore, to\nalleviate the face and hand degradation resulting from discrepancies between\nposes of training videos and inference poses, we implement simple latent\nediting through an affine transformation matrix involving facial and hand\nlandmarks. Extensive experiments on several datasets demonstrate that\nPoseCrafter achieves superior results to baselines pre-trained on a vast\ncollection of videos under 8 commonly used metrics. Besides, PoseCrafter can\nfollow poses from different individuals or artificial edits and simultaneously\nretain the human identity in an open-domain training video. Our project page is\navailable at https://ml-gsai.github.io/PoseCrafter-demo/.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Yong Zhong",
            "Min Zhao",
            "Zebin You",
            "Xiaofeng Yu",
            "Changwang Zhang",
            "Chongxuan Li"
        ],
        "published": "2024-05-23T13:53:50Z"
    },
    {
        "title": "LDM: Large Tensorial SDF Model for Textured Mesh Generation",
        "link": "http://arxiv.org/abs/2405.14580v1",
        "abstract": "Previous efforts have managed to generate production-ready 3D assets from\ntext or images. However, these methods primarily employ NeRF or 3D Gaussian\nrepresentations, which are not adept at producing smooth, high-quality\ngeometries required by modern rendering pipelines. In this paper, we propose\nLDM, a novel feed-forward framework capable of generating high-fidelity,\nillumination-decoupled textured mesh from a single image or text prompts. We\nfirstly utilize a multi-view diffusion model to generate sparse multi-view\ninputs from single images or text prompts, and then a transformer-based model\nis trained to predict a tensorial SDF field from these sparse multi-view image\ninputs. Finally, we employ a gradient-based mesh optimization layer to refine\nthis model, enabling it to produce an SDF field from which high-quality\ntextured meshes can be extracted. Extensive experiments demonstrate that our\nmethod can generate diverse, high-quality 3D mesh assets with corresponding\ndecomposed RGB textures within seconds.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Rengan Xie",
            "Wenting Zheng",
            "Kai Huang",
            "Yizheng Chen",
            "Qi Wang",
            "Qi Ye",
            "Wei Chen",
            "Yuchi Huo"
        ],
        "published": "2024-05-23T13:53:17Z"
    },
    {
        "title": "Surge Phenomenon in Optimal Learning Rate and Batch Size Scaling",
        "link": "http://arxiv.org/abs/2405.14578v1",
        "abstract": "In current deep learning tasks, Adam style optimizers such as Adam, Adagrad,\nRMSProp, Adafactor, and Lion have been widely used as alternatives to SGD style\noptimizers. These optimizers typically update model parameters using the sign\nof gradients, resulting in more stable convergence curves. The learning rate\nand the batch size are the most critical hyperparameters for optimizers, which\nrequire careful tuning to enable effective convergence. Previous research has\nshown that the optimal learning rate increases linearly or follows similar\nrules with batch size for SGD style optimizers. However, this conclusion is not\napplicable to Adam style optimizers. In this paper, we elucidate the connection\nbetween optimal learning rates and batch sizes for Adam style optimizers\nthrough both theoretical analysis and extensive experiments. First, we raise\nthe scaling law between batch sizes and optimal learning rates in the sign of\ngradient case, in which we prove that the optimal learning rate first rises and\nthen falls as the batch size increases. Moreover, the peak value of the surge\nwill gradually move toward the larger batch size as training progresses.\nSecond, we conducted experiments on various CV and NLP tasks and verified the\ncorrectness of the scaling law.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Shuaipeng Li",
            "Penghao Zhao",
            "Hailin Zhang",
            "Xingwu Sun",
            "Hao Wu",
            "Dian Jiao",
            "Weiyan Wang",
            "Chengjun Liu",
            "Zheng Fang",
            "Jinbao Xue",
            "Yangyu Tao",
            "Bin Cui",
            "Di Wang"
        ],
        "published": "2024-05-23T13:52:36Z"
    },
    {
        "title": "Representation noising effectively prevents harmful fine-tuning on LLMs",
        "link": "http://arxiv.org/abs/2405.14577v1",
        "abstract": "Releasing open-source large language models (LLMs) presents a dual-use risk\nsince bad actors can easily fine-tune these models for harmful purposes. Even\nwithout the open release of weights, weight stealing and fine-tuning APIs make\nclosed models vulnerable to harmful fine-tuning attacks (HFAs). While safety\nmeasures like preventing jailbreaks and improving safety guardrails are\nimportant, such measures can easily be reversed through fine-tuning. In this\nwork, we propose Representation Noising (RepNoise), a defence mechanism that is\neffective even when attackers have access to the weights and the defender no\nlonger has any control. RepNoise works by removing information about harmful\nrepresentations such that it is difficult to recover them during fine-tuning.\nImportantly, our defence is also able to generalize across different subsets of\nharm that have not been seen during the defence process. Our method does not\ndegrade the general capability of LLMs and retains the ability to train the\nmodel on harmless tasks. We provide empirical evidence that the effectiveness\nof our defence lies in its \"depth\": the degree to which information about\nharmful representations is removed across all layers of the LLM.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Domenic Rosati",
            "Jan Wehner",
            "Kai Williams",
            "Łukasz Bartoszcze",
            "David Atanasov",
            "Robie Gonzales",
            "Subhabrata Majumdar",
            "Carsten Maple",
            "Hassan Sajjad",
            "Frank Rudzicz"
        ],
        "published": "2024-05-23T13:51:55Z"
    },
    {
        "title": "Share-Based Fairness for Arbitrary Entitlements",
        "link": "http://arxiv.org/abs/2405.14575v1",
        "abstract": "We consider the problem of fair allocation of indivisible items to agents\nthat have arbitrary entitlements to the items. Every agent $i$ has a valuation\nfunction $v_i$ and an entitlement $b_i$, where entitlements sum up to~1. Which\nallocation should one choose in situations in which agents fail to agree on one\nacceptable fairness notion? We study this problem in the case in which each\nagent focuses on the value she gets, and fairness notions are restricted to be\n{\\em share based}. A {\\em share} $s$ is an function that maps every $(v_i,b_i)$\nto a value $s(v_i,b_i)$, representing the minimal value $i$ should get, and $s$\nis {\\em feasible} if it is always possible to give every agent $i$ value of at\nleast $s(v_i,b_i)$.\n  Our main result is that for additive valuations over goods there is an\nallocation that gives every agent at least half her share value, regardless of\nwhich feasible share-based fairness notion the agent wishes to use. Moreover,\nthe ratio of half is best possible. More generally, we provide tight\ncharacterizations of what can be achieved, both ex-post (as single allocations)\nand ex-ante (as expected values of distributions of allocations), both for\ngoods and for chores. We also show that for chores one can achieve the ex-ante\nand ex-post guarantees simultaneously (a ``best of both world\" result), whereas\nfor goods one cannot.",
        "subjects": [
            "cs.GT",
            "econ.TH"
        ],
        "authors": [
            "Moshe Babaioff",
            "Uriel Feige"
        ],
        "published": "2024-05-23T13:50:01Z"
    },
    {
        "title": "Learning with Fitzpatrick Losses",
        "link": "http://arxiv.org/abs/2405.14574v1",
        "abstract": "Fenchel-Young losses are a family of convex loss functions, encompassing the\nsquared, logistic and sparsemax losses, among others. Each Fenchel-Young loss\nis implicitly associated with a link function, for mapping model outputs to\npredictions. For instance, the logistic loss is associated with the soft argmax\nlink function. Can we build new loss functions associated with the same link\nfunction as Fenchel-Young losses? In this paper, we introduce Fitzpatrick\nlosses, a new family of convex loss functions based on the Fitzpatrick\nfunction. A well-known theoretical tool in maximal monotone operator theory,\nthe Fitzpatrick function naturally leads to a refined Fenchel-Young inequality,\nmaking Fitzpatrick losses tighter than Fenchel-Young losses, while maintaining\nthe same link function for prediction. As an example, we introduce the\nFitzpatrick logistic loss and the Fitzpatrick sparsemax loss, counterparts of\nthe logistic and the sparsemax losses. This yields two new tighter losses\nassociated with the soft argmax and the sparse argmax, two of the most\nubiquitous output layers used in machine learning. We study in details the\nproperties of Fitzpatrick losses and in particular, we show that they can be\nseen as Fenchel-Young losses using a modified, target-dependent generating\nfunction. We demonstrate the effectiveness of Fitzpatrick losses for label\nproportion estimation.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Seta Rakotomandimby",
            "Jean-Philippe Chancelier",
            "Michel de Lara",
            "Mathieu Blondel"
        ],
        "published": "2024-05-23T13:49:37Z"
    },
    {
        "title": "AndroidWorld: A Dynamic Benchmarking Environment for Autonomous Agents",
        "link": "http://arxiv.org/abs/2405.14573v1",
        "abstract": "Autonomous agents that execute human tasks by controlling computers can\nenhance human productivity and application accessibility. Yet, progress in this\nfield will be driven by realistic and reproducible benchmarks. We present\nAndroidWorld, a fully functioning Android environment that provides reward\nsignals for 116 programmatic task workflows across 20 real world Android\napplications. Unlike existing interactive environments, which provide a static\ntest set, AndroidWorld dynamically constructs tasks that are parameterized and\nexpressed in natural language in unlimited ways, thus enabling testing on a\nmuch larger and realistic suite of tasks. Reward signals are derived from the\ncomputer's system state, making them durable across task variations and\nextensible across different apps. To demonstrate AndroidWorld's benefits and\nmode of operation, we introduce a new computer control agent, M3A. M3A can\ncomplete 30.6% of the AndroidWorld's tasks, leaving ample room for future work.\nFurthermore, we adapt a popular desktop web agent to work on Android, which we\nfind to be less effective on mobile, suggesting future research is needed to\nachieve universal, cross-domain agents. Finally, we conduct a robustness\nanalysis by testing M3A against a range of task variations on a representative\nsubset of tasks, demonstrating that variations in task parameters can\nsignificantly alter the complexity of a task and therefore an agent's\nperformance, highlighting the importance of testing agents under diverse\nconditions. AndroidWorld and the experiments in this paper are available at\nhttps://github.com/google-research/android_world.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Christopher Rawles",
            "Sarah Clinckemaillie",
            "Yifan Chang",
            "Jonathan Waltz",
            "Gabrielle Lau",
            "Marybeth Fair",
            "Alice Li",
            "William Bishop",
            "Wei Li",
            "Folawiyo Campbell-Ajala",
            "Daniel Toyama",
            "Robert Berry",
            "Divya Tyamagundlu",
            "Timothy Lillicrap",
            "Oriana Riva"
        ],
        "published": "2024-05-23T13:48:54Z"
    },
    {
        "title": "Multicontinuum Homogenization for Coupled Flow and Transport Equations",
        "link": "http://arxiv.org/abs/2405.14572v1",
        "abstract": "In this paper, we present the derivation of a multicontinuum model for the\ncoupled flow and transport equations by applying multicontinuum homogenization.\nWe perform the multicontinuum expansion for both flow and transport solutions\nand formulate novel coupled constraint cell problems to capture the multiscale\nproperty, where oversampled regions are utilized to avoid boundary effects.\nAssuming the smoothness of macroscopic variables, we obtain a multicontinuum\nsystem composed of macroscopic elliptic equations and\nconvection-diffusion-reaction equations with homogenized effective properties.\nFinally, we present numerical results for various coefficient fields and\nboundary conditions to validate our proposed algorithm.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Dmitry Ammosov",
            "W. T. Leung",
            "Buzheng Shan",
            "Jian Huang"
        ],
        "published": "2024-05-23T13:47:31Z"
    },
    {
        "title": "A general method for the development of constrained codes",
        "link": "http://arxiv.org/abs/2405.14570v1",
        "abstract": "Nowadays there are several classes of constrained codes intended for\ndifferent applications. The following two large classes can be distinguished.\nThe first class contains codes with local constraints; for example, the source\ndata must be encoded by binary sequences containing no sub-words 00 and 111.\nThe second class contains codes with global constraints; for example, the\ncode-words must be binary sequences of certain even length with half zeros and\nhalf ones.It is important to note that often the necessary codes must fulfill\nsome requirements of both classes.\n  In this paper we propose a general polynomial complexity method for\nconstructing codes for both classes, as well as for combinations thereof. The\nproposed method uses the enumerative Cover's code, but the main difference\nbetween known applications of this code is that the known algorithms require\nthe use of combinatorial formulae when applied, whereas the proposed method\ncalculates all parameters on-the-fly using a polynomial complexity algorithm.",
        "subjects": [
            "cs.IT",
            "math.IT",
            "94A29"
        ],
        "authors": [
            "Boris Ryabko"
        ],
        "published": "2024-05-23T13:46:25Z"
    },
    {
        "title": "PrivCirNet: Efficient Private Inference via Block Circulant\n  Transformation",
        "link": "http://arxiv.org/abs/2405.14569v1",
        "abstract": "Homomorphic encryption (HE)-based deep neural network (DNN) inference\nprotects data and model privacy but suffers from significant computation\noverhead. We observe transforming the DNN weights into circulant matrices\nconverts general matrix-vector multiplications into HE-friendly 1-dimensional\nconvolutions, drastically reducing the HE computation cost. Hence, in this\npaper, we propose \\method, a protocol/network co-optimization framework based\non block circulant transformation. At the protocol level, PrivCirNet customizes\nthe HE encoding algorithm that is fully compatible with the block circulant\ntransformation and reduces the computation latency in proportion to the block\nsize. At the network level, we propose a latency-aware formulation to search\nfor the layer-wise block size assignment based on second-order information.\nPrivCirNet also leverages layer fusion to further reduce the inference cost. We\ncompare PrivCirNet with the state-of-the-art HE-based framework Bolt (IEEE S\\&P\n2024) and the HE-friendly pruning method SpENCNN (ICML 2023). For ResNet-18 and\nVision Transformer (ViT) on Tiny ImageNet, PrivCirNet reduces latency by\n$5.0\\times$ and $1.3\\times$ with iso-accuracy over Bolt, respectively, and\nimproves accuracy by $4.1\\%$ and $12\\%$ over SpENCNN, respectively. For\nMobileNetV2 on ImageNet, PrivCirNet achieves $1.7\\times$ lower latency and\n$4.2\\%$ better accuracy over Bolt and SpENCNN, respectively. Our code and\ncheckpoints are available in the supplementary materials.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "authors": [
            "Tianshi Xu",
            "Lemeng Wu",
            "Runsheng Wang",
            "Meng Li"
        ],
        "published": "2024-05-23T13:44:48Z"
    },
    {
        "title": "EHRMamba: Towards Generalizable and Scalable Foundation Models for\n  Electronic Health Records",
        "link": "http://arxiv.org/abs/2405.14567v2",
        "abstract": "Transformers have significantly advanced the modeling of Electronic Health\nRecords (EHR), yet their deployment in real-world healthcare is limited by\nseveral key challenges. Firstly, the quadratic computational cost and\ninsufficient context length of these models pose significant obstacles for\nhospitals in processing the extensive medical histories typical in EHR data.\nAdditionally, existing models employ separate finetuning for each clinical\ntask, complicating maintenance in healthcare environments. Moreover, these\nmodels focus exclusively on either clinical prediction or EHR forecasting,\nlacking the flexibility to perform well across both. To overcome these\nlimitations, we introduce EHRMamba, a robust foundation model built on the\nMamba architecture. EHRMamba can process sequences up to four times longer than\nprevious models due to its linear computational cost. We also introduce a novel\napproach to Multitask Prompted Finetuning (MTF) for EHR data, which enables\nEHRMamba to simultaneously learn multiple clinical tasks in a single finetuning\nphase, significantly enhancing deployment and cross-task generalization.\nFurthermore, our model leverages the HL7 FHIR data standard to simplify\nintegration into existing hospital systems. Alongside EHRMamba, we open-source\nOdyssey, a toolkit designed to support the development and deployment of EHR\nfoundation models, with an emphasis on data standardization and\ninterpretability. Our evaluations on the MIMIC-IV dataset demonstrate that\nEHRMamba advances state-of-the-art performance across 6 major clinical tasks\nand excels in EHR forecasting, marking a significant leap forward in the field.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Adibvafa Fallahpour",
            "Mahshid Alinoori",
            "Arash Afkanpour",
            "Amrit Krishnan"
        ],
        "published": "2024-05-23T13:43:29Z"
    },
    {
        "title": "Task-Based Design and Policy Co-Optimization for Tendon-driven\n  Underactuated Kinematic Chains",
        "link": "http://arxiv.org/abs/2405.14566v1",
        "abstract": "Underactuated manipulators reduce the number of bulky motors, thereby\nenabling compact and mechanically robust designs. However, fewer actuators than\njoints means that the manipulator can only access a specific manifold within\nthe joint space, which is particular to a given hardware configuration and can\nbe low-dimensional and/or discontinuous. Determining an appropriate set of\nhardware parameters for this class of mechanisms, therefore, is difficult -\neven for traditional task-based co-optimization methods. In this paper, our\ngoal is to implement a task-based design and policy co-optimization method for\nunderactuated, tendon-driven manipulators. We first formulate a general model\nfor an underactuated, tendon-driven transmission. We then use this model to\nco-optimize a three-link, two-actuator kinematic chain using reinforcement\nlearning. We demonstrate that our optimized tendon transmission and control\npolicy can be transferred reliably to physical hardware with real-world\nreaching experiments.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Sharfin Islam",
            "Zhanpeng He",
            "Matei Ciocarlie"
        ],
        "published": "2024-05-23T13:43:01Z"
    },
    {
        "title": "Concept Visualization: Explaining the CLIP Multi-modal Embedding Using\n  WordNet",
        "link": "http://arxiv.org/abs/2405.14563v1",
        "abstract": "Advances in multi-modal embeddings, and in particular CLIP, have recently\ndriven several breakthroughs in Computer Vision (CV). CLIP has shown impressive\nperformance on a variety of tasks, yet, its inherently opaque architecture may\nhinder the application of models employing CLIP as backbone, especially in\nfields where trust and model explainability are imperative, such as in the\nmedical domain. Current explanation methodologies for CV models rely on\nSaliency Maps computed through gradient analysis or input perturbation.\nHowever, these Saliency Maps can only be computed to explain classes relevant\nto the end task, often smaller in scope than the backbone training classes. In\nthe context of models implementing CLIP as their vision backbone, a substantial\nportion of the information embedded within the learned representations is thus\nleft unexplained.\n  In this work, we propose Concept Visualization (ConVis), a novel saliency\nmethodology that explains the CLIP embedding of an image by exploiting the\nmulti-modal nature of the embeddings. ConVis makes use of lexical information\nfrom WordNet to compute task-agnostic Saliency Maps for any concept, not\nlimited to concepts the end model was trained on. We validate our use of\nWordNet via an out of distribution detection experiment, and test ConVis on an\nobject localization benchmark, showing that Concept Visualizations correctly\nidentify and localize the image's semantic content. Additionally, we perform a\nuser study demonstrating that our methodology can give users insight on the\nmodel's functioning.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Loris Giulivi",
            "Giacomo Boracchi"
        ],
        "published": "2024-05-23T13:41:17Z"
    },
    {
        "title": "FUSE: Fast Unified Simulation and Estimation for PDEs",
        "link": "http://arxiv.org/abs/2405.14558v1",
        "abstract": "The joint prediction of continuous fields and statistical estimation of the\nunderlying discrete parameters is a common problem for many physical systems,\ngoverned by PDEs. Hitherto, it has been separately addressed by employing\noperator learning surrogates for field prediction while using simulation-based\ninference (and its variants) for statistical parameter determination. Here, we\nargue that solving both problems within the same framework can lead to\nconsistent gains in accuracy and robustness. To this end, We propose a novel\nand flexible formulation of the operator learning problem that allows jointly\npredicting continuous quantities and inferring distributions of discrete\nparameters, and thus amortizing the cost of both the inverse and the surrogate\nmodels to a joint pre-training step. We present the capabilities of the\nproposed methodology for predicting continuous and discrete biomarkers in\nfull-body haemodynamics simulations under different levels of missing\ninformation. We also consider a test case for atmospheric large-eddy simulation\nof a two-dimensional dry cold bubble, where we infer both continuous\ntime-series and information about the systems conditions. We present\ncomparisons against different baselines to showcase significantly increased\naccuracy in both the inverse and the surrogate tasks.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Levi E. Lingsch",
            "Dana Grund",
            "Siddhartha Mishra",
            "Georgios Kissas"
        ],
        "published": "2024-05-23T13:37:26Z"
    },
    {
        "title": "Deep Learning Classification of Photoplethysmogram Signal for\n  Hypertension Levels",
        "link": "http://arxiv.org/abs/2405.14556v1",
        "abstract": "Continuous photoplethysmography (PPG)-based blood pressure monitoring is\nnecessary for healthcare and fitness applications. In Artificial Intelligence\n(AI), signal classification levels with the machine and deep learning\narrangements need to be explored further. Techniques based on time-frequency\nspectra, such as Short-time Fourier Transform (STFT), have been used to address\nthe challenges of motion artifact correction. Therefore, the proposed study\nworks with PPG signals of more than 200 patients (650+ signal samples) with\nhypertension, using STFT with various Neural Networks (Convolution Neural\nNetwork (CNN), Long Short-Term Memory (LSTM), Bidirectional Long Short-Term\nMemory (Bi-LSTM), followed by machine learning classifiers, such as, Support\nVector Machine (SVM) and Random Forest (RF). The classification has been done\nfor two categories: Prehypertension (normal levels) and Hypertension (includes\nStage I and Stage II). Various performance metrics have been obtained with two\nbatch sizes of 3 and 16 for the fusion of the neural networks. With precision\nand specificity of 100% and recall of 82.1%, the LSTM model provides the best\nresults among all combinations of Neural Networks. However, the maximum\naccuracy of 71.9% is achieved by the LSTM-CNN model. Further stacked Ensemble\nmethod has been used to achieve 100% accuracy for Meta-LSTM-RF, Meta-\nLSTM-CNN-RF and Meta- STFT-CNN-SVM.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "authors": [
            "Nida Nasir",
            "Mustafa Sameer",
            "Feras Barneih",
            "Omar Alshaltone",
            "Muneeb Ahmed"
        ],
        "published": "2024-05-23T13:35:53Z"
    },
    {
        "title": "Subtle Biases Need Subtler Measures: Dual Metrics for Evaluating\n  Representative and Affinity Bias in Large Language Models",
        "link": "http://arxiv.org/abs/2405.14555v1",
        "abstract": "Research on Large Language Models (LLMs) has often neglected subtle biases\nthat, although less apparent, can significantly influence the models' outputs\ntoward particular social narratives. This study addresses two such biases\nwithin LLMs: \\textit{representative bias}, which denotes a tendency of LLMs to\ngenerate outputs that mirror the experiences of certain identity groups, and\n\\textit{affinity bias}, reflecting the models' evaluative preferences for\nspecific narratives or viewpoints. We introduce two novel metrics to measure\nthese biases: the Representative Bias Score (RBS) and the Affinity Bias Score\n(ABS), and present the Creativity-Oriented Generation Suite (CoGS), a\ncollection of open-ended tasks such as short story writing and poetry\ncomposition, designed with customized rubrics to detect these subtle biases.\nOur analysis uncovers marked representative biases in prominent LLMs, with a\npreference for identities associated with being white, straight, and men.\nFurthermore, our investigation of affinity bias reveals distinctive evaluative\npatterns within each model, akin to `bias fingerprints'. This trend is also\nseen in human evaluators, highlighting a complex interplay between human and\nmachine bias perceptions.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CY",
            "cs.LG"
        ],
        "authors": [
            "Abhishek Kumar",
            "Sarfaroz Yunusov",
            "Ali Emami"
        ],
        "published": "2024-05-23T13:35:34Z"
    },
    {
        "title": "UDKAG: Augmenting Large Vision-Language Models with Up-to-Date Knowledge",
        "link": "http://arxiv.org/abs/2405.14554v1",
        "abstract": "Large vision-language models (LVLMs) are ignorant of the up-to-date\nknowledge, such as LLaVA series, because they cannot be updated frequently due\nto the large amount of resources required, and therefore fail in many cases.\nFor example, if a LVLM was released on January 2024, and it wouldn't know the\ndetailed plot of the new movie Dune 2, which wasn't released until February\n2024. To solve the problem, a promising solution is to provide LVLMs with\nup-to-date knowledge via internet search during inference, i.e.,\ninternet-augmented generation (IAG), which is already integrated in some\nclosed-source commercial LVLMs such as GPT-4V. However, the specific mechanics\nunderpinning them remain a mystery. In this paper, we propose a plug-and-play\nframework, for augmenting existing LVLMs in handling visual question answering\n(VQA) about up-to-date knowledge, dubbed UDKAG. A hierarchical filtering model\nis trained to effectively and efficiently find the most helpful content from\nthe websites returned by a search engine to prompt LVLMs with up-to-date\nknowledge. To train the model and evaluate our framework's performance, we\npropose a pipeline to automatically generate news-related VQA samples to\nconstruct a dataset, dubbed UDK-VQA. A multi-model voting mechanism is\nintroduced to label the usefulness of website/content for VQA samples to\nconstruct the training set. Experimental results demonstrate the effectiveness\nof our framework, outperforming GPT-4V by about 25% in accuracy.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Chuanhao Li",
            "Zhen Li",
            "Chenchen Jing",
            "Shuo Liu",
            "Wenqi Shao",
            "Yuwei Wu",
            "Ping Luo",
            "Yu Qiao",
            "Kaipeng Zhang"
        ],
        "published": "2024-05-23T13:32:07Z"
    },
    {
        "title": "Design and Development of a Roaming Wireless Safety Emergency Stop",
        "link": "http://arxiv.org/abs/2405.14552v1",
        "abstract": "Modern manufacturing is characterized by a high degree of automation, with\nautonomous systems also frequently being used. In such environments human\nintervention in the event of malfunctions or maintenance becomes a rare but\nalso necessary task. When human workers are no longer an integral part of the\nproduction process, but only intervene when necessary, e.g., in the case of\nunexpected machine behavior, appropriate safety solutions will become even more\nimportant. This work describes a wireless communication system enabling a\nflexible and safe emergency stop function for multiple automation cells. A\nportable emergency stop switch allows seamless transition between different\nwireless cells, ensuring functional safety. The communication protocol combines\nIO-Link Wireless features with the safety requirements already implemented in\nIO-Link Safety. Security requirements are fulfilled through encryption and\nauthentication. The IO-Link Wireless roaming functionality is used to extend\nthe system across several manufacturing cells. An experimental setup confirms\nthe suitability of the system for various applications. The results demonstrate\nthe effectiveness of the handover mechanism and evaluate the potential of the\nsystem to improve flexibility, availability and security in dynamic production\nenvironments. Future extensions could include the use of AI based evaluation of\nthe radio signals for an intelligent cell handover.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Henry Beuster",
            "Thomas Doebbert",
            "Christoph Cammin",
            "Dmytro Krush",
            "Gerd Scholl"
        ],
        "published": "2024-05-23T13:31:38Z"
    },
    {
        "title": "Rapid modelling of reactive transport in porous media using machine\n  learning: limitations and solutions",
        "link": "http://arxiv.org/abs/2405.14548v1",
        "abstract": "Reactive transport in porous media plays a pivotal role in subsurface\nreservoir processes, influencing fluid properties and geochemical\ncharacteristics. However, coupling fluid flow and transport with geochemical\nreactions is computationally intensive, requiring geochemical calculations at\neach grid cell and each time step within a discretized simulation domain.\nAlthough recent advancements have integrated machine learning techniques as\nsurrogates for geochemical simulations, ensuring computational efficiency and\naccuracy remains a challenge. This chapter investigates machine learning models\nas replacements for a geochemical module in a reactive transport in porous\nmedia simulation. We test this approach on a well-documented cation exchange\nproblem. While the surrogate models excel in isolated predictions, they fall\nshort in rollout predictions over successive time steps. By introducing\nmodifications, including physics-based constraints and tailored dataset\ngeneration strategies, we show that machine learning surrogates can achieve\naccurate rollout predictions. Our findings emphasize that, when judiciously\ndesigned, machine learning surrogates can substantially expedite the cation\nexchange problem without compromising accuracy, offering significant potential\nfor a range of reactive transport applications.",
        "subjects": [
            "cs.CE"
        ],
        "authors": [
            "Vinicius L S Silva",
            "Geraldine Regnier",
            "Pablo Salinas",
            "Claire E Heaney",
            "Matthew D Jackson",
            "Christopher C Pain"
        ],
        "published": "2024-05-23T13:28:10Z"
    },
    {
        "title": "Causal Effect Identification in a Sub-Population with Latent Variables",
        "link": "http://arxiv.org/abs/2405.14547v1",
        "abstract": "The s-ID problem seeks to compute a causal effect in a specific\nsub-population from the observational data pertaining to the same sub\npopulation (Abouei et al., 2023). This problem has been addressed when all the\nvariables in the system are observable. In this paper, we consider an extension\nof the s-ID problem that allows for the presence of latent variables. To tackle\nthe challenges induced by the presence of latent variables in a sub-population,\nwe first extend the classical relevant graphical definitions, such as\nc-components and Hedges, initially defined for the so-called ID problem (Pearl,\n1995; Tian & Pearl, 2002), to their new counterparts. Subsequently, we propose\na sound algorithm for the s-ID problem with latent variables.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Amir Mohammad Abouei",
            "Ehsan Mokhtarian",
            "Negar Kiyavash",
            "Matthias Grossglauser"
        ],
        "published": "2024-05-23T13:25:41Z"
    },
    {
        "title": "Global Behavior of Learning Dynamics in Zero-Sum Games with Memory\n  Asymmetry",
        "link": "http://arxiv.org/abs/2405.14546v1",
        "abstract": "This study examines the global behavior of dynamics in learning in games\nbetween two players, X and Y. We consider the simplest situation for memory\nasymmetry between two players: X memorizes the other Y's previous action and\nuses reactive strategies, while Y has no memory. Although this memory\ncomplicates the learning dynamics, we discover two novel quantities that\ncharacterize the global behavior of such complex dynamics. One is an extended\nKullback-Leibler divergence from the Nash equilibrium, a well-known conserved\nquantity from previous studies. The other is a family of Lyapunov functions of\nX's reactive strategy. These two quantities capture the global behavior in\nwhich X's strategy becomes more exploitative, and the exploited Y's strategy\nconverges to the Nash equilibrium. Indeed, we theoretically prove that Y's\nstrategy globally converges to the Nash equilibrium in the simplest game\nequipped with an equilibrium in the interior of strategy spaces. Furthermore,\nour experiments also suggest that this global convergence is universal for more\nadvanced zero-sum games than the simplest game. This study provides a novel\ncharacterization of the global behavior of learning in games through a couple\nof indicators.",
        "subjects": [
            "cs.GT",
            "cs.MA",
            "math.OC",
            "nlin.CD"
        ],
        "authors": [
            "Yuma Fujimoto",
            "Kaito Ariu",
            "Kenshi Abe"
        ],
        "published": "2024-05-23T13:25:39Z"
    },
    {
        "title": "A Cross-Field Fusion Strategy for Drug-Target Interaction Prediction",
        "link": "http://arxiv.org/abs/2405.14545v1",
        "abstract": "Drug-target interaction (DTI) prediction is a critical component of the drug\ndiscovery process. In the drug development engineering field, predicting novel\ndrug-target interactions is extremely crucial.However, although existing\nmethods have achieved high accuracy levels in predicting known drugs and drug\ntargets, they fail to utilize global protein information during DTI prediction.\nThis leads to an inability to effectively predict interaction the interactions\nbetween novel drugs and their targets. As a result, the cross-field information\nfusion strategy is employed to acquire local and global protein information.\nThus, we propose the siamese drug-target interaction SiamDTI prediction method,\nwhich utilizes a double channel network structure for cross-field supervised\nlearning.Experimental results on three benchmark datasets demonstrate that\nSiamDTI achieves higher accuracy levels than other state-of-the-art (SOTA)\nmethods on novel drugs and targets.Additionally, SiamDTI's performance with\nknown drugs and targets is comparable to that of SOTA approachs. The code is\navailable at https://anonymous.4open.science/r/DDDTI-434D.",
        "subjects": [
            "q-bio.BM",
            "cs.LG"
        ],
        "authors": [
            "Hongzhi Zhang",
            "Xiuwen Gong",
            "Shirui Pan",
            "Jia Wu",
            "Bo Du",
            "Wenbin Hu"
        ],
        "published": "2024-05-23T13:25:20Z"
    },
    {
        "title": "Nuclear Norm Regularization for Deep Learning",
        "link": "http://arxiv.org/abs/2405.14544v1",
        "abstract": "Penalizing the nuclear norm of a function's Jacobian encourages it to locally\nbehave like a low-rank linear map. Such functions vary locally along only a\nhandful of directions, making the Jacobian nuclear norm a natural regularizer\nfor machine learning problems. However, this regularizer is intractable for\nhigh-dimensional problems, as it requires computing a large Jacobian matrix and\ntaking its singular value decomposition. We show how to efficiently penalize\nthe Jacobian nuclear norm using techniques tailor-made for deep learning. We\nprove that for functions parametrized as compositions $f = g \\circ h$, one may\nequivalently penalize the average squared Frobenius norm of $Jg$ and $Jh$. We\nthen propose a denoising-style approximation that avoids the Jacobian\ncomputations altogether. Our method is simple, efficient, and accurate,\nenabling Jacobian nuclear norm regularization to scale to high-dimensional deep\nlearning problems. We complement our theory with an empirical study of our\nregularizer's performance and investigate applications to denoising and\nrepresentation learning.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Christopher Scarvelis",
            "Justin Solomon"
        ],
        "published": "2024-05-23T13:24:38Z"
    },
    {
        "title": "Initial Burst of Disruptive Efforts over Individual Scientific Careers",
        "link": "http://arxiv.org/abs/2405.14543v1",
        "abstract": "Despite persistent efforts to understand the dynamics of creativity of\nscientists over careers in terms of productivity, impact, and prize, little is\nknown about the dynamics of scientists' disruptive efforts that affect\nindividual academic careers and drive scientific advance. Drawing on millions\nof data over six decades and across nineteen disciplines, associating the\npublication records of individual scientists with the disruption index, we\nsystematically quantify the temporal pattern of disruptive ideas over\nindividual scientific careers, providing a detailed understanding of the macro\nphenomenon of scientific stagnation from the individual perspective. We start\nby checking the relationship between disruption-based and citation-based\npublication profiles. Next, we observe the finite inequality in the disruptive\nproductivity of scientists, diminishing gradually as the level of disruption\nincreases. We then identify the initial burst phenomenon in disruption\ndynamics. It is further revealed that while early engagement in high disruption\nfrictions away initial productivity, compared to initial advantage in\nproductivity or impact, initial high disruption ensures more subsequent\nacademic viability evidenced by a longer career span and relatively final\nhigher productivity, but does not necessarily guarantee academic success\nthroughout careers. Further analysis shows that increasing disruptive work is\nuncorrelated to overall productivity but negatively correlated with the overall\nimpact. However, increasing disruptive work in the early career is associated\nwith higher overall productivity, yet lower overall productivity in the later\ncareer. Our research underscores the urgent need for a policy shift that\nencourages a balance between the pursuit of disruptive efforts and the\nachievement of impactful outcomes.",
        "subjects": [
            "physics.soc-ph",
            "cs.DL"
        ],
        "authors": [
            "Shuang Zhang",
            "Feifan Liu",
            "Haoxiang Xia"
        ],
        "published": "2024-05-23T13:24:00Z"
    },
    {
        "title": "This Too Shall Pass: Removing Stale Observations in Dynamic Bayesian\n  Optimization",
        "link": "http://arxiv.org/abs/2405.14540v1",
        "abstract": "Bayesian Optimization (BO) has proven to be very successful at optimizing a\nstatic, noisy, costly-to-evaluate black-box function $f : \\mathcal{S} \\to\n\\mathbb{R}$. However, optimizing a black-box which is also a function of time\n(i.e., a dynamic function) $f : \\mathcal{S} \\times \\mathcal{T} \\to \\mathbb{R}$\nremains a challenge, since a dynamic Bayesian Optimization (DBO) algorithm has\nto keep track of the optimum over time. This changes the nature of the\noptimization problem in at least three aspects: (i) querying an arbitrary point\nin $\\mathcal{S} \\times \\mathcal{T}$ is impossible, (ii) past observations\nbecome less and less relevant for keeping track of the optimum as time goes by\nand (iii) the DBO algorithm must have a high sampling frequency so it can\ncollect enough relevant observations to keep track of the optimum through time.\nIn this paper, we design a Wasserstein distance-based criterion able to\nquantify the relevancy of an observation with respect to future predictions.\nThen, we leverage this criterion to build W-DBO, a DBO algorithm able to remove\nirrelevant observations from its dataset on the fly, thus maintaining\nsimultaneously a good predictive performance and a high sampling frequency,\neven in continuous-time optimization tasks with unknown horizon. Numerical\nexperiments establish the superiority of W-DBO, which outperforms\nstate-of-the-art methods by a comfortable margin.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Anthony Bardou",
            "Patrick Thiran",
            "Giovanni Ranieri"
        ],
        "published": "2024-05-23T13:22:59Z"
    },
    {
        "title": "VINS-Multi: A Robust Asynchronous Multi-camera-IMU State Estimator",
        "link": "http://arxiv.org/abs/2405.14539v1",
        "abstract": "State estimation is a critical foundational module in robotics applications,\nwhere robustness and performance are paramount. Although in recent years, many\nworks have been focusing on improving one of the most widely adopted state\nestimation methods, visual inertial odometry (VIO), by incorporating multiple\ncameras, these efforts predominantly address synchronous camera systems.\nAsynchronous cameras, which offer simpler hardware configurations and enhanced\nresilience, have been largely overlooked. To fill this gap, this paper presents\nVINS-Multi, a novel multi-camera-IMU state estimator for asynchronous cameras.\nThe estimator comprises parallel front ends, a front end coordinator, and a\nback end optimization module capable of handling asynchronous input frames. It\nutilizes the frames effectively through a dynamic feature number allocation and\na frame priority coordination strategy. The proposed estimator is integrated\ninto a customized quadrotor platform and tested in multiple realistic and\nchallenging scenarios to validate its practicality. Additionally, comprehensive\nbenchmark results are provided to showcase the robustness and superior\nperformance of the proposed estimator.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Luqi Wang",
            "Yang Xu",
            "Shaojie Shen"
        ],
        "published": "2024-05-23T13:22:52Z"
    },
    {
        "title": "Regressor-free Molecule Generation to Support Drug Response Prediction",
        "link": "http://arxiv.org/abs/2405.14536v1",
        "abstract": "Drug response prediction (DRP) is a crucial phase in drug discovery, and the\nmost important metric for its evaluation is the IC50 score. DRP results are\nheavily dependent on the quality of the generated molecules. Existing molecule\ngeneration methods typically employ classifier-based guidance, enabling\nsampling within the IC50 classification range. However, these methods fail to\nensure the sampling space range's effectiveness, generating numerous\nineffective molecules. Through experimental and theoretical study, we\nhypothesize that conditional generation based on the target IC50 score can\nobtain a more effective sampling space. As a result, we introduce\nregressor-free guidance molecule generation to ensure sampling within a more\neffective space and support DRP. Regressor-free guidance combines a diffusion\nmodel's score estimation with a regression controller model's gradient based on\nnumber labels. To effectively map regression labels between drugs and cell\nlines, we design a common-sense numerical knowledge graph that constrains the\norder of text representations. Experimental results on the real-world dataset\nfor the DRP task demonstrate our method's effectiveness in drug discovery. The\ncode is available at:https://anonymous.4open.science/r/RMCD-DBD1.",
        "subjects": [
            "q-bio.MN",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Kun Li",
            "Xiuwen Gong",
            "Shirui Pan",
            "Jia Wu",
            "Bo Du",
            "Wenbin Hu"
        ],
        "published": "2024-05-23T13:22:17Z"
    },
    {
        "title": "High Rank Path Development: an approach of learning the filtration of\n  stochastic processes",
        "link": "http://arxiv.org/abs/2405.14913v1",
        "abstract": "Since the weak convergence for stochastic processes does not account for the\ngrowth of information over time which is represented by the underlying\nfiltration, a slightly erroneous stochastic model in weak topology may cause\nhuge loss in multi-periods decision making problems. To address such\ndiscontinuities Aldous introduced the extended weak convergence, which can\nfully characterise all essential properties, including the filtration, of\nstochastic processes; however was considered to be hard to find efficient\nnumerical implementations. In this paper, we introduce a novel metric called\nHigh Rank PCF Distance (HRPCFD) for extended weak convergence based on the high\nrank path development method from rough path theory, which also defines the\ncharacteristic function for measure-valued processes. We then show that such\nHRPCFD admits many favourable analytic properties which allows us to design an\nefficient algorithm for training HRPCFD from data and construct the HRPCF-GAN\nby using HRPCFD as the discriminator for conditional time series generation.\nOur numerical experiments on both hypothesis testing and generative modelling\nvalidate the out-performance of our approach compared with several\nstate-of-the-art methods, highlighting its potential in broad applications of\nsynthetic time series generation and in addressing classic financial and\neconomic challenges, such as optimal stopping or utility maximisation problems.",
        "subjects": [
            "stat.ME",
            "cs.LG",
            "math.PR",
            "stat.ML"
        ],
        "authors": [
            "Jiajie Tao",
            "Hao Ni",
            "Chong Liu"
        ],
        "published": "2024-05-23T13:20:47Z"
    },
    {
        "title": "Exploring Alignment in Shared Cross-lingual Spaces",
        "link": "http://arxiv.org/abs/2405.14535v1",
        "abstract": "Despite their remarkable ability to capture linguistic nuances across diverse\nlanguages, questions persist regarding the degree of alignment between\nlanguages in multilingual embeddings. Drawing inspiration from research on\nhigh-dimensional representations in neural language models, we employ\nclustering to uncover latent concepts within multilingual models. Our analysis\nfocuses on quantifying the \\textit{alignment} and \\textit{overlap} of these\nconcepts across various languages within the latent space. To this end, we\nintroduce two metrics \\CA{} and \\CO{} aimed at quantifying these aspects,\nenabling a deeper exploration of multilingual embeddings. Our study encompasses\nthree multilingual models (\\texttt{mT5}, \\texttt{mBERT}, and \\texttt{XLM-R})\nand three downstream tasks (Machine Translation, Named Entity Recognition, and\nSentiment Analysis). Key findings from our analysis include: i) deeper layers\nin the network demonstrate increased cross-lingual \\textit{alignment} due to\nthe presence of language-agnostic concepts, ii) fine-tuning of the models\nenhances \\textit{alignment} within the latent space, and iii) such\ntask-specific calibration helps in explaining the emergence of zero-shot\ncapabilities in the models.\\footnote{The code is available at\n\\url{https://github.com/baselmousi/multilingual-latent-concepts}}",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Basel Mousi",
            "Nadir Durrani",
            "Fahim Dalvi",
            "Majd Hawasly",
            "Ahmed Abdelali"
        ],
        "published": "2024-05-23T13:20:24Z"
    },
    {
        "title": "Aligning Embeddings and Geometric Random Graphs: Informational Results\n  and Computational Approaches for the Procrustes-Wasserstein Problem",
        "link": "http://arxiv.org/abs/2405.14532v1",
        "abstract": "The Procrustes-Wasserstein problem consists in matching two high-dimensional\npoint clouds in an unsupervised setting, and has many applications in natural\nlanguage processing and computer vision. We consider a planted model with two\ndatasets $X,Y$ that consist of $n$ datapoints in $\\mathbb{R}^d$, where $Y$ is a\nnoisy version of $X$, up to an orthogonal transformation and a relabeling of\nthe data points. This setting is related to the graph alignment problem in\ngeometric models. In this work, we focus on the euclidean transport cost\nbetween the point clouds as a measure of performance for the alignment. We\nfirst establish information-theoretic results, in the high ($d \\gg \\log n$) and\nlow ($d \\ll \\log n$) dimensional regimes. We then study computational aspects\nand propose the Ping-Pong algorithm, alternatively estimating the orthogonal\ntransformation and the relabeling, initialized via a Franke-Wolfe convex\nrelaxation. We give sufficient conditions for the method to retrieve the\nplanted signal after one single step. We provide experimental results to\ncompare the proposed approach with the state-of-the-art method of Grave et al.\n(2019).",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST",
            "stat.TH"
        ],
        "authors": [
            "Mathieu Even",
            "Luca Ganassali",
            "Jakob Maier",
            "Laurent Massoulié"
        ],
        "published": "2024-05-23T13:18:51Z"
    },
    {
        "title": "Multistable Shape from Shading Emerges from Patch Diffusion",
        "link": "http://arxiv.org/abs/2405.14530v1",
        "abstract": "Models for monocular shape reconstruction of surfaces with diffuse reflection\n-- shape from shading -- ought to produce distributions of outputs, because\nthere are fundamental mathematical ambiguities of both continuous (e.g.,\nbas-relief) and discrete (e.g., convex/concave) varieties which are also\nexperienced by humans. Yet, the outputs of current models are limited to point\nestimates or tight distributions around single modes, which prevent them from\ncapturing these effects. We introduce a model that reconstructs a multimodal\ndistribution of shapes from a single shading image, which aligns with the human\nexperience of multistable perception. We train a small denoising diffusion\nprocess to generate surface normal fields from $16\\times 16$ patches of\nsynthetic images of everyday 3D objects. We deploy this model patch-wise at\nmultiple scales, with guidance from inter-patch shape consistency constraints.\nDespite its relatively small parameter count and predominantly bottom-up\nstructure, we show that multistable shape explanations emerge from this model\nfor ''ambiguous'' test images that humans experience as being multistable. At\nthe same time, the model produces veridical shape estimates for object-like\nimages that include distinctive occluding contours and appear less ambiguous.\nThis may inspire new architectures for stochastic 3D shape perception that are\nmore efficient and better aligned with human experience.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xinran Nicole Han",
            "Todd Zickler",
            "Ko Nishino"
        ],
        "published": "2024-05-23T13:15:24Z"
    },
    {
        "title": "AnomalyDINO: Boosting Patch-based Few-shot Anomaly Detection with DINOv2",
        "link": "http://arxiv.org/abs/2405.14529v1",
        "abstract": "Recent advances in multimodal foundation models have set new standards in\nfew-shot anomaly detection. This paper explores whether high-quality visual\nfeatures alone are sufficient to rival existing state-of-the-art\nvision-language models. We affirm this by adapting DINOv2 for one-shot and\nfew-shot anomaly detection, with a focus on industrial applications. We show\nthat this approach does not only rival existing techniques but can even\noutmatch them in many settings. Our proposed vision-only approach, AnomalyDINO,\nis based on patch similarities and enables both image-level anomaly prediction\nand pixel-level anomaly segmentation. The approach is methodologically simple\nand training-free and, thus, does not require any additional data for\nfine-tuning or meta-learning. Despite its simplicity, AnomalyDINO achieves\nstate-of-the-art results in one- and few-shot anomaly detection (e.g., pushing\nthe one-shot performance on MVTec-AD from an AUROC of 93.1% to 96.6%). The\nreduced overhead, coupled with its outstanding few-shot performance, makes\nAnomalyDINO a strong candidate for fast deployment, for example, in industrial\ncontexts.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Simon Damm",
            "Mike Laszkiewicz",
            "Johannes Lederer",
            "Asja Fischer"
        ],
        "published": "2024-05-23T13:15:13Z"
    },
    {
        "title": "Towards Privacy-Aware and Personalised Assistive Robots: A User-Centred\n  Approach",
        "link": "http://arxiv.org/abs/2405.14528v1",
        "abstract": "The global increase in the elderly population necessitates innovative\nlong-term care solutions to improve the quality of life for vulnerable\nindividuals while reducing caregiver burdens. Assistive robots, leveraging\nadvancements in Machine Learning, offer promising personalised support.\nHowever, their integration into daily life raises significant privacy concerns.\nWidely used frameworks like the Robot Operating System (ROS) historically lack\ninherent privacy mechanisms, complicating data-driven approaches in robotics.\nThis research pioneers user-centric, privacy-aware technologies such as\nFederated Learning (FL) to advance assistive robotics. FL enables collaborative\nlearning without sharing sensitive data, addressing privacy and scalability\nissues. This work includes developing solutions for smart wheelchair\nassistance, enhancing user independence and well-being. By tackling challenges\nrelated to non-stationary data and heterogeneous environments, the research\naims to improve personalisation and user experience. Ultimately, it seeks to\nlead the responsible integration of assistive robots into society, enhancing\nthe quality of life for elderly and care-dependent individuals.",
        "subjects": [
            "cs.RO",
            "cs.HC",
            "cs.LG"
        ],
        "authors": [
            "Fernando E. Casado"
        ],
        "published": "2024-05-23T13:14:08Z"
    },
    {
        "title": "ArchesWeather: An efficient AI weather forecasting model at 1.5°\n  resolution",
        "link": "http://arxiv.org/abs/2405.14527v1",
        "abstract": "One of the guiding principles for designing AI-based weather forecasting\nsystems is to embed physical constraints as inductive priors in the neural\nnetwork architecture. A popular prior is locality, where the atmospheric data\nis processed with local neural interactions, like 3D convolutions or 3D local\nattention windows as in Pangu-Weather. On the other hand, some works have shown\ngreat success in weather forecasting without this locality principle, at the\ncost of a much higher parameter count.\n  In this paper, we show that the 3D local processing in Pangu-Weather is\ncomputationally sub-optimal. We design ArchesWeather, a transformer model that\ncombines 2D attention with a column-wise attention-based feature interaction\nmodule, and demonstrate that this design improves forecasting skill.\n  ArchesWeather is trained at 1.5{\\deg} resolution and 24h lead time, with a\ntraining budget of a few GPU-days and a lower inference cost than competing\nmethods. An ensemble of two of our best models shows competitive RMSE scores\nwith the IFS HRES and outperforms the 1.4{\\deg} 50-members NeuralGCM ensemble\nfor one day ahead forecasting.\n  Code and models will be made publicly available at\nhttps://github.com/gcouairon/ArchesWeather.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Guillaume Couairon",
            "Christian Lessig",
            "Anastase Charantonis",
            "Claire Monteleoni"
        ],
        "published": "2024-05-23T13:11:49Z"
    },
    {
        "title": "QoE-Aware and Secure UAV-Aided Rate-Splitting Multiple Access Based\n  Communications",
        "link": "http://arxiv.org/abs/2405.14524v1",
        "abstract": "In this work, we address the issue of quality of experience (QoE) in unmanned\naerial vehicle (UAV) aided multiuser rate-splitting multiple access (RSMA)\nnetworks under secrecy constraints. The problem is formulated as maximization\nof sum mean opinion scores (MOSs) of the users. The problem is decomposed into\ntwo subproblems, beamforming and rate allocation and UAV trajectory subproblem.\nFor, beamforming and rate allocation subproblem, we use the epigraph method,\nproperty of polynomials, and the norm-bounded error of channels, we linearize\nthe objective function. Then, applying second-order conic (SOC) and first\nTaylor expansion, we convexify the remaining nonconvex constraints. For the\nhighly nonconvex UAV trajectory, we unroll the constraints and we apply first\nTaylor expansion on the unrolled constraints. The simulation results\ndemonstrate the efficiency of the proposed framework.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Abuzar B. M. Adam",
            "Xiaoyu Wan",
            "Mohammed Saleh Ali Muthanna"
        ],
        "published": "2024-05-23T13:07:33Z"
    },
    {
        "title": "Explaining Black-box Model Predictions via Two-level Nested Feature\n  Attributions with Consistency Property",
        "link": "http://arxiv.org/abs/2405.14522v1",
        "abstract": "Techniques that explain the predictions of black-box machine learning models\nare crucial to make the models transparent, thereby increasing trust in AI\nsystems. The input features to the models often have a nested structure that\nconsists of high- and low-level features, and each high-level feature is\ndecomposed into multiple low-level features. For such inputs, both high-level\nfeature attributions (HiFAs) and low-level feature attributions (LoFAs) are\nimportant for better understanding the model's decision. In this paper, we\npropose a model-agnostic local explanation method that effectively exploits the\nnested structure of the input to estimate the two-level feature attributions\nsimultaneously. A key idea of the proposed method is to introduce the\nconsistency property that should exist between the HiFAs and LoFAs, thereby\nbridging the separate optimization problems for estimating them. Thanks to this\nconsistency property, the proposed method can produce HiFAs and LoFAs that are\nboth faithful to the black-box models and consistent with each other, using a\nsmaller number of queries to the models. In experiments on image classification\nin multiple instance learning and text classification using language models, we\ndemonstrate that the HiFAs and LoFAs estimated by the proposed method are\naccurate, faithful to the behaviors of the black-box models, and provide\nconsistent explanations.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "stat.ML"
        ],
        "authors": [
            "Yuya Yoshikawa",
            "Masanari Kimura",
            "Ryotaro Shimizu",
            "Yuki Saito"
        ],
        "published": "2024-05-23T13:03:26Z"
    },
    {
        "title": "Synthetic Data Generation for Intersectional Fairness by Leveraging\n  Hierarchical Group Structure",
        "link": "http://arxiv.org/abs/2405.14521v1",
        "abstract": "In this paper, we introduce a data augmentation approach specifically\ntailored to enhance intersectional fairness in classification tasks. Our method\ncapitalizes on the hierarchical structure inherent to intersectionality, by\nviewing groups as intersections of their parent categories. This perspective\nallows us to augment data for smaller groups by learning a transformation\nfunction that combines data from these parent groups. Our empirical analysis,\nconducted on four diverse datasets including both text and images, reveals that\nclassifiers trained with this data augmentation approach achieve superior\nintersectional fairness and are more robust to ``leveling down'' when compared\nto methods optimizing traditional group fairness metrics.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "authors": [
            "Gaurav Maheshwari",
            "Aurélien Bellet",
            "Pascal Denis",
            "Mikaela Keller"
        ],
        "published": "2024-05-23T13:03:23Z"
    },
    {
        "title": "Ghost-Stereo: GhostNet-based Cost Volume Enhancement and Aggregation for\n  Stereo Matching Networks",
        "link": "http://arxiv.org/abs/2405.14520v1",
        "abstract": "Depth estimation based on stereo matching is a classic but popular computer\nvision problem, which has a wide range of real-world applications. Current\nstereo matching methods generally adopt the deep Siamese neural network\narchitecture, and have achieved impressing performance by constructing feature\nmatching cost volumes and using 3D convolutions for cost aggregation. However,\nmost existing methods suffer from large number of parameters and slow running\ntime due to the sequential use of 3D convolutions. In this paper, we propose\nGhost-Stereo, a novel end-to-end stereo matching network. The feature\nextraction part of the network uses the GhostNet to form a U-shaped structure.\nThe core of Ghost-Stereo is a GhostNet feature-based cost volume enhancement\n(Ghost-CVE) module and a GhostNet-inspired lightweight cost volume aggregation\n(Ghost-CVA) module. For the Ghost-CVE part, cost volumes are constructed and\nfused by the GhostNet-based features to enhance the spatial context awareness.\nFor the Ghost-CVA part, a lightweight 3D convolution bottleneck block based on\nthe GhostNet is proposed to reduce the computational complexity in this module.\nBy combining with the context and geometry fusion module, a classical\nhourglass-shaped cost volume aggregate structure is constructed. Ghost-Stereo\nachieves a comparable performance than state-of-the-art real-time methods on\nseveral publicly benchmarks, and shows a better generalization ability.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xingguang Jiang",
            "Xiaofeng Bian",
            "Chenggang Guo"
        ],
        "published": "2024-05-23T13:02:30Z"
    },
    {
        "title": "A New Formulation for Zeroth-Order Optimization of Adversarial EXEmples\n  in Malware Detection",
        "link": "http://arxiv.org/abs/2405.14519v1",
        "abstract": "Machine learning malware detectors are vulnerable to adversarial EXEmples,\ni.e. carefully-crafted Windows programs tailored to evade detection. Unlike\nother adversarial problems, attacks in this context must be\nfunctionality-preserving, a constraint which is challenging to address. As a\nconsequence heuristic algorithms are typically used, that inject new content,\neither randomly-picked or harvested from legitimate programs. In this paper, we\nshow how learning malware detectors can be cast within a zeroth-order\noptimization framework which allows to incorporate functionality-preserving\nmanipulations. This permits the deployment of sound and efficient gradient-free\noptimization algorithms, which come with theoretical guarantees and allow for\nminimal hyper-parameters tuning. As a by-product, we propose and study ZEXE, a\nnovel zero-order attack against Windows malware detection. Compared to\nstate-of-the-art techniques, ZEXE provides drastic improvement in the evasion\nrate, while reducing to less than one third the size of the injected content.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Marco Rando",
            "Luca Demetrio",
            "Lorenzo Rosasco",
            "Fabio Roli"
        ],
        "published": "2024-05-23T13:01:36Z"
    },
    {
        "title": "Identity Inference from CLIP Models using Only Textual Data",
        "link": "http://arxiv.org/abs/2405.14517v1",
        "abstract": "The widespread usage of large-scale multimodal models like CLIP has\nheightened concerns about the leakage of personally identifiable information\n(PII). Existing methods for identity inference in CLIP models, i.e., to detect\nthe presence of a person's PII used for training a CLIP model, require querying\nthe model with full PII, including textual descriptions of the person and\ncorresponding images (e.g., the name and the face photo of the person).\nHowever, this may lead to potential privacy breach of the image, as it may have\nnot been seen by the target model yet. Additionally, traditional membership\ninference attacks (MIAs) train shadow models to mimic the behaviors of the\ntarget model, which incurs high computational costs, especially for large CLIP\nmodels. To address these challenges, we propose a textual unimodal detector\n(TUNI) in CLIP models, a novel method for ID inference that 1) queries the\ntarget model with only text data; and 2) does not require training shadow\nmodels. Firstly, we develop a feature extraction algorithm, guided by the CLIP\nmodel, to extract features from a text description. TUNI starts with randomly\ngenerating textual gibberish that were clearly not utilized for training, and\nleverages their feature vectors to train a system of anomaly detectors. During\ninference, the feature vector of each test text is fed into the anomaly\ndetectors to determine if the person's PII is in the training set (abnormal) or\nnot (normal). Moreover, TUNI can be further strengthened integrating real\nimages associated with the tested individuals, if available at the detector.\nExtensive experiments of TUNI across various CLIP model architectures and\ndatasets demonstrate its superior performance over baselines, albeit with only\ntext data.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "authors": [
            "Songze Li",
            "Ruoxi Cheng",
            "Xiaojun Jia"
        ],
        "published": "2024-05-23T12:54:25Z"
    },
    {
        "title": "Towards Realistic Long-tailed Semi-supervised Learning in an Open World",
        "link": "http://arxiv.org/abs/2405.14516v1",
        "abstract": "Open-world long-tailed semi-supervised learning (OLSSL) has increasingly\nattracted attention. However, existing OLSSL algorithms generally assume that\nthe distributions between known and novel categories are nearly identical.\nAgainst this backdrop, we construct a more \\emph{Realistic Open-world\nLong-tailed Semi-supervised Learning} (\\textbf{ROLSSL}) setting where there is\nno premise on the distribution relationships between known and novel\ncategories. Furthermore, even within the known categories, the number of\nlabeled samples is significantly smaller than that of the unlabeled samples, as\nacquiring valid annotations is often prohibitively costly in the real world.\nUnder the proposed ROLSSL setting, we propose a simple yet potentially\neffective solution called dual-stage post-hoc logit adjustments. The proposed\napproach revisits the logit adjustment strategy by considering the\nrelationships among the frequency of samples, the total number of categories,\nand the overall size of data. Then, it estimates the distribution of unlabeled\ndata for both known and novel categories to dynamically readjust the\ncorresponding predictive probabilities, effectively mitigating category bias\nduring the learning of known and novel classes with more selective utilization\nof imbalanced unlabeled data. Extensive experiments on datasets such as\nCIFAR100 and ImageNet100 have demonstrated performance improvements of up to\n50.1\\%, validating the superiority of our proposed method and establishing a\nstrong baseline for this task. For further researches, the anonymous link to\nthe experimental code is at\n\\href{https://github.com/heyuanpengpku/ROLSSL}{\\textcolor{brightpink}{https://github.com/heyuanpengpku/ROLSSL}}",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Yuanpeng He",
            "Lijian Li"
        ],
        "published": "2024-05-23T12:53:50Z"
    },
    {
        "title": "Visuo-Tactile Keypoint Correspondences for Object Manipulation",
        "link": "http://arxiv.org/abs/2405.14515v1",
        "abstract": "This paper presents a novel manipulation strategy that uses keypoint\ncorrespondences extracted from visuo-tactile sensor images to facilitate\nprecise object manipulation. Our approach uses the visuo-tactile feedback to\nguide the robot's actions for accurate object grasping and placement,\neliminating the need for post-grasp adjustments and extensive training. This\nmethod provides an improvement in deployment efficiency, addressing the\nchallenges of manipulation tasks in environments where object locations are not\npredefined. We validate the effectiveness of our strategy through experiments\ndemonstrating the extraction of keypoint correspondences and their application\nto real-world tasks such as block alignment and gear insertion, which require\nmillimeter-level precision. The results show an average error margin\nsignificantly lower than that of traditional vision-based methods, which is\nsufficient to achieve the target tasks.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Jeong-Jung Kim",
            "Doo-Yeol Koh",
            "Chang-Hyun Kim"
        ],
        "published": "2024-05-23T12:52:57Z"
    },
    {
        "title": "Unchosen Experts Can Contribute Too: Unleashing MoE Models' Power by\n  Self-Contrast",
        "link": "http://arxiv.org/abs/2405.14507v1",
        "abstract": "Mixture-of-Experts (MoE) has emerged as a prominent architecture for scaling\nmodel size while maintaining computational efficiency. In MoE, each token in\nthe input sequence activates a different subset of experts determined by a\nrouting mechanism. However, the unchosen experts in MoE models do not\ncontribute to the output, potentially leading to underutilization of the\nmodel's capacity. In this work, we first conduct exploratory studies to\ndemonstrate that increasing the number of activated experts does not\nnecessarily improve and can even degrade the output quality. Then, we show that\noutput distributions from an MoE model using different routing strategies\nsubstantially differ, indicating that different experts do not always act\nsynergistically. Motivated by these findings, we propose Self-Contrast\nMixture-of-Experts (SCMoE), a training-free strategy that utilizes unchosen\nexperts in a self-contrast manner during inference. In SCMoE, the next-token\nprobabilities are determined by contrasting the outputs from strong and weak\nactivation using the same MoE model. Our method is conceptually simple and\ncomputationally lightweight, as it incurs minimal latency compared to greedy\ndecoding. Experiments on several benchmarks (GSM8K, StrategyQA, MBPP and\nHumanEval) demonstrate that SCMoE can consistently enhance Mixtral 8x7B's\nreasoning capability across various domains. For example, it improves the\naccuracy on GSM8K from 61.79 to 66.94. Moreover, combining SCMoE with\nself-consistency yields additional gains, increasing major@20 accuracy from\n75.59 to 78.31.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Chufan Shi",
            "Cheng Yang",
            "Xinyu Zhu",
            "Jiahao Wang",
            "Taiqiang Wu",
            "Siheng Li",
            "Deng Cai",
            "Yujiu Yang",
            "Yu Meng"
        ],
        "published": "2024-05-23T12:45:29Z"
    },
    {
        "title": "SIAVC: Semi-Supervised Framework for Industrial Accident Video\n  Classification",
        "link": "http://arxiv.org/abs/2405.14506v1",
        "abstract": "Semi-supervised learning suffers from the imbalance of labeled and unlabeled\ntraining data in the video surveillance scenario. In this paper, we propose a\nnew semi-supervised learning method called SIAVC for industrial accident video\nclassification. Specifically, we design a video augmentation module called the\nSuper Augmentation Block (SAB). SAB adds Gaussian noise and randomly masks\nvideo frames according to historical loss on the unlabeled data for model\noptimization. Then, we propose a Video Cross-set Augmentation Module (VCAM) to\ngenerate diverse pseudo-label samples from the high-confidence unlabeled\nsamples, which alleviates the mismatch of sampling experience and provides\nhigh-quality training data. Additionally, we construct a new industrial\naccident surveillance video dataset with frame-level annotation, namely ECA9,\nto evaluate our proposed method. Compared with the state-of-the-art\nsemi-supervised learning based methods, SIAVC demonstrates outstanding video\nclassification performance, achieving 88.76\\% and 89.13\\% accuracy on ECA9 and\nFire Detection datasets, respectively. The source code and the constructed\ndataset ECA9 will be released in \\url{https://github.com/AlchemyEmperor/SIAVC}.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Zuoyong Li",
            "Qinghua Lin",
            "Haoyi Fan",
            "Tiesong Zhao",
            "David Zhang"
        ],
        "published": "2024-05-23T12:44:51Z"
    },
    {
        "title": "Explainable automatic industrial carbon footprint estimation from bank\n  transaction classification using natural language processing",
        "link": "http://dx.doi.org/10.1109/ACCESS.2022.3226324",
        "abstract": "Concerns about the effect of greenhouse gases have motivated the development\nof certification protocols to quantify the industrial carbon footprint (CF).\nThese protocols are manual, work-intensive, and expensive. All of the above\nhave led to a shift towards automatic data-driven approaches to estimate the\nCF, including Machine Learning (ML) solutions. Unfortunately, the\ndecision-making processes involved in these solutions lack transparency from\nthe end user's point of view, who must blindly trust their outcomes compared to\nintelligible traditional manual approaches. In this research, manual and\nautomatic methodologies for CF estimation were reviewed, taking into account\ntheir transparency limitations. This analysis led to the proposal of a new\nexplainable ML solution for automatic CF calculations through bank transaction\nclassification. Consideration should be given to the fact that no previous\nresearch has considered the explainability of bank transaction classification\nfor this purpose. For classification, different ML models have been employed\nbased on their promising performance in the literature, such as Support Vector\nMachine, Random Forest, and Recursive Neural Networks. The results obtained\nwere in the 90 % range for accuracy, precision, and recall evaluation metrics.\nFrom their decision paths, the proposed solution estimates the CO2 emissions\nassociated with bank transactions. The explainability methodology is based on\nan agnostic evaluation of the influence of the input terms extracted from the\ndescriptions of transactions using locally interpretable models. The\nexplainability terms were automatically validated using a similarity metric\nover the descriptions of the target categories. Conclusively, the explanation\nperformance is satisfactory in terms of the proximity of the explanations to\nthe associated activity sector descriptions.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CE",
            "cs.LG"
        ],
        "authors": [
            "Jaime González-González",
            "Silvia García-Méndez",
            "Francisco de Arriba-Pérez",
            "Francisco J. González-Castaño",
            "Óscar Barba-Seara"
        ],
        "published": "2024-05-23T12:43:06Z"
    },
    {
        "title": "Enhanced Spatiotemporal Prediction Using Physical-guided And\n  Frequency-enhanced Recurrent Neural Networks",
        "link": "http://arxiv.org/abs/2405.14504v1",
        "abstract": "Spatiotemporal prediction plays an important role in solving natural problems\nand processing video frames, especially in weather forecasting and human action\nrecognition. Recent advances attempt to incorporate prior physical knowledge\ninto the deep learning framework to estimate the unknown governing partial\ndifferential equations (PDEs), which have shown promising results in\nspatiotemporal prediction tasks. However, previous approaches only restrict\nneural network architectures or loss functions to acquire physical or PDE\nfeatures, which decreases the representative capacity of a neural network.\nMeanwhile, the updating process of the physical state cannot be effectively\nestimated. To solve the above mentioned problems, this paper proposes a\nphysical-guided neural network, which utilizes the frequency-enhanced Fourier\nmodule and moment loss to strengthen the model's ability to estimate the\nspatiotemporal dynamics. Furthermore, we propose an adaptive second-order\nRunge-Kutta method with physical constraints to model the physical states more\nprecisely. We evaluate our model on both spatiotemporal and video prediction\ntasks. The experimental results show that our model outperforms\nstate-of-the-art methods and performs best in several datasets, with a much\nsmaller parameter count.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Xuanle Zhao",
            "Yue Sun",
            "Tielin Zhang",
            "Bo Xu"
        ],
        "published": "2024-05-23T12:39:49Z"
    },
    {
        "title": "DEX: Scalable Range Indexing on Disaggregated Memory [Extended Version]",
        "link": "http://arxiv.org/abs/2405.14502v1",
        "abstract": "Memory disaggregation can potentially allow memory-optimized range indexes\nsuch as B+-trees to scale beyond one machine while attaining high hardware\nutilization and low cost. Designing scalable indexes on disaggregated memory,\nhowever, is challenging due to rudimentary caching, unprincipled offloading and\nexcessive inconsistency among servers.\n  This paper proposes DEX, a new scalable B+-tree for memory disaggregation.\nDEX includes a set of techniques to reduce remote accesses, including logical\npartitioning, lightweight caching and cost-aware offloading. Our evaluation\nshows that DEX can outperform the state-of-the-art by 1.7--56.3X, and the\nadvantage remains under various setups, such as cache size and skewness.",
        "subjects": [
            "cs.DB",
            "cs.DC"
        ],
        "authors": [
            "Baotong Lu",
            "Kaisong Huang",
            "Chieh-Jan Mike Liang",
            "Tianzheng Wang",
            "Eric Lo"
        ],
        "published": "2024-05-23T12:35:08Z"
    },
    {
        "title": "Improving Single Domain-Generalized Object Detection: A Focus on\n  Diversification and Alignment",
        "link": "http://arxiv.org/abs/2405.14497v1",
        "abstract": "In this work, we tackle the problem of domain generalization for object\ndetection, specifically focusing on the scenario where only a single source\ndomain is available. We propose an effective approach that involves two key\nsteps: diversifying the source domain and aligning detections based on class\nprediction confidence and localization. Firstly, we demonstrate that by\ncarefully selecting a set of augmentations, a base detector can outperform\nexisting methods for single domain generalization by a good margin. This\nhighlights the importance of domain diversification in improving the\nperformance of object detectors. Secondly, we introduce a method to align\ndetections from multiple views, considering both classification and\nlocalization outputs. This alignment procedure leads to better generalized and\nwell-calibrated object detector models, which are crucial for accurate\ndecision-making in safety-critical applications. Our approach is\ndetector-agnostic and can be seamlessly applied to both single-stage and\ntwo-stage detectors. To validate the effectiveness of our proposed methods, we\nconduct extensive experiments and ablations on challenging domain-shift\nscenarios. The results consistently demonstrate the superiority of our approach\ncompared to existing methods. Our code and models are available at:\nhttps://github.com/msohaildanish/DivAlign",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Muhammad Sohail Danish",
            "Muhammad Haris Khan",
            "Muhammad Akhtar Munir",
            "M. Saquib Sarfraz",
            "Mohsen Ali"
        ],
        "published": "2024-05-23T12:29:25Z"
    },
    {
        "title": "Hybrid Global Causal Discovery with Local Search",
        "link": "http://arxiv.org/abs/2405.14496v1",
        "abstract": "Learning the unique directed acyclic graph corresponding to an unknown causal\nmodel is a challenging task. Methods based on functional causal models can\nidentify a unique graph, but either suffer from the curse of dimensionality or\nimpose strong parametric assumptions. To address these challenges, we propose a\nnovel hybrid approach for global causal discovery in observational data that\nleverages local causal substructures. We first present a topological sorting\nalgorithm that leverages ancestral relationships in linear structural equation\nmodels to establish a compact top-down hierarchical ordering, encoding more\ncausal information than linear orderings produced by existing methods. We\ndemonstrate that this approach generalizes to nonlinear settings with arbitrary\nnoise. We then introduce a nonparametric constraint-based algorithm that prunes\nspurious edges by searching for local conditioning sets, achieving greater\naccuracy than current methods. We provide theoretical guarantees for\ncorrectness and worst-case polynomial time complexities, with empirical\nvalidation on synthetic data.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Sujai Hiremath",
            "Jacqueline R. M. A. Maasch",
            "Mengxiao Gao",
            "Promit Ghosal",
            "Kyra Gan"
        ],
        "published": "2024-05-23T12:28:16Z"
    },
    {
        "title": "Entrywise error bounds for low-rank approximations of kernel matrices",
        "link": "http://arxiv.org/abs/2405.14494v1",
        "abstract": "In this paper, we derive entrywise error bounds for low-rank approximations\nof kernel matrices obtained using the truncated eigen-decomposition (or\nsingular value decomposition). While this approximation is well-known to be\noptimal with respect to the spectral and Frobenius norm error, little is known\nabout the statistical behaviour of individual entries. Our error bounds fill\nthis gap. A key technical innovation is a delocalisation result for the\neigenvectors of the kernel matrix corresponding to small eigenvalues, which\ntakes inspiration from the field of Random Matrix Theory. Finally, we validate\nour theory with an empirical study of a collection of synthetic and real-world\ndatasets.",
        "subjects": [
            "math.ST",
            "cs.LG",
            "stat.TH",
            "62G20"
        ],
        "authors": [
            "Alexander Modell"
        ],
        "published": "2024-05-23T12:26:25Z"
    },
    {
        "title": "Minimum Consistent Subset in Interval Graphs and Circle Graphs",
        "link": "http://arxiv.org/abs/2405.14493v1",
        "abstract": "In a connected simple graph G = (V,E), each vertex of V is colored by a color\nfrom the set of colors C={c1, c2,..., c_{\\alpha}}$. We take a subset S of V,\nsuch that for every vertex v in V\\S, at least one vertex of the same color is\npresent in its set of nearest neighbors in S. We refer to such a S as a\nconsistent subset. The Minimum Consistent Subset (MCS) problem is the\ncomputation of a consistent subset of the minimum size. It is established that\nMCS is NP-complete for general graphs, including planar graphs. We expand our\nstudy to interval graphs and circle graphs in an attempt to gain a complete\nunderstanding of the computational complexity of the \\mcs problem across\nvarious graph classes.\n  This work introduces an (4\\alpha+ 2)- approximation algorithm for MCS in\ninterval graphs where \\alpha is the number of colors in the interval graphs.\nLater, we show that in circle graphs, MCS is APX-hard.",
        "subjects": [
            "cs.CG"
        ],
        "authors": [
            "Bubai Manna"
        ],
        "published": "2024-05-23T12:25:31Z"
    },
    {
        "title": "Iterative Methods for Full-Scale Gaussian Process Approximations for\n  Large Spatial Data",
        "link": "http://arxiv.org/abs/2405.14492v1",
        "abstract": "Gaussian processes are flexible probabilistic regression models which are\nwidely used in statistics and machine learning. However, a drawback is their\nlimited scalability to large data sets. To alleviate this, we consider\nfull-scale approximations (FSAs) that combine predictive process methods and\ncovariance tapering, thus approximating both global and local structures. We\nshow how iterative methods can be used to reduce the computational costs for\ncalculating likelihoods, gradients, and predictive distributions with FSAs. We\nintroduce a novel preconditioner and show that it accelerates the conjugate\ngradient method's convergence speed and mitigates its sensitivity with respect\nto the FSA parameters and the eigenvalue structure of the original covariance\nmatrix, and we demonstrate empirically that it outperforms a state-of-the-art\npivoted Cholesky preconditioner. Further, we present a novel, accurate, and\nfast way to calculate predictive variances relying on stochastic estimations\nand iterative methods. In both simulated and real-world data experiments, we\nfind that our proposed methodology achieves the same accuracy as Cholesky-based\ncomputations with a substantial reduction in computational time. Finally, we\nalso compare different approaches for determining inducing points in predictive\nprocess and FSA models. All methods are implemented in a free C++ software\nlibrary with high-level Python and R packages.",
        "subjects": [
            "stat.ME",
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Tim Gyger",
            "Reinhard Furrer",
            "Fabio Sigrist"
        ],
        "published": "2024-05-23T12:25:22Z"
    },
    {
        "title": "Impact of Non-Standard Unicode Characters on Security and Comprehension\n  in Large Language Models",
        "link": "http://arxiv.org/abs/2405.14490v1",
        "abstract": "The advancement of large language models has significantly improved natural\nlanguage processing. However, challenges such as jailbreaks (prompt injections\nthat cause an LLM to follow instructions contrary to its intended use),\nhallucinations (generating incorrect or misleading information), and\ncomprehension errors remain prevalent. In this report, we present a comparative\nanalysis of the performance of fifteen distinct models, with each model\nundergoing a standardized test comprising 38 queries across three key metrics:\njailbreaks, hallucinations, and comprehension errors. The models are assessed\nbased on the total occurrences of jailbreaks, hallucinations, and comprehension\nerrors. Our work exposes these models' inherent vulnerabilities and challenges\nthe notion of human-level language comprehension of these models. We have\nempirically analysed the impact of non-standard Unicode characters on LLMs and\ntheir safeguarding mechanisms on the best-performing LLMs, including GPT-4,\nGemini 1.5 Pro, LlaMA-3-70B, and Claude 3 Opus. By incorporating alphanumeric\nsymbols from Unicode outside the standard Latin block and variants of\ncharacters in other languages, we observed a reduction in the efficacy of\nguardrails implemented through Reinforcement Learning Human Feedback (RLHF).\nConsequently, these models exhibit heightened vulnerability to content policy\nbreaches and prompt leakage. Our study also suggests a need to incorporate\nnon-standard Unicode text in LLM training data to enhance the capabilities of\nthese models.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Johan S Daniel",
            "Anand Pal"
        ],
        "published": "2024-05-23T12:24:38Z"
    },
    {
        "title": "End-to-End User-Defined Keyword Spotting using Shifted Delta\n  Coefficients",
        "link": "http://arxiv.org/abs/2405.14489v1",
        "abstract": "Identifying user-defined keywords is crucial for personalizing interactions\nwith smart devices. Previous approaches of user-defined keyword spotting\n(UDKWS) have relied on short-term spectral features such as mel frequency\ncepstral coefficients (MFCC) to detect the spoken keyword. However, these\nfeatures may face challenges in accurately identifying closely related\npronunciation of audio-text pairs, due to their limited capability in capturing\nthe temporal dynamics of the speech signal. To address this challenge, we\npropose to use shifted delta coefficients (SDC) which help in capturing\npronunciation variability (transition between connecting phonemes) by\nincorporating long-term temporal information. The performance of the SDC\nfeature is compared with various baseline features across four different\ndatasets using a cross-attention based end-to-end system. Additionally, various\nconfigurations of SDC are explored to find the suitable temporal context for\nthe UDKWS task. The experimental results reveal that the SDC feature\noutperforms the MFCC baseline feature, exhibiting an improvement of 8.32% in\narea under the curve (AUC) and 8.69% in terms of equal error rate (EER) on the\nchallenging Libriphrase-hard dataset. Moreover, the proposed approach\ndemonstrated superior performance when compared to state-of-the-art UDKWS\ntechniques.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "authors": [
            "Kesavaraj V",
            "Anuprabha M",
            "Anil Kumar Vuppala"
        ],
        "published": "2024-05-23T12:24:01Z"
    },
    {
        "title": "MoGU: A Framework for Enhancing Safety of Open-Sourced LLMs While\n  Preserving Their Usability",
        "link": "http://arxiv.org/abs/2405.14488v1",
        "abstract": "Large Language Models (LLMs) are increasingly deployed in various\napplications. As their usage grows, concerns regarding their safety are rising,\nespecially in maintaining harmless responses when faced with malicious\ninstructions. Many defense strategies have been developed to enhance the safety\nof LLMs. However, our research finds that existing defense strategies lead LLMs\nto predominantly adopt a rejection-oriented stance, thereby diminishing the\nusability of their responses to benign instructions. To solve this problem, we\nintroduce the MoGU framework, designed to enhance LLMs' safety while preserving\ntheir usability. Our MoGU framework transforms the base LLM into two variants:\nthe usable LLM and the safe LLM, and further employs dynamic routing to balance\ntheir contribution. When encountering malicious instructions, the router will\nassign a higher weight to the safe LLM to ensure that responses are harmless.\nConversely, for benign instructions, the router prioritizes the usable LLM,\nfacilitating usable and helpful responses. On various open-sourced LLMs, we\ncompare multiple defense strategies to verify the superiority of our MoGU\nframework. Besides, our analysis provides key insights into the effectiveness\nof MoGU and verifies that our designed routing mechanism can effectively\nbalance the contribution of each variant by assigning weights. Our work\nreleased the safer Llama2, Vicuna, Falcon, Dolphin, and Baichuan2.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yanrui Du",
            "Sendong Zhao",
            "Danyang Zhao",
            "Ming Ma",
            "Yuhan Chen",
            "Liangyu Huo",
            "Qing Yang",
            "Dongliang Xu",
            "Bing Qin"
        ],
        "published": "2024-05-23T12:19:59Z"
    },
    {
        "title": "A Comprehensive Overview of Large Language Models (LLMs) for Cyber\n  Defences: Opportunities and Directions",
        "link": "http://arxiv.org/abs/2405.14487v1",
        "abstract": "The recent progression of Large Language Models (LLMs) has witnessed great\nsuccess in the fields of data-centric applications. LLMs trained on massive\ntextual datasets showed ability to encode not only context but also ability to\nprovide powerful comprehension to downstream tasks. Interestingly, Generative\nPre-trained Transformers utilised this ability to bring AI a step closer to\nhuman being replacement in at least datacentric applications. Such power can be\nleveraged to identify anomalies of cyber threats, enhance incident response,\nand automate routine security operations. We provide an overview for the recent\nactivities of LLMs in cyber defence sections, as well as categorization for the\ncyber defence sections such as threat intelligence, vulnerability assessment,\nnetwork security, privacy preserving, awareness and training, automation, and\nethical guidelines. Fundamental concepts of the progression of LLMs from\nTransformers, Pre-trained Transformers, and GPT is presented. Next, the recent\nworks of each section is surveyed with the related strengths and weaknesses. A\nspecial section about the challenges and directions of LLMs in cyber security\nis provided. Finally, possible future research directions for benefiting from\nLLMs in cyber security is discussed.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Mohammed Hassanin",
            "Nour Moustafa"
        ],
        "published": "2024-05-23T12:19:07Z"
    },
    {
        "title": "RefChecker: Reference-based Fine-grained Hallucination Checker and\n  Benchmark for Large Language Models",
        "link": "http://arxiv.org/abs/2405.14486v1",
        "abstract": "Large Language Models (LLMs) have shown impressive capabilities but also a\nconcerning tendency to hallucinate. This paper presents RefChecker, a framework\nthat introduces claim-triplets to represent claims in LLM responses, aiming to\ndetect fine-grained hallucinations. In RefChecker, an extractor generates\nclaim-triplets from a response, which are then evaluated by a checker against a\nreference. We delineate three task settings: Zero, Noisy and Accurate Context,\nto reflect various real-world use cases. We curated a benchmark spanning\nvarious NLP tasks and annotated 11k claim-triplets from 2.1k responses by seven\nLLMs. RefChecker supports both proprietary and open-source models as the\nextractor and checker. Experiments demonstrate that claim-triplets enable\nsuperior hallucination detection, compared to other granularities such as\nresponse, sentence and sub-sentence level claims. RefChecker outperforms prior\nmethods by 6.8 to 26.1 points on our benchmark and the checking results of\nRefChecker are strongly aligned with human judgments. This work is open sourced\nat https://github.com/amazon-science/RefChecker",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Xiangkun Hu",
            "Dongyu Ru",
            "Lin Qiu",
            "Qipeng Guo",
            "Tianhang Zhang",
            "Yang Xu",
            "Yun Luo",
            "Pengfei Liu",
            "Yue Zhang",
            "Zheng Zhang"
        ],
        "published": "2024-05-23T12:18:11Z"
    },
    {
        "title": "Novel semi-explicit symplectic schemes for nonseparable stochastic\n  Hamiltonian systems",
        "link": "http://arxiv.org/abs/2405.14484v1",
        "abstract": "In this manuscript, we propose efficient stochastic semi-explicit symplectic\nschemes tailored for nonseparable stochastic Hamiltonian systems (SHSs). These\nsemi-explicit symplectic schemes are constructed by introducing augmented\nHamiltonians and using symmetric projection. In the case of the artificial\nrestraint in augmented Hamiltonians being zero, the proposed schemes also\npreserve quadratic invariants, making them suitable for developing\nsemi-explicit charge-preserved multi-symplectic schemes for stochastic cubic\nSchr\\\"odinger equations with multiplicative noise. Through numerical\nexperiments that validate theoretical results, we demonstrate that the proposed\nstochastic semi-explicit symplectic scheme, which features a straightforward\nNewton iteration solver, outperforms the traditional stochastic midpoint scheme\nin terms of effectiveness and accuracy.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Jialin Hong",
            "Baohui Hou",
            "Liying Sun"
        ],
        "published": "2024-05-23T12:15:55Z"
    },
    {
        "title": "Quantifying Multivariate Graph Dependencies: Theory and Estimation for\n  Multiplex Graphs",
        "link": "http://arxiv.org/abs/2405.14482v1",
        "abstract": "Multiplex graphs, characterised by their layered structure, exhibit\ninformative interdependencies within layers that are crucial for understanding\ncomplex network dynamics. Quantifying the interaction and shared information\namong these layers is challenging due to the non-Euclidean structure of graphs.\nOur paper introduces a comprehensive theory of multivariate information\nmeasures for multiplex graphs. We introduce graphon mutual information for\npairs of graphs and expand this to graphon interaction information for three or\nmore graphs, including their conditional variants. We then define graphon total\ncorrelation and graphon dual total correlation, along with their conditional\nforms, and introduce graphon $O-$information. We discuss and quantify the\nconcepts of synergy and redundancy in graphs for the first time, introduce\nconsistent nonparametric estimators for these multivariate graphon\ninformation--theoretic measures, and provide their convergence rates. We also\nconduct a simulation study to illustrate our theoretical findings and\ndemonstrate the relationship between the introduced measures, multiplex graph\nstructure, and higher--order interdependecies. Real-world applications further\nshow the utility of our estimators in revealing shared information and\ndependence structures in real-world multiplex graphs. This work not only\nanswers fundamental questions about information sharing across multiple graphs\nbut also sets the stage for advanced pattern analysis in complex networks.",
        "subjects": [
            "math.ST",
            "cs.IT",
            "math.CO",
            "math.IT",
            "math.PR",
            "stat.TH"
        ],
        "authors": [
            "Anda Skeja",
            "Sofia C. Olhede"
        ],
        "published": "2024-05-23T12:14:29Z"
    },
    {
        "title": "A logic of judgmental existence and its relation to proof irrelevance",
        "link": "http://arxiv.org/abs/2405.14481v1",
        "abstract": "We introduce a simple natural deduction system for reasoning with judgments\nof the form \"there exists a proof of $\\varphi$\" to explore the notion of\njudgmental existence following Martin-L\\\"{o}f's methodology of distinguishing\nbetween judgments and propositions. In this system, the existential judgment\ncan be internalized into a modal notion of propositional existence that is\nclosely related to truncation modality, a key tool for obtaining proof\nirrelevance, and lax modality. We provide a computational interpretation in the\nstyle of the Curry-Howard isomorphism for the existence modality and show that\nthe corresponding system has some desirable properties such as strong\nnormalization or subject reduction.",
        "subjects": [
            "cs.LO",
            "math.LO"
        ],
        "authors": [
            "Ivo Pezlar"
        ],
        "published": "2024-05-23T12:13:55Z"
    },
    {
        "title": "Scalable Visual State Space Model with Fractal Scanning",
        "link": "http://arxiv.org/abs/2405.14480v1",
        "abstract": "Foundational models have significantly advanced in natural language\nprocessing (NLP) and computer vision (CV), with the Transformer architecture\nbecoming a standard backbone. However, the Transformer's quadratic complexity\nposes challenges for handling longer sequences and higher resolution images. To\naddress this challenge, State Space Models (SSMs) like Mamba have emerged as\nefficient alternatives, initially matching Transformer performance in NLP tasks\nand later surpassing Vision Transformers (ViTs) in various CV tasks. To improve\nthe performance of SSMs, one crucial aspect is effective serialization of image\npatches. Existing methods, relying on linear scanning curves, often fail to\ncapture complex spatial relationships and produce repetitive patterns, leading\nto biases. To address these limitations, we propose using fractal scanning\ncurves for patch serialization. Fractal curves maintain high spatial proximity\nand adapt to different image resolutions, avoiding redundancy and enhancing\nSSMs' ability to model complex patterns accurately. We validate our method in\nimage classification, detection, and segmentation tasks, and the superior\nperformance validates its effectiveness.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Lv Tang",
            "HaoKe Xiao",
            "Peng-Tao Jiang",
            "Hao Zhang",
            "Jinwei Chen",
            "Bo Li"
        ],
        "published": "2024-05-23T12:12:11Z"
    },
    {
        "title": "SLIFER: Investigating Performance and Robustness of Malware Detection\n  Pipelines",
        "link": "http://arxiv.org/abs/2405.14478v1",
        "abstract": "As a result of decades of research, Windows malware detection is approached\nthrough a plethora of techniques. However, there is an ongoing mismatch between\nacademia -- which pursues an optimal performances in terms of detection rate\nand low false alarms -- and the requirements of real-world scenarios. In\nparticular, academia focuses on combining static and dynamic analysis within a\nsingle or ensemble of models, falling into several pitfalls like (i) firing\ndynamic analysis without considering the computational burden it requires; (ii)\ndiscarding impossible-to-analyse samples; and (iii) analysing robustness\nagainst adversarial attacks without considering that malware detectors are\ncomplemented with more non-machine-learning components. Thus, in this paper we\npropose SLIFER, a novel Windows malware detection pipeline sequentially\nleveraging both static and dynamic analysis, interrupting computations as soon\nas one module triggers an alarm, requiring dynamic analysis only when needed.\nContrary to the state of the art, we investigate how to deal with samples\nresistance to analysis, showing how much they impact performances, concluding\nthat it is better to flag them as legitimate to not drastically increase false\nalarms. Lastly, we perform a robustness evaluation of SLIFER leveraging\ncontent-injections attacks, and we show that, counter-intuitively, attacks are\nblocked more by YARA rules than dynamic analysis due to byte artifacts created\nwhile optimizing the adversarial strategy.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "authors": [
            "Andrea Ponte",
            "Dmitrijs Trizna",
            "Luca Demetrio",
            "Battista Biggio",
            "Fabio Roli"
        ],
        "published": "2024-05-23T12:06:10Z"
    },
    {
        "title": "LiteVAE: Lightweight and Efficient Variational Autoencoders for Latent\n  Diffusion Models",
        "link": "http://arxiv.org/abs/2405.14477v1",
        "abstract": "Advances in latent diffusion models (LDMs) have revolutionized\nhigh-resolution image generation, but the design space of the autoencoder that\nis central to these systems remains underexplored. In this paper, we introduce\nLiteVAE, a family of autoencoders for LDMs that leverage the 2D discrete\nwavelet transform to enhance scalability and computational efficiency over\nstandard variational autoencoders (VAEs) with no sacrifice in output quality.\nWe also investigate the training methodologies and the decoder architecture of\nLiteVAE and propose several enhancements that improve the training dynamics and\nreconstruction quality. Our base LiteVAE model matches the quality of the\nestablished VAEs in current LDMs with a six-fold reduction in encoder\nparameters, leading to faster training and lower GPU memory requirements, while\nour larger model outperforms VAEs of comparable complexity across all evaluated\nmetrics (rFID, LPIPS, PSNR, and SSIM).",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Seyedmorteza Sadat",
            "Jakob Buhmann",
            "Derek Bradley",
            "Otmar Hilliges",
            "Romann M. Weber"
        ],
        "published": "2024-05-23T12:06:00Z"
    },
    {
        "title": "MagicDrive3D: Controllable 3D Generation for Any-View Rendering in\n  Street Scenes",
        "link": "http://arxiv.org/abs/2405.14475v1",
        "abstract": "While controllable generative models for images and videos have achieved\nremarkable success, high-quality models for 3D scenes, particularly in\nunbounded scenarios like autonomous driving, remain underdeveloped due to high\ndata acquisition costs. In this paper, we introduce MagicDrive3D, a novel\npipeline for controllable 3D street scene generation that supports\nmulti-condition control, including BEV maps, 3D objects, and text descriptions.\nUnlike previous methods that reconstruct before training the generative models,\nMagicDrive3D first trains a video generation model and then reconstructs from\nthe generated data. This innovative approach enables easily controllable\ngeneration and static scene acquisition, resulting in high-quality scene\nreconstruction. To address the minor errors in generated content, we propose\ndeformable Gaussian splatting with monocular depth initialization and\nappearance modeling to manage exposure discrepancies across viewpoints.\nValidated on the nuScenes dataset, MagicDrive3D generates diverse, high-quality\n3D driving scenes that support any-view rendering and enhance downstream tasks\nlike BEV segmentation. Our results demonstrate the framework's superior\nperformance, showcasing its transformative potential for autonomous driving\nsimulation and beyond.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Ruiyuan Gao",
            "Kai Chen",
            "Zhihao Li",
            "Lanqing Hong",
            "Zhenguo Li",
            "Qiang Xu"
        ],
        "published": "2024-05-23T12:04:51Z"
    },
    {
        "title": "Time Cell Inspired Temporal Codebook in Spiking Neural Networks for\n  Enhanced Image Generation",
        "link": "http://arxiv.org/abs/2405.14474v1",
        "abstract": "This paper presents a novel approach leveraging Spiking Neural Networks\n(SNNs) to construct a Variational Quantized Autoencoder (VQ-VAE) with a\ntemporal codebook inspired by hippocampal time cells. This design captures and\nutilizes temporal dependencies, significantly enhancing the generative\ncapabilities of SNNs. Neuroscientific research has identified hippocampal \"time\ncells\" that fire sequentially during temporally structured experiences. Our\ntemporal codebook emulates this behavior by triggering the activation of time\ncell populations based on similarity measures as input stimuli pass through it.\nWe conducted extensive experiments on standard benchmark datasets, including\nMNIST, FashionMNIST, CIFAR10, CelebA, and downsampled LSUN Bedroom, to validate\nour model's performance. Furthermore, we evaluated the effectiveness of the\ntemporal codebook on neuromorphic datasets NMNIST and DVS-CIFAR10, and\ndemonstrated the model's capability with high-resolution datasets such as\nCelebA-HQ, LSUN Bedroom, and LSUN Church. The experimental results indicate\nthat our method consistently outperforms existing SNN-based generative models\nacross multiple datasets, achieving state-of-the-art performance. Notably, our\napproach excels in generating high-resolution and temporally consistent data,\nunderscoring the crucial role of temporal information in SNN-based generative\nmodeling.",
        "subjects": [
            "cs.NE"
        ],
        "authors": [
            "Linghao Feng",
            "Dongcheng Zhao",
            "Sicheng Shen",
            "Yiting Dong",
            "Guobin Shen",
            "Yi Zeng"
        ],
        "published": "2024-05-23T12:04:46Z"
    },
    {
        "title": "Poisson Variational Autoencoder",
        "link": "http://arxiv.org/abs/2405.14473v1",
        "abstract": "Variational autoencoders (VAE) employ Bayesian inference to interpret sensory\ninputs, mirroring processes that occur in primate vision across both ventral\n(Higgins et al., 2021) and dorsal (Vafaii et al., 2023) pathways. Despite their\nsuccess, traditional VAEs rely on continuous latent variables, which deviates\nsharply from the discrete nature of biological neurons. Here, we developed the\nPoisson VAE (P-VAE), a novel architecture that combines principles of\npredictive coding with a VAE that encodes inputs into discrete spike counts.\nCombining Poisson-distributed latent variables with predictive coding\nintroduces a metabolic cost term in the model loss function, suggesting a\nrelationship with sparse coding which we verify empirically. Additionally, we\nanalyze the geometry of learned representations, contrasting the P-VAE to\nalternative VAE models. We find that the P-VAEencodes its inputs in relatively\nhigher dimensions, facilitating linear separability of categories in a\ndownstream classification task with a much better (5x) sample efficiency. Our\nwork provides an interpretable computational framework to study brain-like\nsensory processing and paves the way for a deeper understanding of perception\nas an inferential process.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.NC"
        ],
        "authors": [
            "Hadi Vafaii",
            "Dekel Galor",
            "Jacob L. Yates"
        ],
        "published": "2024-05-23T12:02:54Z"
    },
    {
        "title": "SolNet: Open-source deep learning models for photovoltaic power\n  forecasting across the globe",
        "link": "http://arxiv.org/abs/2405.14472v1",
        "abstract": "Deep learning models have gained increasing prominence in recent years in the\nfield of solar pho-tovoltaic (PV) forecasting. One drawback of these models is\nthat they require a lot of high-quality data to perform well. This is often\ninfeasible in practice, due to poor measurement infrastructure in legacy\nsystems and the rapid build-up of new solar systems across the world. This\npaper proposes SolNet: a novel, general-purpose, multivariate solar power\nforecaster, which addresses these challenges by using a two-step forecasting\npipeline which incorporates transfer learning from abundant synthetic data\ngenerated from PVGIS, before fine-tuning on observational data. Using actual\nproduction data from hundreds of sites in the Netherlands, Australia and\nBelgium, we show that SolNet improves forecasting performance over data-scarce\nsettings as well as baseline models. We find transfer learning benefits to be\nthe strongest when only limited observational data is available. At the same\ntime we provide several guidelines and considerations for transfer learning\npractitioners, as our results show that weather data, seasonal patterns, amount\nof synthetic data and possible mis-specification in source location, can have a\nmajor impact on the results. The SolNet models created in this way are\napplicable for any land-based solar photovoltaic system across the planet where\nsimulated and observed data can be combined to obtain improved forecasting\ncapabilities.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "authors": [
            "Joris Depoortere",
            "Johan Driesen",
            "Johan Suykens",
            "Hussain Syed Kazmi"
        ],
        "published": "2024-05-23T12:00:35Z"
    },
    {
        "title": "Which Information Matters? Dissecting Human-written Multi-document\n  Summaries with Partial Information Decomposition",
        "link": "http://arxiv.org/abs/2405.14470v1",
        "abstract": "Understanding the nature of high-quality summaries is crucial to further\nimprove the performance of multi-document summarization. We propose an approach\nto characterize human-written summaries using partial information\ndecomposition, which decomposes the mutual information provided by all source\ndocuments into union, redundancy, synergy, and unique information. Our\nempirical analysis on different MDS datasets shows that there is a direct\ndependency between the number of sources and their contribution to the summary.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Laura Mascarell",
            "Yan L'Homme",
            "Majed El Helou"
        ],
        "published": "2024-05-23T11:56:54Z"
    },
    {
        "title": "Generalization of Hamiltonian algorithms",
        "link": "http://arxiv.org/abs/2405.14469v1",
        "abstract": "The paper proves generalization results for a class of stochastic learning\nalgorithms. The method applies whenever the algorithm generates an absolutely\ncontinuous distribution relative to some a-priori measure and the Radon Nikodym\nderivative has subgaussian concentration. Applications are bounds for the Gibbs\nalgorithm and randomizations of stable deterministic algorithms as well as\nPAC-Bayesian bounds with data-dependent priors.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Andreas Maurer"
        ],
        "published": "2024-05-23T11:56:05Z"
    },
    {
        "title": "Neural Collapse versus Low-rank Bias: Is Deep Neural Collapse Really\n  Optimal?",
        "link": "http://arxiv.org/abs/2405.14468v1",
        "abstract": "Deep neural networks (DNNs) exhibit a surprising structure in their final\nlayer known as neural collapse (NC), and a growing body of works has currently\ninvestigated the propagation of neural collapse to earlier layers of DNNs -- a\nphenomenon called deep neural collapse (DNC). However, existing theoretical\nresults are restricted to special cases: linear models, only two layers or\nbinary classification. In contrast, we focus on non-linear models of arbitrary\ndepth in multi-class classification and reveal a surprising qualitative shift.\nAs soon as we go beyond two layers or two classes, DNC stops being optimal for\nthe deep unconstrained features model (DUFM) -- the standard theoretical\nframework for the analysis of collapse. The main culprit is a low-rank bias of\nmulti-layer regularization schemes: this bias leads to optimal solutions of\neven lower rank than the neural collapse. We support our theoretical findings\nwith experiments on both DUFM and real data, which show the emergence of the\nlow-rank structure in the solution found by gradient descent.",
        "subjects": [
            "cs.LG",
            "math.OC",
            "stat.ML"
        ],
        "authors": [
            "Peter Súkeník",
            "Marco Mondelli",
            "Christoph Lampert"
        ],
        "published": "2024-05-23T11:55:49Z"
    },
    {
        "title": "Segformer++: Efficient Token-Merging Strategies for High-Resolution\n  Semantic Segmentation",
        "link": "http://arxiv.org/abs/2405.14467v1",
        "abstract": "Utilizing transformer architectures for semantic segmentation of\nhigh-resolution images is hindered by the attention's quadratic computational\ncomplexity in the number of tokens. A solution to this challenge involves\ndecreasing the number of tokens through token merging, which has exhibited\nremarkable enhancements in inference speed, training efficiency, and memory\nutilization for image classification tasks. In this paper, we explore various\ntoken merging strategies within the framework of the Segformer architecture and\nperform experiments on multiple semantic segmentation and human pose estimation\ndatasets. Notably, without model re-training, we, for example, achieve an\ninference acceleration of 61% on the Cityscapes dataset while maintaining the\nmIoU performance. Consequently, this paper facilitates the deployment of\ntransformer-based architectures on resource-constrained devices and in\nreal-time applications.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Daniel Kienzle",
            "Marco Kantonis",
            "Robin Schön",
            "Rainer Lienhart"
        ],
        "published": "2024-05-23T11:54:27Z"
    },
    {
        "title": "Epistemic EFX Allocations Exist for Monotone Valuations",
        "link": "http://arxiv.org/abs/2405.14463v1",
        "abstract": "We study the fundamental problem of fairly dividing a set of indivisible\nitems among agents with (general) monotone valuations. The notion of\nenvy-freeness up to any item (EFX) is considered to be one of the most\nfascinating fairness concepts in this line of work. Unfortunately, despite\nsignificant efforts, existence of EFX allocations is a major open problem in\nfair division, thereby making the study of approximations and relaxations of\nEFX a natural line of research. Recently, Caragiannis et al. introduced a\npromising relaxation of EFX, called epistemic EFX (EEFX). We say an allocation\nto be EEFX if, for every agent, it is possible to shuffle the items in the\nremaining bundles so that she becomes \"EFX-satisfied\". Caragiannis et al. prove\nexistence and polynomial-time computability of EEFX allocations for additive\nvaluations. A natural question asks what happens when we consider valuations\nmore general than additive?\n  We address this important open question and answer it affirmatively by\nestablishing the existence of EEFX allocations for an arbitrary number of\nagents with general monotone valuations. To the best of our knowledge, EEFX is\nthe only known relaxation of EFX to have such strong existential guarantees.\nFurthermore, we complement our existential result by proving computational and\ninformation-theoretic lower bounds. We prove that even for an arbitrary number\nof (more than one) agents with identical submodular valuations, it is PLS-hard\nto compute EEFX allocations and it requires exponentially-many value queries to\ndo so.",
        "subjects": [
            "cs.GT"
        ],
        "authors": [
            "Hannaneh Akrami",
            "Nidhi Rathi"
        ],
        "published": "2024-05-23T11:52:28Z"
    },
    {
        "title": "YOLOv10: Real-Time End-to-End Object Detection",
        "link": "http://arxiv.org/abs/2405.14458v1",
        "abstract": "Over the past years, YOLOs have emerged as the predominant paradigm in the\nfield of real-time object detection owing to their effective balance between\ncomputational cost and detection performance. Researchers have explored the\narchitectural designs, optimization objectives, data augmentation strategies,\nand others for YOLOs, achieving notable progress. However, the reliance on the\nnon-maximum suppression (NMS) for post-processing hampers the end-to-end\ndeployment of YOLOs and adversely impacts the inference latency. Besides, the\ndesign of various components in YOLOs lacks the comprehensive and thorough\ninspection, resulting in noticeable computational redundancy and limiting the\nmodel's capability. It renders the suboptimal efficiency, along with\nconsiderable potential for performance improvements. In this work, we aim to\nfurther advance the performance-efficiency boundary of YOLOs from both the\npost-processing and model architecture. To this end, we first present the\nconsistent dual assignments for NMS-free training of YOLOs, which brings\ncompetitive performance and low inference latency simultaneously. Moreover, we\nintroduce the holistic efficiency-accuracy driven model design strategy for\nYOLOs. We comprehensively optimize various components of YOLOs from both\nefficiency and accuracy perspectives, which greatly reduces the computational\noverhead and enhances the capability. The outcome of our effort is a new\ngeneration of YOLO series for real-time end-to-end object detection, dubbed\nYOLOv10. Extensive experiments show that YOLOv10 achieves state-of-the-art\nperformance and efficiency across various model scales. For example, our\nYOLOv10-S is 1.8$\\times$ faster than RT-DETR-R18 under the similar AP on COCO,\nmeanwhile enjoying 2.8$\\times$ smaller number of parameters and FLOPs. Compared\nwith YOLOv9-C, YOLOv10-B has 46\\% less latency and 25\\% fewer parameters for\nthe same performance.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ao Wang",
            "Hui Chen",
            "Lihao Liu",
            "Kai Chen",
            "Zijia Lin",
            "Jungong Han",
            "Guiguang Ding"
        ],
        "published": "2024-05-23T11:44:29Z"
    },
    {
        "title": "Tighter Privacy Auditing of DP-SGD in the Hidden State Threat Model",
        "link": "http://arxiv.org/abs/2405.14457v1",
        "abstract": "Machine learning models can be trained with formal privacy guarantees via\ndifferentially private optimizers such as DP-SGD. In this work, we study such\nprivacy guarantees when the adversary only accesses the final model, i.e.,\nintermediate model updates are not released. In the existing literature, this\nhidden state threat model exhibits a significant gap between the lower bound\nprovided by empirical privacy auditing and the theoretical upper bound provided\nby privacy accounting. To challenge this gap, we propose to audit this threat\nmodel with adversaries that craft a gradient sequence to maximize the privacy\nloss of the final model without accessing intermediate models. We demonstrate\nexperimentally how this approach consistently outperforms prior attempts at\nauditing the hidden state model. When the crafted gradient is inserted at every\noptimization step, our results imply that releasing only the final model does\nnot amplify privacy, providing a novel negative result. On the other hand, when\nthe crafted gradient is not inserted at every step, we show strong evidence\nthat a privacy amplification phenomenon emerges in the general non-convex\nsetting (albeit weaker than in convex regimes), suggesting that existing\nprivacy upper bounds can be improved.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "authors": [
            "Tudor Cebere",
            "Aurélien Bellet",
            "Nicolas Papernot"
        ],
        "published": "2024-05-23T11:38:38Z"
    },
    {
        "title": "TIGER: Text-Instructed 3D Gaussian Retrieval and Coherent Editing",
        "link": "http://arxiv.org/abs/2405.14455v1",
        "abstract": "Editing objects within a scene is a critical functionality required across a\nbroad spectrum of applications in computer vision and graphics. As 3D Gaussian\nSplatting (3DGS) emerges as a frontier in scene representation, the effective\nmodification of 3D Gaussian scenes has become increasingly vital. This process\nentails accurately retrieve the target objects and subsequently performing\nmodifications based on instructions. Though available in pieces, existing\ntechniques mainly embed sparse semantics into Gaussians for retrieval, and rely\non an iterative dataset update paradigm for editing, leading to over-smoothing\nor inconsistency issues. To this end, this paper proposes a systematic\napproach, namely TIGER, for coherent text-instructed 3D Gaussian retrieval and\nediting. In contrast to the top-down language grounding approach for 3D\nGaussians, we adopt a bottom-up language aggregation strategy to generate a\ndenser language embedded 3D Gaussians that supports open-vocabulary retrieval.\nTo overcome the over-smoothing and inconsistency issues in editing, we propose\na Coherent Score Distillation (CSD) that aggregates a 2D image editing\ndiffusion model and a multi-view diffusion model for score distillation,\nproducing multi-view consistent editing with much finer details. In various\nexperiments, we demonstrate that our TIGER is able to accomplish more\nconsistent and realistic edits than prior work.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Teng Xu",
            "Jiamin Chen",
            "Peng Chen",
            "Youjia Zhang",
            "Junqing Yu",
            "Wei Yang"
        ],
        "published": "2024-05-23T11:37:17Z"
    },
    {
        "title": "Domain-specific augmentations with resolution agnostic self-attention\n  mechanism improves choroid segmentation in optical coherence tomography\n  images",
        "link": "http://arxiv.org/abs/2405.14453v1",
        "abstract": "The choroid is a key vascular layer of the eye, supplying oxygen to the\nretinal photoreceptors. Non-invasive enhanced depth imaging optical coherence\ntomography (EDI-OCT) has recently improved access and visualisation of the\nchoroid, making it an exciting frontier for discovering novel vascular\nbiomarkers in ophthalmology and wider systemic health. However, current methods\nto measure the choroid often require use of multiple, independent\nsemi-automatic and deep learning-based algorithms which are not made\nopen-source. Previously, Choroidalyzer -- an open-source, fully automatic deep\nlearning method trained on 5,600 OCT B-scans from 385 eyes -- was developed to\nfully segment and quantify the choroid in EDI-OCT images, thus addressing these\nissues. Using the same dataset, we propose a Robust, Resolution-agnostic and\nEfficient Attention-based network for CHoroid segmentation (REACH). REACHNet\nleverages multi-resolution training with domain-specific data augmentation to\npromote generalisation, and uses a lightweight architecture with\nresolution-agnostic self-attention which is not only faster than\nChoroidalyzer's previous network (4 images/s vs. 2.75 images/s on a standard\nlaptop CPU), but has greater performance for segmenting the choroid region,\nvessels and fovea (Dice coefficient for region 0.9769 vs. 0.9749, vessels\n0.8612 vs. 0.8192 and fovea 0.8243 vs. 0.3783) due to its improved\nhyperparameter configuration and model training pipeline. REACHNet can be used\nwith Choroidalyzer as a drop-in replacement for the original model and will be\nmade available upon publication.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Jamie Burke",
            "Justin Engelmann",
            "Charlene Hamid",
            "Diana Moukaddem",
            "Dan Pugh",
            "Neeraj Dhaun",
            "Amos Storkey",
            "Niall Strang",
            "Stuart King",
            "Tom MacGillivray",
            "Miguel O. Bernabeu",
            "Ian J. C. MacCormick"
        ],
        "published": "2024-05-23T11:35:23Z"
    },
    {
        "title": "JointRF: End-to-End Joint Optimization for Dynamic Neural Radiance Field\n  Representation and Compression",
        "link": "http://arxiv.org/abs/2405.14452v1",
        "abstract": "Neural Radiance Field (NeRF) excels in photo-realistically static scenes,\ninspiring numerous efforts to facilitate volumetric videos. However, rendering\ndynamic and long-sequence radiance fields remains challenging due to the\nsignificant data required to represent volumetric videos. In this paper, we\npropose a novel end-to-end joint optimization scheme of dynamic NeRF\nrepresentation and compression, called JointRF, thus achieving significantly\nimproved quality and compression efficiency against the previous methods.\nSpecifically, JointRF employs a compact residual feature grid and a coefficient\nfeature grid to represent the dynamic NeRF. This representation handles large\nmotions without compromising quality while concurrently diminishing temporal\nredundancy. We also introduce a sequential feature compression subnetwork to\nfurther reduce spatial-temporal redundancy. Finally, the representation and\ncompression subnetworks are end-to-end trained combined within the JointRF.\nExtensive experiments demonstrate that JointRF can achieve superior compression\nperformance across various datasets.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Zihan Zheng",
            "Houqiang Zhong",
            "Qiang Hu",
            "Xiaoyun Zhang",
            "Li Song",
            "Ya Zhang",
            "Yanfeng Wang"
        ],
        "published": "2024-05-23T11:32:46Z"
    },
    {
        "title": "Adversarial Schrödinger Bridge Matching",
        "link": "http://arxiv.org/abs/2405.14449v1",
        "abstract": "The Schr\\\"odinger Bridge (SB) problem offers a powerful framework for\ncombining optimal transport and diffusion models. A promising recent approach\nto solve the SB problem is the Iterative Markovian Fitting (IMF) procedure,\nwhich alternates between Markovian and reciprocal projections of\ncontinuous-time stochastic processes. However, the model built by the IMF\nprocedure has a long inference time due to using many steps of numerical\nsolvers for stochastic differential equations. To address this limitation, we\npropose a novel Discrete-time IMF (D-IMF) procedure in which learning of\nstochastic processes is replaced by learning just a few transition\nprobabilities in discrete time. Its great advantage is that in practice it can\nbe naturally implemented using the Denoising Diffusion GAN (DD-GAN), an already\nwell-established adversarial generative modeling technique. We show that our\nD-IMF procedure can provide the same quality of unpaired domain translation as\nthe IMF, using only several generation steps instead of hundreds.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Nikita Gushchin",
            "Daniil Selikhanovych",
            "Sergei Kholkin",
            "Evgeny Burnaev",
            "Alexander Korotin"
        ],
        "published": "2024-05-23T11:29:33Z"
    },
    {
        "title": "Worldwide Federated Training of Language Models",
        "link": "http://arxiv.org/abs/2405.14446v1",
        "abstract": "The reliance of language model training on massive amounts of computation and\nvast datasets scraped from potentially low-quality, copyrighted, or sensitive\ndata has come into question practically, legally, and ethically. Federated\nlearning provides a plausible alternative by enabling previously untapped data\nto be voluntarily gathered from collaborating organizations. However, when\nscaled globally, federated learning requires collaboration across heterogeneous\nlegal, security, and privacy regimes while accounting for the inherent locality\nof language data; this further exacerbates the established challenge of\nfederated statistical heterogeneity. We propose a Worldwide Federated Language\nModel Training~(WorldLM) system based on federations of federations, where each\nfederation has the autonomy to account for factors such as its industry,\noperating jurisdiction, or competitive environment. WorldLM enables such\nautonomy in the presence of statistical heterogeneity via partial model\nlocalization by allowing sub-federations to attentively aggregate key layers\nfrom their constituents. Furthermore, it can adaptively share information\nacross federations via residual layer embeddings. Evaluations of language\nmodeling on naturally heterogeneous datasets show that WorldLM outperforms\nstandard federations by up to $1.91\\times$, approaches the personalized\nperformance of fully local models, and maintains these advantages under\nprivacy-enhancing techniques.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.DC",
            "I.2.7"
        ],
        "authors": [
            "Alex Iacob",
            "Lorenzo Sani",
            "Bill Marino",
            "Preslav Aleksandrov",
            "Nicholas Donald Lane"
        ],
        "published": "2024-05-23T11:25:19Z"
    },
    {
        "title": "Exploring the use of a Large Language Model for data extraction in\n  systematic reviews: a rapid feasibility study",
        "link": "http://arxiv.org/abs/2405.14445v1",
        "abstract": "This paper describes a rapid feasibility study of using GPT-4, a large\nlanguage model (LLM), to (semi)automate data extraction in systematic reviews.\nDespite the recent surge of interest in LLMs there is still a lack of\nunderstanding of how to design LLM-based automation tools and how to robustly\nevaluate their performance. During the 2023 Evidence Synthesis Hackathon we\nconducted two feasibility studies. Firstly, to automatically extract study\ncharacteristics from human clinical, animal, and social science domain studies.\nWe used two studies from each category for prompt-development; and ten for\nevaluation. Secondly, we used the LLM to predict Participants, Interventions,\nControls and Outcomes (PICOs) labelled within 100 abstracts in the EBM-NLP\ndataset. Overall, results indicated an accuracy of around 80%, with some\nvariability between domains (82% for human clinical, 80% for animal, and 72%\nfor studies of human social sciences). Causal inference methods and study\ndesign were the data extraction items with the most errors. In the PICO study,\nparticipants and intervention/control showed high accuracy (>80%), outcomes\nwere more challenging. Evaluation was done manually; scoring methods such as\nBLEU and ROUGE showed limited value. We observed variability in the LLMs\npredictions and changes in response quality. This paper presents a template for\nfuture evaluations of LLMs in the context of data extraction for systematic\nreview automation. Our results show that there might be value in using LLMs,\nfor example as second or third reviewers. However, caution is advised when\nintegrating models such as GPT-4 into tools. Further research on stability and\nreliability in practical settings is warranted for each type of data that is\nprocessed by the LLM.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Lena Schmidt",
            "Kaitlyn Hair",
            "Sergio Graziozi",
            "Fiona Campbell",
            "Claudia Kapp",
            "Alireza Khanteymoori",
            "Dawn Craig",
            "Mark Engelbert",
            "James Thomas"
        ],
        "published": "2024-05-23T11:24:23Z"
    },
    {
        "title": "DuEDL: Dual-Branch Evidential Deep Learning for Scribble-Supervised\n  Medical Image Segmentation",
        "link": "http://arxiv.org/abs/2405.14444v1",
        "abstract": "Despite the recent progress in medical image segmentation with scribble-based\nannotations, the segmentation results of most models are still not ro-bust and\ngeneralizable enough in open environments. Evidential deep learn-ing (EDL) has\nrecently been proposed as a promising solution to model predictive uncertainty\nand improve the reliability of medical image segmen-tation. However directly\napplying EDL to scribble-supervised medical im-age segmentation faces a\ntradeoff between accuracy and reliability. To ad-dress the challenge, we\npropose a novel framework called Dual-Branch Evi-dential Deep Learning (DuEDL).\nFirstly, the decoder of the segmentation network is changed to two different\nbranches, and the evidence of the two branches is fused to generate\nhigh-quality pseudo-labels. Then the frame-work applies partial evidence loss\nand two-branch consistent loss for joint training of the model to adapt to the\nscribble supervision learning. The pro-posed method was tested on two cardiac\ndatasets: ACDC and MSCMRseg. The results show that our method significantly\nenhances the reliability and generalization ability of the model without\nsacrificing accuracy, outper-forming state-of-the-art baselines. The code is\navailable at https://github.com/Gardnery/DuEDL.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yitong Yang",
            "Xinli Xu",
            "Haigen Hu",
            "Haixia Long",
            "Qianwei Zhou",
            "Qiu Guan"
        ],
        "published": "2024-05-23T11:23:57Z"
    },
    {
        "title": "Fully parallel implementation of digital memcomputing on FPGA",
        "link": "http://arxiv.org/abs/2405.14442v1",
        "abstract": "We present a fully parallel digital memcomputing solver implemented on a\nfield-programmable gate array (FPGA) board. For this purpose, we have designed\nan FPGA code that solves the ordinary differential equations associated with\ndigital memcomputing in parallel. A feature of the code is the use of only\ninteger-type variables and integer constants to enhance optimization.\nConsequently, each integration step in our solver is executed in 96~ns. This\nmethod was utilized for difficult instances of the Boolean satisfiability (SAT)\nproblem close to a phase transition, involving up to about 150 variables. Our\nresults demonstrate that the parallel implementation reduces the scaling\nexponent by about 1 compared to a sequential C++ code on a standard computer.\nAdditionally, compared to C++ code, we observed a time-to-solution advantage of\nabout three orders of magnitude. Given the limitations of FPGA resources, the\ncurrent implementation of digital memcomputing will be especially useful for\nsolving compact but challenging problems.",
        "subjects": [
            "cs.ET",
            "nlin.CD"
        ],
        "authors": [
            "Dyk Chung Nguyen",
            "Yuriy V. Pershin"
        ],
        "published": "2024-05-23T11:21:12Z"
    },
    {
        "title": "Leveraging Natural Load Dynamics with Variable Gear-ratio Actuators",
        "link": "http://dx.doi.org/10.1109/LRA.2017.2651946",
        "abstract": "This paper presents a robotic system where the gear-ratio of an actuator is\ndynamically changed to either leverage or attenuate the natural load dynamics.\nBased on this principle, lightweight robotic systems can be made fast and\nstrong; exploiting the natural load dynamics for moving at higher speeds (small\nreduction ratio), while also able to bear a large load through the attenuation\nof the load dynamics (large reduction ratio). A model-based control algorithm\nto automatically select the optimal gear-ratios that minimize the total\nactuator torques for an arbitrary dynamic state and expected uncertainty level\nis proposed. Also, a novel 3-DoF robot arm using custom actuators with two\ndiscrete gear-ratios is presented. The advantages of gear-shifting dynamically\nare demonstrated through experiments and simulations. Results show that\nactively changing the gear-ratio using the proposed control algorithms can lead\nto an order-of-magnitude reduction of necessary actuator torque and power, and\nalso increase robustness to disturbances.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Alexandre Girard",
            "H. Harry Asada"
        ],
        "published": "2024-05-23T11:18:12Z"
    },
    {
        "title": "Bayesian Adaptive Calibration and Optimal Design",
        "link": "http://arxiv.org/abs/2405.14440v1",
        "abstract": "The process of calibrating computer models of natural phenomena is essential\nfor applications in the physical sciences, where plenty of domain knowledge can\nbe embedded into simulations and then calibrated against real observations.\nCurrent machine learning approaches, however, mostly rely on rerunning\nsimulations over a fixed set of designs available in the observed data,\npotentially neglecting informative correlations across the design space and\nrequiring a large amount of simulations. Instead, we consider the calibration\nprocess from the perspective of Bayesian adaptive experimental design and\npropose a data-efficient algorithm to run maximally informative simulations\nwithin a batch-sequential process. At each round, the algorithm jointly\nestimates the parameters of the posterior distribution and optimal designs by\nmaximising a variational lower bound of the expected information gain. The\nsimulator is modelled as a sample from a Gaussian process, which allows us to\ncorrelate simulations and observed data with the unknown calibration\nparameters. We show the benefits of our method when compared to related\napproaches across synthetic and real-data problems.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Rafael Oliveira",
            "Dino Sejdinovic",
            "David Howard",
            "Edwin Bonilla"
        ],
        "published": "2024-05-23T11:14:35Z"
    },
    {
        "title": "LoRA-Ensemble: Efficient Uncertainty Modelling for Self-attention\n  Networks",
        "link": "http://arxiv.org/abs/2405.14438v1",
        "abstract": "Numerous crucial tasks in real-world decision-making rely on machine learning\nalgorithms with calibrated uncertainty estimates. However, modern methods often\nyield overconfident and uncalibrated predictions. Various approaches involve\ntraining an ensemble of separate models to quantify the uncertainty related to\nthe model itself, known as epistemic uncertainty. In an explicit\nimplementation, the ensemble approach has high computational cost and high\nmemory requirements. This particular challenge is evident in state-of-the-art\nneural networks such as transformers, where even a single network is already\ndemanding in terms of compute and memory. Consequently, efforts are made to\nemulate the ensemble model without actually instantiating separate ensemble\nmembers, referred to as implicit ensembling. We introduce LoRA-Ensemble, a\nparameter-efficient deep ensemble method for self-attention networks, which is\nbased on Low-Rank Adaptation (LoRA). Initially developed for efficient LLM\nfine-tuning, we extend LoRA to an implicit ensembling approach. By employing a\nsingle pre-trained self-attention network with weights shared across all\nmembers, we train member-specific low-rank matrices for the attention\nprojections. Our method exhibits superior calibration compared to explicit\nensembles and achieves similar or better accuracy across various prediction\ntasks and datasets.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Michelle Halbheer",
            "Dominik J. Mühlematter",
            "Alexander Becker",
            "Dominik Narnhofer",
            "Helge Aasen",
            "Konrad Schindler",
            "Mehmet Ozgur Turkoglu"
        ],
        "published": "2024-05-23T11:10:32Z"
    },
    {
        "title": "Combining Denoising Autoencoders with Contrastive Learning to fine-tune\n  Transformer Models",
        "link": "http://arxiv.org/abs/2405.14437v1",
        "abstract": "Recently, using large pretrained Transformer models for transfer learning\ntasks has evolved to the point where they have become one of the flagship\ntrends in the Natural Language Processing (NLP) community, giving rise to\nvarious outlooks such as prompt-based, adapters or combinations with\nunsupervised approaches, among many others. This work proposes a 3 Phase\ntechnique to adjust a base model for a classification task. First, we adapt the\nmodel's signal to the data distribution by performing further training with a\nDenoising Autoencoder (DAE). Second, we adjust the representation space of the\noutput to the corresponding classes by clustering through a Contrastive\nLearning (CL) method. In addition, we introduce a new data augmentation\napproach for Supervised Contrastive Learning to correct the unbalanced\ndatasets. Third, we apply fine-tuning to delimit the predefined categories.\nThese different phases provide relevant and complementary knowledge to the\nmodel to learn the final task. We supply extensive experimental results on\nseveral datasets to demonstrate these claims. Moreover, we include an ablation\nstudy and compare the proposed method against other ways of combining these\ntechniques.",
        "subjects": [
            "cs.CL",
            "I.2.7"
        ],
        "authors": [
            "Alejo Lopez-Avila",
            "Víctor Suárez-Paniagua"
        ],
        "published": "2024-05-23T11:08:35Z"
    },
    {
        "title": "LARS-VSA: A Vector Symbolic Architecture For Learning with Abstract\n  Rules",
        "link": "http://arxiv.org/abs/2405.14436v1",
        "abstract": "Human cognition excels at symbolic reasoning, deducing abstract rules from\nlimited samples. This has been explained using symbolic and connectionist\napproaches, inspiring the development of a neuro-symbolic architecture that\ncombines both paradigms. In parallel, recent studies have proposed the use of a\n\"relational bottleneck\" that separates object-level features from abstract\nrules, allowing learning from limited amounts of data . While powerful, it is\nvulnerable to the curse of compositionality meaning that object representations\nwith similar features tend to interfere with each other. In this paper, we\nleverage hyperdimensional computing, which is inherently robust to such\ninterference to build a compositional architecture. We adapt the \"relational\nbottleneck\" strategy to a high-dimensional space, incorporating explicit vector\nbinding operations between symbols and relational representations.\nAdditionally, we design a novel high-dimensional attention mechanism that\nleverages this relational representation. Our system benefits from the low\noverhead of operations in hyperdimensional space, making it significantly more\nefficient than the state of the art when evaluated on a variety of test\ndatasets, while maintaining higher or equal accuracy.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Mohamed Mejri",
            "Chandramouli Amarnath",
            "Abhijit Chatterjee"
        ],
        "published": "2024-05-23T11:05:42Z"
    },
    {
        "title": "High-Level Event Mining: Overview and Future Work",
        "link": "http://arxiv.org/abs/2405.14435v1",
        "abstract": "Process mining traditionally relies on input consisting of low-level events\nthat capture individual activities, such as filling out a form or processing a\nproduct. However, many of the complex problems inherent in processes, such as\nbottlenecks and compliance issues, extend beyond the scope of individual events\nand process instances. Consider congestion, for instance, it can involve and\nimpact numerous cases, much like how a traffic jam affects many cars\nsimultaneously. High-level event mining seeks to address such phenomena using\nthe regular event data available. This report offers an extensive and\ncomprehensive overview at existing work and challenges encountered when lifting\nthe perspective from individual events and cases to system-level events.",
        "subjects": [
            "cs.DB"
        ],
        "authors": [
            "Bianka Bakullari",
            "Wil M. P. van der Aalst"
        ],
        "published": "2024-05-23T11:03:09Z"
    },
    {
        "title": "Boosting Robustness by Clipping Gradients in Distributed Learning",
        "link": "http://arxiv.org/abs/2405.14432v1",
        "abstract": "Robust distributed learning consists in achieving good learning performance\ndespite the presence of misbehaving workers. State-of-the-art (SOTA) robust\ndistributed gradient descent (Robust-DGD) methods, relying on robust\naggregation, have been proven to be optimal: Their learning error matches the\nlower bound established under the standard heterogeneity model of $(G,\nB)$-gradient dissimilarity. The learning guarantee of SOTA Robust-DGD cannot be\nfurther improved when model initialization is done arbitrarily. However, we\nshow that it is possible to circumvent the lower bound, and improve the\nlearning performance, when the workers' gradients at model initialization are\nassumed to be bounded. We prove this by proposing pre-aggregation clipping of\nworkers' gradients, using a novel scheme called adaptive robust clipping (ARC).\nIncorporating ARC in Robust-DGD provably improves the learning, under the\naforementioned assumption on model initialization. The factor of improvement is\nprominent when the tolerable fraction of misbehaving workers approaches the\nbreakdown point. ARC induces this improvement by constricting the search space,\nwhile preserving the robustness property of the original aggregation scheme at\nthe same time. We validate this theoretical finding through exhaustive\nexperiments on benchmark image classification tasks.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Youssef Allouah",
            "Rachid Guerraoui",
            "Nirupam Gupta",
            "Ahmed Jellouli",
            "Geovani Rizk",
            "John Stephan"
        ],
        "published": "2024-05-23T11:00:31Z"
    },
    {
        "title": "RaFe: Ranking Feedback Improves Query Rewriting for RAG",
        "link": "http://arxiv.org/abs/2405.14431v1",
        "abstract": "As Large Language Models (LLMs) and Retrieval Augmentation Generation (RAG)\ntechniques have evolved, query rewriting has been widely incorporated into the\nRAG system for downstream tasks like open-domain QA. Many works have attempted\nto utilize small models with reinforcement learning rather than costly LLMs to\nimprove query rewriting. However, current methods require annotations (e.g.,\nlabeled relevant documents or downstream answers) or predesigned rewards for\nfeedback, which lack generalization, and fail to utilize signals tailored for\nquery rewriting. In this paper, we propose ours, a framework for training query\nrewriting models free of annotations. By leveraging a publicly available\nreranker, ours~provides feedback aligned well with the rewriting objectives.\nExperimental results demonstrate that ours~can obtain better performance than\nbaselines.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR"
        ],
        "authors": [
            "Shengyu Mao",
            "Yong Jiang",
            "Boli Chen",
            "Xiao Li",
            "Peng Wang",
            "Xinyu Wang",
            "Pengjun Xie",
            "Fei Huang",
            "Huajun Chen",
            "Ningyu Zhang"
        ],
        "published": "2024-05-23T11:00:19Z"
    },
    {
        "title": "PipeFusion: Displaced Patch Pipeline Parallelism for Inference of\n  Diffusion Transformer Models",
        "link": "http://arxiv.org/abs/2405.14430v1",
        "abstract": "This paper introduces PipeFusion, a novel approach that harnesses multi-GPU\nparallelism to address the high computational and latency challenges of\ngenerating high-resolution images with diffusion transformers (DiT) models.\nPipeFusion splits images into patches and distributes the network layers across\nmultiple devices. It employs a pipeline parallel manner to orchestrate\ncommunication and computations. By leveraging the high similarity between the\ninput from adjacent diffusion steps, PipeFusion eliminates the waiting time in\nthe pipeline by reusing the one-step stale feature maps to provide context for\nthe current step. Our experiments demonstrate that it can generate higher image\nresolution where existing DiT parallel approaches meet OOM. PipeFusion\nsignificantly reduces the required communication bandwidth, enabling DiT\ninference to be hosted on GPUs connected via PCIe rather than the more costly\nNVLink infrastructure, which substantially lowers the overall operational\nexpenses for serving DiT models. Our code is publicly available at\nhttps://github.com/PipeFusion/PipeFusion.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.PF"
        ],
        "authors": [
            "Jiannan Wang",
            "Jiarui Fang",
            "Aoyu Li",
            "PengCheng Yang"
        ],
        "published": "2024-05-23T11:00:07Z"
    },
    {
        "title": "Mitigating Quantization Errors Due to Activation Spikes in GLU-Based\n  LLMs",
        "link": "http://arxiv.org/abs/2405.14428v1",
        "abstract": "Modern large language models (LLMs) have established state-of-the-art\nperformance through architectural improvements, but still require significant\ncomputational cost for inference. In an effort to reduce the inference cost,\npost-training quantization (PTQ) has become a popular approach, quantizing\nweights and activations to lower precision, such as INT8. In this paper, we\nreveal the challenges of activation quantization in GLU variants, which are\nwidely used in feed-forward network (FFN) of modern LLMs, such as LLaMA family.\nThe problem is that severe local quantization errors, caused by excessive\nmagnitudes of activation in GLU variants, significantly degrade the performance\nof the quantized LLM. We denote these activations as activation spikes. Our\nfurther observations provide a systematic pattern of activation spikes: 1) The\nactivation spikes occur in the FFN of specific layers, particularly in the\nearly and late layers, 2) The activation spikes are dedicated to a couple of\ntokens, rather than being shared across a sequence. Based on our observations,\nwe propose two empirical methods, Quantization-free Module (QFeM) and\nQuantization-free Prefix (QFeP), to isolate the activation spikes during\nquantization. Our extensive experiments validate the effectiveness of the\nproposed methods for the activation quantization, especially with\ncoarse-grained scheme, of latest LLMs with GLU variants, including LLaMA-2/3,\nMistral, Mixtral, SOLAR, and Gemma. In particular, our methods enhance the\ncurrent alleviation techniques (e.g., SmoothQuant) that fail to control the\nactivation spikes. Code is available at\nhttps://github.com/onnoo/activation-spikes.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Jaewoo Yang",
            "Hayun Kim",
            "Younghoon Kim"
        ],
        "published": "2024-05-23T10:54:14Z"
    },
    {
        "title": "Advanced Safety Filter for Smooth Transient Operation of a Battery\n  Energy Storage System",
        "link": "http://arxiv.org/abs/2405.14427v1",
        "abstract": "In this paper, we implement an advanced safety filter to smoothly limit the\ncurrent of an inverter-based Battery Energy Storage System. The task involves\nfinding suitable Control Barrier Function and Control Lyapunov Function via\nSum-of-Squares optimization to certify the system's safety during grid\ntransients. In contrast to the conventional safety filter, the advanced safety\nfilter not only provides a safety certificate but also achieves finite-time\nconvergence to a nominal region. Within this region, the action of the nominal\ncontrol, i.e. the Enhanced Direct Power Control, remains unaltered by the\nsafety filter. The advanced safety filter is implemented using a Quadratically\nConstrained Quadratic Program, providing the capability to also encode\nquadratic input constraints. Finally, we showcase the effectiveness of the\nimplementation through simulations involving a load step at the Point of Common\nCoupling, and we compare the outcomes with those obtained using a standard\nvector current controller.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Michael Schneeberger",
            "Florian Dörfler",
            "Silvia Mastellone"
        ],
        "published": "2024-05-23T10:53:35Z"
    },
    {
        "title": "A hybrid systems framework for data-based adaptive control of linear\n  time-varying systems",
        "link": "http://arxiv.org/abs/2405.14426v1",
        "abstract": "We consider the data-driven stabilization of discrete-time linear\ntime-varying systems. The controller is defined as a linear state-feedback law\nwhose gain is adapted to the plant changes through a data-based\nevent-triggering rule. To do so, we monitor the evolution of a data-based\nLyapunov function along the solution. When this Lyapunov function does not\nsatisfy a designed desirable condition, an episode is triggered to update the\ncontroller gain and the corresponding Lyapunov function using the last\ncollected data. The resulting closed-loop dynamics hence exhibits both physical\njumps, due to the system dynamics, and episodic jumps, which naturally leads to\na hybrid discrete-time system. We leverage the inherent robustness of the\ncontroller and provide general conditions under which various stability notions\ncan be established for the system. Two notable cases where these conditions are\nsatisfied are treated, and numerical results illustrating the relevance of the\napproach are discussed.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Andrea Iannelli",
            "Romain Postoyan"
        ],
        "published": "2024-05-23T10:51:25Z"
    },
    {
        "title": "When predict can also explain: few-shot prediction to select better\n  neural latents",
        "link": "http://arxiv.org/abs/2405.14425v1",
        "abstract": "Latent variable models serve as powerful tools to infer underlying dynamics\nfrom observed neural activity. However, due to the absence of ground truth\ndata, prediction benchmarks are often employed as proxies. In this study, we\nreveal the limitations of the widely-used 'co-smoothing' prediction framework\nand propose an improved few-shot prediction approach that encourages more\naccurate latent dynamics. Utilizing a student-teacher setup with Hidden Markov\nModels, we demonstrate that the high co-smoothing model space can encompass\nmodels with arbitrary extraneous dynamics within their latent representations.\nTo address this, we introduce a secondary metric -- a few-shot version of\nco-smoothing. This involves performing regression from the latent variables to\nheld-out channels in the data using fewer trials. Our results indicate that\namong models with near-optimal co-smoothing, those with extraneous dynamics\nunderperform in the few-shot co-smoothing compared to 'minimal' models devoid\nof such dynamics. We also provide analytical insights into the origin of this\nphenomenon. We further validate our findings on real neural data using two\nstate-of-the-art methods: LFADS and STNDT. In the absence of ground truth, we\nsuggest a proxy measure to quantify extraneous dynamics. By cross-decoding the\nlatent variables of all model pairs with high co-smoothing, we identify models\nwith minimal extraneous dynamics. We find a correlation between few-shot\nco-smoothing performance and this new measure. In summary, we present a novel\nprediction metric designed to yield latent variables that more accurately\nreflect the ground truth, offering a significant improvement for latent\ndynamics inference.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Kabir Dabholkar",
            "Omri Barak"
        ],
        "published": "2024-05-23T10:48:30Z"
    },
    {
        "title": "Unraveling overoptimism and publication bias in ML-driven science",
        "link": "http://arxiv.org/abs/2405.14422v1",
        "abstract": "Machine Learning (ML) is increasingly used across many disciplines with\nimpressive reported results across many domain areas. However, recent studies\nsuggest that the published performance of ML models are often overoptimistic\nand not reflective of true accuracy were these models to be deployed. Validity\nconcerns are underscored by findings of a concerning inverse relationship\nbetween sample size and reported accuracy in published ML models across several\ndomains. This is in contrast with the theory of learning curves in ML, where we\nexpect accuracy to improve or stay the same with increasing sample size. This\npaper investigates the factors contributing to overoptimistic accuracy reports\nin ML-based science, focusing on data leakage and publication bias. Our study\nintroduces a novel stochastic model for observed accuracy, integrating\nparametric learning curves and the above biases. We then construct an estimator\nbased on this model that corrects for these biases in observed data.\nTheoretical and empirical results demonstrate that this framework can estimate\nthe underlying learning curve that gives rise to the observed overoptimistic\nresults, thereby providing more realistic performance assessments of ML\nperformance from a collection of published results. We apply the model to\nvarious meta-analyses in the digital health literature, including\nneuroimaging-based and speech-based classifications of several neurological\nconditions. Our results indicate prevalent overoptimism across these fields and\nwe estimate the inherent limits of ML-based prediction in each domain.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CY"
        ],
        "authors": [
            "Pouria Saidi",
            "Gautam Dasarathy",
            "Visar Berisha"
        ],
        "published": "2024-05-23T10:43:20Z"
    },
    {
        "title": "Motion-based video compression for resource-constrained camera traps",
        "link": "http://arxiv.org/abs/2405.14419v1",
        "abstract": "Field-captured video allows for detailed studies of spatiotemporal aspects of\nanimal locomotion, decision-making, and environmental interactions. However,\ndespite the affordability of data capture with mass-produced hardware, storage,\nprocessing, and transmission overheads pose a significant hurdle to acquiring\nhigh-resolution video from field-deployed camera traps. Therefore, efficient\ncompression algorithms are crucial for monitoring with camera traps that have\nlimited access to power, storage, and bandwidth. In this article, we introduce\na new motion analysis-based video compression algorithm designed to run on\ncamera trap devices. We implemented and tested this algorithm using a case\nstudy of insect-pollinator motion tracking. The algorithm identifies and stores\nonly image regions depicting motion relevant to pollination monitoring,\nreducing the overall data size by an average of 84% across a diverse set of\ntest datasets while retaining the information necessary for relevant\nbehavioural analysis. The methods outlined in this paper facilitate the broader\napplication of computer vision-enabled, low-powered camera trap devices for\nremote, in-situ video-based animal motion monitoring.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "q-bio.QM"
        ],
        "authors": [
            "Malika Nisal Ratnayake",
            "Lex Gallon",
            "Adel N. Toosi",
            "Alan Dorin"
        ],
        "published": "2024-05-23T10:39:33Z"
    },
    {
        "title": "Proving Theorems Recursively",
        "link": "http://arxiv.org/abs/2405.14414v1",
        "abstract": "Recent advances in automated theorem proving leverages language models to\nexplore expanded search spaces by step-by-step proof generation. However, such\napproaches are usually based on short-sighted heuristics (e.g., log probability\nor value function scores) that potentially lead to suboptimal or even\ndistracting subgoals, preventing us from finding longer proofs. To address this\nchallenge, we propose POETRY (PrOvE Theorems RecursivelY), which proves\ntheorems in a recursive, level-by-level manner in the Isabelle theorem prover.\nUnlike previous step-by-step methods, POETRY searches for a verifiable sketch\nof the proof at each level and focuses on solving the current level's theorem\nor conjecture. Detailed proofs of intermediate conjectures within the sketch\nare temporarily replaced by a placeholder tactic called sorry, deferring their\nproofs to subsequent levels. This approach allows the theorem to be tackled\nincrementally by outlining the overall theorem at the first level and then\nsolving the intermediate conjectures at deeper levels. Experiments are\nconducted on the miniF2F and PISA datasets and significant performance gains\nare observed in our POETRY approach over state-of-the-art methods. POETRY on\nminiF2F achieves an average proving success rate improvement of 5.1%. Moreover,\nwe observe a substantial increase in the maximum proof length found by POETRY,\nfrom 10 to 26.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Haiming Wang",
            "Huajian Xin",
            "Zhengying Liu",
            "Wenda Li",
            "Yinya Huang",
            "Jianqiao Lu",
            "Zhicheng Yang",
            "Jing Tang",
            "Jian Yin",
            "Zhenguo Li",
            "Xiaodan Liang"
        ],
        "published": "2024-05-23T10:35:08Z"
    },
    {
        "title": "GeoFaaS: An Edge-to-Cloud FaaS Platform",
        "link": "http://arxiv.org/abs/2405.14413v1",
        "abstract": "The massive growth of mobile and IoT devices demands geographically\ndistributed computing systems for optimal performance, privacy, and\nscalability. However, existing edge-to-cloud serverless platforms lack location\nawareness, resulting in inefficient network usage and increased latency.\n  In this paper, we propose GeoFaaS, a novel edge-to-cloud\nFunction-as-a-Service (FaaS) platform that leverages real-time client location\ninformation for transparent request execution on the nearest available FaaS\nnode. If needed, GeoFaaS transparently offloads requests to the cloud when edge\nresources are overloaded, thus, ensuring consistent execution without user\nintervention. GeoFaaS has a modular and decentralized architecture: building on\nthe single-node FaaS system tinyFaaS, GeoFaaS works as a stand-alone\nedge-to-cloud FaaS platform but can also integrate and act as a routing layer\nfor existing FaaS services, e.g., in the cloud. To evaluate our approach, we\nimplemented an open-source proof-of-concept prototype and studied performance\nand fault-tolerance behavior in experiments.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Mohammadreza Malekabbasi",
            "Tobias Pfandzelter",
            "Trever Schirmer",
            "David Bermbach"
        ],
        "published": "2024-05-23T10:34:21Z"
    },
    {
        "title": "Large Language Models for Explainable Decisions in Dynamic Digital Twins",
        "link": "http://arxiv.org/abs/2405.14411v1",
        "abstract": "Dynamic data-driven Digital Twins (DDTs) can enable informed decision-making\nand provide an optimisation platform for the underlying system. By leveraging\nprinciples of Dynamic Data-Driven Applications Systems (DDDAS), DDTs can\nformulate computational modalities for feedback loops, model updates and\ndecision-making, including autonomous ones. However, understanding autonomous\ndecision-making often requires technical and domain-specific knowledge. This\npaper explores using large language models (LLMs) to provide an explainability\nplatform for DDTs, generating natural language explanations of the system's\ndecision-making by leveraging domain-specific knowledge bases. A case study\nfrom smart agriculture is presented.",
        "subjects": [
            "cs.AI",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Nan Zhang",
            "Christian Vergara-Marcillo",
            "Georgios Diamantopoulos",
            "Jingran Shen",
            "Nikos Tziritas",
            "Rami Bahsoon",
            "Georgios Theodoropoulos"
        ],
        "published": "2024-05-23T10:32:38Z"
    },
    {
        "title": "Investigating the Common Authorship of Signatures by Off-Line Automatic\n  Signature Verification Without the Use of Reference Signatures",
        "link": "http://dx.doi.org/10.1109/TIFS.2019.2924195",
        "abstract": "In automatic signature verification, questioned specimens are usually\ncompared with reference signatures. In writer-dependent schemes, a number of\nreference signatures are required to build up the individual signer model while\na writer-independent system requires a set of reference signatures from several\nsigners to develop the model of the system. This paper addresses the problem of\nautomatic signature verification when no reference signatures are available.\nThe scenario we explore consists of a set of signatures, which could be signed\nby the same author or by multiple signers. As such, we discuss three methods\nwhich estimate automatically the common authorship of a set of off-line\nsignatures. The first method develops a score similarity matrix, worked out\nwith the assistance of duplicated signatures; the second uses a\nfeature-distance matrix for each pair of signatures; and the last method\nintroduces pre-classification based on the complexity of each signature.\nPublicly available signatures were used in the experiments, which gave\nencouraging results. As a baseline for the performance obtained by our\napproaches, we carried out a visual Turing Test where forensic and non-forensic\nhuman volunteers, carrying out the same task, performed less well than the\nautomatic schemes.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Moises Diaz",
            "Miguel A. Ferrer",
            "Soodamani Ramalingam",
            "Richard Guest"
        ],
        "published": "2024-05-23T10:30:48Z"
    },
    {
        "title": "Interpretable Price Bounds Estimation with Shape Constraints in Price\n  Optimization",
        "link": "http://arxiv.org/abs/2405.14909v1",
        "abstract": "This paper addresses the interpretable estimation of price bounds within the\ncontext of price optimization. In recent years, price optimization methods have\nbecome indispensable for maximizing revenues and profits. However, effectively\napplying these methods to real-world pricing operations remains a significant\nchallenge. It is crucial for operators, who are responsible for setting prices,\nto utilize reasonable price bounds that are not only interpretable but also\nacceptable. Despite this necessity, most studies assume that price bounds are\ngiven constant values, and few have explored the reasonable determination of\nthese bounds. In response, we propose a comprehensive framework for determining\nprice bounds, which includes both the estimation and adjustment of these\nbounds. Specifically, we first estimate the price bounds using three distinct\napproaches based on historical pricing data. We then adjust the estimated price\nbounds by solving an optimization problem that incorporates shape constraints.\nThis method allows for the implementation of price optimization under practical\nand reasonable price bounds, suitable for real-world applications. We report\nthe effectiveness of our proposed method through numerical experiments\nconducted with historical pricing data from actual services.",
        "subjects": [
            "cs.GT",
            "cs.AI",
            "math.OC"
        ],
        "authors": [
            "Shunnosuke Ikeda",
            "Naoki Nishimura",
            "Shunji Umetani"
        ],
        "published": "2024-05-23T10:30:16Z"
    },
    {
        "title": "Adaptive tempering schedules with approximative intermediate measures\n  for filtering problems",
        "link": "http://arxiv.org/abs/2405.14408v1",
        "abstract": "Data assimilation algorithms integrate prior information from numerical model\nsimulations with observed data. Ensemble-based filters, regarded as\nstate-of-the-art, are widely employed for large-scale estimation tasks in\ndisciplines such as geoscience and meteorology. Despite their inability to\nproduce the true posterior distribution for nonlinear systems, their robustness\nand capacity for state tracking are noteworthy. In contrast, Particle filters\nyield the correct distribution in the ensemble limit but require substantially\nlarger ensemble sizes than ensemble-based filters to maintain stability in\nhigher-dimensional spaces. It is essential to transcend traditional Gaussian\nassumptions to achieve realistic quantification of uncertainties. One approach\ninvolves the hybridisation of filters, facilitated by tempering, to harness the\ncomplementary strengths of different filters. A new adaptive tempering method\nis proposed to tune the underlying schedule, aiming to systematically surpass\nthe performance previously achieved. Although promising numerical results for\ncertain filter combinations in toy examples exist in the literature, the tuning\nof hyperparameters presents a considerable challenge. A deeper understanding of\nthese interactions is crucial for practical applications.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "stat.CO",
            "65C05, 62M20, 63G35"
        ],
        "authors": [
            "Iris Rammelmüller",
            "Gottfried Hastermann",
            "Jana de Wiljes"
        ],
        "published": "2024-05-23T10:30:00Z"
    },
    {
        "title": "Gradient Transformation: Towards Efficient and Model-Agnostic Unlearning\n  for Dynamic Graph Neural Networks",
        "link": "http://arxiv.org/abs/2405.14407v1",
        "abstract": "Graph unlearning has emerged as an essential tool for safeguarding user\nprivacy and mitigating the negative impacts of undesirable data. Meanwhile, the\nadvent of dynamic graph neural networks (DGNNs) marks a significant advancement\ndue to their superior capability in learning from dynamic graphs, which\nencapsulate spatial-temporal variations in diverse real-world applications\n(e.g., traffic forecasting). With the increasing prevalence of DGNNs, it\nbecomes imperative to investigate the implementation of dynamic graph\nunlearning. However, current graph unlearning methodologies are designed for\nGNNs operating on static graphs and exhibit limitations including their serving\nin a pre-processing manner and impractical resource demands. Furthermore, the\nadaptation of these methods to DGNNs presents non-trivial challenges, owing to\nthe distinctive nature of dynamic graphs. To this end, we propose an effective,\nefficient, model-agnostic, and post-processing method to implement DGNN\nunlearning. Specifically, we first define the unlearning requests and formulate\ndynamic graph unlearning in the context of continuous-time dynamic graphs.\nAfter conducting a role analysis on the unlearning data, the remaining data,\nand the target DGNN model, we propose a method called Gradient Transformation\nand a loss function to map the unlearning request to the desired parameter\nupdate. Evaluations on six real-world datasets and state-of-the-art DGNN\nbackbones demonstrate its effectiveness (e.g., limited performance drop even\nobvious improvement) and efficiency (e.g., at most 7.23$\\times$ speed-up)\noutperformance, and potential advantages in handling future unlearning requests\n(e.g., at most 32.59$\\times$ speed-up).",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "He Zhang",
            "Bang Wu",
            "Xiangwen Yang",
            "Xingliang Yuan",
            "Chengqi Zhang",
            "Shirui Pan"
        ],
        "published": "2024-05-23T10:26:18Z"
    },
    {
        "title": "A Unification Between Deep-Learning Vision, Compartmental Dynamical\n  Thermodynamics, and Robotic Manipulation for a Circular Economy",
        "link": "http://arxiv.org/abs/2405.14406v1",
        "abstract": "The shift from a linear to a circular economy has the potential to\nsimultaneously reduce uncertainties of material supplies and waste generation.\nTo date, the development of robotic and, more generally, autonomous systems\nhave been rarely integrated into circular economy implementation strategies. In\nthis review, we merge deep-learning vision, compartmental dynamical\nthermodynamics, and robotic manipulation into a theoretically-coherent\nphysics-based research framework to lay the foundations of circular flow\ndesigns of materials, and hence, to speed-up the transition from linearity to\ncircularity. Then, we discuss opportunities for robotics in circular economy.",
        "subjects": [
            "cs.RO",
            "cs.CE"
        ],
        "authors": [
            "Federico Zocco",
            "Wassim M. Haddad",
            "Andrea Corti",
            "Monica Malvezzi"
        ],
        "published": "2024-05-23T10:26:16Z"
    },
    {
        "title": "Qubit-efficient Variational Quantum Algorithms for Image Segmentation",
        "link": "http://arxiv.org/abs/2405.14405v1",
        "abstract": "Quantum computing is expected to transform a range of computational tasks\nbeyond the reach of classical algorithms. In this work, we examine the\napplication of variational quantum algorithms (VQAs) for unsupervised image\nsegmentation to partition images into separate semantic regions. Specifically,\nwe formulate the task as a graph cut optimization problem and employ two\nestablished qubit-efficient VQAs, which we refer to as Parametric Gate Encoding\n(PGE) and Ancilla Basis Encoding (ABE), to find the optimal segmentation mask.\nIn addition, we propose Adaptive Cost Encoding (ACE), a new approach that\nleverages the same circuit architecture as ABE but adopts a problem-dependent\ncost function. We benchmark PGE, ABE and ACE on synthetically generated images,\nfocusing on quality and trainability. ACE shows consistently faster convergence\nin training the parameterized quantum circuits in comparison to PGE and ABE.\nFurthermore, we provide a theoretical analysis of the scalability of these\napproaches against the Quantum Approximate Optimization Algorithm (QAOA),\nshowing a significant cutback in the quantum resources, especially in the\nnumber of qubits that logarithmically depends on the number of pixels. The\nresults validate the strengths of ACE, while concurrently highlighting its\ninherent limitations and challenges. This paves way for further research in\nquantum-enhanced computer vision.",
        "subjects": [
            "cs.CV",
            "eess.IV",
            "quant-ph"
        ],
        "authors": [
            "Supreeth Mysore Venkatesh",
            "Antonio Macaluso",
            "Marlon Nuske",
            "Matthias Klusch",
            "Andreas Dengel"
        ],
        "published": "2024-05-23T10:21:57Z"
    },
    {
        "title": "Representative electricity price profiles for European day-ahead and\n  intraday spot markets",
        "link": "http://arxiv.org/abs/2405.14403v1",
        "abstract": "We propose a method to construct representative price profiles of the\nday-ahead (DA) and the intraday (ID) electricity spot markets and use this\nmethod to provide examples of ready-to-use price data sets. In contrast to\ncommon scenario generation approaches, the method is deterministic and relies\non a small number of degrees of freedom, with the aim to be well defined and\neasy to use. We thereby target an enhanced comparability of future research\nstudies on demand-side management and energy cost optimization. We construct\nthe price profiles based on historical time series from the spot markets of\ninterest, e.g., European Power Exchange (EPEX) spot. To this end, we extract\nkey price components from the data while also accounting for known dominant\nmechanisms in the price variation. Further, the method is able to preserve key\nstatistical features of the historical data (e.g., mean and standard deviation)\nwhen constructing the benchmark profile. Finally, our approach ensures\ncomparability of ID and DA price profiles by design, as their cumulative\n(integral) price can be made identical if needed.",
        "subjects": [
            "stat.AP",
            "cs.CE",
            "physics.soc-ph"
        ],
        "authors": [
            "Chrysanthi Papadimitriou",
            "Jan C. Schulze",
            "Alexander Mitsos"
        ],
        "published": "2024-05-23T10:21:18Z"
    },
    {
        "title": "Exact Gauss-Newton Optimization for Training Deep Neural Networks",
        "link": "http://arxiv.org/abs/2405.14402v1",
        "abstract": "We present EGN, a stochastic second-order optimization algorithm that\ncombines the generalized Gauss-Newton (GN) Hessian approximation with low-rank\nlinear algebra to compute the descent direction. Leveraging the Duncan-Guttman\nmatrix identity, the parameter update is obtained by factorizing a matrix which\nhas the size of the mini-batch. This is particularly advantageous for\nlarge-scale machine learning problems where the dimension of the neural network\nparameter vector is several orders of magnitude larger than the batch size.\nAdditionally, we show how improvements such as line search, adaptive\nregularization, and momentum can be seamlessly added to EGN to further\naccelerate the algorithm. Moreover, under mild assumptions, we prove that our\nalgorithm converges to an $\\epsilon$-stationary point at a linear rate.\nFinally, our numerical experiments demonstrate that EGN consistently exceeds,\nor at most matches the generalization performance of well-tuned SGD, Adam, and\nSGN optimizers across various supervised and reinforcement learning tasks.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Mikalai Korbit",
            "Adeyemi D. Adeoye",
            "Alberto Bemporad",
            "Mario Zanon"
        ],
        "published": "2024-05-23T10:21:05Z"
    },
    {
        "title": "Verifying Global Two-Safety Properties in Neural Networks with\n  Confidence",
        "link": "http://arxiv.org/abs/2405.14400v1",
        "abstract": "We present the first automated verification technique for confidence-based\n2-safety properties, such as global robustness and global fairness, in deep\nneural networks (DNNs). Our approach combines self-composition to leverage\nexisting reachability analysis techniques and a novel abstraction of the\nsoftmax function, which is amenable to automated verification. We characterize\nand prove the soundness of our static analysis technique. Furthermore, we\nimplement it on top of Marabou, a safety analysis tool for neural networks,\nconducting a performance evaluation on several publicly available benchmarks\nfor DNN verification.",
        "subjects": [
            "cs.LO"
        ],
        "authors": [
            "Anagha Athavale",
            "Ezio Bartocci",
            "Maria Christakis",
            "Matteo Maffei",
            "Dejan Nickovic",
            "Georg Weissenbacher"
        ],
        "published": "2024-05-23T10:19:35Z"
    },
    {
        "title": "Endowing Interpretability for Neural Cognitive Diagnosis by Efficient\n  Kolmogorov-Arnold Networks",
        "link": "http://arxiv.org/abs/2405.14399v1",
        "abstract": "In the realm of intelligent education, cognitive diagnosis plays a crucial\nrole in subsequent recommendation tasks attributed to the revealed students'\nproficiency in knowledge concepts. Although neural network-based neural\ncognitive diagnosis models (CDMs) have exhibited significantly better\nperformance than traditional models, neural cognitive diagnosis is criticized\nfor the poor model interpretability due to the multi-layer perception (MLP)\nemployed, even with the monotonicity assumption. Therefore, this paper proposes\nto empower the interpretability of neural cognitive diagnosis models through\nefficient kolmogorov-arnold networks (KANs), named KAN2CD, where KANs are\ndesigned to enhance interpretability in two manners. Specifically, in the first\nmanner, KANs are directly used to replace the used MLPs in existing neural\nCDMs; while in the second manner, the student embedding, exercise embedding,\nand concept embedding are directly processed by several KANs, and then their\noutputs are further combined and learned in a unified KAN to get final\npredictions. To overcome the problem of training KANs slowly, we modify the\nimplementation of original KANs to accelerate the training. Experiments on four\nreal-world datasets show that the proposed KA2NCD exhibits better performance\nthan traditional CDMs, and the proposed KA2NCD still has a bit of performance\nleading even over the existing neural CDMs. More importantly, the learned\nstructures of KANs enable the proposed KA2NCD to hold as good interpretability\nas traditional CDMs, which is superior to existing neural CDMs. Besides, the\ntraining cost of the proposed KA2NCD is competitive to existing models.",
        "subjects": [
            "cs.LG",
            "cs.CY",
            "68T30",
            "I.2.4"
        ],
        "authors": [
            "Shangshang Yang",
            "Linrui Qin",
            "Xiaoshan Yu"
        ],
        "published": "2024-05-23T10:19:10Z"
    },
    {
        "title": "SpGesture: Source-Free Domain-adaptive sEMG-based Gesture Recognition\n  with Jaccard Attentive Spiking Neural Network",
        "link": "http://arxiv.org/abs/2405.14398v1",
        "abstract": "Surface electromyography (sEMG) based gesture recognition offers a natural\nand intuitive interaction modality for wearable devices. Despite significant\nadvancements in sEMG-based gesture-recognition models, existing methods often\nsuffer from high computational latency and increased energy consumption.\nAdditionally, the inherent instability of sEMG signals, combined with their\nsensitivity to distribution shifts in real-world settings, compromises model\nrobustness.\n  To tackle these challenges, we propose a novel SpGesture framework based on\nSpiking Neural Networks, which possesses several unique merits compared with\nexisting methods: (1) Robustness: By utilizing membrane potential as a memory\nlist, we pioneer the introduction of Source-Free Domain Adaptation into SNN for\nthe first time. This enables SpGesture to mitigate the accuracy degradation\ncaused by distribution shifts. (2) High Accuracy: With a novel Spiking Jaccard\nAttention, SpGesture enhances the SNNs' ability to represent sEMG features,\nleading to a notable rise in system accuracy. To validate SpGesture's\nperformance, we collected a new sEMG gesture dataset which has different\nforearm postures, where SpGesture achieved the highest accuracy among the\nbaselines ($89.26\\%$). Moreover, the actual deployment on the CPU demonstrated\na system latency below 100ms, well within real-time requirements. This\nimpressive performance showcases SpGesture's potential to enhance the\napplicability of sEMG in real-world scenarios. The code is available at\nhttps://anonymous.4open.science/r/SpGesture.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "eess.SP"
        ],
        "authors": [
            "Weiyu Guo",
            "Ying Sun",
            "Yijie Xu",
            "Ziyue Qiao",
            "Yongkui Yang",
            "Hui Xiong"
        ],
        "published": "2024-05-23T10:15:29Z"
    },
    {
        "title": "BORA: A Personalized Data Display for Large-scale Experiments",
        "link": "http://arxiv.org/abs/2405.14397v1",
        "abstract": "Given the rapid improvement of the detectors at high-energy physics\nexperiments, the need for real-time data monitoring systems has become\nimperative. The significance of these systems lies in their ability to display\nexperiment status, steer software and hardware instrumentation, and provide\nalarms, thus enabling researchers to manage their experiments better. However,\nresearchers typically build most data monitoring systems as standalone in-house\nsolutions that cannot be reused for other experiments or future upgrades. We\npresent BORA (personalized collaBORAtive data display), a lightweight\nbrowser-based monitoring system that supports diverse protocols and is built\nspecifically for customizable visualization of complex data, which we\nstandardize via video streaming. We show how absolute positioning layout and\nvisual overlay background can address the diverse data display design\nrequirements. Using the client-server architecture, we enable support for\ndiverse communication protocols, with the server component responsible for\nparsing the incoming data. We integrate the Jupyter Notebook as part of our\necosystem to address the limitations of the web-based framework, providing a\nfoundation to leverage scripting capabilities and integrate popular AI\nframeworks. Since video streaming is a core component of our framework, we\nevaluate viable approaches to streaming protocols like HLS, WebRTC, and\nMPEG-Websocket. The study explores the implications for our use case,\nhighlighting its potential to transform data visualization and decision-making\nprocesses.",
        "subjects": [
            "cs.HC",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Nicholas Tan Jerome",
            "Suren Chilingaryan",
            "Timo Dritschler",
            "Andreas Kopmann"
        ],
        "published": "2024-05-23T10:14:33Z"
    },
    {
        "title": "Instruction Tuning With Loss Over Instructions",
        "link": "http://arxiv.org/abs/2405.14394v1",
        "abstract": "Instruction tuning plays a crucial role in shaping the outputs of language\nmodels (LMs) to desired styles. In this work, we propose a simple yet effective\nmethod, Instruction Modelling (IM), which trains LMs by applying a loss\nfunction to the instruction and prompt part rather than solely to the output\npart. Through experiments across 21 diverse benchmarks, we show that, in many\nscenarios, IM can effectively improve the LM performance on both NLP tasks\n(e.g., MMLU, TruthfulQA, and HumanEval) and open-ended generation benchmarks\n(e.g., MT-Bench and AlpacaEval). Remarkably, in the most advantageous case, IM\nboosts model performance on AlpacaEval 1.0 by over 100%. We identify two key\nfactors influencing the effectiveness of IM: (1) The ratio between instruction\nlength and output length in the training data; and (2) The number of training\nexamples. We observe that IM is especially beneficial when trained on datasets\nwith lengthy instructions paired with brief outputs, or under the Superficial\nAlignment Hypothesis (SAH) where a small amount of training examples are used\nfor instruction tuning. Further analysis substantiates our hypothesis that the\nimprovement can be attributed to reduced overfitting to instruction tuning\ndatasets. Our work provides practical guidance for instruction tuning LMs,\nespecially in low-resource scenarios.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Zhengyan Shi",
            "Adam X. Yang",
            "Bin Wu",
            "Laurence Aitchison",
            "Emine Yilmaz",
            "Aldo Lipani"
        ],
        "published": "2024-05-23T10:12:03Z"
    },
    {
        "title": "Qualifying and Quantifying the Benefits of Mindfulness Practices for IT\n  Workers",
        "link": "http://arxiv.org/abs/2405.14393v1",
        "abstract": "The well-being and productivity of IT workers are crucial for both individual\nsuccess and the overall prosperity of the organisations they serve. This study\nproposes mindfulness to alleviate stress and improve mental well-being for IT\nworkers. During an 8-week program, IT workers learn about mindfulness, coupled\nwith breathing practices. This study investigates the potential effects of\nthese practices by analysing participants' reflections through thematic\nanalysis and daily well-being ratings. The analysis showcased an increase in\nmental well-being and perceived productivity. It also indicated a change in the\nparticipants' perception, which showed increased self-awareness. The study\nrecommends continuing the program in the industry to see its impact on work\noutputs.",
        "subjects": [
            "cs.SE",
            "cs.CY",
            "cs.HC"
        ],
        "authors": [
            "Cristina Martinez Montes",
            "Fredrik Sjögren",
            "Adam Klevfors",
            "Birgit Penzenstadler"
        ],
        "published": "2024-05-23T10:11:14Z"
    },
    {
        "title": "Markovian Flow Matching: Accelerating MCMC with Continuous Normalizing\n  Flows",
        "link": "http://arxiv.org/abs/2405.14392v1",
        "abstract": "Continuous normalizing flows (CNFs) learn the probability path between a\nreference and a target density by modeling the vector field generating said\npath using neural networks. Recently, Lipman et al. (2022) introduced a simple\nand inexpensive method for training CNFs in generative modeling, termed flow\nmatching (FM). In this paper, we re-purpose this method for probabilistic\ninference by incorporating Markovian sampling methods in evaluating the FM\nobjective and using the learned probability path to improve Monte Carlo\nsampling. We propose a sequential method, which uses samples from a Markov\nchain to fix the probability path defining the FM objective. We augment this\nscheme with an adaptive tempering mechanism that allows the discovery of\nmultiple modes in the target. Under mild assumptions, we establish convergence\nto a local optimum of the FM objective, discuss improvements in the convergence\nrate, and illustrate our methods on synthetic and real-world examples.",
        "subjects": [
            "stat.ME",
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Alberto Cabezas",
            "Louis Sharrock",
            "Christopher Nemeth"
        ],
        "published": "2024-05-23T10:08:19Z"
    },
    {
        "title": "Explainable Few-shot Knowledge Tracing",
        "link": "http://arxiv.org/abs/2405.14391v1",
        "abstract": "Knowledge tracing (KT), aiming to mine students' mastery of knowledge by\ntheir exercise records and predict their performance on future test questions,\nis a critical task in educational assessment. While researchers achieved\ntremendous success with the rapid development of deep learning techniques,\ncurrent knowledge tracing tasks fall into the cracks from real-world teaching\nscenarios. Relying heavily on extensive student data and solely predicting\nnumerical performances differs from the settings where teachers assess\nstudents' knowledge state from limited practices and provide explanatory\nfeedback. To fill this gap, we explore a new task formulation: Explainable\nFew-shot Knowledge Tracing. By leveraging the powerful reasoning and generation\nabilities of large language models (LLMs), we then propose a cognition-guided\nframework that can track the student knowledge from a few student records while\nproviding natural language explanations. Experimental results from three widely\nused datasets show that LLMs can perform comparable or superior to competitive\ndeep knowledge tracing methods. We also discuss potential directions and call\nfor future improvements in relevant topics.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CY"
        ],
        "authors": [
            "Haoxuan Li",
            "Jifan Yu",
            "Yuanxin Ouyang",
            "Zhuang Liu",
            "Wenge Rong",
            "Juanzi Li",
            "Zhang Xiong"
        ],
        "published": "2024-05-23T10:07:21Z"
    },
    {
        "title": "Speculating About Multi-user Conversational Interfaces and LLMs: What If\n  Chatting Wasn't So Lonely?",
        "link": "http://dx.doi.org/10.1145/3640794.3665888",
        "abstract": "The advent of LLMs means that CUIs are cool again, but what isn't so cool is\nthat we're doomed to use them alone. The one user, one account, one device\nparadigm has dominated the design of CUIs and is not going away as new\nconversational technologies emerge. In this provocation we explore some of the\ntechnical, legal, and design difficulties that seem to make multi-user CUIs so\ndifficult to implement. Drawing inspiration from the ways that people manage\nmessy group discussions, such as parliamentary and consensus-based paradigms,\nwe show how LLM-based CUIs might be well suited to bridging the gap. With any\nluck, this might even result in everyone having to sit through fewer poorly run\nmeetings and agonising group discussions - truly a laudable goal!",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "William Seymour",
            "Emilee Rader"
        ],
        "published": "2024-05-23T10:05:29Z"
    },
    {
        "title": "stl2vec: Semantic and Interpretable Vector Representation of Temporal\n  Logic",
        "link": "http://arxiv.org/abs/2405.14389v1",
        "abstract": "Integrating symbolic knowledge and data-driven learning algorithms is a\nlongstanding challenge in Artificial Intelligence. Despite the recognized\nimportance of this task, a notable gap exists due to the discreteness of\nsymbolic representations and the continuous nature of machine-learning\ncomputations. One of the desired bridges between these two worlds would be to\ndefine semantically grounded vector representation (feature embedding) of logic\nformulae, thus enabling to perform continuous learning and optimization in the\nsemantic space of formulae. We tackle this goal for knowledge expressed in\nSignal Temporal Logic (STL) and devise a method to compute continuous\nembeddings of formulae with several desirable properties: the embedding (i) is\nfinite-dimensional, (ii) faithfully reflects the semantics of the formulae,\n(iii) does not require any learning but instead is defined from basic\nprinciples, (iv) is interpretable. Another significant contribution lies in\ndemonstrating the efficacy of the approach in two tasks: learning model\nchecking, where we predict the probability of requirements being satisfied in\nstochastic processes; and integrating the embeddings into a neuro-symbolic\nframework, to constrain the output of a deep-learning generative model to\ncomply to a given logical specification.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Gaia Saveri",
            "Laura Nenzi",
            "Luca Bortolussi",
            "Jan Křetínský"
        ],
        "published": "2024-05-23T10:04:56Z"
    },
    {
        "title": "Evaluation of the Programming Skills of Large Language Models",
        "link": "http://arxiv.org/abs/2405.14388v1",
        "abstract": "The advent of Large Language Models (LLM) has revolutionized the efficiency\nand speed with which tasks are completed, marking a significant leap in\nproductivity through technological innovation. As these chatbots tackle\nincreasingly complex tasks, the challenge of assessing the quality of their\noutputs has become paramount. This paper critically examines the output quality\nof two leading LLMs, OpenAI's ChatGPT and Google's Gemini AI, by comparing the\nquality of programming code generated in both their free versions. Through the\nlens of a real-world example coupled with a systematic dataset, we investigate\nthe code quality produced by these LLMs. Given their notable proficiency in\ncode generation, this aspect of chatbot capability presents a particularly\ncompelling area for analysis. Furthermore, the complexity of programming code\noften escalates to levels where its verification becomes a formidable task,\nunderscoring the importance of our study. This research aims to shed light on\nthe efficacy and reliability of LLMs in generating high-quality programming\ncode, an endeavor that has significant implications for the field of software\ndevelopment and beyond.",
        "subjects": [
            "cs.SE",
            "cs.CL",
            "cs.CR"
        ],
        "authors": [
            "Luc Bryan Heitz",
            "Joun Chamas",
            "Christopher Scherb"
        ],
        "published": "2024-05-23T10:04:36Z"
    },
    {
        "title": "Capsule Network Projectors are Equivariant and Invariant Learners",
        "link": "http://arxiv.org/abs/2405.14386v1",
        "abstract": "Learning invariant representations has been the longstanding approach to\nself-supervised learning. However, recently progress has been made in\npreserving equivariant properties in representations, yet do so with highly\nprescribed architectures. In this work, we propose an invariant-equivariant\nself-supervised architecture that employs Capsule Networks (CapsNets) which\nhave been shown to capture equivariance with respect to novel viewpoints. We\ndemonstrate that the use of CapsNets in equivariant self-supervised\narchitectures achieves improved downstream performance on equivariant tasks\nwith higher efficiency and fewer network parameters. To accommodate the\narchitectural changes of CapsNets, we introduce a new objective function based\non entropy minimisation. This approach, which we name CapsIE (Capsule Invariant\nEquivariant Network), achieves state-of-the-art performance across all\ninvariant and equivariant downstream tasks on the 3DIEBench dataset, while\noutperforming supervised baselines. Our results demonstrate the ability of\nCapsNets to learn complex and generalised representations for large-scale,\nmulti-task datasets compared to previous CapsNet benchmarks. Code is available\nat https://github.com/AberdeenML/CapsIE.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Miles Everett",
            "Aiden Durrant",
            "Mingjun Zhong",
            "Georgios Leontidis"
        ],
        "published": "2024-05-23T10:04:23Z"
    },
    {
        "title": "Emotion Identification for French in Written Texts: Considering their\n  Modes of Expression as a Step Towards Text Complexity Analysis",
        "link": "http://arxiv.org/abs/2405.14385v1",
        "abstract": "The objective of this paper is to predict (A) whether a sentence in a written\ntext expresses an emotion, (B) the mode(s) in which it is expressed, (C)\nwhether it is basic or complex, and (D) its emotional category.\n  One of our major contributions, through a dataset and a model, is to\nintegrate the fact that an emotion can be expressed in different modes: from a\ndirect mode, essentially lexicalized, to a more indirect mode, where emotions\nwill only be suggested, a mode that NLP approaches generally don't take into\naccount.\n  Another originality is that the scope is on written texts, as opposed usual\nwork focusing on conversational (often multi-modal) data. In this context,\nmodes of expression are seen as a factor towards the automatic analysis of\ncomplexity in texts.\n  Experiments on French texts show acceptable results compared to the human\nannotators' agreement, and outperforming results compared to using a large\nlanguage model with in-context learning (i.e. no fine-tuning).",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Aline Étienne",
            "Delphine Battistelli",
            "Gwénolé Lecorvé"
        ],
        "published": "2024-05-23T10:02:13Z"
    },
    {
        "title": "Reliable Trajectory Prediction and Uncertainty Quantification with\n  Conditioned Diffusion Models",
        "link": "http://arxiv.org/abs/2405.14384v1",
        "abstract": "This work introduces the conditioned Vehicle Motion Diffusion (cVMD) model, a\nnovel network architecture for highway trajectory prediction using diffusion\nmodels. The proposed model ensures the drivability of the predicted trajectory\nby integrating non-holonomic motion constraints and physical constraints into\nthe generative prediction module. Central to the architecture of cVMD is its\ncapacity to perform uncertainty quantification, a feature that is crucial in\nsafety-critical applications. By integrating the quantified uncertainty into\nthe prediction process, the cVMD's trajectory prediction performance is\nimproved considerably. The model's performance was evaluated using the publicly\navailable highD dataset. Experiments show that the proposed architecture\nachieves competitive trajectory prediction accuracy compared to\nstate-of-the-art models, while providing guaranteed drivable trajectories and\nuncertainty quantification.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Marion Neumeier",
            "Sebastian Dorn",
            "Michael Botsch",
            "Wolfgang Utschick"
        ],
        "published": "2024-05-23T10:01:39Z"
    },
    {
        "title": "Perception of Knowledge Boundary for Large Language Models through\n  Semi-open-ended Question Answering",
        "link": "http://arxiv.org/abs/2405.14383v1",
        "abstract": "Large Language Models (LLMs) are widely used for knowledge-seeking yet suffer\nfrom hallucinations. The knowledge boundary (KB) of an LLM limits its factual\nunderstanding, beyond which it may begin to hallucinate. Investigating the\nperception of LLMs' KB is crucial for detecting hallucinations and LLMs'\nreliable generation. Current studies perceive LLMs' KB on questions with a\nconcrete answer (close-ended questions) while paying limited attention to\nsemi-open-ended questions (SoeQ) that correspond to many potential answers.\nSome researchers achieve it by judging whether the question is answerable or\nnot. However, this paradigm is unsuitable for SoeQ, which are usually partially\nanswerable, containing both answerable and ambiguous (unanswerable) answers.\nAmbiguous answers are essential for knowledge-seeking, but they may go beyond\nthe KB of LLMs. In this paper, we perceive the LLMs' KB with SoeQ by\ndiscovering more ambiguous answers. First, we apply an LLM-based approach to\nconstruct SoeQ and obtain answers from a target LLM. Unfortunately, the output\nprobabilities of mainstream black-box LLMs are inaccessible to sample for\nlow-probability ambiguous answers. Therefore, we apply an open-sourced\nauxiliary model to explore ambiguous answers for the target LLM. We calculate\nthe nearest semantic representation for existing answers to estimate their\nprobabilities, with which we reduce the generation probability of\nhigh-probability answers to achieve a more effective generation. Finally, we\ncompare the results from the RAG-based evaluation and LLM self-evaluation to\ncategorize four types of ambiguous answers that are beyond the KB of the target\nLLM. Following our method, we construct a dataset to perceive the KB for GPT-4.\nWe find that GPT-4 performs poorly on SoeQ and is often unaware of its KB.\nBesides, our auxiliary model, LLaMA-2-13B, is effective in discovering more\nambiguous answers.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Zhihua Wen",
            "Zhiliang Tian",
            "Zexin Jian",
            "Zhen Huang",
            "Pei Ke",
            "Yifu Gao",
            "Minlie Huang",
            "Dongsheng Li"
        ],
        "published": "2024-05-23T10:00:14Z"
    },
    {
        "title": "Multi-purpose robot for rehabilitation of small diameter water pipes",
        "link": "http://arxiv.org/abs/2405.14382v1",
        "abstract": "Rehabilitating cast iron pipes through lining offers several advantages,\nincluding increased durability, reduced water leaks, and minimal\ndisruption.This approach presents a cost effective and environmentally friendly\nsolution by sealing cracks and joints, extending the pipeline's lifespan, and\nreducing water wastage, all while avoiding the need for trench excavation.\nHowever, due to the relining process, branch connections are sealed and need to\nbe reestablished. To address the issue of rehabilitating small-diameter water\npipes, we have designed a modular robot capable of traversing and working\nwithin 200 meter long, 100 mm diameter cast iron pipes. This robot is equipped\nwith perception functions to detect, locate, and characterize the branch\nconnections in cast iron pipes and relocate them after lining, as well as\nmachining functions. A first prototype of this system has been developed and\nvalidated on an 8 meter long section, in a laboratory environment.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Julien Feiguel",
            "Mouhamed NDiaye",
            "Pascal Chambaud",
            "Adrien Chambellan",
            "Pierre Blanc",
            "Steve Bourgeois",
            "Lucas Labarussiat",
            "Clemence Dubois",
            "Audrey Vigneron",
            "Thomas Desrez",
            "Alain Riwan",
            "Caroline Vienne"
        ],
        "published": "2024-05-23T09:59:04Z"
    },
    {
        "title": "A high-level comparison of state-of-the-art quantum algorithms for\n  breaking asymmetric cryptography",
        "link": "http://arxiv.org/abs/2405.14381v1",
        "abstract": "We provide a high-level cost comparison between Regev's quantum algorithm\nwith Eker{\\aa}-G\\\"artner's extensions on the one hand, and existing\nstate-of-the-art quantum algorithms for factoring and computing discrete\nlogarithms on the other. This when targeting cryptographically relevant problem\ninstances, and when accounting for the space-saving optimizations of Ragavan\nand Vaikuntanathan that apply to Regev's algorithm, and optimizations such as\nwindowing that apply to the existing algorithms.\n  Our conclusion is that Regev's algorithm without the space-saving\noptimizations may achieve a per-run advantage, but not an overall advantage, if\nnon-computational quantum memory is cheap. Regev's algorithm with the\nspace-saving optimizations does not achieve an advantage, since it uses more\ncomputational memory, whilst also performing more work, per run and overall,\ncompared to the existing state-of-the-art algorithms. As such, further\noptimizations are required for it to achieve an advantage for cryptographically\nrelevant problem instances.",
        "subjects": [
            "cs.CR",
            "quant-ph"
        ],
        "authors": [
            "Martin Ekerå",
            "Joel Gärtner"
        ],
        "published": "2024-05-23T09:59:00Z"
    },
    {
        "title": "Can Large Language Models Create New Knowledge for Spatial Reasoning\n  Tasks?",
        "link": "http://arxiv.org/abs/2405.14379v1",
        "abstract": "The potential for Large Language Models (LLMs) to generate new information\noffers a potential step change for research and innovation. This is challenging\nto assert as it can be difficult to determine what an LLM has previously seen\nduring training, making \"newness\" difficult to substantiate. In this paper we\nobserve that LLMs are able to perform sophisticated reasoning on problems with\na spatial dimension, that they are unlikely to have previously directly\nencountered. While not perfect, this points to a significant level of\nunderstanding that state-of-the-art LLMs can now achieve, supporting the\nproposition that LLMs are able to yield significant emergent properties. In\nparticular, Claude 3 is found to perform well in this regard.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Thomas Greatrix",
            "Roger Whitaker",
            "Liam Turner",
            "Walter Colombo"
        ],
        "published": "2024-05-23T09:54:54Z"
    },
    {
        "title": "CoMERA: Computing- and Memory-Efficient Training via Rank-Adaptive\n  Tensor Optimization",
        "link": "http://arxiv.org/abs/2405.14377v1",
        "abstract": "Training large AI models such as deep learning recommendation systems and\nfoundation language (or multi-modal) models costs massive GPUs and computing\ntime. The high training cost has become only affordable to big tech companies,\nmeanwhile also causing increasing concerns about the environmental impact. This\npaper presents CoMERA, a Computing- and Memory-Efficient training method via\nRank-Adaptive tensor optimization. CoMERA achieves end-to-end rank-adaptive\ntensor-compressed training via a multi-objective optimization formulation, and\nimproves the training to provide both a high compression ratio and excellent\naccuracy in the training process. Our optimized numerical computation (e.g.,\noptimized tensorized embedding and tensor-vector contractions) and GPU\nimplementation eliminate part of the run-time overhead in the tensorized\ntraining on GPU. This leads to, for the first time, $2-3\\times$ speedup per\ntraining epoch compared with standard training. CoMERA also outperforms the\nrecent GaLore in terms of both memory and computing efficiency. Specifically,\nCoMERA is $2\\times$ faster per training epoch and $9\\times$ more\nmemory-efficient than GaLore on a tested six-encoder transformer with\nsingle-batch training. With further HPC optimization, CoMERA may significantly\nreduce the training cost of large language models.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Zi Yang",
            "Samridhi Choudhary",
            "Xinfeng Xie",
            "Cao Gao",
            "Siegfried Kunzmann",
            "Zheng Zhang"
        ],
        "published": "2024-05-23T09:52:15Z"
    },
    {
        "title": "State-Constrained Offline Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.14374v1",
        "abstract": "Traditional offline reinforcement learning methods predominantly operate in a\nbatch-constrained setting. This confines the algorithms to a specific\nstate-action distribution present in the dataset, reducing the effects of\ndistributional shift but restricting the algorithm greatly. In this paper, we\nalleviate this limitation by introducing a novel framework named\n\\emph{state-constrained} offline reinforcement learning. By exclusively\nfocusing on the dataset's state distribution, our framework significantly\nenhances learning potential and reduces previous limitations. The proposed\nsetting not only broadens the learning horizon but also improves the ability to\ncombine different trajectories from the dataset effectively, a desirable\nproperty inherent in offline reinforcement learning. Our research is\nunderpinned by solid theoretical findings that pave the way for subsequent\nadvancements in this domain. Additionally, we introduce StaCQ, a deep learning\nalgorithm that is both performance-driven on the D4RL benchmark datasets and\nclosely aligned with our theoretical propositions. StaCQ establishes a strong\nbaseline for forthcoming explorations in state-constrained offline\nreinforcement learning.",
        "subjects": [
            "stat.ML",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Charles A. Hepburn",
            "Yue Jin",
            "Giovanni Montana"
        ],
        "published": "2024-05-23T09:50:04Z"
    },
    {
        "title": "Skew-symmetric schemes for stochastic differential equations with\n  non-Lipschitz drift: an unadjusted Barker algorithm",
        "link": "http://arxiv.org/abs/2405.14373v1",
        "abstract": "We propose a new simple and explicit numerical scheme for time-homogeneous\nstochastic differential equations. The scheme is based on sampling increments\nat each time step from a skew-symmetric probability distribution, with the\nlevel of skewness determined by the drift and volatility of the underlying\nprocess. We show that as the step-size decreases the scheme converges weakly to\nthe diffusion of interest. We then consider the problem of simulating from the\nlimiting distribution of an ergodic diffusion process using the numerical\nscheme with a fixed step-size. We establish conditions under which the\nnumerical scheme converges to equilibrium at a geometric rate, and quantify the\nbias between the equilibrium distributions of the scheme and of the true\ndiffusion process. Notably, our results do not require a global Lipschitz\nassumption on the drift, in contrast to those required for the Euler--Maruyama\nscheme for long-time simulation at fixed step-sizes. Our weak convergence\nresult relies on an extension of the theory of Milstein \\& Tretyakov to\nstochastic differential equations with non-Lipschitz drift, which could also be\nof independent interest. We support our theoretical results with numerical\nsimulations.",
        "subjects": [
            "math.PR",
            "cs.NA",
            "math.NA",
            "stat.CO",
            "60J60, 60F05, 65C40, 68W40"
        ],
        "authors": [
            "Samuel Livingstone",
            "Nikolas Nüsken",
            "Giorgos Vasdekis",
            "Rui-Yang Zhang"
        ],
        "published": "2024-05-23T09:49:46Z"
    },
    {
        "title": "Learning Constrained Markov Decision Processes With Non-stationary\n  Rewards and Constraints",
        "link": "http://arxiv.org/abs/2405.14372v1",
        "abstract": "In constrained Markov decision processes (CMDPs) with adversarial rewards and\nconstraints, a well-known impossibility result prevents any algorithm from\nattaining both sublinear regret and sublinear constraint violation, when\ncompeting against a best-in-hindsight policy that satisfies constraints on\naverage. In this paper, we show that this negative result can be eased in CMDPs\nwith non-stationary rewards and constraints, by providing algorithms whose\nperformances smoothly degrade as non-stationarity increases. Specifically, we\npropose algorithms attaining $\\tilde{\\mathcal{O}} (\\sqrt{T} + C)$ regret and\npositive constraint violation under bandit feedback, where $C$ is a corruption\nvalue measuring the environment non-stationarity. This can be $\\Theta(T)$ in\nthe worst case, coherently with the impossibility result for adversarial CMDPs.\nFirst, we design an algorithm with the desired guarantees when $C$ is known.\nThen, in the case $C$ is unknown, we show how to obtain the same results by\nembedding such an algorithm in a general meta-procedure. This is of independent\ninterest, as it can be applied to any non-stationary constrained online\nlearning setting.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Francesco Emanuele Stradi",
            "Anna Lunghi",
            "Matteo Castiglioni",
            "Alberto Marchesi",
            "Nicola Gatti"
        ],
        "published": "2024-05-23T09:48:48Z"
    },
    {
        "title": "EdgeShard: Efficient LLM Inference via Collaborative Edge Computing",
        "link": "http://arxiv.org/abs/2405.14371v1",
        "abstract": "Large language models (LLMs) have shown great potential in natural language\nprocessing and content generation. However, current LLMs heavily rely on cloud\ncomputing, leading to prolonged latency, high bandwidth cost, and privacy\nconcerns. Edge computing is promising to address such concerns by deploying\nLLMs on edge devices, closer to data sources. Some works try to leverage model\nquantization to reduce the model size to fit the resource-constraint edge\ndevices, but they lead to accuracy loss. Other works use cloud-edge\ncollaboration, suffering from unstable network connections. In this work, we\nleverage collaborative edge computing to facilitate the collaboration among\nedge devices and cloud servers for jointly performing efficient LLM inference.\nWe propose a general framework to partition the LLM model into shards and\ndeploy on distributed devices. To achieve efficient LLM inference, we formulate\nan adaptive joint device selection and model partition problem and design an\nefficient dynamic programming algorithm to optimize the inference latency and\nthroughput, respectively. Experiments of Llama2 serial models on a\nheterogeneous physical prototype demonstrate that EdgeShard achieves up to 50%\nlatency reduction and 2x throughput improvement over baseline methods.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Mingjin Zhang",
            "Jiannong Cao",
            "Xiaoming Shen",
            "Zeyang Cui"
        ],
        "published": "2024-05-23T09:46:22Z"
    },
    {
        "title": "RoPINN: Region Optimized Physics-Informed Neural Networks",
        "link": "http://arxiv.org/abs/2405.14369v1",
        "abstract": "Physics-informed neural networks (PINNs) have been widely applied to solve\npartial differential equations (PDEs) by enforcing outputs and gradients of\ndeep models to satisfy target equations. Due to the limitation of numerical\ncomputation, PINNs are conventionally optimized on finite selected points.\nHowever, since PDEs are usually defined on continuous domains, solely\noptimizing models on scattered points may be insufficient to obtain an accurate\nsolution for the whole domain. To mitigate this inherent deficiency of the\ndefault scatter-point optimization, this paper proposes and theoretically\nstudies a new training paradigm as region optimization. Concretely, we propose\nto extend the optimization process of PINNs from isolated points to their\ncontinuous neighborhood regions, which can theoretically decrease the\ngeneralization error, especially for hidden high-order constraints of PDEs. A\npractical training algorithm, Region Optimized PINN (RoPINN), is seamlessly\nderived from this new paradigm, which is implemented by a straightforward but\neffective Monte Carlo sampling method. By calibrating the sampling process into\ntrust regions, RoPINN finely balances sampling efficiency and generalization\nerror. Experimentally, RoPINN consistently boosts the performance of diverse\nPINNs on a wide range of PDEs without extra backpropagation or gradient\ncalculation.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Haixu Wu",
            "Huakun Luo",
            "Yuezhou Ma",
            "Jianmin Wang",
            "Mingsheng Long"
        ],
        "published": "2024-05-23T09:45:57Z"
    },
    {
        "title": "Data Mixing Made Efficient: A Bivariate Scaling Law for Language Model\n  Pretraining",
        "link": "http://arxiv.org/abs/2405.14908v1",
        "abstract": "Large language models exhibit exceptional generalization capabilities,\nprimarily attributed to the utilization of diversely sourced data. However,\nconventional practices in integrating this diverse data heavily rely on\nheuristic schemes, lacking theoretical guidance. This research tackles these\nlimitations by investigating strategies based on low-cost proxies for data\nmixtures, with the aim of streamlining data curation to enhance training\nefficiency. Specifically, we propose a unified scaling law, termed BiMix, which\naccurately models the bivariate scaling behaviors of both data quantity and\nmixing proportions. We conduct systematic experiments and provide empirical\nevidence for the predictive power and fundamental principles of BiMix. Notably,\nour findings reveal that entropy-driven training-free data mixtures can achieve\ncomparable or even better performance than more resource-intensive methods. We\nhope that our quantitative insights can shed light on further judicious\nresearch and development in cost-effective language modeling.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Ce Ge",
            "Zhijian Ma",
            "Daoyuan Chen",
            "Yaliang Li",
            "Bolin Ding"
        ],
        "published": "2024-05-23T09:44:02Z"
    },
    {
        "title": "MiniCache: KV Cache Compression in Depth Dimension for Large Language\n  Models",
        "link": "http://arxiv.org/abs/2405.14366v1",
        "abstract": "A critical approach for efficiently deploying computationally demanding large\nlanguage models (LLMs) is Key-Value (KV) caching. The KV cache stores key-value\nstates of previously generated tokens, significantly reducing the need for\nrepetitive computations and thereby lowering latency in autoregressive\ngeneration. However, the size of the KV cache grows linearly with sequence\nlength, posing challenges for applications requiring long context input and\nextensive sequence generation. In this paper, we present a simple yet effective\napproach, called MiniCache, to compress the KV cache across layers from a novel\ndepth perspective, significantly reducing the memory footprint for LLM\ninference. Our approach is based on the observation that KV cache states\nexhibit high similarity between the adjacent layers in the middle-to-deep\nportion of LLMs. To facilitate merging, we propose disentangling the states\ninto the magnitude and direction components, interpolating the directions of\nthe state vectors while preserving their lengths unchanged. Furthermore, we\nintroduce a token retention strategy to keep highly distinct state pairs\nunmerged, thus preserving the information with minimal additional storage\noverhead. Our MiniCache is training-free and general, complementing existing KV\ncache compression strategies, such as quantization and sparsity. We conduct a\ncomprehensive evaluation of MiniCache utilizing various models including\nLLaMA-2, LLaMA-3, Phi-3, Mistral, and Mixtral across multiple benchmarks,\ndemonstrating its exceptional performance in achieving superior compression\nratios and high throughput. On the ShareGPT dataset, LLaMA-2-7B with 4-bit\nMiniCache achieves a remarkable compression ratio of up to 5.02x, enhances\ninference throughput by approximately 5x, and reduces the memory footprint by\n41% compared to the FP16 full cache baseline, all while maintaining\nnear-lossless performance.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Akide Liu",
            "Jing Liu",
            "Zizheng Pan",
            "Yefei He",
            "Gholamreza Haffari",
            "Bohan Zhuang"
        ],
        "published": "2024-05-23T09:43:52Z"
    },
    {
        "title": "JiuZhang3.0: Efficiently Improving Mathematical Reasoning by Training\n  Small Data Synthesis Models",
        "link": "http://arxiv.org/abs/2405.14365v1",
        "abstract": "Mathematical reasoning is an important capability of large language\nmodels~(LLMs) for real-world applications. To enhance this capability, existing\nwork either collects large-scale math-related texts for pre-training, or relies\non stronger LLMs (\\eg GPT-4) to synthesize massive math problems. Both types of\nwork generally lead to large costs in training or synthesis. To reduce the\ncost, based on open-source available texts, we propose an efficient way that\ntrains a small LLM for math problem synthesis, to efficiently generate\nsufficient high-quality pre-training data. To achieve it, we create a dataset\nusing GPT-4 to distill its data synthesis capability into the small LLM.\nConcretely, we craft a set of prompts based on human education stages to guide\nGPT-4, to synthesize problems covering diverse math knowledge and difficulty\nlevels. Besides, we adopt the gradient-based influence estimation method to\nselect the most valuable math-related texts. The both are fed into GPT-4 for\ncreating the knowledge distillation dataset to train the small LLM. We leverage\nit to synthesize 6 million math problems for pre-training our JiuZhang3.0\nmodel, which only needs to invoke GPT-4 API 9.3k times and pre-train on 4.6B\ndata. Experimental results have shown that JiuZhang3.0 achieves\nstate-of-the-art performance on several mathematical reasoning datasets, under\nboth natural language reasoning and tool manipulation settings. Our code and\ndata will be publicly released in\n\\url{https://github.com/RUCAIBox/JiuZhang3.0}.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Kun Zhou",
            "Beichen Zhang",
            "Jiapeng Wang",
            "Zhipeng Chen",
            "Wayne Xin Zhao",
            "Jing Sha",
            "Zhichao Sheng",
            "Shijin Wang",
            "Ji-Rong Wen"
        ],
        "published": "2024-05-23T09:43:19Z"
    },
    {
        "title": "Optimal Whole Body Trajectory Planning for Mobile Manipulators in\n  Planetary Exploration and Construction",
        "link": "http://arxiv.org/abs/2405.14363v1",
        "abstract": "Space robotics poses unique challenges arising from the limitation of energy\nand computational resources, and the complexity of the environment and employed\nplatforms. At the control center, offline motion planning is fundamental in the\ncomputation of optimized trajectories accounting for the system's constraints.\nSmooth movements, collision and forbidden areas avoidance, target visibility\nand energy consumption are all important factors to consider to be able to\ngenerate feasible and optimal plans. When mobile manipulators (terrestrial,\naerial) are employed, the base and the arm movements are often separately\nplanned, ultimately resulting in sub-optimal solutions. We propose an Optimal\nWhole Body Planner (OptiWB) based on Discrete Dynamic Programming (DDP) and\noptimal interpolation. Kinematic redundancy is exploited for collision and\nforbidden areas avoidance, and to improve target illumination and visibility\nfrom onboard cameras. The planner, implemented in ROS (Robot Operating System),\ninterfaces 3DROCS, a mission planner used in several programs of the European\nSpace Agency (ESA) to support planetary exploration surface missions and part\nof the ExoMars Rover's planning software. The proposed approach is exercised on\na simplified version of the Analog-1 Interact rover by ESA, a 7-DOFs robotic\narm mounted on a four wheels non-holonomic platform.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Federica Storiale",
            "Enrico Ferrentino",
            "Federico Salvioli",
            "Konstantinos Kapellos",
            "Pasquale Chiacchio"
        ],
        "published": "2024-05-23T09:39:23Z"
    },
    {
        "title": "Advancing Spiking Neural Networks for Sequential Modeling with Central\n  Pattern Generators",
        "link": "http://arxiv.org/abs/2405.14362v1",
        "abstract": "Spiking neural networks (SNNs) represent a promising approach to developing\nartificial neural networks that are both energy-efficient and biologically\nplausible. However, applying SNNs to sequential tasks, such as text\nclassification and time-series forecasting, has been hindered by the challenge\nof creating an effective and hardware-friendly spike-form positional encoding\n(PE) strategy. Drawing inspiration from the central pattern generators (CPGs)\nin the human brain, which produce rhythmic patterned outputs without requiring\nrhythmic inputs, we propose a novel PE technique for SNNs, termed CPG-PE. We\ndemonstrate that the commonly used sinusoidal PE is mathematically a specific\nsolution to the membrane potential dynamics of a particular CPG. Moreover,\nextensive experiments across various domains, including time-series\nforecasting, natural language processing, and image classification, show that\nSNNs with CPG-PE outperform their conventional counterparts. Additionally, we\nperform analysis experiments to elucidate the mechanism through which SNNs\nencode positional information and to explore the function of CPGs in the human\nbrain. This investigation may offer valuable insights into the fundamental\nprinciples of neural computation.",
        "subjects": [
            "cs.NE"
        ],
        "authors": [
            "Changze Lv",
            "Dongqi Han",
            "Yansen Wang",
            "Xiaoqing Zheng",
            "Xuanjing Huang",
            "Dongsheng Li"
        ],
        "published": "2024-05-23T09:39:12Z"
    },
    {
        "title": "On discount functions for economic model predictive control without\n  terminal conditions",
        "link": "http://arxiv.org/abs/2405.14361v1",
        "abstract": "In this paper, we investigate discounted economic model predictive control\n(E-MPC) schemes without terminal conditions in scenarios where the optimal\noperating behavior is a periodic orbit. For such a setting, it is known that a\nlinearly discounted stage cost guarantees asymptotic stability of any\narbitrarily small neighborhood of the optimal orbit if the prediction horizon\nis sufficiently long. However, in some examples very long prediction horizons\nare needed to achieve the desired performance. In this work, we extend these\nresults by providing the same qualitative stability guarantees for a large\nclass of discount functions. Numerical examples illustrate the influence of the\ndiscount function and show that with suitable discounting we can achieve\nsignificantly better performance than the linearly discounted E-MPC, even for\nshort prediction horizons.",
        "subjects": [
            "math.OC",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Lukas Schwenkel",
            "Daniel Briem",
            "Matthias A. Müller",
            "Frank Allgöwer"
        ],
        "published": "2024-05-23T09:36:24Z"
    },
    {
        "title": "Look into the Future: Deep Contextualized Sequential Recommendation",
        "link": "http://arxiv.org/abs/2405.14359v1",
        "abstract": "Sequential recommendation focuses on mining useful patterns from the user\nbehavior history to better estimate his preference on the candidate items.\nPrevious solutions adopt recurrent networks or retrieval methods to obtain the\nuser's profile representation so as to perform the preference estimation. In\nthis paper, we propose a novel framework of sequential recommendation called\nLook into the Future (LIFT), which builds and leverages the contexts of\nsequential recommendation. The context in LIFT refers to a user's current\nprofile that can be represented based on both past and future behaviors. As\nsuch, the learned context will be more effective in predicting the user's\nbehaviors in sequential recommendation. Apparently, it is impossible to use\nreal future information to predict the current behavior, we thus propose a\nnovel retrieval-based framework to use the most similar interaction's future\ninformation as the future context of the target interaction without data\nleakage. Furthermore, in order to exploit the intrinsic information embedded\nwithin the context itself, we introduce an innovative pretraining methodology\nincorporating behavior masking. This approach is designed to facilitate the\nefficient acquisition of context representations. We demonstrate that finding\nrelevant contexts from the global user pool via retrieval methods will greatly\nimprove preference estimation performance. In our extensive experiments over\nreal-world datasets, LIFT demonstrates significant performance improvement on\nclick-through rate prediction tasks in sequential recommendation over strong\nbaselines.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Lei Zheng",
            "Ning Li",
            "Yanhuan Huang",
            "Ruiwen Xu",
            "Weinan Zhang",
            "Yong Yu"
        ],
        "published": "2024-05-23T09:34:28Z"
    },
    {
        "title": "AI-Olympics: Exploring the Generalization of Agents through Open\n  Competitions",
        "link": "http://arxiv.org/abs/2405.14358v1",
        "abstract": "Between 2021 and 2023, AI-Olympics, a series of online AI competitions was\nhosted by the online evaluation platform Jidi in collaboration with the IJCAI\ncommittee. In these competitions, an agent is required to accomplish diverse\nsports tasks in a two-dimensional continuous world, while competing against an\nopponent. This paper provides a brief overview of the competition series and\nhighlights notable findings. We aim to contribute insights to the field of\nmulti-agent decision-making and explore the generalization of agents through\nengineering efforts.",
        "subjects": [
            "cs.MA"
        ],
        "authors": [
            "Chen Wang",
            "Yan Song",
            "Shuai Wu",
            "Sa Wu",
            "Ruizhi Zhang",
            "Shu Lin",
            "Haifeng Zhang"
        ],
        "published": "2024-05-23T09:33:57Z"
    },
    {
        "title": "Retrieval-Augmented Mining of Temporal Logic Specifications from Data",
        "link": "http://arxiv.org/abs/2405.14355v1",
        "abstract": "The integration of cyber-physical systems (CPS) into everyday life raises the\ncritical necessity of ensuring their safety and reliability. An important step\nin this direction is requirement mining, i.e. inferring formally specified\nsystem properties from observed behaviors, in order to discover knowledge about\nthe system. Signal Temporal Logic (STL) offers a concise yet expressive\nlanguage for specifying requirements, particularly suited for CPS, where\nbehaviors are typically represented as time series data. This work addresses\nthe task of learning STL requirements from observed behaviors in a data-driven\nmanner, focusing on binary classification, i.e. on inferring properties of the\nsystem which are able to discriminate between regular and anomalous behaviour,\nand that can be used both as classifiers and as monitors of the compliance of\nthe CPS to desirable specifications. We present a novel framework that combines\nBayesian Optimization (BO) and Information Retrieval (IR) techniques to\nsimultaneously learn both the structure and the parameters of STL formulae,\nwithout restrictions on the STL grammar. Specifically, we propose a framework\nthat leverages a dense vector database containing semantic-preserving\ncontinuous representations of millions of formulae, queried for facilitating\nthe mining of requirements inside a BO loop. We demonstrate the effectiveness\nof our approach in several signal classification applications, showing its\nability to extract interpretable insights from system executions and advance\nthe state-of-the-art in requirement mining for CPS.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Gaia Saveri",
            "Luca Bortolussi"
        ],
        "published": "2024-05-23T09:29:00Z"
    },
    {
        "title": "Explaining Graph Neural Networks via Structure-aware Interaction Index",
        "link": "http://arxiv.org/abs/2405.14352v1",
        "abstract": "The Shapley value is a prominent tool for interpreting black-box machine\nlearning models thanks to its strong theoretical foundation. However, for\nmodels with structured inputs, such as graph neural networks, existing\nShapley-based explainability approaches either focus solely on node-wise\nimportance or neglect the graph structure when perturbing the input instance.\nThis paper introduces the Myerson-Taylor interaction index that internalizes\nthe graph structure into attributing the node values and the interaction values\namong nodes. Unlike the Shapley-based methods, the Myerson-Taylor index\ndecomposes coalitions into components satisfying a pre-chosen connectivity\ncriterion. We prove that the Myerson-Taylor index is the unique one that\nsatisfies a system of five natural axioms accounting for graph structure and\nhigh-order interaction among nodes. Leveraging these properties, we propose\nMyerson-Taylor Structure-Aware Graph Explainer (MAGE), a novel explainer that\nuses the second-order Myerson-Taylor index to identify the most important\nmotifs influencing the model prediction, both positively and negatively.\nExtensive experiments on various graph datasets and models demonstrate that our\nmethod consistently provides superior subgraph explanations compared to\nstate-of-the-art methods.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ngoc Bui",
            "Hieu Trung Nguyen",
            "Viet Anh Nguyen",
            "Rex Ying"
        ],
        "published": "2024-05-23T09:24:33Z"
    },
    {
        "title": "Doubly-Dynamic ISAC Precoding for Vehicular Networks: A Constrained Deep\n  Reinforcement Learning (CDRL) Approach",
        "link": "http://arxiv.org/abs/2405.14347v1",
        "abstract": "Integrated sensing and communication (ISAC) technology is essential for\nenabling the vehicular networks. However, the communication channel in this\nscenario exhibits time-varying characteristics, and the potential targets may\nmove rapidly, creating a doubly-dynamic phenomenon. This nature poses a\nchallenge for real-time precoder design. While optimization-based solutions are\nwidely researched, they are complex and heavily rely on perfect prior\ninformation, which is impractical in double dynamics. To address this\nchallenge, we propose using constrained deep reinforcement learning (CDRL) to\nfacilitate dynamic updates to the ISAC precoder design. Additionally, the\nprimal dual-deep deterministic policy gradient (PD-DDPG) and Wolpertinger\narchitecture are tailored to efficiently train the algorithm under complex\nconstraints and variable numbers of users. The proposed scheme not only adapts\nto the dynamics based on observations but also leverages environmental\ninformation to enhance performance and reduce complexity. Its superiority over\nexisting candidates has been validated through experiments.",
        "subjects": [
            "eess.SP",
            "cs.AI"
        ],
        "authors": [
            "Zonghui Yang",
            "Shijian Gao",
            "Xiang Cheng"
        ],
        "published": "2024-05-23T09:19:14Z"
    },
    {
        "title": "Mixture of Public and Private Distributions in Imperfect Information\n  Games",
        "link": "http://dx.doi.org/10.1109/CoG57401.2023.10333169",
        "abstract": "In imperfect information games (e.g. Bridge, Skat, Poker), one of the\nfundamental considerations is to infer the missing information while at the\nsame time avoiding the disclosure of private information. Disregarding the\nissue of protecting private information can lead to a highly exploitable\nperformance. Yet, excessive attention to it leads to hesitations that are no\nlonger consistent with our private information. In our work, we show that to\nimprove performance, one must choose whether to use a player's private\ninformation. We extend our work by proposing a new belief distribution\ndepending on the amount of private and public information desired. We\nempirically demonstrate an increase in performance and, with the aim of further\nimproving performance, the new distribution should be used according to the\nposition in the game. Our experiments have been done on multiple benchmarks and\nin multiple determinization-based algorithms (PIMC and IS-MCTS).",
        "subjects": [
            "cs.AI",
            "cs.GT"
        ],
        "authors": [
            "Jérôme Arjonilla",
            "Abdallah Saffidine",
            "Tristan Cazenave"
        ],
        "published": "2024-05-23T09:18:25Z"
    },
    {
        "title": "Expert exploranation for communicating scientific methods -- A case\n  study in conflict research",
        "link": "http://dx.doi.org/10.1016/j.cag.2024.103937",
        "abstract": "Science communication aims at making key research insights accessible to the\nbroad public. If explanatory and exploratory visualization techniques are\ncombined to do so, the approach is also referred to as exploranation. In this\ncontext, the audience is usually not required to have domain expertise.\nHowever, we show that exploranation can not only support the communication\nbetween researchers and a broad audience, but also between researchers\ndirectly. With the goal of communicating an existing method for conducting\ncausal inference on spatio-temporal conflict event data, we investigated how to\nperform exploranation for experts, i.e., expert exploranation. Based on\napplication scenarios of the inference method, we developed three versions of\nan interactive visual story to explain the method to conflict researchers. We\nabstracted the corresponding design process and evaluated the stories both with\nexperts who were unfamiliar with the explained method and experts who were\nalready familiar with it. The positive and extensive feedback from the\nevaluation shows that expert exploranation is a promising direction for visual\nstorytelling, as it can help to improve scientific outreach, methodological\nunderstanding, and accessibility for researchers new to a field.",
        "subjects": [
            "cs.CY",
            "cs.HC"
        ],
        "authors": [
            "Benedikt Mayer",
            "Karsten Donnay",
            "Kai Lawonn",
            "Bernhard Preim",
            "Monique Meuschke"
        ],
        "published": "2024-05-23T09:15:46Z"
    },
    {
        "title": "Efficient Visual State Space Model for Image Deblurring",
        "link": "http://arxiv.org/abs/2405.14343v1",
        "abstract": "Convolutional neural networks (CNNs) and Vision Transformers (ViTs) have\nachieved excellent performance in image restoration. ViTs typically yield\nsuperior results in image restoration compared to CNNs due to their ability to\ncapture long-range dependencies and input-dependent characteristics. However,\nthe computational complexity of Transformer-based models grows quadratically\nwith the image resolution, limiting their practical appeal in high-resolution\nimage restoration tasks. In this paper, we propose a simple yet effective\nvisual state space model (EVSSM) for image deblurring, leveraging the benefits\nof state space models (SSMs) to visual data. In contrast to existing methods\nthat employ several fixed-direction scanning for feature extraction, which\nsignificantly increases the computational cost, we develop an efficient visual\nscan block that applies various geometric transformations before each SSM-based\nmodule, capturing useful non-local information and maintaining high efficiency.\nExtensive experimental results show that the proposed EVSSM performs favorably\nagainst state-of-the-art image deblurring methods on benchmark datasets and\nreal-captured images.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Lingshun Kong",
            "Jiangxin Dong",
            "Ming-Hsuan Yang",
            "Jinshan Pan"
        ],
        "published": "2024-05-23T09:13:36Z"
    },
    {
        "title": "How do Observable Users Decompose D3 Code? An Exploratory Study",
        "link": "http://arxiv.org/abs/2405.14341v1",
        "abstract": "Users often struggle to program visualizations using complex toolkits like\nD3. Before we can design effective code assistants to support them, we must\nfirst understand how D3 users reason about their code. In this work, we explore\nusers' understanding of D3 using an important gauge of code comprehension in CS\neducation: code decomposition. We qualitatively analyze 560 D3 programs\npublished on Observable and identify three distinct strategies to decomposing\nD3 programs: segmenting code into layers of functionality, keeping everything\nall in one cell, or creating reusable visualization functions. We also observe\nhow users inherit decomposition methods from copied examples and reorganize\ncopied code to suit their needs. We corroborate our findings for decomposition\npreferences through interviews with D3 and Observable users. Based on our\nfindings, we suggest strategies for generating more intuitive D3 code\nrecommendations using decomposition preferences and highlight new research\nopportunities for visualization code assistants. All supplemental materials are\navailable at https://osf.io/sudb8/?view_only=302fc5c8d397412aac35c6e094ae7dd6.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Melissa Lin",
            "Heer Patel",
            "Medina Lamkin",
            "Tukey Tu",
            "Hannah Bako",
            "Soham Raut",
            "Leilani Battle"
        ],
        "published": "2024-05-23T09:11:47Z"
    },
    {
        "title": "RoGS: Large Scale Road Surface Reconstruction based on 2D Gaussian\n  Splatting",
        "link": "http://arxiv.org/abs/2405.14342v2",
        "abstract": "Road surface reconstruction plays a crucial role in autonomous driving, which\ncan be used for road lane perception and autolabeling tasks. Recently,\nmesh-based road surface reconstruction algorithms show promising reconstruction\nresults. However, these mesh-based methods suffer from slow speed and poor\nrendering quality. In contrast, the 3D Gaussian Splatting (3DGS) shows superior\nrendering speed and quality. Although 3DGS employs explicit Gaussian spheres to\nrepresent the scene, it lacks the ability to directly represent the geometric\ninformation of the scene. To address this limitation, we propose a novel\nlarge-scale road surface reconstruction approach based on 2D Gaussian Splatting\n(2DGS), named RoGS. The geometric shape of the road is explicitly represented\nusing 2D Gaussian surfels, where each surfel stores color, semantics, and\ngeometric information. Compared to Gaussian spheres, the Gaussian surfels\naligns more closely with the physical reality of the road. Distinct from\nprevious initialization methods that rely on point clouds for Gaussian spheres,\nwe introduce a trajectory-based initialization for Gaussian surfels. Thanks to\nthe explicit representation of the Gaussian surfels and a good initialization,\nour method achieves a significant acceleration while improving reconstruction\nquality. We achieve excellent results in reconstruction of roads surfaces in a\nvariety of challenging real-world scenes.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhiheng Feng",
            "Wenhua Wu",
            "Hesheng Wang"
        ],
        "published": "2024-05-23T09:11:47Z"
    },
    {
        "title": "Green Multi-Objective Scheduling -- A memetic NSGA-III for flexible\n  production with real-time energy cost and emissions",
        "link": "http://arxiv.org/abs/2405.14339v1",
        "abstract": "The use of renewable energies strengthens decarbonization strategies. To\nintegrate volatile renewable sources, energy systems require grid expansion,\nstorage capabilities, or flexible consumption. This study focuses on industries\nadjusting production to real-time energy markets, offering flexible consumption\nto the grid. Flexible production considers not only traditional goals like\nminimizing production time but also minimizing energy costs and emissions,\nthereby enhancing the sustainability of businesses. However, existing research\nfocuses on single goals, neglects the combination of makespan, energy costs and\nemissions, or assumes constant or periodic tariffs instead of a dynamic energy\nmarket. We present a novel memetic NSGA-III to minimize makespan, energy cost,\nand emissions, integrating real energy market data, and allowing manufacturers\nto adapt consumption to current grid conditions. Evaluating it with benchmark\ninstances from literature and real energy market data, we explore the\ntrade-offs between objectives, showcasing potential savings in energy costs and\nemissions on estimated Pareto fronts.",
        "subjects": [
            "cs.NE"
        ],
        "authors": [
            "Sascha C Burmeister"
        ],
        "published": "2024-05-23T09:11:21Z"
    },
    {
        "title": "MAMBA4D: Efficient Long-Sequence Point Cloud Video Understanding with\n  Disentangled Spatial-Temporal State Space Models",
        "link": "http://arxiv.org/abs/2405.14338v1",
        "abstract": "Point cloud videos effectively capture real-world spatial geometries and\ntemporal dynamics, which are essential for enabling intelligent agents to\nunderstand the dynamically changing 3D world we live in. Although static 3D\npoint cloud processing has witnessed significant advancements, designing an\neffective 4D point cloud video backbone remains challenging, mainly due to the\nirregular and unordered distribution of points and temporal inconsistencies\nacross frames. Moreover, recent state-of-the-art 4D backbones predominantly\nrely on transformer-based architectures, which commonly suffer from large\ncomputational costs due to their quadratic complexity, particularly when\nprocessing long video sequences. To address these challenges, we propose a\nnovel 4D point cloud video understanding backbone based on the recently\nadvanced State Space Models (SSMs). Specifically, our backbone begins by\ndisentangling space and time in raw 4D sequences, and then establishing\nspatio-temporal correlations using our newly developed Intra-frame Spatial\nMamba and Inter-frame Temporal Mamba blocks. The Intra-frame Spatial Mamba\nmodule is designed to encode locally similar or related geometric structures\nwithin a certain temporal searching stride, which can effectively capture\nshort-term dynamics. Subsequently, these locally correlated tokens are\ndelivered to the Inter-frame Temporal Mamba module, which globally integrates\npoint features across the entire video with linear complexity, further\nestablishing long-range motion dependencies. Experimental results on human\naction recognition and 4D semantic segmentation tasks demonstrate the\nsuperiority of our proposed method. Especially, for long video sequences, our\nproposed Mamba-based method has an 87.5% GPU memory reduction, 5.36 times\nspeed-up, and much higher accuracy (up to +10.4%) compared with\ntransformer-based counterparts on MSR-Action3D dataset.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jiuming Liu",
            "Jinru Han",
            "Lihao Liu",
            "Angelica I. Aviles-Rivero",
            "Chaokang Jiang",
            "Zhe Liu",
            "Hesheng Wang"
        ],
        "published": "2024-05-23T09:08:09Z"
    },
    {
        "title": "Logarithmic Smoothing for Pessimistic Off-Policy Evaluation, Selection\n  and Learning",
        "link": "http://arxiv.org/abs/2405.14335v1",
        "abstract": "This work investigates the offline formulation of the contextual bandit\nproblem, where the goal is to leverage past interactions collected under a\nbehavior policy to evaluate, select, and learn new, potentially\nbetter-performing, policies. Motivated by critical applications, we move beyond\npoint estimators. Instead, we adopt the principle of pessimism where we\nconstruct upper bounds that assess a policy's worst-case performance, enabling\nus to confidently select and learn improved policies. Precisely, we introduce\nnovel, fully empirical concentration bounds for a broad class of importance\nweighting risk estimators. These bounds are general enough to cover most\nexisting estimators and pave the way for the development of new ones. In\nparticular, our pursuit of the tightest bound within this class motivates a\nnovel estimator (LS), that logarithmically smooths large importance weights.\nThe bound for LS is provably tighter than all its competitors, and naturally\nresults in improved policy selection and learning strategies. Extensive policy\nevaluation, selection, and learning experiments highlight the versatility and\nfavorable performance of LS.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Otmane Sakhi",
            "Imad Aouali",
            "Pierre Alquier",
            "Nicolas Chopin"
        ],
        "published": "2024-05-23T09:07:27Z"
    },
    {
        "title": "Hierarchical Salient Patch Identification for Interpretable Fundus\n  Disease Localization",
        "link": "http://arxiv.org/abs/2405.14334v1",
        "abstract": "With the widespread application of deep learning technology in medical image\nanalysis, how to effectively explain model decisions and improve diagnosis\naccuracy has become an urgent problem that needs to be solved. Attribution\nmethods have become a key tool to help doctors better understand the diagnostic\nbasis of models, and they are used to explain and localize diseases in medical\nimages. However, previous methods suffer from inaccurate and incomplete\nlocalization problems for fundus diseases with complex and diverse structures.\nIn order to solve the above problems, we propose a weakly supervised\ninterpretable fundus disease localization method hierarchical salient patch\nidentification (HSPI), which can achieve interpretable disease localization\nusing only image-level labels and neural network classifiers. First, we\nproposed salient patch identification (SPI), which divides the image into\nseveral patches and optimizes consistency loss to identify which patch in the\ninput image is most important for decision-making to locate the disease.\nSecondly, we propose a hierarchical identification strategy to force SPI to\nanalyze the importance of different areas to neural network classifiers\ndecision-making to comprehensively locate disease areas. Then, we introduced\nconditional peak focusing to ensure that the mask vector can accurately locate\nthe decision area. Finally, we also propose patch selection based on multi-size\nintersection to filter out incorrectly or additionally identified non-disease\nregions. We conduct disease localization experiments on medical image datasets\nand achieve the best performance on multiple evaluation metrics compared with\nprevious interpretable attribution methods. We performed additional ablation\nstudies to verify the effectiveness of each method.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yitao Peng",
            "Lianghua He",
            "Die Hu"
        ],
        "published": "2024-05-23T09:07:21Z"
    },
    {
        "title": "DeepSeek-Prover: Advancing Theorem Proving in LLMs through Large-Scale\n  Synthetic Data",
        "link": "http://arxiv.org/abs/2405.14333v1",
        "abstract": "Proof assistants like Lean have revolutionized mathematical proof\nverification, ensuring high accuracy and reliability. Although large language\nmodels (LLMs) show promise in mathematical reasoning, their advancement in\nformal theorem proving is hindered by a lack of training data. To address this\nissue, we introduce an approach to generate extensive Lean 4 proof data derived\nfrom high-school and undergraduate-level mathematical competition problems.\nThis approach involves translating natural language problems into formal\nstatements, filtering out low-quality statements, and generating proofs to\ncreate synthetic data. After fine-tuning the DeepSeekMath 7B model on this\nsynthetic dataset, which comprises 8 million formal statements with proofs, our\nmodel achieved whole-proof generation accuracies of 46.3% with 64 samples and\n52% cumulatively on the Lean 4 miniF2F test, surpassing the baseline GPT-4 at\n23.0% with 64 samples and a tree search reinforcement learning method at 41.0%.\nAdditionally, our model successfully proved 5 out of 148 problems in the Lean 4\nFormalized International Mathematical Olympiad (FIMO) benchmark, while GPT-4\nfailed to prove any. These results demonstrate the potential of leveraging\nlarge-scale synthetic data to enhance theorem-proving capabilities in LLMs.\nBoth the synthetic dataset and the model will be made available to facilitate\nfurther research in this promising field.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Huajian Xin",
            "Daya Guo",
            "Zhihong Shao",
            "Zhizhou Ren",
            "Qihao Zhu",
            "Bo Liu",
            "Chong Ruan",
            "Wenda Li",
            "Xiaodan Liang"
        ],
        "published": "2024-05-23T09:03:42Z"
    },
    {
        "title": "LucidPPN: Unambiguous Prototypical Parts Network for User-centric\n  Interpretable Computer Vision",
        "link": "http://arxiv.org/abs/2405.14331v1",
        "abstract": "Prototypical parts networks combine the power of deep learning with the\nexplainability of case-based reasoning to make accurate, interpretable\ndecisions. They follow the this looks like that reasoning, representing each\nprototypical part with patches from training images. However, a single image\npatch comprises multiple visual features, such as color, shape, and texture,\nmaking it difficult for users to identify which feature is important to the\nmodel.\n  To reduce this ambiguity, we introduce the Lucid Prototypical Parts Network\n(LucidPPN), a novel prototypical parts network that separates color prototypes\nfrom other visual features. Our method employs two reasoning branches: one for\nnon-color visual features, processing grayscale images, and another focusing\nsolely on color information. This separation allows us to clarify whether the\nmodel's decisions are based on color, shape, or texture. Additionally, LucidPPN\nidentifies prototypical parts corresponding to semantic parts of classified\nobjects, making comparisons between data classes more intuitive, e.g., when two\nbird species might differ primarily in belly color.\n  Our experiments demonstrate that the two branches are complementary and\ntogether achieve results comparable to baseline methods. More importantly,\nLucidPPN generates less ambiguous prototypical parts, enhancing user\nunderstanding.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Mateusz Pach",
            "Dawid Rymarczyk",
            "Koryna Lewandowska",
            "Jacek Tabor",
            "Bartosz Zieliński"
        ],
        "published": "2024-05-23T09:00:59Z"
    },
    {
        "title": "Autoregressive Image Diffusion: Generation of Image Sequence and\n  Application in MRI",
        "link": "http://arxiv.org/abs/2405.14327v2",
        "abstract": "Magnetic resonance imaging (MRI) is a widely used non-invasive imaging\nmodality. However, a persistent challenge lies in balancing image quality with\nimaging speed. This trade-off is primarily constrained by k-space measurements,\nwhich traverse specific trajectories in the spatial Fourier domain (k-space).\nThese measurements are often undersampled to shorten acquisition times,\nresulting in image artifacts and compromised quality. Generative models learn\nimage distributions and can be used to reconstruct high-quality images from\nundersampled k-space data. In this work, we present the autoregressive image\ndiffusion (AID) model for image sequences and use it to sample the posterior\nfor accelerated MRI reconstruction. The algorithm incorporates both\nundersampled k-space and pre-existing information. Models trained with fastMRI\ndataset are evaluated comprehensively. The results show that the AID model can\nrobustly generate sequentially coherent image sequences. In 3D and dynamic MRI,\nthe AID can outperform the standard diffusion model and reduce hallucinations,\ndue to the learned inter-image dependencies.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Guanxiong Luo",
            "Shoujin Huang",
            "Martin Uecker"
        ],
        "published": "2024-05-23T08:57:10Z"
    },
    {
        "title": "Dinomaly: The Less Is More Philosophy in Multi-Class Unsupervised\n  Anomaly Detection",
        "link": "http://arxiv.org/abs/2405.14325v1",
        "abstract": "Recent studies highlighted a practical setting of unsupervised anomaly\ndetection (UAD) that builds a unified model for multi-class images, serving as\nan alternative to the conventional one-class-one-model setup. Despite various\nadvancements addressing this challenging task, the detection performance under\nthe multi-class setting still lags far behind state-of-the-art class-separated\nmodels. Our research aims to bridge this substantial performance gap. In this\npaper, we introduce a minimalistic reconstruction-based anomaly detection\nframework, namely Dinomaly, which leverages pure Transformer architectures\nwithout relying on complex designs, additional modules, or specialized tricks.\nGiven this powerful framework consisted of only Attentions and MLPs, we found\nfour simple components that are essential to multi-class anomaly detection: (1)\nFoundation Transformers that extracts universal and discriminative features,\n(2) Noisy Bottleneck where pre-existing Dropouts do all the noise injection\ntricks, (3) Linear Attention that naturally cannot focus, and (4) Loose\nReconstruction that does not force layer-to-layer and point-by-point\nreconstruction. Extensive experiments are conducted across three popular\nanomaly detection benchmarks including MVTec-AD, VisA, and the recently\nreleased Real-IAD. Our proposed Dinomaly achieves impressive image AUROC of\n99.6%, 98.7%, and 89.3% on the three datasets respectively, which is not only\nsuperior to state-of-the-art multi-class UAD methods, but also surpasses the\nmost advanced class-separated UAD records.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jia Guo",
            "Shuai Lu",
            "Weihang Zhang",
            "Huiqi Li"
        ],
        "published": "2024-05-23T08:55:20Z"
    },
    {
        "title": "SmartCS: Enabling the Creation of ML-Powered Computer Vision Mobile Apps\n  for Citizen Science Applications without Coding",
        "link": "http://arxiv.org/abs/2405.14323v1",
        "abstract": "It is undeniable that citizen science contributes to the advancement of\nvarious fields of study. There are now software tools that facilitate the\ndevelopment of citizen science apps. However, apps developed with these tools\nrely on individual human skills to correctly collect useful data. Machine\nlearning (ML)-aided apps provide on-field guidance to citizen scientists on\ndata collection tasks. However, these apps rely on server-side ML support, and\ntherefore need a reliable internet connection. Furthermore, the development of\ncitizen science apps with ML support requires a significant investment of time\nand money. For some projects, this barrier may preclude the use of citizen\nscience effectively. We present a platform that democratizes citizen science by\nmaking it accessible to a much broader audience of both researchers and\nparticipants. The SmartCS platform allows one to create citizen science apps\nwith ML support quickly and without coding skills. Apps developed using SmartCS\nhave client-side ML support, making them usable in the field, even when there\nis no internet connection. The client-side ML helps educate users to better\nrecognize the subjects, thereby enabling high-quality data collection. We\npresent several citizen science apps created using SmartCS, some of which were\nconceived and created by high school students.",
        "subjects": [
            "cs.CY"
        ],
        "authors": [
            "Fahim Hasan Khan",
            "Akila de Silva",
            "Gregory Dusek",
            "James Davis",
            "Alex Pang"
        ],
        "published": "2024-05-23T08:54:50Z"
    },
    {
        "title": "An 808 Line Phasor-Based Dehomogenisation Matlab Code For Multi-Scale\n  Topology Optimisation",
        "link": "http://arxiv.org/abs/2405.14321v2",
        "abstract": "This work presents an 808-line Matlab educational code for combined\nmulti-scale topology optimisation and phasor-based dehomogenisation titled\ndeHomTop808. The multi-scale formulation utilises homogenisation of optimal\nmicrostructures to facilitate efficient coarse-scale optimisation.\nDehomogenisation allows for a high-resolution single-scale reconstruction of\nthe optimised multi-scale structure, achieving minor losses in structural\nperformance, at a fraction of the computational cost, compared to its\nlarge-scale topology optimisation counterpart. The presented code utilises\nstiffness optimal Rank-2 microstructures to minimise the compliance of a\nsingle-load case problem, subject to a volume fraction constraint. By\nexploiting the inherent efficiency benefits of the phasor-based\ndehomogenisation procedure, on-the-fly dehomogenisation to a single-scale\nstructure is obtained. The presented code includes procedures for structural\nverification of the final dehomogenised structure by comparison to the\nmulti-scale solution. The code is introduced in terms of the underlying theory\nand its major components, including examples and potential extensions, and can\nbe downloaded from https://github.com/peterdorffler/deHomTop808.git.",
        "subjects": [
            "cs.MS",
            "cs.NA",
            "math.NA",
            "math.OC"
        ],
        "authors": [
            "Rebekka Varum Woldseth",
            "Ole Sigmund",
            "Peter Dørffler Ladegaard Jensen"
        ],
        "published": "2024-05-23T08:53:24Z"
    },
    {
        "title": "Adaptive Rentention & Correction for Continual Learning",
        "link": "http://arxiv.org/abs/2405.14318v1",
        "abstract": "Continual learning, also known as lifelong learning or incremental learning,\nrefers to the process by which a model learns from a stream of incoming data\nover time. A common problem in continual learning is the classification layer's\nbias towards the most recent task. Traditionally, methods have relied on\nincorporating data from past tasks during training to mitigate this issue.\nHowever, the recent shift in continual learning to memory-free environments has\nrendered these approaches infeasible. In this study, we propose a solution\nfocused on the testing phase. We first introduce a simple Out-of-Task Detection\nmethod, OTD, designed to accurately identify samples from past tasks during\ntesting. Leveraging OTD, we then propose: (1) an Adaptive Retention mechanism\nfor dynamically tuning the classifier layer on past task data; (2) an Adaptive\nCorrection mechanism for revising predictions when the model classifies data\nfrom previous tasks into classes from the current task. We name our approach\nAdaptive Retention & Correction (ARC). While designed for memory-free\nenvironments, ARC also proves effective in memory-based settings. Extensive\nexperiments show that our proposed method can be plugged in to virtually any\nexisting continual learning approach without requiring any modifications to its\ntraining procedure. Specifically, when integrated with state-of-the-art\napproaches, ARC achieves an average performance increase of 2.7% and 2.6% on\nthe CIFAR-100 and Imagenet-R datasets, respectively.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Haoran Chen",
            "Micah Goldblum",
            "Zuxuan Wu",
            "Yu-Gang Jiang"
        ],
        "published": "2024-05-23T08:43:09Z"
    },
    {
        "title": "Estimating the Expected Social Welfare and Cost of Random Serial\n  Dictatorship",
        "link": "http://arxiv.org/abs/2405.14316v1",
        "abstract": "We consider the assignment problem, where $n$ agents have to be matched to\n$n$ items. Each agent has a preference order over the items. In the serial\ndictatorship (SD) mechanism the agents act in a particular order and pick their\nmost preferred available item when it is their turn to act. Applying SD using a\nuniformly random permutation as agent ordering results in the well-known random\nserial dictatorship (RSD) mechanism. Accurate estimates of the (expected)\nefficiency of its outcome can be used to assess whether RSD is attractive\ncompared to other mechanisms. In this paper, we explore whether such estimates\nare possible by sampling a (hopefully) small number of agent orderings and\napplying SD using them. We consider a value setting in which agents have values\nfor the items as well as a metric cost setting where agents and items are\nassumed to be points in a metric space, and the cost of an agent for an item is\nequal to the distance of the corresponding points. We show that a (relatively)\nsmall number of samples is enough to approximate the expected social welfare of\nRSD in the value setting and its expected social cost in the metric cost\nsetting despite the #P-hardness of the corresponding exact computation\nproblems.",
        "subjects": [
            "cs.GT"
        ],
        "authors": [
            "Ioannis Caragiannis",
            "Sebastian Homrighausen"
        ],
        "published": "2024-05-23T08:41:39Z"
    },
    {
        "title": "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration",
        "link": "http://arxiv.org/abs/2405.14314v1",
        "abstract": "Grounding the reasoning ability of large language models (LLMs) for embodied\ntasks is challenging due to the complexity of the physical world. Especially,\nLLM planning for multi-agent collaboration requires communication of agents or\ncredit assignment as the feedback to re-adjust the proposed plans and achieve\neffective coordination. However, existing methods that overly rely on physical\nverification or self-reflection suffer from excessive and inefficient querying\nof LLMs. In this paper, we propose a novel framework for multi-agent\ncollaboration that introduces Reinforced Advantage feedback (ReAd) for\nefficient self-refinement of plans. Specifically, we perform critic regression\nto learn a sequential advantage function from LLM-planned data, and then treat\nthe LLM planner as an optimizer to generate actions that maximize the advantage\nfunction. It endows the LLM with the foresight to discern whether the action\ncontributes to accomplishing the final task. We provide theoretical analysis by\nextending advantage-weighted regression in reinforcement learning to\nmulti-agent systems. Experiments on Overcooked-AI and a difficult variant of\nRoCoBench show that ReAd surpasses baselines in success rate, and also\nsignificantly decreases the interaction steps of agents and query rounds of\nLLMs, demonstrating its high efficiency for grounding LLMs. More results are\ngiven at \\url{https://read-llm.github.io/}.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.MA",
            "cs.RO"
        ],
        "authors": [
            "Yang Zhang",
            "Shixin Yang",
            "Chenjia Bai",
            "Fei Wu",
            "Xiu Li",
            "Xuelong Li",
            "Zhen Wang"
        ],
        "published": "2024-05-23T08:33:19Z"
    },
    {
        "title": "Smooth Pseudo-Labeling",
        "link": "http://arxiv.org/abs/2405.14313v1",
        "abstract": "Semi-Supervised Learning (SSL) seeks to leverage large amounts of\nnon-annotated data along with the smallest amount possible of annotated data in\norder to achieve the same level of performance as if all data were annotated. A\nfruitful method in SSL is Pseudo-Labeling (PL), which, however, suffers from\nthe important drawback that the associated loss function has discontinuities in\nits derivatives, which cause instabilities in performance when labels are very\nscarce. In the present work, we address this drawback with the introduction of\na Smooth Pseudo-Labeling (SP L) loss function. It consists in adding a\nmultiplicative factor in the loss function that smooths out the discontinuities\nin the derivative due to thresholding. In our experiments, we test our\nimprovements on FixMatch and show that it significantly improves the\nperformance in the regime of scarce labels, without addition of any modules,\nhyperparameters, or computational overhead. In the more stable regime of\nabundant labels, performance remains at the same level. Robustness with respect\nto variation of hyperparameters and training parameters is also significantly\nimproved. Moreover, we introduce a new benchmark, where labeled images are\nselected randomly from the whole dataset, without imposing representation of\neach class proportional to its frequency in the dataset. We see that the smooth\nversion of FixMatch does appear to perform better than the original, non-smooth\nimplementation. However, more importantly, we notice that both implementations\ndo not necessarily see their performance improve when labeled images are added,\nan important issue in the design of SSL algorithms that should be addressed so\nthat Active Learning algorithms become more reliable and explainable.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Nikolaos Karaliolios",
            "Hervé Le Borgne",
            "Florian Chabot"
        ],
        "published": "2024-05-23T08:33:07Z"
    },
    {
        "title": "Improving Gloss-free Sign Language Translation by Reducing\n  Representation Density",
        "link": "http://arxiv.org/abs/2405.14312v1",
        "abstract": "Gloss-free sign language translation (SLT) aims to develop well-performing\nSLT systems with no requirement for the costly gloss annotations, but currently\nstill lags behind gloss-based approaches significantly. In this paper, we\nidentify a representation density problem that could be a bottleneck in\nrestricting the performance of gloss-free SLT. Specifically, the representation\ndensity problem describes that the visual representations of semantically\ndistinct sign gestures tend to be closely packed together in feature space,\nwhich makes gloss-free methods struggle with distinguishing different sign\ngestures and suffer from a sharp performance drop. To address the\nrepresentation density problem, we introduce a simple but effective contrastive\nlearning strategy, namely SignCL, which encourages gloss-free models to learn\nmore discriminative feature representation in a self-supervised manner. Our\nexperiments demonstrate that the proposed SignCL can significantly reduce the\nrepresentation density and improve performance across various translation\nframeworks. Specifically, SignCL achieves a significant improvement in BLEU\nscore for the Sign Language Transformer and GFSLT-VLP on the CSL-Daily dataset\nby 39% and 46%, respectively, without any increase of model parameters.\nCompared to Sign2GPT, a state-of-the-art method based on large-scale\npre-trained vision and language models, SignCL achieves better performance with\nonly 35% of its parameters. Implementation and Checkpoints are available at\nhttps://github.com/JinhuiYE/SignCL.",
        "subjects": [
            "cs.CV",
            "cs.CL",
            "cs.MM"
        ],
        "authors": [
            "Jinhui Ye",
            "Xing Wang",
            "Wenxiang Jiao",
            "Junwei Liang",
            "Hui Xiong"
        ],
        "published": "2024-05-23T08:32:58Z"
    },
    {
        "title": "Deep Learning Fusion For Effective Malware Detection: Leveraging Visual\n  Features",
        "link": "http://arxiv.org/abs/2405.14311v1",
        "abstract": "Malware has become a formidable threat as it has been growing exponentially\nin number and sophistication, thus, it is imperative to have a solution that is\neasy to implement, reliable, and effective. While recent research has\nintroduced deep learning multi-feature fusion algorithms, they lack a proper\nexplanation. In this work, we investigate the power of fusing Convolutional\nNeural Network models trained on different modalities of a malware executable.\nWe are proposing a novel multimodal fusion algorithm, leveraging three\ndifferent visual malware features: Grayscale Image, Entropy Graph, and SimHash\nImage, with which we conducted exhaustive experiments independently on each\nfeature and combinations of all three of them using fusion operators such as\naverage, maximum, add, and concatenate for effective malware detection and\nclassification. The proposed strategy has a detection rate of 1.00 (on a scale\nof 0-1) in identifying malware in the given dataset. We explained its\ninterpretability with visualization techniques such as t-SNE and Grad-CAM.\nExperimental results show the model works even for a highly imbalanced dataset.\nWe also assessed the effectiveness of the proposed method on obfuscated malware\nand achieved state-of-the-art results. The proposed methodology is more\nreliable as our findings prove VGG16 model can detect and classify malware in a\nmatter of seconds in real-time.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Jahez Abraham Johny",
            "Vinod P.",
            "Asmitha K. A.",
            "G. Radhamani",
            "Rafidha Rehiman K. A.",
            "Mauro Conti"
        ],
        "published": "2024-05-23T08:32:40Z"
    },
    {
        "title": "AdaGMLP: AdaBoosting GNN-to-MLP Knowledge Distillation",
        "link": "http://arxiv.org/abs/2405.14307v1",
        "abstract": "Graph Neural Networks (GNNs) have revolutionized graph-based machine\nlearning, but their heavy computational demands pose challenges for\nlatency-sensitive edge devices in practical industrial applications. In\nresponse, a new wave of methods, collectively known as GNN-to-MLP Knowledge\nDistillation, has emerged. They aim to transfer GNN-learned knowledge to a more\nefficient MLP student, which offers faster, resource-efficient inference while\nmaintaining competitive performance compared to GNNs. However, these methods\nface significant challenges in situations with insufficient training data and\nincomplete test data, limiting their applicability in real-world applications.\nTo address these challenges, we propose AdaGMLP, an AdaBoosting GNN-to-MLP\nKnowledge Distillation framework. It leverages an ensemble of diverse MLP\nstudents trained on different subsets of labeled nodes, addressing the issue of\ninsufficient training data. Additionally, it incorporates a Node Alignment\ntechnique for robust predictions on test data with missing or incomplete\nfeatures. Our experiments on seven benchmark datasets with different settings\ndemonstrate that AdaGMLP outperforms existing G2M methods, making it suitable\nfor a wide range of latency-sensitive real-world applications. We have\nsubmitted our code to the GitHub repository\n(https://github.com/WeigangLu/AdaGMLP-KDD24).",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Weigang Lu",
            "Ziyu Guan",
            "Wei Zhao",
            "Yaming Yang"
        ],
        "published": "2024-05-23T08:28:44Z"
    },
    {
        "title": "Exposure Diffusion: HDR Image Generation by Consistent LDR denoising",
        "link": "http://arxiv.org/abs/2405.14304v1",
        "abstract": "We demonstrate generating high-dynamic range (HDR) images using the concerted\naction of multiple black-box, pre-trained low-dynamic range (LDR) image\ndiffusion models. Common diffusion models are not HDR as, first, there is no\nsufficiently large HDR image dataset available to re-train them, and second,\neven if it was, re-training such models is impossible for most compute budgets.\nInstead, we seek inspiration from the HDR image capture literature that\ntraditionally fuses sets of LDR images, called \"brackets\", to produce a single\nHDR image. We operate multiple denoising processes to generate multiple LDR\nbrackets that together form a valid HDR result. To this end, we introduce an\nexposure consistency term into the diffusion process to couple the brackets\nsuch that they agree across the exposure range they share. We demonstrate HDR\nversions of state-of-the-art unconditional and conditional as well as\nrestoration-type (LDR2HDR) generative modeling.",
        "subjects": [
            "cs.GR",
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Mojtaba Bemana",
            "Thomas Leimkühler",
            "Karol Myszkowski",
            "Hans-Peter Seidel",
            "Tobias Ritschel"
        ],
        "published": "2024-05-23T08:24:22Z"
    },
    {
        "title": "Similarity-Navigated Conformal Prediction for Graph Neural Networks",
        "link": "http://arxiv.org/abs/2405.14303v1",
        "abstract": "Graph Neural Networks have achieved remarkable accuracy in semi-supervised\nnode classification tasks. However, these results lack reliable uncertainty\nestimates. Conformal prediction methods provide a theoretical guarantee for\nnode classification tasks, ensuring that the conformal prediction set contains\nthe ground-truth label with a desired probability (e.g., 95%). In this paper,\nwe empirically show that for each node, aggregating the non-conformity scores\nof nodes with the same label can improve the efficiency of conformal prediction\nsets. This observation motivates us to propose a novel algorithm named\nSimilarity-Navigated Adaptive Prediction Sets (SNAPS), which aggregates the\nnon-conformity scores based on feature similarity and structural neighborhood.\nThe key idea behind SNAPS is that nodes with high feature similarity or direct\nconnections tend to have the same label. By incorporating adaptive similar\nnodes information, SNAPS can generate compact prediction sets and increase the\nsingleton hit ratio (correct prediction sets of size one). Moreover, we\ntheoretically provide a finite-sample coverage guarantee of SNAPS. Extensive\nexperiments demonstrate the superiority of SNAPS, improving the efficiency of\nprediction sets and singleton hit ratio while maintaining valid coverage.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Jianqing Song",
            "Jianguo Huang",
            "Wenyu Jiang",
            "Baoming Zhang",
            "Shuangjie Li",
            "Chongjun Wang"
        ],
        "published": "2024-05-23T08:23:22Z"
    },
    {
        "title": "Graphcode: Learning from multiparameter persistent homology using graph\n  neural networks",
        "link": "http://arxiv.org/abs/2405.14302v1",
        "abstract": "We introduce graphcodes, a novel multi-scale summary of the topological\nproperties of a dataset that is based on the well-established theory of\npersistent homology. Graphcodes handle datasets that are filtered along two\nreal-valued scale parameters. Such multi-parameter topological summaries are\nusually based on complicated theoretical foundations and difficult to compute;\nin contrast, graphcodes yield an informative and interpretable summary and can\nbe computed as efficient as one-parameter summaries. Moreover, a graphcode is\nsimply an embedded graph and can therefore be readily integrated in machine\nlearning pipelines using graph neural networks. We describe such a pipeline and\ndemonstrate that graphcodes achieve better classification accuracy than\nstate-of-the-art approaches on various datasets.",
        "subjects": [
            "math.AT",
            "cs.LG"
        ],
        "authors": [
            "Michael Kerber",
            "Florian Russold"
        ],
        "published": "2024-05-23T08:22:00Z"
    },
    {
        "title": "Does context matter in digital pathology?",
        "link": "http://arxiv.org/abs/2405.14301v1",
        "abstract": "The development of Artificial Intelligence for healthcare is of great\nimportance. Models can sometimes achieve even superior performance to human\nexperts, however, they can reason based on spurious features. This is not\nacceptable to the experts as it is expected that the models catch the valid\npatterns in the data following domain expertise. In the work, we analyse\nwhether Deep Learning (DL) models for vision follow the histopathologists'\npractice so that when diagnosing a part of a lesion, they take into account\nalso the surrounding tissues which serve as context. It turns out that the\nperformance of DL models significantly decreases when the amount of contextual\ninformation is limited, therefore contextual information is valuable at\nprediction time. Moreover, we show that the models sometimes behave in an\nunstable way as for some images, they change the predictions many times\ndepending on the size of the context. It may suggest that partial contextual\ninformation can be misleading.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Paulina Tomaszewska",
            "Mateusz Sperkowski",
            "Przemysław Biecek"
        ],
        "published": "2024-05-23T08:21:11Z"
    },
    {
        "title": "Automatic diagnosis of cardiac magnetic resonance images based on\n  semi-supervised learning",
        "link": "http://arxiv.org/abs/2405.14300v1",
        "abstract": "Cardiac magnetic resonance imaging (MRI) is a pivotal tool for assessing\ncardiac function. Precise segmentation of cardiac structures is imperative for\naccurate cardiac functional evaluation. This paper introduces a semi-supervised\nmodel for automatic segmentation of cardiac images and auxiliary diagnosis. By\nharnessing cardiac MRI images and necessitating only a small portion of\nannotated image data, the model achieves fully automated, high-precision\nsegmentation of cardiac images, extraction of features, calculation of clinical\nindices, and prediction of diseases. The provided segmentation results,\nclinical indices, and prediction outcomes can aid physicians in diagnosis,\nthereby serving as auxiliary diagnostic tools. Experimental results showcase\nthat this semi-supervised model for automatic segmentation of cardiac images\nand auxiliary diagnosis attains high accuracy in segmentation and correctness\nin prediction, demonstrating substantial practical guidance and application\nvalue.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Hejun Huang",
            "Zuguo Chen",
            "Yi Huang",
            "Guangqiang Luo",
            "Chaoyang Chen",
            "Youzhi Song"
        ],
        "published": "2024-05-23T08:21:03Z"
    },
    {
        "title": "Dynamic Mixture of Experts: An Auto-Tuning Approach for Efficient\n  Transformer Models",
        "link": "http://arxiv.org/abs/2405.14297v1",
        "abstract": "The Sparse Mixture of Experts (SMoE) has been widely employed to enhance the\nefficiency of training and inference for Transformer-based foundational models,\nyielding promising results. However, the performance of SMoE heavily depends on\nthe choice of hyper-parameters, such as the number of experts and the number of\nexperts to be activated (referred to as top-k), resulting in significant\ncomputational overhead due to the extensive model training by searching over\nvarious hyper-parameter configurations. As a remedy, we introduce the Dynamic\nMixture of Experts (DynMoE) technique. DynMoE incorporates (1) a novel gating\nmethod that enables each token to automatically determine the number of experts\nto activate. (2) An adaptive process automatically adjusts the number of\nexperts during training. Extensive numerical results across Vision, Language,\nand Vision-Language tasks demonstrate the effectiveness of our approach to\nachieve competitive performance compared to GMoE for vision and language tasks,\nand MoE-LLaVA for vision-language tasks, while maintaining efficiency by\nactivating fewer parameters. Our code is available at\nhttps://github.com/LINs-lab/DynMoE.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Yongxin Guo",
            "Zhenglin Cheng",
            "Xiaoying Tang",
            "Tao Lin"
        ],
        "published": "2024-05-23T08:18:30Z"
    },
    {
        "title": "Focus Anywhere for Fine-grained Multi-page Document Understanding",
        "link": "http://arxiv.org/abs/2405.14295v1",
        "abstract": "Modern LVLMs still struggle to achieve fine-grained document understanding,\nsuch as OCR/translation/caption for regions of interest to the user, tasks that\nrequire the context of the entire page, or even multiple pages. Accordingly,\nthis paper proposes Fox, an effective pipeline, hybrid data, and tuning\nstrategy, that catalyzes LVLMs to focus anywhere on single/multi-page\ndocuments. We introduce a novel task to boost the document understanding by\nmaking LVLMs focus attention on the document-level region, such as redefining\nfull-page OCR as foreground focus. We employ multiple vision vocabularies to\nextract visual hybrid knowledge for interleaved document pages (e.g., a page\ncontaining a photo). Meanwhile, we render cross-vocabulary vision data as the\ncatalyzer to achieve a full reaction of multiple visual vocabularies and\nin-document figure understanding. Further, without modifying the weights of\nmultiple vision vocabularies, the above catalyzed fine-grained understanding\ncapabilities can be efficiently tuned to multi-page documents, enabling the\nmodel to focus anywhere in both format-free and page-free manners. Besides, we\nbuild a benchmark including 9 fine-grained sub-tasks (e.g., region-level\nOCR/summary, color-guided OCR) to promote document analysis in the community.\nThe experimental results verify the superiority of our model.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Chenglong Liu",
            "Haoran Wei",
            "Jinyue Chen",
            "Lingyu Kong",
            "Zheng Ge",
            "Zining Zhu",
            "Liang Zhao",
            "Jianjian Sun",
            "Chunrui Han",
            "Xiangyu Zhang"
        ],
        "published": "2024-05-23T08:15:49Z"
    },
    {
        "title": "Tuning-free Universally-Supervised Semantic Segmentation",
        "link": "http://arxiv.org/abs/2405.14294v1",
        "abstract": "This work presents a tuning-free semantic segmentation framework based on\nclassifying SAM masks by CLIP, which is universally applicable to various types\nof supervision. Initially, we utilize CLIP's zero-shot classification ability\nto generate pseudo-labels or perform open-vocabulary segmentation. However, the\nmisalignment between mask and CLIP text embeddings leads to suboptimal results.\nTo address this issue, we propose discrimination-bias aligned CLIP to closely\nalign mask and text embedding, offering an overhead-free performance gain. We\nthen construct a global-local consistent classifier to classify SAM masks,\nwhich reveals the intrinsic structure of high-quality embeddings produced by\nDBA-CLIP and demonstrates robustness against noisy pseudo-labels. Extensive\nexperiments validate the efficiency and effectiveness of our method, and we\nachieve state-of-the-art (SOTA) or competitive performance across various\ndatasets and supervision types.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xiaobo Yang",
            "Xiaojin Gong"
        ],
        "published": "2024-05-23T08:13:52Z"
    },
    {
        "title": "Sybil-Proof Mechanism for Information Propagation with Budgets",
        "link": "http://arxiv.org/abs/2405.14293v1",
        "abstract": "This paper examines the problem of distributing rewards on social networks to\nimprove the efficiency of crowdsourcing tasks for sponsors. To complete the\ntasks efficiently, we aim to design reward mechanisms that incentivize\nearly-joining agents to invite more participants to the tasks. Nonetheless,\nparticipants could potentially engage in strategic behaviors, e.g., not\ninviting others to the tasks, misreporting their capacity for the tasks, or\ncreaking fake identities (aka Sybil attacks), to maximize their own rewards.\nThe focus of this study is to address the challenge outlined above by designing\neffective reward mechanisms. To this end, we propose a novel reward mechanism,\ncalled Propagation Reward Distribution Mechanism (PRDM), for the general\ninformation propagation model with limited budgets. It is proved that the PRDM\ncan not only incentivize all agents to contribute their full efforts to the\ntasks and share the task information to all their neighbors in the social\nnetworks, but can also prevent them from Sybil attacks.",
        "subjects": [
            "cs.GT"
        ],
        "authors": [
            "Junjie Zheng",
            "Xu Ge",
            "Bin Li",
            "Dengji Zhao"
        ],
        "published": "2024-05-23T08:12:47Z"
    },
    {
        "title": "A New Method in Facial Registration in Clinics Based on Structure Light\n  Images",
        "link": "http://arxiv.org/abs/2405.14292v1",
        "abstract": "Background and Objective: In neurosurgery, fusing clinical images and depth\nimages that can improve the information and details is beneficial to surgery.\nWe found that the registration of face depth images was invalid frequently\nusing existing methods. To abundant traditional image methods with depth\ninformation, a method in registering with depth images and traditional clinical\nimages was investigated. Methods: We used the dlib library, a C++ library that\ncould be used in face recognition, and recognized the key points on faces from\nthe structure light camera and CT image. The two key point clouds were\nregistered for coarse registration by the ICP method. Fine registration was\nfinished after coarse registration by the ICP method. Results: RMSE after\ncoarse and fine registration is as low as 0.995913 mm. Compared with\ntraditional methods, it also takes less time. Conclusions: The new method\nsuccessfully registered the facial depth image from structure light images and\nCT with a low error, and that would be promising and efficient in clinical\napplication of neurosurgery.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Pengfei Li",
            "Ziyue Ma",
            "Hong Wang",
            "Juan Deng",
            "Yan Wang",
            "Zhenyu Xu",
            "Feng Yan",
            "Wenjun Tu",
            "Hong Sha"
        ],
        "published": "2024-05-23T08:10:09Z"
    },
    {
        "title": "Variational Bayes for Federated Continual Learning",
        "link": "http://arxiv.org/abs/2405.14291v1",
        "abstract": "Federated continual learning (FCL) has received increasing attention due to\nits potential in handling real-world streaming data, characterized by evolving\ndata distributions and varying client classes over time. The constraints of\nstorage limitations and privacy concerns confine local models to exclusively\naccess the present data within each learning cycle. Consequently, this\nrestriction induces performance degradation in model training on previous data,\ntermed \"catastrophic forgetting\". However, existing FCL approaches need to\nidentify or know changes in data distribution, which is difficult in the real\nworld. To release these limitations, this paper directs attention to a broader\ncontinuous framework. Within this framework, we introduce Federated Bayesian\nNeural Network (FedBNN), a versatile and efficacious framework employing a\nvariational Bayesian neural network across all clients. Our method continually\nintegrates knowledge from local and historical data distributions into a single\nmodel, adeptly learning from new data distributions while retaining performance\non historical distributions. We rigorously evaluate FedBNN's performance\nagainst prevalent methods in federated learning and continual learning using\nvarious metrics. Experimental analyses across diverse datasets demonstrate that\nFedBNN achieves state-of-the-art results in mitigating forgetting.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC"
        ],
        "authors": [
            "Dezhong Yao",
            "Sanmu Li",
            "Yutong Dai",
            "Zhiqiang Xu",
            "Shengshan Hu",
            "Peilin Zhao",
            "Lichao Sun"
        ],
        "published": "2024-05-23T08:09:21Z"
    },
    {
        "title": "Frequency-Domain Sound Field from the Perspective of Band-Limited\n  Functions",
        "link": "http://arxiv.org/abs/2405.14290v1",
        "abstract": "In this paper, the frequency-domain sound field is regarded as an element of\nsome band-limited function space, and a representation of the field as a linear\ncombination of the reproducing kernel in that space is proposed. This model has\nthe strongest representational capacity of all function systems when we know\nonly the sound pressure information at arbitrary positions. The proposed model\ncan be considered a generalization of the existing three-dimensional sound\nfield model using the reproducing kernel of the solution space of the Helmholtz\nequation to the spatial dimension. One of the advantages of capturing the\nfrequency-domain sound field in this way is the simplicity achieved for the\nestimation formula of the wavenumber spectrum. Two numerical simulations were\nconducted to validate the proposed methods.",
        "subjects": [
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Takahiro Iwami",
            "Akira Omoto"
        ],
        "published": "2024-05-23T08:07:41Z"
    },
    {
        "title": "Co-Representation Neural Hypergraph Diffusion for Edge-Dependent Node\n  Classification",
        "link": "http://arxiv.org/abs/2405.14286v1",
        "abstract": "Hypergraphs are widely employed to represent complex higher-order\nrelationships in real-world applications. Most hypergraph learning research\nfocuses on node- or edge-level tasks. A practically relevant but more\nchallenging task, edge-dependent node classification (ENC), is only recently\nproposed. In ENC, a node can have different labels across different hyperedges,\nwhich requires the modeling of node-hyperedge pairs instead of single nodes or\nhyperedges. Existing solutions for this task are based on message passing and\nmodel within-edge and within-node interactions as multi-input single-output\nfunctions. This brings three limitations: (1) non-adaptive representation size,\n(2) node/edge agnostic messages, and (3) insufficient interactions among nodes\nor hyperedges. To tackle these limitations, we develop CoNHD, a new solution\nbased on hypergraph diffusion. Specifically, we first extend hypergraph\ndiffusion using node-hyperedge co-representations. This extension explicitly\nmodels both within-edge and within-node interactions as multi-input\nmulti-output functions using two equivariant diffusion operators. To avoid\nhandcrafted regularization functions, we propose a neural implementation for\nthe co-representation hypergraph diffusion process. Extensive experiments\ndemonstrate the effectiveness and efficiency of the proposed CoNHD model.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Yijia Zheng",
            "Marcel Worring"
        ],
        "published": "2024-05-23T08:01:25Z"
    },
    {
        "title": "Computing the Bias of Constant-step Stochastic Approximation with\n  Markovian Noise",
        "link": "http://arxiv.org/abs/2405.14285v1",
        "abstract": "We study stochastic approximation algorithms with Markovian noise and\nconstant step-size $\\alpha$. We develop a method based on infinitesimal\ngenerator comparisons to study the bias of the algorithm, which is the expected\ndifference between $\\theta_n$ -- the value at iteration $n$ -- and $\\theta^*$\n-- the unique equilibrium of the corresponding ODE. We show that, under some\nsmoothness conditions, this bias is of order $O(\\alpha)$. Furthermore, we show\nthat the time-averaged bias is equal to $\\alpha V + O(\\alpha^2)$, where $V$ is\na constant characterized by a Lyapunov equation, showing that\n$\\esp{\\bar{\\theta}_n} \\approx \\theta^*+V\\alpha + O(\\alpha^2)$, where\n$\\bar{\\theta}_n=(1/n)\\sum_{k=1}^n\\theta_k$ is the Polyak-Ruppert average. We\nalso show that $\\bar{\\theta}_n$ converges with high probability around\n$\\theta^*+\\alpha V$. We illustrate how to combine this with Richardson-Romberg\nextrapolation to derive an iterative scheme with a bias of order $O(\\alpha^2)$.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Sebastian Allmeier",
            "Nicolas Gast"
        ],
        "published": "2024-05-23T08:00:45Z"
    },
    {
        "title": "Transient Nonlinear Electrothermal Adjoint Sensitivity Analysis for HVDC\n  Cable Joints",
        "link": "http://arxiv.org/abs/2405.14284v1",
        "abstract": "Efficient computation of sensitivities is a promising approach for\nefficiently of designing and optimizing high voltage direct current cable\njoints. This paper presents the adjoint variable method for coupled nonlinear\ntransient electrothermal problems as an efficient approach to compute\nsensitivities with respect to a large number of design parameters. The method\nis used to compute material sensitivities of a 320kV high voltage direct\ncurrent cable joint specimen. The results are validated against sensitivities\nobtained via the direct sensitivity method.",
        "subjects": [
            "cs.CE"
        ],
        "authors": [
            "M. Greta Ruppert",
            "Yvonne Späck-Leigsnering",
            "Herbert De Gersem"
        ],
        "published": "2024-05-23T08:00:07Z"
    },
    {
        "title": "ASI++: Towards Distributionally Balanced End-to-End Generative Retrieval",
        "link": "http://arxiv.org/abs/2405.14280v1",
        "abstract": "Generative retrieval, a promising new paradigm in information retrieval,\nemploys a seq2seq model to encode document features into parameters and decode\nrelevant document identifiers (IDs) based on search queries. Existing\ngenerative retrieval solutions typically rely on a preprocessing stage to\npre-define document IDs, which can suffer from a semantic gap between these IDs\nand the retrieval task. However, end-to-end training for both ID assignments\nand retrieval tasks is challenging due to the long-tailed distribution\ncharacteristics of real-world data, resulting in inefficient and unbalanced ID\nspace utilization. To address these issues, we propose ASI++, a novel fully\nend-to-end generative retrieval method that aims to simultaneously learn\nbalanced ID assignments and improve retrieval performance. ASI++ builds on the\nfully end-to-end training framework of vanilla ASI and introduces several key\ninnovations. First, a distributionally balanced criterion addresses the\nimbalance in ID assignments, promoting more efficient utilization of the ID\nspace. Next, a representation bottleneck criterion enhances dense\nrepresentations to alleviate bottlenecks in learning ID assignments. Finally,\nan information consistency criterion integrates these processes into a joint\noptimization framework grounded in information theory. We further explore\nvarious module structures for learning ID assignments, including neural\nquantization, differentiable product quantization, and residual quantization.\nExtensive experiments on both public and industrial datasets demonstrate the\neffectiveness of ASI++ in improving retrieval performance and achieving\nbalanced ID assignments.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Yuxuan Liu",
            "Tianchi Yang",
            "Zihan Zhang",
            "Minghui Song",
            "Haizhen Huang",
            "Weiwei Deng",
            "Feng Sun",
            "Qi Zhang"
        ],
        "published": "2024-05-23T07:54:57Z"
    },
    {
        "title": "Optimized Cost Per Click in Online Advertising: A Theoretical Analysis",
        "link": "http://arxiv.org/abs/2405.14279v1",
        "abstract": "In recent years, Optimized Cost Per Click (OCPC) and Optimized Cost Per Mille\n(OCPM) have emerged as the most widely adopted pricing models in the online\nadvertising industry. However, the existing literature has yet to identify the\nspecific conditions under which these models outperform traditional pricing\nmodels like Cost Per Click (CPC) and Cost Per Action (CPA). To fill the gap,\nthis paper builds an economic model that compares OCPC with CPC and CPA\ntheoretically, which incorporates out-site scenarios and outside options as two\nkey factors. Our analysis reveals that OCPC can effectively replace CPA by\ntackling the problem of advertisers strategically manipulating conversion\nreporting in out-site scenarios where conversions occur outside the advertising\nplatform. Furthermore, OCPC exhibits the potential to surpass CPC in platform\npayoffs by providing higher advertiser payoffs and consequently attracting more\nadvertisers. However, if advertisers have less competitive outside options and\nconsistently stay in the focal platform, the platform may achieve higher\npayoffs using CPC. Our findings deliver valuable insights for online\nadvertising platforms in selecting optimal pricing models, and provide\nrecommendations for further enhancing their payoffs. To the best of our\nknowledge, this is the first study to analyze OCPC from an economic\nperspective. Moreover, our analysis can be applied to the OCPM model as well.",
        "subjects": [
            "cs.GT",
            "econ.TH"
        ],
        "authors": [
            "Kaichen Zhang",
            "Zixuan Yuan",
            "Hui Xiong"
        ],
        "published": "2024-05-23T07:54:14Z"
    },
    {
        "title": "SCMix: Stochastic Compound Mixing for Open Compound Domain Adaptation in\n  Semantic Segmentation",
        "link": "http://arxiv.org/abs/2405.14278v1",
        "abstract": "Open compound domain adaptation (OCDA) aims to transfer knowledge from a\nlabeled source domain to a mix of unlabeled homogeneous compound target domains\nwhile generalizing to open unseen domains. Existing OCDA methods solve the\nintra-domain gaps by a divide-and-conquer strategy, which divides the problem\ninto several individual and parallel domain adaptation (DA) tasks. Such\napproaches often contain multiple sub-networks or stages, which may constrain\nthe model's performance. In this work, starting from the general DA theory, we\nestablish the generalization bound for the setting of OCDA. Built upon this, we\nargue that conventional OCDA approaches may substantially underestimate the\ninherent variance inside the compound target domains for model generalization.\nWe subsequently present Stochastic Compound Mixing (SCMix), an augmentation\nstrategy with the primary objective of mitigating the divergence between source\nand mixed target distributions. We provide theoretical analysis to substantiate\nthe superiority of SCMix and prove that the previous methods are sub-groups of\nour methods. Extensive experiments show that our method attains a lower\nempirical risk on OCDA semantic segmentation tasks, thus supporting our\ntheories. Combining the transformer architecture, SCMix achieves a notable\nperformance boost compared to the SoTA results.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Kai Yao",
            "Zhaorui Tan",
            "Zixian Su",
            "Xi Yang",
            "Jie Sun",
            "Kaizhu Huang"
        ],
        "published": "2024-05-23T07:53:10Z"
    },
    {
        "title": "Improving Language Models Trained with Translated Data via Continual\n  Pre-Training and Dictionary Learning Analysis",
        "link": "http://arxiv.org/abs/2405.14277v1",
        "abstract": "Training LLMs in low resources languages usually utilizes data augmentation\nwith machine translation (MT) from English language. However, translation\nbrings a number of challenges: there are large costs attached to translating\nand curating huge amounts of content with high-end machine translation\nsolutions, the translated content carries over cultural biases, and if the\ntranslation is not faithful and accurate, the quality of the data degrades\ncausing issues in the trained model. In this work we investigate the role of\ntranslation and synthetic data in training language models. We translate\nTinyStories, a dataset of 2.2M short stories for 3-4 year old children, from\nEnglish to Arabic using the free NLLB-3B MT model. We train a number of story\ngeneration models of sizes 1M-33M parameters using this data. We identify a\nnumber of quality and task-specific issues in the resulting models. To rectify\nthese issues, we further pre-train the models with a small dataset of\nsynthesized high-quality stories, representing 1\\% of the original training\ndata, using a capable LLM in Arabic. We show using GPT-4 as a judge and\ndictionary learning analysis from mechanistic interpretability that the\nsuggested approach is a practical means to resolve some of the translation\npitfalls. We illustrate the improvement through case studies of linguistic\nissues and cultural bias.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Sabri Boughorbel",
            "MD Rizwan Parvez",
            "Majd Hawasly"
        ],
        "published": "2024-05-23T07:53:04Z"
    },
    {
        "title": "D-MiSo: Editing Dynamic 3D Scenes using Multi-Gaussians Soup",
        "link": "http://arxiv.org/abs/2405.14276v2",
        "abstract": "Over the past years, we have observed an abundance of approaches for modeling\ndynamic 3D scenes using Gaussian Splatting (GS). Such solutions use GS to\nrepresent the scene's structure and the neural network to model dynamics. Such\napproaches allow fast rendering and extracting each element of such a dynamic\nscene. However, modifying such objects over time is challenging. SC-GS (Sparse\nControlled Gaussian Splatting) enhanced with Deformed Control Points partially\nsolves this issue. However, this approach necessitates selecting elements that\nneed to be kept fixed, as well as centroids that should be adjusted throughout\nediting. Moreover, this task poses additional difficulties regarding the\nre-productivity of such editing. To address this, we propose Dynamic\nMulti-Gaussian Soup (D-MiSo), which allows us to model the mesh-inspired\nrepresentation of dynamic GS. Additionally, we propose a strategy of linking\nparameterized Gaussian splats, forming a Triangle Soup with the estimated mesh.\nConsequently, we can separately construct new trajectories for the 3D objects\ncomposing the scene. Thus, we can make the scene's dynamic editable over time\nor while maintaining partial dynamics.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Joanna Waczyńska",
            "Piotr Borycki",
            "Joanna Kaleta",
            "Sławomir Tadeja",
            "Przemysław Spurek"
        ],
        "published": "2024-05-23T07:53:01Z"
    },
    {
        "title": "A Language-Theoretic Approach to the Heapability of Signed Permutations",
        "link": "http://arxiv.org/abs/2405.14275v1",
        "abstract": "We investigate a signed version of the Hammersley process, a discrete process\non words related to a property of integer sequences called heapability (Byers\net al., ANALCO 2011). The specific version that we investigate corresponds to a\nversion of this property for signed sequences.\n  We give a characterization of the words that can appear as images the signed\nHammersley process. In particular we show that the language of such words is\nthe intersection of two deterministic one-counter languages.",
        "subjects": [
            "math.CO",
            "cs.DM",
            "cs.FL"
        ],
        "authors": [
            "Gabriel Istrate"
        ],
        "published": "2024-05-23T07:52:54Z"
    },
    {
        "title": "A fast algorithm to minimize prediction loss of the optimal solution in\n  inverse optimization problem of MILP",
        "link": "http://arxiv.org/abs/2405.14273v1",
        "abstract": "This paper tackles the problem of minimizing the prediction loss of the\noptimal solution (PLS) of the MILP with given data, which is one of the inverse\noptimization problems. While existing methods can approximately solve this\nproblem, their implementation in the high-dimensional case to minimize the PLS\nis computationally expensive because they are inefficient in reducing the\nprediction loss of weights (PLW). We propose a fast algorithm for minimizing\nthe PLS of MILP. To demonstrate this property, we attribute the problem of\nminimizing the PLS to that of minimizing the suboptimality loss (SL), which is\nconvex. If the PLS does not vanish, we can adapt the SL to have the estimated\nloss (SPO loss) with a positive lower bound, which enables us to evaluate the\nPLW. Consequently, we prove that the proposed algorithm can effectively reduce\nthe PLW and achieve the minimum value of PLS. Our numerical experiments\ndemonstrated that our algorithm successfully achieved the minimum PLS. Compared\nto existing methods, our algorithm exhibited a smaller dimensionality effect\nand minimized the PLS in less than 1/7 the number of iterations. Especially in\nhigh dimensions, our algorithm significantly improved the PLS by more than two\norders of magnitude compared to existing algorithms.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.OC"
        ],
        "authors": [
            "Akira Kitaoka"
        ],
        "published": "2024-05-23T07:51:05Z"
    },
    {
        "title": "Nominal Tree Automata With Name Allocation",
        "link": "http://arxiv.org/abs/2405.14272v1",
        "abstract": "Data trees serve as an abstraction of structured data, such as XML documents.\nA number of specification formalisms for languages of data trees have been\ndeveloped, many of them adhering to the paradigm of register automata, which is\nbased on storing data values encountered on the tree in registers for\nsubsequent comparison with further data values. Already on word languages, the\nexpressiveness of such automata models typically increases with the power of\ncontrol (e.g. deterministic, non-deterministic, alternating). Language\ninclusion is typically undecidable for non-deterministic or alternating models\nunless the number of registers is radically restricted, and even then often\nremains non-elementary. We present an automaton model for data trees that\nretains a reasonable level of expressiveness, in particular allows\nnon-determinism and any number of registers, while admitting language inclusion\nchecking in elementary complexity, in fact in parametrized exponential time. We\nphrase the description of our automaton model in the language of nominal sets,\nbuilding on the recently introduced paradigm of explicit name allocation in\nnominal automata.",
        "subjects": [
            "cs.FL",
            "68Q45",
            "F.4.3"
        ],
        "authors": [
            "Simon Prucker",
            "Lutz Schröder"
        ],
        "published": "2024-05-23T07:50:46Z"
    },
    {
        "title": "Fine-grained Image-to-LiDAR Contrastive Distillation with Visual\n  Foundation Models",
        "link": "http://arxiv.org/abs/2405.14271v1",
        "abstract": "Contrastive image-to-LiDAR knowledge transfer, commonly used for learning 3D\nrepresentations with synchronized images and point clouds, often faces a\nself-conflict dilemma. This issue arises as contrastive losses unintentionally\ndissociate features of unmatched points and pixels that share semantic labels,\ncompromising the integrity of learned representations. To overcome this, we\nharness Visual Foundation Models (VFMs), which have revolutionized the\nacquisition of pixel-level semantics, to enhance 3D representation learning.\nSpecifically, we utilize off-the-shelf VFMs to generate semantic labels for\nweakly-supervised pixel-to-point contrastive distillation. Additionally, we\nemploy von Mises-Fisher distributions to structure the feature space, ensuring\nsemantic embeddings within the same class remain consistent across varying\ninputs. Furthermore, we adapt sampling probabilities of points to address\nimbalances in spatial distribution and category frequency, promoting\ncomprehensive and balanced learning. Extensive experiments demonstrate that our\napproach mitigates the challenges posed by traditional methods and consistently\nsurpasses existing image-to-LiDAR contrastive distillation methods in\ndownstream tasks. The source code is available at\n\\href{https://github.com/Eaphan/OLIVINE.}{\\color{black}https://github.com/Eaphan/OLIVINE}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yifan Zhang",
            "Junhui Hou"
        ],
        "published": "2024-05-23T07:48:19Z"
    },
    {
        "title": "Sparse $L^1$-Autoencoders for Scientific Data Compression",
        "link": "http://arxiv.org/abs/2405.14270v1",
        "abstract": "Scientific datasets present unique challenges for machine learning-driven\ncompression methods, including more stringent requirements on accuracy and\nmitigation of potential invalidating artifacts. Drawing on results from\ncompressed sensing and rate-distortion theory, we introduce effective data\ncompression methods by developing autoencoders using high dimensional latent\nspaces that are $L^1$-regularized to obtain sparse low dimensional\nrepresentations. We show how these information-rich latent spaces can be used\nto mitigate blurring and other artifacts to obtain highly effective data\ncompression methods for scientific data. We demonstrate our methods for short\nangle scattering (SAS) datasets showing they can achieve compression ratios\naround two orders of magnitude and in some cases better. Our compression\nmethods show promise for use in addressing current bottlenecks in transmission,\nstorage, and analysis in high-performance distributed computing environments.\nThis is central to processing the large volume of SAS data being generated at\nshared experimental facilities around the world to support scientific\ninvestigations. Our approaches provide general ways for obtaining specialized\ncompression methods for targeted scientific datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Matthias Chung",
            "Rick Archibald",
            "Paul Atzberger",
            "Jack Michael Solomon"
        ],
        "published": "2024-05-23T07:48:00Z"
    },
    {
        "title": "Multi-Representation Genetic Programming: A Case Study on Tree-based and\n  Linear Representations",
        "link": "http://arxiv.org/abs/2405.14268v1",
        "abstract": "Existing genetic programming (GP) methods are typically designed based on a\ncertain representation, such as tree-based or linear representations. These\nrepresentations show various pros and cons in different domains. However, due\nto the complicated relationships among representation and fitness landscapes of\nGP, it is hard to intuitively determine which GP representation is the most\nsuitable for solving a certain problem. Evolving programs (or models) with\nmultiple representations simultaneously can alternatively search on different\nfitness landscapes since representations are highly related to the search space\nthat essentially defines the fitness landscape. Fully using the latent\nsynergies among different GP individual representations might be helpful for GP\nto search for better solutions. However, existing GP literature rarely\ninvestigates the simultaneous effective use of evolving multiple\nrepresentations. To fill this gap, this paper proposes a multi-representation\nGP algorithm based on tree-based and linear representations, which are two\ncommonly used GP representations. In addition, we develop a new\ncross-representation crossover operator to harness the interplay between\ntree-based and linear representations. Empirical results show that navigating\nthe learned knowledge between basic tree-based and linear representations\nsuccessfully improves the effectiveness of GP with solely tree-based or linear\nrepresentation in solving symbolic regression and dynamic job shop scheduling\nproblems.",
        "subjects": [
            "cs.NE",
            "cs.AI"
        ],
        "authors": [
            "Zhixing Huang",
            "Yi Mei",
            "Fangfang Zhang",
            "Mengjie Zhang",
            "Wolfgang Banzhaf"
        ],
        "published": "2024-05-23T07:47:06Z"
    },
    {
        "title": "A Gap in Time: The Challenge of Processing Heterogeneous IoT Point Data\n  in Buildings",
        "link": "http://arxiv.org/abs/2405.14267v1",
        "abstract": "The growing need for sustainable energy solutions has driven the integration\nof digitalized buildings into the power grid, utilizing Internet-of-Things\ntechnology to optimize building performance and energy efficiency. However,\nincorporating IoT point data within deep-learning frameworks for energy\nmanagement presents a complex challenge, predominantly due to the inherent data\nheterogeneity. This paper comprehensively analyzes the multifaceted\nheterogeneity present in real-world building IoT data streams. We meticulously\ndissect the heterogeneity across multiple dimensions, encompassing ontology,\netiology, temporal irregularity, spatial diversity, and their combined effects\non the IoT point data distribution. In addition, experiments using\nstate-of-the-art forecasting models are conducted to evaluate their impacts on\nthe performance of deep-learning models for forecasting tasks. By charting the\ndiversity along these dimensions, we illustrate the challenges and delineate\npathways for future research to leverage this heterogeneity as a resource\nrather than a roadblock. This exploration sets the stage for advancing the\npredictive abilities of deep-learning algorithms and catalyzing the evolution\nof intelligent energy-efficient buildings.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Xiachong Lin",
            "Arian Prabowo",
            "Imran Razzak",
            "Hao Xue",
            "Matthew Amos",
            "Sam Behrens",
            "Stephen White",
            "Flora D. Salim"
        ],
        "published": "2024-05-23T07:45:48Z"
    },
    {
        "title": "Deep Reinforcement Learning for 5*5 Multiplayer Go",
        "link": "http://dx.doi.org/10.1007/978-3-031-30229-9_48",
        "abstract": "In recent years, much progress has been made in computer Go and most of the\nresults have been obtained thanks to search algorithms (Monte Carlo Tree\nSearch) and Deep Reinforcement Learning (DRL). In this paper, we propose to use\nand analyze the latest algorithms that use search and DRL (AlphaZero and\nDescent algorithms) to automatically learn to play an extended version of the\ngame of Go with more than two players. We show that using search and DRL we\nwere able to improve the level of play, even though there are more than two\nplayers.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Brahim Driss",
            "Jérôme Arjonilla",
            "Hui Wang",
            "Abdallah Saffidine",
            "Tristan Cazenave"
        ],
        "published": "2024-05-23T07:44:24Z"
    },
    {
        "title": "Reassessing Evaluation Functions in Algorithmic Recourse: An Empirical\n  Study from a Human-Centered Perspective",
        "link": "http://arxiv.org/abs/2405.14264v1",
        "abstract": "In this study, we critically examine the foundational premise of algorithmic\nrecourse - a process of generating counterfactual action plans (i.e.,\nrecourses) assisting individuals to reverse adverse decisions made by AI\nsystems. The assumption underlying algorithmic recourse is that individuals\naccept and act on recourses that minimize the gap between their current and\ndesired states. This assumption, however, remains empirically unverified. To\naddress this issue, we conducted a user study with 362 participants and\nassessed whether minimizing the distance function, a metric of the gap between\nthe current and desired states, indeed prompts them to accept and act upon\nsuggested recourses. Our findings reveal a nuanced landscape: participants'\nacceptance of recourses did not correlate with the recourse distance. Moreover,\nparticipants' willingness to act upon recourses peaked at the minimal recourse\ndistance but was otherwise constant. These findings cast doubt on the\nprevailing assumption of algorithmic recourse research and signal the need to\nrethink the evaluation functions to pave the way for human-centered recourse\ngeneration.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.HC"
        ],
        "authors": [
            "Tomu Tominaga",
            "Naomi Yamashita",
            "Takeshi Kurashima"
        ],
        "published": "2024-05-23T07:43:24Z"
    },
    {
        "title": "Graph Sparsification via Mixture of Graphs",
        "link": "http://arxiv.org/abs/2405.14260v1",
        "abstract": "Graph Neural Networks (GNNs) have demonstrated superior performance across\nvarious graph learning tasks but face significant computational challenges when\napplied to large-scale graphs. One effective approach to mitigate these\nchallenges is graph sparsification, which involves removing non-essential edges\nto reduce computational overhead. However, previous graph sparsification\nmethods often rely on a single global sparsity setting and uniform pruning\ncriteria, failing to provide customized sparsification schemes for each node's\ncomplex local context. In this paper, we introduce Mixture-of-Graphs (MoG),\nleveraging the concept of Mixture-of-Experts (MoE), to dynamically select\ntailored pruning solutions for each node. Specifically, MoG incorporates\nmultiple sparsifier experts, each characterized by unique sparsity levels and\npruning criteria, and selects the appropriate experts for each node.\nSubsequently, MoG performs a mixture of the sparse graphs produced by different\nexperts on the Grassmann manifold to derive an optimal sparse graph. One\nnotable property of MoG is its entirely local nature, as it depends on the\nspecific circumstances of each individual node. Extensive experiments on four\nlarge-scale OGB datasets and two superpixel datasets, equipped with five GNN\nbackbones, demonstrate that MoG (I) identifies subgraphs at higher sparsity\nlevels ($8.67\\%\\sim 50.85\\%$), with performance equal to or better than the\ndense graph, (II) achieves $1.47-2.62\\times$ speedup in GNN inference with\nnegligible performance drop, and (III) boosts ``top-student'' GNN performance\n($1.02\\%\\uparrow$ on RevGNN+\\textsc{ogbn-proteins} and $1.74\\%\\uparrow$ on\nDeeperGCN+\\textsc{ogbg-ppa}).",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Guibin Zhang",
            "Xiangguo Sun",
            "Yanwei Yue",
            "Kun Wang",
            "Tianlong Chen",
            "Shirui Pan"
        ],
        "published": "2024-05-23T07:40:21Z"
    },
    {
        "title": "Let's Fuse Step by Step: A Generative Fusion Decoding Algorithm with\n  LLMs for Multi-modal Text Recognition",
        "link": "http://arxiv.org/abs/2405.14259v1",
        "abstract": "We introduce ``Generative Fusion Decoding'' (GFD), a novel shallow fusion\nframework, utilized to integrate Large Language Models (LLMs) into multi-modal\ntext recognition systems such as automatic speech recognition (ASR) and optical\ncharacter recognition (OCR). We derive the formulas necessary to enable GFD to\noperate across mismatched token spaces of different models by mapping text\ntoken space to byte token space, enabling seamless fusion during the decoding\nprocess. The framework is plug-and-play, compatible with various\nauto-regressive models, and does not require re-training for feature alignment,\nthus overcoming limitations of previous fusion techniques. We highlight three\nmain advantages of GFD: First, by simplifying the complexity of aligning\ndifferent model sample spaces, GFD allows LLMs to correct errors in tandem with\nthe recognition model, reducing computation latencies. Second, the in-context\nlearning ability of LLMs is fully capitalized by GFD, increasing robustness in\nlong-form speech recognition and instruction aware speech recognition. Third,\nGFD enables fusing recognition models deficient in Chinese text recognition\nwith LLMs extensively trained on Chinese. Our evaluation demonstrates that GFD\nsignificantly improves performance in ASR and OCR tasks, with ASR reaching\nstate-of-the-art in the NTUML2021 benchmark. GFD provides a significant step\nforward in model integration, offering a unified solution that could be widely\napplicable to leveraging existing pre-trained models through step by step\nfusion.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Chan-Jan Hsu",
            "Yi-Chang Chen",
            "Feng-Ting Liao",
            "Pei-Chen Ho",
            "Yu-Hsiang Wang",
            "Po-Chun Hsu",
            "Da-shan Shiu"
        ],
        "published": "2024-05-23T07:39:42Z"
    },
    {
        "title": "Deep Learning Methods for Adjusting Global MFD Speed Estimations to\n  Local Link Configurations",
        "link": "http://arxiv.org/abs/2405.14257v1",
        "abstract": "In large-scale traffic optimization, models based on Macroscopic Fundamental\nDiagram (MFD) are recognized for their efficiency in broad analyses. However,\nthey fail to reflect variations in the individual traffic status of each road\nlink, leading to a gap in detailed traffic optimization and analysis. To\naddress the limitation, this study introduces a Local Correction Factor (LCF)\nthat a function integrates MFD-derived network mean speed with network\nconfigurations to accurately estimate the individual speed of the link. We use\na novel deep learning framework combining Graph Attention Networks (GATs) with\nGated Recurrent Units (GRUs) to capture both spatial configurations and\ntemporal dynamics of the network. Coupled with a strategic network partitioning\nmethod, our model enhances the precision of link-level traffic speed\nestimations while preserving the computational benefits of aggregate models. In\nthe experiment, we evaluate the proposed LCF through various urban traffic\nscenarios, including different demand levels, origin-destination distributions,\nand road configurations. The results show the robust adaptability and\neffectiveness of the proposed model. Furthermore, we validate the practicality\nof our model by calculating the travel time of each randomly generated path,\nwith the average error relative to MFD-based results being reduced to\napproximately 76%.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Zhixiong Jin",
            "Dimitrios Tsitsokas",
            "Nikolas Geroliminis",
            "Ludovic Leclercq"
        ],
        "published": "2024-05-23T07:37:33Z"
    },
    {
        "title": "ZipCache: Accurate and Efficient KV Cache Quantization with Salient\n  Token Identification",
        "link": "http://arxiv.org/abs/2405.14256v1",
        "abstract": "KV cache stores key and value states from previous tokens to avoid\nre-computation, yet it demands substantial storage space, especially for long\nsequences. Adaptive KV cache compression seeks to discern the saliency of\ntokens, preserving vital information while aggressively compressing those of\nless importance. However, previous methods of this approach exhibit significant\nperformance degradation at high compression ratios due to inaccuracies in\nidentifying salient tokens. In this paper, we present ZipCache, an accurate and\nefficient KV cache quantization method for LLMs. First, we construct a strong\nbaseline for quantizing KV cache. Through the proposed channel-separable\ntokenwise quantization scheme, the memory overhead of quantization parameters\nare substantially reduced compared to fine-grained groupwise quantization. To\nenhance the compression ratio, we propose normalized attention score as an\neffective metric for identifying salient tokens by considering the lower\ntriangle characteristics of the attention matrix. Moreover, we develop an\nefficient approximation method that decouples the saliency metric from full\nattention scores, enabling compatibility with fast attention implementations\nlike FlashAttention. Extensive experiments demonstrate that ZipCache achieves\nsuperior compression ratios, fast generation speed and minimal performance\nlosses compared with previous KV cache compression methods. For instance, when\nevaluating Mistral-7B model on GSM8k dataset, ZipCache is capable of\ncompressing the KV cache by $4.98\\times$, with only a $0.38\\%$ drop in\naccuracy. In terms of efficiency, ZipCache also showcases a $37.3\\%$ reduction\nin prefill-phase latency, a $56.9\\%$ reduction in decoding-phase latency, and a\n$19.8\\%$ reduction in GPU memory usage when evaluating LLaMA3-8B model with a\ninput length of $4096$.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Yefei He",
            "Luoming Zhang",
            "Weijia Wu",
            "Jing Liu",
            "Hong Zhou",
            "Bohan Zhuang"
        ],
        "published": "2024-05-23T07:37:16Z"
    },
    {
        "title": "Path-Reporting Distance Oracles with Linear Size",
        "link": "http://arxiv.org/abs/2405.14254v1",
        "abstract": "Given an undirected weighted graph, an (approximate) distance oracle is a\ndata structure that can (approximately) answer distance queries. A {\\em\nPath-Reporting Distance Oracle}, or {\\em PRDO}, is a distance oracle that must\nalso return a path between the queried vertices. Given a graph on $n$ vertices\nand an integer parameter $k\\ge 1$, Thorup and Zwick \\cite{TZ01} showed a PRDO\nwith stretch $2k-1$, size $O(k\\cdot n^{1+1/k})$ and query time $O(k)$ (for the\nquery time of PRDOs, we omit the time needed to report the path itself).\nSubsequent works \\cite{MN06,C14,C15} improved the size to $O(n^{1+1/k})$ and\nthe query time to $O(1)$. However, these improvements produce distance oracles\nwhich are not path-reporting. Several other works \\cite{ENW16,EP15} focused on\nsmall size PRDO for general graphs, but all known results on distance oracles\nwith linear size suffer from polynomial stretch, polynomial query time, or not\nbeing path-reporting.\n  In this paper we devise the first linear size PRDO with poly-logarithmic\nstretch and low query time $O(\\log\\log n)$. More generally, for any integer\n$k\\ge 1$, we obtain a PRDO with stretch at most $O(k^{4.82})$, size\n$O(n^{1+1/k})$, and query time $O(\\log k)$. In addition, we can make the size\nof our PRDO as small as $n+o(n)$, at the cost of increasing the query time to\npoly-logarithmic. For unweighted graphs, we improve the stretch to $O(k^2)$.\n  We also consider {\\em pairwise PRDO}, which is a PRDO that is only required\nto answer queries from a given set of pairs ${\\cal P}$. An exact PRDO of size\n$O(n+|{\\cal P}|^2)$ and constant query time was provided in \\cite{EP15}. In\nthis work we dramatically improve the size, at the cost of slightly increasing\nthe stretch. Specifically, given any $\\epsilon>0$, we devise a pairwise PRDO\nwith stretch $1+\\epsilon$, constant query time, and near optimal size\n$n^{o(1)}\\cdot (n+|{\\cal P}|)$.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Ofer Neiman",
            "Idan Shabat"
        ],
        "published": "2024-05-23T07:31:25Z"
    },
    {
        "title": "Higher-Rank Irreducible Cartesian Tensors for Equivariant Message\n  Passing",
        "link": "http://arxiv.org/abs/2405.14253v1",
        "abstract": "The ability to perform fast and accurate atomistic simulations is crucial for\nadvancing the chemical sciences. By learning from high-quality data,\nmachine-learned interatomic potentials achieve accuracy on par with ab initio\nand first-principles methods at a fraction of their computational cost. The\nsuccess of machine-learned interatomic potentials arises from integrating\ninductive biases such as equivariance to group actions on an atomic system,\ne.g., equivariance to rotations and reflections. In particular, the field has\nnotably advanced with the emergence of equivariant message-passing\narchitectures. Most of these models represent an atomic system using spherical\ntensors, tensor products of which require complicated numerical coefficients\nand can be computationally demanding. This work introduces higher-rank\nirreducible Cartesian tensors as an alternative to spherical tensors,\naddressing the above limitations. We integrate irreducible Cartesian tensor\nproducts into message-passing neural networks and prove the equivariance of the\nresulting layers. Through empirical evaluations on various benchmark data sets,\nwe consistently observe on-par or better performance than that of\nstate-of-the-art spherical models.",
        "subjects": [
            "cs.LG",
            "physics.comp-ph"
        ],
        "authors": [
            "Viktor Zaverkin",
            "Francesco Alesiani",
            "Takashi Maruyama",
            "Federico Errica",
            "Henrik Christiansen",
            "Makoto Takamoto",
            "Nicolas Weber",
            "Mathias Niepert"
        ],
        "published": "2024-05-23T07:31:20Z"
    },
    {
        "title": "Time-FFM: Towards LM-Empowered Federated Foundation Model for Time\n  Series Forecasting",
        "link": "http://arxiv.org/abs/2405.14252v1",
        "abstract": "Unlike natural language processing and computer vision, the development of\nFoundation Models (FMs) for time series forecasting is blocked due to data\nscarcity. While recent efforts are focused on building such FMs by unlocking\nthe potential of language models (LMs) for time series analysis, dedicated\nparameters for various downstream forecasting tasks need training, which\nhinders the common knowledge sharing across domains. Moreover, data owners may\nhesitate to share the access to local data due to privacy concerns and\ncopyright protection, which makes it impossible to simply construct a FM on\ncross-domain training instances. To address these issues, we propose Time-FFM,\na Federated Foundation Model for Time series forecasting by leveraging\npretrained LMs. Specifically, we begin by transforming time series into the\nmodality of text tokens. To bootstrap LMs for time series reasoning, we propose\na prompt adaption module to determine domain-customized prompts dynamically\ninstead of artificially. Given the data heterogeneity across domains, we design\na personalized federated training strategy by learning global encoders and\nlocal prediction heads. Our comprehensive experiments indicate that Time-FFM\noutperforms state-of-the-arts and promises effective few-shot and zero-shot\nforecaster.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Qingxiang Liu",
            "Xu Liu",
            "Chenghao Liu",
            "Qingsong Wen",
            "Yuxuan Liang"
        ],
        "published": "2024-05-23T07:31:10Z"
    },
    {
        "title": "Efficient Navigation of a Robotic Fish Swimming Across the Vortical Flow\n  Field",
        "link": "http://arxiv.org/abs/2405.14251v1",
        "abstract": "Navigating efficiently across vortical flow fields presents a significant\nchallenge in various robotic applications. The dynamic and unsteady nature of\nvortical flows often disturbs the control of underwater robots, complicating\ntheir operation in hydrodynamic environments. Conventional control methods,\nwhich depend on accurate modeling, fail in these settings due to the complexity\nof fluid-structure interactions (FSI) caused by unsteady hydrodynamics. This\nstudy proposes a deep reinforcement learning (DRL) algorithm, trained in a\ndata-driven manner, to enable efficient navigation of a robotic fish swimming\nacross vortical flows. Our proposed algorithm incorporates the LSTM\narchitecture and uses several recent consecutive observations as the state to\naddress the issue of partial observation, often due to sensor limitations. We\npresent a numerical study of navigation within a Karman vortex street, created\nby placing a stationary cylinder in a uniform flow, utilizing the immersed\nboundary-lattice Boltzmann method (IB-LBM). The aim is to train the robotic\nfish to discover efficient navigation policies, enabling it to reach a\ndesignated target point across the Karman vortex street from various initial\npositions. After training, the fish demonstrates the ability to rapidly reach\nthe target from different initial positions, showcasing the effectiveness and\nrobustness of our proposed algorithm. Analysis of the results reveals that the\nrobotic fish can leverage velocity gains and pressure differences induced by\nthe vortices to reach the target, underscoring the potential of our proposed\nalgorithm in enhancing navigation in complex hydrodynamic environments.",
        "subjects": [
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Haodong Feng",
            "Dehan Yuan",
            "Jiale Miao",
            "Jie You",
            "Yue Wang",
            "Yi Zhu",
            "Dixia Fan"
        ],
        "published": "2024-05-23T07:30:58Z"
    },
    {
        "title": "Diffusion models for Gaussian distributions: Exact solutions and\n  Wasserstein errors",
        "link": "http://arxiv.org/abs/2405.14250v1",
        "abstract": "Diffusion or score-based models recently showed high performance in image\ngeneration. They rely on a forward and a backward stochastic differential\nequations (SDE). The sampling of a data distribution is achieved by solving\nnumerically the backward SDE or its associated flow ODE. Studying the\nconvergence of these models necessitates to control four different types of\nerror: the initialization error, the truncation error, the discretization and\nthe score approximation. In this paper, we study theoretically the behavior of\ndiffusion models and their numerical implementation when the data distribution\nis Gaussian. In this restricted framework where the score function is a linear\noperator, we can derive the analytical solutions of the forward and backward\nSDEs as well as the associated flow ODE. This provides exact expressions for\nvarious Wasserstein errors which enable us to compare the influence of each\nerror type for any sampling scheme, thus allowing to monitor convergence\ndirectly in the data space instead of relying on Inception features. Our\nexperiments show that the recommended numerical schemes from the diffusion\nmodels literature are also the best sampling schemes for Gaussian\ndistributions.",
        "subjects": [
            "cs.LG",
            "eess.IV",
            "math.PR"
        ],
        "authors": [
            "Emile Pierret",
            "Bruno Galerne"
        ],
        "published": "2024-05-23T07:28:56Z"
    },
    {
        "title": "Identifying Breakdowns in Conversational Recommender Systems using User\n  Simulation",
        "link": "http://dx.doi.org/10.1145/3640794.3665539",
        "abstract": "We present a methodology to systematically test conversational recommender\nsystems with regards to conversational breakdowns. It involves examining\nconversations generated between the system and simulated users for a set of\npre-defined breakdown types, extracting responsible conversational paths, and\ncharacterizing them in terms of the underlying dialogue intents. User\nsimulation offers the advantages of simplicity, cost-effectiveness, and time\nefficiency for obtaining conversations where potential breakdowns can be\nidentified. The proposed methodology can be used as diagnostic tool as well as\na development tool to improve conversational recommendation systems. We apply\nour methodology in a case study with an existing conversational recommender\nsystem and user simulator, demonstrating that with just a few iterations, we\ncan make the system more robust to conversational breakdowns.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Nolwenn Bernard",
            "Krisztian Balog"
        ],
        "published": "2024-05-23T07:28:26Z"
    },
    {
        "title": "Text-Based Correlation Matrix in Multi-Asset Allocation",
        "link": "http://arxiv.org/abs/2405.14247v1",
        "abstract": "The purpose of this study is to estimate the correlation structure between\nmultiple assets using financial text analysis. In recent years, as the\nbackground of elevating inflation in the global economy and monetary policy\ntightening by central banks, the correlation structure between assets,\nespecially interest rate sensitivity and inflation sensitivity, has changed\ndramatically, increasing the impact on the performance of investors'\nportfolios. Therefore, the importance of estimating a robust correlation\nstructure in portfolio management has increased. On the other hand, the\ncorrelation coefficient using only the historical price data observed in the\nfinancial market is accompanied by a certain degree of time lag, and also has\nthe aspect that prediction errors can occur due to the nonstationarity of\nfinancial time series data, and that the interpretability from the viewpoint of\nfundamentals is a little poor when a phase change occurs. In this study, we\nperformed natural language processing on news text and central bank text to\nverify the prediction accuracy of future correlation coefficient changes. As a\nresult, it was suggested that this method is useful in comparison with the\nprediction from ordinary time series data.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yasuhiro Nakayama",
            "Tomochika Sawaki",
            "Issei Furuya",
            "Shunsuke Tamura"
        ],
        "published": "2024-05-23T07:25:51Z"
    },
    {
        "title": "GCondenser: Benchmarking Graph Condensation",
        "link": "http://arxiv.org/abs/2405.14246v1",
        "abstract": "Large-scale graphs are valuable for graph representation learning, yet the\nabundant data in these graphs hinders the efficiency of the training process.\nGraph condensation (GC) alleviates this issue by compressing the large graph\ninto a significantly smaller one that still supports effective model training.\nAlthough recent research has introduced various approaches to improve the\neffectiveness of the condensed graph, comprehensive and practical evaluations\nacross different GC methods are neglected. This paper proposes the first\nlarge-scale graph condensation benchmark, GCondenser, to holistically evaluate\nand compare mainstream GC methods. GCondenser includes a standardised GC\nparadigm, consisting of condensation, validation, and evaluation procedures, as\nwell as enabling extensions to new GC methods and datasets. With GCondenser, a\ncomprehensive performance study is conducted, presenting the effectiveness of\nexisting methods. GCondenser is open-sourced and available at\nhttps://github.com/superallen13/GCondenser.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yilun Liu",
            "Ruihong Qiu",
            "Zi Huang"
        ],
        "published": "2024-05-23T07:25:31Z"
    },
    {
        "title": "Tell my why: Training preferences-based RL with human preferences and\n  step-level explanations",
        "link": "http://arxiv.org/abs/2405.14244v1",
        "abstract": "Human-in-the-loop reinforcement learning (HRL) allows the training of agents\nthrough various interfaces, even for non-expert humans. Recently,\npreference-based methods (PBRL), where the human has to give his preference\nover two trajectories, increased in popularity since they allow training in\ndomains where more direct feedback is hard to formulate. However, the current\nPBRL methods have limitations and do not provide humans with an expressive\ninterface for giving feedback. With this work, we propose a new\npreference-based learning method that provides humans with a more expressive\ninterface to provide their preference over trajectories and a factual\nexplanation (or annotation of why they have this preference). These\nexplanations allow the human to explain what parts of the trajectory are most\nrelevant for the preference. We allow the expression of the explanations over\nindividual trajectory steps. We evaluate our method in various simulations\nusing a simulated human oracle (with realistic restrictions), and our results\nshow that our extended feedback can improve the speed of learning. Code & data:\ngithub.com/under-rewiev",
        "subjects": [
            "cs.AI",
            "cs.HC",
            "cs.LG"
        ],
        "authors": [
            "Jakob Karalus"
        ],
        "published": "2024-05-23T07:23:33Z"
    },
    {
        "title": "M2ANET: Mobile Malaria Attention Network for efficient classification of\n  plasmodium parasites in blood cells",
        "link": "http://arxiv.org/abs/2405.14242v1",
        "abstract": "Malaria is a life-threatening infectious disease caused by Plasmodium\nparasites, which poses a significant public health challenge worldwide,\nparticularly in tropical and subtropical regions. Timely and accurate detection\nof malaria parasites in blood cells is crucial for effective treatment and\ncontrol of the disease. In recent years, deep learning techniques have\ndemonstrated remarkable success in medical image analysis tasks, offering\npromising avenues for improving diagnostic accuracy, with limited studies on\nhybrid mobile models due to the complexity of combining two distinct models and\nthe significant memory demand of self-attention mechanism especially for edge\ndevices. In this study, we explore the potential of designing a hybrid mobile\nmodel for efficient classification of plasmodium parasites in blood cell\nimages. Therefore, we present M2ANET (Mobile Malaria Attention Network). The\nmodel integrates MBConv3 (MobileNetV3 blocks) for efficient capturing of local\nfeature extractions within blood cell images and a modified global-MHSA\n(multi-head self-attention) mechanism in the latter stages of the network for\ncapturing global context. Through extensive experimentation on benchmark, we\ndemonstrate that M2ANET outperforms some state-of-the-art lightweight and\nmobile networks in terms of both accuracy and efficiency. Moreover, we discuss\nthe potential implications of M2ANET in advancing malaria diagnosis and\ntreatment, highlighting its suitability for deployment in resource-constrained\nhealthcare settings. The development of M2ANET represents a significant\nadvancement in the pursuit of efficient and accurate malaria detection, with\nbroader implications for medical image analysis and global healthcare\ninitiatives.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Salam Ahmed Ali",
            "Peshraw Salam Abdulqadir",
            "Shan Ali Abdullah",
            "Haruna Yunusa"
        ],
        "published": "2024-05-23T07:22:33Z"
    },
    {
        "title": "NeuroGauss4D-PCI: 4D Neural Fields and Gaussian Deformation Fields for\n  Point Cloud Interpolation",
        "link": "http://arxiv.org/abs/2405.14241v1",
        "abstract": "Point Cloud Interpolation confronts challenges from point sparsity, complex\nspatiotemporal dynamics, and the difficulty of deriving complete 3D point\nclouds from sparse temporal information. This paper presents NeuroGauss4D-PCI,\nwhich excels at modeling complex non-rigid deformations across varied dynamic\nscenes. The method begins with an iterative Gaussian cloud soft clustering\nmodule, offering structured temporal point cloud representations. The proposed\ntemporal radial basis function Gaussian residual utilizes Gaussian parameter\ninterpolation over time, enabling smooth parameter transitions and capturing\ntemporal residuals of Gaussian distributions. Additionally, a 4D Gaussian\ndeformation field tracks the evolution of these parameters, creating continuous\nspatiotemporal deformation fields. A 4D neural field transforms low-dimensional\nspatiotemporal coordinates ($x,y,z,t$) into a high-dimensional latent space.\nFinally, we adaptively and efficiently fuse the latent features from neural\nfields and the geometric features from Gaussian deformation fields.\nNeuroGauss4D-PCI outperforms existing methods in point cloud frame\ninterpolation, delivering leading performance on both object-level (DHB) and\nlarge-scale autonomous driving datasets (NL-Drive), with scalability to\nauto-labeling and point cloud densification tasks. The source code is released\nat https://github.com/jiangchaokang/NeuroGauss4D-PCI.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Chaokang Jiang",
            "Dalong Du",
            "Jiuming Liu",
            "Siting Zhu",
            "Zhenqiang Liu",
            "Zhuang Ma",
            "Zhujin Liang",
            "Jie Zhou"
        ],
        "published": "2024-05-23T07:21:01Z"
    },
    {
        "title": "Harmony: A Joint Self-Supervised and Weakly-Supervised Framework for\n  Learning General Purpose Visual Representations",
        "link": "http://arxiv.org/abs/2405.14239v1",
        "abstract": "Vision-language contrastive learning frameworks like CLIP enable learning\nrepresentations from natural language supervision, and provide strong zero-shot\nclassification capabilities. However, due to the nature of the supervisory\nsignal in these paradigms, they lack the ability to learn localized features,\nleading to degraded performance on dense prediction tasks like segmentation and\ndetection. On the other hand, self-supervised learning methods have shown the\nability to learn granular representations, complementing the high-level\nfeatures in vision-language training. In this work, we present Harmony, a\nframework that combines vision-language training with discriminative and\ngenerative self-supervision to learn visual features that can be generalized\nacross vision downstream tasks. Our framework is specifically designed to work\non web-scraped data by not relying on negative examples and addressing the\none-to-one correspondence issue using soft CLIP targets generated by an EMA\nmodel. We comprehensively evaluate Harmony across various vision downstream\ntasks and find that it significantly outperforms the baseline CLIP and the\npreviously leading joint self and weakly-supervised methods, MaskCLIP and SLIP.\nSpecifically, when comparing against these methods, Harmony shows superior\nperformance in fine-tuning and zero-shot classification on ImageNet-1k,\nsemantic segmentation on ADE20K, and both object detection and instance\nsegmentation on MS-COCO, when pre-training a ViT-S/16 on CC3M. We also show\nthat Harmony outperforms other self-supervised learning methods like iBOT and\nMAE across all tasks evaluated. On https://github.com/MohammedSB/Harmony our\ncode is publicly available.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "68T07, 68T45",
            "I.2.10"
        ],
        "authors": [
            "Mohammed Baharoon",
            "Jonathan Klein",
            "Dominik L. Michels"
        ],
        "published": "2024-05-23T07:18:08Z"
    },
    {
        "title": "Language processing in humans and computers",
        "link": "http://arxiv.org/abs/2405.14233v1",
        "abstract": "Machine-learned language models have transformed everyday life: they steer us\nwhen we study, drive, manage money. They have the potential to transform our\ncivilization. But they hallucinate. Their realities are virtual. This note\nprovides a high-level overview of language models and outlines a low-level\nmodel of learning machines. It turns out that, after they become capable of\nrecognizing hallucinations and dreaming safely, as humans tend to be, the\nlanguage-learning machines proceed to generate broader systems of false beliefs\nand self-confirming theories, as humans tend to do.",
        "subjects": [
            "cs.CL",
            "cs.LG",
            "cs.LO",
            "68T07, 68T50",
            "I.2.7; I.2.6; H.3.1; H.3.3"
        ],
        "authors": [
            "Dusko Pavlovic"
        ],
        "published": "2024-05-23T07:08:57Z"
    },
    {
        "title": "FloodDamageCast: Building Flood Damage Nowcasting with Machine Learning\n  and Data Augmentation",
        "link": "http://arxiv.org/abs/2405.14232v2",
        "abstract": "Near-real time estimation of damage to buildings and infrastructure, referred\nto as damage nowcasting in this study, is crucial for empowering emergency\nresponders to make informed decisions regarding evacuation orders and\ninfrastructure repair priorities during disaster response and recovery. Here,\nwe introduce FloodDamageCast, a machine learning framework tailored for\nproperty flood damage nowcasting. The framework leverages heterogeneous data to\npredict residential flood damage at a resolution of 500 meters by 500 meters\nwithin Harris County, Texas, during the 2017 Hurricane Harvey. To deal with\ndata imbalance, FloodDamageCast incorporates a generative adversarial\nnetworks-based data augmentation coupled with an efficient machine learning\nmodel. The results demonstrate the model's ability to identify high-damage\nspatial areas that would be overlooked by baseline models. Insights gleaned\nfrom flood damage nowcasting can assist emergency responders to more\nefficiently identify repair needs, allocate resources, and streamline\non-the-ground inspections, thereby saving both time and effort.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Chia-Fu Liu",
            "Lipai Huang",
            "Kai Yin",
            "Sam Brody",
            "Ali Mostafavi"
        ],
        "published": "2024-05-23T07:04:41Z"
    },
    {
        "title": "From Role-Play to Drama-Interaction: An LLM Solution",
        "link": "http://arxiv.org/abs/2405.14231v1",
        "abstract": "Drama is a form of storytelling inspired by human creativity, proceeding with\na predefined storyline, carrying emotions and thoughts. This paper introduces\n\\emph{LLM-based interactive drama}, which endows traditional drama with an\nunprecedented immersion, where a person is allowed to walk into it and interact\nwith the characters and scenes. We define this new artistic genre by 6\nessential elements-plot, character, thought, diction, spectacle and\ninteraction-and study the entire pipeline to forge a backbone \\emph{drama LLM}\nto drive the playing process, which is challenged by limited drama resources,\nuncontrollable narrative development, and complicated instruction following. We\npropose \\emph{Narrative Chain} to offer finer control over the narrative\nprogression during interaction with players; \\emph{Auto-Drama} to synthesize\ndrama scripts given arbitrary stories; \\emph{Sparse Instruction Tuning} to\nallow the model to follow sophisticated instructions. We manually craft 3\nscripts, \\emph{Detective Conan}, \\emph{Harry Potter}, \\emph{Romeo and Juliet},\nand design a 5-dimension principle to evaluate the drama LLM comprehensively.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Weiqi Wu",
            "Hongqiu Wu",
            "Lai Jiang",
            "Xingyuan Liu",
            "Jiale Hong",
            "Hai Zhao",
            "Min Zhang"
        ],
        "published": "2024-05-23T07:03:56Z"
    },
    {
        "title": "Boosting Medical Image-based Cancer Detection via Text-guided\n  Supervision from Reports",
        "link": "http://arxiv.org/abs/2405.14230v1",
        "abstract": "The absence of adequately sufficient expert-level tumor annotations hinders\nthe effectiveness of supervised learning based opportunistic cancer screening\non medical imaging. Clinical reports (that are rich in descriptive textual\ndetails) can offer a \"free lunch'' supervision information and provide tumor\nlocation as a type of weak label to cope with screening tasks, thus saving\nhuman labeling workloads, if properly leveraged. However, predicting cancer\nonly using such weak labels can be very changeling since tumors are usually\npresented in small anatomical regions compared to the whole 3D medical scans.\nWeakly semi-supervised learning (WSSL) utilizes a limited set of voxel-level\ntumor annotations and incorporates alongside a substantial number of medical\nimages that have only off-the-shelf clinical reports, which may strike a good\nbalance between minimizing expert annotation workload and optimizing screening\nefficacy. In this paper, we propose a novel text-guided learning method to\nachieve highly accurate cancer detection results. Through integrating\ndiagnostic and tumor location text prompts into the text encoder of a\nvision-language model (VLM), optimization of weakly supervised learning can be\neffectively performed in the latent space of VLM, thereby enhancing the\nstability of training. Our approach can leverage clinical knowledge by\nlarge-scale pre-trained VLM to enhance generalization ability, and produce\nreliable pseudo tumor masks to improve cancer detection. Our extensive\nquantitative experimental results on a large-scale cancer dataset, including\n1,651 unique patients, validate that our approach can reduce human annotation\nefforts by at least 70% while maintaining comparable cancer detection accuracy\nto competing fully supervised methods (AUC value 0.961 versus 0.966).",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Guangyu Guo",
            "Jiawen Yao",
            "Yingda Xia",
            "Tony C. W. Mok",
            "Zhilin Zheng",
            "Junwei Han",
            "Le Lu",
            "Dingwen Zhang",
            "Jian Zhou",
            "Ling Zhang"
        ],
        "published": "2024-05-23T07:03:38Z"
    },
    {
        "title": "Piecewise rational rotation-minimizing motions via data stream\n  interpolation",
        "link": "http://arxiv.org/abs/2405.14229v1",
        "abstract": "When a moving frame defined along a space curve is required to keep an axis\naligned with the tangent direction of motion, the use of rotation-minimizing\nframes (RMF) avoids unnecessary rotations in the normal plane. The construction\nof rigid body motions using a specific subset of quintic curves with rational\nRMFs (RRMFs) is here considered. In particular, a novel geometric\ncharacterization of such subset enables the design of a local algorithm to\ninterpolate an assigned stream of positions, together with an initial frame\norientation. To achieve this, the translational part of the motion is described\nby a parametric $G^1$ spline curve whose segments are quintic RRMFs, with a\nglobally continuous piecewise rational rotation-minimizing frame. A selection\nof numerical experiments illustrates the performances of the proposed method on\nsynthetic and arbitrary data streams.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "65D05 65D07 65D17 (Primary)"
        ],
        "authors": [
            "Carlotta Giannelli",
            "Lorenzo Sacco",
            "Alessandra Sestioni",
            "Zbyněk Šír"
        ],
        "published": "2024-05-23T07:02:34Z"
    },
    {
        "title": "$t$-Balanced Codes with the Kendall-$τ$ Metric",
        "link": "http://arxiv.org/abs/2405.14228v1",
        "abstract": "We investigate the maximum cardinality and the mathematical structure of\nerror-correcting codes endowed with the Kendall-$\\tau$ metric. We establish an\naveraging bound for the cardinality of a code with prescribed minimum distance,\ndiscuss its sharpness, and characterize codes attaining it. This leads to\nintroducing the family of $t$-balanced codes in the Kendall-$\\tau$ metric. The\nresults are based on novel arguments that shed new light on the structure of\nthe Kendall-$\\tau$ metric space.",
        "subjects": [
            "math.CO",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Benjamin Jany",
            "Alberto Ravagnani"
        ],
        "published": "2024-05-23T07:02:22Z"
    },
    {
        "title": "Variational Delayed Policy Optimization",
        "link": "http://arxiv.org/abs/2405.14226v1",
        "abstract": "In environments with delayed observation, state augmentation by including\nactions within the delay window is adopted to retrieve Markovian property to\nenable reinforcement learning (RL). However, state-of-the-art (SOTA) RL\ntechniques with Temporal-Difference (TD) learning frameworks often suffer from\nlearning inefficiency, due to the significant expansion of the augmented state\nspace with the delay. To improve learning efficiency without sacrificing\nperformance, this work introduces a novel framework called Variational Delayed\nPolicy Optimization (VDPO), which reformulates delayed RL as a variational\ninference problem. This problem is further modelled as a two-step iterative\noptimization problem, where the first step is TD learning in the delay-free\nenvironment with a small state space, and the second step is behaviour cloning\nwhich can be addressed much more efficiently than TD learning. We not only\nprovide a theoretical analysis of VDPO in terms of sample complexity and\nperformance, but also empirically demonstrate that VDPO can achieve consistent\nperformance with SOTA methods, with a significant enhancement of sample\nefficiency (approximately 50\\% less amount of samples) in the MuJoCo benchmark.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Qingyuan Wu",
            "Simon Sinong Zhan",
            "Yixuan Wang",
            "Yuhui Wang",
            "Chung-Wei Lin",
            "Chen Lv",
            "Qi Zhu",
            "Chao Huang"
        ],
        "published": "2024-05-23T06:57:04Z"
    },
    {
        "title": "ReactXT: Understanding Molecular \"Reaction-ship\" via\n  Reaction-Contextualized Molecule-Text Pretraining",
        "link": "http://arxiv.org/abs/2405.14225v1",
        "abstract": "Molecule-text modeling, which aims to facilitate molecule-relevant tasks with\na textual interface and textual knowledge, is an emerging research direction.\nBeyond single molecules, studying reaction-text modeling holds promise for\nhelping the synthesis of new materials and drugs. However, previous works\nmostly neglect reaction-text modeling: they primarily focus on modeling\nindividual molecule-text pairs or learning chemical reactions without texts in\ncontext. Additionally, one key task of reaction-text modeling -- experimental\nprocedure prediction -- is less explored due to the absence of an open-source\ndataset. The task is to predict step-by-step actions of conducting chemical\nexperiments and is crucial to automating chemical synthesis. To resolve the\nchallenges above, we propose a new pretraining method, ReactXT, for\nreaction-text modeling, and a new dataset, OpenExp, for experimental procedure\nprediction. Specifically, ReactXT features three types of input contexts to\nincrementally pretrain LMs. Each of the three input contexts corresponds to a\npretraining task to improve the text-based understanding of either reactions or\nsingle molecules. ReactXT demonstrates consistent improvements in experimental\nprocedure prediction and molecule captioning and offers competitive results in\nretrosynthesis. Our code is available at https://github.com/syr-cn/ReactXT.",
        "subjects": [
            "q-bio.QM",
            "cs.CL",
            "cs.MM"
        ],
        "authors": [
            "Zhiyuan Liu",
            "Yaorui Shi",
            "An Zhang",
            "Sihang Li",
            "Enzhi Zhang",
            "Xiang Wang",
            "Kenji Kawaguchi",
            "Tat-Seng Chua"
        ],
        "published": "2024-05-23T06:55:59Z"
    },
    {
        "title": "DiM: Diffusion Mamba for Efficient High-Resolution Image Synthesis",
        "link": "http://arxiv.org/abs/2405.14224v1",
        "abstract": "Diffusion models have achieved great success in image generation, with the\nbackbone evolving from U-Net to Vision Transformers. However, the computational\ncost of Transformers is quadratic to the number of tokens, leading to\nsignificant challenges when dealing with high-resolution images. In this work,\nwe propose Diffusion Mamba (DiM), which combines the efficiency of Mamba, a\nsequence model based on State Space Models (SSM), with the expressive power of\ndiffusion models for efficient high-resolution image synthesis. To address the\nchallenge that Mamba cannot generalize to 2D signals, we make several\narchitecture designs including multi-directional scans, learnable padding\ntokens at the end of each row and column, and lightweight local feature\nenhancement. Our DiM architecture achieves inference-time efficiency for\nhigh-resolution images. In addition, to further improve training efficiency for\nhigh-resolution image generation with DiM, we investigate ``weak-to-strong''\ntraining strategy that pretrains DiM on low-resolution images ($256\\times 256$)\nand then finetune it on high-resolution images ($512 \\times 512$). We further\nexplore training-free upsampling strategies to enable the model to generate\nhigher-resolution images (e.g., $1024\\times 1024$ and $1536\\times 1536$)\nwithout further fine-tuning. Experiments demonstrate the effectiveness and\nefficiency of our DiM.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yao Teng",
            "Yue Wu",
            "Han Shi",
            "Xuefei Ning",
            "Guohao Dai",
            "Yu Wang",
            "Zhenguo Li",
            "Xihui Liu"
        ],
        "published": "2024-05-23T06:53:18Z"
    },
    {
        "title": "Metric distortion Under Probabilistic Voting",
        "link": "http://arxiv.org/abs/2405.14223v1",
        "abstract": "Metric distortion in social choice provides a framework for assessing how\nwell voting rules minimize social cost in scenarios where voters and candidates\nexist in a shared metric space, with voters submitting rankings and the rule\noutputting a single winner. We expand this framework to include probabilistic\nvoting. Our extension encompasses a broad range of probability functions,\nincluding widely studied models like Plackett-Luce (PL) and Bradley-Terry, and\na novel \"pairwise quantal voting\" model inspired by quantal response theory.\n  We demonstrate that distortion results under probabilistic voting better\ncorrespond with conventional intuitions regarding popular voting rules such as\nPlurality, Copeland, and Random Dictator (RD) than those under deterministic\nvoting. For example, in the PL model with candidate strength inversely\nproportional to the square of their metric distance, we show that Copeland's\ndistortion is at most 2, whereas that of RD is $\\Omega(\\sqrt{m})$ in large\nelections, where $m$ is the number of candidates. This contrasts sharply with\nthe classical model, where RD beats Copeland with a distortion of 3 versus 5\n[1].",
        "subjects": [
            "cs.GT"
        ],
        "authors": [
            "Sahasrajit Sarmasarkar",
            "Mohak Goyal"
        ],
        "published": "2024-05-23T06:46:26Z"
    },
    {
        "title": "RAQ-VAE: Rate-Adaptive Vector-Quantized Variational Autoencoder",
        "link": "http://arxiv.org/abs/2405.14222v1",
        "abstract": "Vector Quantized Variational AutoEncoder (VQ-VAE) is an established technique\nin machine learning for learning discrete representations across various\nmodalities. However, its scalability and applicability are limited by the need\nto retrain the model to adjust the codebook for different data or model scales.\nWe introduce the Rate-Adaptive VQ-VAE (RAQ-VAE) framework, which addresses this\nchallenge with two novel codebook representation methods: a model-based\napproach using a clustering-based technique on an existing well-trained VQ-VAE\nmodel, and a data-driven approach utilizing a sequence-to-sequence (Seq2Seq)\nmodel for variable-rate codebook generation. Our experiments demonstrate that\nRAQ-VAE achieves effective reconstruction performance across multiple rates,\noften outperforming conventional fixed-rate VQ-VAE models. This work enhances\nthe adaptability and performance of VQ-VAEs, with broad applications in data\nreconstruction, generation, and computer vision tasks.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Jiwan Seo",
            "Joonhyuk Kang"
        ],
        "published": "2024-05-23T06:32:42Z"
    },
    {
        "title": "Survey on Visual Signal Coding and Processing with Generative Models:\n  Technologies, Standards and Optimization",
        "link": "http://dx.doi.org/10.1109/JETCAS.2024.3403524",
        "abstract": "This paper provides a survey of the latest developments in visual signal\ncoding and processing with generative models. Specifically, our focus is on\npresenting the advancement of generative models and their influence on research\nin the domain of visual signal coding and processing. This survey study begins\nwith a brief introduction of well-established generative models, including the\nVariational Autoencoder (VAE) models, Generative Adversarial Network (GAN)\nmodels, Autoregressive (AR) models, Normalizing Flows and Diffusion models. The\nsubsequent section of the paper explores the advancements in visual signal\ncoding based on generative models, as well as the ongoing international\nstandardization activities. In the realm of visual signal processing, our focus\nlies on the application and development of various generative models in the\nresearch of visual signal restoration. We also present the latest developments\nin generative visual signal synthesis and editing, along with visual signal\nquality assessment using generative models and quality assessment for\ngenerative models. The practical implementation of these studies is closely\nlinked to the investigation of fast optimization. This paper additionally\npresents the latest advancements in fast optimization on visual signal coding\nand processing with generative models. We hope to advance this field by\nproviding researchers and practitioners a comprehensive literature review on\nthe topic of visual signal coding and processing with generative models.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Zhibo Chen",
            "Heming Sun",
            "Li Zhang",
            "Fan Zhang"
        ],
        "published": "2024-05-23T06:32:27Z"
    },
    {
        "title": "Understanding the Training and Generalization of Pretrained Transformer\n  for Sequential Decision Making",
        "link": "http://arxiv.org/abs/2405.14219v1",
        "abstract": "In this paper, we consider the supervised pretrained transformer for a class\nof sequential decision-making problems. The class of considered problems is a\nsubset of the general formulation of reinforcement learning in that there is no\ntransition probability matrix, and the class of problems covers bandits,\ndynamic pricing, and newsvendor problems as special cases. Such a structure\nenables the use of optimal actions/decisions in the pretraining phase, and the\nusage also provides new insights for the training and generalization of the\npretrained transformer. We first note that the training of the transformer\nmodel can be viewed as a performative prediction problem, and the existing\nmethods and theories largely ignore or cannot resolve the arisen\nout-of-distribution issue. We propose a natural solution that includes the\ntransformer-generated action sequences in the training procedure, and it enjoys\nbetter properties both numerically and theoretically. The availability of the\noptimal actions in the considered tasks also allows us to analyze the\nproperties of the pretrained transformer as an algorithm and explains why it\nmay lack exploration and how this can be automatically resolved. Numerically,\nwe categorize the advantages of the pretrained transformer over the structured\nalgorithms such as UCB and Thompson sampling into three cases: (i) it better\nutilizes the prior knowledge in the pretraining data; (ii) it can elegantly\nhandle the misspecification issue suffered by the structured algorithms; (iii)\nfor short time horizon such as $T\\le50$, it behaves more greedy and enjoys much\nbetter regret than the structured algorithms which are designed for asymptotic\noptimality.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Hanzhao Wang",
            "Yu Pan",
            "Fupeng Sun",
            "Shang Liu",
            "Kalyan Talluri",
            "Guanting Chen",
            "Xiaocheng Li"
        ],
        "published": "2024-05-23T06:28:44Z"
    },
    {
        "title": "A Behavior-Aware Approach for Deep Reinforcement Learning in\n  Non-stationary Environments without Known Change Points",
        "link": "http://arxiv.org/abs/2405.14214v1",
        "abstract": "Deep reinforcement learning is used in various domains, but usually under the\nassumption that the environment has stationary conditions like transitions and\nstate distributions. When this assumption is not met, performance suffers. For\nthis reason, tracking continuous environmental changes and adapting to\nunpredictable conditions is challenging yet crucial because it ensures that\nsystems remain reliable and flexible in practical scenarios. Our research\nintroduces Behavior-Aware Detection and Adaptation (BADA), an innovative\nframework that merges environmental change detection with behavior adaptation.\nThe key inspiration behind our method is that policies exhibit different global\nbehaviors in changing environments. Specifically, environmental changes are\nidentified by analyzing variations between behaviors using Wasserstein\ndistances without manually set thresholds. The model adapts to the new\nenvironment through behavior regularization based on the extent of changes. The\nresults of a series of experiments demonstrate better performance relative to\nseveral current algorithms. This research also indicates significant potential\nfor tackling this long-standing challenge.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Zihe Liu",
            "Jie Lu",
            "Guangquan Zhang",
            "Junyu Xuan"
        ],
        "published": "2024-05-23T06:17:26Z"
    },
    {
        "title": "From Text to Pixel: Advancing Long-Context Understanding in MLLMs",
        "link": "http://arxiv.org/abs/2405.14213v1",
        "abstract": "The rapid progress in Multimodal Large Language Models (MLLMs) has\nsignificantly advanced their ability to process and understand complex visual\nand textual information. However, the integration of multiple images and\nextensive textual contexts remains a challenge due to the inherent limitation\nof the models' capacity to handle long input sequences efficiently. In this\npaper, we introduce SEEKER, a multimodal large language model designed to\ntackle this issue. SEEKER aims to optimize the compact encoding of long text by\ncompressing the text sequence into the visual pixel space via images, enabling\nthe model to handle long text within a fixed token-length budget efficiently.\nOur empirical experiments on six long-context multimodal tasks demonstrate that\nSEEKER can leverage fewer image tokens to convey the same amount of textual\ninformation compared with the OCR-based approach, and is more efficient in\nunderstanding long-form multimodal input and generating long-form textual\noutput, outperforming all existing proprietary and open-source MLLMs by large\nmargins.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "authors": [
            "Yujie Lu",
            "Xiujun Li",
            "Tsu-Jui Fu",
            "Miguel Eckstein",
            "William Yang Wang"
        ],
        "published": "2024-05-23T06:17:23Z"
    },
    {
        "title": "Federated Domain-Specific Knowledge Transfer on Large Language Models\n  Using Synthetic Data",
        "link": "http://arxiv.org/abs/2405.14212v1",
        "abstract": "As large language models (LLMs) demonstrate unparalleled performance and\ngeneralization ability, LLMs are widely used and integrated into various\napplications. When it comes to sensitive domains, as commonly described in\nfederated learning scenarios, directly using external LLMs on private data is\nstrictly prohibited by stringent data security and privacy regulations. For\nlocal clients, the utilization of LLMs to improve the domain-specific small\nlanguage models (SLMs), characterized by limited computational resources and\ndomain-specific data, has attracted considerable research attention. By\nobserving that LLMs can empower domain-specific SLMs, existing methods\npredominantly concentrate on leveraging the public data or LLMs to generate\nmore data to transfer knowledge from LLMs to SLMs. However, due to the\ndiscrepancies between LLMs' generated data and clients' domain-specific data,\nthese methods cannot yield substantial improvements in the domain-specific\ntasks. In this paper, we introduce a Federated Domain-specific Knowledge\nTransfer (FDKT) framework, which enables domain-specific knowledge transfer\nfrom LLMs to SLMs while preserving clients' data privacy. The core insight is\nto leverage LLMs to augment data based on domain-specific few-shot\ndemonstrations, which are synthesized from private domain data using\ndifferential privacy. Such synthetic samples share similar data distribution\nwith clients' private data and allow the server LLM to generate particular\nknowledge to improve clients' SLMs. The extensive experimental results\ndemonstrate that the proposed FDKT framework consistently and greatly improves\nSLMs' task performance by around 5\\% with a privacy budget of less than 10,\ncompared to local training on private data.",
        "subjects": [
            "cs.CR",
            "cs.CL"
        ],
        "authors": [
            "Haoran Li",
            "Xinyuan Zhao",
            "Dadi Guo",
            "Hanlin Gu",
            "Ziqian Zeng",
            "Yuxing Han",
            "Yangqiu Song",
            "Lixin Fan",
            "Qiang Yang"
        ],
        "published": "2024-05-23T06:14:35Z"
    },
    {
        "title": "ChronosLex: Time-aware Incremental Training for Temporal Generalization\n  of Legal Classification Tasks",
        "link": "http://arxiv.org/abs/2405.14211v1",
        "abstract": "This study investigates the challenges posed by the dynamic nature of legal\nmulti-label text classification tasks, where legal concepts evolve over time.\nExisting models often overlook the temporal dimension in their training\nprocess, leading to suboptimal performance of those models over time, as they\ntreat training data as a single homogeneous block. To address this, we\nintroduce ChronosLex, an incremental training paradigm that trains models on\nchronological splits, preserving the temporal order of the data. However, this\nincremental approach raises concerns about overfitting to recent data,\nprompting an assessment of mitigation strategies using continual learning and\ntemporal invariant methods. Our experimental results over six legal multi-label\ntext classification datasets reveal that continual learning methods prove\neffective in preventing overfitting thereby enhancing temporal\ngeneralizability, while temporal invariant methods struggle to capture these\ndynamics of temporal shifts.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "T. Y. S. S Santosh",
            "Tuan-Quang Vuong",
            "Matthias Grabmair"
        ],
        "published": "2024-05-23T06:09:16Z"
    },
    {
        "title": "Eidos: Efficient, Imperceptible Adversarial 3D Point Clouds",
        "link": "http://arxiv.org/abs/2405.14210v1",
        "abstract": "Classification of 3D point clouds is a challenging machine learning (ML) task\nwith important real-world applications in a spectrum from autonomous driving\nand robot-assisted surgery to earth observation from low orbit. As with other\nML tasks, classification models are notoriously brittle in the presence of\nadversarial attacks. These are rooted in imperceptible changes to inputs with\nthe effect that a seemingly well-trained model ends up misclassifying the\ninput. This paper adds to the understanding of adversarial attacks by\npresenting Eidos, a framework providing Efficient Imperceptible aDversarial\nattacks on 3D pOint cloudS. Eidos supports a diverse set of imperceptibility\nmetrics. It employs an iterative, two-step procedure to identify optimal\nadversarial examples, thereby enabling a runtime-imperceptibility trade-off. We\nprovide empirical evidence relative to several popular 3D point cloud\nclassification models and several established 3D attack methods, showing Eidos'\nsuperiority with respect to efficiency as well as imperceptibility.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Hanwei Zhang",
            "Luo Cheng",
            "Qisong He",
            "Wei Huang",
            "Renjue Li",
            "Ronan Sicre",
            "Xiaowei Huang",
            "Holger Hermanns",
            "Lijun Zhang"
        ],
        "published": "2024-05-23T06:09:08Z"
    },
    {
        "title": "Exploring and Evaluating Real-world CXL: Use Cases and System Adoption",
        "link": "http://arxiv.org/abs/2405.14209v1",
        "abstract": "Compute eXpress Link (CXL) is emerging as a promising memory interface\ntechnology. Because of the common unavailiability of CXL devices, the\nperformance of the CXL memory is largely unknown. What are the use cases for\nthe CXL memory? What are the impacts of the CXL memory on application\nperformance? How to use the CXL memory in combination with existing memory\ncomponents? In this work, we study the performance of three genuine CXL\nmemory-expansion cards from different vendors. We characterize the basic\nperformance of the CXL memory, study how HPC applications and large language\nmodels can benefit from the CXL memory, and study the interplay between memory\ntiering and page interleaving. We also propose a novel data object-level\ninterleaving policy to match the interleaving policy with memory access\npatterns. We reveal the challenges and opportunities of using the CXL memory.",
        "subjects": [
            "cs.PF",
            "cs.AR"
        ],
        "authors": [
            "Jie Liu",
            "Xi Wang",
            "Jianbo Wu",
            "Shuangyan Yang",
            "Jie Ren",
            "Bhanu Shankar",
            "Dong Li"
        ],
        "published": "2024-05-23T06:06:32Z"
    },
    {
        "title": "LG-VQ: Language-Guided Codebook Learning",
        "link": "http://arxiv.org/abs/2405.14206v1",
        "abstract": "Vector quantization (VQ) is a key technique in high-resolution and\nhigh-fidelity image synthesis, which aims to learn a codebook to encode an\nimage with a sequence of discrete codes and then generate an image in an\nauto-regression manner. Although existing methods have shown superior\nperformance, most methods prefer to learn a single-modal codebook (\\emph{e.g.},\nimage), resulting in suboptimal performance when the codebook is applied to\nmulti-modal downstream tasks (\\emph{e.g.}, text-to-image, image captioning) due\nto the existence of modal gaps. In this paper, we propose a novel\nlanguage-guided codebook learning framework, called LG-VQ, which aims to learn\na codebook that can be aligned with the text to improve the performance of\nmulti-modal downstream tasks. Specifically, we first introduce pre-trained text\nsemantics as prior knowledge, then design two novel alignment modules\n(\\emph{i.e.}, Semantic Alignment Module, and Relationship Alignment Module) to\ntransfer such prior knowledge into codes for achieving codebook text alignment.\nIn particular, our LG-VQ method is model-agnostic, which can be easily\nintegrated into existing VQ models. Experimental results show that our method\nachieves superior performance on reconstruction and various multi-modal\ndownstream tasks.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Guotao Liang",
            "Baoquan Zhang",
            "Yaowei Wang",
            "Xutao Li",
            "Yunming Ye",
            "Huaibin Wang",
            "Chuyao Luo",
            "Kola Ye",
            "linfeng Luo"
        ],
        "published": "2024-05-23T06:04:40Z"
    },
    {
        "title": "Agent Planning with World Knowledge Model",
        "link": "http://arxiv.org/abs/2405.14205v1",
        "abstract": "Recent endeavors towards directly using large language models (LLMs) as agent\nmodels to execute interactive planning tasks have shown commendable results.\nDespite their achievements, however, they still struggle with brainless\ntrial-and-error in global planning and generating hallucinatory actions in\nlocal planning due to their poor understanding of the ''real'' physical world.\nImitating humans' mental world knowledge model which provides global prior\nknowledge before the task and maintains local dynamic knowledge during the\ntask, in this paper, we introduce parametric World Knowledge Model (WKM) to\nfacilitate agent planning. Concretely, we steer the agent model to\nself-synthesize knowledge from both expert and sampled trajectories. Then we\ndevelop WKM, providing prior task knowledge to guide the global planning and\ndynamic state knowledge to assist the local planning. Experimental results on\nthree complex real-world simulated datasets with three state-of-the-art\nopen-source LLMs, Mistral-7B, Gemma-7B, and Llama-3-8B, demonstrate that our\nmethod can achieve superior performance compared to various strong baselines.\nBesides, we analyze to illustrate that our WKM can effectively alleviate the\nblind trial-and-error and hallucinatory action issues, providing strong support\nfor the agent's understanding of the world. Other interesting findings include:\n1) our instance-level task knowledge can generalize better to unseen tasks, 2)\nweak WKM can guide strong agent model planning, and 3) unified WKM training has\npromising potential for further development. Code will be available at\nhttps://github.com/zjunlp/WKM.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.MA"
        ],
        "authors": [
            "Shuofei Qiao",
            "Runnan Fang",
            "Ningyu Zhang",
            "Yuqi Zhu",
            "Xiang Chen",
            "Shumin Deng",
            "Yong Jiang",
            "Pengjun Xie",
            "Fei Huang",
            "Huajun Chen"
        ],
        "published": "2024-05-23T06:03:19Z"
    },
    {
        "title": "GLaD: Synergizing Molecular Graphs and Language Descriptors for Enhanced\n  Power Conversion Efficiency Prediction in Organic Photovoltaic Devices",
        "link": "http://arxiv.org/abs/2405.14203v1",
        "abstract": "This paper presents a novel approach for predicting Power Conversion\nEfficiency (PCE) of Organic Photovoltaic (OPV) devices, called GLaD:\nsynergizing molecular Graphs and Language Descriptors for enhanced PCE\nprediction. Due to the lack of high-quality experimental data, we collect a\ndataset consisting of 500 pairs of OPV donor and acceptor molecules along with\ntheir corresponding PCE values, which we utilize as the training data for our\npredictive model. In this low-data regime, GLaD leverages properties learned\nfrom large language models (LLMs) pretrained on extensive scientific literature\nto enrich molecular structural representations, allowing for a multimodal\nrepresentation of molecules. GLaD achieves precise predictions of PCE, thereby\nfacilitating the synthesis of new OPV molecules with improved efficiency.\nFurthermore, GLaD showcases versatility, as it applies to a range of molecular\nproperty prediction tasks (BBBP, BACE, ClinTox, and SIDER), not limited to\nthose concerning OPV materials. Especially, GLaD proves valuable for tasks in\nlow-data regimes within the chemical space, as it enriches molecular\nrepresentations by incorporating molecular property descriptions learned from\nlarge-scale pretraining. This capability is significant in real-world\nscientific endeavors like drug and material discovery, where access to\ncomprehensive data is crucial for informed decision-making and efficient\nexploration of the chemical space.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "physics.chem-ph"
        ],
        "authors": [
            "Thao Nguyen",
            "Tiara Torres-Flores",
            "Changhyun Hwang",
            "Carl Edwards",
            "Ying Diao",
            "Heng Ji"
        ],
        "published": "2024-05-23T06:02:07Z"
    },
    {
        "title": "FreeTuner: Any Subject in Any Style with Training-free Diffusion",
        "link": "http://arxiv.org/abs/2405.14201v1",
        "abstract": "With the advance of diffusion models, various personalized image generation\nmethods have been proposed. However, almost all existing work only focuses on\neither subject-driven or style-driven personalization. Meanwhile,\nstate-of-the-art methods face several challenges in realizing compositional\npersonalization, i.e., composing different subject and style concepts, such as\nconcept disentanglement, unified reconstruction paradigm, and insufficient\ntraining data. To address these issues, we introduce FreeTuner, a flexible and\ntraining-free method for compositional personalization that can generate any\nuser-provided subject in any user-provided style (see Figure 1). Our approach\nemploys a disentanglement strategy that separates the generation process into\ntwo stages to effectively mitigate concept entanglement. FreeTuner leverages\nthe intermediate features within the diffusion model for subject concept\nrepresentation and introduces style guidance to align the synthesized images\nwith the style concept, ensuring the preservation of both the subject's\nstructure and the style's aesthetic features. Extensive experiments have\ndemonstrated the generation ability of FreeTuner across various personalization\nsettings.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Youcan Xu",
            "Zhen Wang",
            "Jun Xiao",
            "Wei Liu",
            "Long Chen"
        ],
        "published": "2024-05-23T06:01:13Z"
    },
    {
        "title": "Awesome Multi-modal Object Tracking",
        "link": "http://arxiv.org/abs/2405.14200v1",
        "abstract": "Multi-modal object tracking (MMOT) is an emerging field that combines data\nfrom various modalities, \\eg vision (RGB), depth, thermal infrared, event,\nlanguage and audio, to estimate the state of an arbitrary object in a video\nsequence. It is of great significance for many applications such as autonomous\ndriving and intelligent surveillance. In recent years, MMOT has received more\nand more attention. However, existing MMOT algorithms mainly focus on two\nmodalities (\\eg RGB+depth, RGB+thermal infrared, and RGB+language). To leverage\nmore modalities, some recent efforts have been made to learn a unified visual\nobject tracking model for any modality. Additionally, some large-scale\nmulti-modal tracking benchmarks have been established by simultaneously\nproviding more than two modalities, such as vision-language-audio (\\eg\nWebUAV-3M) and vision-depth-language (\\eg UniMod1K). To track the latest\nprogress in MMOT, we conduct a comprehensive investigation in this report.\nSpecifically, we first divide existing MMOT tasks into five main categories,\n\\ie RGBL tracking, RGBE tracking, RGBD tracking, RGBT tracking, and\nmiscellaneous (RGB+X), where X can be any modality, such as language, depth,\nand event. Then, we analyze and summarize each MMOT task, focusing on widely\nused datasets and mainstream tracking algorithms based on their technical\nparadigms (\\eg self-supervised learning, prompt learning, knowledge\ndistillation, generative models, and state space models). Finally, we maintain\na continuously updated paper list for MMOT at\nhttps://github.com/983632847/Awesome-Multimodal-Object-Tracking.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Chunhui Zhang",
            "Li Liu",
            "Hao Wen",
            "Xi Zhou",
            "Yanfeng Wang"
        ],
        "published": "2024-05-23T05:58:10Z"
    },
    {
        "title": "Adaptive Teaching in Heterogeneous Agents: Balancing Surprise in Sparse\n  Reward Scenarios",
        "link": "http://arxiv.org/abs/2405.14199v1",
        "abstract": "Learning from Demonstration (LfD) can be an efficient way to train systems\nwith analogous agents by enabling ``Student'' agents to learn from the\ndemonstrations of the most experienced ``Teacher'' agent, instead of training\ntheir policy in parallel. However, when there are discrepancies in agent\ncapabilities, such as divergent actuator power or joint angle constraints,\nnaively replicating demonstrations that are out of bounds for the Student's\ncapability can limit efficient learning. We present a Teacher-Student learning\nframework specifically tailored to address the challenge of heterogeneity\nbetween the Teacher and Student agents. Our framework is based on the concept\nof ``surprise'', inspired by its application in exploration incentivization in\nsparse-reward environments. Surprise is repurposed to enable the Teacher to\ndetect and adapt to differences between itself and the Student. By focusing on\nmaximizing its surprise in response to the environment while concurrently\nminimizing the Student's surprise in response to the demonstrations, the\nTeacher agent can effectively tailor its demonstrations to the Student's\nspecific capabilities and constraints. We validate our method by demonstrating\nimprovements in the Student's learning in control tasks within sparse-reward\nenvironments.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "authors": [
            "Emma Clark",
            "Kanghyun Ryu",
            "Negar Mehr"
        ],
        "published": "2024-05-23T05:52:42Z"
    },
    {
        "title": "Enabling Sustainable Freight Forwarding Network via Collaborative Games",
        "link": "http://arxiv.org/abs/2405.14198v1",
        "abstract": "Freight forwarding plays a crucial role in facilitating global trade and\nlogistics. However, as the freight forwarding market is extremely fragmented,\nfreight forwarders often face the issue of not being able to fill the available\nshipping capacity. This recurrent issue motivates the creation of various\nfreight forwarding networks that aim at exchanging capacities and demands so\nthat the resource utilization of individual freight forwarders can be\nmaximized. In this paper, we focus on how to design such a collaborative\nnetwork based on collaborative game theory, with the Shapley value representing\na fair scheme for profit sharing. Noting that the exact computation of Shapley\nvalues is intractable for large-scale real-world scenarios, we incorporate the\nobservation that collaboration among two forwarders is only possible if their\nservice routes and demands overlap. This leads to a new class of collaborative\ngames called the Locally Collaborative Games (LCGs), where agents can only\ncollaborate with their neighbors. We propose an efficient approach to compute\nShapley values for LCGs, and numerically demonstrate that our approach\nsignificantly outperforms the state-of-the-art approach for a wide variety of\nnetwork structures.",
        "subjects": [
            "cs.MA"
        ],
        "authors": [
            "Pang-Jin Tan",
            "Shih-Fen Cheng",
            "Richard Chen"
        ],
        "published": "2024-05-23T05:52:38Z"
    },
    {
        "title": "Enhanced Object Tracking by Self-Supervised Auxiliary Depth Estimation\n  Learning",
        "link": "http://arxiv.org/abs/2405.14195v1",
        "abstract": "RGB-D tracking significantly improves the accuracy of object tracking.\nHowever, its dependency on real depth inputs and the complexity involved in\nmulti-modal fusion limit its applicability across various scenarios. The\nutilization of depth information in RGB-D tracking inspired us to propose a new\nmethod, named MDETrack, which trains a tracking network with an additional\ncapability to understand the depth of scenes, through supervised or\nself-supervised auxiliary Monocular Depth Estimation learning. The outputs of\nMDETrack's unified feature extractor are fed to the side-by-side tracking head\nand auxiliary depth estimation head, respectively. The auxiliary module will be\ndiscarded in inference, thus keeping the same inference speed. We evaluated our\nmodels with various training strategies on multiple datasets, and the results\nshow an improved tracking accuracy even without real depth. Through these\nfindings we highlight the potential of depth estimation in enhancing object\ntracking performance.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Zhenyu Wei",
            "Yujie He",
            "Zhanchuan Cai"
        ],
        "published": "2024-05-23T05:43:38Z"
    },
    {
        "title": "Graphlets correct for the topological information missed by random walks",
        "link": "http://arxiv.org/abs/2405.14194v1",
        "abstract": "Random walks are widely used for mining networks due to the computational\nefficiency of computing them. For instance, graph representation learning\nlearns a d-dimensional embedding space, so that the nodes that tend to co-occur\non random walks (a proxy of being in the same network neighborhood) are close\nin the embedding space. Specific local network topology (i.e., structure)\ninfluences the co-occurrence of nodes on random walks, so random walks of\nlimited length capture only partial topological information, hence diminishing\nthe performance of downstream methods. We explicitly capture all topological\nneighborhood information and improve performance by introducing orbit\nadjacencies that quantify the adjacencies of two nodes as co-occurring on a\ngiven pair of graphlet orbits, which are symmetric positions on graphlets\n(small, connected, non-isomorphic, induced subgraphs of a large network).\nImportantly, we mathematically prove that random walks on up to k nodes capture\nonly a subset of all the possible orbit adjacencies for up to k-node graphlets.\nFurthermore, we enable orbit adjacency-based analysis of networks by developing\nan efficient GRaphlet-orbit ADjacency COunter (GRADCO), which exhaustively\ncomputes all 28 orbit adjacency matrices for up to four-node graphlets. Note\nthat four-node graphlets suffice, because real networks are usually\nsmall-world. In large networks on around 20,000 nodes,\nGRADCOcomputesthe28matricesinminutes. Onsixrealnetworksfromvarious domains, we\ncompare the performance of node-label predictors obtained by using the network\nembeddings based on our orbit adjacencies to those based on random walks. We\nfind that orbit adjacencies, which include those unseen by random walks,\noutperform random walk-based adjacencies, demonstrating the importance of the\ninclusion of the topological neighborhood information that is unseen by random\nwalks.",
        "subjects": [
            "cs.SI",
            "cs.AI",
            "cs.DS",
            "cs.LG",
            "68Uxx",
            "I.5"
        ],
        "authors": [
            "Sam F. L. Windels",
            "Noel Malod-Dognin",
            "Natasa Przulj"
        ],
        "published": "2024-05-23T05:42:38Z"
    },
    {
        "title": "IB-AdCSCNet:Adaptive Convolutional Sparse Coding Network Driven by\n  Information Bottleneck",
        "link": "http://arxiv.org/abs/2405.14192v1",
        "abstract": "In the realm of neural network models, the perpetual challenge remains in\nretaining task-relevant information while effectively discarding redundant data\nduring propagation. In this paper, we introduce IB-AdCSCNet, a deep learning\nmodel grounded in information bottleneck theory. IB-AdCSCNet seamlessly\nintegrates the information bottleneck trade-off strategy into deep networks by\ndynamically adjusting the trade-off hyperparameter $\\lambda$ through gradient\ndescent, updating it within the FISTA(Fast Iterative Shrinkage-Thresholding\nAlgorithm ) framework. By optimizing the compressive excitation loss function\ninduced by the information bottleneck principle, IB-AdCSCNet achieves an\noptimal balance between compression and fitting at a global level,\napproximating the globally optimal representation feature. This information\nbottleneck trade-off strategy driven by downstream tasks not only helps to\nlearn effective features of the data, but also improves the generalization of\nthe model. This study's contribution lies in presenting a model with consistent\nperformance and offering a fresh perspective on merging deep learning with\nsparse representation theory, grounded in the information bottleneck concept.\nExperimental results on CIFAR-10 and CIFAR-100 datasets demonstrate that\nIB-AdCSCNet not only matches the performance of deep residual convolutional\nnetworks but also outperforms them when handling corrupted data. Through the\ninference of the IB trade-off, the model's robustness is notably enhanced.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "He Zou",
            "Meng'en Qin",
            "Yu Song",
            "Xiaohui Yang"
        ],
        "published": "2024-05-23T05:35:57Z"
    },
    {
        "title": "S-Eval: Automatic and Adaptive Test Generation for Benchmarking Safety\n  Evaluation of Large Language Models",
        "link": "http://arxiv.org/abs/2405.14191v1",
        "abstract": "Large Language Models have gained considerable attention for their\nrevolutionary capabilities. However, there is also growing concern on their\nsafety implications, making a comprehensive safety evaluation for LLMs urgently\nneeded before model deployment. In this work, we propose S-Eval, a new\ncomprehensive, multi-dimensional and open-ended safety evaluation benchmark. At\nthe core of S-Eval is a novel LLM-based automatic test prompt generation and\nselection framework, which trains an expert testing LLM Mt combined with a\nrange of test selection strategies to automatically construct a high-quality\ntest suite for the safety evaluation. The key to the automation of this process\nis a novel expert safety-critique LLM Mc able to quantify the riskiness score\nof a LLM's response, and additionally produce risk tags and explanations.\nBesides, the generation process is also guided by a carefully designed risk\ntaxonomy with four different levels, covering comprehensive and\nmulti-dimensional safety risks of concern. Based on these, we systematically\nconstruct a new and large-scale safety evaluation benchmark for LLMs consisting\nof 220,000 evaluation prompts, including 20,000 base risk prompts (10,000 in\nChinese and 10,000 in English) and 200, 000 corresponding attack prompts\nderived from 10 popular adversarial instruction attacks against LLMs. Moreover,\nconsidering the rapid evolution of LLMs and accompanied safety threats, S-Eval\ncan be flexibly configured and adapted to include new risks, attacks and\nmodels. S-Eval is extensively evaluated on 20 popular and representative LLMs.\nThe results confirm that S-Eval can better reflect and inform the safety risks\nof LLMs compared to existing benchmarks. We also explore the impacts of\nparameter scales, language environments, and decoding parameters on the\nevaluation, providing a systematic methodology for evaluating the safety of\nLLMs.",
        "subjects": [
            "cs.CR",
            "cs.CL"
        ],
        "authors": [
            "Xiaohan Yuan",
            "Jinfeng Li",
            "Dongxia Wang",
            "Yuefeng Chen",
            "Xiaofeng Mao",
            "Longtao Huang",
            "Hui Xue",
            "Wenhai Wang",
            "Kui Ren",
            "Jingyi Wang"
        ],
        "published": "2024-05-23T05:34:31Z"
    },
    {
        "title": "Semantic-guided Prompt Organization for Universal Goal Hijacking against\n  LLMs",
        "link": "http://arxiv.org/abs/2405.14189v1",
        "abstract": "With the rising popularity of Large Language Models (LLMs), assessing their\ntrustworthiness through security tasks has gained critical importance.\nRegarding the new task of universal goal hijacking, previous efforts have\nconcentrated solely on optimization algorithms, overlooking the crucial role of\nthe prompt. To fill this gap, we propose a universal goal hijacking method\ncalled POUGH that incorporates semantic-guided prompt processing strategies.\nSpecifically, the method starts with a sampling strategy to select\nrepresentative prompts from a candidate pool, followed by a ranking strategy\nthat prioritizes the prompts. Once the prompts are organized sequentially, the\nmethod employs an iterative optimization algorithm to generate the universal\nfixed suffix for the prompts. Experiments conducted on four popular LLMs and\nten types of target responses verified the effectiveness of our method.",
        "subjects": [
            "cs.CL",
            "cs.CV"
        ],
        "authors": [
            "Yihao Huang",
            "Chong Wang",
            "Xiaojun Jia",
            "Qing Guo",
            "Felix Juefei-Xu",
            "Jian Zhang",
            "Geguang Pu",
            "Yang Liu"
        ],
        "published": "2024-05-23T05:31:41Z"
    },
    {
        "title": "Design Considerations for Automatic Musical Soundscapes of Visual Art\n  for People with Blindness or Low Vision",
        "link": "http://arxiv.org/abs/2405.14188v1",
        "abstract": "Music has been identified as a promising medium to enhance the accessibility\nand experience of visual art for people who are blind or have low vision (BLV).\nHowever, composing music and designing soundscapes for visual art is a\ntime-consuming, resource intensive process - limiting its scalability for large\nexhibitions. In this paper, we investigate the use of automated soundscapes to\nincrease the accessibility of visual art. We built a prototype system and ran a\nqualitative study to evaluate the aesthetic experience provided by the\nautomated soundscapes with 10 BLV participants. From the study, we identified a\nset of design considerations that reveal requirements from BLV people for the\ndevelopment of automated soundscape systems, setting new directions in which\ncreative systems could enrich the aesthetic experience conveyed by these.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Stephen James Krol",
            "Maria Teresa Llano",
            "Matthew Butler",
            "Cagatay Goncu"
        ],
        "published": "2024-05-23T05:30:43Z"
    },
    {
        "title": "Fairness Hub Technical Briefs: Definition and Detection of Distribution\n  Shift",
        "link": "http://arxiv.org/abs/2405.14186v1",
        "abstract": "Distribution shift is a common situation in machine learning tasks, where the\ndata used for training a model is different from the data the model is applied\nto in the real world. This issue arises across multiple technical settings:\nfrom standard prediction tasks, to time-series forecasting, and to more recent\napplications of large language models (LLMs). This mismatch can lead to\nperformance reductions, and can be related to a multiplicity of factors:\nsampling issues and non-representative data, changes in the environment or\npolicies, or the emergence of previously unseen scenarios. This brief focuses\non the definition and detection of distribution shifts in educational settings.\nWe focus on standard prediction problems, where the task is to learn a model\nthat takes in a series of input (predictors) $X=(x_1,x_2,...,x_m)$ and produces\nan output $Y=f(X)$.",
        "subjects": [
            "cs.LG",
            "cs.CY"
        ],
        "authors": [
            "Nicolas Acevedo",
            "Carmen Cortez",
            "Chris Brooks",
            "Rene Kizilcec",
            "Renzhe Yu"
        ],
        "published": "2024-05-23T05:29:36Z"
    },
    {
        "title": "A structure-aware framework for learning device placements on\n  computation graphs",
        "link": "http://arxiv.org/abs/2405.14185v1",
        "abstract": "Existing approaches for device placement ignore the topological features of\ncomputation graphs and rely mostly on heuristic methods for graph partitioning.\nAt the same time, they either follow a grouper-placer or an encoder-placer\narchitecture, which requires understanding the interaction structure between\ncode operations. To bridge the gap between encoder-placer and grouper-placer\ntechniques, we propose a novel framework for the task of device placement,\nrelying on smaller computation graphs extracted from the OpenVINO toolkit using\nreinforcement learning. The framework consists of five steps, including graph\ncoarsening, node representation learning and policy optimization. It\nfacilitates end-to-end training and takes into consideration the directed and\nacyclic nature of the computation graphs. We also propose a model variant,\ninspired by graph parsing networks and complex network analysis, enabling graph\nrepresentation learning and personalized graph partitioning jointly, using an\nunspecified number of groups. To train the entire framework, we utilize\nreinforcement learning techniques by employing the execution time of the\nsuggested device placements to formulate the reward. We demonstrate the\nflexibility and effectiveness of our approach through multiple experiments with\nthree benchmark models, namely Inception-V3, ResNet, and BERT. The robustness\nof the proposed framework is also highlighted through an ablation study. The\nsuggested placements improve the inference speed for the benchmark models by up\nto $58.2\\%$ over CPU execution and by up to $60.24\\%$ compared to other\ncommonly used baselines.",
        "subjects": [
            "cs.LG",
            "cs.PF"
        ],
        "authors": [
            "Shukai Duan",
            "Heng Ping",
            "Nikos Kanakaris",
            "Xiongye Xiao",
            "Peiyu Zhang",
            "Panagiotis Kyriakis",
            "Nesreen K. Ahmed",
            "Guixiang Ma",
            "Mihai Capota",
            "Shahin Nazarian",
            "Theodore L. Willke",
            "Paul Bogdan"
        ],
        "published": "2024-05-23T05:29:29Z"
    },
    {
        "title": "Deterministic Policies for Constrained Reinforcement Learning in\n  Polynomial-Time",
        "link": "http://arxiv.org/abs/2405.14183v1",
        "abstract": "We present a novel algorithm that efficiently computes near-optimal\ndeterministic policies for constrained reinforcement learning (CRL) problems.\nOur approach combines three key ideas: (1) value-demand augmentation, (2)\naction-space approximate dynamic programming, and (3) time-space rounding.\nUnder mild reward assumptions, our algorithm constitutes a fully\npolynomial-time approximation scheme (FPTAS) for a diverse class of cost\ncriteria. This class requires that the cost of a policy can be computed\nrecursively over both time and (state) space, which includes classical\nexpectation, almost sure, and anytime constraints. Our work not only provides\nprovably efficient algorithms to address real-world challenges in\ndecision-making but also offers a unifying theory for the efficient computation\nof constrained deterministic policies.",
        "subjects": [
            "cs.LG",
            "cs.DS"
        ],
        "authors": [
            "Jeremy McMahan"
        ],
        "published": "2024-05-23T05:27:51Z"
    },
    {
        "title": "UzMorphAnalyser: A Morphological Analysis Model for the Uzbek Language\n  Using Inflectional Endings",
        "link": "http://arxiv.org/abs/2405.14179v1",
        "abstract": "As Uzbek language is agglutinative, has many morphological features which\nwords formed by combining root and affixes. Affixes play an important role in\nthe morphological analysis of words, by adding additional meanings and\ngrammatical functions to words. Inflectional endings are utilized to express\nvarious morphological features within the language. This feature introduces\nnumerous possibilities for word endings, thereby significantly expanding the\nword vocabulary and exacerbating issues related to data sparsity in statistical\nmodels. This paper present modeling of the morphological analysis of Uzbek\nwords, including stemming, lemmatizing, and the extraction of morphological\ninformation while considering morpho-phonetic exceptions. Main steps of the\nmodel involve developing a complete set of word-ending with assigned\nmorphological information, and additional datasets for morphological analysis.\nThe proposed model was evaluated using a curated test set comprising 5.3K\nwords. Through manual verification of stemming, lemmatizing, and morphological\nfeature corrections carried out by linguistic specialists, it obtained a\nword-level accuracy of over 91%. The developed tool based on the proposed model\nis available as a web-based application and an open-source Python library.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Ulugbek Salaev"
        ],
        "published": "2024-05-23T05:06:55Z"
    },
    {
        "title": "Desirable Characteristics for AI Teaching Assistants in Programming\n  Education",
        "link": "http://dx.doi.org/10.1145/3649217.3653574",
        "abstract": "Providing timely and personalized feedback to large numbers of students is a\nlong-standing challenge in programming courses. Relying on human teaching\nassistants (TAs) has been extensively studied, revealing a number of potential\nshortcomings. These include inequitable access for students with low confidence\nwhen needing support, as well as situations where TAs provide direct solutions\nwithout helping students to develop their own problem-solving skills. With the\nadvent of powerful large language models (LLMs), digital teaching assistants\nconfigured for programming contexts have emerged as an appealing and scalable\nway to provide instant, equitable, round-the-clock support. Although digital\nTAs can provide a variety of help for programming tasks, from high-level\nproblem solving advice to direct solution generation, the effectiveness of such\ntools depends on their ability to promote meaningful learning experiences. If\nstudents find the guardrails implemented in digital TAs too constraining, or if\nother expectations are not met, they may seek assistance in ways that do not\nhelp them learn. Thus, it is essential to identify the features that students\nbelieve make digital teaching assistants valuable. We deployed an LLM-powered\ndigital assistant in an introductory programming course and collected student\nfeedback ($n=813$) on the characteristics of the tool they perceived to be most\nimportant. Our results highlight that students value such tools for their\nability to provide instant, engaging support, particularly during peak times\nsuch as before assessment deadlines. They also expressed a strong preference\nfor features that enable them to retain autonomy in their learning journey,\nsuch as scaffolding that helps to guide them through problem-solving steps\nrather than simply being shown direct solutions.",
        "subjects": [
            "cs.CY",
            "cs.HC"
        ],
        "authors": [
            "Paul Denny",
            "Stephen MacNeil",
            "Jaromir Savelka",
            "Leo Porter",
            "Andrew Luxton-Reilly"
        ],
        "published": "2024-05-23T05:03:49Z"
    },
    {
        "title": "Certified Robustness against Sparse Adversarial Perturbations via Data\n  Localization",
        "link": "http://arxiv.org/abs/2405.14176v1",
        "abstract": "Recent work in adversarial robustness suggests that natural data\ndistributions are localized, i.e., they place high probability in small volume\nregions of the input space, and that this property can be utilized for\ndesigning classifiers with improved robustness guarantees for $\\ell_2$-bounded\nperturbations. Yet, it is still unclear if this observation holds true for more\ngeneral metrics. In this work, we extend this theory to $\\ell_0$-bounded\nadversarial perturbations, where the attacker can modify a few pixels of the\nimage but is unrestricted in the magnitude of perturbation, and we show\nnecessary and sufficient conditions for the existence of $\\ell_0$-robust\nclassifiers. Theoretical certification approaches in this regime essentially\nemploy voting over a large ensemble of classifiers. Such procedures are\ncombinatorial and expensive or require complicated certification techniques. In\ncontrast, a simple classifier emerges from our theory, dubbed Box-NN, which\nnaturally incorporates the geometry of the problem and improves upon the\ncurrent state-of-the-art in certified robustness against sparse attacks for the\nMNIST and Fashion-MNIST datasets.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Ambar Pal",
            "René Vidal",
            "Jeremias Sulam"
        ],
        "published": "2024-05-23T05:02:00Z"
    },
    {
        "title": "Multi-Scale VMamba: Hierarchy in Hierarchy Visual State Space Model",
        "link": "http://arxiv.org/abs/2405.14174v1",
        "abstract": "Despite the significant achievements of Vision Transformers (ViTs) in various\nvision tasks, they are constrained by the quadratic complexity. Recently, State\nSpace Models (SSMs) have garnered widespread attention due to their global\nreceptive field and linear complexity with respect to the input length,\ndemonstrating substantial potential across fields including natural language\nprocessing and computer vision. To improve the performance of SSMs in vision\ntasks, a multi-scan strategy is widely adopted, which leads to significant\nredundancy of SSMs. For a better trade-off between efficiency and performance,\nwe analyze the underlying reasons behind the success of the multi-scan\nstrategy, where long-range dependency plays an important role. Based on the\nanalysis, we introduce Multi-Scale Vision Mamba (MSVMamba) to preserve the\nsuperiority of SSMs in vision tasks with limited parameters. It employs a\nmulti-scale 2D scanning technique on both original and downsampled feature\nmaps, which not only benefits long-range dependency learning but also reduces\ncomputational costs. Additionally, we integrate a Convolutional Feed-Forward\nNetwork (ConvFFN) to address the lack of channel mixing. Our experiments\ndemonstrate that MSVMamba is highly competitive, with the MSVMamba-Tiny model\nachieving 82.8% top-1 accuracy on ImageNet, 46.9% box mAP, and 42.2% instance\nmAP with the Mask R-CNN framework, 1x training schedule on COCO, and 47.6% mIoU\nwith single-scale testing on ADE20K.Code is available at\n\\url{https://github.com/YuHengsss/MSVMamba}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yuheng Shi",
            "Minjing Dong",
            "Chang Xu"
        ],
        "published": "2024-05-23T04:59:49Z"
    },
    {
        "title": "Human-Agent Cooperation in Games under Incomplete Information through\n  Natural Language Communication",
        "link": "http://arxiv.org/abs/2405.14173v1",
        "abstract": "Developing autonomous agents that can strategize and cooperate with humans\nunder information asymmetry is challenging without effective communication in\nnatural language. We introduce a shared-control game, where two players\ncollectively control a token in alternating turns to achieve a common objective\nunder incomplete information. We formulate a policy synthesis problem for an\nautonomous agent in this game with a human as the other player. To solve this\nproblem, we propose a communication-based approach comprising a language module\nand a planning module. The language module translates natural language messages\ninto and from a finite set of flags, a compact representation defined to\ncapture player intents. The planning module leverages these flags to compute a\npolicy using an asymmetric information-set Monte Carlo tree search with flag\nexchange algorithm we present. We evaluate the effectiveness of this approach\nin a testbed based on Gnomes at Night, a search-and-find maze board game.\nResults of human subject experiments show that communication narrows the\ninformation gap between players and enhances human-agent cooperation efficiency\nwith fewer turns.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "authors": [
            "Shenghui Chen",
            "Daniel Fried",
            "Ufuk Topcu"
        ],
        "published": "2024-05-23T04:58:42Z"
    },
    {
        "title": "Automated Optimal Layout Generator for Animal Shelters: A framework\n  based on Genetic Algorithm, TOPSIS and Graph Theory",
        "link": "http://arxiv.org/abs/2405.14172v1",
        "abstract": "Overpopulation in animal shelters contributes to increased disease spread and\nhigher expenses on animal healthcare, leading to fewer adoptions and more\nshelter deaths. Additionally, one of the greatest challenges that shelters face\nis the noise level in the dog kennel area, which is physically and\nphysiologically hazardous for both animals and staff. This paper proposes a\nmulti-criteria optimization framework to automatically design cage layouts that\nmaximize shelter capacity, minimize tension in the dog kennel area by reducing\nthe number of cages facing each other, and ensure accessibility for staff and\nvisitors. The proposed framework uses a Genetic Algorithm (GA) to\nsystematically generate and improve layouts. A novel graph theory-based\nalgorithm is introduced to process solutions and calculate fitness values.\nAdditionally, the Technique for Order of Preference by Similarity to Ideal\nSolution (TOPSIS) is used to rank and sort the layouts in each iteration. The\ngraph-based algorithm calculates variables such as cage accessibility and\nshortest paths to access points. Furthermore, a heuristic algorithm is\ndeveloped to calculate layout scores based on the number of cages facing each\nother. This framework provides animal shelter management with a flexible\ndecision-support system that allows for different strategies by assigning\nvarious weights to the TOPSIS criteria. Results from cats' and dogs' kennel\nareas show that the proposed framework can suggest optimal layouts that respect\ndifferent priorities within acceptable runtimes.",
        "subjects": [
            "cs.NE"
        ],
        "authors": [
            "Arghavan Jalayer",
            "Masoud Jalayer",
            "Mehdi Khahzand",
            "Mohsen Faizi"
        ],
        "published": "2024-05-23T04:57:55Z"
    },
    {
        "title": "Multi-view Remote Sensing Image Segmentation With SAM priors",
        "link": "http://arxiv.org/abs/2405.14171v1",
        "abstract": "Multi-view segmentation in Remote Sensing (RS) seeks to segment images from\ndiverse perspectives within a scene. Recent methods leverage 3D information\nextracted from an Implicit Neural Field (INF), bolstering result consistency\nacross multiple views while using limited accounts of labels (even within 3-5\nlabels) to streamline labor. Nonetheless, achieving superior performance within\nthe constraints of limited-view labels remains challenging due to inadequate\nscene-wide supervision and insufficient semantic features within the INF. To\naddress these. we propose to inject the prior of the visual foundation\nmodel-Segment Anything(SAM), to the INF to obtain better results under the\nlimited number of training data. Specifically, we contrast SAM features between\ntesting and training views to derive pseudo labels for each testing view,\naugmenting scene-wide labeling information. Subsequently, we introduce SAM\nfeatures via a transformer into the INF of the scene, supplementing the\nsemantic information. The experimental results demonstrate that our method\noutperforms the mainstream method, confirming the efficacy of SAM as a\nsupplement to the INF for this task.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zipeng Qi",
            "Chenyang Liu",
            "Zili Liu",
            "Hao Chen",
            "Yongchang Wu",
            "Zhengxia Zou",
            "Zhenwei Sh"
        ],
        "published": "2024-05-23T04:57:41Z"
    },
    {
        "title": "Large Language Models-guided Dynamic Adaptation for Temporal Knowledge\n  Graph Reasoning",
        "link": "http://arxiv.org/abs/2405.14170v1",
        "abstract": "Temporal Knowledge Graph Reasoning (TKGR) is the process of utilizing\ntemporal information to capture complex relations within a Temporal Knowledge\nGraph (TKG) to infer new knowledge. Conventional methods in TKGR typically\ndepend on deep learning algorithms or temporal logical rules. However, deep\nlearning-based TKGRs often lack interpretability, whereas rule-based TKGRs\nstruggle to effectively learn temporal rules that capture temporal patterns.\nRecently, Large Language Models (LLMs) have demonstrated extensive knowledge\nand remarkable proficiency in temporal reasoning. Consequently, the employment\nof LLMs for Temporal Knowledge Graph Reasoning (TKGR) has sparked increasing\ninterest among researchers. Nonetheless, LLMs are known to function as black\nboxes, making it challenging to comprehend their reasoning process.\nAdditionally, due to the resource-intensive nature of fine-tuning, promptly\nupdating LLMs to integrate evolving knowledge within TKGs for reasoning is\nimpractical. To address these challenges, in this paper, we propose a Large\nLanguage Models-guided Dynamic Adaptation (LLM-DA) method for reasoning on\nTKGs. Specifically, LLM-DA harnesses the capabilities of LLMs to analyze\nhistorical data and extract temporal logical rules. These rules unveil temporal\npatterns and facilitate interpretable reasoning. To account for the evolving\nnature of TKGs, a dynamic adaptation strategy is proposed to update the\nLLM-generated rules with the latest events. This ensures that the extracted\nrules always incorporate the most recent knowledge and better generalize to the\npredictions on future events. Experimental results show that without the need\nof fine-tuning, LLM-DA significantly improves the accuracy of reasoning over\nseveral common datasets, providing a robust framework for TKGR tasks.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Jiapu Wang",
            "Kai Sun",
            "Linhao Luo",
            "Wei Wei",
            "Yongli Hu",
            "Alan Wee-Chung Liew",
            "Shirui Pan",
            "Baocai Yin"
        ],
        "published": "2024-05-23T04:54:37Z"
    },
    {
        "title": "Towards Transferable Attacks Against Vision-LLMs in Autonomous Driving\n  with Typography",
        "link": "http://arxiv.org/abs/2405.14169v1",
        "abstract": "Vision-Large-Language-Models (Vision-LLMs) are increasingly being integrated\ninto autonomous driving (AD) systems due to their advanced visual-language\nreasoning capabilities, targeting the perception, prediction, planning, and\ncontrol mechanisms. However, Vision-LLMs have demonstrated susceptibilities\nagainst various types of adversarial attacks, which would compromise their\nreliability and safety. To further explore the risk in AD systems and the\ntransferability of practical threats, we propose to leverage typographic\nattacks against AD systems relying on the decision-making capabilities of\nVision-LLMs. Different from the few existing works developing general datasets\nof typographic attacks, this paper focuses on realistic traffic scenarios where\nthese attacks can be deployed, on their potential effects on the\ndecision-making autonomy, and on the practical ways in which these attacks can\nbe physically presented. To achieve the above goals, we first propose a\ndataset-agnostic framework for automatically generating false answers that can\nmislead Vision-LLMs' reasoning. Then, we present a linguistic augmentation\nscheme that facilitates attacks at image-level and region-level reasoning, and\nwe extend it with attack patterns against multiple reasoning tasks\nsimultaneously. Based on these, we conduct a study on how these attacks can be\nrealized in physical traffic scenarios. Through our empirical study, we\nevaluate the effectiveness, transferability, and realizability of typographic\nattacks in traffic scenes. Our findings demonstrate particular harmfulness of\nthe typographic attacks against existing Vision-LLMs (e.g., LLaVA, Qwen-VL,\nVILA, and Imp), thereby raising community awareness of vulnerabilities when\nincorporating such models into AD systems. We will release our source code upon\nacceptance.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Nhat Chung",
            "Sensen Gao",
            "Tuan-Anh Vu",
            "Jie Zhang",
            "Aishan Liu",
            "Yun Lin",
            "Jin Song Dong",
            "Qing Guo"
        ],
        "published": "2024-05-23T04:52:02Z"
    },
    {
        "title": "A generative model for community types in directed networks",
        "link": "http://arxiv.org/abs/2405.14168v1",
        "abstract": "Large complex networks are often organized into groups or communities. In\nthis paper, we introduce and investigate a generative model of network\nevolution that reproduces all four pairwise community types that exist in\ndirected networks: assortative, core-periphery, disassortative, and the newly\nintroduced source-basin type. We fix the number of nodes and the community\nmembership of each node, allowing node connectivity to change through rewiring\nmechanisms that depend on the community membership of the involved nodes. We\ndetermine the dependence of the community relationship on the model parameters\nusing a mean-field solution. It reveals that a difference in the swap\nprobabilities of the two communities is a necessary condition to obtain a\ncore-periphery relationship and that a difference in the average in-degree of\nthe communities is a necessary condition for a source-basin relationship. More\ngenerally, our analysis reveals multiple possible scenarios for the transition\nbetween the different structure types, and sheds light on the mechanisms\nunderlying the observation of the different types of communities in network\ndata.",
        "subjects": [
            "cs.SI",
            "physics.soc-ph"
        ],
        "authors": [
            "Cathy Xuanchi Liu",
            "Tristram J. Alexander",
            "Eduardo G. Altmann"
        ],
        "published": "2024-05-23T04:49:07Z"
    },
    {
        "title": "Leveraging Semantic Segmentation Masks with Embeddings for Fine-Grained\n  Form Classification",
        "link": "http://arxiv.org/abs/2405.14162v2",
        "abstract": "Efficient categorization of historical documents is crucial for fields such\nas genealogy, legal research, and historical scholarship, where manual\nclassification is impractical for large collections due to its labor-intensive\nand error-prone nature. To address this, we propose a representational learning\nstrategy that integrates semantic segmentation and deep learning models such as\nResNet, CLIP, Document Image Transformer (DiT), and masked auto-encoders (MAE),\nto generate embeddings that capture document features without predefined\nlabels. To the best of our knowledge, we are the first to evaluate embeddings\non fine-grained, unsupervised form classification. To improve these embeddings,\nwe propose to first employ semantic segmentation as a preprocessing step. We\ncontribute two novel datasets$\\unicode{x2014}$the French 19th-century and U.S.\n1950 Census records$\\unicode{x2014}$to demonstrate our approach. Our results\nshow the effectiveness of these various embedding techniques in distinguishing\nsimilar document types and indicate that applying semantic segmentation can\ngreatly improve clustering and classification results. The census datasets are\navailable at https://github.com/tahlor/census_forms",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Taylor Archibald",
            "Tony Martinez"
        ],
        "published": "2024-05-23T04:28:50Z"
    },
    {
        "title": "Self-Taught Recognizer: Toward Unsupervised Adaptation for Speech\n  Foundation Models",
        "link": "http://arxiv.org/abs/2405.14161v1",
        "abstract": "We propose an unsupervised adaptation framework, Self-TAught Recognizer\n(STAR), which leverages unlabeled data to enhance the robustness of automatic\nspeech recognition (ASR) systems in diverse target domains, such as noise and\naccents. STAR is developed for prevalent speech foundation models based on\nTransformer-related architecture with auto-regressive decoding (e.g., Whisper,\nCanary). Specifically, we propose a novel indicator that empirically integrates\nstep-wise information during decoding to assess the token-level quality of\npseudo labels without ground truth, thereby guiding model updates for effective\nunsupervised adaptation. Experimental results show that STAR achieves an\naverage of 13.5% relative reduction in word error rate across 14 target\ndomains, and it sometimes even approaches the upper-bound performance of\nsupervised adaptation. Surprisingly, we also observe that STAR prevents the\nadapted model from the common catastrophic forgetting problem without recalling\nsource-domain data. Furthermore, STAR exhibits high data efficiency that only\nrequires less than one-hour unlabeled data, and seamless generality to\nalternative large speech models and speech translation tasks. Our code aims to\nopen source to the research communities.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Yuchen Hu",
            "Chen Chen",
            "Chao-Han Huck Yang",
            "Chengwei Qin",
            "Pin-Yu Chen",
            "Eng Siong Chng",
            "Chao Zhang"
        ],
        "published": "2024-05-23T04:27:11Z"
    },
    {
        "title": "Super Tiny Language Models",
        "link": "http://arxiv.org/abs/2405.14159v1",
        "abstract": "The rapid advancement of large language models (LLMs) has led to significant\nimprovements in natural language processing but also poses challenges due to\ntheir high computational and energy demands. This paper introduces a series of\nresearch efforts focused on Super Tiny Language Models (STLMs), which aim to\ndeliver high performance with significantly reduced parameter counts. We\nexplore innovative techniques such as byte-level tokenization with a pooling\nmechanism, weight tying, and efficient training strategies. These methods\ncollectively reduce the parameter count by $90\\%$ to $95\\%$ compared to\ntraditional models while maintaining competitive performance. This series of\npapers will explore into various subproblems, including tokenizer-free models,\nself-play based training, and alternative training objectives, targeting models\nwith 10M, 50M, and 100M parameters. Our ultimate goal is to make\nhigh-performance language models more accessible and practical for a wide range\nof applications.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "I.2.7"
        ],
        "authors": [
            "Dylan Hillier",
            "Leon Guertler",
            "Cheston Tan",
            "Palaash Agrawal",
            "Chen Ruirui",
            "Bobby Cheng"
        ],
        "published": "2024-05-23T04:12:49Z"
    },
    {
        "title": "Unveiling the Tapestry of Consistency in Large Vision-Language Models",
        "link": "http://arxiv.org/abs/2405.14156v1",
        "abstract": "Large vision-language models (LVLMs) have recently achieved rapid progress,\nexhibiting great perception and reasoning abilities concerning visual\ninformation. However, when faced with prompts in different sizes of solution\nspaces, LVLMs fail to always give consistent answers regarding the same\nknowledge point. This inconsistency of answers between different solution\nspaces is prevalent in LVLMs and erodes trust. To this end, we provide a\nmulti-modal benchmark ConBench, to intuitively analyze how LVLMs perform when\nthe solution space of a prompt revolves around a knowledge point. Based on the\nConBench tool, we are the first to reveal the tapestry and get the following\nfindings: (1) In the discriminate realm, the larger the solution space of the\nprompt, the lower the accuracy of the answers. (2) Establish the relationship\nbetween the discriminative and generative realms: the accuracy of the\ndiscriminative question type exhibits a strong positive correlation with its\nConsistency with the caption. (3) Compared to open-source models, closed-source\nmodels exhibit a pronounced bias advantage in terms of Consistency. Eventually,\nwe ameliorate the consistency of LVLMs by trigger-based diagnostic refinement,\nindirectly improving the performance of their caption. We hope this paper will\naccelerate the research community in better evaluating their models and\nencourage future advancements in the consistency domain.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yuan Zhang",
            "Fei Xiao",
            "Tao Huang",
            "Chun-Kai Fan",
            "Hongyuan Dong",
            "Jiawen Li",
            "Jiacong Wang",
            "Kuan Cheng",
            "Shanghang Zhang",
            "Haoyuan Guo"
        ],
        "published": "2024-05-23T04:08:23Z"
    },
    {
        "title": "Skip-SCAR: A Modular Approach to ObjectGoal Navigation with Sparsity and\n  Adaptive Skips",
        "link": "http://arxiv.org/abs/2405.14154v1",
        "abstract": "In ObjectGoal navigation (ObjectNav), agents must locate specific objects\nwithin unseen environments, requiring effective observation, prediction, and\nnavigation capabilities. This study found that traditional methods looking only\nfor prediction accuracy often compromise on computational efficiency. To\naddress this, we introduce \"Skip-SCAR,\" a modular framework that enhances\nefficiency by leveraging sparsity and adaptive skips. The SparseConv-Augmented\nResNet (SCAR) at the core of our approach uses sparse and dense feature\nprocessing in parallel, optimizing both the computation and memory footprint.\nOur adaptive skip technique further reduces computational demands by\nselectively bypassing unnecessary semantic segmentation steps based on\nenvironmental constancy. Tested on the HM3D ObjectNav datasets, Skip-SCAR not\nonly minimizes resource use but also sets new performance benchmarks,\ndemonstrating a robust method for improving efficiency and accuracy in robotic\nnavigation tasks.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Yaotian Liu",
            "Jeff Zhang"
        ],
        "published": "2024-05-23T04:03:39Z"
    },
    {
        "title": "A Neighbor-Searching Discrepancy-based Drift Detection Scheme for\n  Learning Evolving Data",
        "link": "http://arxiv.org/abs/2405.14153v1",
        "abstract": "Uncertain changes in data streams present challenges for machine learning\nmodels to dynamically adapt and uphold performance in real-time. Particularly,\nclassification boundary change, also known as real concept drift, is the major\ncause of classification performance deterioration. However, accurately\ndetecting real concept drift remains challenging because the theoretical\nfoundations of existing drift detection methods - two-sample distribution tests\nand monitoring classification error rate, both suffer from inherent limitations\nsuch as the inability to distinguish virtual drift (changes not affecting the\nclassification boundary, will introduce unnecessary model maintenance), limited\nstatistical power, or high computational cost. Furthermore, no existing\ndetection method can provide information on the trend of the drift, which could\nbe invaluable for model maintenance. This work presents a novel real concept\ndrift detection method based on Neighbor-Searching Discrepancy, a new statistic\nthat measures the classification boundary difference between two samples. The\nproposed method is able to detect real concept drift with high accuracy while\nignoring virtual drift. It can also indicate the direction of the\nclassification boundary change by identifying the invasion or retreat of a\ncertain class, which is also an indicator of separability change between\nclasses. A comprehensive evaluation of 11 experiments is conducted, including\nempirical verification of the proposed theory using artificial datasets, and\nexperimental comparisons with commonly used drift handling methods on\nreal-world datasets. The results show that the proposed theory is robust\nagainst a range of distributions and dimensions, and the drift detection method\noutperforms state-of-the-art alternative methods.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Feng Gu",
            "Jie Lu",
            "Zhen Fang",
            "Kun Wang",
            "Guangquan Zhang"
        ],
        "published": "2024-05-23T04:03:36Z"
    },
    {
        "title": "jp-evalb: Robust Alignment-based PARSEVAL Measures",
        "link": "http://arxiv.org/abs/2405.14150v1",
        "abstract": "We introduce an evaluation system designed to compute PARSEVAL measures,\noffering a viable alternative to \\texttt{evalb} commonly used for constituency\nparsing evaluation. The widely used \\texttt{evalb} script has traditionally\nbeen employed for evaluating the accuracy of constituency parsing results,\nalbeit with the requirement for consistent tokenization and sentence\nboundaries. In contrast, our approach, named \\texttt{jp-evalb}, is founded on\nan alignment method. This method aligns sentences and words when discrepancies\narise. It aims to overcome several known issues associated with \\texttt{evalb}\nby utilizing the `jointly preprocessed (JP)' alignment-based method. We\nintroduce a more flexible and adaptive framework, ultimately contributing to a\nmore accurate assessment of constituency parsing performance.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Jungyeul Park",
            "Junrui Wang",
            "Eunkyul Leah Jo",
            "Angela Yoonseo Park"
        ],
        "published": "2024-05-23T03:54:25Z"
    },
    {
        "title": "Real Time Deep Learning Weapon Detection Techniques for Mitigating Lone\n  Wolf Attacks",
        "link": "http://arxiv.org/abs/2405.14148v1",
        "abstract": "Firearm Shootings and stabbings attacks are intense and result in severe\ntrauma and threat to public safety. Technology is needed to prevent lone-wolf\nattacks without human supervision. Hence designing an automatic weapon\ndetection using deep learning, is an optimized solution to localize and detect\nthe presence of weapon objects using Neural Networks. This research focuses on\nboth unified and II-stage object detectors whose resultant model not only\ndetects the presence of weapons but also classifies with respective to its\nweapon classes, including handgun, knife, revolver, and rifle, along with\nperson detection. This research focuses on (You Look Only Once) family and\nFaster RCNN family for model validation and training. Pruning and Ensembling\ntechniques were applied to YOLOv5 to enhance their speed and performance.\nmodels achieve the highest score of 78% with an inference speed of 8.1ms.\nHowever, Faster R-CNN models achieve the highest AP 89%.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Kambhatla Akhila",
            "Khaled R Ahmed"
        ],
        "published": "2024-05-23T03:48:26Z"
    },
    {
        "title": "Minimum number of neurons in fully connected layers of a given neural\n  network (the first approximation)",
        "link": "http://arxiv.org/abs/2405.14147v1",
        "abstract": "This paper presents an algorithm for searching for the minimum number of\nneurons in fully connected layers of an arbitrary network solving given\nproblem, which does not require multiple training of the network with different\nnumber of neurons. The algorithm is based at training the initial wide network\nusing the cross-validation method over at least two folds. Then by using\ntruncated singular value decomposition autoencoder inserted after the studied\nlayer of trained network we search the minimum number of neurons in inference\nonly mode of the network.\n  It is shown that the minimum number of neurons in a fully connected layer\ncould be interpreted not as network hyperparameter associated with the other\nhyperparameters of the network, but as internal (latent) property of the\nsolution, determined by the network architecture, the training dataset, layer\nposition, and the quality metric used. So the minimum number of neurons can be\nestimated for each hidden fully connected layer independently. The proposed\nalgorithm is the first approximation for estimating the minimum number of\nneurons in the layer, since, on the one hand, the algorithm does not guarantee\nthat a neural network with the found number of neurons can be trained to the\nrequired quality, and on the other hand, it searches for the minimum number of\nneurons in a limited class of possible solutions.\n  The solution was tested on several datasets in classification and regression\nproblems.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "68T07",
            "I.2.6"
        ],
        "authors": [
            "Oleg I. Berngardt"
        ],
        "published": "2024-05-23T03:46:07Z"
    },
    {
        "title": "Hyperspectral Image Dataset for Individual Penguin Identification",
        "link": "http://arxiv.org/abs/2405.14146v1",
        "abstract": "Remote individual animal identification is important for food safety, sport,\nand animal conservation. Numerous existing remote individual animal\nidentification studies have focused on RGB images. In this paper, we tackle\nindividual penguin identification using hyperspectral (HS) images. To the best\nof our knowledge, it is the first work to analyze spectral differences between\npenguin individuals using an HS camera. We have constructed a novel penguin HS\nimage dataset, including 990 hyperspectral images of 27 penguins. We\nexperimentally demonstrate that the spectral information of HS image pixels can\nbe used for individual penguin identification. The experimental results show\nthe effectiveness of using HS images for individual penguin identification. The\ndataset and source code are available here:\nhttps://033labcodes.github.io/igrass24_penguin/",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Youta Noboru",
            "Yuko Ozasa",
            "Masayuki Tanaka"
        ],
        "published": "2024-05-23T03:43:13Z"
    },
    {
        "title": "A Single Motor Nano Aerial Vehicle with Novel Peer-to-Peer Communication\n  and Sensing Mechanism",
        "link": "http://arxiv.org/abs/2405.14144v1",
        "abstract": "Communication and position sensing are among the most important capabilities\nfor swarm robots to interact with their peers and perform tasks\ncollaboratively. However, the hardware required to facilitate communication and\nposition sensing is often too complicated, expensive, and bulky to be carried\non swarm robots. Here we present Maneuverable Piccolissimo 3 (MP3), a\nminimalist, single motor drone capable of executing inter-robot communication\nvia infrared light and triangulation-based sensing of relative bearing,\ndistance, and elevation using message arrival time. Thanks to its novel design,\nMP3 can communicate with peers and localize itself using simple components,\nkeeping its size and mass small and making it inherently safe for human\ninteraction. Here we present the hardware and software design of MP3 and\ndemonstrate its capability to localize itself, fly stably and maneuver in the\nenvironment using peer-to-peer communication and sensing.",
        "subjects": [
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Jingxian Wang",
            "Andrew G. Curtis",
            "Mark Yim",
            "Michael Rubenstein"
        ],
        "published": "2024-05-23T03:38:00Z"
    },
    {
        "title": "Imagery as Inquiry: Exploring A Multimodal Dataset for Conversational\n  Recommendation",
        "link": "http://arxiv.org/abs/2405.14142v1",
        "abstract": "We introduce a multimodal dataset where users express preferences through\nimages. These images encompass a broad spectrum of visual expressions ranging\nfrom landscapes to artistic depictions. Users request recommendations for books\nor music that evoke similar feelings to those captured in the images, and\nrecommendations are endorsed by the community through upvotes. This dataset\nsupports two recommendation tasks: title generation and multiple-choice\nselection. Our experiments with large foundation models reveal their\nlimitations in these tasks. Particularly, vision-language models show no\nsignificant advantage over language-only counterparts that use descriptions,\nwhich we hypothesize is due to underutilized visual capabilities. To better\nharness these abilities, we propose the chain-of-imagery prompting, which\nresults in notable improvements. We release our code and datasets.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Se-eun Yoon",
            "Hyunsik Jeon",
            "Julian McAuley"
        ],
        "published": "2024-05-23T03:36:31Z"
    },
    {
        "title": "ViHateT5: Enhancing Hate Speech Detection in Vietnamese With A Unified\n  Text-to-Text Transformer Model",
        "link": "http://arxiv.org/abs/2405.14141v1",
        "abstract": "Recent advancements in hate speech detection (HSD) in Vietnamese have made\nsignificant progress, primarily attributed to the emergence of\ntransformer-based pre-trained language models, particularly those built on the\nBERT architecture. However, the necessity for specialized fine-tuned models has\nresulted in the complexity and fragmentation of developing a multitasking HSD\nsystem. Moreover, most current methodologies focus on fine-tuning general\npre-trained models, primarily trained on formal textual datasets like\nWikipedia, which may not accurately capture human behavior on online platforms.\nIn this research, we introduce ViHateT5, a T5-based model pre-trained on our\nproposed large-scale domain-specific dataset named VOZ-HSD. By harnessing the\npower of a text-to-text architecture, ViHateT5 can tackle multiple tasks using\na unified model and achieve state-of-the-art performance across all standard\nHSD benchmarks in Vietnamese. Our experiments also underscore the significance\nof label distribution in pre-training data on model efficacy. We provide our\nexperimental materials for research purposes, including the VOZ-HSD dataset,\npre-trained checkpoint, the unified HSD-multitask ViHateT5 model, and related\nsource code on GitHub publicly.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Luan Thanh Nguyen"
        ],
        "published": "2024-05-23T03:31:50Z"
    },
    {
        "title": "Contribute to balance, wire in accordance: Emergence of backpropagation\n  from a simple, bio-plausible neuroplasticity rule",
        "link": "http://arxiv.org/abs/2405.14139v1",
        "abstract": "Backpropagation (BP) has been pivotal in advancing machine learning and\nremains essential in computational applications and comparative studies of\nbiological and artificial neural networks. Despite its widespread use, the\nimplementation of BP in the brain remains elusive, and its biological\nplausibility is often questioned due to inherent issues such as the need for\nsymmetry of weights between forward and backward connections, and the\nrequirement of distinct forward and backward phases of computation. Here, we\nintroduce a novel neuroplasticity rule that offers a potential mechanism for\nimplementing BP in the brain. Similar in general form to the classical Hebbian\nrule, this rule is based on the core principles of maintaining the balance of\nexcitatory and inhibitory inputs as well as on retrograde signaling, and\noperates over three progressively slower timescales: neural firing, retrograde\nsignaling, and neural plasticity. We hypothesize that each neuron possesses an\ninternal state, termed credit, in addition to its firing rate. After achieving\nequilibrium in firing rates, neurons receive credits based on their\ncontribution to the E-I balance of postsynaptic neurons through retrograde\nsignaling. As the network's credit distribution stabilizes, connections from\nthose presynaptic neurons are strengthened that significantly contribute to the\nbalance of postsynaptic neurons. We demonstrate mathematically that our\nlearning rule precisely replicates BP in layered neural networks without any\napproximations. Simulations on artificial neural networks reveal that this rule\ninduces varying community structures in networks, depending on the learning\nrate. This simple theoretical framework presents a biologically plausible\nimplementation of BP, with testable assumptions and predictions that may be\nevaluated through biological experiments.",
        "subjects": [
            "q-bio.NC",
            "cs.LG",
            "cs.NE"
        ],
        "authors": [
            "Xinhao Fan",
            "Shreesh P Mysore"
        ],
        "published": "2024-05-23T03:28:52Z"
    },
    {
        "title": "RET-CLIP: A Retinal Image Foundation Model Pre-trained with Clinical\n  Diagnostic Reports",
        "link": "http://arxiv.org/abs/2405.14137v1",
        "abstract": "The Vision-Language Foundation model is increasingly investigated in the\nfields of computer vision and natural language processing, yet its exploration\nin ophthalmology and broader medical applications remains limited. The\nchallenge is the lack of labeled data for the training of foundation model. To\nhandle this issue, a CLIP-style retinal image foundation model is developed in\nthis paper. Our foundation model, RET-CLIP, is specifically trained on a\ndataset of 193,865 patients to extract general features of color fundus\nphotographs (CFPs), employing a tripartite optimization strategy to focus on\nleft eye, right eye, and patient level to reflect real-world clinical\nscenarios. Extensive experiments demonstrate that RET-CLIP outperforms existing\nbenchmarks across eight diverse datasets spanning four critical diagnostic\ncategories: diabetic retinopathy, glaucoma, multiple disease diagnosis, and\nmulti-label classification of multiple diseases, which demonstrate the\nperformance and generality of our foundation model. The sourse code and\npre-trained model are available at https://github.com/sStonemason/RET-CLIP.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jiawei Du",
            "Jia Guo",
            "Weihang Zhang",
            "Shengzhu Yang",
            "Hanruo Liu",
            "Huiqi Li",
            "Ningli Wang"
        ],
        "published": "2024-05-23T03:20:51Z"
    },
    {
        "title": "Efficient Multitask Dense Predictor via Binarization",
        "link": "http://arxiv.org/abs/2405.14136v1",
        "abstract": "Multi-task learning for dense prediction has emerged as a pivotal area in\ncomputer vision, enabling simultaneous processing of diverse yet interrelated\npixel-wise prediction tasks. However, the substantial computational demands of\nstate-of-the-art (SoTA) models often limit their widespread deployment. This\npaper addresses this challenge by introducing network binarization to compress\nresource-intensive multi-task dense predictors. Specifically, our goal is to\nsignificantly accelerate multi-task dense prediction models via Binary Neural\nNetworks (BNNs) while maintaining and even improving model performance at the\nsame time. To reach this goal, we propose a Binary Multi-task Dense Predictor,\nBi-MTDP, and several variants of Bi-MTDP, in which a multi-task dense predictor\nis constructed via specified binarized modules. Our systematical analysis of\nthis predictor reveals that performance drop from binarization is primarily\ncaused by severe information degradation. To address this issue, we introduce a\ndeep information bottleneck layer that enforces representations for downstream\ntasks satisfying Gaussian distribution in forward propagation. Moreover, we\nintroduce a knowledge distillation mechanism to correct the direction of\ninformation flow in backward propagation. Intriguingly, one variant of Bi-MTDP\noutperforms full-precision (FP) multi-task dense prediction SoTAs, ARTC\n(CNN-based) and InvPT (ViT-Based). This result indicates that Bi-MTDP is not\nmerely a naive trade-off between performance and efficiency, but is rather a\nbenefit of the redundant information flow thanks to the multi-task\narchitecture. Code is available at https://github.com/42Shawn/BiMTDP.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yuzhang Shang",
            "Dan Xu",
            "Gaowen Liu",
            "Ramana Rao Kompella",
            "Yan Yan"
        ],
        "published": "2024-05-23T03:19:23Z"
    },
    {
        "title": "Learning Geospatial Region Embedding with Heterogeneous Graph",
        "link": "http://arxiv.org/abs/2405.14135v1",
        "abstract": "Learning effective geospatial embeddings is crucial for a series of\ngeospatial applications such as city analytics and earth monitoring. However,\nlearning comprehensive region representations presents two significant\nchallenges: first, the deficiency of effective intra-region feature\nrepresentation; and second, the difficulty of learning from intricate\ninter-region dependencies. In this paper, we present GeoHG, an effective\nheterogeneous graph structure for learning comprehensive region embeddings for\nvarious downstream tasks. Specifically, we tailor satellite image\nrepresentation learning through geo-entity segmentation and point-of-interest\n(POI) integration for expressive intra-regional features. Furthermore, GeoHG\nunifies informative spatial interdependencies and socio-environmental\nattributes into a powerful heterogeneous graph to encourage explicit modeling\nof higher-order inter-regional relationships. The intra-regional features and\ninter-regional correlations are seamlessly integrated by a model-agnostic graph\nlearning framework for diverse downstream tasks. Extensive experiments\ndemonstrate the effectiveness of GeoHG in geo-prediction tasks compared to\nexisting methods, even under extreme data scarcity (with just 5% of training\ndata). With interpretable region representations, GeoHG exhibits strong\ngeneralization capabilities across regions. We will release code and data upon\npaper notification.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Xingchen Zou",
            "Jiani Huang",
            "Xixuan Hao",
            "Yuhao Yang",
            "Haomin Wen",
            "Yibo Yan",
            "Chao Huang",
            "Yuxuan Liang"
        ],
        "published": "2024-05-23T03:19:02Z"
    },
    {
        "title": "Automated Loss function Search for Class-imbalanced Node Classification",
        "link": "http://arxiv.org/abs/2405.14133v1",
        "abstract": "Class-imbalanced node classification tasks are prevalent in real-world\nscenarios. Due to the uneven distribution of nodes across different classes,\nlearning high-quality node representations remains a challenging endeavor. The\nengineering of loss functions has shown promising potential in addressing this\nissue. It involves the meticulous design of loss functions, utilizing\ninformation about the quantities of nodes in different categories and the\nnetwork's topology to learn unbiased node representations. However, the design\nof these loss functions heavily relies on human expert knowledge and exhibits\nlimited adaptability to specific target tasks. In this paper, we introduce a\nhigh-performance, flexible, and generalizable automated loss function search\nframework to tackle this challenge. Across 15 combinations of graph neural\nnetworks and datasets, our framework achieves a significant improvement in\nperformance compared to state-of-the-art methods. Additionally, we observe that\nhomophily in graph-structured data significantly contributes to the\ntransferability of the proposed framework.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.SC"
        ],
        "authors": [
            "Xinyu Guo",
            "Kai Wu",
            "Xiaoyu Zhang",
            "Jing Liu"
        ],
        "published": "2024-05-23T03:12:49Z"
    },
    {
        "title": "Text-to-Model: Text-Conditioned Neural Network Diffusion for\n  Train-Once-for-All Personalization",
        "link": "http://arxiv.org/abs/2405.14132v1",
        "abstract": "Generative artificial intelligence (GenAI) has made significant progress in\nunderstanding world knowledge and generating content from human languages\nacross various modalities, like text-to-text large language models,\ntext-to-image stable diffusion, and text-to-video Sora. While in this paper, we\ninvestigate the capability of GenAI for text-to-model generation, to see\nwhether GenAI can comprehend hyper-level knowledge embedded within AI itself\nparameters. Specifically, we study a practical scenario termed\ntrain-once-for-all personalization, aiming to generate personalized models for\ndiverse end-users and tasks using text prompts. Inspired by the recent\nemergence of neural network diffusion, we present Tina, a text-conditioned\nneural network diffusion for train-once-for-all personalization. Tina leverages\na diffusion transformer model conditioned on task descriptions embedded using a\nCLIP model. Despite the astronomical number of potential personalized tasks\n(e.g., $1.73\\times10^{13}$), by our design, Tina demonstrates remarkable\nin-distribution and out-of-distribution generalization even trained on small\ndatasets ($\\sim 1000$). We further verify whether and how \\Tina understands\nworld knowledge by analyzing its capabilities under zero-shot/few-shot image\nprompts, different numbers of personalized classes, prompts of natural language\ndescriptions, and predicting unseen entities.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Zexi Li",
            "Lingzhi Gao",
            "Chao Wu"
        ],
        "published": "2024-05-23T03:11:18Z"
    },
    {
        "title": "Statistical Advantages of Perturbing Cosine Router in Sparse Mixture of\n  Experts",
        "link": "http://arxiv.org/abs/2405.14131v1",
        "abstract": "The cosine router in sparse Mixture of Experts (MoE) has recently emerged as\nan attractive alternative to the conventional linear router. Indeed, the cosine\nrouter demonstrates favorable performance in image and language tasks and\nexhibits better ability to mitigate the representation collapse issue, which\noften leads to parameter redundancy and limited representation potentials.\nDespite its empirical success, a comprehensive analysis of the cosine router in\nsparse MoE has been lacking. Considering the least square estimation of the\ncosine routing sparse MoE, we demonstrate that due to the intrinsic interaction\nof the model parameters in the cosine router via some partial differential\nequations, regardless of the structures of the experts, the estimation rates of\nexperts and model parameters can be as slow as $\\mathcal{O}(1/\\log^{\\tau}(n))$\nwhere $\\tau > 0$ is some constant and $n$ is the sample size. Surprisingly,\nthese pessimistic non-polynomial convergence rates can be circumvented by the\nwidely used technique in practice to stabilize the cosine router -- simply\nadding noises to the $\\mathbb{L}_{2}$ norms in the cosine router, which we\nrefer to as \\textit{perturbed cosine router}. Under the strongly identifiable\nsettings of the expert functions, we prove that the estimation rates for both\nthe experts and model parameters under the perturbed cosine routing sparse MoE\nare significantly improved to polynomial rates. Finally, we conduct extensive\nsimulation studies in both synthetic and real data settings to empirically\nvalidate our theoretical results.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Huy Nguyen",
            "Pedram Akbarian",
            "Trang Pham",
            "Trang Nguyen",
            "Shujian Zhang",
            "Nhat Ho"
        ],
        "published": "2024-05-23T03:11:07Z"
    },
    {
        "title": "AlignGPT: Multi-modal Large Language Models with Adaptive Alignment\n  Capability",
        "link": "http://arxiv.org/abs/2405.14129v1",
        "abstract": "Multimodal Large Language Models (MLLMs) are widely regarded as crucial in\nthe exploration of Artificial General Intelligence (AGI). The core of MLLMs\nlies in their capability to achieve cross-modal alignment. To attain this goal,\ncurrent MLLMs typically follow a two-phase training paradigm: the pre-training\nphase and the instruction-tuning phase. Despite their success, there are\nshortcomings in the modeling of alignment capabilities within these models.\nFirstly, during the pre-training phase, the model usually assumes that all\nimage-text pairs are uniformly aligned, but in fact the degree of alignment\nbetween different image-text pairs is inconsistent. Secondly, the instructions\ncurrently used for finetuning incorporate a variety of tasks, different tasks's\ninstructions usually require different levels of alignment capabilities, but\nprevious MLLMs overlook these differentiated alignment needs. To tackle these\nissues, we propose a new multimodal large language model AlignGPT. In the\npre-training stage, instead of treating all image-text pairs equally, we assign\ndifferent levels of alignment capabilities to different image-text pairs. Then,\nin the instruction-tuning phase, we adaptively combine these different levels\nof alignment capabilities to meet the dynamic alignment needs of different\ninstructions. Extensive experimental results show that our model achieves\ncompetitive performance on 12 benchmarks.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Fei Zhao",
            "Taotian Pang",
            "Chunhui Li",
            "Zhen Wu",
            "Junjie Guo",
            "Shangyu Xing",
            "Xinyu Dai"
        ],
        "published": "2024-05-23T03:07:56Z"
    },
    {
        "title": "Transformers for Image-Goal Navigation",
        "link": "http://arxiv.org/abs/2405.14128v2",
        "abstract": "Visual perception and navigation have emerged as major focus areas in the\nfield of embodied artificial intelligence. We consider the task of image-goal\nnavigation, where an agent is tasked to navigate to a goal specified by an\nimage, relying only on images from an onboard camera. This task is particularly\nchallenging since it demands robust scene understanding, goal-oriented planning\nand long-horizon navigation. Most existing approaches typically learn\nnavigation policies reliant on recurrent neural networks trained via online\nreinforcement learning. However, training such policies requires substantial\ncomputational resources and time, and performance of these models is not\nreliable on long-horizon navigation. In this work, we present a generative\nTransformer based model that jointly models image goals, camera observations\nand the robot's past actions to predict future actions. We use state-of-the-art\nperception models and navigation policies to learn robust goal conditioned\npolicies without the need for real-time interaction with the environment. Our\nmodel demonstrates capability in capturing and associating visual information\nacross long time horizons, helping in effective navigation.\n  NOTE: This work was submitted as part of a Master's Capstone Project and must\nbe treated as such. This is still an early work in progress and not the final\nversion.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "cs.LG",
            "I.2.9; I.2.10; I.4.9"
        ],
        "authors": [
            "Nikhilanj Pelluri"
        ],
        "published": "2024-05-23T03:01:32Z"
    },
    {
        "title": "The Disappearance of Timestep Embedding in Modern Time-Dependent Neural\n  Networks",
        "link": "http://arxiv.org/abs/2405.14126v1",
        "abstract": "Dynamical systems are often time-varying, whose modeling requires a function\nthat evolves with respect to time. Recent studies such as the neural ordinary\ndifferential equation proposed a time-dependent neural network, which provides\na neural network varying with respect to time. However, we claim that the\narchitectural choice to build a time-dependent neural network significantly\naffects its time-awareness but still lacks sufficient validation in its current\nstates. In this study, we conduct an in-depth analysis of the architecture of\nmodern time-dependent neural networks. Here, we report a vulnerability of\nvanishing timestep embedding, which disables the time-awareness of a\ntime-dependent neural network. Furthermore, we find that this vulnerability can\nalso be observed in diffusion models because they employ a similar architecture\nthat incorporates timestep embedding to discriminate between different\ntimesteps during a diffusion process. Our analysis provides a detailed\ndescription of this phenomenon as well as several solutions to address the root\ncause. Through experiments on neural ordinary differential equations and\ndiffusion models, we observed that ensuring alive time-awareness via proposed\nsolutions boosted their performance, which implies that their current\nimplementations lack sufficient time-dependency.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Bum Jun Kim",
            "Yoshinobu Kawahara",
            "Sang Woo Kim"
        ],
        "published": "2024-05-23T02:58:23Z"
    },
    {
        "title": "ALI-Agent: Assessing LLMs' Alignment with Human Values via Agent-based\n  Evaluation",
        "link": "http://arxiv.org/abs/2405.14125v2",
        "abstract": "Large Language Models (LLMs) can elicit unintended and even harmful content\nwhen misaligned with human values, posing severe risks to users and society. To\nmitigate these risks, current evaluation benchmarks predominantly employ\nexpert-designed contextual scenarios to assess how well LLMs align with human\nvalues. However, the labor-intensive nature of these benchmarks limits their\ntest scope, hindering their ability to generalize to the extensive variety of\nopen-world use cases and identify rare but crucial long-tail risks.\nAdditionally, these static tests fail to adapt to the rapid evolution of LLMs,\nmaking it hard to evaluate timely alignment issues. To address these\nchallenges, we propose ALI-Agent, an evaluation framework that leverages the\nautonomous abilities of LLM-powered agents to conduct in-depth and adaptive\nalignment assessments. ALI-Agent operates through two principal stages:\nEmulation and Refinement. During the Emulation stage, ALI-Agent automates the\ngeneration of realistic test scenarios. In the Refinement stage, it iteratively\nrefines the scenarios to probe long-tail risks. Specifically, ALI-Agent\nincorporates a memory module to guide test scenario generation, a tool-using\nmodule to reduce human labor in tasks such as evaluating feedback from target\nLLMs, and an action module to refine tests. Extensive experiments across three\naspects of human values--stereotypes, morality, and legality--demonstrate that\nALI-Agent, as a general evaluation framework, effectively identifies model\nmisalignment. Systematic analysis also validates that the generated test\nscenarios represent meaningful use cases, as well as integrate enhanced\nmeasures to probe long-tail risks. Our code is available at\nhttps://github.com/SophieZheng998/ALI-Agent.git",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Jingnan Zheng",
            "Han Wang",
            "An Zhang",
            "Tai D. Nguyen",
            "Jun Sun",
            "Tat-Seng Chua"
        ],
        "published": "2024-05-23T02:57:42Z"
    },
    {
        "title": "AutoCoder: Enhancing Code Large Language Model with\n  \\textsc{AIEV-Instruct}",
        "link": "http://arxiv.org/abs/2405.14906v1",
        "abstract": "We introduce AutoCoder, the first Large Language Model to surpass GPT-4 Turbo\n(April 2024) and GPT-4o in pass@1 on the Human Eval benchmark test\n($\\mathbf{90.9\\%}$ vs. $\\mathbf{90.2\\%}$). In addition, AutoCoder offers a more\nversatile code interpreter compared to GPT-4 Turbo and GPT-4o. It's code\ninterpreter can install external packages instead of limiting to built-in\npackages. AutoCoder's training data is a multi-turn dialogue dataset created by\na system combining agent interaction and external code execution verification,\na method we term \\textbf{\\textsc{AIEV-Instruct}} (Instruction Tuning with\nAgent-Interaction and Execution-Verified). Compared to previous large-scale\ncode dataset generation methods, \\textsc{AIEV-Instruct} reduces dependence on\nproprietary large models and provides execution-validated code dataset. The\ncode and the demo video is available in\n\\url{https://github.com/bin123apple/AutoCoder}.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "authors": [
            "Bin Lei",
            "Yuchen Li",
            "Qiuwu Chen"
        ],
        "published": "2024-05-23T02:53:25Z"
    },
    {
        "title": "Equations for the overlaps of a SIC",
        "link": "http://arxiv.org/abs/2405.14123v1",
        "abstract": "We give a holomorphic quartic polynomial in the overlap variables whose zeros\non the torus are precisely the Weyl-Heisenberg SICs (symmetric informationally\ncomplete positive operator valued measures). By way of comparison, all the\nother known systems of equations that determine a Weyl-Heisenberg SIC involve\nvariables and their complex conjugates. We also give a related interesting\nresult about the powers of the projective Fourier transform of the group G = Z\nd x Z d .",
        "subjects": [
            "cs.IT",
            "math.IT",
            "20F70, 81P15, 81Q10, 81R05"
        ],
        "authors": [
            "Len Bos",
            "Shayne Waldron"
        ],
        "published": "2024-05-23T02:49:57Z"
    },
    {
        "title": "Mixture of Experts Meets Prompt-Based Continual Learning",
        "link": "http://arxiv.org/abs/2405.14124v1",
        "abstract": "Exploiting the power of pre-trained models, prompt-based approaches stand out\ncompared to other continual learning solutions in effectively preventing\ncatastrophic forgetting, even with very few learnable parameters and without\nthe need for a memory buffer. While existing prompt-based continual learning\nmethods excel in leveraging prompts for state-of-the-art performance, they\noften lack a theoretical explanation for the effectiveness of prompting. This\npaper conducts a theoretical analysis to unravel how prompts bestow such\nadvantages in continual learning, thus offering a new perspective on prompt\ndesign. We first show that the attention block of pre-trained models like\nVision Transformers inherently encodes a special mixture of experts\narchitecture, characterized by linear experts and quadratic gating score\nfunctions. This realization drives us to provide a novel view on prefix tuning,\nreframing it as the addition of new task-specific experts, thereby inspiring\nthe design of a novel gating mechanism termed Non-linear Residual Gates\n(NoRGa). Through the incorporation of non-linear activation and residual\nconnection, NoRGa enhances continual learning performance while preserving\nparameter efficiency. The effectiveness of NoRGa is substantiated both\ntheoretically and empirically across diverse benchmarks and pretraining\nparadigms.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Minh Le",
            "An Nguyen",
            "Huy Nguyen",
            "Trang Nguyen",
            "Trang Pham",
            "Linh Van Ngo",
            "Nhat Ho"
        ],
        "published": "2024-05-23T02:49:57Z"
    },
    {
        "title": "Modeling Other Players with Bayesian Beliefs for Games with Incomplete\n  Information",
        "link": "http://arxiv.org/abs/2405.14122v1",
        "abstract": "Bayesian games model interactive decision-making where players have\nincomplete information -- e.g., regarding payoffs and private data on players'\nstrategies and preferences -- and must actively reason and update their belief\nmodels (with regard to such information) using observation and interaction\nhistory. Existing work on counterfactual regret minimization have shown great\nsuccess for games with complete or imperfect information, but not for Bayesian\ngames. To this end, we introduced a new CFR algorithm: Bayesian-CFR and analyze\nits regret bound with respect to Bayesian Nash Equilibria in Bayesian games.\nFirst, we present a method for updating the posterior distribution of beliefs\nabout the game and other players' types. The method uses a kernel-density\nestimate and is shown to converge to the true distribution. Second, we define\nBayesian regret and present a Bayesian-CFR minimization algorithm for computing\nthe Bayesian Nash equilibrium. Finally, we extend this new approach to other\nexisting algorithms, such as Bayesian-CFR+ and Deep Bayesian CFR. Experimental\nresults show that our proposed solutions significantly outperform existing\nmethods in classical Texas Hold'em games.",
        "subjects": [
            "cs.GT"
        ],
        "authors": [
            "Zuyuan Zhang",
            "Mahdi Imani",
            "Tian Lan"
        ],
        "published": "2024-05-23T02:49:05Z"
    },
    {
        "title": "One-shot Active Learning Based on Lewis Weight Sampling for Multiple\n  Deep Models",
        "link": "http://arxiv.org/abs/2405.14121v1",
        "abstract": "Active learning (AL) for multiple target models aims to reduce labeled data\nquerying while effectively training multiple models concurrently. Existing AL\nalgorithms often rely on iterative model training, which can be computationally\nexpensive, particularly for deep models. In this paper, we propose a one-shot\nAL method to address this challenge, which performs all label queries without\nrepeated model training.\n  Specifically, we extract different representations of the same dataset using\ndistinct network backbones, and actively learn the linear prediction layer on\neach representation via an $\\ell_p$-regression formulation. The regression\nproblems are solved approximately by sampling and reweighting the unlabeled\ninstances based on their maximum Lewis weights across the representations. An\nupper bound on the number of samples needed is provided with a rigorous\nanalysis for $p\\in [1, +\\infty)$.\n  Experimental results on 11 benchmarks show that our one-shot approach\nachieves competitive performances with the state-of-the-art AL methods for\nmultiple target models.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Sheng-Jun Huang",
            "Yi Li",
            "Yiming Sun",
            "Ying-Peng Tang"
        ],
        "published": "2024-05-23T02:48:16Z"
    },
    {
        "title": "PuTR: A Pure Transformer for Decoupled and Online Multi-Object Tracking",
        "link": "http://arxiv.org/abs/2405.14119v1",
        "abstract": "Recent advances in Multi-Object Tracking (MOT) have achieved remarkable\nsuccess in short-term association within the decoupled tracking-by-detection\nonline paradigm. However, long-term tracking still remains a challenging task.\nAlthough graph-based approaches can address this issue by modeling trajectories\nas a graph in the decoupled manner, their non-online nature poses obstacles for\nreal-time applications. In this paper, we demonstrate that the trajectory graph\nis a directed acyclic graph, which can be represented by an object sequence\narranged by frame and a binary adjacency matrix. It is a coincidence that the\nbinary matrix matches the attention mask in the Transformer, and the object\nsequence serves exactly as a natural input sequence. Intuitively, we propose\nthat a pure Transformer can naturally unify short- and long-term associations\nin a decoupled and online manner. Our experiments show that a classic\nTransformer architecture naturally suits the association problem and achieves a\nstrong baseline compared to existing foundational methods across four datasets:\nDanceTrack, SportsMOT, MOT17, and MOT20, as well as superior generalizability\nin domain shift. Moreover, the decoupled property also enables efficient\ntraining and inference. This work pioneers a promising Transformer-based\napproach for the MOT task, and provides code to facilitate further research.\nhttps://github.com/chongweiliu/PuTR",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Chongwei Liu",
            "Haojie Li",
            "Zhihui Wang",
            "Rui Xu"
        ],
        "published": "2024-05-23T02:44:46Z"
    },
    {
        "title": "Knowledge Localization: Mission Not Accomplished? Enter Query\n  Localization!",
        "link": "http://arxiv.org/abs/2405.14117v1",
        "abstract": "Large language models (LLMs) store extensive factual knowledge, but the\nmechanisms behind how they store and express this knowledge remain unclear. The\nKnowledge Neuron (KN) thesis is a prominent theory for explaining these\nmechanisms. This theory is based on the knowledge localization (KL) assumption,\nwhich suggests that a fact can be localized to a few knowledge storage units,\nnamely knowledge neurons. However, this assumption may be overly strong\nregarding knowledge storage and neglects knowledge expression mechanisms. Thus,\nwe re-examine the KL assumption and confirm the existence of facts that do not\nadhere to it from both statistical and knowledge modification perspectives.\nFurthermore, we propose the Query Localization (QL) assumption. (1) Query-KN\nMapping: The localization results are associated with the query rather than the\nfact. (2) Dynamic KN Selection: The attention module contributes to the\nselection of KNs for answering a query. Based on this, we further propose the\nConsistency-Aware KN modification method, which improves the performance of\nknowledge modification. We conduct 39 sets of experiments, along with\nadditional visualization experiments, to rigorously validate our conclusions.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Yuheng Chen",
            "Pengfei Cao",
            "Yubo Chen",
            "Kang Liu",
            "Jun Zhao"
        ],
        "published": "2024-05-23T02:44:12Z"
    },
    {
        "title": "Learning Multimodal Confidence for Intention Recognition in Human-Robot\n  Interaction",
        "link": "http://arxiv.org/abs/2405.14116v1",
        "abstract": "The rapid development of collaborative robotics has provided a new\npossibility of helping the elderly who has difficulties in daily life, allowing\nrobots to operate according to specific intentions. However, efficient\nhuman-robot cooperation requires natural, accurate and reliable intention\nrecognition in shared environments. The current paramount challenge for this is\nreducing the uncertainty of multimodal fused intention to be recognized and\nreasoning adaptively a more reliable result despite current interactive\ncondition. In this work we propose a novel learning-based multimodal fusion\nframework Batch Multimodal Confidence Learning for Opinion Pool (BMCLOP). Our\napproach combines Bayesian multimodal fusion method and batch confidence\nlearning algorithm to improve accuracy, uncertainty reduction and success rate\ngiven the interactive condition. In particular, the generic and practical\nmultimodal intention recognition framework can be easily extended further. Our\ndesired assistive scenarios consider three modalities gestures, speech and\ngaze, all of which produce categorical distributions over all the finite\nintentions. The proposed method is validated with a six-DoF robot through\nextensive experiments and exhibits high performance compared to baselines.",
        "subjects": [
            "cs.RO",
            "cs.HC",
            "cs.LG"
        ],
        "authors": [
            "Xiyuan Zhao",
            "Huijun Li",
            "Tianyuan Miao",
            "Xianyi Zhu",
            "Zhikai Wei",
            "Aiguo Song"
        ],
        "published": "2024-05-23T02:43:31Z"
    },
    {
        "title": "Configuring Data Augmentations to Reduce Variance Shift in Positional\n  Embedding of Vision Transformers",
        "link": "http://arxiv.org/abs/2405.14115v1",
        "abstract": "Vision transformers (ViTs) have demonstrated remarkable performance in a\nvariety of vision tasks. Despite their promising capabilities, training a ViT\nrequires a large amount of diverse data. Several studies empirically found that\nusing rich data augmentations, such as Mixup, Cutmix, and random erasing, is\ncritical to the successful training of ViTs. Now, the use of rich data\naugmentations has become a standard practice in the current state. However, we\nreport a vulnerability to this practice: Certain data augmentations such as\nMixup cause a variance shift in the positional embedding of ViT, which has been\na hidden factor that degrades the performance of ViT during the test phase. We\nclaim that achieving a stable effect from positional embedding requires a\nspecific condition on the image, which is often broken for the current data\naugmentation methods. We provide a detailed analysis of this problem as well as\nthe correct configuration for these data augmentations to remove the side\neffects of variance shift. Experiments showed that adopting our guidelines\nimproves the performance of ViTs compared with the current configuration of\ndata augmentations.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Bum Jun Kim",
            "Sang Woo Kim"
        ],
        "published": "2024-05-23T02:42:32Z"
    },
    {
        "title": "Offline Reinforcement Learning from Datasets with Structured\n  Non-Stationarity",
        "link": "http://arxiv.org/abs/2405.14114v1",
        "abstract": "Current Reinforcement Learning (RL) is often limited by the large amount of\ndata needed to learn a successful policy. Offline RL aims to solve this issue\nby using transitions collected by a different behavior policy. We address a\nnovel Offline RL problem setting in which, while collecting the dataset, the\ntransition and reward functions gradually change between episodes but stay\nconstant within each episode. We propose a method based on Contrastive\nPredictive Coding that identifies this non-stationarity in the offline dataset,\naccounts for it when training a policy, and predicts it during evaluation. We\nanalyze our proposed method and show that it performs well in simple continuous\ncontrol tasks and challenging, high-dimensional locomotion tasks. We show that\nour method often achieves the oracle performance and performs better than\nbaselines.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Johannes Ackermann",
            "Takayuki Osa",
            "Masashi Sugiyama"
        ],
        "published": "2024-05-23T02:41:36Z"
    },
    {
        "title": "Multi-modality Regional Alignment Network for Covid X-Ray Survival\n  Prediction and Report Generation",
        "link": "http://arxiv.org/abs/2405.14113v1",
        "abstract": "In response to the worldwide COVID-19 pandemic, advanced automated\ntechnologies have emerged as valuable tools to aid healthcare professionals in\nmanaging an increased workload by improving radiology report generation and\nprognostic analysis. This study proposes Multi-modality Regional Alignment\nNetwork (MRANet), an explainable model for radiology report generation and\nsurvival prediction that focuses on high-risk regions. By learning spatial\ncorrelation in the detector, MRANet visually grounds region-specific\ndescriptions, providing robust anatomical regions with a completion strategy.\nThe visual features of each region are embedded using a novel survival\nattention mechanism, offering spatially and risk-aware features for sentence\nencoding while maintaining global coherence across tasks. A cross LLMs\nalignment is employed to enhance the image-to-text transfer process, resulting\nin sentences rich with clinical detail and improved explainability for\nradiologist. Multi-center experiments validate both MRANet's overall\nperformance and each module's composition within the model, encouraging further\nadvancements in radiology report generation research emphasizing clinical\ninterpretation and trustworthiness in AI models applied to medical studies. The\ncode is available at https://github.com/zzs95/MRANet.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Zhusi Zhong",
            "Jie Li",
            "John Sollee",
            "Scott Collins",
            "Harrison Bai",
            "Paul Zhang",
            "Terrence Healey",
            "Michael Atalay",
            "Xinbo Gao",
            "Zhicheng Jiao"
        ],
        "published": "2024-05-23T02:41:08Z"
    },
    {
        "title": "Improving Generalization of Deep Neural Networks by Optimum Shifting",
        "link": "http://arxiv.org/abs/2405.14111v1",
        "abstract": "Recent studies showed that the generalization of neural networks is\ncorrelated with the sharpness of the loss landscape, and flat minima suggests a\nbetter generalization ability than sharp minima. In this paper, we propose a\nnovel method called \\emph{optimum shifting}, which changes the parameters of a\nneural network from a sharp minimum to a flatter one while maintaining the same\ntraining loss value. Our method is based on the observation that when the input\nand output of a neural network are fixed, the matrix multiplications within the\nnetwork can be treated as systems of under-determined linear equations,\nenabling adjustment of parameters in the solution space, which can be simply\naccomplished by solving a constrained optimization problem. Furthermore, we\nintroduce a practical stochastic optimum shifting technique utilizing the\nNeural Collapse theory to reduce computational costs and provide more degrees\nof freedom for optimum shifting. Extensive experiments (including\nclassification and detection) with various deep neural network architectures on\nbenchmark datasets demonstrate the effectiveness of our method.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yuyan Zhou",
            "Ye Li",
            "Lei Feng",
            "Sheng-Jun Huang"
        ],
        "published": "2024-05-23T02:31:55Z"
    },
    {
        "title": "Regularity-Conforming Neural Networks (ReCoNNs) for solving Partial\n  Differential Equations",
        "link": "http://arxiv.org/abs/2405.14110v1",
        "abstract": "Whilst the Universal Approximation Theorem guarantees the existence of\napproximations to Sobolev functions -- the natural function spaces for PDEs --\nby Neural Networks (NNs) of sufficient size, low-regularity solutions may lead\nto poor approximations in practice. For example, classical fully-connected\nfeed-forward NNs fail to approximate continuous functions whose gradient is\ndiscontinuous when employing strong formulations like in Physics Informed\nNeural Networks (PINNs). In this article, we propose the use of\nregularity-conforming neural networks, where a priori information on the\nregularity of solutions to PDEs can be employed to construct proper\narchitectures. We illustrate the potential of such architectures via a\ntwo-dimensional (2D) transmission problem, where the solution may admit\ndiscontinuities in the gradient across interfaces, as well as power-like\nsingularities at certain points. In particular, we formulate the weak\ntransmission problem in a PINNs-like strong formulation with interface and\ncontinuity conditions. Such architectures are partially explainable;\ndiscontinuities are explicitly described, allowing the introduction of novel\nterms into the loss function. We demonstrate via several model problems in one\nand two dimensions the advantages of using regularity-conforming architectures\nin contrast to classical architectures. The ideas presented in this article\neasily extend to problems in higher dimensions.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Jamie M. Taylor",
            "David Pardo",
            "Judit Muñoz-Matute"
        ],
        "published": "2024-05-23T02:31:53Z"
    },
    {
        "title": "Deep Learning for Protein-Ligand Docking: Are We There Yet?",
        "link": "http://arxiv.org/abs/2405.14108v1",
        "abstract": "The effects of ligand binding on protein structures and their in vivo\nfunctions carry numerous implications for modern biomedical research and\nbiotechnology development efforts such as drug discovery. Although several deep\nlearning (DL) methods and benchmarks designed for protein-ligand docking have\nrecently been introduced, to date no prior works have systematically studied\nthe behavior of docking methods within the practical context of (1) predicted\n(apo) protein structures, (2) multiple ligands concurrently binding to a given\ntarget protein, and (3) having no prior knowledge of binding pockets. To enable\na deeper understanding of docking methods' real-world utility, we introduce\nPoseBench, the first comprehensive benchmark for practical protein-ligand\ndocking. PoseBench enables researchers to rigorously and systematically\nevaluate DL docking methods for apo-to-holo protein-ligand docking and\nprotein-ligand structure generation using both single and multi-ligand\nbenchmark datasets, the latter of which we introduce for the first time to the\nDL community. Empirically, using PoseBench, we find that all recent DL docking\nmethods but one fail to generalize to multi-ligand protein targets and also\nthat template-based docking algorithms perform equally well or better for\nmulti-ligand docking as recent single-ligand DL docking methods, suggesting\nareas of improvement for future work. Code, data, tutorials, and benchmark\nresults are available at https://github.com/BioinfoMachineLearning/PoseBench.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.BM",
            "q-bio.QM",
            "I.2.1; J.3"
        ],
        "authors": [
            "Alex Morehead",
            "Nabin Giri",
            "Jian Liu",
            "Jianlin Cheng"
        ],
        "published": "2024-05-23T02:27:39Z"
    },
    {
        "title": "Towards Feature Engineering with Human and AI's Knowledge: Understanding\n  Data Science Practitioners' Perceptions in Human&AI-Assisted Feature\n  Engineering Design",
        "link": "http://dx.doi.org/10.1145/3643834.3661517",
        "abstract": "As AI technology continues to advance, the importance of human-AI\ncollaboration becomes increasingly evident, with numerous studies exploring its\npotential in various fields. One vital field is data science, including feature\nengineering (FE), where both human ingenuity and AI capabilities play pivotal\nroles. Despite the existence of AI-generated recommendations for FE, there\nremains a limited understanding of how to effectively integrate and utilize\nhumans' and AI's knowledge. To address this gap, we design a readily-usable\nprototype, human\\&AI-assisted FE in Jupyter notebooks. It harnesses the\nstrengths of humans and AI to provide feature suggestions to users, seamlessly\nintegrating these recommendations into practical workflows. Using the prototype\nas a research probe, we conducted an exploratory study to gain valuable\ninsights into data science practitioners' perceptions, usage patterns, and\ntheir potential needs when presented with feature suggestions from both humans\nand AI. Through qualitative analysis, we discovered that the Creator of the\nfeature (i.e., AI or human) significantly influences users' feature selection,\nand the semantic clarity of the suggested feature greatly impacts its adoption\nrate. Furthermore, our findings indicate that users perceive both differences\nand complementarity between features generated by humans and those generated by\nAI. Lastly, based on our study results, we derived a set of design\nrecommendations for future human&AI FE design. Our findings show the\ncollaborative potential between humans and AI in the field of FE.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Qian Zhu",
            "Dakuo Wang",
            "Shuai Ma",
            "April Yi Wang",
            "Zixin Chen",
            "Udayan Khurana",
            "Xiaojuan Ma"
        ],
        "published": "2024-05-23T02:26:14Z"
    },
    {
        "title": "Nearly Tight Black-Box Auditing of Differentially Private Machine\n  Learning",
        "link": "http://arxiv.org/abs/2405.14106v1",
        "abstract": "This paper presents a nearly tight audit of the Differentially Private\nStochastic Gradient Descent (DP-SGD) algorithm in the black-box model. Our\nauditing procedure empirically estimates the privacy leakage from DP-SGD using\nmembership inference attacks; unlike prior work, the estimates are appreciably\nclose to the theoretical DP bounds. The main intuition is to craft worst-case\ninitial model parameters, as DP-SGD's privacy analysis is agnostic to the\nchoice of the initial model parameters. For models trained with theoretical\n$\\varepsilon=10.0$ on MNIST and CIFAR-10, our auditing procedure yields\nempirical estimates of $7.21$ and $6.95$, respectively, on 1,000-record samples\nand $6.48$ and $4.96$ on the full datasets. By contrast, previous work achieved\ntight audits only in stronger (i.e., less realistic) white-box models that\nallow the adversary to access the model's inner parameters and insert arbitrary\ngradients. Our auditing procedure can be used to detect bugs and DP violations\nmore easily and offers valuable insight into how the privacy analysis of DP-SGD\ncan be further improved.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "authors": [
            "Meenatchi Sundaram Muthu Selva Annamalai",
            "Emiliano De Cristofaro"
        ],
        "published": "2024-05-23T02:24:52Z"
    },
    {
        "title": "Distributed Speculative Inference of Large Language Models",
        "link": "http://arxiv.org/abs/2405.14105v1",
        "abstract": "Accelerating the inference of large language models (LLMs) is an important\nchallenge in artificial intelligence. This paper introduces distributed\nspeculative inference (DSI), a novel distributed inference algorithm that is\nprovably faster than speculative inference (SI) [leviathan2023fast,\nchen2023accelerating, miao2023specinfer] and traditional autoregressive\ninference (non-SI). Like other SI algorithms, DSI works on frozen LLMs,\nrequiring no training or architectural modifications, and it preserves the\ntarget distribution.\n  Prior studies on SI have demonstrated empirical speedups (compared to non-SI)\nbut require a fast and accurate drafter LLM. In practice, off-the-shelf LLMs\noften do not have matching drafters that are sufficiently fast and accurate. We\nshow a gap: SI gets slower than non-SI when using slower or less accurate\ndrafters. We close this gap by proving that DSI is faster than both SI and\nnon-SI given any drafters. By orchestrating multiple instances of the target\nand drafters, DSI is not only faster than SI but also supports LLMs that cannot\nbe accelerated with SI.\n  Our simulations show speedups of off-the-shelf LLMs in realistic settings:\nDSI is 1.29-1.92x faster than SI.",
        "subjects": [
            "cs.DC",
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Nadav Timor",
            "Jonathan Mamou",
            "Daniel Korat",
            "Moshe Berchansky",
            "Oren Pereg",
            "Moshe Wasserblat",
            "Tomer Galanti",
            "Michal Gordon",
            "David Harel"
        ],
        "published": "2024-05-23T02:14:17Z"
    },
    {
        "title": "Online Self-Preferring Language Models",
        "link": "http://arxiv.org/abs/2405.14103v1",
        "abstract": "Aligning with human preference datasets has been critical to the success of\nlarge language models (LLMs). Reinforcement learning from human feedback (RLHF)\nemploys a costly reward model to provide feedback for on-policy sampling\nresponses. Recently, offline methods that directly fit responses with binary\npreferences in the dataset have emerged as alternatives. However, existing\nmethods do not explicitly model preference strength information, which is\ncrucial for distinguishing different response pairs. To overcome this\nlimitation, we propose Online Self-Preferring (OSP) language models to learn\nfrom self-generated response pairs and self-judged preference strengths. For\neach prompt and corresponding self-generated responses, we introduce a ranked\npairing method to construct multiple response pairs with preference strength\ninformation. We then propose the soft-preference cross-entropy loss to leverage\nsuch information. Empirically, we demonstrate that leveraging preference\nstrength is crucial for avoiding overfitting and enhancing alignment\nperformance. OSP achieves state-of-the-art alignment performance across various\nmetrics in two widely used human preference datasets. OSP is\nparameter-efficient and more robust than the dominant online method, RLHF when\nlimited offline data are available and generalizing to out-of-domain tasks.\nMoreover, OSP language models established by LLMs with proficiency in\nself-preferring can efficiently self-improve without external supervision.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yuanzhao Zhai",
            "Zhuo Zhang",
            "Kele Xu",
            "Hanyang Peng",
            "Yue Yu",
            "Dawei Feng",
            "Cheng Yang",
            "Bo Ding",
            "Huaimin Wang"
        ],
        "published": "2024-05-23T02:13:34Z"
    },
    {
        "title": "Enhancing Image Layout Control with Loss-Guided Diffusion Models",
        "link": "http://arxiv.org/abs/2405.14101v1",
        "abstract": "Diffusion models are a powerful class of generative models capable of\nproducing high-quality images from pure noise. In particular, conditional\ndiffusion models allow one to specify the contents of the desired image using a\nsimple text prompt. Conditioning on a text prompt alone, however, does not\nallow for fine-grained control over the composition and layout of the final\nimage, which instead depends closely on the initial noise distribution. While\nmost methods which introduce spatial constraints (e.g., bounding boxes) require\nfine-tuning, a smaller and more recent subset of these methods are\ntraining-free. They are applicable whenever the prompt influences the model\nthrough an attention mechanism, and generally fall into one of two categories.\nThe first entails modifying the cross-attention maps of specific tokens\ndirectly to enhance the signal in certain regions of the image. The second\nworks by defining a loss function over the cross-attention maps, and using the\ngradient of this loss to guide the latent. While previous work explores these\nas alternative strategies, we provide an interpretation for these methods which\nhighlights their complimentary features, and demonstrate that it is possible to\nobtain superior performance when both methods are used in concert.",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ],
        "authors": [
            "Zakaria Patel",
            "Kirill Serkh"
        ],
        "published": "2024-05-23T02:08:44Z"
    },
    {
        "title": "Automatic Differentiation is Essential in Training Neural Networks for\n  Solving Differential Equations",
        "link": "http://arxiv.org/abs/2405.14099v1",
        "abstract": "Neural network-based approaches have recently shown significant promise in\nsolving partial differential equations (PDEs) in science and engineering,\nespecially in scenarios featuring complex domains or the incorporation of\nempirical data. One advantage of the neural network method for PDEs lies in its\nautomatic differentiation (AD), which necessitates only the sample points\nthemselves, unlike traditional finite difference (FD) approximations that\nrequire nearby local points to compute derivatives. In this paper, we\nquantitatively demonstrate the advantage of AD in training neural networks. The\nconcept of truncated entropy is introduced to characterize the training\nproperty. Specifically, through comprehensive experimental and theoretical\nanalyses conducted on random feature models and two-layer neural networks, we\ndiscover that the defined truncated entropy serves as a reliable metric for\nquantifying the residual loss of random feature models and the training speed\nof neural networks for both AD and FD methods. Our experimental and theoretical\nanalyses demonstrate that, from a training perspective, AD outperforms FD in\nsolving partial differential equations.",
        "subjects": [
            "cs.LG",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Chuqi Chen",
            "Yahong Yang",
            "Yang Xiang",
            "Wenrui Hao"
        ],
        "published": "2024-05-23T02:01:05Z"
    },
    {
        "title": "A continuous perspective on the inertial corrected primal-dual proximal\n  splitting",
        "link": "http://arxiv.org/abs/2405.14098v1",
        "abstract": "We give a continuous perspective on the Inertial Corrected Primal-Dual\nProximal Splitting (IC-PDPS) proposed by Valkonen ({\\it SIAM J. Optim.}, 30(2):\n1391--1420, 2020) for solving saddle-point problems. The algorithm possesses\nnonergodic convergence rate and admits a tight preconditioned proximal point\nformulation which involves both inertia and additional correction. Based on new\nunderstandings on the relation between the discrete step size and rescaling\neffect, we rebuild IC-PDPS as a semi-implicit Euler scheme with respect to its\niterative sequences and integrated parameters. This leads to two novel\nsecond-order ordinary differential equation (ODE) models that are equivalent\nunder proper time transformation, and also provides an alternative\ninterpretation from the continuous point of view. Besides, we present the\nconvergence analysis of the Lagrangian gap along the continuous trajectory by\nusing proper Lyapunov functions.",
        "subjects": [
            "math.OC",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Hao Luo"
        ],
        "published": "2024-05-23T01:58:32Z"
    },
    {
        "title": "Newton Informed Neural Operator for Computing Multiple Solutions of\n  Nonlinear Partials Differential Equations",
        "link": "http://arxiv.org/abs/2405.14096v1",
        "abstract": "Solving nonlinear partial differential equations (PDEs) with multiple\nsolutions using neural networks has found widespread applications in various\nfields such as physics, biology, and engineering. However, classical neural\nnetwork methods for solving nonlinear PDEs, such as Physics-Informed Neural\nNetworks (PINN), Deep Ritz methods, and DeepONet, often encounter challenges\nwhen confronted with the presence of multiple solutions inherent in the\nnonlinear problem. These methods may encounter ill-posedness issues. In this\npaper, we propose a novel approach called the Newton Informed Neural Operator,\nwhich builds upon existing neural network techniques to tackle nonlinearities.\nOur method combines classical Newton methods, addressing well-posed problems,\nand efficiently learns multiple solutions in a single learning process while\nrequiring fewer supervised data points compared to existing neural network\nmethods.",
        "subjects": [
            "cs.LG",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Wenrui Hao",
            "Xinliang Liu",
            "Yahong Yang"
        ],
        "published": "2024-05-23T01:52:54Z"
    },
    {
        "title": "Attending to Topological Spaces: The Cellular Transformer",
        "link": "http://arxiv.org/abs/2405.14094v1",
        "abstract": "Topological Deep Learning seeks to enhance the predictive performance of\nneural network models by harnessing topological structures in input data.\nTopological neural networks operate on spaces such as cell complexes and\nhypergraphs, that can be seen as generalizations of graphs. In this work, we\nintroduce the Cellular Transformer (CT), a novel architecture that generalizes\ngraph-based transformers to cell complexes. First, we propose a new formulation\nof the usual self- and cross-attention mechanisms, tailored to leverage\nincidence relations in cell complexes, e.g., edge-face and node-edge relations.\nAdditionally, we propose a set of topological positional encodings specifically\ndesigned for cell complexes. By transforming three graph datasets into cell\ncomplex datasets, our experiments reveal that CT not only achieves\nstate-of-the-art performance, but it does so without the need for more complex\nenhancements such as virtual nodes, in-domain structural encodings, or graph\nrewiring.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV",
            "math.AT",
            "stat.ML"
        ],
        "authors": [
            "Rubén Ballester",
            "Pablo Hernández-García",
            "Mathilde Papillon",
            "Claudio Battiloro",
            "Nina Miolane",
            "Tolga Birdal",
            "Carles Casacuberta",
            "Sergio Escalera",
            "Mustafa Hajij"
        ],
        "published": "2024-05-23T01:48:32Z"
    },
    {
        "title": "A Survey on Vision-Language-Action Models for Embodied AI",
        "link": "http://arxiv.org/abs/2405.14093v1",
        "abstract": "Deep learning has demonstrated remarkable success across many domains,\nincluding computer vision, natural language processing, and reinforcement\nlearning. Representative artificial neural networks in these fields span\nconvolutional neural networks, Transformers, and deep Q-networks. Built upon\nunimodal neural networks, numerous multi-modal models have been introduced to\naddress a range of tasks such as visual question answering, image captioning,\nand speech recognition. The rise of instruction-following robotic policies in\nembodied AI has spurred the development of a novel category of multi-modal\nmodels known as vision-language-action models (VLAs). Their multi-modality\ncapability has become a foundational element in robot learning. Various methods\nhave been proposed to enhance traits such as versatility, dexterity, and\ngeneralizability. Some models focus on refining specific components through\npretraining. Others aim to develop control policies adept at predicting\nlow-level actions. Certain VLAs serve as high-level task planners capable of\ndecomposing long-horizon tasks into executable subtasks. Over the past few\nyears, a myriad of VLAs have emerged, reflecting the rapid advancement of\nembodied AI. Therefore, it is imperative to capture the evolving landscape\nthrough a comprehensive survey.",
        "subjects": [
            "cs.RO",
            "cs.CL",
            "cs.CV"
        ],
        "authors": [
            "Yueen Ma",
            "Zixing Song",
            "Yuzheng Zhuang",
            "Jianye Hao",
            "Irwin King"
        ],
        "published": "2024-05-23T01:43:54Z"
    },
    {
        "title": "Large Language Models Can Self-Correct with Minimal Effort",
        "link": "http://arxiv.org/abs/2405.14092v1",
        "abstract": "Intrinsic self-correct was a method that instructed large language models\n(LLMs) to verify and correct their responses without external feedback.\nUnfortunately, the study concluded that the LLMs could not self-correct\nreasoning yet. We find that a simple yet effective verification method can\nunleash inherent capabilities of the LLMs. That is to mask a key condition in\nthe question, add the current response to construct a verification question,\nand predict the condition to verify the response. The condition can be an\nentity in an open-domain question or a numeric value in a math question, which\nrequires minimal effort (via prompting) to identify. We propose an iterative\nverify-then-correct framework to progressively identify and correct (probably)\nfalse responses, named ProCo. We conduct experiments on three reasoning tasks.\nOn average, ProCo, with GPT-3.5-Turbo as the backend LLM, yields $+6.8$ exact\nmatch on four open-domain question answering datasets, $+14.1$ accuracy on\nthree arithmetic reasoning datasets, and $+9.6$ accuracy on a commonsense\nreasoning dataset, compared to Self-Correct.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Zhenyu Wu",
            "Qingkai Zeng",
            "Zhihan Zhang",
            "Zhaoxuan Tan",
            "Chao Shen",
            "Meng Jiang"
        ],
        "published": "2024-05-23T01:43:45Z"
    },
    {
        "title": "Actively Learning Combinatorial Optimization Using a Membership Oracle",
        "link": "http://arxiv.org/abs/2405.14090v1",
        "abstract": "We consider solving a combinatorial optimization problem with an unknown\nlinear constraint using a membership oracle that, given a solution, determines\nwhether it is feasible or infeasible with absolute certainty. The goal of the\ndecision maker is to find the best possible solution subject to a budget on the\nnumber of oracle calls. Inspired by active learning based on Support Vector\nMachines (SVMs), we adapt a classical framework in order to solve the problem\nby learning and exploiting a surrogate linear constraint. The resulting new\nframework includes training a linear separator on the labeled points and\nselecting new points to be labeled, which is achieved by applying a sampling\nstrategy and solving a 0-1 integer linear program. Following the active\nlearning literature, one can consider using SVM as a linear classifier and the\ninformation-based sampling strategy known as Simple margin. We improve on both\nsides: we propose an alternative sampling strategy based on mixed-integer\nquadratic programming and a linear separation method inspired by an algorithm\nfor convex optimization in the oracle model. We conduct experiments on the pure\nknapsack problem and on a college study plan problem from the literature to\nshow how different linear separation methods and sampling strategies influence\nthe quality of the results in terms of objective value.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Rosario Messana",
            "Rui Chen",
            "Andrea Lodi"
        ],
        "published": "2024-05-23T01:34:21Z"
    },
    {
        "title": "Improved Canonicalization for Model Agnostic Equivariance",
        "link": "http://arxiv.org/abs/2405.14089v1",
        "abstract": "This work introduces a novel approach to achieving architecture-agnostic\nequivariance in deep learning, particularly addressing the limitations of\ntraditional equivariant architectures and the inefficiencies of the existing\narchitecture-agnostic methods. Building equivariant models using traditional\nmethods requires designing equivariant versions of existing models and training\nthem from scratch, a process that is both impractical and resource-intensive.\nCanonicalization has emerged as a promising alternative for inducing\nequivariance without altering model architecture, but it suffers from the need\nfor highly expressive and expensive equivariant networks to learn canonical\norientations accurately. We propose a new method that employs any\nnon-equivariant network for canonicalization. Our method uses contrastive\nlearning to efficiently learn a unique canonical orientation and offers more\nflexibility for the choice of canonicalization network. We empirically\ndemonstrate that this approach outperforms existing methods in achieving\nequivariance for large pretrained models and significantly speeds up the\ncanonicalization process, making it up to 2 times faster.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Siba Smarak Panigrahi",
            "Arnab Kumar Mondal"
        ],
        "published": "2024-05-23T01:34:12Z"
    },
    {
        "title": "High-dimensional Learning with Noisy Labels",
        "link": "http://arxiv.org/abs/2405.14088v1",
        "abstract": "This paper provides theoretical insights into high-dimensional binary\nclassification with class-conditional noisy labels. Specifically, we study the\nbehavior of a linear classifier with a label noisiness aware loss function,\nwhen both the dimension of data $p$ and the sample size $n$ are large and\ncomparable. Relying on random matrix theory by supposing a Gaussian mixture\ndata model, the performance of the linear classifier when $p,n\\to \\infty$ is\nshown to converge towards a limit, involving scalar statistics of the data.\nImportantly, our findings show that the low-dimensional intuitions to handle\nlabel noise do not hold in high-dimension, in the sense that the optimal\nclassifier in low-dimension dramatically fails in high-dimension. Based on our\nderivations, we design an optimized method that is shown to be provably more\nefficient in handling noisy labels in high dimensions. Our theoretical\nconclusions are further confirmed by experiments on real datasets, where we\nshow that our optimized approach outperforms the considered baselines.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Aymane El Firdoussi",
            "Mohamed El Amine Seddik"
        ],
        "published": "2024-05-23T01:32:25Z"
    },
    {
        "title": "Structural Entities Extraction and Patient Indications Incorporation for\n  Chest X-ray Report Generation",
        "link": "http://arxiv.org/abs/2405.14905v1",
        "abstract": "The automated generation of imaging reports proves invaluable in alleviating\nthe workload of radiologists. A clinically applicable reports generation\nalgorithm should demonstrate its effectiveness in producing reports that\naccurately describe radiology findings and attend to patient-specific\nindications. In this paper, we introduce a novel method, \\textbf{S}tructural\n\\textbf{E}ntities extraction and patient indications \\textbf{I}ncorporation\n(SEI) for chest X-ray report generation. Specifically, we employ a structural\nentities extraction (SEE) approach to eliminate presentation-style vocabulary\nin reports and improve the quality of factual entity sequences. This reduces\nthe noise in the following cross-modal alignment module by aligning X-ray\nimages with factual entity sequences in reports, thereby enhancing the\nprecision of cross-modal alignment and further aiding the model in\ngradient-free retrieval of similar historical cases. Subsequently, we propose a\ncross-modal fusion network to integrate information from X-ray images, similar\nhistorical cases, and patient-specific indications. This process allows the\ntext decoder to attend to discriminative features of X-ray images, assimilate\nhistorical diagnostic information from similar cases, and understand the\nexamination intention of patients. This, in turn, assists in triggering the\ntext decoder to produce high-quality reports. Experiments conducted on\nMIMIC-CXR validate the superiority of SEI over state-of-the-art approaches on\nboth natural language generation and clinical efficacy metrics.",
        "subjects": [
            "eess.IV",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Kang Liu",
            "Zhuoqi Ma",
            "Xiaolu Kang",
            "Zhusi Zhong",
            "Zhicheng Jiao",
            "Grayson Baird",
            "Harrison Bai",
            "Qiguang Miao"
        ],
        "published": "2024-05-23T01:29:47Z"
    },
    {
        "title": "Exclusively Penalized Q-learning for Offline Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.14082v1",
        "abstract": "Constraint-based offline reinforcement learning (RL) involves policy\nconstraints or imposing penalties on the value function to mitigate\noverestimation errors caused by distributional shift. This paper focuses on a\nlimitation in existing offline RL methods with penalized value function,\nindicating the potential for underestimation bias due to unnecessary bias\nintroduced in the value function. To address this concern, we propose\nExclusively Penalized Q-learning (EPQ), which reduces estimation bias in the\nvalue function by selectively penalizing states that are prone to inducing\nestimation errors. Numerical results show that our method significantly reduces\nunderestimation bias and improves performance in various offline control tasks\ncompared to other offline RL methods",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Junghyuk Yeom",
            "Yonghyeon Jo",
            "Jungmo Kim",
            "Sanghyeon Lee",
            "Seungyul Han"
        ],
        "published": "2024-05-23T01:06:05Z"
    },
    {
        "title": "Advancing Transportation Mode Share Analysis with Built Environment:\n  Deep Hybrid Models with Urban Road Network",
        "link": "http://arxiv.org/abs/2405.14079v1",
        "abstract": "Transportation mode share analysis is important to various real-world\ntransportation tasks as it helps researchers understand the travel behaviors\nand choices of passengers. A typical example is the prediction of communities'\ntravel mode share by accounting for their sociodemographics like age, income,\netc., and travel modes' attributes (e.g. travel cost and time). However, there\nexist only limited efforts in integrating the structure of the urban built\nenvironment, e.g., road networks, into the mode share models to capture the\nimpacts of the built environment. This task usually requires manual feature\nengineering or prior knowledge of the urban design features. In this study, we\npropose deep hybrid models (DHM), which directly combine road networks and\nsociodemographic features as inputs for travel mode share analysis. Using graph\nembedding (GE) techniques, we enhance travel demand models with a more powerful\nrepresentation of urban structures. In experiments of mode share prediction in\nChicago, results demonstrate that DHM can provide valuable spatial insights\ninto the sociodemographic structure, improving the performance of travel demand\nmodels in estimating different mode shares at the city level. Specifically, DHM\nimproves the results by more than 20\\% while retaining the interpretation power\nof the choice models, demonstrating its superiority in interpretability,\nprediction accuracy, and geographical insights.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Dingyi Zhuang",
            "Qingyi Wang",
            "Yunhan Zheng",
            "Xiaotong Guo",
            "Shenhao Wang",
            "Haris N Koutsopoulos",
            "Jinhua Zhao"
        ],
        "published": "2024-05-23T00:59:00Z"
    },
    {
        "title": "A finite time analysis of distributed Q-learning",
        "link": "http://arxiv.org/abs/2405.14078v1",
        "abstract": "Multi-agent reinforcement learning (MARL) has witnessed a remarkable surge in\ninterest, fueled by the empirical success achieved in applications of\nsingle-agent reinforcement learning (RL). In this study, we consider a\ndistributed Q-learning scenario, wherein a number of agents cooperatively solve\na sequential decision making problem without access to the central reward\nfunction which is an average of the local rewards. In particular, we study\nfinite-time analysis of a distributed Q-learning algorithm, and provide a new\nsample complexity result of $\\tilde{\\mathcal{O}}\\left(\n\\min\\left\\{\\frac{1}{\\epsilon^2}\\frac{t_{\\text{mix}}}{(1-\\gamma)^6 d_{\\min}^4 }\n,\\frac{1}{\\epsilon}\\frac{\\sqrt{|\\gS||\\gA|}}{(1-\\sigma_2(\\boldsymbol{W}))(1-\\gamma)^4\nd_{\\min}^3} \\right\\}\\right)$ under tabular lookup",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.MA"
        ],
        "authors": [
            "Han-Dong Lim",
            "Donghwan Lee"
        ],
        "published": "2024-05-23T00:52:38Z"
    },
    {
        "title": "Learning to Transform Dynamically for Better Adversarial Transferability",
        "link": "http://arxiv.org/abs/2405.14077v1",
        "abstract": "Adversarial examples, crafted by adding perturbations imperceptible to\nhumans, can deceive neural networks. Recent studies identify the adversarial\ntransferability across various models, \\textit{i.e.}, the cross-model attack\nability of adversarial samples. To enhance such adversarial transferability,\nexisting input transformation-based methods diversify input data with\ntransformation augmentation. However, their effectiveness is limited by the\nfinite number of available transformations. In our study, we introduce a novel\napproach named Learning to Transform (L2T). L2T increases the diversity of\ntransformed images by selecting the optimal combination of operations from a\npool of candidates, consequently improving adversarial transferability. We\nconceptualize the selection of optimal transformation combinations as a\ntrajectory optimization problem and employ a reinforcement learning strategy to\neffectively solve the problem. Comprehensive experiments on the ImageNet\ndataset, as well as practical tests with Google Vision and GPT-4V, reveal that\nL2T surpasses current methodologies in enhancing adversarial transferability,\nthereby confirming its effectiveness and practical significance. The code is\navailable at https://github.com/RongyiZhu/L2T.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Rongyi Zhu",
            "Zeliang Zhang",
            "Susan Liang",
            "Zhuo Liu",
            "Chenliang Xu"
        ],
        "published": "2024-05-23T00:46:53Z"
    },
    {
        "title": "$T^2$ of Thoughts: Temperature Tree Elicits Reasoning in Large Language\n  Models",
        "link": "http://arxiv.org/abs/2405.14075v1",
        "abstract": "Large Language Models (LLMs) have emerged as powerful tools in artificial\nintelligence, especially in complex decision-making scenarios, but their static\nproblem-solving strategies often limit their adaptability to dynamic\nenvironments. We explore the enhancement of reasoning capabilities in LLMs\nthrough Temperature Tree ($T^2$) prompting via Particle Swarm Optimization,\ntermed as $T^2$ of Thoughts ($T^2oT$). The primary focus is on enhancing\ndecision-making processes by dynamically adjusting search parameters,\nespecially temperature, to improve accuracy without increasing computational\ndemands. We empirically validate that our hybrid $T^2oT$ approach yields\nenhancements in, single-solution accuracy, multi-solution generation and text\ngeneration quality. Our findings suggest that while dynamic search depth\nadjustments based on temperature can yield mixed results, a fixed search depth,\nwhen coupled with adaptive capabilities of $T^2oT$, provides a more reliable\nand versatile problem-solving strategy. This work highlights the potential for\nfuture explorations in optimizing algorithmic interactions with foundational\nlanguage models, particularly illustrated by our development for the Game of 24\nand Creative Writing tasks.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Chengkun Cai",
            "Xu Zhao",
            "Yucheng Du",
            "Haoliang Liu",
            "Lei Li"
        ],
        "published": "2024-05-23T00:40:43Z"
    },
    {
        "title": "Enhancing Critical Infrastructure Cybersecurity: Collaborative DNN\n  Synthesis in the Cloud Continuum",
        "link": "http://arxiv.org/abs/2405.14074v1",
        "abstract": "Researchers are exploring the integration of IoT and the cloud continuum,\ntogether with AI to enhance the cost-effectiveness and efficiency of critical\ninfrastructure (CI) systems. This integration, however, increases\nsusceptibility of CI systems to cyberattacks, potentially leading to\ndisruptions like power outages, oil spills, or even a nuclear mishap. CI\nsystems are inherently complex and generate vast amounts of heterogeneous and\nhigh-dimensional data, which crosses many trust boundaries in their journey\nacross the IoT, edge, and cloud domains over the communication network\ninterconnecting them. As a result, they face expanded attack surfaces. To\nensure the security of these dataflows, researchers have used deep neural\nnetwork models with encouraging results. Nevertheless, two important challenges\nthat remain are tackling the computational complexity of these models to reduce\nconvergence times and preserving the accuracy of detection of\nintegrity-violating intrusions. In this paper, we propose an innovative\napproach that utilizes trained edge cloud models to synthesize central cloud\nmodels, effectively overcoming these challenges. We empirically validate the\neffectiveness of the proposed method by comparing it with traditional\ncentralized and distributed techniques, including a contemporary collaborative\ntechnique.",
        "subjects": [
            "cs.CR",
            "cs.NI"
        ],
        "authors": [
            "Lav Gupta",
            "Guoxing Yao"
        ],
        "published": "2024-05-23T00:36:45Z"
    },
    {
        "title": "PEAC: Unsupervised Pre-training for Cross-Embodiment Reinforcement\n  Learning",
        "link": "http://arxiv.org/abs/2405.14073v1",
        "abstract": "Designing generalizable agents capable of adapting to diverse embodiments has\nachieved significant attention in Reinforcement Learning (RL), which is\ncritical for deploying RL agents in various real-world applications. Previous\nCross-Embodiment RL approaches have focused on transferring knowledge across\nembodiments within specific tasks. These methods often result in knowledge\ntightly coupled with those tasks and fail to adequately capture the distinct\ncharacteristics of different embodiments. To address this limitation, we\nintroduce the notion of Cross-Embodiment Unsupervised RL (CEURL), which\nleverages unsupervised learning to enable agents to acquire embodiment-aware\nand task-agnostic knowledge through online interactions within reward-free\nenvironments. We formulate CEURL as a novel Controlled Embodiment Markov\nDecision Process (CE-MDP) and systematically analyze CEURL's pre-training\nobjectives under CE-MDP. Based on these analyses, we develop a novel algorithm\nPre-trained Embodiment-Aware Control (PEAC) for handling CEURL, incorporating\nan intrinsic reward function specifically designed for cross-embodiment\npre-training. PEAC not only provides an intuitive optimization strategy for\ncross-embodiment pre-training but also can integrate flexibly with existing\nunsupervised RL methods, facilitating cross-embodiment exploration and skill\ndiscovery. Extensive experiments in both simulated (e.g., DMC and Robosuite)\nand real-world environments (e.g., legged locomotion) demonstrate that PEAC\nsignificantly improves adaptation performance and cross-embodiment\ngeneralization, demonstrating its effectiveness in overcoming the unique\nchallenges of CEURL.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Chengyang Ying",
            "Zhongkai Hao",
            "Xinning Zhou",
            "Xuezhou Xu",
            "Hang Su",
            "Xingxing Zhang",
            "Jun Zhu"
        ],
        "published": "2024-05-23T00:35:23Z"
    }
]