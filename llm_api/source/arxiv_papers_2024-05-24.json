[
    {
        "title": "FastDrag: Manipulate Anything in One Step",
        "link": "http://arxiv.org/abs/2405.15769v1",
        "abstract": "Drag-based image editing using generative models provides precise control\nover image contents, enabling users to manipulate anything in an image with a\nfew clicks. However, prevailing methods typically adopt $n$-step iterations for\nlatent semantic optimization to achieve drag-based image editing, which is\ntime-consuming and limits practical applications. In this paper, we introduce a\nnovel one-step drag-based image editing method, i.e., FastDrag, to accelerate\nthe editing process. Central to our approach is a latent warpage function\n(LWF), which simulates the behavior of a stretched material to adjust the\nlocation of individual pixels within the latent space. This innovation achieves\none-step latent semantic optimization and hence significantly promotes editing\nspeeds. Meanwhile, null regions emerging after applying LWF are addressed by\nour proposed bilateral nearest neighbor interpolation (BNNI) strategy. This\nstrategy interpolates these regions using similar features from neighboring\nareas, thus enhancing semantic integrity. Additionally, a\nconsistency-preserving strategy is introduced to maintain the consistency\nbetween the edited and original images by adopting semantic information from\nthe original image, saved as key and value pairs in self-attention module\nduring diffusion inversion, to guide the diffusion sampling. Our FastDrag is\nvalidated on the DragBench dataset, demonstrating substantial improvements in\nprocessing time over existing methods, while achieving enhanced editing\nperformance.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xuanjia Zhao",
            "Jian Guan",
            "Congyi Fan",
            "Dongli Xu",
            "Youtian Lin",
            "Haiwei Pan",
            "Pengming Feng"
        ],
        "published": "2024-05-24T17:59:26Z"
    },
    {
        "title": "Canonical Variates in Wasserstein Metric Space",
        "link": "http://arxiv.org/abs/2405.15768v1",
        "abstract": "In this paper, we address the classification of instances each characterized\nnot by a singular point, but by a distribution on a vector space. We employ the\nWasserstein metric to measure distances between distributions, which are then\nused by distance-based classification algorithms such as k-nearest neighbors,\nk-means, and pseudo-mixture modeling. Central to our investigation is dimension\nreduction within the Wasserstein metric space to enhance classification\naccuracy. We introduce a novel approach grounded in the principle of maximizing\nFisher's ratio, defined as the quotient of between-class variation to\nwithin-class variation. The directions in which this ratio is maximized are\ntermed discriminant coordinates or canonical variates axes. In practice, we\ndefine both between-class and within-class variations as the average squared\ndistances between pairs of instances, with the pairs either belonging to the\nsame class or to different classes. This ratio optimization is achieved through\nan iterative algorithm, which alternates between optimal transport and\nmaximization steps within the vector space. We conduct empirical studies to\nassess the algorithm's convergence and, through experimental validation,\ndemonstrate that our dimension reduction technique substantially enhances\nclassification performance. Moreover, our method outperforms well-established\nalgorithms that operate on vector representations derived from distributional\ndata. It also exhibits robustness against variations in the distributional\nrepresentations of data clouds.",
        "subjects": [
            "stat.ML",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Jia Li",
            "Lin Lin"
        ],
        "published": "2024-05-24T17:59:21Z"
    },
    {
        "title": "Improved Particle Approximation Error for Mean Field Neural Networks",
        "link": "http://arxiv.org/abs/2405.15767v1",
        "abstract": "Mean-field Langevin dynamics (MFLD) minimizes an entropy-regularized\nnonlinear convex functional defined over the space of probability\ndistributions. MFLD has gained attention due to its connection with noisy\ngradient descent for mean-field two-layer neural networks. Unlike standard\nLangevin dynamics, the nonlinearity of the objective functional induces\nparticle interactions, necessitating multiple particles to approximate the\ndynamics in a finite-particle setting. Recent works (Chen et al., 2022; Suzuki\net al., 2023b) have demonstrated the uniform-in-time propagation of chaos for\nMFLD, showing that the gap between the particle system and its mean-field limit\nuniformly shrinks over time as the number of particles increases. In this work,\nwe improve the dependence on logarithmic Sobolev inequality (LSI) constants in\ntheir particle approximation errors, which can exponentially deteriorate with\nthe regularization coefficient. Specifically, we establish an LSI-constant-free\nparticle approximation error concerning the objective gap by leveraging the\nproblem structure in risk minimization. As the application, we demonstrate\nimproved convergence of MFLD, sampling guarantee for the mean-field stationary\ndistribution, and uniform-in-time Wasserstein propagation of chaos in terms of\nparticle complexity.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Atsushi Nitanda"
        ],
        "published": "2024-05-24T17:59:06Z"
    },
    {
        "title": "Enhancing Adverse Drug Event Detection with Multimodal Dataset: Corpus\n  Creation and Model Development",
        "link": "http://arxiv.org/abs/2405.15766v1",
        "abstract": "The mining of adverse drug events (ADEs) is pivotal in pharmacovigilance,\nenhancing patient safety by identifying potential risks associated with\nmedications, facilitating early detection of adverse events, and guiding\nregulatory decision-making. Traditional ADE detection methods are reliable but\nslow, not easily adaptable to large-scale operations, and offer limited\ninformation. With the exponential increase in data sources like social media\ncontent, biomedical literature, and Electronic Medical Records (EMR),\nextracting relevant ADE-related information from these unstructured texts is\nimperative. Previous ADE mining studies have focused on text-based\nmethodologies, overlooking visual cues, limiting contextual comprehension, and\nhindering accurate interpretation. To address this gap, we present a MultiModal\nAdverse Drug Event (MMADE) detection dataset, merging ADE-related textual\ninformation with visual aids. Additionally, we introduce a framework that\nleverages the capabilities of LLMs and VLMs for ADE detection by generating\ndetailed descriptions of medical images depicting ADEs, aiding healthcare\nprofessionals in visually identifying adverse events. Using our MMADE dataset,\nwe showcase the significance of integrating visual cues from images to enhance\noverall performance. This approach holds promise for patient safety, ADE\nawareness, and healthcare accessibility, paving the way for further exploration\nin personalized healthcare.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "authors": [
            "Pranab Sahoo",
            "Ayush Kumar Singh",
            "Sriparna Saha",
            "Aman Chadha",
            "Samrat Mondal"
        ],
        "published": "2024-05-24T17:58:42Z"
    },
    {
        "title": "Scaling Laws for Discriminative Classification in Large Language Models",
        "link": "http://arxiv.org/abs/2405.15765v1",
        "abstract": "Modern large language models (LLMs) represent a paradigm shift in what can\nplausibly be expected of machine learning models. The fact that LLMs can\neffectively generate sensible answers to a diverse range of queries suggests\nthat they would be useful in customer support applications. While powerful,\nLLMs have been observed to be prone to hallucination which unfortunately makes\ntheir near term use in customer support applications challenging. To address\nthis issue we present a system that allows us to use an LLM to augment our\ncustomer support advocates by re-framing the language modeling task as a\ndiscriminative classification task. In this framing, we seek to present the\ntop-K best template responses for a customer support advocate to use when\nresponding to a customer. We present the result of both offline and online\nexperiments where we observed offline gains and statistically significant\nonline lifts for our experimental system. Along the way, we present observed\nscaling curves for validation loss and top-K accuracy, resulted from model\nparameter ablation studies. We close by discussing the space of trade-offs with\nrespect to model size, latency, and accuracy as well as and suggesting future\napplications to explore.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Dean Wyatte",
            "Fatemeh Tahmasbi",
            "Ming Li",
            "Thomas Markovich"
        ],
        "published": "2024-05-24T17:58:38Z"
    },
    {
        "title": "FreeMotion: A Unified Framework for Number-free Text-to-Motion Synthesis",
        "link": "http://arxiv.org/abs/2405.15763v1",
        "abstract": "Text-to-motion synthesis is a crucial task in computer vision. Existing\nmethods are limited in their universality, as they are tailored for\nsingle-person or two-person scenarios and can not be applied to generate\nmotions for more individuals. To achieve the number-free motion synthesis, this\npaper reconsiders motion generation and proposes to unify the single and\nmulti-person motion by the conditional motion distribution. Furthermore, a\ngeneration module and an interaction module are designed for our FreeMotion\nframework to decouple the process of conditional motion generation and finally\nsupport the number-free motion synthesis. Besides, based on our framework, the\ncurrent single-person motion spatial control method could be seamlessly\nintegrated, achieving precise control of multi-person motion. Extensive\nexperiments demonstrate the superior performance of our method and our\ncapability to infer single and multi-human motions simultaneously.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ke Fan",
            "Junshu Tang",
            "Weijian Cao",
            "Ran Yi",
            "Moran Li",
            "Jingyu Gong",
            "Jiangning Zhang",
            "Yabiao Wang",
            "Chengjie Wang",
            "Lizhuang Ma"
        ],
        "published": "2024-05-24T17:57:57Z"
    },
    {
        "title": "Sliding-Mode Nash Equilibrium Seeking for a Quadratic Duopoly Game",
        "link": "http://arxiv.org/abs/2405.15762v1",
        "abstract": "This paper introduces a new method to achieve stable convergence to Nash\nequilibrium in duopoly noncooperative games. Inspired by the recent fixed-time\nNash Equilibrium seeking (NES) as well as prescribed-time extremum seeking (ES)\nand source seeking schemes, our approach employs a distributed sliding mode\ncontrol (SMC) scheme, integrating extremum seeking with sinusoidal perturbation\nsignals to estimate the pseudogradients of quadratic payoff functions. Notably,\nthis is the first attempt to address noncooperative games without relying on\nmodels, combining classical extremum seeking with relay components instead of\nproportional control laws. We prove finite-time convergence of the closed-loop\naverage system to Nash equilibrium using stability analysis techniques such as\ntime-scaling, Lyapunov's direct method, and averaging theory for discontinuous\nsystems. Additionally, we quantify the size of residual sets around the Nash\nequilibrium and validate our theoretical results through simulations.",
        "subjects": [
            "math.OC",
            "cs.SY",
            "eess.SY",
            "91Axx, 91A05, 91A10, 93-XX, 93B52, 93C40, 93D30"
        ],
        "authors": [
            "Victor Hugo Pereira Rodrigues",
            "Tiago Roux Oliveira",
            "Miroslav Krstić",
            "Tamer Başar"
        ],
        "published": "2024-05-24T17:57:52Z"
    },
    {
        "title": "GPT is Not an Annotator: The Necessity of Human Annotation in Fairness\n  Benchmark Construction",
        "link": "http://arxiv.org/abs/2405.15760v1",
        "abstract": "Social biases in LLMs are usually measured via bias benchmark datasets.\nCurrent benchmarks have limitations in scope, grounding, quality, and human\neffort required. Previous work has shown success with a community-sourced,\nrather than crowd-sourced, approach to benchmark development. However, this\nwork still required considerable effort from annotators with relevant lived\nexperience. This paper explores whether an LLM (specifically, GPT-3.5-Turbo)\ncan assist with the task of developing a bias benchmark dataset from responses\nto an open-ended community survey. We also extend the previous work to a new\ncommunity and set of biases: the Jewish community and antisemitism. Our\nanalysis shows that GPT-3.5-Turbo has poor performance on this annotation task\nand produces unacceptable quality issues in its output. Thus, we conclude that\nGPT-3.5-Turbo is not an appropriate substitute for human annotation in\nsensitive tasks related to social biases, and that its use actually negates\nmany of the benefits of community-sourcing bias benchmarks.",
        "subjects": [
            "cs.CL",
            "cs.CY",
            "I.2.7; K.4.2"
        ],
        "authors": [
            "Virginia K. Felkner",
            "Jennifer A. Thompson",
            "Jonathan May"
        ],
        "published": "2024-05-24T17:56:03Z"
    },
    {
        "title": "InstructAvatar: Text-Guided Emotion and Motion Control for Avatar\n  Generation",
        "link": "http://arxiv.org/abs/2405.15758v1",
        "abstract": "Recent talking avatar generation models have made strides in achieving\nrealistic and accurate lip synchronization with the audio, but often fall short\nin controlling and conveying detailed expressions and emotions of the avatar,\nmaking the generated video less vivid and controllable. In this paper, we\npropose a novel text-guided approach for generating emotionally expressive 2D\navatars, offering fine-grained control, improved interactivity, and\ngeneralizability to the resulting video. Our framework, named InstructAvatar,\nleverages a natural language interface to control the emotion as well as the\nfacial motion of avatars. Technically, we design an automatic annotation\npipeline to construct an instruction-video paired training dataset, equipped\nwith a novel two-branch diffusion-based generator to predict avatars with audio\nand text instructions at the same time. Experimental results demonstrate that\nInstructAvatar produces results that align well with both conditions, and\noutperforms existing methods in fine-grained emotion control, lip-sync quality,\nand naturalness. Our project page is\nhttps://wangyuchi369.github.io/InstructAvatar/.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Yuchi Wang",
            "Junliang Guo",
            "Jianhong Bai",
            "Runyi Yu",
            "Tianyu He",
            "Xu Tan",
            "Xu Sun",
            "Jiang Bian"
        ],
        "published": "2024-05-24T17:53:54Z"
    },
    {
        "title": "Looking Backward: Streaming Video-to-Video Translation with Feature\n  Banks",
        "link": "http://arxiv.org/abs/2405.15757v1",
        "abstract": "This paper introduces StreamV2V, a diffusion model that achieves real-time\nstreaming video-to-video (V2V) translation with user prompts. Unlike prior V2V\nmethods using batches to process limited frames, we opt to process frames in a\nstreaming fashion, to support unlimited frames. At the heart of StreamV2V lies\na backward-looking principle that relates the present to the past. This is\nrealized by maintaining a feature bank, which archives information from past\nframes. For incoming frames, StreamV2V extends self-attention to include banked\nkeys and values and directly fuses similar past features into the output. The\nfeature bank is continually updated by merging stored and new features, making\nit compact but informative. StreamV2V stands out for its adaptability and\nefficiency, seamlessly integrating with image diffusion models without\nfine-tuning. It can run 20 FPS on one A100 GPU, being 15x, 46x, 108x, and 158x\nfaster than FlowVid, CoDeF, Rerender, and TokenFlow, respectively. Quantitative\nmetrics and user studies confirm StreamV2V's exceptional ability to maintain\ntemporal consistency.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "authors": [
            "Feng Liang",
            "Akio Kodaira",
            "Chenfeng Xu",
            "Masayoshi Tomizuka",
            "Kurt Keutzer",
            "Diana Marculescu"
        ],
        "published": "2024-05-24T17:53:06Z"
    },
    {
        "title": "Sparse Expansion and Neuronal Disentanglement",
        "link": "http://arxiv.org/abs/2405.15756v1",
        "abstract": "We show how to improve the inference efficiency of an LLM by expanding it\ninto a mixture of sparse experts, where each expert is a copy of the original\nweights, one-shot pruned for a specific cluster of input values. We call this\napproach $\\textit{Sparse Expansion}$. We show that, for models such as Llama 2\n70B, as we increase the number of sparse experts, Sparse Expansion outperforms\nall other one-shot sparsification approaches for the same inference FLOP budget\nper token, and that this gap grows as sparsity increases, leading to inference\nspeedups.\n  But why? To answer this, we provide strong evidence that the mixture of\nsparse experts is effectively $\\textit{disentangling}$ the input-output\nrelationship of every individual neuron across clusters of inputs.\nSpecifically, sparse experts approximate the dense neuron output distribution\nwith fewer weights by decomposing the distribution into a collection of simpler\nones, each with a separate sparse dot product covering it. Interestingly, we\nshow that the Wasserstein distance between a neuron's output distribution and a\nGaussian distribution is an indicator of its entanglement level and\ncontribution to the accuracy of the model. Every layer of an LLM has a fraction\nof highly entangled Wasserstein neurons, and model performance suffers more\nwhen these are sparsified as opposed to others.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Shashata Sawmya",
            "Linghao Kong",
            "Ilia Markov",
            "Dan Alistarh",
            "Nir Shavit"
        ],
        "published": "2024-05-24T17:51:39Z"
    },
    {
        "title": "ETTrack: Enhanced Temporal Motion Predictor for Multi-Object Tracking",
        "link": "http://arxiv.org/abs/2405.15755v1",
        "abstract": "Many Multi-Object Tracking (MOT) approaches exploit motion information to\nassociate all the detected objects across frames. However, many methods that\nrely on filtering-based algorithms, such as the Kalman Filter, often work well\nin linear motion scenarios but struggle to accurately predict the locations of\nobjects undergoing complex and non-linear movements. To tackle these scenarios,\nwe propose a motion-based MOT approach with an enhanced temporal motion\npredictor, ETTrack. Specifically, the motion predictor integrates a transformer\nmodel and a Temporal Convolutional Network (TCN) to capture short-term and\nlong-term motion patterns, and it predicts the future motion of individual\nobjects based on the historical motion information. Additionally, we propose a\nnovel Momentum Correction Loss function that provides additional information\nregarding the motion direction of objects during training. This allows the\nmotion predictor rapidly adapt to motion variations and more accurately predict\nfuture motion. Our experimental results demonstrate that ETTrack achieves a\ncompetitive performance compared with state-of-the-art trackers on DanceTrack\nand SportsMOT, scoring 56.4% and 74.4% in HOTA metrics, respectively.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xudong Han",
            "Nobuyuki Oishi",
            "Yueying Tian",
            "Elif Ucurum",
            "Rupert Young",
            "Chris Chatwin",
            "Philip Birch"
        ],
        "published": "2024-05-24T17:51:33Z"
    },
    {
        "title": "Score-based generative models are provably robust: an uncertainty\n  quantification perspective",
        "link": "http://arxiv.org/abs/2405.15754v1",
        "abstract": "Through an uncertainty quantification (UQ) perspective, we show that\nscore-based generative models (SGMs) are provably robust to the multiple\nsources of error in practical implementation. Our primary tool is the\nWasserstein uncertainty propagation (WUP) theorem, a model-form UQ bound that\ndescribes how the $L^2$ error from learning the score function propagates to a\nWasserstein-1 ($\\mathbf{d}_1$) ball around the true data distribution under the\nevolution of the Fokker-Planck equation. We show how errors due to (a) finite\nsample approximation, (b) early stopping, (c) score-matching objective choice,\n(d) score function parametrization expressiveness, and (e) reference\ndistribution choice, impact the quality of the generative model in terms of a\n$\\mathbf{d}_1$ bound of computable quantities. The WUP theorem relies on\nBernstein estimates for Hamilton-Jacobi-Bellman partial differential equations\n(PDE) and the regularizing properties of diffusion processes. Specifically, PDE\nregularity theory shows that stochasticity is the key mechanism ensuring SGM\nalgorithms are provably robust. The WUP theorem applies to integral probability\nmetrics beyond $\\mathbf{d}_1$, such as the total variation distance and the\nmaximum mean discrepancy. Sample complexity and generalization bounds in\n$\\mathbf{d}_1$ follow directly from the WUP theorem. Our approach requires\nminimal assumptions, is agnostic to the manifold hypothesis and avoids absolute\ncontinuity assumptions for the target distribution. Additionally, our results\nclarify the trade-offs among multiple error sources in SGMs.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.ST",
            "stat.TH"
        ],
        "authors": [
            "Nikiforos Mimikos-Stamatopoulos",
            "Benjamin J. Zhang",
            "Markos A. Katsoulakis"
        ],
        "published": "2024-05-24T17:50:17Z"
    },
    {
        "title": "Data Reconstruction: When You See It and When You Don't",
        "link": "http://arxiv.org/abs/2405.15753v1",
        "abstract": "We revisit the fundamental question of formally defining what constitutes a\nreconstruction attack. While often clear from the context, our exploration\nreveals that a precise definition is much more nuanced than it appears, to the\nextent that a single all-encompassing definition may not exist. Thus, we employ\na different strategy and aim to \"sandwich\" the concept of reconstruction\nattacks by addressing two complementing questions: (i) What conditions\nguarantee that a given system is protected against such attacks? (ii) Under\nwhat circumstances does a given attack clearly indicate that a system is not\nprotected? More specifically,\n  * We introduce a new definitional paradigm -- Narcissus Resiliency -- to\nformulate a security definition for protection against reconstruction attacks.\nThis paradigm has a self-referential nature that enables it to circumvent\nshortcomings of previously studied notions of security. Furthermore, as a\nside-effect, we demonstrate that Narcissus resiliency captures as special cases\nmultiple well-studied concepts including differential privacy and other\nsecurity notions of one-way functions and encryption schemes.\n  * We formulate a link between reconstruction attacks and Kolmogorov\ncomplexity. This allows us to put forward a criterion for evaluating when such\nattacks are convincingly successful.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Edith Cohen",
            "Haim Kaplan",
            "Yishay Mansour",
            "Shay Moran",
            "Kobbi Nissim",
            "Uri Stemmer",
            "Eliad Tsfadia"
        ],
        "published": "2024-05-24T17:49:34Z"
    },
    {
        "title": "Analysis of Marketed versus Not-marketed Mobile App Releases",
        "link": "http://arxiv.org/abs/2405.15752v1",
        "abstract": "Market and user characteristics of mobile apps make their release management\ndifferent from proprietary software products and web services. Despite the\nwealth of information regarding users' feedback on an app, an in-depth analysis\nof app releases is difficult due to the inconsistency and uncertainty of the\ninformation. To better understand and potentially improve app release\nprocesses, we analyze major, minor, and patch releases for releases following\nsemantic versioning. In particular, we were interested in finding out the\ndifference between marketed and not-marketed releases. Our results show that,\nin general, major, minor, and patch releases have significant differences in\nthe release cycle duration, nature, and change velocity. We also observed that\nthere is a significant difference between marketed and non-marketed mobile app\nreleases in terms of cycle duration, nature and the extent of changes, and the\nnumber of opened and closed issues.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Maleknaz Nayebi",
            "Homayoon Farrahi",
            "Guenther Ruhe"
        ],
        "published": "2024-05-24T17:48:49Z"
    },
    {
        "title": "Filtered Corpus Training (FiCT) Shows that Language Models can\n  Generalize from Indirect Evidence",
        "link": "http://arxiv.org/abs/2405.15750v1",
        "abstract": "This paper introduces Filtered Corpus Training, a method that trains language\nmodels (LMs) on corpora with certain linguistic constructions filtered out from\nthe training data, and uses it to measure the ability of LMs to perform\nlinguistic generalization on the basis of indirect evidence. We apply the\nmethod to both LSTM and Transformer LMs (of roughly comparable size),\ndeveloping filtered corpora that target a wide range of linguistic phenomena.\nOur results show that while transformers are better qua LMs (as measured by\nperplexity), both models perform equally and surprisingly well on linguistic\ngeneralization measures, suggesting that they are capable of generalizing from\nindirect evidence.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Abhinav Patil",
            "Jaap Jumelet",
            "Yu Ying Chiu",
            "Andy Lapastora",
            "Peter Shen",
            "Lexie Wang",
            "Clevis Willrich",
            "Shane Steinert-Threlkeld"
        ],
        "published": "2024-05-24T17:47:20Z"
    },
    {
        "title": "Collaborative Access Control for IoT -- A Blockchain Approach",
        "link": "http://arxiv.org/abs/2405.15749v1",
        "abstract": "The Internet of Things (IoT) necessitates robust access control mechanisms to\nsecure a vast array of interconnected devices. Most of the existing IoT systems\nin practice use centralized solutions. We identify the problems in such\nsolutions and adopt the blockchain based decentralized access control approach.\nThough there are works in the literature that use blockchain for access\ncontrol, there are some gaps in these works. We develop a blockchain embedded\naccess control (BEAC) framework to bridge the gaps. First, blockchain based\nsolutions for access control require an enabling P2P network while existing P2P\noverlays do not support some required features. We develop a novel P2P\ninfrastructure to seamlessly support our BEAC framework. Second, most of the\nworks consider blockchain based access control for a single access control\nmodel, and we develop a generic blockchain mechanism and show that it can\nsupport the embedding of various access control models. Finally, existing works\nadopt existing blockchain mechanisms which may incur a high communication\noverhead. We develop a shortcut approach to improve the number of message\nrounds in the access protocol. Our experiments demonstrate the efficacy of our\nsystem, showing that the shortcut mechanism can reduces access time by\napproximately 43%.",
        "subjects": [
            "cs.DC",
            "cs.CR"
        ],
        "authors": [
            "Yongtao Huang",
            "I-Ling Yen",
            "Farokh Bastani"
        ],
        "published": "2024-05-24T17:46:53Z"
    },
    {
        "title": "Over-the-Air Runtime Wi-Fi MAC Address Re-randomization",
        "link": "http://arxiv.org/abs/2405.15747v1",
        "abstract": "Medium Access Control (MAC) address randomization is a key component for\nprivacy protection in Wi-Fi networks. Current proposals periodically change the\nmobile device MAC addresses when it disconnects from the Access Point (AP).\nThis way frames cannot be linked across changes, but the mobile device presence\nis exposed as long as it remains connected: all its communication is trivially\nlinkable by observing the randomized yet same MAC address throughout the\nconnection. Our runtime MAC re-randomization scheme addresses this issue,\nreducing or eliminating Wi-Fi frames linkability without awaiting for or\nrequiring a disconnection. Our MAC re-randomization is practically\n'over-the-air': MAC addresses are re-randomized just before transmission, while\nthe protocol stacks (at the mobile and the AP) maintain locally the original\nconnection MAC addresses - making our MAC layer scheme transparent to upper\nlayers. With an implementation and a set of small-scale experiments with\noff-the-shelf devices, we show the feasibility of our scheme and the potential\ntowards future deployment.",
        "subjects": [
            "cs.NI",
            "cs.CR"
        ],
        "authors": [
            "Hongyu Jin",
            "Panos Papadimitratos"
        ],
        "published": "2024-05-24T17:42:15Z"
    },
    {
        "title": "CAFe: Cost and Age aware Federated Learning",
        "link": "http://arxiv.org/abs/2405.15744v1",
        "abstract": "In many federated learning (FL) models, a common strategy employed to ensure\nthe progress in the training process, is to wait for at least $M$ clients out\nof the total $N$ clients to send back their local gradients based on a\nreporting deadline $T$, once the parameter server (PS) has broadcasted the\nglobal model. If enough clients do not report back within the deadline, the\nparticular round is considered to be a failed round and the training round is\nrestarted from scratch. If enough clients have responded back, the round is\ndeemed successful and the local gradients of all the clients that responded\nback are used to update the global model. In either case, the clients that\nfailed to report back an update within the deadline would have wasted their\ncomputational resources. Having a tighter deadline (small $T$) and waiting for\na larger number of participating clients (large $M$) leads to a large number of\nfailed rounds and therefore greater communication cost and computation resource\nwastage. However, having a larger $T$ leads to longer round durations whereas\nsmaller $M$ may lead to noisy gradients. Therefore, there is a need to optimize\nthe parameters $M$ and $T$ such that communication cost and the resource\nwastage is minimized while having an acceptable convergence rate. In this\nregard, we show that the average age of a client at the PS appears explicitly\nin the theoretical convergence bound, and therefore, can be used as a metric to\nquantify the convergence of the global model. We provide an analytical scheme\nto select the parameters $M$ and $T$ in this setting.",
        "subjects": [
            "cs.LG",
            "cs.DC",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Sahan Liyanaarachchi",
            "Kanchana Thilakarathna",
            "Sennur Ulukus"
        ],
        "published": "2024-05-24T17:41:30Z"
    },
    {
        "title": "Sparse maximal update parameterization: A holistic approach to sparse\n  training dynamics",
        "link": "http://arxiv.org/abs/2405.15743v1",
        "abstract": "Several challenges make it difficult for sparse neural networks to compete\nwith dense models. First, setting a large fraction of weights to zero impairs\nforward and gradient signal propagation. Second, sparse studies often need to\ntest multiple sparsity levels, while also introducing new hyperparameters\n(HPs), leading to prohibitive tuning costs. Indeed, the standard practice is to\nre-use the learning HPs originally crafted for dense models. Unfortunately, we\nshow sparse and dense networks do not share the same optimal HPs. Without\nstable dynamics and effective training recipes, it is costly to test sparsity\nat scale, which is key to surpassing dense networks and making the business\ncase for sparsity acceleration in hardware. A holistic approach is needed to\ntackle these challenges and we propose S$\\mu$Par as one such approach.\nS$\\mu$Par ensures activations, gradients, and weight updates all scale\nindependently of sparsity level. Further, by reparameterizing the HPs,\nS$\\mu$Par enables the same HP values to be optimal as we vary both sparsity\nlevel and model width. HPs can be tuned on small dense networks and transferred\nto large sparse models, greatly reducing tuning costs. On large-scale language\nmodeling, S$\\mu$Par training improves loss by up to 8.2% over the common\napproach of using the dense model standard parameterization.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Nolan Dey",
            "Shane Bergsma",
            "Joel Hestness"
        ],
        "published": "2024-05-24T17:39:26Z"
    },
    {
        "title": "Large Language Models Reflect Human Citation Patterns with a Heightened\n  Citation Bias",
        "link": "http://arxiv.org/abs/2405.15739v1",
        "abstract": "Citation practices are crucial in shaping the structure of scientific\nknowledge, yet they are often influenced by contemporary norms and biases. The\nemergence of Large Language Models (LLMs) like GPT-4 introduces a new dynamic\nto these practices. Interestingly, the characteristics and potential biases of\nreferences recommended by LLMs that entirely rely on their parametric\nknowledge, and not on search or retrieval-augmented generation, remain\nunexplored. Here, we analyze these characteristics in an experiment using a\ndataset of 166 papers from AAAI, NeurIPS, ICML, and ICLR, published after\nGPT-4's knowledge cut-off date, encompassing 3,066 references in total. In our\nexperiment, GPT-4 was tasked with suggesting scholarly references for the\nanonymized in-text citations within these papers. Our findings reveal a\nremarkable similarity between human and LLM citation patterns, but with a more\npronounced high citation bias in GPT-4, which persists even after controlling\nfor publication year, title length, number of authors, and venue. Additionally,\nwe observe a large consistency between the characteristics of GPT-4's existing\nand non-existent generated references, indicating the model's internalization\nof citation patterns. By analyzing citation graphs, we show that the references\nrecommended by GPT-4 are embedded in the relevant citation context, suggesting\nan even deeper conceptual internalization of the citation networks. While LLMs\ncan aid in citation generation, they may also amplify existing biases and\nintroduce new ones, potentially skewing scientific knowledge dissemination. Our\nresults underscore the need for identifying the model's biases and for\ndeveloping balanced methods to interact with LLMs in general.",
        "subjects": [
            "cs.DL",
            "cs.AI",
            "cs.LG",
            "cs.SI"
        ],
        "authors": [
            "Andres Algaba",
            "Carmen Mazijn",
            "Vincent Holst",
            "Floriano Tori",
            "Sylvia Wenmackers",
            "Vincent Ginis"
        ],
        "published": "2024-05-24T17:34:32Z"
    },
    {
        "title": "ConvLLaVA: Hierarchical Backbones as Visual Encoder for Large Multimodal\n  Models",
        "link": "http://arxiv.org/abs/2405.15738v1",
        "abstract": "High-resolution Large Multimodal Models (LMMs) encounter the challenges of\nexcessive visual tokens and quadratic visual complexity. Current\nhigh-resolution LMMs address the quadratic complexity while still generating\nexcessive visual tokens. However, the redundancy in visual tokens is the key\nproblem as it leads to more substantial compute. To mitigate this issue, we\npropose ConvLLaVA, which employs ConvNeXt, a hierarchical backbone, as the\nvisual encoder of LMM to replace Vision Transformer (ViT). ConvLLaVA compresses\nhigh-resolution images into information-rich visual features, effectively\npreventing the generation of excessive visual tokens. To enhance the\ncapabilities of ConvLLaVA, we propose two critical optimizations. Since the\nlow-resolution pretrained ConvNeXt underperforms when directly applied on high\nresolution, we update it to bridge the gap. Moreover, since ConvNeXt's original\ncompression ratio is inadequate for much higher resolution inputs, we train a\nsuccessive stage to further compress the visual tokens, thereby reducing\nredundancy. These optimizations enable ConvLLaVA to support inputs of 1536x1536\nresolution generating only 576 visual tokens, capable of handling images of\narbitrary aspect ratios. Experimental results demonstrate that our method\nachieves competitive performance with state-of-the-art models on mainstream\nbenchmarks. The ConvLLaVA model series are publicly available at\nhttps://github.com/alibaba/conv-llava.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Chunjiang Ge",
            "Sijie Cheng",
            "Ziming Wang",
            "Jiale Yuan",
            "Yuan Gao",
            "Jun Song",
            "Shiji Song",
            "Gao Huang",
            "Bo Zheng"
        ],
        "published": "2024-05-24T17:34:15Z"
    },
    {
        "title": "More Insight from Being More Focused: Analysis of Clustered Market Apps",
        "link": "http://arxiv.org/abs/2405.15737v1",
        "abstract": "The increasing attraction of mobile apps has inspired researchers to analyze\napps from different perspectives. As with any software product, apps have\ndifferent attributes such as size, content maturity, rating, category, or\nnumber of downloads. Current research studies mostly consider sampling across\nall apps. This often results in comparisons of apps being quite different in\nnature and category (games compared with weather and calendar apps), also being\ndifferent in size and complexity. Similar to proprietary software and web-based\nservices, more specific results can be expected from looking at more\nhomogeneous samples as they can be received as a result of applying clustering.\nIn this paper, we target homogeneous samples of apps to increase the degree of\ninsight gained from analytics. As a proof-of-concept, we applied the clustering\ntechnique DBSCAN and subsequent correlation analysis between app attributes for\na set of 940 open-source mobile apps from F-Droid. We showed that (i) clusters\nof apps with similar characteristics provided more insight compared to applying\nthe same to the whole data and (ii) defining the similarity of apps based on\nthe similarity of topics as created from the topic modeling technique Latent\nDirichlet Allocation does not significantly improve clustering results.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Maleknaz Nayebi",
            "Homayoon Farrahi",
            "Ada Lee",
            "Henry Cho",
            "Guenther Ruhe"
        ],
        "published": "2024-05-24T17:34:06Z"
    },
    {
        "title": "Single-Round Proofs of Quantumness from Knowledge Assumptions",
        "link": "http://arxiv.org/abs/2405.15736v1",
        "abstract": "A proof of quantumness is an efficiently verifiable interactive test that an\nefficient quantum computer can pass, but all efficient classical computers\ncannot (under some cryptographic assumption). Such protocols play a crucial\nrole in the certification of quantum devices. Existing single-round protocols\n(like asking the quantum computer to factor a large number) require large\nquantum circuits, whereas multi-round ones use smaller circuits but require\nexperimentally challenging mid-circuit measurements. As such, current proofs of\nquantumness are out of reach for near-term devices.\n  In this work, we construct efficient single-round proofs of quantumness based\non existing knowledge assumptions. While knowledge assumptions have not been\npreviously considered in this context, we show that they provide a natural\nbasis for separating classical and quantum computation. Specifically, we show\nthat multi-round protocols based on Decisional Diffie-Hellman (DDH) or Learning\nWith Errors (LWE) can be \"compiled\" into single-round protocols using a\nknowledge-of-exponent assumption or knowledge-of-lattice-point assumption,\nrespectively. We also prove an adaptive hardcore-bit statement for a family of\nclaw-free functions based on DDH, which might be of independent interest.\n  Previous approaches to constructing single-round protocols relied on the\nrandom oracle model and thus incurred the overhead associated with\ninstantiating the oracle with a cryptographic hash function. In contrast, our\nprotocols have the same resource requirements as their multi-round counterparts\nwithout necessitating mid-circuit measurements, making them, arguably, the most\nefficient single-round proofs of quantumness to date. Our work also helps in\nunderstanding the interplay between black-box/white-box reductions and\ncryptographic assumptions in the design of proofs of quantumness.",
        "subjects": [
            "quant-ph",
            "cs.CR"
        ],
        "authors": [
            "Petia Arabadjieva",
            "Alexandru Gheorghiu",
            "Victor Gitton",
            "Tony Metger"
        ],
        "published": "2024-05-24T17:33:10Z"
    },
    {
        "title": "A Higher Order Local Mesh Method for Approximating Laplacians on Unknown\n  Manifolds",
        "link": "http://arxiv.org/abs/2405.15735v1",
        "abstract": "In this work, we introduce a numerical method for approximating arbitrary\ndifferential operators on vector fields in the weak form given point cloud data\nsampled randomly from a $d$ dimensional manifold embedded in $\\mathbb{R}^n$.\nThis method generalizes the local linear mesh method to the local curved mesh\nmethod, thus, allowing for the estimation of differential operators with\nnontrivial Christoffer symbols, such as the Bochner or Hodge Laplacians. In\nparticular, we leverage the potentially small intrinsic dimension of the\nmanifold $(d \\ll n)$ to construct local parameterizations that incorporate both\nlocal meshes and higher-order curvature information. The former is constructed\nusing low dimensional meshes obtained from local data projected to the tangent\nspaces, while the latter is obtained by fitting local polynomials with the\ngeneralized moving least squares. Theoretically, we prove the weak and spectral\nconvergence rates for the proposed method for the estimation of the Bochner\nLaplacian. We provide numerical results supporting the theoretical convergence\nrates for the Bochner and Hodge Laplacians on simple manifolds.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "John Wilson Peoples",
            "John Harlim"
        ],
        "published": "2024-05-24T17:26:46Z"
    },
    {
        "title": "LM4LV: A Frozen Large Language Model for Low-level Vision Tasks",
        "link": "http://arxiv.org/abs/2405.15734v1",
        "abstract": "The success of large language models (LLMs) has fostered a new research trend\nof multi-modality large language models (MLLMs), which changes the paradigm of\nvarious fields in computer vision. Though MLLMs have shown promising results in\nnumerous high-level vision and vision-language tasks such as VQA and\ntext-to-image, no works have demonstrated how low-level vision tasks can\nbenefit from MLLMs. We find that most current MLLMs are blind to low-level\nfeatures due to their design of vision modules, thus are inherently incapable\nfor solving low-level vision tasks. In this work, we purpose $\\textbf{LM4LV}$,\na framework that enables a FROZEN LLM to solve a range of low-level vision\ntasks without any multi-modal data or prior. This showcases the LLM's strong\npotential in low-level vision and bridges the gap between MLLMs and low-level\nvision tasks. We hope this work can inspire new perspectives on LLMs and deeper\nunderstanding of their mechanisms.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Boyang Zheng",
            "Jinjin Gu",
            "Shijun Li",
            "Chao Dong"
        ],
        "published": "2024-05-24T17:25:00Z"
    },
    {
        "title": "Neural Persistence Dynamics",
        "link": "http://arxiv.org/abs/2405.15732v1",
        "abstract": "We consider the problem of learning the dynamics in the topology of\ntime-evolving point clouds, the prevalent spatiotemporal model for systems\nexhibiting collective behavior, such as swarms of insects and birds or\nparticles in physics. In such systems, patterns emerge from (local)\ninteractions among self-propelled entities. While several well-understood\ngoverning equations for motion and interaction exist, they are difficult to fit\nto data due to the often large number of entities and missing correspondences\nbetween the observation times, which may also not be equidistant. To evade such\nconfounding factors, we investigate collective behavior from a\n\\textit{topological perspective}, but instead of summarizing entire observation\nsequences (as in prior work), we propose learning a latent dynamical model from\ntopological features \\textit{per time point}. The latter is then used to\nformulate a downstream regression task to predict the parametrization of some a\npriori specified governing equation. We implement this idea based on a latent\nODE learned from vectorized (static) persistence diagrams and show that this\nmodeling choice is justified by a combination of recent stability results for\npersistent homology. Various (ablation) experiments not only demonstrate the\nrelevance of each individual model component, but provide compelling empirical\nevidence that our proposed model -- \\textit{neural persistence dynamics} --\nsubstantially outperforms the state-of-the-art across a diverse set of\nparameter regression tasks.",
        "subjects": [
            "cs.LG",
            "cs.CE"
        ],
        "authors": [
            "Sebastian Zeng",
            "Florian Graf",
            "Martin Uray",
            "Stefan Huber",
            "Roland Kwitt"
        ],
        "published": "2024-05-24T17:20:18Z"
    },
    {
        "title": "Understanding the differences in Foundation Models: Attention, State\n  Space Models, and Recurrent Neural Networks",
        "link": "http://arxiv.org/abs/2405.15731v1",
        "abstract": "Softmax attention is the principle backbone of foundation models for various\nartificial intelligence applications, yet its quadratic complexity in sequence\nlength can limit its inference throughput in long-context settings. To address\nthis challenge, alternative architectures such as linear attention, State Space\nModels (SSMs), and Recurrent Neural Networks (RNNs) have been considered as\nmore efficient alternatives. While connections between these approaches exist,\nsuch models are commonly developed in isolation and there is a lack of\ntheoretical understanding of the shared principles underpinning these\narchitectures and their subtle differences, greatly influencing performance and\nscalability. In this paper, we introduce the Dynamical Systems Framework (DSF),\nwhich allows a principled investigation of all these architectures in a common\nrepresentation. Our framework facilitates rigorous comparisons, providing new\ninsights on the distinctive characteristics of each model class. For instance,\nwe compare linear attention and selective SSMs, detailing their differences and\nconditions under which both are equivalent. We also provide principled\ncomparisons between softmax attention and other model classes, discussing the\ntheoretical conditions under which softmax attention can be approximated.\nAdditionally, we substantiate these new insights with empirical validations and\nmathematical arguments. This shows the DSF's potential to guide the systematic\ndevelopment of future more efficient and scalable foundation models.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Jerome Sieber",
            "Carmen Amo Alonso",
            "Alexandre Didier",
            "Melanie N. Zeilinger",
            "Antonio Orvieto"
        ],
        "published": "2024-05-24T17:19:57Z"
    },
    {
        "title": "Optimizing Large Language Models for OpenAPI Code Completion",
        "link": "http://arxiv.org/abs/2405.15729v1",
        "abstract": "Recent advancements in Large Language Models (LLMs) and their utilization in\ncode generation tasks have significantly reshaped the field of software\ndevelopment. Despite the remarkable efficacy of code completion solutions in\nmainstream programming languages, their performance lags when applied to less\nubiquitous formats such as OpenAPI definitions. This study evaluates the\nOpenAPI completion performance of GitHub Copilot, a prevalent commercial code\ncompletion tool, and proposes a set of task-specific optimizations leveraging\nMeta's open-source model Code Llama. A semantics-aware OpenAPI completion\nbenchmark proposed in this research is used to perform a series of experiments\nthrough which the impact of various prompt-engineering and fine-tuning\ntechniques on the Code Llama model's performance is analyzed. The fine-tuned\nCode Llama model reaches a peak correctness improvement of 55.2% over GitHub\nCopilot despite utilizing 25 times fewer parameters than the commercial\nsolution's underlying Codex model. Additionally, this research proposes an\nenhancement to a widely used code infilling training technique, addressing the\nissue of underperformance when the model is prompted with context sizes smaller\nthan those used during training.",
        "subjects": [
            "cs.SE",
            "cs.CL",
            "cs.LG",
            "68T07, 68T50, 68T05"
        ],
        "authors": [
            "Bohdan Petryshyn",
            "Mantas Lukoševičius"
        ],
        "published": "2024-05-24T17:19:03Z"
    },
    {
        "title": "Disease-informed Adaptation of Vision-Language Models",
        "link": "http://arxiv.org/abs/2405.15728v1",
        "abstract": "In medical image analysis, the expertise scarcity and the high cost of data\nannotation limits the development of large artificial intelligence models. This\npaper investigates the potential of transfer learning with pre-trained\nvision-language models (VLMs) in this domain. Currently, VLMs still struggle to\ntransfer to the underrepresented diseases with minimal presence and new\ndiseases entirely absent from the pretraining dataset. We argue that effective\nadaptation of VLMs hinges on the nuanced representation learning of disease\nconcepts. By capitalizing on the joint visual-linguistic capabilities of VLMs,\nwe introduce disease-informed contextual prompting in a novel disease prototype\nlearning framework. This approach enables VLMs to grasp the concepts of new\ndisease effectively and efficiently, even with limited data. Extensive\nexperiments across multiple image modalities showcase notable enhancements in\nperformance compared to existing techniques.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jiajin Zhang",
            "Ge Wang",
            "Mannudeep K. Kalra",
            "Pingkun Yan"
        ],
        "published": "2024-05-24T17:18:02Z"
    },
    {
        "title": "Anomalous Change Point Detection Using Probabilistic Predictive Coding",
        "link": "http://arxiv.org/abs/2405.15727v1",
        "abstract": "Change point detection (CPD) and anomaly detection (AD) are essential\ntechniques in various fields to identify abrupt changes or abnormal data\ninstances. However, existing methods are often constrained to univariate data,\nface scalability challenges with large datasets due to computational demands,\nand experience reduced performance with high-dimensional or intricate data, as\nwell as hidden anomalies. Furthermore, they often lack interpretability and\nadaptability to domain-specific knowledge, which limits their versatility\nacross different fields. In this work, we propose a deep learning-based CPD/AD\nmethod called Probabilistic Predictive Coding (PPC) that jointly learns to\nencode sequential data to low dimensional latent space representations and to\npredict the subsequent data representations as well as the corresponding\nprediction uncertainties. The model parameters are optimized with maximum\nlikelihood estimation by comparing these predictions with the true encodings.\nAt the time of application, the true and predicted encodings are used to\ndetermine the probability of conformity, an interpretable and meaningful\nanomaly score. Furthermore, our approach has linear time complexity,\nscalability issues are prevented, and the method can easily be adjusted to a\nwide range of data types and intricate applications. We demonstrate the\neffectiveness and adaptability of our proposed method across synthetic time\nseries experiments, image data, and real-world magnetic resonance spectroscopic\nimaging data.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Roelof G. Hup",
            "Julian P. Merkofer",
            "Alex A. Bhogal",
            "Ruud J. G. van Sloun",
            "Reinder Haakma",
            "Rik Vullings"
        ],
        "published": "2024-05-24T17:17:34Z"
    },
    {
        "title": "Reconfiguration Algorithms for Cubic Modular Robots with Realistic\n  Movement Constraints",
        "link": "http://arxiv.org/abs/2405.15724v1",
        "abstract": "We introduce and analyze a model for self-reconfigurable robots made up of\nunit-cube modules. Compared to past models, our model aims to newly capture two\nimportant practical aspects of real-world robots. First, modules often do not\noccupy an exact unit cube, but rather have features like bumps extending\noutside the allotted space so that modules can interlock. Thus, for example,\nour model forbids modules from squeezing in between two other modules that are\none unit distance apart. Second, our model captures the practical scenario of\nmany passive modules assembled by a single robot, instead of requiring all\nmodules to be able to move on their own.\n  We prove two universality results. First, with a supply of auxiliary modules,\nwe show that any connected polycube structure can be constructed by a carefully\naligned plane sweep. Second, without additional modules, we show how to\nconstruct any structure for which a natural notion of external feature size is\nat least a constant; this property largely consolidates forbidden-pattern\nproperties used in previous works on reconfigurable modular robots.",
        "subjects": [
            "cs.CG",
            "cs.DM",
            "cs.RO"
        ],
        "authors": [
            "MIT--NASA Space Robots Team",
            "Josh Brunner",
            "Kenneth C. Cheung",
            "Erik D. Demaine",
            "Jenny Diomidova",
            "Christine Gregg",
            "Della H. Hendrickson",
            "Irina Kostitsyna"
        ],
        "published": "2024-05-24T17:13:54Z"
    },
    {
        "title": "Bisimulation Learning",
        "link": "http://arxiv.org/abs/2405.15723v1",
        "abstract": "We introduce a data-driven approach to computing finite bisimulations for\nstate transition systems with very large, possibly infinite state space. Our\nnovel technique computes stutter-insensitive bisimulations of deterministic\nsystems, which we characterize as the problem of learning a state classifier\ntogether with a ranking function for each class. Our procedure learns a\ncandidate state classifier and candidate ranking functions from a finite\ndataset of sample states; then, it checks whether these generalise to the\nentire state space using satisfiability modulo theory solving. Upon the\naffirmative answer, the procedure concludes that the classifier constitutes a\nvalid stutter-insensitive bisimulation of the system. Upon a negative answer,\nthe solver produces a counterexample state for which the classifier violates\nthe claim, adds it to the dataset, and repeats learning and checking in a\ncounterexample-guided inductive synthesis loop until a valid bisimulation is\nfound. We demonstrate on a range of benchmarks from reactive verification and\nsoftware model checking that our method yields faster verification results than\nalternative state-of-the-art tools in practice. Our method produces succinct\nabstractions that enable an effective verification of linear temporal logic\nwithout next operator, and are interpretable for system diagnostics.",
        "subjects": [
            "cs.LO",
            "cs.LG"
        ],
        "authors": [
            "Alessandro Abate",
            "Mirco Giacobbe",
            "Yannik Schnitzer"
        ],
        "published": "2024-05-24T17:11:27Z"
    },
    {
        "title": "Models That Prove Their Own Correctness",
        "link": "http://arxiv.org/abs/2405.15722v1",
        "abstract": "How can we trust the correctness of a learned model on a particular input of\ninterest? Model accuracy is typically measured \\emph{on average} over a\ndistribution of inputs, giving no guarantee for any fixed input. This paper\nproposes a theoretically-founded solution to this problem: to train\n*Self-Proving models* that prove the correctness of their output to a\nverification algorithm $V$ via an Interactive Proof. Self-Proving models\nsatisfy that, with high probability over a random input, the model generates a\ncorrect output \\emph{and} successfully proves its correctness to $V\\!$. The\n*soundness* property of $V$ guarantees that, for *every* input, no model can\nconvince $V$ of the correctness of an incorrect output. Thus, a Self-Proving\nmodel proves correctness of most of its outputs, while *all* incorrect outputs\n(of any model) are detected by $V$. We devise a generic method for learning\nSelf-Proving models, and we prove convergence bounds under certain assumptions.\nThe theoretical framework and results are complemented by experiments on an\narithmetic capability: computing the greatest common divisor (GCD) of two\nintegers. Our learning method is used to train a Self-Proving transformer that\ncomputes the GCD *and* proves the correctness of its answer.",
        "subjects": [
            "cs.LG",
            "cs.CC",
            "cs.SE"
        ],
        "authors": [
            "Noga Amit",
            "Shafi Goldwasser",
            "Orr Paradise",
            "Guy Rothblum"
        ],
        "published": "2024-05-24T17:10:08Z"
    },
    {
        "title": "Hierarchical Uncertainty Exploration via Feedforward Posterior Trees",
        "link": "http://arxiv.org/abs/2405.15719v1",
        "abstract": "When solving ill-posed inverse problems, one often desires to explore the\nspace of potential solutions rather than be presented with a single plausible\nreconstruction. Valuable insights into these feasible solutions and their\nassociated probabilities are embedded in the posterior distribution. However,\nwhen confronted with data of high dimensionality (such as images), visualizing\nthis distribution becomes a formidable challenge, necessitating the application\nof effective summarization techniques before user examination. In this work, we\nintroduce a new approach for visualizing posteriors across multiple levels of\ngranularity using tree-valued predictions. Our method predicts a tree-valued\nhierarchical summarization of the posterior distribution for any input\nmeasurement, in a single forward pass of a neural network. We showcase the\nefficacy of our approach across diverse datasets and image restoration\nchallenges, highlighting its prowess in uncertainty quantification and\nvisualization. Our findings reveal that our method performs comparably to a\nbaseline that hierarchically clusters samples from a diffusion-based posterior\nsampler, yet achieves this with orders of magnitude greater speed.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "eess.IV",
            "stat.ML"
        ],
        "authors": [
            "Elias Nehme",
            "Rotem Mulayoff",
            "Tomer Michaeli"
        ],
        "published": "2024-05-24T17:06:51Z"
    },
    {
        "title": "Integrated Design for Wave Energy Converter Farms: Assessing Plant,\n  Control, Layout, and Site Selection Coupling in the Presence of Irregular\n  Waves",
        "link": "http://arxiv.org/abs/2405.15717v1",
        "abstract": "A promising direction towards reducing the levelized cost of energy for wave\nenergy converter (WEC) farms is to improve their performance. WEC design\nstudies generally focus on a single design domain (e.g., geometry, control, or\nlayout) to improve the farm's performance under simplifying assumptions, such\nas regular waves. This strategy, however, has resulted in design\nrecommendations that are impractical or limited in scope because WEC farms are\ncomplex systems that exhibit strong coupling among geometry, control, and\nlayout domains. In addition, the location of the candidate site, which has a\nlarge impact on the performance of the farm, is often overlooked. Motivated by\nsome of the limitations observed in WEC literature, this study uses an\nintegrated design framework, based on simultaneous control co-design (CCD)\nprinciples, to discuss the impact of site selection and wave type on WEC farm\ndesign. Interactions among plant, control, and layout are also investigated and\ndiscussed using a wide range of simulations and optimization studies. All of\nthe studies were conducted using frequency-domain heaving cylinder WEC devices\nwithin a farm with a linear reactive controller in the presence of irregular\nprobabilistic waves. The results provide high-level guidelines to help the WEC\ndesign community move toward an integrated design perspective.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Saeed Azad",
            "Suraj Khanal",
            "Daniel R. Herber",
            "Gaofeng Jia"
        ],
        "published": "2024-05-24T17:06:18Z"
    },
    {
        "title": "Infinite Limits of Multi-head Transformer Dynamics",
        "link": "http://arxiv.org/abs/2405.15712v1",
        "abstract": "In this work, we analyze various scaling limits of the training dynamics of\ntransformer models in the feature learning regime. We identify the set of\nparameterizations that admit well-defined infinite width and depth limits,\nallowing the attention layers to update throughout training--a relevant notion\nof feature learning in these models. We then use tools from dynamical mean\nfield theory (DMFT) to analyze various infinite limits (infinite key/query\ndimension, infinite heads, and infinite depth) which have different statistical\ndescriptions depending on which infinite limit is taken and how attention\nlayers are scaled. We provide numerical evidence of convergence to the limits\nand discuss how the parameterization qualitatively influences learned features.",
        "subjects": [
            "stat.ML",
            "cond-mat.dis-nn",
            "cs.LG"
        ],
        "authors": [
            "Blake Bordelon",
            "Hamza Tahir Chaudhry",
            "Cengiz Pehlevan"
        ],
        "published": "2024-05-24T17:01:37Z"
    },
    {
        "title": "An Adaptive Framework for Manipulator Skill Reproduction in Dynamic\n  Environments",
        "link": "http://arxiv.org/abs/2405.15711v1",
        "abstract": "Robot skill learning and execution in uncertain and dynamic environments is a\nchallenging task. This paper proposes an adaptive framework that combines\nLearning from Demonstration (LfD), environment state prediction, and high-level\ndecision making. Proactive adaptation prevents the need for reactive\nadaptation, which lags behind changes in the environment rather than\nanticipating them. We propose a novel LfD representation, Elastic-Laplacian\nTrajectory Editing (ELTE), which continuously adapts the trajectory shape to\npredictions of future states. Then, a high-level reactive system using an\nUnscented Kalman Filter (UKF) and Hidden Markov Model (HMM) prevents unsafe\nexecution in the current state of the dynamic environment based on a discrete\nset of decisions. We first validate our LfD representation in simulation, then\nexperimentally assess the entire framework using a legged mobile manipulator in\n36 real-world scenarios. We show the effectiveness of the proposed framework\nunder different dynamic changes in the environment. Our results show that the\nproposed framework produces robust and stable adaptive behaviors.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Ryan Donald",
            "Brendan Hertel",
            "Stephen Misenti",
            "Yan Gu",
            "Reza Azadeh"
        ],
        "published": "2024-05-24T17:01:12Z"
    },
    {
        "title": "Information-theoretic Generalization Analysis for Expected Calibration\n  Error",
        "link": "http://arxiv.org/abs/2405.15709v1",
        "abstract": "While the expected calibration error (ECE), which employs binning, is widely\nadopted to evaluate the calibration performance of machine learning models,\ntheoretical understanding of its estimation bias is limited. In this paper, we\npresent the first comprehensive analysis of the estimation bias in the two\ncommon binning strategies, uniform mass and uniform width binning. Our analysis\nestablishes upper bounds on the bias, achieving an improved convergence rate.\nMoreover, our bounds reveal, for the first time, the optimal number of bins to\nminimize the estimation bias. We further extend our bias analysis to\ngeneralization error analysis based on the information-theoretic approach,\nderiving upper bounds that enable the numerical evaluation of how small the ECE\nis for unknown data. Experiments using deep learning models show that our\nbounds are nonvacuous thanks to this information-theoretic generalization\nanalysis approach.",
        "subjects": [
            "cs.LG",
            "math.ST",
            "stat.ML",
            "stat.TH"
        ],
        "authors": [
            "Futoshi Futami",
            "Masahiro Fujisawa"
        ],
        "published": "2024-05-24T16:59:29Z"
    },
    {
        "title": "EmpathicStories++: A Multimodal Dataset for Empathy towards Personal\n  Experiences",
        "link": "http://arxiv.org/abs/2405.15708v1",
        "abstract": "Modeling empathy is a complex endeavor that is rooted in interpersonal and\nexperiential dimensions of human interaction, and remains an open problem\nwithin AI. Existing empathy datasets fall short in capturing the richness of\nempathy responses, often being confined to in-lab or acted scenarios, lacking\nlongitudinal data, and missing self-reported labels. We introduce a new\nmultimodal dataset for empathy during personal experience sharing: the\nEmpathicStories++ dataset\n(https://mitmedialab.github.io/empathic-stories-multimodal/) containing 53\nhours of video, audio, and text data of 41 participants sharing vulnerable\nexperiences and reading empathically resonant stories with an AI agent.\nEmpathicStories++ is the first longitudinal dataset on empathy, collected over\na month-long deployment of social robots in participants' homes, as\nparticipants engage in natural, empathic storytelling interactions with AI\nagents. We then introduce a novel task of predicting individuals' empathy\ntoward others' stories based on their personal experiences, evaluated in two\ncontexts: participants' own personal shared story context and their reflections\non stories they read. We benchmark this task using state-of-the-art models to\npave the way for future improvements in contextualized and longitudinal empathy\nmodeling. Our work provides a valuable resource for further research in\ndeveloping empathetic AI systems and understanding the intricacies of human\nempathy within genuine, real-world settings.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Jocelyn Shen",
            "Yubin Kim",
            "Mohit Hulse",
            "Wazeer Zulfikar",
            "Sharifa Alghowinem",
            "Cynthia Breazeal",
            "Hae Won Park"
        ],
        "published": "2024-05-24T16:57:18Z"
    },
    {
        "title": "The Impact of Geometric Complexity on Neural Collapse in Transfer\n  Learning",
        "link": "http://arxiv.org/abs/2405.15706v1",
        "abstract": "Many of the recent remarkable advances in computer vision and language models\ncan be attributed to the success of transfer learning via the pre-training of\nlarge foundation models. However, a theoretical framework which explains this\nempirical success is incomplete and remains an active area of research.\nFlatness of the loss surface and neural collapse have recently emerged as\nuseful pre-training metrics which shed light on the implicit biases underlying\npre-training. In this paper, we explore the geometric complexity of a model's\nlearned representations as a fundamental mechanism that relates these two\nconcepts. We show through experiments and theory that mechanisms which affect\nthe geometric complexity of the pre-trained network also influence the neural\ncollapse. Furthermore, we show how this effect of the geometric complexity\ngeneralizes to the neural collapse of new classes as well, thus encouraging\nbetter performance on downstream tasks, particularly in the few-shot setting.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Michael Munn",
            "Benoit Dherin",
            "Javier Gonzalvo"
        ],
        "published": "2024-05-24T16:52:09Z"
    },
    {
        "title": "Sums: Sniffing Unknown Multiband Signals under Low Sampling Rates",
        "link": "http://arxiv.org/abs/2405.15705v1",
        "abstract": "Due to sophisticated deployments of all kinds of wireless networks (e.g., 5G,\nWi-Fi, Bluetooth, LEO satellite, etc.), multiband signals distribute in a large\nbandwidth (e.g., from 70 MHz to 8 GHz). Consequently, for network monitoring\nand spectrum sharing applications, a sniffer for extracting physical layer\ninformation, such as structure of packet, with low sampling rate (especially,\nsub-Nyquist sampling) can significantly improve their cost- and\nenergy-efficiency. However, to achieve a multiband signals sniffer is really a\nchallenge. To this end, we propose Sums, a system that can sniff and analyze\nmultiband signals in a blind manner. Our Sums takes advantage of hardware and\nalgorithm co-design, multi-coset sub-Nyquist sampling hardware, and a\nmulti-task deep learning framework. The hardware component breaks the Nyquist\nrule to sample GHz bandwidth, but only pays for a 50 MSPS sampling rate. Our\nmulti-task learning framework directly tackles the sampling data to perform\nspectrum sensing, physical layer protocol recognition, and demodulation for\ndeep inspection from multiband signals. Extensive experiments demonstrate that\nSums achieves higher accuracy than the state-of-theart baselines in spectrum\nsensing, modulation classification, and demodulation. As a result, our Sums can\nhelp researchers and end-users to diagnose or troubleshoot their problems of\nwireless infrastructures deployments in practice.",
        "subjects": [
            "cs.AR",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Jinbo Peng",
            "Zhe Chen",
            "Zheng Lin",
            "Haoxuan Yuan",
            "Zihan Fang",
            "Lingzhong Bao",
            "Zihang Song",
            "Ying Li",
            "Jing Ren",
            "Yue Gao"
        ],
        "published": "2024-05-24T16:52:04Z"
    },
    {
        "title": "Trackastra: Transformer-based cell tracking for live-cell microscopy",
        "link": "http://arxiv.org/abs/2405.15700v1",
        "abstract": "Cell tracking is an omnipresent image analysis task in live-cell microscopy.\nIt is similar to multiple object tracking (MOT), however, each frame contains\nhundreds of similar-looking objects that can divide, making it a challenging\nproblem. Current state-of-the-art approaches follow the tracking-by-detection\nparadigm, i.e. first all cells are detected per frame and successively linked\nin a second step to form biologically consistent cell tracks. Linking is\ncommonly solved via discrete optimization methods, which require manual tuning\nof hyperparameters for each dataset and are therefore cumbersome to use in\npractice. Here we propose Trackastra, a general purpose cell tracking approach\nthat uses a simple transformer architecture to directly learn pairwise\nassociations of cells within a temporal window from annotated data.\nImportantly, unlike existing transformer-based MOT pipelines, our learning\narchitecture also accounts for dividing objects such as cells and allows for\naccurate tracking even with simple greedy linking, thus making strides towards\nremoving the requirement for a complex linking step. The proposed architecture\noperates on the full spatio-temporal context of detections within a time window\nby avoiding the computational burden of processing dense images. We show that\nour tracking approach performs on par with or better than highly tuned\nstate-of-the-art cell tracking algorithms for various biological datasets, such\nas bacteria, cell cultures and fluorescent particles. We provide code at\nhttps://github.com/weigertlab/trackastra.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Benjamin Gallusser",
            "Martin Weigert"
        ],
        "published": "2024-05-24T16:44:22Z"
    },
    {
        "title": "Dimension-free deterministic equivalents for random feature regression",
        "link": "http://arxiv.org/abs/2405.15699v1",
        "abstract": "In this work we investigate the generalization performance of random feature\nridge regression (RFRR). Our main contribution is a general deterministic\nequivalent for the test error of RFRR. Specifically, under a certain\nconcentration property, we show that the test error is well approximated by a\nclosed-form expression that only depends on the feature map eigenvalues.\nNotably, our approximation guarantee is non-asymptotic, multiplicative, and\nindependent of the feature map dimension -- allowing for infinite-dimensional\nfeatures. We expect this deterministic equivalent to hold broadly beyond our\ntheoretical analysis, and we empirically validate its predictions on various\nreal and synthetic datasets. As an application, we derive sharp excess error\nrates under standard power-law assumptions of the spectrum and target decay. In\nparticular, we provide a tight result for the smallest number of features\nachieving optimal minimax error rate.",
        "subjects": [
            "stat.ML",
            "cond-mat.dis-nn",
            "cs.LG"
        ],
        "authors": [
            "Leonardo Defilippis",
            "Bruno Loureiro",
            "Theodor Misiakiewicz"
        ],
        "published": "2024-05-24T16:43:26Z"
    },
    {
        "title": "A Case Study of LLM for Automated Vulnerability Repair: Assessing Impact\n  of Reasoning and Patch Validation Feedback",
        "link": "http://arxiv.org/abs/2405.15690v1",
        "abstract": "Recent work in automated program repair (APR) proposes the use of reasoning\nand patch validation feedback to reduce the semantic gap between the LLMs and\nthe code under analysis. The idea has been shown to perform well for general\nAPR, but its effectiveness in other particular contexts remains underexplored.\nIn this work, we assess the impact of reasoning and patch validation feedback\nto LLMs in the context of vulnerability repair, an important and challenging\ntask in security. To support the evaluation, we present VRpilot, an LLM-based\nvulnerability repair technique based on reasoning and patch validation\nfeedback. VRpilot (1) uses a chain-of-thought prompt to reason about a\nvulnerability prior to generating patch candidates and (2) iteratively refines\nprompts according to the output of external tools (e.g., compiler, code\nsanitizers, test suite, etc.) on previously-generated patches. To evaluate\nperformance, we compare VRpilot against the state-of-the-art vulnerability\nrepair techniques for C and Java using public datasets from the literature. Our\nresults show that VRpilot generates, on average, 14% and 7.6% more correct\npatches than the baseline techniques on C and Java, respectively. We show,\nthrough an ablation study, that reasoning and patch validation feedback are\ncritical. We report several lessons from this study and potential directions\nfor advancing LLM-empowered vulnerability repair",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Ummay Kulsum",
            "Haotian Zhu",
            "Bowen Xu",
            "Marcelo d'Amorim"
        ],
        "published": "2024-05-24T16:29:48Z"
    },
    {
        "title": "UNION: Unsupervised 3D Object Detection using Object Appearance-based\n  Pseudo-Classes",
        "link": "http://arxiv.org/abs/2405.15688v1",
        "abstract": "Unsupervised 3D object detection methods have emerged to leverage vast\namounts of data efficiently without requiring manual labels for training.\nRecent approaches rely on dynamic objects for learning to detect objects but\npenalize the detections of static instances during training. Multiple rounds of\n(self) training are used in which detected static instances are added to the\nset of training targets; this procedure to improve performance is\ncomputationally expensive. To address this, we propose the method UNION. We use\nspatial clustering and self-supervised scene flow to obtain a set of static and\ndynamic object proposals from LiDAR. Subsequently, object proposals' visual\nappearances are encoded to distinguish static objects in the foreground and\nbackground by selecting static instances that are visually similar to dynamic\nobjects. As a result, static and dynamic foreground objects are obtained\ntogether, and existing detectors can be trained with a single training. In\naddition, we extend 3D object discovery to detection by using object\nappearance-based cluster labels as pseudo-class labels for training object\nclassification. We conduct extensive experiments on the nuScenes dataset and\nincrease the state-of-the-art performance for unsupervised object discovery,\ni.e. UNION more than doubles the average precision to 33.9. The code will be\nmade publicly available.",
        "subjects": [
            "cs.CV",
            "68T10, 62H35, 68T05, 68U10",
            "I.2.10; I.4.8; I.5.1; I.5.4"
        ],
        "authors": [
            "Ted Lentsch",
            "Holger Caesar",
            "Dariu M. Gavrila"
        ],
        "published": "2024-05-24T16:27:05Z"
    },
    {
        "title": "Chain-of-Thought Prompting for Demographic Inference with Large\n  Multimodal Models",
        "link": "http://arxiv.org/abs/2405.15687v1",
        "abstract": "Conventional demographic inference methods have predominantly operated under\nthe supervision of accurately labeled data, yet struggle to adapt to shifting\nsocial landscapes and diverse cultural contexts, leading to narrow\nspecialization and limited accuracy in applications. Recently, the emergence of\nlarge multimodal models (LMMs) has shown transformative potential across\nvarious research tasks, such as visual comprehension and description. In this\nstudy, we explore the application of LMMs to demographic inference and\nintroduce a benchmark for both quantitative and qualitative evaluation. Our\nfindings indicate that LMMs possess advantages in zero-shot learning,\ninterpretability, and handling uncurated 'in-the-wild' inputs, albeit with a\npropensity for off-target predictions. To enhance LMM performance and achieve\ncomparability with supervised learning baselines, we propose a Chain-of-Thought\naugmented prompting approach, which effectively mitigates the off-target\nprediction issue.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Yongsheng Yu",
            "Jiebo Luo"
        ],
        "published": "2024-05-24T16:26:56Z"
    },
    {
        "title": "Stratified Sampling Algorithms for Machine Learning Methods in Solving\n  Two-scale Partial Differential Equations",
        "link": "http://arxiv.org/abs/2405.15686v1",
        "abstract": "Partial differential equations (PDEs) with multiple scales or those defined\nover sufficiently large domains arise in various areas of science and\nengineering and often present problems when approximating the solutions\nnumerically. Machine learning techniques are a relatively recent method for\nsolving PDEs. Despite the increasing number of machine learning strategies\ndeveloped to approximate PDEs, many remain focused on relatively small domains.\nWhen scaling the equations, a large domain is naturally obtained, especially\nwhen the solution exhibits multiscale characteristics. This study examines\ntwo-scale equations whose solution structures exhibit distinct characteristics:\nhighly localized in some regions and significantly flat in others. These two\nregions must be adequately addressed over a large domain to approximate the\nsolution more accurately. We focus on the vanishing gradient problem given by\nthe diminishing gradient zone of the activation function over large domains and\npropose a stratified sampling algorithm to address this problem. We compare the\nuniform random classical sampling method over the entire domain and the\nproposed stratified sampling method. The numerical results confirm that the\nproposed method yields more accurate and consistent solutions than classical\nmethods.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "65M99 (Primary) 68T07 (Secondary)",
            "G.1.8"
        ],
        "authors": [
            "Eddel Elí Ojeda Avilés",
            "Daniel Olmos-Liceaga",
            "Jae-Hun Jung"
        ],
        "published": "2024-05-24T16:26:26Z"
    },
    {
        "title": "Prompt-Aware Adapter: Towards Learning Adaptive Visual Tokens for\n  Multimodal Large Language Models",
        "link": "http://arxiv.org/abs/2405.15684v1",
        "abstract": "To bridge the gap between vision and language modalities, Multimodal Large\nLanguage Models (MLLMs) usually learn an adapter that converts visual inputs to\nunderstandable tokens for Large Language Models (LLMs). However, most adapters\ngenerate consistent visual tokens, regardless of the specific objects of\ninterest mentioned in the prompt. Since these adapters distribute equal\nattention to every detail in the image and focus on the entire scene, they may\nincrease the cognitive load for LLMs, particularly when processing complex\nscenes. To alleviate this problem, we propose prompt-aware adapters. These\nadapters are designed with the capability to dynamically embed visual inputs\nbased on the specific focus of the prompt. Specifically, prompt-aware adapters\nutilize both global and local textual features to capture the most relevant\nvisual clues from the prompt at both coarse and fine granularity levels. This\napproach significantly enhances the ability of LLMs to understand and interpret\nvisual content. Experiments on various visual question answering tasks, such as\ncounting and position reasoning, demonstrate the effectiveness of prompt-aware\nadapters.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Yue Zhang",
            "Hehe Fan",
            "Yi Yang"
        ],
        "published": "2024-05-24T16:24:10Z"
    },
    {
        "title": "VDGD: Mitigating LVLM Hallucinations in Cognitive Prompts by Bridging\n  the Visual Perception Gap",
        "link": "http://arxiv.org/abs/2405.15683v1",
        "abstract": "Recent interest in Large Vision-Language Models (LVLMs) for practical\napplications is moderated by the significant challenge of hallucination or the\ninconsistency between the factual information and the generated text. In this\npaper, we first perform an in-depth analysis of hallucinations and discover\nseveral novel insights about how and when LVLMs hallucinate. From our analysis,\nwe show that: (1) The community's efforts have been primarily targeted towards\nreducing hallucinations related to visual recognition (VR) prompts (e.g.,\nprompts that only require describing the image), thereby ignoring\nhallucinations for cognitive prompts (e.g., prompts that require additional\nskills like reasoning on contents of the image). (2) LVLMs lack visual\nperception, i.e., they can see but not necessarily understand or perceive the\ninput image. We analyze responses to cognitive prompts and show that LVLMs\nhallucinate due to a perception gap: although LVLMs accurately recognize visual\nelements in the input image and possess sufficient cognitive skills, they\nstruggle to respond accurately and hallucinate. To overcome this shortcoming,\nwe propose Visual Description Grounded Decoding (VDGD), a simple, robust, and\ntraining-free method for alleviating hallucinations. Specifically, we first\ndescribe the image and add it as a prefix to the instruction. Next, during\nauto-regressive decoding, we sample from the plausible candidates according to\ntheir KL-Divergence (KLD) to the description, where lower KLD is given higher\npreference. Experimental results on several benchmarks and LVLMs show that VDGD\nimproves significantly over other baselines in reducing hallucinations. We also\npropose VaLLu, a benchmark for the comprehensive evaluation of the cognitive\ncapabilities of LVLMs.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Sreyan Ghosh",
            "Chandra Kiran Reddy Evuru",
            "Sonal Kumar",
            "Utkarsh Tyagi",
            "Oriol Nieto",
            "Zeyu Jin",
            "Dinesh Manocha"
        ],
        "published": "2024-05-24T16:21:59Z"
    },
    {
        "title": "The Road Less Scheduled",
        "link": "http://arxiv.org/abs/2405.15682v1",
        "abstract": "Existing learning rate schedules that do not require specification of the\noptimization stopping step T are greatly out-performed by learning rate\nschedules that depend on T. We propose an approach that avoids the need for\nthis stopping time by eschewing the use of schedules entirely, while exhibiting\nstate-of-the-art performance compared to schedules across a wide family of\nproblems ranging from convex problems to large-scale deep learning problems.\nOur Schedule-Free approach introduces no additional hyper-parameters over\nstandard optimizers with momentum. Our method is a direct consequence of a new\ntheory we develop that unifies scheduling and iterate averaging. An open source\nimplementation of our method is available\n(https://github.com/facebookresearch/schedule_free).",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.OC",
            "stat.ML"
        ],
        "authors": [
            "Aaron Defazio",
            " Xingyu",
            " Yang",
            "Harsh Mehta",
            "Konstantin Mishchenko",
            "Ahmed Khaled",
            "Ashok Cutkosky"
        ],
        "published": "2024-05-24T16:20:46Z"
    },
    {
        "title": "SMART: Scalable Multi-agent Real-time Simulation via Next-token\n  Prediction",
        "link": "http://arxiv.org/abs/2405.15677v1",
        "abstract": "Data-driven autonomous driving motion generation tasks are frequently\nimpacted by the limitations of dataset size and the domain gap between\ndatasets, which precludes their extensive application in real-world scenarios.\nTo address this issue, we introduce SMART, a novel autonomous driving motion\ngeneration paradigm that models vectorized map and agent trajectory data into\ndiscrete sequence tokens. These tokens are then processed through a\ndecoder-only transformer architecture to train for the next token prediction\ntask across spatial-temporal series. This GPT-style method allows the model to\nlearn the motion distribution in real driving scenarios. SMART achieves\nstate-of-the-art performance across most of the metrics on the generative Sim\nAgents challenge, ranking 1st on the leaderboards of Waymo Open Motion Dataset\n(WOMD), demonstrating remarkable inference speed. Moreover, SMART represents\nthe generative model in the autonomous driving motion domain, exhibiting\nzero-shot generalization capabilities: Using only the NuPlan dataset for\ntraining and WOMD for validation, SMART achieved a competitive score of 0.71 on\nthe Sim Agents challenge. Lastly, we have collected over 1 billion motion\ntokens from multiple datasets, validating the model's scalability. These\nresults suggest that SMART has initially emulated two important properties:\nscalability and zero-shot generalization, and preliminarily meets the needs of\nlarge-scale real-time simulation applications. We have released all the code to\npromote the exploration of models for motion generation in the autonomous\ndriving field.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "authors": [
            "Wei Wu",
            "Xiaoxin Feng",
            "Ziyan Gao",
            "Yuheng Kan"
        ],
        "published": "2024-05-24T16:17:35Z"
    },
    {
        "title": "Taming Score-Based Diffusion Priors for Infinite-Dimensional Nonlinear\n  Inverse Problems",
        "link": "http://arxiv.org/abs/2405.15676v1",
        "abstract": "This work introduces a sampling method capable of solving Bayesian inverse\nproblems in function space. It does not assume the log-concavity of the\nlikelihood, meaning that it is compatible with nonlinear inverse problems. The\nmethod leverages the recently defined infinite-dimensional score-based\ndiffusion models as a learning-based prior, while enabling provable posterior\nsampling through a Langevin-type MCMC algorithm defined on function spaces. A\nnovel convergence analysis is conducted, inspired by the fixed-point methods\nestablished for traditional regularization-by-denoising algorithms and\ncompatible with weighted annealing. The obtained convergence bound explicitly\ndepends on the approximation error of the score; a well-approximated score is\nessential to obtain a well-approximated posterior. Stylized and PDE-based\nexamples are provided, demonstrating the validity of our convergence analysis.\nWe conclude by presenting a discussion of the method's challenges related to\nlearning the score and computational complexity.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "cs.NA",
            "math.NA",
            "62F15, 65N21, 68Q32, 60Hxx, 60Jxx, 65C05, 82C31"
        ],
        "authors": [
            "Lorenzo Baldassari",
            "Ali Siahkoohi",
            "Josselin Garnier",
            "Knut Solna",
            "Maarten V. de Hoop"
        ],
        "published": "2024-05-24T16:17:01Z"
    },
    {
        "title": "Consistency of Neural Causal Partial Identification",
        "link": "http://arxiv.org/abs/2405.15673v1",
        "abstract": "Recent progress in Neural Causal Models (NCMs) showcased how identification\nand partial identification of causal effects can be automatically carried out\nvia training of neural generative models that respect the constraints encoded\nin a given causal graph [Xia et al. 2022, Balazadeh et al. 2022]. However,\nformal consistency of these methods has only been proven for the case of\ndiscrete variables or only for linear causal models. In this work, we prove\nconsistency of partial identification via NCMs in a general setting with both\ncontinuous and categorical variables. Further, our results highlight the impact\nof the design of the underlying neural network architecture in terms of depth\nand connectivity as well as the importance of applying Lipschitz regularization\nin the training phase. In particular, we provide a counterexample showing that\nwithout Lipschitz regularization the NCM may not be asymptotically consistent.\nOur results are enabled by new results on the approximability of structural\ncausal models via neural generative models, together with an analysis of the\nsample complexity of the resulting architectures and how that translates into\nan error in the constrained optimization problem that defines the partial\nidentification bounds.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Jiyuan Tan",
            "Jose Blanchet",
            "Vasilis Syrgkanis"
        ],
        "published": "2024-05-24T16:12:39Z"
    },
    {
        "title": "The Undecidability of Quantified Announcements",
        "link": "http://arxiv.org/abs/2405.15671v1",
        "abstract": "This paper demonstrates the undecidability of a number of logics with\nquantification over public announcements: arbitrary public announcement logic\n(APAL), group announcement logic (GAL), and coalition announcement logic (CAL).\nIn APAL we consider the informative consequences of any announcement, in GAL we\nconsider the informative consequences of a group of agents (this group may be a\nproper subset of the set of all agents) all of which are simultaneously (and\npublicly) making known announcements. So this is more restrictive than APAL.\nFinally, CAL is as GAL except that we now quantify over anything the agents not\nin that group may announce simultaneously as well. The logic CAL therefore has\nsome features of game logic and of ATL. We show that when there are multiple\nagents in the language, the satisfiability problem is undecidable for APAL,\nGAL, and CAL. In the single agent case, the satisfiability problem is decidable\nfor all three logics. This paper corrects an error to the submitted version of\nUndecidability of Quantified Announcements, identified by Yuta Assami . The\nnature of the error was in the definition of the formula cga (X) (see\nSubsection 5.2) which is corrected in this version.",
        "subjects": [
            "cs.LO"
        ],
        "authors": [
            "Thomas Ågotnes",
            "Hans van Ditmarsch",
            "Tim French"
        ],
        "published": "2024-05-24T16:07:25Z"
    },
    {
        "title": "Enhancing Reentry Support Programs Through Digital Literacy Integration",
        "link": "http://dx.doi.org/10.1145/3643834.3660730",
        "abstract": "Challenges faced by formerly incarcerated individuals in the United States\nraise questions about our society's ability to truly provide second chances.\nThis paper presents the outcomes of our ongoing collaboration with a non-profit\norganization dedicated to reentry support. We highlight the multifaceted\nchallenges individuals face during their reentry journey, including support\nprograms that prioritize supervision over service, unresponsive support\nsystems, limited access to resources, financial struggles exacerbated by\nrestricted employment opportunities, and technological barriers. In the face of\nsuch complex social challenges, our work aims to facilitate our partner\norganization's ongoing efforts to promote digital literacy through a web\napplication that is integrated into their existing processes. We share initial\nfeedback from the stakeholders, draw out four implications: supporting\ncontinuity of care, promoting reflection through slow technology, building in\nflexibility, and reconfiguring toward existing infrastructure, and conclude\nwith a reflection on our role as partners on the side.",
        "subjects": [
            "cs.HC",
            "cs.DL"
        ],
        "authors": [
            "Aakash Gautam",
            "Khushboo Gandhi",
            "Jessica Eileen Sendejo"
        ],
        "published": "2024-05-24T16:06:01Z"
    },
    {
        "title": "What Do You See? Enhancing Zero-Shot Image Classification with\n  Multimodal Large Language Models",
        "link": "http://arxiv.org/abs/2405.15668v1",
        "abstract": "Large language models (LLMs) has been effectively used for many computer\nvision tasks, including image classification. In this paper, we present a\nsimple yet effective approach for zero-shot image classification using\nmultimodal LLMs. By employing multimodal LLMs, we generate comprehensive\ntextual representations from input images. These textual representations are\nthen utilized to generate fixed-dimensional features in a cross-modal embedding\nspace. Subsequently, these features are fused together to perform zero-shot\nclassification using a linear classifier. Our method does not require prompt\nengineering for each dataset; instead, we use a single, straightforward, set of\nprompts across all datasets. We evaluated our method on several datasets, and\nour results demonstrate its remarkable effectiveness, surpassing benchmark\naccuracy on multiple datasets. On average over ten benchmarks, our method\nachieved an accuracy gain of 4.1 percentage points, with an increase of 6.8\npercentage points on the ImageNet dataset, compared to prior methods. Our\nfindings highlight the potential of multimodal LLMs to enhance computer vision\ntasks such as zero-shot image classification, offering a significant\nimprovement over traditional methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Abdelrahman Abdelhamed",
            "Mahmoud Afifi",
            "Alec Go"
        ],
        "published": "2024-05-24T16:05:15Z"
    },
    {
        "title": "Examining Ownership Models in Software Teams: A Systematic Literature\n  Review and a Replication Study",
        "link": "http://arxiv.org/abs/2405.15665v1",
        "abstract": "Effective ownership of software artifacts, particularly code, is crucial for\naccountability, knowledge sharing, and code quality enhancement. Researchers\nhave proposed models linking ownership of software artifacts with developer\nperformance and code quality. Our study aims to systematically examine various\nownership models and provide a structured literature overview. Conducting a\nsystematic literature review, we identified 79 relevant papers published\nbetween 2005 and 2022. We developed a taxonomy of ownership artifacts based on\ntype, owners, and degree of ownership, along with compiling modeling variables\nand analytics types used in each study. Additionally, we assessed the\nreplication status of each study. As a result, we identified nine distinct\nsoftware artifacts whose ownership has been discussed in the literature, with\n\"Code\" being the most frequently analyzed artifact. We found that only three\npapers (3.79%) provided code and data, whereas nine papers (11.4%) provided\nonly data. Using our systematic literature review results, we replicated\nexperiments on nine priority projects at \\texttt{Brightsquid}. The company\naimed to compare its code quality against ownership factors in other teams, so\nwe conducted a replication study using their data. Unlike prior studies, we\nfound no strong correlation between minor contributors and bug numbers.\nSurprisingly, we found no strong link between the total number of developers\nmodifying a file and bug counts, contrasting previous findings. However, we\nobserved a significant correlation between major contributors and bug counts,\ndiverging from earlier research.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Umme Ayman Koana",
            "Quang Hy Le",
            "Shadikur Rahman",
            "Chris Carlson",
            "Francis Chew",
            "Maleknaz Nayebi"
        ],
        "published": "2024-05-24T16:03:22Z"
    },
    {
        "title": "GroundGrid:LiDAR Point Cloud Ground Segmentation and Terrain Estimation",
        "link": "http://dx.doi.org/10.1109/LRA.2023.3333233",
        "abstract": "The precise point cloud ground segmentation is a crucial prerequisite of\nvirtually all perception tasks for LiDAR sensors in autonomous vehicles.\nEspecially the clustering and extraction of objects from a point cloud usually\nrelies on an accurate removal of ground points. The correct estimation of the\nsurrounding terrain is important for aspects of the drivability of a surface,\npath planning, and obstacle prediction. In this article, we propose our system\nGroundGrid which relies on 2D elevation maps to solve the terrain estimation\nand point cloud ground segmentation problems. We evaluate the ground\nsegmentation and terrain estimation performance of GroundGrid and compare it to\nother state-of-the-art methods using the SemanticKITTI dataset and a novel\nevaluation method relying on airborne LiDAR scanning. The results show that\nGroundGrid is capable of outperforming other state-of-the-art systems with an\naverage IoU of 94.78% while maintaining a high run-time performance of 171Hz.\nThe source code is available at https://github.com/dcmlr/groundgrid",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "authors": [
            "Nicolai Steinke",
            "Daniel Göhring",
            "Raùl Rojas"
        ],
        "published": "2024-05-24T16:02:44Z"
    },
    {
        "title": "Soft happy colourings and community structure of networks",
        "link": "http://arxiv.org/abs/2405.15663v1",
        "abstract": "For $0<\\rho\\leq 1$, a $\\rho$-happy vertex $v$ in a coloured graph $G$ has at\nleast $\\rho\\cdot \\mathrm{deg}(v)$ same-colour neighbours, and a $\\rho$-happy\ncolouring (aka soft happy colouring) of $G$ is a vertex colouring that makes\nall the vertices $\\rho$-happy. A community is a subgraph whose vertices are\nmore adjacent to themselves than the rest of the vertices. Graphs with\ncommunity structures can be modelled by random graph models such as the\nstochastic block model (SBM). In this paper, we present several theorems\nshowing that both of these notions are related, with numerous real-world\napplications. We show that, with high probability, communities of graphs in the\nstochastic block model induce $\\rho$-happy colouring on all vertices if certain\nconditions on the model parameters are satisfied. Moreover, a probabilistic\nthreshold on $\\rho$ is derived so that communities of a graph in the SBM induce\na $\\rho$-happy colouring. Furthermore, the asymptotic behaviour of $\\rho$-happy\ncolouring induced by the graph's communities is discussed when $\\rho$ is less\nthan a threshold. We develop heuristic polynomial-time algorithms for soft\nhappy colouring that often correlate with the graphs' community structure.\nFinally, we present an experimental evaluation to compare the performance of\nthe proposed algorithms thereby demonstrating the validity of the theoretical\nresults.",
        "subjects": [
            "cs.DM"
        ],
        "authors": [
            "Mohammad H. Shekarriz",
            "Dhananjay Thiruvady",
            "Asef Nazari",
            "Rhyd Lewis"
        ],
        "published": "2024-05-24T16:00:38Z"
    },
    {
        "title": "Class Machine Unlearning for Complex Data via Concepts Inference and\n  Data Poisoning",
        "link": "http://arxiv.org/abs/2405.15662v1",
        "abstract": "In current AI era, users may request AI companies to delete their data from\nthe training dataset due to the privacy concerns. As a model owner, retraining\na model will consume significant computational resources. Therefore, machine\nunlearning is a new emerged technology to allow model owner to delete requested\ntraining data or a class with little affecting on the model performance.\nHowever, for large-scaling complex data, such as image or text data, unlearning\na class from a model leads to a inferior performance due to the difficulty to\nidentify the link between classes and model. An inaccurate class deleting may\nlead to over or under unlearning. In this paper, to accurately defining the\nunlearning class of complex data, we apply the definition of Concept, rather\nthan an image feature or a token of text data, to represent the semantic\ninformation of unlearning class. This new representation can cut the link\nbetween the model and the class, leading to a complete erasing of the impact of\na class. To analyze the impact of the concept of complex data, we adopt a\nPost-hoc Concept Bottleneck Model, and Integrated Gradients to precisely\nidentify concepts across different classes. Next, we take advantage of data\npoisoning with random and targeted labels to propose unlearning methods. We\ntest our methods on both image classification models and large language models\n(LLMs). The results consistently show that the proposed methods can accurately\nerase targeted information from models and can largely maintain the performance\nof the models.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Wenhan Chang",
            "Tianqing Zhu",
            "Heng Xu",
            "Wenjian Liu",
            "Wanlei Zhou"
        ],
        "published": "2024-05-24T15:59:17Z"
    },
    {
        "title": "Exposing Image Classifier Shortcuts with Counterfactual Frequency (CoF)\n  Tables",
        "link": "http://arxiv.org/abs/2405.15661v1",
        "abstract": "The rise of deep learning in image classification has brought unprecedented\naccuracy but also highlighted a key issue: the use of 'shortcuts' by models.\nSuch shortcuts are easy-to-learn patterns from the training data that fail to\ngeneralise to new data. Examples include the use of a copyright watermark to\nrecognise horses, snowy background to recognise huskies, or ink markings to\ndetect malignant skin lesions. The explainable AI (XAI) community has suggested\nusing instance-level explanations to detect shortcuts without external data,\nbut this requires the examination of many explanations to confirm the presence\nof such shortcuts, making it a labour-intensive process. To address these\nchallenges, we introduce Counterfactual Frequency (CoF) tables, a novel\napproach that aggregates instance-based explanations into global insights, and\nexposes shortcuts. The aggregation implies the need for some semantic concepts\nto be used in the explanations, which we solve by labelling the segments of an\nimage. We demonstrate the utility of CoF tables across several datasets,\nrevealing the shortcuts learned from them.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "James Hinns",
            "David Martens"
        ],
        "published": "2024-05-24T15:58:02Z"
    },
    {
        "title": "Low-Light Video Enhancement via Spatial-Temporal Consistent Illumination\n  and Reflection Decomposition",
        "link": "http://arxiv.org/abs/2405.15660v1",
        "abstract": "Low-Light Video Enhancement (LLVE) seeks to restore dynamic and static scenes\nplagued by severe invisibility and noise. One critical aspect is formulating a\nconsistency constraint specifically for temporal-spatial illumination and\nappearance enhanced versions, a dimension overlooked in existing methods. In\nthis paper, we present an innovative video Retinex-based decomposition strategy\nthat operates without the need for explicit supervision to delineate\nillumination and reflectance components. We leverage dynamic cross-frame\ncorrespondences for intrinsic appearance and enforce a scene-level continuity\nconstraint on the illumination field to yield satisfactory consistent\ndecomposition results. To further ensure consistent decomposition, we introduce\na dual-structure enhancement network featuring a novel cross-frame interaction\nmechanism. This mechanism can seamlessly integrate with encoder-decoder\nsingle-frame networks, incurring minimal additional parameter costs. By\nsupervising different frames simultaneously, this network encourages them to\nexhibit matching decomposition features, thus achieving the desired temporal\npropagation. Extensive experiments are conducted on widely recognized LLVE\nbenchmarks, covering diverse scenarios. Our framework consistently outperforms\nexisting methods, establishing a new state-of-the-art (SOTA) performance.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xiaogang Xu",
            "Kun Zhou",
            "Tao Hu",
            "Ruixing Wang",
            "Hujun Bao"
        ],
        "published": "2024-05-24T15:56:40Z"
    },
    {
        "title": "HDC: Hierarchical Semantic Decoding with Counting Assistance for\n  Generalized Referring Expression Segmentation",
        "link": "http://arxiv.org/abs/2405.15658v1",
        "abstract": "The newly proposed Generalized Referring Expression Segmentation (GRES)\namplifies the formulation of classic RES by involving multiple/non-target\nscenarios. Recent approaches focus on optimizing the last modality-fused\nfeature which is directly utilized for segmentation and object-existence\nidentification. However, the attempt to integrate all-grained information into\na single joint representation is impractical in GRES due to the increased\ncomplexity of the spatial relationships among instances and deceptive text\ndescriptions. Furthermore, the subsequent binary target justification across\nall referent scenarios fails to specify their inherent differences, leading to\nambiguity in object understanding. To address the weakness, we propose a\n$\\textbf{H}$ierarchical Semantic $\\textbf{D}$ecoding with $\\textbf{C}$ounting\nAssistance framework (HDC). It hierarchically transfers complementary modality\ninformation across granularities, and then aggregates each well-aligned\nsemantic correspondence for multi-level decoding. Moreover, with complete\nsemantic context modeling, we endow HDC with explicit counting capability to\nfacilitate comprehensive object perception in multiple/single/non-target\nsettings. Experimental results on gRefCOCO, Ref-ZOM, R-RefCOCO, and RefCOCO\nbenchmarks demonstrate the effectiveness and rationality of HDC which\noutperforms the state-of-the-art GRES methods by a remarkable margin. Code will\nbe available $\\href{https://github.com/RobertLuo1/HDC}{here}$.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Zhuoyan Luo",
            "Yinghao Wu",
            "Yong Liu",
            "Yicheng Xiao",
            "Xiao-Ping Zhang",
            "Yujiu Yang"
        ],
        "published": "2024-05-24T15:53:59Z"
    },
    {
        "title": "Balanced truncation with conformal maps",
        "link": "http://arxiv.org/abs/2405.15656v1",
        "abstract": "We consider the problem of constructing reduced models for large scale\nsystems with poles in general domains in the complex plane (as opposed to,\ne.g., the open left-half plane or the open unit disk). Our goal is to design a\nmodel reduction scheme, building upon theoretically established methodologies,\nyet encompassing this new class of models. To this aim, we develop a balanced\ntruncation framework through conformal maps to handle poles in general domains.\nThe major difference from classical balanced truncation resides in the\nformulation of the Gramians. We show that these new Gramians can still be\ncomputed by solving modified Lyapunov equations for specific conformal maps. A\nnumerical algorithm to perform balanced truncation with conformal maps is\ndeveloped and is tested on three numerical examples, namely a heat model, the\nSchr\\\"odinger equation, and the undamped linear wave equation, the latter two\nhaving spectra on the imaginary axis.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "math.OC"
        ],
        "authors": [
            "Alessandro Borghi",
            "Tobias Breiten",
            "Serkan Gugercin"
        ],
        "published": "2024-05-24T15:51:32Z"
    },
    {
        "title": "HiddenSpeaker: Generate Imperceptible Unlearnable Audios for Speaker\n  Verification System",
        "link": "http://arxiv.org/abs/2405.15655v1",
        "abstract": "In recent years, the remarkable advancements in deep neural networks have\nbrought tremendous convenience. However, the training process of a highly\neffective model necessitates a substantial quantity of samples, which brings\nhuge potential threats, like unauthorized exploitation with privacy leakage. In\nresponse, we propose a framework named HiddenSpeaker, embedding imperceptible\nperturbations within the training speech samples and rendering them unlearnable\nfor deep-learning-based speaker verification systems that employ large-scale\nspeakers for efficient training. The HiddenSpeaker utilizes a simplified\nerror-minimizing method named Single-Level Error-Minimizing (SLEM) to generate\nspecific and effective perturbations. Additionally, a hybrid objective function\nis employed for human perceptual optimization, ensuring the perturbation is\nindistinguishable from human listeners. We conduct extensive experiments on\nmultiple state-of-the-art (SOTA) models in the speaker verification domain to\nevaluate HiddenSpeaker. Our results demonstrate that HiddenSpeaker not only\ndeceives the model with unlearnable samples but also enhances the\nimperceptibility of the perturbations, showcasing strong transferability across\ndifferent models.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "authors": [
            "Zhisheng Zhang",
            "Pengyang Huang"
        ],
        "published": "2024-05-24T15:49:00Z"
    },
    {
        "title": "$$\\mathbf{L^2\\cdot M = C^2}$$ Large Language Models as Covert\n  Channels... a Systematic Analysis",
        "link": "http://arxiv.org/abs/2405.15652v1",
        "abstract": "Large Language Models (LLMs) have gained significant popularity in the last\nfew years due to their performance in diverse tasks such as translation,\nprediction, or content generation. At the same time, the research community has\nshown that LLMs are susceptible to various attacks but can also improve the\nsecurity of diverse systems. However, besides enabling more secure systems, how\nwell do open source LLMs behave as covertext distributions to, e.g., facilitate\ncensorship resistant communication?\n  In this paper, we explore the capabilities of open-source LLM-based covert\nchannels. We approach this problem from the experimental side by empirically\nmeasuring the security vs. capacity of the open-source LLM model (Llama-7B) to\nassess how well it performs as a covert channel. Although our results indicate\nthat such channels are not likely to achieve high practical bitrates, which\ndepend on message length and model entropy, we also show that the chance for an\nadversary to detect covert communication is low. To ensure that our results can\nbe used with the least effort as a general reference, we employ a conceptually\nsimple and concise scheme and only assume public models.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Simen Gaure",
            "Stefanos Koffas",
            "Stjepan Picek",
            "Sondre Rønjom"
        ],
        "published": "2024-05-24T15:47:35Z"
    },
    {
        "title": "A Logic of Knowledge and Justifications, with an Application to\n  Computational Trust",
        "link": "http://arxiv.org/abs/2405.15647v1",
        "abstract": "We present a logical framework that enables us to define a formal theory of\ncomputational trust in which this notion is analysed in terms of epistemic\nattitudes towards the possible objects of trust and in relation to existing\nevidence in favour of the trustworthiness of these objects. The framework is\nbased on a quantified epistemic and justification logic featuring a\nnon-standard handling of identities. Thus, the theory is able to account for\nthe hyperintensional nature of computational trust. We present a proof system\nand a frame semantics for the logic, we prove soundness and completeness\nresults and we introduce the syntactical machinery required to define a theory\nof trust.",
        "subjects": [
            "cs.LO"
        ],
        "authors": [
            "Francesco A. Genco"
        ],
        "published": "2024-05-24T15:37:55Z"
    },
    {
        "title": "LLM-based Robot Task Planning with Exceptional Handling for General\n  Purpose Service Robots",
        "link": "http://arxiv.org/abs/2405.15646v1",
        "abstract": "The development of a general purpose service robot for daily life\nnecessitates the robot's ability to deploy a myriad of fundamental behaviors\njudiciously. Recent advancements in training Large Language Models (LLMs) can\nbe used to generate action sequences directly, given an instruction in natural\nlanguage with no additional domain information. However, while the outputs of\nLLMs are semantically correct, the generated task plans may not accurately map\nto acceptable actions and might encompass various linguistic ambiguities. LLM\nhallucinations pose another challenge for robot task planning, which results in\ncontent that is inconsistent with real-world facts or user inputs. In this\npaper, we propose a task planning method based on a constrained LLM prompt\nscheme, which can generate an executable action sequence from a command. An\nexceptional handling module is further proposed to deal with LLM hallucinations\nproblem. This module can ensure the LLM-generated results are admissible in the\ncurrent environment. We evaluate our method on the commands generated by the\nRoboCup@Home Command Generator, observing that the robot demonstrates\nexceptional performance in both comprehending instructions and executing tasks.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Ruoyu Wang",
            "Zhipeng Yang",
            "Zinan Zhao",
            "Xinyan Tong",
            "Zhi Hong",
            "Kun Qian"
        ],
        "published": "2024-05-24T15:35:49Z"
    },
    {
        "title": "An Online Probabilistic Distributed Tracing System",
        "link": "http://arxiv.org/abs/2405.15645v1",
        "abstract": "Distributed tracing has become a fundamental tool for diagnosing performance\nissues in the cloud by recording causally ordered, end-to-end workflows of\nrequest executions. However, tracing in production workloads can introduce\nsignificant overheads due to the extensive instrumentation needed for\nidentifying performance variations. This paper addresses the trade-off between\nthe cost of tracing and the utility of the \"spans\" within that trace through\nAstraea, an online probabilistic distributed tracing system. Astraea is based\non our technique that combines online Bayesian learning and multi-armed bandit\nframeworks. This formulation enables Astraea to effectively steer tracing\ntowards the useful instrumentation needed for accurate performance diagnosis.\nAstraea localizes performance variations using only 10-28% of available\ninstrumentation, markedly reducing tracing overhead, storage, compute costs,\nand trace analysis time.",
        "subjects": [
            "cs.PF",
            "cs.DC"
        ],
        "authors": [
            "M. Toslali",
            "S. Qasim",
            "S. Parthasarathy",
            "F. A. Oliveira",
            "H. Huang",
            "G. Stringhini",
            "Z. Liu",
            "A. K. Coskun"
        ],
        "published": "2024-05-24T15:34:25Z"
    },
    {
        "title": "Harnessing Increased Client Participation with Cohort-Parallel Federated\n  Learning",
        "link": "http://arxiv.org/abs/2405.15644v1",
        "abstract": "Federated Learning (FL) is a machine learning approach where nodes\ncollaboratively train a global model. As more nodes participate in a round of\nFL, the effectiveness of individual model updates by nodes also diminishes. In\nthis study, we increase the effectiveness of client updates by dividing the\nnetwork into smaller partitions, or cohorts. We introduce Cohort-Parallel\nFederated Learning (CPFL): a novel learning approach where each cohort\nindependently trains a global model using FL, until convergence, and the\nproduced models by each cohort are then unified using one-shot Knowledge\nDistillation (KD) and a cross-domain, unlabeled dataset. The insight behind\nCPFL is that smaller, isolated networks converge quicker than in a one-network\nsetting where all nodes participate. Through exhaustive experiments involving\nrealistic traces and non-IID data distributions on the CIFAR-10 and FEMNIST\nimage classification tasks, we investigate the balance between the number of\ncohorts, model accuracy, training time, and compute and communication\nresources. Compared to traditional FL, CPFL with four cohorts, non-IID data\ndistribution, and CIFAR-10 yields a 1.9$\\times$ reduction in train time and a\n1.3$\\times$ reduction in resource usage, with a minimal drop in test accuracy.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "authors": [
            "Akash Dhasade",
            "Anne-Marie Kermarrec",
            "Tuan-Anh Nguyen",
            "Rafael Pires",
            "Martijn de Vos"
        ],
        "published": "2024-05-24T15:34:09Z"
    },
    {
        "title": "Reducing the cost of posterior sampling in linear inverse problems via\n  task-dependent score learning",
        "link": "http://arxiv.org/abs/2405.15643v1",
        "abstract": "Score-based diffusion models (SDMs) offer a flexible approach to sample from\nthe posterior distribution in a variety of Bayesian inverse problems. In the\nliterature, the prior score is utilized to sample from the posterior by\ndifferent methods that require multiple evaluations of the forward mapping in\norder to generate a single posterior sample. These methods are often designed\nwith the objective of enabling the direct use of the unconditional prior score\nand, therefore, task-independent training. In this paper, we focus on linear\ninverse problems, when evaluation of the forward mapping is computationally\nexpensive and frequent posterior sampling is required for new measurement data,\nsuch as in medical imaging. We demonstrate that the evaluation of the forward\nmapping can be entirely bypassed during posterior sample generation. Instead,\nwithout introducing any error, the computational effort can be shifted to an\noffline task of training the score of a specific diffusion-like random process.\nIn particular, the training is task-dependent requiring information about the\nforward mapping but not about the measurement data. It is shown that the\nconditional score corresponding to the posterior can be obtained from the\nauxiliary score by suitable affine transformations. We prove that this\nobservation generalizes to the framework of infinite-dimensional diffusion\nmodels introduced recently and provide numerical analysis of the method.\nMoreover, we validate our findings with numerical experiments.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "cs.NA",
            "math.AP",
            "math.NA",
            "math.PR",
            "62F15, 65N21, 68Q32, 60Hxx, 60Jxx"
        ],
        "authors": [
            "Fabian Schneider",
            "Duc-Lam Duong",
            "Matti Lassas",
            "Maarten V. de Hoop",
            "Tapio Helin"
        ],
        "published": "2024-05-24T15:33:27Z"
    },
    {
        "title": "Effective Confidence Region Prediction Using Probability Forecasters",
        "link": "http://dx.doi.org/10.1007/11527770_66",
        "abstract": "Confidence region prediction is a practically useful extension to the\ncommonly studied pattern recognition problem. Instead of predicting a single\nlabel, the constraint is relaxed to allow prediction of a subset of labels\ngiven a desired confidence level 1-delta. Ideally, effective region predictions\nshould be (1) well calibrated - predictive regions at confidence level 1-delta\nshould err with relative frequency at most delta and (2) be as narrow (or\ncertain) as possible. We present a simple technique to generate confidence\nregion predictions from conditional probability estimates (probability\nforecasts). We use this 'conversion' technique to generate confidence region\npredictions from probability forecasts output by standard machine learning\nalgorithms when tested on 15 multi-class datasets. Our results show that\napproximately 44% of experiments demonstrate well-calibrated confidence region\npredictions, with the K-Nearest Neighbour algorithm tending to perform\nconsistently well across all data. Our results illustrate the practical\nbenefits of effective confidence region prediction with respect to medical\ndiagnostics, where guarantees of capturing the true disease label can be given.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "David Lindsay",
            "Sian Lindsay"
        ],
        "published": "2024-05-24T15:33:08Z"
    },
    {
        "title": "GECKO: Generative Language Model for English, Code and Korean",
        "link": "http://arxiv.org/abs/2405.15640v1",
        "abstract": "We introduce GECKO, a bilingual large language model (LLM) optimized for\nKorean and English, along with programming languages. GECKO is pretrained on\nthe balanced, high-quality corpus of Korean and English employing LLaMA\narchitecture. In this report, we share the experiences of several efforts to\nbuild a better data pipeline for the corpus and to train our model. GECKO shows\ngreat efficiency in token generations for both Korean and English, despite its\nsmall size of vocabulary. We measure the performance on the representative\nbenchmarks in terms of Korean, English and Code, and it exhibits great\nperformance on KMMLU (Korean MMLU) and modest performance in English and Code,\neven with its smaller number of trained tokens compared to English-focused\nLLMs. GECKO is available to the open-source community under a permissive\nlicense. We hope our work offers a research baseline and practical insights for\nKorean LLM research. The model can be found at:\nhttps://huggingface.co/kifai/GECKO-7B",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Sungwoo Oh",
            "Donggyu Kim"
        ],
        "published": "2024-05-24T15:30:41Z"
    },
    {
        "title": "M4U: Evaluating Multilingual Understanding and Reasoning for Large\n  Multimodal Models",
        "link": "http://arxiv.org/abs/2405.15638v1",
        "abstract": "Multilingual multimodal reasoning is a core component in achieving\nhuman-level intelligence. However, most existing benchmarks for multilingual\nmultimodal reasoning struggle to differentiate between models of varying\nperformance; even language models without visual capabilities can easily\nachieve high scores. This leaves a comprehensive evaluation of leading\nmultilingual multimodal models largely unexplored. In this work, we introduce\nM4U, a novel and challenging benchmark for assessing the capability of\nmulti-discipline multilingual multimodal understanding and reasoning. M4U\ncontains 8,931 samples covering 64 disciplines across 16 subfields in Science,\nEngineering, and Healthcare in Chinese, English, and German. Using M4U, we\nconduct extensive evaluations of 21 leading Large Multimodal Models (LMMs) and\nLarge Language Models (LLMs) with external tools. The evaluation results show\nthat the state-of-the-art model, GPT-4o, achieves only 47.6% average accuracy\non M4U. Additionally, we observe that the leading LMMs exhibit significant\nlanguage preferences. Our in-depth analysis indicates that leading LMMs,\nincluding GPT-4o, suffer performance degradation when prompted with\ncross-lingual multimodal questions, such as images with key textual information\nin Chinese while the question is in German. We believe that M4U can serve as a\ncrucial tool for systematically evaluating LMMs based on their multilingual\nmultimodal reasoning capabilities and monitoring their development. The\nhomepage, codes and data are public available.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "authors": [
            "Hongyu Wang",
            "Jiayu Xu",
            "Senwei Xie",
            "Ruiping Wang",
            "Jialin Li",
            "Zhaojie Xie",
            "Bin Zhang",
            "Chuyan Xiong",
            "Xilin Chen"
        ],
        "published": "2024-05-24T15:25:28Z"
    },
    {
        "title": "Clearing the Path for Software Sustainability",
        "link": "http://arxiv.org/abs/2405.15637v1",
        "abstract": "The advancement of software sustainability encounters notable challenges,\nunderscoring the necessity for understanding these challenges to facilitate\nsignificant progress and pave the way for effective solutions to advance\nsoftware sustainability. This paper outlines key challenges identified in\nliterature based on findings from a tertiary study. Challenges identified\ninclude: confusion regarding the definition of software sustainability,\nuncertainty about when to consider sustainability in software development, lack\nof assessment metrics and tools, narrow perspectives on sustainability in\nsoftware systems, insufficient awareness and education, and a lack of serious\nconsiderations in practice. The paper aims at clarifying the confusion\nsurrounding software sustainability to motivate effective solutions. The\nprovided recommendations aim to give a more organized approach towards\nadvancing sustainable software development, emphasizing comprehensive\nstrategies, the integration of sustainability as a fundamental aspect of\nsoftware development, actionable research directions, and the cultivation of a\ncommon understanding of sustainable software.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Jennifer Gross",
            "Sofia Ouhbi"
        ],
        "published": "2024-05-24T15:24:24Z"
    },
    {
        "title": "Visualize and Paint GAN Activations",
        "link": "http://arxiv.org/abs/2405.15636v1",
        "abstract": "We investigate how generated structures of GANs correlate with their\nactivations in hidden layers, with the purpose of better understanding the\ninner workings of those models and being able to paint structures with\nunconditionally trained GANs. This gives us more control over the generated\nimages, allowing to generate them from a semantic segmentation map while not\nrequiring such a segmentation in the training data. To this end we introduce\nthe concept of tileable features, allowing us to identify activations that work\nwell for painting.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Rudolf Herdt",
            "Peter Maass"
        ],
        "published": "2024-05-24T15:22:58Z"
    },
    {
        "title": "Less is more: Summarizing Patch Tokens for efficient Multi-Label\n  Class-Incremental Learning",
        "link": "http://arxiv.org/abs/2405.15633v1",
        "abstract": "Prompt tuning has emerged as an effective rehearsal-free technique for\nclass-incremental learning (CIL) that learns a tiny set of task-specific\nparameters (or prompts) to instruct a pre-trained transformer to learn on a\nsequence of tasks. Albeit effective, prompt tuning methods do not lend well in\nthe multi-label class incremental learning (MLCIL) scenario (where an image\ncontains multiple foreground classes) due to the ambiguity in selecting the\ncorrect prompt(s) corresponding to different foreground objects belonging to\nmultiple tasks. To circumvent this issue we propose to eliminate the prompt\nselection mechanism by maintaining task-specific pathways, which allow us to\nlearn representations that do not interact with the ones from the other tasks.\nSince independent pathways in truly incremental scenarios will result in an\nexplosion of computation due to the quadratically complex multi-head\nself-attention (MSA) operation in prompt tuning, we propose to reduce the\noriginal patch token embeddings into summarized tokens. Prompt tuning is then\napplied to these fewer summarized tokens to compute the final representation.\nOur proposed method Multi-Label class incremental learning via summarising\npAtch tokeN Embeddings (MULTI-LANE) enables learning disentangled task-specific\nrepresentations in MLCIL while ensuring fast inference. We conduct experiments\nin common benchmarks and demonstrate that our MULTI-LANE achieves a new\nstate-of-the-art in MLCIL. Additionally, we show that MULTI-LANE is also\ncompetitive in the CIL setting. Source code available at\nhttps://github.com/tdemin16/multi-lane",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Thomas De Min",
            "Massimiliano Mancini",
            "Stéphane Lathuilière",
            "Subhankar Roy",
            "Elisa Ricci"
        ],
        "published": "2024-05-24T15:18:27Z"
    },
    {
        "title": "Federated Behavioural Planes: Explaining the Evolution of Client\n  Behaviour in Federated Learning",
        "link": "http://arxiv.org/abs/2405.15632v1",
        "abstract": "Federated Learning (FL), a privacy-aware approach in distributed deep\nlearning environments, enables many clients to collaboratively train a model\nwithout sharing sensitive data, thereby reducing privacy risks. However,\nenabling human trust and control over FL systems requires understanding the\nevolving behaviour of clients, whether beneficial or detrimental for the\ntraining, which still represents a key challenge in the current literature. To\naddress this challenge, we introduce Federated Behavioural Planes (FBPs), a\nnovel method to analyse, visualise, and explain the dynamics of FL systems,\nshowing how clients behave under two different lenses: predictive performance\n(error behavioural space) and decision-making processes (counterfactual\nbehavioural space). Our experiments demonstrate that FBPs provide informative\ntrajectories describing the evolving states of clients and their contributions\nto the global model, thereby enabling the identification of clusters of clients\nwith similar behaviours. Leveraging the patterns identified by FBPs, we propose\na robust aggregation technique named Federated Behavioural Shields to detect\nmalicious or noisy client models, thereby enhancing security and surpassing the\nefficacy of existing state-of-the-art FL defense mechanisms.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "authors": [
            "Dario Fenoglio",
            "Gabriele Dominici",
            "Pietro Barbiero",
            "Alberto Tonda",
            "Martin Gjoreski",
            "Marc Langheinrich"
        ],
        "published": "2024-05-24T15:17:51Z"
    },
    {
        "title": "GPTZoo: A Large-scale Dataset of GPTs for the Research Community",
        "link": "http://arxiv.org/abs/2405.15630v1",
        "abstract": "The rapid advancements in Large Language Models (LLMs) have revolutionized\nnatural language processing, with GPTs, customized versions of ChatGPT\navailable on the GPT Store, emerging as a prominent technology for specific\ndomains and tasks. To support academic research on GPTs, we introduce GPTZoo, a\nlarge-scale dataset comprising 730,420 GPT instances. Each instance includes\nrich metadata with 21 attributes describing its characteristics, as well as\ninstructions, knowledge files, and third-party services utilized during its\ndevelopment. GPTZoo aims to provide researchers with a comprehensive and\nreadily available resource to study the real-world applications, performance,\nand potential of GPTs. To facilitate efficient retrieval and analysis of GPTs,\nwe also developed an automated command-line interface (CLI) that supports\nkeyword-based searching of the dataset. To promote open research and\ninnovation, the GPTZoo dataset will undergo continuous updates, and we are\ngranting researchers public access to GPTZoo and its associated tools.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Xinyi Hou",
            "Yanjie Zhao",
            "Shenao Wang",
            "Haoyu Wang"
        ],
        "published": "2024-05-24T15:17:03Z"
    },
    {
        "title": "A Comparative Analysis of Distributed Training Strategies for GPT-2",
        "link": "http://arxiv.org/abs/2405.15628v1",
        "abstract": "The rapid advancement in Large Language Models has been met with significant\nchallenges in their training processes, primarily due to their considerable\ncomputational and memory demands. This research examines parallelization\ntechniques developed to address these challenges, enabling the efficient and\nscalable training of Large Language Models. A comprehensive analysis of both\ndata and model parallelism strategies, including Fully Sharded Data Parallelism\nand Distributed Data-Parallel frameworks, is provided to assess methods that\nfacilitate efficient model training. Furthermore, the architectural\ncomplexities and training methodologies of the Generative Pre-Trained\nTransformer-2 model are explored. The application of these strategies is\nfurther investigated, which is crucial in managing the substantial\ncomputational and memory demands of training sophisticated models. This\nanalysis not only highlights the effectiveness of these parallel training\nstrategies in enhancing training efficiency but also their role in enabling the\nscalable training of large language models. Drawing on recent research\nfindings, through a comprehensive literature review, this research underscores\nthe critical role of parallelization techniques in addressing the computational\nchallenges of training state-of-the-art Large Language Models, thereby\ncontributing to the advancement of training more sophisticated and capable\nartificial intelligence systems.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Ishan Patwardhan",
            "Shubham Gandhi",
            "Om Khare",
            "Amit Joshi",
            "Suraj Sawant"
        ],
        "published": "2024-05-24T15:16:50Z"
    },
    {
        "title": "The Scattering Matrix-Based Characteristic Mode for Structure amidst\n  Arbitrary Background: Theory, Benchmark and Applications",
        "link": "http://arxiv.org/abs/2405.15627v1",
        "abstract": "This paper presents a novel approach for computing substructure\ncharacteristic modes. This method leverages electromagnetic scattering matrices\nand spherical wave expansion to directly decompose electromagnetic fields.\nUnlike conventional methods that rely on the impedance matrix generated by the\nmethod of moments (MoM), our technique simplifies the problem into a\nsmall-scale ordinary eigenvalue problem, improving numerical dynamics and\ncomputational efficiency. We have developed analytical substructure\ncharacteristic mode solutions for a scenario involving two spheres, which can\nserve as benchmarks for evaluating other numerical solvers. A key advantage of\nour method is its independence from specific MoM frameworks, allowing for the\nuse of various numerical methods. This flexibility paves the way for\nsubstructure characteristic mode decomposition to become a universal frequency\ntechnique.",
        "subjects": [
            "physics.class-ph",
            "cs.CE"
        ],
        "authors": [
            "Chenbo Shi",
            "Jin Pan",
            "Xin Gu",
            "Shichen Liang",
            "Le Zuo"
        ],
        "published": "2024-05-24T15:16:29Z"
    },
    {
        "title": "Nonlinear denoising score matching for enhanced learning of structured\n  distributions",
        "link": "http://arxiv.org/abs/2405.15625v1",
        "abstract": "We present a novel method for training score-based generative models which\nuses nonlinear noising dynamics to improve learning of structured\ndistributions. Generalizing to a nonlinear drift allows for additional\nstructure to be incorporated into the dynamics, thus making the training better\nadapted to the data, e.g., in the case of multimodality or (approximate)\nsymmetries. Such structure can be obtained from the data by an inexpensive\npreprocessing step. The nonlinear dynamics introduces new challenges into\ntraining which we address in two ways: 1) we develop a new nonlinear denoising\nscore matching (NDSM) method, 2) we introduce neural control variates in order\nto reduce the variance of the NDSM training objective. We demonstrate the\neffectiveness of this method on several examples: a) a collection of\nlow-dimensional examples, motivated by clustering in latent space, b)\nhigh-dimensional images, addressing issues with mode collapse, small training\nsets, and approximate symmetries, the latter being a challenge for methods\nbased on equivariant neural networks, which require exact symmetries.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Jeremiah Birrell",
            "Markos A. Katsoulakis",
            "Luc Rey-Bellet",
            "Benjamin Zhang",
            "Wei Zhu"
        ],
        "published": "2024-05-24T15:14:23Z"
    },
    {
        "title": "Inverse-RLignment: Inverse Reinforcement Learning from Demonstrations\n  for LLM Alignment",
        "link": "http://arxiv.org/abs/2405.15624v1",
        "abstract": "Aligning Large Language Models (LLMs) is crucial for enhancing their safety\nand utility. However, existing methods, primarily based on preference datasets,\nface challenges such as noisy labels, high annotation costs, and privacy\nconcerns. In this work, we introduce Alignment from Demonstrations (AfD), a\nnovel approach leveraging high-quality demonstration data to overcome these\nchallenges. We formalize AfD within a sequential decision-making framework,\nhighlighting its unique challenge of missing reward signals. Drawing insights\nfrom forward and inverse reinforcement learning, we introduce divergence\nminimization objectives for AfD. Analytically, we elucidate the mass-covering\nand mode-seeking behaviors of various approaches, explaining when and why\ncertain methods are superior. Practically, we propose a computationally\nefficient algorithm that extrapolates over a tailored reward model for AfD. We\nvalidate our key insights through experiments on the Harmless and Helpful\ntasks, demonstrating their strong empirical performance while maintaining\nsimplicity.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Hao Sun",
            "Mihaela van der Schaar"
        ],
        "published": "2024-05-24T15:13:53Z"
    },
    {
        "title": "LAM3D: Large Image-Point-Cloud Alignment Model for 3D Reconstruction\n  from Single Image",
        "link": "http://arxiv.org/abs/2405.15622v1",
        "abstract": "Large Reconstruction Models have made significant strides in the realm of\nautomated 3D content generation from single or multiple input images. Despite\ntheir success, these models often produce 3D meshes with geometric\ninaccuracies, stemming from the inherent challenges of deducing 3D shapes\nsolely from image data. In this work, we introduce a novel framework, the Large\nImage and Point Cloud Alignment Model (LAM3D), which utilizes 3D point cloud\ndata to enhance the fidelity of generated 3D meshes. Our methodology begins\nwith the development of a point-cloud-based network that effectively generates\nprecise and meaningful latent tri-planes, laying the groundwork for accurate 3D\nmesh reconstruction. Building upon this, our Image-Point-Cloud Feature\nAlignment technique processes a single input image, aligning to the latent\ntri-planes to imbue image features with robust 3D information. This process not\nonly enriches the image features but also facilitates the production of\nhigh-fidelity 3D meshes without the need for multi-view input, significantly\nreducing geometric distortions. Our approach achieves state-of-the-art\nhigh-fidelity 3D mesh reconstruction from a single image in just 6 seconds, and\nexperiments on various datasets demonstrate its effectiveness.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ruikai Cui",
            "Xibin Song",
            "Weixuan Sun",
            "Senbo Wang",
            "Weizhe Liu",
            "Shenzhou Chen",
            "Taizhang Shang",
            "Yang Li",
            "Nick Barnes",
            "Hongdong Li",
            "Pan Ji"
        ],
        "published": "2024-05-24T15:09:12Z"
    },
    {
        "title": "DiffCalib: Reformulating Monocular Camera Calibration as Diffusion-Based\n  Dense Incident Map Generation",
        "link": "http://arxiv.org/abs/2405.15619v1",
        "abstract": "Monocular camera calibration is a key precondition for numerous 3D vision\napplications. Despite considerable advancements, existing methods often hinge\non specific assumptions and struggle to generalize across varied real-world\nscenarios, and the performance is limited by insufficient training data.\nRecently, diffusion models trained on expansive datasets have been confirmed to\nmaintain the capability to generate diverse, high-quality images. This success\nsuggests a strong potential of the models to effectively understand varied\nvisual information. In this work, we leverage the comprehensive visual\nknowledge embedded in pre-trained diffusion models to enable more robust and\naccurate monocular camera intrinsic estimation. Specifically, we reformulate\nthe problem of estimating the four degrees of freedom (4-DoF) of camera\nintrinsic parameters as a dense incident map generation task. The map details\nthe angle of incidence for each pixel in the RGB image, and its format aligns\nwell with the paradigm of diffusion models. The camera intrinsic then can be\nderived from the incident map with a simple non-learning RANSAC algorithm\nduring inference. Moreover, to further enhance the performance, we jointly\nestimate a depth map to provide extra geometric information for the incident\nmap estimation. Extensive experiments on multiple testing datasets demonstrate\nthat our model achieves state-of-the-art performance, gaining up to a 40%\nreduction in prediction errors. Besides, the experiments also show that the\nprecise camera intrinsic and depth maps estimated by our pipeline can greatly\nbenefit practical applications such as 3D reconstruction from a single\nin-the-wild image.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xiankang He",
            "Guangkai Xu",
            "Bo Zhang",
            "Hao Chen",
            "Ying Cui",
            "Dongyan Guo"
        ],
        "published": "2024-05-24T15:05:04Z"
    },
    {
        "title": "MLPs Learn In-Context",
        "link": "http://arxiv.org/abs/2405.15618v1",
        "abstract": "In-context learning (ICL), the remarkable ability to solve a task from only\ninput exemplars, has commonly been assumed to be a unique hallmark of\nTransformer models. In this study, we demonstrate that multi-layer perceptrons\n(MLPs) can also learn in-context. Moreover, we find that MLPs, and the closely\nrelated MLP-Mixer models, learn in-context competitively with Transformers\ngiven the same compute budget. We further show that MLPs outperform\nTransformers on a subset of ICL tasks designed to test relational reasoning.\nThese results suggest that in-context learning is not exclusive to Transformers\nand highlight the potential of exploring this phenomenon beyond attention-based\narchitectures. In addition, MLPs' surprising success on relational tasks\nchallenges prior assumptions about simple connectionist models. Altogether, our\nresults endorse the broad trend that ``less inductive bias is better\" and\ncontribute to the growing interest in all-MLP alternatives to task-specific\narchitectures.",
        "subjects": [
            "cs.LG",
            "cs.NE"
        ],
        "authors": [
            "William L. Tong",
            "Cengiz Pehlevan"
        ],
        "published": "2024-05-24T15:04:36Z"
    },
    {
        "title": "Neuromorphic dreaming: A pathway to efficient learning in artificial\n  agents",
        "link": "http://arxiv.org/abs/2405.15616v1",
        "abstract": "Achieving energy efficiency in learning is a key challenge for artificial\nintelligence (AI) computing platforms. Biological systems demonstrate\nremarkable abilities to learn complex skills quickly and efficiently. Inspired\nby this, we present a hardware implementation of model-based reinforcement\nlearning (MBRL) using spiking neural networks (SNNs) on mixed-signal\nanalog/digital neuromorphic hardware. This approach leverages the energy\nefficiency of mixed-signal neuromorphic chips while achieving high sample\nefficiency through an alternation of online learning, referred to as the\n\"awake\" phase, and offline learning, known as the \"dreaming\" phase. The model\nproposed includes two symbiotic networks: an agent network that learns by\ncombining real and simulated experiences, and a learned world model network\nthat generates the simulated experiences. We validate the model by training the\nhardware implementation to play the Atari game Pong. We start from a baseline\nconsisting of an agent network learning without a world model and dreaming,\nwhich successfully learns to play the game. By incorporating dreaming, the\nnumber of required real game experiences are reduced significantly compared to\nthe baseline. The networks are implemented using a mixed-signal neuromorphic\nprocessor, with the readout layers trained using a computer in-the-loop, while\nthe other layers remain fixed. These results pave the way toward\nenergy-efficient neuromorphic learning systems capable of rapid learning in\nreal world applications and use-cases.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "cs.NE"
        ],
        "authors": [
            "Ingo Blakowski",
            "Dmitrii Zendrikov",
            "Cristiano Capone",
            "Giacomo Indiveri"
        ],
        "published": "2024-05-24T15:03:56Z"
    },
    {
        "title": "Harnessing Large Language Models for Software Vulnerability Detection: A\n  Comprehensive Benchmarking Study",
        "link": "http://arxiv.org/abs/2405.15614v1",
        "abstract": "Despite various approaches being employed to detect vulnerabilities, the\nnumber of reported vulnerabilities shows an upward trend over the years. This\nsuggests the problems are not caught before the code is released, which could\nbe caused by many factors, like lack of awareness, limited efficacy of the\nexisting vulnerability detection tools or the tools not being user-friendly. To\nhelp combat some issues with traditional vulnerability detection tools, we\npropose using large language models (LLMs) to assist in finding vulnerabilities\nin source code. LLMs have shown a remarkable ability to understand and generate\ncode, underlining their potential in code-related tasks. The aim is to test\nmultiple state-of-the-art LLMs and identify the best prompting strategies,\nallowing extraction of the best value from the LLMs. We provide an overview of\nthe strengths and weaknesses of the LLM-based approach and compare the results\nto those of traditional static analysis tools. We find that LLMs can pinpoint\nmany more issues than traditional static analysis tools, outperforming\ntraditional tools in terms of recall and F1 scores. The results should benefit\nsoftware developers and security analysts responsible for ensuring that the\ncode is free of vulnerabilities.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.SE"
        ],
        "authors": [
            "Karl Tamberg",
            "Hayretdin Bahsi"
        ],
        "published": "2024-05-24T14:59:19Z"
    },
    {
        "title": "Automatic Data Curation for Self-Supervised Learning: A Clustering-Based\n  Approach",
        "link": "http://arxiv.org/abs/2405.15613v1",
        "abstract": "Self-supervised features are the cornerstone of modern machine learning\nsystems. They are typically pre-trained on data collections whose construction\nand curation typically require extensive human effort. This manual process has\nsome limitations similar to those encountered in supervised learning, e.g., the\ncrowd-sourced selection of data is costly and time-consuming, preventing\nscaling the dataset size. In this work, we consider the problem of automatic\ncuration of high-quality datasets for self-supervised pre-training. We posit\nthat such datasets should be large, diverse and balanced, and propose a\nclustering-based approach for building ones satisfying all these criteria. Our\nmethod involves successive and hierarchical applications of $k$-means on a\nlarge and diverse data repository to obtain clusters that distribute uniformly\namong data concepts, followed by a hierarchical, balanced sampling step from\nthese clusters. Extensive experiments on three different data domains including\nweb-based images, satellite images and text show that features trained on our\nautomatically curated datasets outperform those trained on uncurated data while\nbeing on par or better than ones trained on manually curated data.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Huy V. Vo",
            "Vasil Khalidov",
            "Timothée Darcet",
            "Théo Moutakanni",
            "Nikita Smetanin",
            "Marc Szafraniec",
            "Hugo Touvron",
            "Camille Couprie",
            "Maxime Oquab",
            "Armand Joulin",
            "Hervé Jégou",
            "Patrick Labatut",
            "Piotr Bojanowski"
        ],
        "published": "2024-05-24T14:58:51Z"
    },
    {
        "title": "Increasing Efficiency and Result Reliability of Continuous Benchmarking\n  for FaaS Applications",
        "link": "http://arxiv.org/abs/2405.15610v1",
        "abstract": "In a continuous deployment setting, Function-as-a-Service (FaaS) applications\nfrequently receive updated releases, each of which can cause a performance\nregression. While continuous benchmarking, i.e., comparing benchmark results of\nthe updated and the previous version, can detect such regressions, performance\nvariability of FaaS platforms necessitates thousands of function calls, thus,\nmaking continuous benchmarking time-intensive and expensive.\n  In this paper, we propose DuetFaaS, an approach which adapts duet\nbenchmarking to FaaS applications. With DuetFaaS, we deploy two versions of\nFaaS function in a single cloud function instance and execute them in parallel\nto reduce the impact of platform variability. We evaluate our approach against\nstate-of-the-art approaches, running on AWS Lambda. Overall, DuetFaaS requires\nfewer invocations to accurately detect performance regressions than other\nstate-of-the-art approaches. In 99.65% of evaluated cases, our approach\nprovides smaller confidence interval sizes than the comparing approaches, and\ncan reduce the size by up to 98.23%.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Tim C. Rese",
            "Nils Japke",
            "Sebastian Koch",
            "Tobias Pfandzelter",
            "David Bermbach"
        ],
        "published": "2024-05-24T14:53:33Z"
    },
    {
        "title": "Autonomous programmable microscopic electronic lablets optimized with\n  digital control",
        "link": "http://arxiv.org/abs/2405.15608v1",
        "abstract": "Lablets are autonomous microscopic particles with programmable CMOS\nelectronics that can control electrokinetic phenomena and electrochemical\nreactions in solution via actuator and sensor microelectrodes. In this paper,\nwe describe the design and fabrication of optimized singulated lablets (CMOS3)\nwith dimensions 140x140x50 um carrying an integrated coplanar encapsulated\nsupercapacitor as a rechargeable power supply. The lablets are designed to\nallow docking to one another or to a smart surface for interchange of energy,\nelectronic information, and chemicals. The paper focusses on the digital and\nanalog design of the lablets to allow significant programmable functionality in\na microscopic footprint, including the control of autonomous actuation and\nsensing up to the level of being able to support a complete lablet\nself-reproduction life cycle, although experimentally this remains to be\nproven. The potential of lablets in autonomous sensing and control and for\nevolutionary experimentation are discussed.",
        "subjects": [
            "cs.RO",
            "cond-mat.mtrl-sci",
            "I.2.9; B.7.0; J.2; J.3; J.7"
        ],
        "authors": [
            "Thomas Maeke",
            "John McCaskill",
            "Dominic Funke",
            "Pierre Mayr",
            "Abhishek Sharma",
            "Uwe Tangen",
            "Jürgen Oehm"
        ],
        "published": "2024-05-24T14:47:59Z"
    },
    {
        "title": "Fast-PGM: Fast Probabilistic Graphical Model Learning and Inference",
        "link": "http://arxiv.org/abs/2405.15605v1",
        "abstract": "Probabilistic graphical models (PGMs) serve as a powerful framework for\nmodeling complex systems with uncertainty and extracting valuable insights from\ndata. However, users face challenges when applying PGMs to their problems in\nterms of efficiency and usability. This paper presents Fast-PGM, an efficient\nand open-source library for PGM learning and inference. Fast-PGM supports\ncomprehensive tasks on PGMs, including structure and parameter learning, as\nwell as exact and approximate inference, and enhances efficiency of the tasks\nthrough computational and memory optimizations and parallelization techniques.\nConcurrently, Fast-PGM furnishes developers with flexible building blocks,\nfurnishes learners with detailed documentation, and affords non-experts\nuser-friendly interfaces, thereby ameliorating the usability of PGMs to users\nacross a spectrum of expertise levels. The source code of Fast-PGM is available\nat https://github.com/jjiantong/FastPGM.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Jiantong Jiang",
            "Zeyi Wen",
            "Peiyu Yang",
            "Atif Mansoor",
            "Ajmal Mian"
        ],
        "published": "2024-05-24T14:43:37Z"
    },
    {
        "title": "Text Generation: A Systematic Literature Review of Tasks, Evaluation,\n  and Challenges",
        "link": "http://arxiv.org/abs/2405.15604v1",
        "abstract": "Text generation has become more accessible than ever, and the increasing\ninterest in these systems, especially those using large language models, has\nspurred an increasing number of related publications. We provide a systematic\nliterature review comprising 244 selected papers between 2017 and 2024. This\nreview categorizes works in text generation into five main tasks: open-ended\ntext generation, summarization, translation, paraphrasing, and question\nanswering. For each task, we review their relevant characteristics, sub-tasks,\nand specific challenges (e.g., missing datasets for multi-document\nsummarization, coherence in story generation, and complex reasoning for\nquestion answering). Additionally, we assess current approaches for evaluating\ntext generation systems and ascertain problems with current metrics. Our\ninvestigation shows nine prominent challenges common to all tasks and sub-tasks\nin recent text generation publications: bias, reasoning, hallucinations,\nmisuse, privacy, interpretability, transparency, datasets, and computing. We\nprovide a detailed analysis of these challenges, their potential solutions, and\nwhich gaps still require further engagement from the community. This systematic\nliterature review targets two main audiences: early career researchers in\nnatural language processing looking for an overview of the field and promising\nresearch directions, as well as experienced researchers seeking a detailed view\nof tasks, evaluation methodologies, open challenges, and recent mitigation\nstrategies.",
        "subjects": [
            "cs.CL",
            "A.1; I.2.7"
        ],
        "authors": [
            "Jonas Becker",
            "Jan Philip Wahle",
            "Bela Gipp",
            "Terry Ruas"
        ],
        "published": "2024-05-24T14:38:11Z"
    },
    {
        "title": "Kronecker-Factored Approximate Curvature for Physics-Informed Neural\n  Networks",
        "link": "http://arxiv.org/abs/2405.15603v1",
        "abstract": "Physics-informed neural networks (PINNs) are infamous for being hard to\ntrain. Recently, second-order methods based on natural gradient and\nGauss-Newton methods have shown promising performance, improving the accuracy\nachieved by first-order methods by several orders of magnitude. While\npromising, the proposed methods only scale to networks with a few thousand\nparameters due to the high computational cost to evaluate, store, and invert\nthe curvature matrix. We propose Kronecker-factored approximate curvature\n(KFAC) for PINN losses that greatly reduces the computational cost and allows\nscaling to much larger networks. Our approach goes beyond the established KFAC\nfor traditional deep learning problems as it captures contributions from a\nPDE's differential operator that are crucial for optimization. To establish\nKFAC for such losses, we use Taylor-mode automatic differentiation to describe\nthe differential operator's computation graph as a forward network with shared\nweights. This allows us to apply KFAC thanks to a recently-developed general\nformulation for networks with weight sharing. Empirically, we find that our\nKFAC-based optimizers are competitive with expensive second-order methods on\nsmall problems, scale more favorably to higher-dimensional neural networks and\nPDEs, and consistently outperform first-order methods and LBFGS.",
        "subjects": [
            "cs.LG",
            "physics.comp-ph"
        ],
        "authors": [
            "Felix Dangel",
            "Johannes Müller",
            "Marius Zeinhofer"
        ],
        "published": "2024-05-24T14:36:02Z"
    },
    {
        "title": "On the Computational Landscape of Replicable Learning",
        "link": "http://arxiv.org/abs/2405.15599v1",
        "abstract": "We study computational aspects of algorithmic replicability, a notion of\nstability introduced by Impagliazzo, Lei, Pitassi, and Sorrell [2022].\nMotivated by a recent line of work that established strong statistical\nconnections between replicability and other notions of learnability such as\nonline learning, private learning, and SQ learning, we aim to understand better\nthe computational connections between replicability and these learning\nparadigms. Our first result shows that there is a concept class that is\nefficiently replicably PAC learnable, but, under standard cryptographic\nassumptions, no efficient online learner exists for this class. Subsequently,\nwe design an efficient replicable learner for PAC learning parities when the\nmarginal distribution is far from uniform, making progress on a question posed\nby Impagliazzo et al. [2022]. To obtain this result, we design a replicable\nlifting framework inspired by Blanc, Lange, Malik, and Tan [2023] that\ntransforms in a black-box manner efficient replicable PAC learners under the\nuniform marginal distribution over the Boolean hypercube to replicable PAC\nlearners under any marginal distribution, with sample and time complexity that\ndepends on a certain measure of the complexity of the distribution. Finally, we\nshow that any pure DP learner can be transformed to a replicable one in time\npolynomial in the accuracy, confidence parameters and exponential in the\nrepresentation dimension of the underlying hypothesis class.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Alkis Kalavasis",
            "Amin Karbasi",
            "Grigoris Velegkas",
            "Felix Zhou"
        ],
        "published": "2024-05-24T14:30:40Z"
    },
    {
        "title": "MCDFN: Supply Chain Demand Forecasting via an Explainable Multi-Channel\n  Data Fusion Network Model Integrating CNN, LSTM, and GRU",
        "link": "http://arxiv.org/abs/2405.15598v1",
        "abstract": "Accurate demand forecasting is crucial for optimizing supply chain\nmanagement. Traditional methods often fail to capture complex patterns from\nseasonal variability and special events. Despite advancements in deep learning,\ninterpretable forecasting models remain a challenge. To address this, we\nintroduce the Multi-Channel Data Fusion Network (MCDFN), a hybrid architecture\nthat integrates Convolutional Neural Networks (CNN), Long Short-Term Memory\nnetworks (LSTM), and Gated Recurrent Units (GRU) to enhance predictive\nperformance by extracting spatial and temporal features from time series data.\nOur rigorous benchmarking demonstrates that MCDFN outperforms seven other\ndeep-learning models, achieving superior metrics: MSE (23.5738%), RMSE\n(4.8553%), MAE (3.9991%), and MAPE (20.1575%). Additionally, MCDFN's\npredictions were statistically indistinguishable from actual values, confirmed\nby a paired t-test with a 5% p-value and a 10-fold cross-validated statistical\npaired t-test. We apply explainable AI techniques like ShapTime and Permutation\nFeature Importance to enhance interpretability. This research advances demand\nforecasting methodologies and offers practical guidelines for integrating MCDFN\ninto supply chain systems, highlighting future research directions for\nscalability and user-friendly deployment.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Md Abrar Jahin",
            "Asef Shahriar",
            "Md Al Amin"
        ],
        "published": "2024-05-24T14:30:00Z"
    },
    {
        "title": "Multimodal Object Detection via Probabilistic a priori Information\n  Integration",
        "link": "http://arxiv.org/abs/2405.15596v1",
        "abstract": "Multimodal object detection has shown promise in remote sensing. However,\nmultimodal data frequently encounter the problem of low-quality, wherein the\nmodalities lack strict cell-to-cell alignment, leading to mismatch between\ndifferent modalities. In this paper, we investigate multimodal object detection\nwhere only one modality contains the target object and the others provide\ncrucial contextual information. We propose to resolve the alignment problem by\nconverting the contextual binary information into probability maps. We then\npropose an early fusion architecture that we validate with extensive\nexperiments on the DOTA dataset.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hafsa El Hafyani",
            "Bastien Pasdeloup",
            "Camille Yver",
            "Pierre Romenteau"
        ],
        "published": "2024-05-24T14:28:06Z"
    },
    {
        "title": "MicroAdam: Accurate Adaptive Optimization with Low Space Overhead and\n  Provable Convergence",
        "link": "http://arxiv.org/abs/2405.15593v1",
        "abstract": "We propose a new variant of the Adam optimizer [Kingma and Ba, 2014] called\nMICROADAM that specifically minimizes memory overheads, while maintaining\ntheoretical convergence guarantees. We achieve this by compressing the gradient\ninformation before it is fed into the optimizer state, thereby reducing its\nmemory footprint significantly. We control the resulting compression error via\na novel instance of the classical error feedback mechanism from distributed\noptimization [Seide et al., 2014, Alistarh et al., 2018, Karimireddy et al.,\n2019] in which the error correction information is itself compressed to allow\nfor practical memory gains. We prove that the resulting approach maintains\ntheoretical convergence guarantees competitive to those of AMSGrad, while\nproviding good practical performance. Specifically, we show that MICROADAM can\nbe implemented efficiently on GPUs: on both million-scale (BERT) and\nbillion-scale (LLaMA) models, MicroAdam provides practical convergence\ncompetitive to that of the uncompressed Adam baseline, with lower memory usage\nand similar running time. Our code is available at\nhttps://github.com/IST-DASLab/MicroAdam.",
        "subjects": [
            "cs.LG",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Ionut-Vlad Modoranu",
            "Mher Safaryan",
            "Grigory Malinovsky",
            "Eldar Kurtic",
            "Thomas Robert",
            "Peter Richtarik",
            "Dan Alistarh"
        ],
        "published": "2024-05-24T14:25:23Z"
    },
    {
        "title": "Profiling checkpointing schedules in adjoint ST-AD",
        "link": "http://arxiv.org/abs/2405.15590v1",
        "abstract": "Checkpointing is a cornerstone of data-flow reversal in adjoint algorithmic\ndifferentiation. Checkpointing is a storage/recomputation trade-off that can be\napplied at different levels, one of which being the call tree. We are looking\nfor good placements of checkpoints onto the call tree of a given application,\nto reduce run time and memory footprint of its adjoint. There is no known\noptimal solution to this problem other than a combinatorial search on all\nplacements. We propose a heuristics based on run-time profiling of the adjoint\ncode. We describe implementation of this profiling tool in an existing\nsource-transformation AD tool. We demonstrate the interest of this approach on\ntest cases taken from the MITgcm ocean and atmospheric global circulation\nmodel. We discuss the limitations of our approach and propose directions to\nlift them.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Laurent Hascoët",
            "Jean-Luc Bouchot",
            "Shreyas Sunil Gaikwad",
            "Sri Hari Krishna Narayanan",
            "Jan Hückelheim"
        ],
        "published": "2024-05-24T14:20:45Z"
    },
    {
        "title": "Efficient Adversarial Training in LLMs with Continuous Attacks",
        "link": "http://arxiv.org/abs/2405.15589v1",
        "abstract": "Large language models (LLMs) are vulnerable to adversarial attacks that can\nbypass their safety guardrails. In many domains, adversarial training has\nproven to be one of the most promising methods to reliably improve robustness\nagainst such attacks. Yet, in the context of LLMs, current methods for\nadversarial training are hindered by the high computational costs required to\nperform discrete adversarial attacks at each training iteration. We address\nthis problem by instead calculating adversarial attacks in the continuous\nembedding space of the LLM, which is orders of magnitudes more efficient. We\npropose a fast adversarial training algorithm (C-AdvUL) composed of two losses:\nthe first makes the model robust on continuous embedding attacks computed on an\nadversarial behaviour dataset; the second ensures the usefulness of the final\nmodel by fine-tuning on utility data. Moreover, we introduce C-AdvIPO, an\nadversarial variant of IPO that does not require utility data for adversarially\nrobust alignment. Our empirical evaluation on four models from different\nfamilies (Gemma, Phi3, Mistral, Zephyr) and at different scales (2B, 3.8B, 7B)\nshows that both algorithms substantially enhance LLM robustness against\ndiscrete attacks (GCG, AutoDAN, PAIR), while maintaining utility. Our results\ndemonstrate that robustness to continuous perturbations can extrapolate to\ndiscrete threat models. Thereby, we present a path toward scalable adversarial\ntraining algorithms for robustly aligning LLMs.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "authors": [
            "Sophie Xhonneux",
            "Alessandro Sordoni",
            "Stephan Günnemann",
            "Gauthier Gidel",
            "Leo Schwinn"
        ],
        "published": "2024-05-24T14:20:09Z"
    },
    {
        "title": "Composed Image Retrieval for Remote Sensing",
        "link": "http://arxiv.org/abs/2405.15587v1",
        "abstract": "This work introduces composed image retrieval to remote sensing. It allows to\nquery a large image archive by image examples alternated by a textual\ndescription, enriching the descriptive power over unimodal queries, either\nvisual or textual. Various attributes can be modified by the textual part, such\nas shape, color, or context. A novel method fusing image-to-image and\ntext-to-image similarity is introduced. We demonstrate that a vision-language\nmodel possesses sufficient descriptive power and no further learning step or\ntraining data are necessary. We present a new evaluation benchmark focused on\ncolor, context, density, existence, quantity, and shape modifications. Our work\nnot only sets the state-of-the-art for this task, but also serves as a\nfoundational step in addressing a gap in the field of remote sensing image\nretrieval. Code at: https://github.com/billpsomas/rscir",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Bill Psomas",
            "Ioannis Kakogeorgiou",
            "Nikos Efthymiadis",
            "Giorgos Tolias",
            "Ondrej Chum",
            "Yannis Avrithis",
            "Konstantinos Karantzalos"
        ],
        "published": "2024-05-24T14:18:31Z"
    },
    {
        "title": "DAGER: Exact Gradient Inversion for Large Language Models",
        "link": "http://arxiv.org/abs/2405.15586v1",
        "abstract": "Federated learning works by aggregating locally computed gradients from\nmultiple clients, thus enabling collaborative training without sharing private\nclient data. However, prior work has shown that the data can actually be\nrecovered by the server using so-called gradient inversion attacks. While these\nattacks perform well when applied on images, they are limited in the text\ndomain and only permit approximate reconstruction of small batches and short\ninput sequences. In this work, we propose DAGER, the first algorithm to recover\nwhole batches of input text exactly. DAGER leverages the low-rank structure of\nself-attention layer gradients and the discrete nature of token embeddings to\nefficiently check if a given token sequence is part of the client data. We use\nthis check to exactly recover full batches in the honest-but-curious setting\nwithout any prior on the data for both encoder- and decoder-based architectures\nusing exhaustive heuristic search and a greedy approach, respectively. We\nprovide an efficient GPU implementation of DAGER and show experimentally that\nit recovers full batches of size up to 128 on large language models (LLMs),\nbeating prior attacks in speed (20x at same batch size), scalability (10x\nlarger batches), and reconstruction quality (ROUGE-1/2 > 0.99).",
        "subjects": [
            "cs.LG",
            "cs.DC",
            "I.2.7; I.2.11"
        ],
        "authors": [
            "Ivo Petrov",
            "Dimitar I. Dimitrov",
            "Maximilian Baader",
            "Mark Niklas Müller",
            "Martin Vechev"
        ],
        "published": "2024-05-24T14:14:24Z"
    },
    {
        "title": "Synergizing In-context Learning with Hints for End-to-end Task-oriented\n  Dialog Systems",
        "link": "http://arxiv.org/abs/2405.15585v1",
        "abstract": "Large language models (LLM) based end-to-end task-oriented dialog (TOD)\nsystems built using few-shot (in-context) learning perform better than\nsupervised models only when the train data is limited. This is due to the\ninherent ability of LLMs to learn any task with just a few demonstrations. As\nthe number of train dialogs increases, supervised SoTA models surpass\nin-context learning LLMs as they learn to better align with the style of the\nsystem responses in the training data, which LLMs struggle to mimic. In\nresponse, we propose SyncTOD, which synergizes LLMs with useful hints about the\ntask for improved alignment. At a high level, SyncTOD trains auxiliary models\nto provide these hints and select exemplars for the in-context prompts. With\nChatGPT, SyncTOD achieves superior performance compared to LLM-based baselines\nand SoTA models in low-data settings, while retaining competitive performance\nin full-data settings",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Vishal Vivek Saley",
            "Rocktim Jyoti Das",
            "Dinesh Raghu",
            " Mausam"
        ],
        "published": "2024-05-24T14:13:54Z"
    },
    {
        "title": "Transfer Learning with Informative Priors: Simple Baselines Better than\n  Previously Reported",
        "link": "http://arxiv.org/abs/2405.15583v1",
        "abstract": "We pursue transfer learning to improve classifier accuracy on a target task\nwith few labeled examples available for training. Recent work suggests that\nusing a source task to learn a prior distribution over neural net weights, not\njust an initialization, can boost target task performance. In this study, we\ncarefully compare transfer learning with and without source task informed\npriors across 5 datasets. We find that standard transfer learning informed by\nan initialization only performs far better than reported in previous\ncomparisons. The relative gains of methods using informative priors over\nstandard transfer learning vary in magnitude across datasets. For the scenario\nof 5-300 examples per class, we find negative or negligible gains on 2\ndatasets, modest gains (between 1.5-3 points of accuracy) on 2 other datasets,\nand substantial gains (>8 points) on one dataset. Among methods using\ninformative priors, we find that an isotropic covariance appears competitive\nwith learned low-rank covariance matrix while being substantially simpler to\nunderstand and tune. Further analysis suggests that the mechanistic\njustification for informed priors -- hypothesized improved alignment between\ntrain and test loss landscapes -- is not consistently supported due to high\nvariability in empirical landscapes. We release code to allow independent\nreproduction of all experiments.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ethan Harvey",
            "Mikhail Petrov",
            "Michael C. Hughes"
        ],
        "published": "2024-05-24T14:12:23Z"
    },
    {
        "title": "Open-Vocabulary SAM3D: Understand Any 3D Scene",
        "link": "http://arxiv.org/abs/2405.15580v1",
        "abstract": "Open-vocabulary 3D scene understanding presents a significant challenge in\nthe field. Recent advancements have sought to transfer knowledge embedded in\nvision language models from the 2D domain to 3D domain. However, these\napproaches often require learning prior knowledge from specific 3D scene\ndatasets, which limits their applicability in open-world scenarios. The Segment\nAnything Model (SAM) has demonstrated remarkable zero-shot segmentation\ncapabilities, prompting us to investigate its potential for comprehending 3D\nscenes without the need for training. In this paper, we introduce OV-SAM3D, a\nuniversal framework for open-vocabulary 3D scene understanding. This framework\nis designed to perform understanding tasks for any 3D scene without requiring\nprior knowledge of the scene. Specifically, our method is composed of two key\nsub-modules: First, we initiate the process by generating superpoints as the\ninitial 3D prompts and refine these prompts using segment masks derived from\nSAM. Moreover, we then integrate a specially designed overlapping score table\nwith open tags from the Recognize Anything Model (RAM) to produce final 3D\ninstances with open-world label. Empirical evaluations conducted on the\nScanNet200 and nuScenes datasets demonstrate that our approach surpasses\nexisting open-vocabulary methods in unknown open-world environments.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hanchen Tai",
            "Qingdong He",
            "Jiangning Zhang",
            "Yijie Qian",
            "Zhenyu Zhang",
            "Xiaobin Hu",
            "Yabiao Wang",
            "Yong Liu"
        ],
        "published": "2024-05-24T14:07:57Z"
    },
    {
        "title": "Generating density nowcasts for U.S. GDP growth with deep learning:\n  Bayes by Backprop and Monte Carlo dropout",
        "link": "http://arxiv.org/abs/2405.15579v1",
        "abstract": "Recent results in the literature indicate that artificial neural networks\n(ANNs) can outperform the dynamic factor model (DFM) in terms of the accuracy\nof GDP nowcasts. Compared to the DFM, the performance advantage of these highly\nflexible, nonlinear estimators is particularly evident in periods of recessions\nand structural breaks. From the perspective of policy-makers, however, nowcasts\nare the most useful when they are conveyed with uncertainty attached to them.\nWhile the DFM and other classical time series approaches analytically derive\nthe predictive (conditional) distribution for GDP growth, ANNs can only produce\npoint nowcasts based on their default training procedure (backpropagation). To\nfill this gap, first in the literature, we adapt two different deep learning\nalgorithms that enable ANNs to generate density nowcasts for U.S. GDP growth:\nBayes by Backprop and Monte Carlo dropout. The accuracy of point nowcasts,\ndefined as the mean of the empirical predictive distribution, is evaluated\nrelative to a naive constant growth model for GDP and a benchmark DFM\nspecification. Using a 1D CNN as the underlying ANN architecture, both\nalgorithms outperform those benchmarks during the evaluation period (2012:Q1 --\n2022:Q4). Furthermore, both algorithms are able to dynamically adjust the\nlocation (mean), scale (variance), and shape (skew) of the empirical predictive\ndistribution. The results indicate that both Bayes by Backprop and Monte Carlo\ndropout can effectively augment the scope and functionality of ANNs, rendering\nthem a fully compatible and competitive alternative for classical time series\napproaches.",
        "subjects": [
            "econ.EM",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Kristóf Németh",
            "Dániel Hadházi"
        ],
        "published": "2024-05-24T14:06:08Z"
    },
    {
        "title": "Distributed Locking as a Data Type",
        "link": "http://arxiv.org/abs/2405.15578v1",
        "abstract": "Mixed-consistency programming models assist programmers in designing\napplications that provide high availability while still ensuring\napplication-specific safety invariants. However, existing models often make\nspecific system assumptions, such as building on a particular database system\nor having baked-in coordination strategies. This makes it difficult to apply\nthese strategies in diverse settings, ranging from client/server to ad-hoc\npeer-to-peer networks.\n  This work proposes a new strategy for building programmable coordination\nmechanisms based on the algebraic replicated data types (ARDTs) approach. ARDTs\nallow for simple and composable implementations of various protocols, while\nmaking minimal assumptions about the network environment. As a case study, two\ndifferent locking protocols are presented, both implemented as ARDTs. In\naddition, we elaborate on our ongoing efforts to integrate the approach into\nthe LoRe mixed-consistency programming language.",
        "subjects": [
            "cs.PL",
            "cs.DC"
        ],
        "authors": [
            "Julian Haas",
            "Ragnar Mogk",
            "Annette Bieniusa",
            "Mira Mezini"
        ],
        "published": "2024-05-24T14:06:05Z"
    },
    {
        "title": "Meteor: Mamba-based Traversal of Rationale for Large Language and Vision\n  Models",
        "link": "http://arxiv.org/abs/2405.15574v1",
        "abstract": "The rapid development of large language and vision models (LLVMs) has been\ndriven by advances in visual instruction tuning. Recently, open-source LLVMs\nhave curated high-quality visual instruction tuning datasets and utilized\nadditional vision encoders or multiple computer vision models in order to\nnarrow the performance gap with powerful closed-source LLVMs. These\nadvancements are attributed to multifaceted information required for diverse\ncapabilities, including fundamental image understanding, real-world knowledge\nabout common-sense and non-object concepts (e.g., charts, diagrams, symbols,\nsigns, and math problems), and step-by-step procedures for solving complex\nquestions. Drawing from the multifaceted information, we present a new\nefficient LLVM, Mamba-based traversal of rationales (Meteor), which leverages\nmultifaceted rationale to enhance understanding and answering capabilities. To\nembed lengthy rationales containing abundant information, we employ the Mamba\narchitecture, capable of processing sequential data with linear time\ncomplexity. We introduce a new concept of traversal of rationale that\nfacilitates efficient embedding of rationale. Subsequently, the backbone\nmultimodal language model (MLM) is trained to generate answers with the aid of\nrationale. Through these steps, Meteor achieves significant improvements in\nvision language performances across multiple evaluation benchmarks requiring\ndiverse capabilities, without scaling up the model size or employing additional\nvision encoders and computer vision models.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Byung-Kwan Lee",
            "Chae Won Kim",
            "Beomchan Park",
            "Yong Man Ro"
        ],
        "published": "2024-05-24T14:04:03Z"
    },
    {
        "title": "Uniform $\\mathcal{H}$-matrix Compression with Applications to Boundary\n  Integral Equations",
        "link": "http://arxiv.org/abs/2405.15573v1",
        "abstract": "Boundary integral equation formulations of elliptic partial differential\nequations lead to dense system matrices when discretized, yet they are\ndata-sparse. Using the $\\mathcal{H}$-matrix format, this sparsity is exploited\nto achieve $\\mathcal{O}(N\\log N)$ complexity for storage and multiplication by\na vector. This is achieved purely algebraically, based on low-rank\napproximations of subblocks, and hence the format is also applicable to a wider\nrange of problems. The $\\mathcal{H}^2$-matrix format improves the complexity to\n$\\mathcal{O}(N)$ by introducing a recursive structure onto subblocks on\nmultiple levels. However, in practice this comes with a large proportionality\nconstant, making the $\\mathcal{H}^2$-matrix format advantageous mostly for\nlarge problems. In this paper we investigate the usefulness of a matrix format\nthat lies in between these two: Uniform $\\mathcal{H}$-matrices. An algebraic\ncompression algorithm is introduced to transform a regular $\\mathcal{H}$-matrix\ninto a uniform $\\mathcal{H}$-matrix, which maintains the asymptotic complexity.",
        "subjects": [
            "math.NA",
            "cs.MS",
            "cs.NA"
        ],
        "authors": [
            "Kobe Bruyninckx",
            "Daan Huybrechs",
            "Karl Meerbergen"
        ],
        "published": "2024-05-24T14:03:42Z"
    },
    {
        "title": "RCInvestigator: Towards Better Investigation of Anomaly Root Causes in\n  Cloud Computing Systems",
        "link": "http://arxiv.org/abs/2405.15571v1",
        "abstract": "Finding the root causes of anomalies in cloud computing systems quickly is\ncrucial to ensure availability and efficiency since accurate root causes can\nguide engineers to take appropriate actions to address the anomalies and\nmaintain customer satisfaction. However, it is difficult to investigate and\nidentify the root causes based on large-scale and high-dimension monitoring\ndata collected from complex cloud computing environments. Due to the inherently\ndynamic characteristics of cloud computing systems, the existing approaches in\npractice largely rely on manual analyses for flexibility and reliability, but\nmassive unpredictable factors and high data complexity make the process\ntime-consuming. Despite recent advances in automated detection and\ninvestigation approaches, the speed and quality of root cause analyses remain\nlimited by the lack of expert involvement in these approaches. The limitations\nfound in the current solutions motivate us to propose a visual analytics\napproach that facilitates the interactive investigation of the anomaly root\ncauses in cloud computing systems. We identified three challenges, namely, a)\nmodeling databases for the root cause investigation, b) inferring root causes\nfrom large-scale time series, and c) building comprehensible investigation\nresults. In collaboration with domain experts, we addressed these challenges\nwith RCInvestigator, a novel visual analytics system that establishes a tight\ncollaboration between human and machine and assists experts in investigating\nthe root causes of cloud computing system anomalies. We evaluated the\neffectiveness of RCInvestigator through two use cases based on real-world data\nand received positive feedback from experts.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Shuhan Liu",
            "Yunfan Zhou",
            "Lu Ying",
            "Yuan Tian",
            "Jue Zhang",
            "Shandan Zhou",
            "Weiwei Cui",
            "Qingwei Lin",
            "Thomas Moscibroda",
            "Haidong Zhang",
            "Di Weng",
            "Yingcai Wu"
        ],
        "published": "2024-05-24T14:03:27Z"
    },
    {
        "title": "Multi-Gigabit Interactive Extended Reality over Millimeter-Wave: An\n  End-to-End System Approach",
        "link": "http://arxiv.org/abs/2405.15570v1",
        "abstract": "Achieving high-quality wireless interactive Extended Reality (XR) will\nrequire multi-gigabit throughput at extremely low latency. The Millimeter-Wave\n(mmWave) frequency bands, between 24 and 300GHz, can achieve such extreme\nperformance. However, maintaining a consistently high Quality of Experience\nwith highly mobile users is challenging, as mmWave communications are\ninherently directional. In this work, we present and evaluate an end-to-end\napproach to such a mmWave-based mobile XR system. We perform a highly realistic\nsimulation of the system, incorporating accurate XR data traffic, detailed\nmmWave propagation models and actual user motion. We evaluate the impact of the\nbeamforming strategy and frequency on the overall performance. In addition, we\nprovide the first system-level evaluation of the CoVRage algorithm, a proactive\nand spatially aware user-side beamforming approach designed specifically for\nhighly mobile XR environments.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "authors": [
            "Jakob Struye",
            "Filip Lemic",
            "Jeroen Famaey"
        ],
        "published": "2024-05-24T14:03:16Z"
    },
    {
        "title": "Randomized heuristic repair for large-scale multidimensional knapsack\n  problem",
        "link": "http://arxiv.org/abs/2405.15569v1",
        "abstract": "The multidimensional knapsack problem (MKP) is an NP-hard combinatorial\noptimization problem whose solution is determining a subset of maximum total\nprofit items that do not violate capacity constraints. Due to its hardness,\nlarge-scale MKP instances are usually a target for metaheuristics, a context in\nwhich effective feasibility maintenance strategies are crucial. In 1998, Chu\nand Beasley proposed an effective heuristic repair that is still relevant for\nrecent metaheuristics. However, due to its deterministic nature, the diversity\nof solutions such heuristic provides is insufficient for long runs. As a\nresult, the search for new solutions ceases after a while. This paper proposes\nan efficiency-based randomization strategy for the heuristic repair that\nincreases the variability of the repaired solutions without deteriorating\nquality and improves the overall results.",
        "subjects": [
            "cs.AI",
            "cs.NE"
        ],
        "authors": [
            "Jean P. Martins"
        ],
        "published": "2024-05-24T14:01:05Z"
    },
    {
        "title": "OMNI-EPIC: Open-endedness via Models of human Notions of Interestingness\n  with Environments Programmed in Code",
        "link": "http://arxiv.org/abs/2405.15568v1",
        "abstract": "Open-ended and AI-generating algorithms aim to continuously generate and\nsolve increasingly complex tasks indefinitely, offering a promising path toward\nmore general intelligence. To accomplish this grand vision, learning must occur\nwithin a vast array of potential tasks. Existing approaches to automatically\ngenerating environments are constrained within manually predefined, often\nnarrow distributions of environment, limiting their ability to create any\nlearning environment. To address this limitation, we introduce a novel\nframework, OMNI-EPIC, that augments previous work in Open-endedness via Models\nof human Notions of Interestingness (OMNI) with Environments Programmed in Code\n(EPIC). OMNI-EPIC leverages foundation models to autonomously generate code\nspecifying the next learnable (i.e., not too easy or difficult for the agent's\ncurrent skill set) and interesting (e.g., worthwhile and novel) tasks.\nOMNI-EPIC generates both environments (e.g., an obstacle course) and reward\nfunctions (e.g., progress through the obstacle course quickly without touching\nred objects), enabling it, in principle, to create any simulatable learning\ntask. We showcase the explosive creativity of OMNI-EPIC, which continuously\ninnovates to suggest new, interesting learning challenges. We also highlight\nhow OMNI-EPIC can adapt to reinforcement learning agents' learning progress,\ngenerating tasks that are of suitable difficulty. Overall, OMNI-EPIC can\nendlessly create learnable and interesting environments, further propelling the\ndevelopment of self-improving AI systems and AI-Generating Algorithms. Project\nwebsite with videos: https://dub.sh/omniepic",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Maxence Faldor",
            "Jenny Zhang",
            "Antoine Cully",
            "Jeff Clune"
        ],
        "published": "2024-05-24T13:57:32Z"
    },
    {
        "title": "PyCellMech: A shape-based feature extraction pipeline for use in medical\n  and biological studies",
        "link": "http://arxiv.org/abs/2405.15567v1",
        "abstract": "Summary: Medical researchers obtain knowledge about the prevention and\ntreatment of disability and disease using physical measurements and image data.\nTo assist in this endeavor, feature extraction packages are available that are\ndesigned to collect data from the image structure. In this study, we aim to\naugment current works by adding to the current mix of shape-based features. The\nsignificance of shape-based features has been explored extensively in research\nfor several decades, but there is no single package available in which all\nshape-related features can be extracted easily by the researcher. PyCellMech\nhas been crafted to address this gap. The PyCellMech package extracts three\nclasses of shape features, which are classified as one-dimensional, geometric,\nand polygonal. Future iterations will be expanded to include other feature\nclasses, such as scale-space.\n  Availability and implementation: PyCellMech is freely available at\nhttps://github.com/icm-dac/pycellmech.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Janan Arslan",
            "Henri Chhoa",
            "Ines Khemir",
            "Romain Valabregue",
            "Kurt K. Benke"
        ],
        "published": "2024-05-24T13:55:42Z"
    },
    {
        "title": "Rethinking Independent Cross-Entropy Loss For Graph-Structured Data",
        "link": "http://arxiv.org/abs/2405.15564v1",
        "abstract": "Graph neural networks (GNNs) have exhibited prominent performance in learning\ngraph-structured data. Considering node classification task, based on the i.i.d\nassumption among node labels, the traditional supervised learning simply sums\nup cross-entropy losses of the independent training nodes and applies the\naverage loss to optimize GNNs' weights. But different from other data formats,\nthe nodes are naturally connected. It is found that the independent\ndistribution modeling of node labels restricts GNNs' capability to generalize\nover the entire graph and defend adversarial attacks. In this work, we propose\na new framework, termed joint-cluster supervised learning, to model the joint\ndistribution of each node with its corresponding cluster. We learn the joint\ndistribution of node and cluster labels conditioned on their representations,\nand train GNNs with the obtained joint loss. In this way, the data-label\nreference signals extracted from the local cluster explicitly strengthen the\ndiscrimination ability on the target node. The extensive experiments\ndemonstrate that our joint-cluster supervised learning can effectively bolster\nGNNs' node classification accuracy. Furthermore, being benefited from the\nreference signals which may be free from spiteful interference, our learning\nparadigm significantly protects the node classification from being affected by\nthe adversarial attack.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Rui Miao",
            "Kaixiong Zhou",
            "Yili Wang",
            "Ninghao Liu",
            "Ying Wang",
            "Xin Wang"
        ],
        "published": "2024-05-24T13:52:41Z"
    },
    {
        "title": "Heterogeneous virus classification using a functional deep learning\n  model based on transmission electron microscopy images (Preprint)",
        "link": "http://arxiv.org/abs/2405.15563v1",
        "abstract": "Viruses are submicroscopic agents that can infect all kinds of lifeforms and\nuse their hosts' living cells to replicate themselves. Despite having some of\nthe simplest genetic structures among all living beings, viruses are highly\nadaptable, resilient, and given the right conditions, are capable of causing\nunforeseen complications in their hosts' bodies. Due to their multiple\ntransmission pathways, high contagion rate, and lethality, viruses are the\nbiggest biological threat faced by animal and plant species. It is often\nchallenging to promptly detect the presence of a virus in a possible host's\nbody and accurately determine its type using manual examination techniques;\nhowever, it can be done using computer-based automatic diagnosis methods. Most\nnotably, the analysis of Transmission Electron Microscopy (TEM) images has been\nproven to be quite successful in instant virus identification. Using TEM images\ncollected from a recently published dataset, this article proposes a deep\nlearning-based classification model to identify the type of virus within those\nimages correctly. The methodology of this study includes two coherent image\nprocessing techniques to reduce the noise present in the raw microscopy images.\nExperimental results show that it can differentiate among the 14 types of\nviruses present in the dataset with a maximum of 97.44% classification accuracy\nand F1-score, which asserts the effectiveness and reliability of the proposed\nmethod. Implementing this scheme will impart a fast and dependable way of virus\nidentification subsidiary to the thorough diagnostic procedures.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Niloy Sikder",
            "Md. Al-Masrur Khan",
            "Anupam Kumar Bairagi",
            "Mehedi Masud",
            "Jun Jiat Tiang",
            "Abdullah-Al Nahid"
        ],
        "published": "2024-05-24T13:52:14Z"
    },
    {
        "title": "Transformer-XL for Long Sequence Tasks in Robotic Learning from\n  Demonstration",
        "link": "http://arxiv.org/abs/2405.15562v1",
        "abstract": "This paper presents an innovative application of Transformer-XL for long\nsequence tasks in robotic learning from demonstrations (LfD). The proposed\nframework effectively integrates multi-modal sensor inputs, including RGB-D\nimages, LiDAR, and tactile sensors, to construct a comprehensive feature\nvector. By leveraging the advanced capabilities of Transformer-XL, particularly\nits attention mechanism and position encoding, our approach can handle the\ninherent complexities and long-term dependencies of multi-modal sensory data.\nThe results of an extensive empirical evaluation demonstrate significant\nimprovements in task success rates, accuracy, and computational efficiency\ncompared to conventional methods such as Long Short-Term Memory (LSTM) networks\nand Convolutional Neural Networks (CNNs). The findings indicate that the\nTransformer-XL-based framework not only enhances the robot's perception and\ndecision-making abilities but also provides a robust foundation for future\nadvancements in robotic learning from demonstrations.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Gao Tianci"
        ],
        "published": "2024-05-24T13:49:31Z"
    },
    {
        "title": "When Generative AI Meets Workplace Learning: Creating A Realistic &\n  Motivating Learning Experience With A Generative PCA",
        "link": "http://arxiv.org/abs/2405.15561v1",
        "abstract": "Workplace learning is used to train employees systematically, e.g., via\ne-learning or in 1:1 training. However, this is often deemed ineffective and\ncostly. Whereas pure e-learning lacks the possibility of conversational\nexercise and personal contact, 1:1 training with human instructors involves a\nhigh level of personnel and organizational costs. Hence, pedagogical\nconversational agents (PCAs), based on generative AI, seem to compensate for\nthe disadvantages of both forms. Following Action Design Research, this paper\ndescribes an organizational communication training with a Generative PCA\n(GenPCA). The evaluation shows promising results: the agent was perceived\npositively among employees and contributed to an improvement in self-determined\nlearning. However, the integration of such agent comes not without limitations.\nWe conclude with suggestions concerning the didactical methods, which are\nsupported by a GenPCA, and possible improvements of such an agent for workplace\nlearning.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Andreas Bucher",
            "Birgit Schenk",
            "Mateusz Dolata",
            "Gerhard Schwabe"
        ],
        "published": "2024-05-24T13:49:18Z"
    },
    {
        "title": "Learning from Linear Algebra: A Graph Neural Network Approach to\n  Preconditioner Design for Conjugate Gradient Solvers",
        "link": "http://arxiv.org/abs/2405.15557v1",
        "abstract": "Large linear systems are ubiquitous in modern computational science. The main\nrecipe for solving them is iterative solvers with well-designed\npreconditioners. Deep learning models may be used to precondition residuals\nduring iteration of such linear solvers as the conjugate gradient (CG) method.\nNeural network models require an enormous number of parameters to approximate\nwell in this setup. Another approach is to take advantage of small graph neural\nnetworks (GNNs) to construct preconditioners of the predefined sparsity\npattern. In our work, we recall well-established preconditioners from linear\nalgebra and use them as a starting point for training the GNN. Numerical\nexperiments demonstrate that our approach outperforms both classical methods\nand neural network-based preconditioning. We also provide a heuristic\njustification for the loss function used and validate our approach on complex\ndatasets.",
        "subjects": [
            "cs.LG",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Vladislav Trifonov",
            "Alexander Rudikov",
            "Oleg Iliev",
            "Ivan Oseledets",
            "Ekaterina Muravleva"
        ],
        "published": "2024-05-24T13:44:30Z"
    },
    {
        "title": "Certifiably Robust RAG against Retrieval Corruption",
        "link": "http://arxiv.org/abs/2405.15556v1",
        "abstract": "Retrieval-augmented generation (RAG) has been shown vulnerable to retrieval\ncorruption attacks: an attacker can inject malicious passages into retrieval\nresults to induce inaccurate responses. In this paper, we propose RobustRAG as\nthe first defense framework against retrieval corruption attacks. The key\ninsight of RobustRAG is an isolate-then-aggregate strategy: we get LLM\nresponses from each passage in isolation and then securely aggregate these\nisolated responses. To instantiate RobustRAG, we design keyword-based and\ndecoding-based algorithms for securely aggregating unstructured text responses.\nNotably, RobustRAG can achieve certifiable robustness: we can formally prove\nand certify that, for certain queries, RobustRAG can always return accurate\nresponses, even when the attacker has full knowledge of our defense and can\narbitrarily inject a small number of malicious passages. We evaluate RobustRAG\non open-domain QA and long-form text generation datasets and demonstrate its\neffectiveness and generalizability across various tasks and datasets.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.CR"
        ],
        "authors": [
            "Chong Xiang",
            "Tong Wu",
            "Zexuan Zhong",
            "David Wagner",
            "Danqi Chen",
            "Prateek Mittal"
        ],
        "published": "2024-05-24T13:44:25Z"
    },
    {
        "title": "Thinking Forward: Memory-Efficient Federated Finetuning of Language\n  Models",
        "link": "http://arxiv.org/abs/2405.15551v1",
        "abstract": "Finetuning large language models (LLMs) in federated learning (FL) settings\nhas become important as it allows resource-constrained devices to finetune a\nmodel using private data. However, finetuning LLMs using backpropagation\nrequires excessive memory (especially from intermediate activations) for\nresource-constrained devices. While Forward-mode Auto-Differentiation (AD) can\nreduce memory footprint from activations, we observe that directly applying it\nto LLM finetuning results in slow convergence and poor accuracy. This work\nintroduces Spry, an FL algorithm that splits trainable weights of an LLM among\nparticipating clients, such that each client computes gradients using\nForward-mode AD that are closer estimates of the true gradients. Spry achieves\na low memory footprint, high accuracy, and fast convergence. We theoretically\nshow that the global gradients in Spry are unbiased estimates of true global\ngradients for homogeneous data distributions across clients, while\nheterogeneity increases bias of the estimates. We also derive Spry's\nconvergence rate, showing that the gradients decrease inversely proportional to\nthe number of FL rounds, indicating the convergence up to the limits of\nheterogeneity. Empirically, Spry reduces the memory footprint during training\nby 1.4-7.1$\\times$ in contrast to backpropagation, while reaching comparable\naccuracy, across a wide range of language tasks, models, and FL settings. Spry\nreduces the convergence time by 1.2-20.3$\\times$ and achieves 5.2-13.5\\% higher\naccuracy against state-of-the-art zero-order methods. When finetuning Llama2-7B\nwith LoRA, compared to the peak memory usage of 33.9GB of backpropagation, Spry\nonly consumes 6.2GB of peak memory. For OPT13B, the reduction is from 76.5GB to\n10.8GB. Spry makes feasible previously impossible FL deployments on commodity\nmobile and edge devices. Source code is available at\nhttps://github.com/Astuary/Spry.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Kunjal Panchal",
            "Nisarg Parikh",
            "Sunav Choudhary",
            "Lijun Zhang",
            "Yuriy Brun",
            "Hui Guan"
        ],
        "published": "2024-05-24T13:37:48Z"
    },
    {
        "title": "CowScreeningDB: A public benchmark dataset for lameness detection in\n  dairy cows",
        "link": "http://dx.doi.org/10.1016/j.compag.2023.108500",
        "abstract": "Lameness is one of the costliest pathological problems affecting dairy\nanimals. It is usually assessed by trained veterinary clinicians who observe\nfeatures such as gait symmetry or gait parameters as step counts in real-time.\nWith the development of artificial intelligence, various modular systems have\nbeen proposed to minimize subjectivity in lameness assessment. However, the\nmajor limitation in their development is the unavailability of a public dataset\nwhich is currently either commercial or privately held. To tackle this\nlimitation, we have introduced CowScreeningDB which was created using sensory\ndata. This dataset was sourced from 43 cows at a dairy located in Gran Canaria,\nSpain. It consists of a multi-sensor dataset built on data collected using an\nApple Watch 6 during the normal daily routine of a dairy cow. Thanks to the\ncollection environment, sampling technique, information regarding the sensors,\nthe applications used for data conversion and storage make the dataset a\ntransparent one. This transparency of data can thus be used for further\ndevelopment of techniques for lameness detection for dairy cows which can be\nobjectively compared. Aside from the public sharing of the dataset, we have\nalso shared a machine-learning technique which classifies the caws in healthy\nand lame by using the raw sensory data. Hence validating the major objective\nwhich is to establish the relationship between sensor data and lameness.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Shahid Ismail",
            "Moises Diaz",
            "Cristina Carmona-Duarte",
            "Jose Manuel Vilar",
            "Miguel A. Ferrer"
        ],
        "published": "2024-05-24T13:36:00Z"
    },
    {
        "title": "SEP: Self-Enhanced Prompt Tuning for Visual-Language Model",
        "link": "http://arxiv.org/abs/2405.15549v1",
        "abstract": "Prompt tuning based on Context Optimization (CoOp) effectively adapts\nvisual-language models (VLMs) to downstream tasks by inferring additional\nlearnable prompt tokens. However, these tokens are less discriminative as they\nare independent of the pre-trained tokens and fail to capture input-specific\nknowledge, such as class-aware textual or instance-aware visual knowledge.\nLeveraging the discriminative and generalization capabilities inherent in\npre-trained tokens, we introduce a novel approach named Self-Enhanced Prompt\nTuning (SEP). The core principle of SEP involves adapting the learnable prompt\ntokens at each encoder layer from the corresponding self-pretrained tokens,\nthereby explicitly incorporating discriminative prior knowledge to enhance both\ntextual-level and visual-level embeddings. Furthermore, SEP's self-enhanced\ntokens not only boost discrimination but also mitigate domain shifts in unseen\ndomains, enhancing generalization. In practice, SEP selects several\nrepresentative tokens from all pre-trained tokens for each input data at every\nlayer of the text/visual encoders. Subsequently, a Token Fusion Module (TFM) is\nintroduced to generate a self-enhanced token by merging these representative\ntokens with the learnable tokens using a cross-attention mechanism. This\nself-enhanced token is then concatenated with all pre-trained tokens, serving\nas input for subsequent encoder layers to produce the relevant embeddings.\nComprehensive evaluations across various benchmarks and tasks confirm SEP's\nefficacy in prompt tuning. Code: \\href{Code}{https://github.com/htyao89/SEP}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hantao Yao",
            "Rui Zhang",
            "Lu Yu",
            "Changsheng Xu"
        ],
        "published": "2024-05-24T13:35:56Z"
    },
    {
        "title": "UAV-assisted C-RAN for On-demand Cellular Coverage: Opportunities and\n  Challenges",
        "link": "http://arxiv.org/abs/2405.15548v1",
        "abstract": "The deployment of beyond fifth-generation (5G) infrastructure over\ndisaster-affected regions, temporary hotspot situations (e.g., massive\ngatherings, etc.), complex terrains (e.g., sea, hills, marshes, etc.) poses\nnumerous challenges for cellular service providers. Recently, unmanned aerial\nvehicles (UAVs) have emerged as potential candidates to overcome the\naforementioned technical issues based on their multi-role capabilities to serve\nas aerial base stations, mobile relays, and flying wireless access points. As\nsuch, the UAVs can act as portable platforms that can be deployed immediately\non demand without requiring massive ground infrastructure to support wireless\nservices. This article introduces the integration of UAVs to cloud radio access\nnetworks (C-RAN) for beyond 5G applications. The article mainly focuses on the\nunderlying opportunities and challenges to realize the UAV-assisted C-RAN\n(UC-RAN) architecture in view of three generic application scenarios, i.e.,\ndisaster management, hotspots, and complex terrains. A preliminary performance\nanalysis via simulation is further provided for the proposed UC-RAN under\nhotspot application scenario based on the relevant metrics.",
        "subjects": [
            "cs.NI",
            "cs.ET"
        ],
        "authors": [
            "Byomakesh Mahapatra",
            "Deepika Gupta",
            "Pankaj Kumar Sharma"
        ],
        "published": "2024-05-24T13:34:52Z"
    },
    {
        "title": "Freya PAGE: First Optimal Time Complexity for Large-Scale Nonconvex\n  Finite-Sum Optimization with Heterogeneous Asynchronous Computations",
        "link": "http://arxiv.org/abs/2405.15545v1",
        "abstract": "In practical distributed systems, workers are typically not homogeneous, and\ndue to differences in hardware configurations and network conditions, can have\nhighly varying processing times. We consider smooth nonconvex finite-sum\n(empirical risk minimization) problems in this setup and introduce a new\nparallel method, Freya PAGE, designed to handle arbitrarily heterogeneous and\nasynchronous computations. By being robust to \"stragglers\" and adaptively\nignoring slow computations, Freya PAGE offers significantly improved time\ncomplexity guarantees compared to all previous methods, including Asynchronous\nSGD, Rennala SGD, SPIDER, and PAGE, while requiring weaker assumptions. The\nalgorithm relies on novel generic stochastic gradient collection strategies\nwith theoretical guarantees that can be of interest on their own, and may be\nused in the design of future optimization methods. Furthermore, we establish a\nlower bound for smooth nonconvex finite-sum problems in the asynchronous setup,\nproviding a fundamental time complexity limit. This lower bound is tight and\ndemonstrates the optimality of Freya PAGE in the large-scale regime, i.e., when\n$\\sqrt{m} \\geq n$, where $n$ is # of workers, and $m$ is # of data samples.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Alexander Tyurin",
            "Kaja Gruntkowska",
            "Peter Richtárik"
        ],
        "published": "2024-05-24T13:33:30Z"
    },
    {
        "title": "Knowledge-enhanced Relation Graph and Task Sampling for Few-shot\n  Molecular Property Prediction",
        "link": "http://arxiv.org/abs/2405.15544v1",
        "abstract": "Recently, few-shot molecular property prediction (FSMPP) has garnered\nincreasing attention. Despite impressive breakthroughs achieved by existing\nmethods, they often overlook the inherent many-to-many relationships between\nmolecules and properties, which limits their performance. For instance, similar\nsubstructures of molecules can inspire the exploration of new compounds.\nAdditionally, the relationships between properties can be quantified, with\nhigh-related properties providing more information in exploring the target\nproperty than those low-related. To this end, this paper proposes a novel\nmeta-learning FSMPP framework (KRGTS), which comprises the Knowledge-enhanced\nRelation Graph module and the Task Sampling module. The knowledge-enhanced\nrelation graph module constructs the molecule-property multi-relation graph\n(MPMRG) to capture the many-to-many relationships between molecules and\nproperties. The task sampling module includes a meta-training task sampler and\nan auxiliary task sampler, responsible for scheduling the meta-training process\nand sampling high-related auxiliary tasks, respectively, thereby achieving\nefficient meta-knowledge learning and reducing noise introduction. Empirically,\nextensive experiments on five datasets demonstrate the superiority of KRGTS\nover a variety of state-of-the-art methods. The code is available in\nhttps://github.com/Vencent-Won/KRGTS-public.",
        "subjects": [
            "q-bio.QM",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Zeyu Wang",
            "Tianyi Jiang",
            "Yao Lu",
            "Xiaoze Bao",
            "Shanqing Yu",
            "Bin Wei",
            "Qi Xuan"
        ],
        "published": "2024-05-24T13:31:19Z"
    },
    {
        "title": "A tame vs. feral dichotomy for graph classes excluding an induced minor\n  or induced topological minor",
        "link": "http://arxiv.org/abs/2405.15543v1",
        "abstract": "A minimal separator in a graph is an inclusion-minimal set of vertices that\nseparates some fixed pair of nonadjacent vertices. A graph class is said to be\ntame if there exists a polynomial upper bound for the number of minimal\nseparators of every graph in the class, and feral if it contains arbitrarily\nlarge graphs with exponentially many minimal separators. Building on recent\nworks of Gartland and Lokshtanov [SODA 2023] and Gajarsk\\'y, Jaffke, Lima,\nNovotn\\'a, Pilipczuk, Rz\\k{a}\\.zewski, and Souza [arXiv, 2022], we show that\nevery graph class defined by a single forbidden induced minor or induced\ntopological minor is either tame or feral, and classify the two cases. This\nleads to new graph classes in which Maximum Weight Independent Set and many\nother problems are solvable in polynomial time. We complement the\nclassification results with polynomial-time recognition algorithms for the\nmaximal tame graph classes appearing in the obtained classifications.",
        "subjects": [
            "math.CO",
            "cs.DM",
            "cs.DS",
            "05C69, 05C75 (Primary) 05C40, 05C30, 05C85, 68R10 (Secondary)"
        ],
        "authors": [
            "Martin Milanič",
            "Nevena Pivač"
        ],
        "published": "2024-05-24T13:30:49Z"
    },
    {
        "title": "SATSense: Multi-Satellite Collaborative Framework for Spectrum Sensing",
        "link": "http://arxiv.org/abs/2405.15542v1",
        "abstract": "Low Earth Orbit satellite Internet has recently been deployed, providing\nworldwide service with non-terrestrial networks. With the large-scale\ndeployment of both non-terrestrial and terrestrial networks, limited spectrum\nresources will not be allocated enough. Consequently, dynamic spectrum sharing\nis crucial for their coexistence in the same spectrum, where accurate spectrum\nsensing is essential. However, spectrum sensing in space is more challenging\nthan in terrestrial networks due to variable channel conditions, making\nsingle-satellite sensing unstable. Therefore, we first attempt to design a\ncollaborative sensing scheme utilizing diverse data from multiple satellites.\nHowever, it is non-trivial to achieve this collaboration due to heterogeneous\nchannel quality, considerable raw sampling data, and packet loss. To address\nthe above challenges, we first establish connections between the satellites by\nmodeling their sensing data as a graph and devising a graph neural\nnetwork-based algorithm to achieve effective spectrum sensing. Meanwhile, we\nestablish a joint sub-Nyquist sampling and autoencoder data compression\nframework to reduce the amount of transmitted sensing data. Finally, we propose\na contrastive learning-based mechanism compensates for missing packets.\nExtensive experiments demonstrate that our proposed strategy can achieve\nefficient spectrum sensing performance and outperform the conventional deep\nlearning algorithm in spectrum sensing accuracy.",
        "subjects": [
            "cs.NI",
            "cs.DC",
            "cs.LG",
            "eess.SP"
        ],
        "authors": [
            "Haoxuan Yuan",
            "Zhe Chen",
            "Zheng Lin",
            "Jinbo Peng",
            "Zihan Fang",
            "Yuhang Zhong",
            "Zihang Song",
            "Yue Gao"
        ],
        "published": "2024-05-24T13:29:57Z"
    },
    {
        "title": "Learning Generalizable Human Motion Generator with Reinforcement\n  Learning",
        "link": "http://arxiv.org/abs/2405.15541v1",
        "abstract": "Text-driven human motion generation, as one of the vital tasks in\ncomputer-aided content creation, has recently attracted increasing attention.\nWhile pioneering research has largely focused on improving numerical\nperformance metrics on given datasets, practical applications reveal a common\nchallenge: existing methods often overfit specific motion expressions in the\ntraining data, hindering their ability to generalize to novel descriptions like\nunseen combinations of motions. This limitation restricts their broader\napplicability. We argue that the aforementioned problem primarily arises from\nthe scarcity of available motion-text pairs, given the many-to-many nature of\ntext-driven motion generation. To tackle this problem, we formulate\ntext-to-motion generation as a Markov decision process and present\n\\textbf{InstructMotion}, which incorporate the trail and error paradigm in\nreinforcement learning for generalizable human motion generation. Leveraging\ncontrastive pre-trained text and motion encoders, we delve into optimizing\nreward design to enable InstructMotion to operate effectively on both paired\ndata, enhancing global semantic level text-motion alignment, and synthetic\ntext-only data, facilitating better generalization to novel prompts without the\nneed for ground-truth motion supervision. Extensive experiments on prevalent\nbenchmarks and also our synthesized unpaired dataset demonstrate that the\nproposed InstructMotion achieves outstanding performance both quantitatively\nand qualitatively.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yunyao Mao",
            "Xiaoyang Liu",
            "Wengang Zhou",
            "Zhenbo Lu",
            "Houqiang Li"
        ],
        "published": "2024-05-24T13:29:12Z"
    },
    {
        "title": "Bundle Neural Networks for message diffusion on graphs",
        "link": "http://arxiv.org/abs/2405.15540v1",
        "abstract": "The dominant paradigm for learning on graph-structured data is message\npassing. Despite being a strong inductive bias, the local message passing\nmechanism suffers from pathological issues such as over-smoothing,\nover-squashing, and limited node-level expressivity. To address these\nlimitations we propose Bundle Neural Networks (BuNN), a new type of GNN that\noperates via message diffusion over flat vector bundles - structures analogous\nto connections on Riemannian manifolds that augment the graph by assigning to\neach node a vector space and an orthogonal map. A BuNN layer evolves the\nfeatures according to a diffusion-type partial differential equation. When\ndiscretized, BuNNs are a special case of Sheaf Neural Networks (SNNs), a\nrecently proposed MPNN capable of mitigating over-smoothing. The continuous\nnature of message diffusion enables BuNNs to operate on larger scales of the\ngraph and, therefore, to mitigate over-squashing. Finally, we prove that BuNN\ncan approximate any feature transformation over nodes on any (potentially\ninfinite) family of graphs given injective positional encodings, resulting in\nuniversal node-level expressivity. We support our theory via synthetic\nexperiments and showcase the strong empirical performance of BuNNs over a range\nof real-world tasks, achieving state-of-the-art results on several standard\nbenchmarks in transductive and inductive settings.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Jacob Bamberger",
            "Federico Barbero",
            "Xiaowen Dong",
            "Michael Bronstein"
        ],
        "published": "2024-05-24T13:28:48Z"
    },
    {
        "title": "A generalized neural tangent kernel for surrogate gradient learning",
        "link": "http://arxiv.org/abs/2405.15539v1",
        "abstract": "State-of-the-art neural network training methods depend on the gradient of\nthe network function. Therefore, they cannot be applied to networks whose\nactivation functions do not have useful derivatives, such as binary and\ndiscrete-time spiking neural networks. To overcome this problem, the activation\nfunction's derivative is commonly substituted with a surrogate derivative,\ngiving rise to surrogate gradient learning (SGL). This method works well in\npractice but lacks theoretical foundation. The neural tangent kernel (NTK) has\nproven successful in the analysis of gradient descent. Here, we provide a\ngeneralization of the NTK, which we call the surrogate gradient NTK, that\nenables the analysis of SGL. First, we study a naive extension of the NTK to\nactivation functions with jumps, demonstrating that gradient descent for such\nactivation functions is also ill-posed in the infinite-width limit. To address\nthis problem, we generalize the NTK to gradient descent with surrogate\nderivatives, i.e., SGL. We carefully define this generalization and expand the\nexisting key theorems on the NTK with mathematical rigor. Further, we\nillustrate our findings with numerical experiments. Finally, we numerically\ncompare SGL in networks with sign activation function and finite width to\nkernel regression with the surrogate gradient NTK; the results confirm that the\nsurrogate gradient NTK provides a good characterization of SGL.",
        "subjects": [
            "stat.ML",
            "cond-mat.dis-nn",
            "cs.LG",
            "math.PR",
            "q-bio.NC"
        ],
        "authors": [
            "Luke Eilers",
            "Raoul-Martin Memmesheimer",
            "Sven Goedeke"
        ],
        "published": "2024-05-24T13:27:23Z"
    },
    {
        "title": "Do Not Trust Power Management: Challenges and Hints for Securing Future\n  Trusted Execution Environments",
        "link": "http://arxiv.org/abs/2405.15537v1",
        "abstract": "Over the past few years, several research groups have introduced innovative\nhardware designs for Trusted Execution Environments (TEEs), aiming to secure\napplications against potentially compromised privileged software, including the\nkernel. Since 2017, Tang et al. introduced a new class of software-enabled\nhardware attacks, which leverages energy management mechanisms. These attacks\naim at bypassing TEE security guarantees and exposing sensitive information\nlike cryptographic keys. They have increased in prevalence over the past few\nyears. Despite that, current RISC-V TEE architectures have yet to incorporate\nthem into their threat models. Proprietary implementations, such as Arm\nTrustZone and Intel SGX, embed countermeasures. However, these countermeasures\nare not viable in the long term and hinder the capabilities of energy\nmanagement mechanisms. This article presents the first comprehensive knowledge\nsurvey of these attacks, along with an evaluation of literature\ncountermeasures. Our analysis highlights a substantial security gap between\nassumed threat models and the actual ones, presenting considerable threats in\nmodern systems-on-chip that can undermine even the security guarantees provided\nby TEEs. We advocate for the enhancement of the next generation of RISC-V TEEs\nto address these attacks within their threat models, and we believe this study\nwill spur further community efforts in this direction.",
        "subjects": [
            "cs.CR",
            "cs.AR",
            "cs.ET"
        ],
        "authors": [
            "Owen Le Gonidec",
            "Maria Méndez Real",
            "Guillaume Bouffard",
            "Jean-Christophe Prévotet"
        ],
        "published": "2024-05-24T13:26:39Z"
    },
    {
        "title": "Using covariance extension equation to solve the Nevanlinna-Pick\n  interpolation with degree constraint",
        "link": "http://arxiv.org/abs/2405.15533v1",
        "abstract": "Nevanlinna-Pick interpolation problem has been widely studied in recent\ndecades, however, the known algorithm is not simplistic and robust enough. This\npaper provide a new method to solve the Nevanlinna-Pick interpolation problem\nwith degree constraint. It is based on the covariance extension equation\nproposed by Byrnes and Lindquist. A reformulation of the Nevanlinna-Pick\ninterpolation problem is achieved and then solved by continuation method. This\nmethod need not calculate the initial value and a numerical example illustrates\nrobustness and effciency of the proposed procedure",
        "subjects": [
            "math.NA",
            "cs.NA",
            "math.OC"
        ],
        "authors": [
            "Cui Yufang"
        ],
        "published": "2024-05-24T13:23:49Z"
    },
    {
        "title": "Sparse Matrix in Large Language Model Fine-tuning",
        "link": "http://arxiv.org/abs/2405.15525v1",
        "abstract": "LoRA and its variants have become popular parameter-efficient fine-tuning\n(PEFT) methods due to their ability to avoid excessive computational costs.\nHowever, an accuracy gap often exists between PEFT methods and full fine-tuning\n(FT), and this gap has yet to be systematically studied. In this work, we\nintroduce a method for selecting sparse sub-matrices that aim to minimize the\nperformance gap between PEFT vs. full fine-tuning (FT) while also reducing both\nfine-tuning computational cost and memory cost. Our Sparse Matrix Tuning (SMT)\nmethod begins by identifying the most significant sub-matrices in the gradient\nupdate, updating only these blocks during the fine-tuning process. In our\nexperiments, we demonstrate that SMT consistently surpasses other PEFT baseline\n(e.g. LoRA and DoRA) in fine-tuning popular large language models such as LLaMA\nacross a broad spectrum of tasks, while reducing the GPU memory footprint by\n67% compared to FT. We also examine how the performance of LoRA and DoRA tends\nto plateau and decline as the number of trainable parameters increases, in\ncontrast, our SMT method does not suffer from such issue.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Haoze He",
            "Juncheng Billy Li",
            "Xuan Jiang",
            "Heather Miller"
        ],
        "published": "2024-05-24T13:12:14Z"
    },
    {
        "title": "Polyp Segmentation Generalisability of Pretrained Backbones",
        "link": "http://arxiv.org/abs/2405.15524v1",
        "abstract": "It has recently been demonstrated that pretraining backbones in a\nself-supervised manner generally provides better fine-tuned polyp segmentation\nperformance, and that models with ViT-B backbones typically perform better than\nmodels with ResNet50 backbones. In this paper, we extend this recent work to\nconsider generalisability. I.e., we assess the performance of models on a\ndifferent dataset to that used for fine-tuning, accounting for variation in\nnetwork architecture and pretraining pipeline (algorithm and dataset). This\nreveals how well models with different pretrained backbones generalise to data\nof a somewhat different distribution to the training data, which will likely\narise in deployment due to different cameras and demographics of patients,\namongst other factors. We observe that the previous findings, regarding\npretraining pipelines for polyp segmentation, hold true when considering\ngeneralisability. However, our results imply that models with ResNet50\nbackbones typically generalise better, despite being outperformed by models\nwith ViT-B backbones in evaluation on the test set from the same dataset used\nfor fine-tuning.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Edward Sanderson",
            "Bogdan J. Matuszewski"
        ],
        "published": "2024-05-24T13:09:52Z"
    },
    {
        "title": "Mosaic Memory: Fuzzy Duplication in Copyright Traps for Large Language\n  Models",
        "link": "http://arxiv.org/abs/2405.15523v1",
        "abstract": "The immense datasets used to develop Large Language Models (LLMs) often\ninclude copyright-protected content, typically without the content creator's\nconsent. Copyright traps have been proposed to be injected into the original\ncontent, improving content detectability in newly released LLMs. Traps,\nhowever, rely on the exact duplication of a unique text sequence, leaving them\nvulnerable to commonly deployed data deduplication techniques. We here propose\nthe generation of fuzzy copyright traps, featuring slight modifications across\nduplication. When injected in the fine-tuning data of a 1.3B LLM, we show fuzzy\ntrap sequences to be memorized nearly as well as exact duplicates.\nSpecifically, the Membership Inference Attack (MIA) ROC AUC only drops from\n0.90 to 0.87 when 4 tokens are replaced across the fuzzy duplicates. We also\nfind that selecting replacement positions to minimize the exact overlap between\nfuzzy duplicates leads to similar memorization, while making fuzzy duplicates\nhighly unlikely to be removed by any deduplication process. Lastly, we argue\nthat the fact that LLMs memorize across fuzzy duplicates challenges the study\nof LLM memorization relying on naturally occurring duplicates. Indeed, we find\nthat the commonly used training dataset, The Pile, contains significant amounts\nof fuzzy duplicates. This introduces a previously unexplored confounding factor\nin post-hoc studies of LLM memorization, and questions the effectiveness of\n(exact) data deduplication as a privacy protection technique.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Igor Shilov",
            "Matthieu Meeus",
            "Yves-Alexandre de Montjoye"
        ],
        "published": "2024-05-24T13:05:05Z"
    },
    {
        "title": "A Preference-oriented Diversity Model Based on Mutual-information in\n  Re-ranking for E-commerce Search",
        "link": "http://arxiv.org/abs/2405.15521v1",
        "abstract": "Re-ranking is a process of rearranging ranking list to more effectively meet\nuser demands by accounting for the interrelationships between items. Existing\nmethods predominantly enhance the precision of search results, often at the\nexpense of diversity, leading to outcomes that may not fulfill the varied needs\nof users. Conversely, methods designed to promote diversity might compromise\nthe precision of the results, failing to satisfy the users' requirements for\naccuracy. To alleviate the above problems, this paper proposes a\nPreference-oriented Diversity Model Based on Mutual-information (PODM-MI),\nwhich consider both accuracy and diversity in the re-ranking process.\nSpecifically, PODM-MI adopts Multidimensional Gaussian distributions based on\nvariational inference to capture users' diversity preferences with uncertainty.\nThen we maximize the mutual information between the diversity preferences of\nthe users and the candidate items using the maximum variational inference lower\nbound to enhance their correlations. Subsequently, we derive a utility matrix\nbased on the correlations, enabling the adaptive ranking of items in line with\nuser preferences and establishing a balance between the aforementioned\nobjectives. Experimental results on real-world online e-commerce systems\ndemonstrate the significant improvements of PODM-MI, and we have successfully\ndeployed PODM-MI on an e-commerce search platform.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "authors": [
            "Huimu Wang",
            "Mingming Li",
            "Dadong Miao",
            "Songlin Wang",
            "Guoyu Tang",
            "Lin Liu",
            "Sulong Xu",
            "Jinghe Hu"
        ],
        "published": "2024-05-24T13:03:34Z"
    },
    {
        "title": "From Data Complexity to User Simplicity: A Framework for Linked Open\n  Data Reconciliation and Serendipitous Discovery",
        "link": "http://arxiv.org/abs/2405.15520v1",
        "abstract": "This article introduces a novel software solution to create a Web portal to\nalign Linked Open Data sources and provide user-friendly interfaces for\nserendipitous discovery. We present the Polifonia Web portal as a motivating\nscenario and case study to address research problems such as data\nreconciliation and serving generous interfaces in the music heritage domain.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Marco Grasso",
            "Giulia Renda",
            "Marilena Daquino"
        ],
        "published": "2024-05-24T13:03:20Z"
    },
    {
        "title": "Feature Splatting for Better Novel View Synthesis with Low Overlap",
        "link": "http://arxiv.org/abs/2405.15518v1",
        "abstract": "3D Gaussian Splatting has emerged as a very promising scene representation,\nachieving state-of-the-art quality in novel view synthesis significantly faster\nthan competing alternatives. However, its use of spherical harmonics to\nrepresent scene colors limits the expressivity of 3D Gaussians and, as a\nconsequence, the capability of the representation to generalize as we move away\nfrom the training views. In this paper, we propose to encode the color\ninformation of 3D Gaussians into per-Gaussian feature vectors, which we denote\nas Feature Splatting (FeatSplat). To synthesize a novel view, Gaussians are\nfirst \"splatted\" into the image plane, then the corresponding feature vectors\nare alpha-blended, and finally the blended vector is decoded by a small MLP to\nrender the RGB pixel values. To further inform the model, we concatenate a\ncamera embedding to the blended feature vector, to condition the decoding also\non the viewpoint information. Our experiments show that these novel model for\nencoding the radiance considerably improves novel view synthesis for low\noverlap views that are distant from the training views. Finally, we also show\nthe capacity and convenience of our feature vector representation,\ndemonstrating its capability not only to generate RGB values for novel views,\nbut also their per-pixel semantic labels. We will release the code upon\nacceptance.\n  Keywords: Gaussian Splatting, Novel View Synthesis, Feature Splatting",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "T. Berriel Martins",
            "Javier Civera"
        ],
        "published": "2024-05-24T13:02:29Z"
    },
    {
        "title": "Erase to Enhance: Data-Efficient Machine Unlearning in MRI\n  Reconstruction",
        "link": "http://arxiv.org/abs/2405.15517v1",
        "abstract": "Machine unlearning is a promising paradigm for removing unwanted data samples\nfrom a trained model, towards ensuring compliance with privacy regulations and\nlimiting harmful biases. Although unlearning has been shown in, e.g.,\nclassification and recommendation systems, its potential in medical\nimage-to-image translation, specifically in image recon-struction, has not been\nthoroughly investigated. This paper shows that machine unlearning is possible\nin MRI tasks and has the potential to benefit for bias removal. We set up a\nprotocol to study how much shared knowledge exists between datasets of\ndifferent organs, allowing us to effectively quantify the effect of unlearning.\nOur study reveals that combining training data can lead to hallucinations and\nreduced image quality in the reconstructed data. We use unlearning to remove\nhallucinations as a proxy exemplar of undesired data removal. Indeed, we show\nthat machine unlearning is possible without full retraining. Furthermore, our\nobservations indicate that maintaining high performance is feasible even when\nusing only a subset of retain data. We have made our code publicly accessible.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Yuyang Xue",
            "Jingshuai Liu",
            "Steven McDonagh",
            "Sotirios A. Tsaftaris"
        ],
        "published": "2024-05-24T13:01:35Z"
    },
    {
        "title": "Source Code Archiving to the Rescue of Reproducible Deployment",
        "link": "http://dx.doi.org/10.1145/3641525.3663622",
        "abstract": "The ability to verify research results and to experiment with methodologies\nare core tenets of science. As research results are increasingly the outcome of\ncomputational processes, software plays a central role. GNU Guix is a software\ndeployment tool that supports reproducible software deployment, making it a\nfoundation for computational research workflows. To achieve reproducibility, we\nmust first ensure the source code of software packages Guix deploys remains\navailable.We describe our work connecting Guix with Software Heritage, the\nuniversal source code archive, making Guix the first free software distribution\nand tool backed by a stable archive. Our contribution is twofold: we explain\nthe rationale and present the design and implementation we came up with;\nsecond, we report on the archival coverage for package source code with data\ncollected over five years and discuss remaining challenges.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Ludovic Courtès",
            "Timothy Sample",
            "Simon Tournier",
            "Stefano Zacchiroli"
        ],
        "published": "2024-05-24T13:00:28Z"
    },
    {
        "title": "On the Convexity and Reliability of the Bethe Free Energy Approximation",
        "link": "http://arxiv.org/abs/2405.15514v1",
        "abstract": "The Bethe free energy approximation provides an effective way for relaxing\nNP-hard problems of probabilistic inference. However, its accuracy depends on\nthe model parameters and particularly degrades if a phase transition in the\nmodel occurs. In this work, we analyze when the Bethe approximation is reliable\nand how this can be verified. We argue and show by experiment that it is mostly\naccurate if it is convex on a submanifold of its domain, the 'Bethe box'. For\nverifying its convexity, we derive two sufficient conditions that are based on\nthe definiteness properties of the Bethe Hessian matrix: the first uses the\nconcept of diagonal dominance, and the second decomposes the Bethe Hessian\nmatrix into a sum of sparse matrices and characterizes the definiteness\nproperties of the individual matrices in that sum. These theoretical results\nprovide a simple way to estimate the critical phase transition temperature of a\nmodel. As a practical contribution we propose $\\texttt{BETHE-MIN}$, a projected\nquasi-Newton method to efficiently find a minimum of the Bethe free energy.",
        "subjects": [
            "stat.ML",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Harald Leisenberger",
            "Christian Knoll",
            "Franz Pernkopf"
        ],
        "published": "2024-05-24T12:57:40Z"
    },
    {
        "title": "ChatGPT Code Detection: Techniques for Uncovering the Source of Code",
        "link": "http://arxiv.org/abs/2405.15512v1",
        "abstract": "In recent times, large language models (LLMs) have made significant strides\nin generating computer code, blurring the lines between code created by humans\nand code produced by artificial intelligence (AI). As these technologies evolve\nrapidly, it is crucial to explore how they influence code generation,\nespecially given the risk of misuse in areas like higher education. This paper\nexplores this issue by using advanced classification techniques to\ndifferentiate between code written by humans and that generated by ChatGPT, a\ntype of LLM. We employ a new approach that combines powerful embedding features\n(black-box) with supervised learning algorithms - including Deep Neural\nNetworks, Random Forests, and Extreme Gradient Boosting - to achieve this\ndifferentiation with an impressive accuracy of 98%. For the successful\ncombinations, we also examine their model calibration, showing that some of the\nmodels are extremely well calibrated. Additionally, we present white-box\nfeatures and an interpretable Bayes classifier to elucidate critical\ndifferences between the code sources, enhancing the explainability and\ntransparency of our approach. Both approaches work well but provide at most\n85-88% accuracy. We also show that untrained humans solve the same task not\nbetter than random guessing. This study is crucial in understanding and\nmitigating the potential risks associated with using AI in code generation,\nparticularly in the context of higher education, software development, and\ncompetitive programming.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Marc Oedingen",
            "Raphael C. Engelhardt",
            "Robin Denz",
            "Maximilian Hammer",
            "Wolfgang Konen"
        ],
        "published": "2024-05-24T12:56:18Z"
    },
    {
        "title": "Randomized algorithms and PAC bounds for inverse reinforcement learning\n  in continuous spaces",
        "link": "http://arxiv.org/abs/2405.15509v1",
        "abstract": "This work studies discrete-time discounted Markov decision processes with\ncontinuous state and action spaces and addresses the inverse problem of\ninferring a cost function from observed optimal behavior. We first consider the\ncase in which we have access to the entire expert policy and characterize the\nset of solutions to the inverse problem by using occupation measures, linear\nduality, and complementary slackness conditions. To avoid trivial solutions and\nill-posedness, we introduce a natural linear normalization constraint. This\nresults in an infinite-dimensional linear feasibility problem, prompting a\nthorough analysis of its properties. Next, we use linear function approximators\nand adopt a randomized approach, namely the scenario approach and related\nprobabilistic feasibility guarantees, to derive epsilon-optimal solutions for\nthe inverse problem. We further discuss the sample complexity for a desired\napproximation accuracy. Finally, we deal with the more realistic case where we\nonly have access to a finite set of expert demonstrations and a generative\nmodel and provide bounds on the error made when working with samples.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "authors": [
            "Angeliki Kamoutsi",
            "Peter Schmitt-Förster",
            "Tobias Sutter",
            "Volkan Cevher",
            "John Lygeros"
        ],
        "published": "2024-05-24T12:53:07Z"
    },
    {
        "title": "Human-in-the-loop Reinforcement Learning for Data Quality Monitoring in\n  Particle Physics Experiments",
        "link": "http://arxiv.org/abs/2405.15508v1",
        "abstract": "Data Quality Monitoring (DQM) is a crucial task in large particle physics\nexperiments, since detector malfunctioning can compromise the data. DQM is\ncurrently performed by human shifters, which is costly and results in limited\naccuracy. In this work, we provide a proof-of-concept for applying\nhuman-in-the-loop Reinforcement Learning (RL) to automate the DQM process while\nadapting to operating conditions that change over time. We implement a\nprototype based on the Proximal Policy Optimization (PPO) algorithm and\nvalidate it on a simplified synthetic dataset. We demonstrate how a multi-agent\nsystem can be trained for continuous automated monitoring during data\ncollection, with human intervention actively requested only when relevant. We\nshow that random, unbiased noise in human classification can be reduced,\nleading to an improved accuracy over the baseline. Additionally, we propose\ndata augmentation techniques to deal with scarce data and to accelerate the\nlearning process. Finally, we discuss further steps needed to implement the\napproach in the real world, including protocols for periodic control of the\nalgorithm's outputs.",
        "subjects": [
            "hep-ex",
            "cs.LG"
        ],
        "authors": [
            "Olivia Jullian Parra",
            "Julián García Pardiñas",
            "Lorenzo Del Pianta Pérez",
            "Maximilian Janisch",
            "Suzanne Klaver",
            "Thomas Lehéricy",
            "Nicola Serra"
        ],
        "published": "2024-05-24T12:52:46Z"
    },
    {
        "title": "Time-Harmonic Optical Flow with Applications in Elastography",
        "link": "http://arxiv.org/abs/2405.15507v1",
        "abstract": "In this paper, we propose mathematical models for reconstructing the optical\nflow in time-harmonic elastography. In this image acquisition technique, the\nobject undergoes a special time-harmonic oscillation with known frequency so\nthat only the spatially varying amplitude of the velocity field has to be\ndetermined. This allows for a simpler multi-frame optical flow analysis using\nFourier analytic tools in time. We propose three variational optical flow\nmodels and show how their minimization can be tackled via Fourier transform in\ntime. Numerical examples with synthetic as well as real-world data demonstrate\nthe benefits of our approach.\n  Keywords: optical flow, elastography, Fourier transform, iteratively\nreweighted least squares, Horn--Schunck method",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Oleh Melnyk",
            "Michael Quellmalz",
            "Gabriele Steidl",
            "Noah Jaitner",
            "Jakob Jordan",
            "Ingolf Sack"
        ],
        "published": "2024-05-24T12:52:34Z"
    },
    {
        "title": "Learning to Discretize Denoising Diffusion ODEs",
        "link": "http://arxiv.org/abs/2405.15506v1",
        "abstract": "Diffusion Probabilistic Models (DPMs) are powerful generative models showing\ncompetitive performance in various domains, including image synthesis and 3D\npoint cloud generation. However, sampling from pre-trained DPMs involves\nmultiple neural function evaluations (NFE) to transform Gaussian noise samples\ninto images, resulting in higher computational costs compared to single-step\ngenerative models such as GANs or VAEs. Therefore, a crucial problem is to\nreduce NFE while preserving generation quality. To this end, we propose LD3, a\nlightweight framework for learning time discretization while sampling from the\ndiffusion ODE encapsulated by DPMs. LD3 can be combined with various diffusion\nODE solvers and consistently improves performance without retraining\nresource-intensive neural networks. We demonstrate analytically and empirically\nthat LD3 enhances sampling efficiency compared to distillation-based methods,\nwithout the extensive computational overhead. We evaluate our method with\nextensive experiments on 5 datasets, covering unconditional and conditional\nsampling in both pixel-space and latent-space DPMs. For example, in about 5\nminutes of training on a single GPU, our method reduces the FID score from 6.63\nto 2.68 on CIFAR10 (7 NFE), and in around 20 minutes, decreases the FID from\n8.51 to 5.03 on class-conditional ImageNet-256 (5 NFE). LD3 complements\ndistillation methods, offering a more efficient approach to sampling from\npre-trained diffusion models.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Vinh Tong",
            "Anji Liu",
            "Trung-Dung Hoang",
            "Guy Van den Broeck",
            "Mathias Niepert"
        ],
        "published": "2024-05-24T12:51:23Z"
    },
    {
        "title": "Revisiting Counterfactual Regression through the Lens of\n  Gromov-Wasserstein Information Bottleneck",
        "link": "http://arxiv.org/abs/2405.15505v1",
        "abstract": "As a promising individualized treatment effect (ITE) estimation method,\ncounterfactual regression (CFR) maps individuals' covariates to a latent space\nand predicts their counterfactual outcomes. However, the selection bias between\ncontrol and treatment groups often imbalances the two groups' latent\ndistributions and negatively impacts this method's performance. In this study,\nwe revisit counterfactual regression through the lens of information bottleneck\nand propose a novel learning paradigm called Gromov-Wasserstein information\nbottleneck (GWIB). In this paradigm, we learn CFR by maximizing the mutual\ninformation between covariates' latent representations and outcomes while\npenalizing the kernelized mutual information between the latent representations\nand the covariates. We demonstrate that the upper bound of the penalty term can\nbe implemented as a new regularizer consisting of $i)$ the fused\nGromov-Wasserstein distance between the latent representations of different\ngroups and $ii)$ the gap between the transport cost generated by the model and\nthe cross-group Gromov-Wasserstein distance between the latent representations\nand the covariates. GWIB effectively learns the CFR model through alternating\noptimization, suppressing selection bias while avoiding trivial latent\ndistributions. Experiments on ITE estimation tasks show that GWIB consistently\noutperforms state-of-the-art CFR methods. To promote the research community, we\nrelease our project at https://github.com/peteryang1031/Causal-GWIB.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Hao Yang",
            "Zexu Sun",
            "Hongteng Xu",
            "Xu Chen"
        ],
        "published": "2024-05-24T12:48:24Z"
    },
    {
        "title": "Hierarchical Loss And Geometric Mask Refinement For Multilabel Ribs\n  Segmentation",
        "link": "http://arxiv.org/abs/2405.15500v1",
        "abstract": "Automatic ribs segmentation and numeration can increase computed tomography\nassessment speed and reduce radiologists mistakes. We introduce a model for\nmultilabel ribs segmentation with hierarchical loss function, which enable to\nimprove multilabel segmentation quality. Also we propose postprocessing\ntechnique to further increase labeling quality. Our model achieved new\nstate-of-the-art 98.2% label accuracy on public RibSeg v2 dataset, surpassing\nprevious result by 6.7%.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Aleksei Leonov",
            "Aleksei Zakharov",
            "Sergey Koshelev",
            "Maxim Pisov",
            "Anvar Kurmukov",
            "Mikhail Belyaev"
        ],
        "published": "2024-05-24T12:39:21Z"
    },
    {
        "title": "Node Accessibility Characterization of Radially-Grown Structures",
        "link": "http://arxiv.org/abs/2405.15498v1",
        "abstract": "Complex systems have motivated continuing interest from the scientific\ncommunity, leading to new concepts and methods. Growing systems represent a\ncase of particular interest, as their topological, geometrical, and also\ndynamical properties change along time, as new elements are incorporated into\nthe existing structure. In the present work, an approach is the case in which\nsystems grown radially around some straight axis of reference, such as particle\ndeposition on electrodes, or urban expansion along avenues, roads, coastline,\nor rivers, among several other possibilities. More specifically, we aim at\ncharacterizing the topological properties of simulated growing structures,\nwhich are represented as graphs, in terms of a measurement corresponding to the\naccessibility of each involved node. The incorporation of new elements (nodes\nand links) is performed preferentially to the angular orientation respectively\nto the reference axis. Several interesting results are reported, including the\ntendency of structures grown preferentially to the orientation normal to the\naxis to have smaller accessibility.",
        "subjects": [
            "cs.SI",
            "physics.soc-ph"
        ],
        "authors": [
            "Alexandre Benatti",
            "Roberto M. Cesar Jr.",
            "Luciano da F. Costa"
        ],
        "published": "2024-05-24T12:37:05Z"
    },
    {
        "title": "Finite-time convergence to an $ε$-efficient Nash equilibrium in\n  potential games",
        "link": "http://arxiv.org/abs/2405.15497v1",
        "abstract": "This paper investigates the convergence time of log-linear learning to an\n$\\epsilon$-efficient Nash equilibrium (NE) in potential games. In such games,\nan efficient NE is defined as the maximizer of the potential function. Existing\nresults are limited to potential games with stringent structural assumptions\nand entail exponential convergence times in $1/\\epsilon$. Unaddressed so far,\nwe tackle general potential games and prove the first finite-time convergence\nto an $\\epsilon$-efficient NE. In particular, by using a problem-dependent\nanalysis, our bound depends polynomially on $1/\\epsilon$. Furthermore, we\nprovide two extensions of our convergence result: first, we show that a variant\nof log-linear learning that requires a factor $A$ less feedback on the utility\nper round enjoys a similar convergence time; second, we demonstrate the\nrobustness of our convergence guarantee if log-linear learning is subject to\nsmall perturbations such as alterations in the learning rule or noise-corrupted\nutilities.",
        "subjects": [
            "cs.MA"
        ],
        "authors": [
            "Anna Maddux",
            "Reda Ouhamma",
            "Maryam Kamgarpour"
        ],
        "published": "2024-05-24T12:34:32Z"
    },
    {
        "title": "Towards Natural Machine Unlearning",
        "link": "http://arxiv.org/abs/2405.15495v1",
        "abstract": "Machine unlearning (MU) aims to eliminate information that has been learned\nfrom specific training data, namely forgetting data, from a pre-trained model.\nCurrently, the mainstream of existing MU methods involves modifying the\nforgetting data with incorrect labels and subsequently fine-tuning the model.\nWhile learning such incorrect information can indeed remove knowledge, the\nprocess is quite unnatural as the unlearning process undesirably reinforces the\nincorrect information and leads to over-forgetting. Towards more\n\\textit{natural} machine unlearning, we inject correct information from the\nremaining data to the forgetting samples when changing their labels. Through\npairing these adjusted samples with their labels, the model will tend to use\nthe injected correct information and naturally suppress the information meant\nto be forgotten. Albeit straightforward, such a first step towards natural\nmachine unlearning can significantly outperform current state-of-the-art\napproaches. In particular, our method substantially reduces the over-forgetting\nand leads to strong robustness to hyperparameters, making it a promising\ncandidate for practical machine unlearning.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Zhengbao He",
            "Tao Li",
            "Xinwen Cheng",
            "Zhehao Huang",
            "Xiaolin Huang"
        ],
        "published": "2024-05-24T12:23:38Z"
    },
    {
        "title": "Design and Implementation of DC-DC Buck Converter based on Deep Neural\n  Network Sliding Mode Control",
        "link": "http://arxiv.org/abs/2405.15493v1",
        "abstract": "In order to address the challenge of traditional sliding mode controllers\nstruggling to balance between suppressing system jitter and accelerating\nconvergence speed, a deep neural network (DNN)-based sliding mode control\nstrategy is proposed in this paper. The strategy achieves dynamic adjustment of\nparameters by modelling and learning the system through deep neural networks,\nwhich suppresses the system jitter while ensuring the convergence speed of the\nsystem. To demonstrate the stability of the system, a Lyapunov function is\ndesigned to prove the stability of the mathematical model of the DNN-based\nsliding mode control strategy for DC-DC buck switching power supply. We adopt a\ndouble closed-loop control mode to combine the sliding mode control of the\nvoltage inner loop with the PI control of the current outer loop.\nSimultaneously, The DNN performance is evaluated through simulation and\nhardware experiments and compared with conventional control methods. The\nresults demonstrate that the sliding mode controller based on the DNN exhibits\nfaster system convergence speed, enhanced jitter suppression capability, and\ngreater robustness.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Liu Zhiwei",
            "Yu Wangbing"
        ],
        "published": "2024-05-24T12:21:57Z"
    },
    {
        "title": "Finding Induced Subgraphs from Graphs with Small Mim-Width",
        "link": "http://arxiv.org/abs/2405.15492v1",
        "abstract": "In the last decade, algorithmic frameworks based on a structural graph\nparameter called mim-width have been developed to solve generally NP-hard\nproblems. However, it is known that the frameworks cannot be applied to the\nClique problem, and the complexity status of many problems of finding dense\ninduced subgraphs remains open when parameterized by mim-width. In this paper,\nwe investigate the complexity of the problem of finding a maximum induced\nsubgraph that satisfies prescribed properties from a given graph with small\nmim-width. We first give a meta-theorem implying that various induced subgraph\nproblems are NP-hard for bounded mim-width graphs. Moreover, we show that some\nproblems, including Clique and Induced Cluster Subgraph, remain NP-hard even\nfor graphs with (linear) mim-width at most 2. In contrast to the\nintractability, we provide an algorithm that, given a graph and its branch\ndecomposition with mim-width at most 1, solves Induced Cluster Subgraph in\npolynomial time. We emphasize that our algorithmic technique is applicable to\nother problems such as Induced Polar Subgraph and Induced Split Subgraph. Since\na branch decomposition with mim-width at most 1 can be constructed in\npolynomial time for block graphs, interval graphs, permutation graphs,\ncographs, distance-hereditary graphs, convex graphs, and their complement\ngraphs, our positive results reveal the polynomial-time solvability of various\nproblems for these graph classes.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Yota Otachi",
            "Akira Suzuki",
            "Yuma Tamura"
        ],
        "published": "2024-05-24T12:16:47Z"
    },
    {
        "title": "GSDeformer: Direct Cage-based Deformation for 3D Gaussian Splatting",
        "link": "http://arxiv.org/abs/2405.15491v1",
        "abstract": "We present GSDeformer, a method that achieves free-form deformation on 3D\nGaussian Splatting(3DGS) without requiring any architectural changes. Our\nmethod extends cage-based deformation, a traditional mesh deformation method,\nto 3DGS. This is done by converting 3DGS into a novel proxy point cloud\nrepresentation, where its deformation can be used to infer the transformations\nto apply on the 3D gaussians making up 3DGS. We also propose an automatic cage\nconstruction algorithm for 3DGS to minimize manual work. Our method does not\nmodify the underlying architecture of 3DGS. Therefore, any existing trained\nvanilla 3DGS can be easily edited by our method. We compare the deformation\ncapability of our method against other existing methods, demonstrating the ease\nof use and comparable quality of our method, despite being more direct and thus\neasier to integrate with other concurrent developments on 3DGS.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jiajun Huang",
            "Hongchuan Yu"
        ],
        "published": "2024-05-24T12:16:28Z"
    },
    {
        "title": "Out of Many, One: Designing and Scaffolding Proteins at the Scale of the\n  Structural Universe with Genie 2",
        "link": "http://arxiv.org/abs/2405.15489v1",
        "abstract": "Protein diffusion models have emerged as a promising approach for protein\ndesign. One such pioneering model is Genie, a method that asymmetrically\nrepresents protein structures during the forward and backward processes, using\nsimple Gaussian noising for the former and expressive SE(3)-equivariant\nattention for the latter. In this work we introduce Genie 2, extending Genie to\ncapture a larger and more diverse protein structure space through architectural\ninnovations and massive data augmentation. Genie 2 adds motif scaffolding\ncapabilities via a novel multi-motif framework that designs co-occurring motifs\nwith unspecified inter-motif positions and orientations. This makes possible\ncomplex protein designs that engage multiple interaction partners and perform\nmultiple functions. On both unconditional and conditional generation, Genie 2\nachieves state-of-the-art performance, outperforming all known methods on key\ndesign metrics including designability, diversity, and novelty. Genie 2 also\nsolves more motif scaffolding problems than other methods and does so with more\nunique and varied solutions. Taken together, these advances set a new standard\nfor structure-based protein design. Genie 2 inference and training code, as\nwell as model weights, are freely available at:\nhttps://github.com/aqlaboratory/genie2.",
        "subjects": [
            "q-bio.BM",
            "cs.LG"
        ],
        "authors": [
            "Yeqing Lin",
            "Minji Lee",
            "Zhao Zhang",
            "Mohammed AlQuraishi"
        ],
        "published": "2024-05-24T12:11:41Z"
    },
    {
        "title": "Learning Beyond Pattern Matching? Assaying Mathematical Understanding in\n  LLMs",
        "link": "http://arxiv.org/abs/2405.15485v1",
        "abstract": "We are beginning to see progress in language model assisted scientific\ndiscovery. Motivated by the use of LLMs as a general scientific assistant, this\npaper assesses the domain knowledge of LLMs through its understanding of\ndifferent mathematical skills required to solve problems. In particular, we\nlook at not just what the pre-trained model already knows, but how it learned\nto learn from information during in-context learning or instruction-tuning\nthrough exploiting the complex knowledge structure within mathematics.\nMotivated by the Neural Tangent Kernel (NTK), we propose \\textit{NTKEval} to\nassess changes in LLM's probability distribution via training on different\nkinds of math data. Our systematic analysis finds evidence of domain\nunderstanding during in-context learning. By contrast, certain\ninstruction-tuning leads to similar performance changes irrespective of\ntraining on different data, suggesting a lack of domain understanding across\ndifferent skills.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Siyuan Guo",
            "Aniket Didolkar",
            "Nan Rosemary Ke",
            "Anirudh Goyal",
            "Ferenc Huszár",
            "Bernhard Schölkopf"
        ],
        "published": "2024-05-24T12:04:54Z"
    },
    {
        "title": "An input-output continuous-time version of Willems' lemma",
        "link": "http://arxiv.org/abs/2405.15482v1",
        "abstract": "We illustrate a novel version of Willems' lemma for data-based representation\nof continuous-time systems. The main novelties compared to previous works are\ntwo. First, the proposed framework relies only on measured input-output\ntrajectories from the system and no internal (state) information is required.\nSecond, our system representation makes use of exact system trajectories,\nwithout resorting to orthogonal bases representations and consequent\napproximations. We first establish sufficient and necessary conditions for\ndata-based generation of system trajectories in terms of suitable latent\nvariables. Subsequently, we reformulate these conditions using measured\ninput-output data and show how to span the full behavior of the system.\nFurthermore, we show how to use the developed framework to solve the data-based\ncontinuous-time simulation problem.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Victor G. Lopez",
            "Matthias A. Müller",
            "Paolo Rapisarda"
        ],
        "published": "2024-05-24T12:00:29Z"
    },
    {
        "title": "Sparse Spectral Training and Inference on Euclidean and Hyperbolic\n  Neural Networks",
        "link": "http://arxiv.org/abs/2405.15481v1",
        "abstract": "The growing computational demands posed by increasingly number of neural\nnetwork's parameters necessitate low-memory-consumption training approaches.\nPrevious memory reduction techniques, such as Low-Rank Adaptation (LoRA) and\nReLoRA, suffer from the limitation of low rank and saddle point issues,\nparticularly during intensive tasks like pre-training. In this paper, we\npropose Sparse Spectral Training (SST), an advanced training methodology that\nupdates all singular values and selectively updates singular vectors of network\nweights, thereby optimizing resource usage while closely approximating\nfull-rank training. SST refines the training process by employing a targeted\nupdating strategy for singular vectors, which is determined by a multinomial\nsampling method weighted by the significance of the singular values, ensuring\nboth high performance and memory reduction. Through comprehensive testing on\nboth Euclidean and hyperbolic neural networks across various tasks, including\nnatural language generation, machine translation, node classification and link\nprediction, SST demonstrates its capability to outperform existing memory\nreduction training methods and is comparable with full-rank training in some\ncases. On OPT-125M, with rank equating to 8.3% of embedding dimension, SST\nreduces the perplexity gap to full-rank training by 67.6%, demonstrating a\nsignificant reduction of the performance loss with prevalent low-rank methods.\nThis approach offers a strong alternative to traditional training techniques,\npaving the way for more efficient and scalable neural network training\nsolutions.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Jialin Zhao",
            "Yingtao Zhang",
            "Xinghang Li",
            "Huaping Liu",
            "Carlo Vittorio Cannistraci"
        ],
        "published": "2024-05-24T11:59:41Z"
    },
    {
        "title": "Fundamental limits of weak learnability in high-dimensional multi-index\n  models",
        "link": "http://arxiv.org/abs/2405.15480v1",
        "abstract": "Multi-index models -- functions which only depend on the covariates through a\nnon-linear transformation of their projection on a subspace -- are a useful\nbenchmark for investigating feature learning with neural networks. This paper\nexamines the theoretical boundaries of learnability in this hypothesis class,\nfocusing particularly on the minimum sample complexity required for weakly\nrecovering their low-dimensional structure with first-order iterative\nalgorithms, in the high-dimensional regime where the number of samples is\n$n=\\alpha d$ is proportional to the covariate dimension $d$. Our findings\nunfold in three parts: (i) first, we identify under which conditions a\n\\textit{trivial subspace} can be learned with a single step of a first-order\nalgorithm for any $\\alpha\\!>\\!0$; (ii) second, in the case where the trivial\nsubspace is empty, we provide necessary and sufficient conditions for the\nexistence of an {\\it easy subspace} consisting of directions that can be\nlearned only above a certain sample complexity $\\alpha\\!>\\!\\alpha_c$. The\ncritical threshold $\\alpha_{c}$ marks the presence of a computational phase\ntransition, in the sense that no efficient iterative algorithm can succeed for\n$\\alpha\\!<\\!\\alpha_c$. In a limited but interesting set of really hard\ndirections -- akin to the parity problem -- $\\alpha_c$ is found to diverge.\nFinally, (iii) we demonstrate that interactions between different directions\ncan result in an intricate hierarchical learning phenomenon, where some\ndirections can be learned sequentially when coupled to easier ones. Our\nanalytical approach is built on the optimality of approximate message-passing\nalgorithms among first-order iterative methods, delineating the fundamental\nlearnability limit across a broad spectrum of algorithms, including neural\nnetworks trained with gradient descent.",
        "subjects": [
            "cs.LG",
            "cond-mat.dis-nn",
            "cs.CC"
        ],
        "authors": [
            "Emanuele Troiani",
            "Yatin Dandi",
            "Leonardo Defilippis",
            "Lenka Zdeborová",
            "Bruno Loureiro",
            "Florent Krzakala"
        ],
        "published": "2024-05-24T11:59:02Z"
    },
    {
        "title": "MagicBathyNet: A Multimodal Remote Sensing Dataset for Bathymetry\n  Prediction and Pixel-based Classification in Shallow Waters",
        "link": "http://arxiv.org/abs/2405.15477v1",
        "abstract": "Accurate, detailed, and high-frequent bathymetry, coupled with complex\nsemantic content, is crucial for the undermapped shallow seabed areas facing\nintense climatological and anthropogenic pressures. Current methods exploiting\nremote sensing images to derive bathymetry or seabed classes mainly exploit\nnon-open data. This lack of openly accessible benchmark archives prevents the\nwider use of deep learning methods in such applications. To address this issue,\nin this paper we present the MagicBathyNet, which is a benchmark dataset made\nup of image patches of Sentinel2, SPOT-6 and aerial imagery, bathymetry in\nraster format and annotations of seabed classes. MagicBathyNet is then\nexploited to benchmark state-of-the-art methods in learning-based bathymetry\nand pixel-based classification. Dataset, pre-trained weights, and code are\npublicly available at www.magicbathy.eu/magicbathynet.html.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Panagiotis Agrafiotis",
            "Łukasz Janowski",
            "Dimitrios Skarlatos",
            "Begüm Demir"
        ],
        "published": "2024-05-24T11:58:02Z"
    },
    {
        "title": "Editable Concept Bottleneck Models",
        "link": "http://arxiv.org/abs/2405.15476v1",
        "abstract": "Concept Bottleneck Models (CBMs) have garnered much attention for their\nability to elucidate the prediction process through a human-understandable\nconcept layer. However, most previous studies focused on cases where the data,\nincluding concepts, are clean. In many scenarios, we always need to\nremove/insert some training data or new concepts from trained CBMs due to\ndifferent reasons, such as privacy concerns, data mislabelling, spurious\nconcepts, and concept annotation errors. Thus, the challenge of deriving\nefficient editable CBMs without retraining from scratch persists, particularly\nin large-scale applications. To address these challenges, we propose Editable\nConcept Bottleneck Models (ECBMs). Specifically, ECBMs support three different\nlevels of data removal: concept-label-level, concept-level, and data-level.\nECBMs enjoy mathematically rigorous closed-form approximations derived from\ninfluence functions that obviate the need for re-training. Experimental results\ndemonstrate the efficiency and effectiveness of our ECBMs, affirming their\nadaptability within the realm of CBMs.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Lijie Hu",
            "Chenyang Ren",
            "Zhengyu Hu",
            "Cheng-Long Wang",
            "Di Wang"
        ],
        "published": "2024-05-24T11:55:46Z"
    },
    {
        "title": "Efficient Degradation-aware Any Image Restoration",
        "link": "http://arxiv.org/abs/2405.15475v1",
        "abstract": "Reconstructing missing details from degraded low-quality inputs poses a\nsignificant challenge. Recent progress in image restoration has demonstrated\nthe efficacy of learning large models capable of addressing various\ndegradations simultaneously. Nonetheless, these approaches introduce\nconsiderable computational overhead and complex learning paradigms, limiting\ntheir practical utility. In response, we propose \\textit{DaAIR}, an efficient\nAll-in-One image restorer employing a Degradation-aware Learner (DaLe) in the\nlow-rank regime to collaboratively mine shared aspects and subtle nuances\nacross diverse degradations, generating a degradation-aware embedding. By\ndynamically allocating model capacity to input degradations, we realize an\nefficient restorer integrating holistic and specific learning within a unified\nmodel. Furthermore, DaAIR introduces a cost-efficient parameter update\nmechanism that enhances degradation awareness while maintaining computational\nefficiency. Extensive comparisons across five image degradations demonstrate\nthat our DaAIR outperforms both state-of-the-art All-in-One models and\ndegradation-specific counterparts, affirming our efficacy and practicality. The\nsource will be publicly made available at\n\\url{https://eduardzamfir.github.io/daair/}",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Eduard Zamfir",
            "Zongwei Wu",
            "Nancy Mehta",
            "Danda Dani Paudel",
            "Yulun Zhang",
            "Radu Timofte"
        ],
        "published": "2024-05-24T11:53:27Z"
    },
    {
        "title": "Unlearning during Learning: An Efficient Federated Machine Unlearning\n  Method",
        "link": "http://arxiv.org/abs/2405.15474v1",
        "abstract": "In recent years, Federated Learning (FL) has garnered significant attention\nas a distributed machine learning paradigm. To facilitate the implementation of\nthe right to be forgotten, the concept of federated machine unlearning (FMU)\nhas also emerged. However, current FMU approaches often involve additional\ntime-consuming steps and may not offer comprehensive unlearning capabilities,\nwhich renders them less practical in real FL scenarios. In this paper, we\nintroduce FedAU, an innovative and efficient FMU framework aimed at overcoming\nthese limitations. Specifically, FedAU incorporates a lightweight auxiliary\nunlearning module into the learning process and employs a straightforward\nlinear operation to facilitate unlearning. This approach eliminates the\nrequirement for extra time-consuming steps, rendering it well-suited for FL.\nFurthermore, FedAU exhibits remarkable versatility. It not only enables\nmultiple clients to carry out unlearning tasks concurrently but also supports\nunlearning at various levels of granularity, including individual data samples,\nspecific classes, and even at the client level. We conducted extensive\nexperiments on MNIST, CIFAR10, and CIFAR100 datasets to evaluate the\nperformance of FedAU. The results demonstrate that FedAU effectively achieves\nthe desired unlearning effect while maintaining model accuracy.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "authors": [
            "Hanlin Gu",
            "Gongxi Zhu",
            "Jie Zhang",
            "Xinyuan Zhao",
            "Yuxing Han",
            "Lixin Fan",
            "Qiang Yang"
        ],
        "published": "2024-05-24T11:53:13Z"
    },
    {
        "title": "Encoder Embedding for General Graph and Node Classification",
        "link": "http://arxiv.org/abs/2405.15473v1",
        "abstract": "Graph encoder embedding, a recent technique for graph data, offers speed and\nscalability in producing vertex-level representations from binary graphs. In\nthis paper, we extend the applicability of this method to a general graph\nmodel, which includes weighted graphs, distance matrices, and kernel matrices.\nWe prove that the encoder embedding satisfies the law of large numbers and the\ncentral limit theorem on a per-observation basis. Under certain condition, it\nachieves asymptotic normality on a per-class basis, enabling optimal\nclassification through discriminant analysis. These theoretical findings are\nvalidated through a series of experiments involving weighted graphs, as well as\ntext and image data transformed into general graph representations using\nappropriate distance metrics.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "cs.SI"
        ],
        "authors": [
            "Cencheng Shen"
        ],
        "published": "2024-05-24T11:51:08Z"
    },
    {
        "title": "Emergence of a High-Dimensional Abstraction Phase in Language\n  Transformers",
        "link": "http://arxiv.org/abs/2405.15471v1",
        "abstract": "A language model (LM) is a mapping from a linguistic context to an output\ntoken. However, much remains to be known about this mapping, including how its\ngeometric properties relate to its function. We take a high-level geometric\napproach to its analysis, observing, across five pre-trained transformer-based\nLMs and three input datasets, a distinct phase characterized by high intrinsic\ndimensionality. During this phase, representations (1) correspond to the first\nfull linguistic abstraction of the input; (2) are the first to viably transfer\nto downstream tasks; (3) predict each other across different LMs. Moreover, we\nfind that an earlier onset of the phase strongly predicts better language\nmodelling performance. In short, our results suggest that a central\nhigh-dimensionality phase underlies core linguistic processing in many common\nLM architectures.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Emily Cheng",
            "Diego Doimo",
            "Corentin Kervadec",
            "Iuri Macocco",
            "Jade Yu",
            "Alessandro Laio",
            "Marco Baroni"
        ],
        "published": "2024-05-24T11:49:07Z"
    },
    {
        "title": "Semantic Aware Diffusion Inverse Tone Mapping",
        "link": "http://arxiv.org/abs/2405.15468v1",
        "abstract": "The range of real-world scene luminance is larger than the capture capability\nof many digital camera sensors which leads to details being lost in captured\nimages, most typically in bright regions. Inverse tone mapping attempts to\nboost these captured Standard Dynamic Range (SDR) images back to High Dynamic\nRange (HDR) by creating a mapping that linearizes the well exposed values from\nthe SDR image, and provides a luminance boost to the clipped content. However,\nin most cases, the details in the clipped regions cannot be recovered or\nestimated. In this paper, we present a novel inverse tone mapping approach for\nmapping SDR images to HDR that generates lost details in clipped regions\nthrough a semantic-aware diffusion based inpainting approach. Our method\nproposes two major contributions - first, we propose to use a semantic graph to\nguide SDR diffusion based inpainting in masked regions in a saturated image.\nSecond, drawing inspiration from traditional HDR imaging and bracketing\nmethods, we propose a principled formulation to lift the SDR inpainted regions\nto HDR that is compatible with generative inpainting methods. Results show that\nour method demonstrates superior performance across different datasets on\nobjective metrics, and subjective experiments show that the proposed method\nmatches (and in most cases outperforms) state-of-art inverse tone mapping\noperators in terms of objective metrics and outperforms them for visual\nfidelity.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "authors": [
            "Abhishek Goswami",
            "Aru Ranjan Singh",
            "Francesco Banterle",
            "Kurt Debattista",
            "Thomas Bashford-Rogers"
        ],
        "published": "2024-05-24T11:44:22Z"
    },
    {
        "title": "Scale-Invariant Feature Disentanglement via Adversarial Learning for\n  UAV-based Object Detection",
        "link": "http://arxiv.org/abs/2405.15465v1",
        "abstract": "Detecting objects from Unmanned Aerial Vehicles (UAV) is often hindered by a\nlarge number of small objects, resulting in low detection accuracy. To address\nthis issue, mainstream approaches typically utilize multi-stage inferences.\nDespite their remarkable detecting accuracies, real-time efficiency is\nsacrificed, making them less practical to handle real applications. To this\nend, we propose to improve the single-stage inference accuracy through learning\nscale-invariant features. Specifically, a Scale-Invariant Feature Disentangling\nmodule is designed to disentangle scale-related and scale-invariant features.\nThen an Adversarial Feature Learning scheme is employed to enhance\ndisentanglement. Finally, scale-invariant features are leveraged for robust\nUAV-based object detection. Furthermore, we construct a multi-modal UAV object\ndetection dataset, State-Air, which incorporates annotated UAV state\nparameters. We apply our approach to three state-of-the-art lightweight\ndetection frameworks on three benchmark datasets, including State-Air.\nExtensive experiments demonstrate that our approach can effectively improve\nmodel accuracy. Our code and dataset are provided in Supplementary Materials\nand will be publicly available once the paper is accepted.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Fan Liu",
            "Liang Yao",
            "Chuanyi Zhang",
            "Ting Wu",
            "Xinlei Zhang",
            "Jun Zhou",
            "Xiruo Jiang"
        ],
        "published": "2024-05-24T11:40:22Z"
    },
    {
        "title": "PoinTramba: A Hybrid Transformer-Mamba Framework for Point Cloud\n  Analysis",
        "link": "http://arxiv.org/abs/2405.15463v1",
        "abstract": "Point cloud analysis has seen substantial advancements due to deep learning,\nalthough previous Transformer-based methods excel at modeling long-range\ndependencies on this task, their computational demands are substantial.\nConversely, the Mamba offers greater efficiency but shows limited potential\ncompared with Transformer-based methods. In this study, we introduce\nPoinTramba, a pioneering hybrid framework that synergies the analytical power\nof Transformer with the remarkable computational efficiency of Mamba for\nenhanced point cloud analysis. Specifically, our approach first segments point\nclouds into groups, where the Transformer meticulously captures intricate\nintra-group dependencies and produces group embeddings, whose inter-group\nrelationships will be simultaneously and adeptly captured by efficient Mamba\narchitecture, ensuring comprehensive analysis. Unlike previous Mamba\napproaches, we introduce a bi-directional importance-aware ordering (BIO)\nstrategy to tackle the challenges of random ordering effects. This innovative\nstrategy intelligently reorders group embeddings based on their calculated\nimportance scores, significantly enhancing Mamba's performance and optimizing\nthe overall analytical process. Our framework achieves a superior balance\nbetween computational efficiency and analytical performance by seamlessly\nintegrating these advanced techniques, marking a substantial leap forward in\npoint cloud analysis. Extensive experiments on datasets such as ScanObjectNN,\nModelNet40, and ShapeNetPart demonstrate the effectiveness of our approach,\nestablishing a new state-of-the-art analysis benchmark on point cloud\nrecognition. For the first time, this paradigm leverages the combined strengths\nof both Transformer and Mamba architectures, facilitating a new standard in the\nfield. The code is available at https://github.com/xiaoyao3302/PoinTramba.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zicheng Wang",
            "Zhenghao Chen",
            "Yiming Wu",
            "Zhen Zhao",
            "Luping Zhou",
            "Dong Xu"
        ],
        "published": "2024-05-24T11:36:26Z"
    },
    {
        "title": "Optimal market-neutral currency trading on the cryptocurrency platform",
        "link": "http://arxiv.org/abs/2405.15461v1",
        "abstract": "This research proposes a novel arbitrage approach with respect to\nmultivariate pair trading called Optimal Trading Technique (OTT). We introduce\nthe method to selectively form a \"bucket\" of fiat currencies anchored to\ncryptocurrency for simultaneously monitoring and exploiting trading\nopportunities. To handle the quantitative conflicts that arise when receiving\nmultiple trading signals, a bi-objective convex optimization process is\ndesigned to cater to the investor's preference between profitability and risk\ntolerance. This process includes tunable parameters such as volatility\npunishment, action thresholds. During our experiments in the cryptocurrency\nmarket from 2020 to 2022 when the market was experiencing a vigorous bull-run\nimmediately followed by a bear-run, the OTT realized an annualized profit of\n15.49%. We further carried out the experiments in bull, bear, and full-cycle\nmarket conditions separately, and found that OTT is capable of achieving stable\nprofit under various market conditions. Apart from the profitability side of\nthe OTT, the arbitrage operation provides a new perspective of trading, which\nrequires no external shorting and never hold intermediate cryptocurrency during\nthe arbitrage period.",
        "subjects": [
            "cs.CE",
            "q-fin.MF",
            "91B28, 62P05"
        ],
        "authors": [
            "Hongshen Yang",
            "Avinash Malik",
            "Andrea Raith"
        ],
        "published": "2024-05-24T11:35:49Z"
    },
    {
        "title": "TD3 Based Collision Free Motion Planning for Robot Navigation",
        "link": "http://arxiv.org/abs/2405.15460v1",
        "abstract": "This paper addresses the challenge of collision-free motion planning in\nautomated navigation within complex environments. Utilizing advancements in\nDeep Reinforcement Learning (DRL) and sensor technologies like LiDAR, we\npropose the TD3-DWA algorithm, an innovative fusion of the traditional Dynamic\nWindow Approach (DWA) with the Twin Delayed Deep Deterministic Policy Gradient\n(TD3). This hybrid algorithm enhances the efficiency of robotic path planning\nby optimizing the sampling interval parameters of DWA to effectively navigate\naround both static and dynamic obstacles. The performance of the TD3-DWA\nalgorithm is validated through various simulation experiments, demonstrating\nits potential to significantly improve the reliability and safety of autonomous\nnavigation systems.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Hao Liu",
            "Yi Shen",
            "Chang Zhou",
            "Yuelin Zou",
            "Zijun Gao",
            "Qi Wang"
        ],
        "published": "2024-05-24T11:34:45Z"
    },
    {
        "title": "Repetita Iuvant: Data Repetition Allows SGD to Learn High-Dimensional\n  Multi-Index Functions",
        "link": "http://arxiv.org/abs/2405.15459v1",
        "abstract": "Neural networks can identify low-dimensional relevant structures within\nhigh-dimensional noisy data, yet our mathematical understanding of how they do\nso remains scarce. Here, we investigate the training dynamics of two-layer\nshallow neural networks trained with gradient-based algorithms, and discuss how\nthey learn pertinent features in multi-index models, that is target functions\nwith low-dimensional relevant directions. In the high-dimensional regime, where\nthe input dimension $d$ diverges, we show that a simple modification of the\nidealized single-pass gradient descent training scenario, where data can now be\nrepeated or iterated upon twice, drastically improves its computational\nefficiency. In particular, it surpasses the limitations previously believed to\nbe dictated by the Information and Leap exponents associated with the target\nfunction to be learned. Our results highlight the ability of networks to learn\nrelevant structures from data alone without any pre-processing. More precisely,\nwe show that (almost) all directions are learned with at most $O(d \\log d)$\nsteps. Among the exceptions is a set of hard functions that includes sparse\nparities. In the presence of coupling between directions, however, these can be\nlearned sequentially through a hierarchical mechanism that generalizes the\nnotion of staircase functions. Our results are proven by a rigorous study of\nthe evolution of the relevant statistics for high-dimensional dynamics.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Luca Arnaboldi",
            "Yatin Dandi",
            "Florent Krzakala",
            "Luca Pesce",
            "Ludovic Stephan"
        ],
        "published": "2024-05-24T11:34:31Z"
    },
    {
        "title": "FedCal: Achieving Local and Global Calibration in Federated Learning via\n  Aggregated Parameterized Scaler",
        "link": "http://arxiv.org/abs/2405.15458v1",
        "abstract": "Federated learning (FL) enables collaborative machine learning across\ndistributed data owners, but data heterogeneity poses a challenge for model\ncalibration. While prior work focused on improving accuracy for non-iid data,\ncalibration remains under-explored. This study reveals existing FL aggregation\napproaches lead to sub-optimal calibration, and theoretical analysis shows\ndespite constraining variance in clients' label distributions, global\ncalibration error is still asymptotically lower bounded. To address this, we\npropose a novel Federated Calibration (FedCal) approach, emphasizing both local\nand global calibration. It leverages client-specific scalers for local\ncalibration to effectively correct output misalignment without sacrificing\nprediction accuracy. These scalers are then aggregated via weight averaging to\ngenerate a global scaler, minimizing the global calibration error. Extensive\nexperiments demonstrate FedCal significantly outperforms the best-performing\nbaseline, reducing global calibration error by 47.66% on average.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "authors": [
            "Hongyi Peng",
            "Han Yu",
            "Xiaoli Tang",
            "Xiaoxiao Li"
        ],
        "published": "2024-05-24T11:33:58Z"
    },
    {
        "title": "Linearly Controlled Language Generation with Performative Guarantees",
        "link": "http://arxiv.org/abs/2405.15454v1",
        "abstract": "The increasing prevalence of Large Language Models (LMs) in critical\napplications highlights the need for controlled language generation strategies\nthat are not only computationally efficient but that also enjoy performance\nguarantees. To achieve this, we use a common model of concept semantics as\nlinearly represented in an LM's latent space. In particular, we take the view\nthat natural language generation traces a trajectory in this continuous\nsemantic space, realized by the language model's hidden activations. This view\npermits a control-theoretic treatment of text generation in latent space, in\nwhich we propose a lightweight, gradient-free intervention that dynamically\nsteers trajectories away from regions corresponding to undesired meanings.\nCrucially, we show that this intervention, which we compute in closed form, is\nguaranteed (in probability) to steer the output into the allowed region.\nFinally, we demonstrate on a toxicity avoidance objective that the intervention\nsteers language away from undesired content while maintaining text quality.",
        "subjects": [
            "cs.CL",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Emily Cheng",
            "Marco Baroni",
            "Carmen Amo Alonso"
        ],
        "published": "2024-05-24T11:30:44Z"
    },
    {
        "title": "Benchmarking Pre-trained Large Language Models' Potential Across Urdu\n  NLP tasks",
        "link": "http://arxiv.org/abs/2405.15453v1",
        "abstract": "Large Language Models (LLMs) pre-trained on multilingual data have\nrevolutionized natural language processing research, by transitioning from\nlanguages and task specific model pipelines to a single model adapted on a\nvariety of tasks. However majority of existing multilingual NLP benchmarks for\nLLMs provide evaluation data in only few languages with little linguistic\ndiversity. In addition these benchmarks lack quality assessment against the\nrespective state-of the art models. This study presents an in-depth examination\nof prominent LLMs; GPT-3.5-turbo, Llama2-7B-Chat, Bloomz 7B1 and Bloomz 3B,\nacross 14 tasks using 15 Urdu datasets, in a zero-shot setting, and their\nperformance against state-of-the-art (SOTA) models, has been compared and\nanalysed. Our experiments show that SOTA models surpass all the encoder-decoder\npre-trained language models in all Urdu NLP tasks with zero-shot learning. Our\nresults further show that LLMs with fewer parameters, but more language\nspecific data in the base model perform better than larger computational\nmodels, but low language data.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "I.2.7"
        ],
        "authors": [
            "Munief Hassan Tahir",
            "Sana Shams",
            "Layba Fiaz",
            "Farah Adeeba",
            "Sarmad Hussain"
        ],
        "published": "2024-05-24T11:30:37Z"
    },
    {
        "title": "Leveraging Logical Rules in Knowledge Editing: A Cherry on the Top",
        "link": "http://arxiv.org/abs/2405.15452v1",
        "abstract": "Multi-hop Question Answering (MQA) under knowledge editing (KE) is a key\nchallenge in Large Language Models (LLMs). While best-performing solutions in\nthis domain use a plan and solve paradigm to split a question into\nsub-questions followed by response generation, we claim that this approach is\nsub-optimal as it fails for hard to decompose questions, and it does not\nexplicitly cater to correlated knowledge updates resulting as a consequence of\nknowledge edits. This has a detrimental impact on the overall consistency of\nthe updated knowledge. To address these issues, in this paper, we propose a\nnovel framework named RULE-KE, i.e., RULE based Knowledge Editing, which is a\ncherry on the top for augmenting the performance of all existing MQA methods\nunder KE. Specifically, RULE-KE leverages rule discovery to discover a set of\nlogical rules. Then, it uses these discovered rules to update knowledge about\nfacts highly correlated with the edit. Experimental evaluation using existing\nand newly curated datasets (i.e., RKE-EVAL) shows that RULE-KE helps augment\nboth performances of parameter-based and memory-based solutions up to 92% and\n112.9%, respectively.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Keyuan Cheng",
            "Muhammad Asif Ali",
            "Shu Yang",
            "Gang Ling",
            "Yuxuan Zhai",
            "Haoyang Fei",
            "Ke Xu",
            "Lu Yu",
            "Lijie Hu",
            "Di Wang"
        ],
        "published": "2024-05-24T11:30:00Z"
    },
    {
        "title": "Self-distilled Dynamic Fusion Network for Language-based Fashion\n  Retrieval",
        "link": "http://arxiv.org/abs/2405.15451v1",
        "abstract": "In the domain of language-based fashion image retrieval, pinpointing the\ndesired fashion item using both a reference image and its accompanying textual\ndescription is an intriguing challenge. Existing approaches lean heavily on\nstatic fusion techniques, intertwining image and text. Despite their\ncommendable advancements, these approaches are still limited by a deficiency in\nflexibility. In response, we propose a Self-distilled Dynamic Fusion Network to\ncompose the multi-granularity features dynamically by considering the\nconsistency of routing path and modality-specific information simultaneously.\nTwo new modules are included in our proposed method: (1) Dynamic Fusion Network\nwith Modality Specific Routers. The dynamic network enables a flexible\ndetermination of the routing for each reference image and modification text,\ntaking into account their distinct semantics and distributions. (2) Self Path\nDistillation Loss. A stable path decision for queries benefits the optimization\nof feature extraction as well as routing, and we approach this by progressively\nrefine the path decision with previous path information. Extensive experiments\ndemonstrate the effectiveness of our proposed model compared to existing\nmethods.",
        "subjects": [
            "cs.CV",
            "cs.IR",
            "cs.MM"
        ],
        "authors": [
            "Yiming Wu",
            "Hangfei Li",
            "Fangfang Wang",
            "Yilong Zhang",
            "Ronghua Liang"
        ],
        "published": "2024-05-24T11:28:01Z"
    },
    {
        "title": "Faster and Better Quantum Software Testing through Specification\n  Reduction and Projective Measurements",
        "link": "http://arxiv.org/abs/2405.15450v1",
        "abstract": "Quantum computing promises polynomial and exponential speedups in many\ndomains, such as unstructured search and prime number factoring. However,\nquantum programs yield probabilistic outputs from exponentially growing\ndistributions and are vulnerable to quantum-specific faults. Existing quantum\nsoftware testing (QST) approaches treat quantum superpositions as classical\ndistributions. This leads to two major limitations when applied to quantum\nprograms: (1) an exponentially growing sample space distribution and (2)\nfailing to detect quantum-specific faults such as phase flips. To overcome\nthese limitations, we introduce a QST approach, which applies a reduction\nalgorithm to a quantum program specification. The reduced specification\nalleviates the limitations (1) by enabling faster sampling through quantum\nparallelism and (2) by performing projective measurements in the mixed Hadamard\nbasis. Our evaluation of 143 quantum programs across four categories\ndemonstrates significant improvements in test runtimes and fault detection with\nour reduction approach. Average test runtimes improved from 169.9s to 11.8s,\nwith notable enhancements in programs with large circuit depths (383.1s to\n33.4s) and large program specifications (464.8s to 7.7s). Furthermore, our\napproach increases mutation scores from 54.5% to 74.7%, effectively detecting\nphase flip faults that non-reduced specifications miss. These results underline\nour approach's importance to improve QST efficiency and effectiveness.",
        "subjects": [
            "cs.SE",
            "quant-ph"
        ],
        "authors": [
            "Noah H. Oldfield",
            "Christoph Laaber",
            "Tao Yue",
            "Shaukat Ali"
        ],
        "published": "2024-05-24T11:26:18Z"
    },
    {
        "title": "Faster $(Δ+ 1)$-Edge Coloring: Breaking the $m \\sqrt{n}$ Time\n  Barrier",
        "link": "http://arxiv.org/abs/2405.15449v1",
        "abstract": "Vizing's theorem states that any $n$-vertex $m$-edge graph of maximum degree\n$\\Delta$ can be {\\em edge colored} using at most $\\Delta + 1$ different colors\n[Diskret.~Analiz, '64]. Vizing's original proof is algorithmic and shows that\nsuch an edge coloring can be found in $\\tilde{O}(mn)$ time. This was\nsubsequently improved to $\\tilde O(m\\sqrt{n})$, independently by Arjomandi\n[1982] and by Gabow et al.~[1985].\n  In this paper we present an algorithm that computes such an edge coloring in\n$\\tilde O(mn^{1/3})$ time, giving the first polynomial improvement for this\nfundamental problem in over 40 years.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Sayan Bhattacharya",
            "Din Carmon",
            "Martín Costa",
            "Shay Solomon",
            "Tianyi Zhang"
        ],
        "published": "2024-05-24T11:25:45Z"
    },
    {
        "title": "A global approach for the redefinition of higher-order flexibility and\n  rigidity",
        "link": "http://arxiv.org/abs/2405.15447v1",
        "abstract": "The famous example of the double-Watt mechanism given by Connelly and\nServatius raises some problems concerning the classical definitions of\nhigher-order flexibility and rigidity, respectively, as they attest the cusp\nconfiguration of the mechanism a third-order rigidity, which conflicts with its\ncontinuous flexion. Some attempts were done to resolve the dilemma but they\ncould not settle the problem. As cusp mechanisms demonstrate the basic\nshortcoming of any local mobility analysis using higher-order constraints, we\npresent a global approach inspired by Sabitov's finite algorithm for testing\nthe bendability of a polyhedron, which allows us (a) to compute iteratively\nconfigurations with a higher-order flexion and (b) to come up with a proper\nredefinition of higher-order flexibility and rigidity. We also give algorithms\nfor computing the flexion orders as well as the associated flexes. The\npresented approach is demonstrated on several examples (double-Watt mechanisms\nand Tarnai's Leonardo structure). Moreover, we determine all configurations of\na given 3-RPR manipulator with a third-order flexion and present a\ncorresponding joint-bar framework of flexion order 23.",
        "subjects": [
            "math.AG",
            "cs.RO"
        ],
        "authors": [
            "Georg Nawratil"
        ],
        "published": "2024-05-24T11:23:30Z"
    },
    {
        "title": "Mind the Gap: A Causal Perspective on Bias Amplification in Prediction &\n  Decision-Making",
        "link": "http://arxiv.org/abs/2405.15446v1",
        "abstract": "Investigating fairness and equity of automated systems has become a critical\nfield of inquiry. Most of the literature in fair machine learning focuses on\ndefining and achieving fairness criteria in the context of prediction, while\nnot explicitly focusing on how these predictions may be used later on in the\npipeline. For instance, if commonly used criteria, such as independence or\nsufficiency, are satisfied for a prediction score $S$ used for binary\nclassification, they need not be satisfied after an application of a simple\nthresholding operation on $S$ (as commonly used in practice). In this paper, we\ntake an important step to address this issue in numerous statistical and causal\nnotions of fairness. We introduce the notion of a margin complement, which\nmeasures how much a prediction score $S$ changes due to a thresholding\noperation. We then demonstrate that the marginal difference in the optimal 0/1\npredictor $\\widehat Y$ between groups, written $P(\\hat y \\mid x_1) - P(\\hat y\n\\mid x_0)$, can be causally decomposed into the influences of $X$ on the\n$L_2$-optimal prediction score $S$ and the influences of $X$ on the margin\ncomplement $M$, along different causal pathways (direct, indirect, spurious).\nWe then show that under suitable causal assumptions, the influences of $X$ on\nthe prediction score $S$ are equal to the influences of $X$ on the true outcome\n$Y$. This yields a new decomposition of the disparity in the predictor\n$\\widehat Y$ that allows us to disentangle causal differences inherited from\nthe true outcome $Y$ that exists in the real world vs. those coming from the\noptimization procedure itself. This observation highlights the need for more\nregulatory oversight due to the potential for bias amplification, and to\naddress this issue we introduce new notions of weak and strong business\nnecessity, together with an algorithm for assessing whether these notions are\nsatisfied.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Drago Plecko",
            "Elias Bareinboim"
        ],
        "published": "2024-05-24T11:22:19Z"
    },
    {
        "title": "HyperInterval: Hypernetwork approach to training weight interval regions\n  in continual learning",
        "link": "http://arxiv.org/abs/2405.15444v1",
        "abstract": "Recently, a new Continual Learning (CL) paradigm was presented to control\ncatastrophic forgetting, called Interval Continual Learning (InterContiNet),\nwhich relies on enforcing interval constraints on the neural network parameter\nspace. Unfortunately, InterContiNet training is challenging due to the high\ndimensionality of the weight space, making intervals difficult to manage. To\naddress this issue, we introduce HyperInterval, a technique that employs\ninterval arithmetic within the embedding space and utilizes a hypernetwork to\nmap these intervals to the target network parameter space. We train interval\nembeddings for consecutive tasks and train a hypernetwork to transform these\nembeddings into weights of the target network. An embedding for a given task is\ntrained along with the hypernetwork, preserving the response of the target\nnetwork for the previous task embeddings. Interval arithmetic works with a more\nmanageable, lower-dimensional embedding space rather than directly preparing\nintervals in a high-dimensional weight space. Our model allows faster and more\nefficient training. Furthermore, HyperInterval maintains the guarantee of not\nforgetting. At the end of training, we can choose one universal embedding to\nproduce a single network dedicated to all tasks. In such a framework,\nhypernetwork is used only for training and can be seen as a meta-trainer.\nHyperInterval obtains significantly better results than InterContiNet and gives\nSOTA results on several benchmarks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Patryk Krukowski",
            "Anna Bielawska",
            "Kamil Książek",
            "Paweł Wawrzyński",
            "Paweł Batorski",
            "Przemysław Spurek"
        ],
        "published": "2024-05-24T11:20:41Z"
    },
    {
        "title": "Fairness-Accuracy Trade-Offs: A Causal Perspective",
        "link": "http://arxiv.org/abs/2405.15443v1",
        "abstract": "Systems based on machine learning may exhibit discriminatory behavior based\non sensitive characteristics such as gender, sex, religion, or race. In light\nof this, various notions of fairness and methods to quantify discrimination\nwere proposed, leading to the development of numerous approaches for\nconstructing fair predictors. At the same time, imposing fairness constraints\nmay decrease the utility of the decision-maker, highlighting a tension between\nfairness and utility. This tension is also recognized in legal frameworks, for\ninstance in the disparate impact doctrine of Title VII of the Civil Rights Act\nof 1964 -- in which specific attention is given to considerations of business\nnecessity -- possibly allowing the usage of proxy variables associated with the\nsensitive attribute in case a high-enough utility cannot be achieved without\nthem. In this work, we analyze the tension between fairness and accuracy from a\ncausal lens for the first time. We introduce the notion of a path-specific\nexcess loss (PSEL) that captures how much the predictor's loss increases when a\ncausal fairness constraint is enforced. We then show that the total excess loss\n(TEL), defined as the difference between the loss of predictor fair along all\ncausal pathways vs. an unconstrained predictor, can be decomposed into a sum of\nmore local PSELs. At the same time, enforcing a causal constraint often reduces\nthe disparity between demographic groups. Thus, we introduce a quantity that\nsummarizes the fairness-utility trade-off, called the causal fairness/utility\nratio, defined as the ratio of the reduction in discrimination vs. the excess\nloss from constraining a causal pathway. This quantity is suitable for\ncomparing the fairness-utility trade-off across causal pathways. Finally, as\nour approach requires causally-constrained fair predictors, we introduce a new\nneural approach for causally-constrained fair learning.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Drago Plecko",
            "Elias Bareinboim"
        ],
        "published": "2024-05-24T11:19:52Z"
    },
    {
        "title": "Towards Precision Healthcare: Robust Fusion of Time Series and Image\n  Data",
        "link": "http://arxiv.org/abs/2405.15442v1",
        "abstract": "With the increasing availability of diverse data types, particularly images\nand time series data from medical experiments, there is a growing demand for\ntechniques designed to combine various modalities of data effectively. Our\nmotivation comes from the important areas of predicting mortality and\nphenotyping where using different modalities of data could significantly\nimprove our ability to predict. To tackle this challenge, we introduce a new\nmethod that uses two separate encoders, one for each type of data, allowing the\nmodel to understand complex patterns in both visual and time-based information.\nApart from the technical challenges, our goal is to make the predictive model\nmore robust in noisy conditions and perform better than current methods. We\nalso deal with imbalanced datasets and use an uncertainty loss function,\nyielding improved results while simultaneously providing a principled means of\nmodeling uncertainty. Additionally, we include attention mechanisms to fuse\ndifferent modalities, allowing the model to focus on what's important for each\ntask. We tested our approach using the comprehensive multimodal MIMIC dataset,\ncombining MIMIC-IV and MIMIC-CXR datasets. Our experiments show that our method\nis effective in improving multimodal deep learning for clinical applications.\nThe code will be made available online.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Ali Rasekh",
            "Reza Heidari",
            "Amir Hosein Haji Mohammad Rezaie",
            "Parsa Sharifi Sedeh",
            "Zahra Ahmadi",
            "Prasenjit Mitra",
            "Wolfgang Nejdl"
        ],
        "published": "2024-05-24T11:18:13Z"
    },
    {
        "title": "Statistical and Computational Guarantees of Kernel Max-Sliced\n  Wasserstein Distances",
        "link": "http://arxiv.org/abs/2405.15441v1",
        "abstract": "Optimal transport has been very successful for various machine learning\ntasks; however, it is known to suffer from the curse of dimensionality. Hence,\ndimensionality reduction is desirable when applied to high-dimensional data\nwith low-dimensional structures. The kernel max-sliced (KMS) Wasserstein\ndistance is developed for this purpose by finding an optimal nonlinear mapping\nthat reduces data into $1$ dimensions before computing the Wasserstein\ndistance. However, its theoretical properties have not yet been fully\ndeveloped. In this paper, we provide sharp finite-sample guarantees under\nmilder technical assumptions compared with state-of-the-art for the KMS\n$p$-Wasserstein distance between two empirical distributions with $n$ samples\nfor general $p\\in[1,\\infty)$. Algorithm-wise, we show that computing the KMS\n$2$-Wasserstein distance is NP-hard, and then we further propose a semidefinite\nrelaxation (SDR) formulation (which can be solved efficiently in polynomial\ntime) and provide a relaxation gap for the SDP solution. We provide numerical\nexamples to demonstrate the good performance of our scheme for high-dimensional\ntwo-sample testing.",
        "subjects": [
            "stat.ML",
            "cs.CC",
            "cs.LG"
        ],
        "authors": [
            "Jie Wang",
            "March Boedihardjo",
            "Yao Xie"
        ],
        "published": "2024-05-24T11:14:56Z"
    },
    {
        "title": "Text-guided 3D Human Motion Generation with Keyframe-based Parallel Skip\n  Transformer",
        "link": "http://arxiv.org/abs/2405.15439v1",
        "abstract": "Text-driven human motion generation is an emerging task in animation and\nhumanoid robot design. Existing algorithms directly generate the full sequence\nwhich is computationally expensive and prone to errors as it does not pay\nspecial attention to key poses, a process that has been the cornerstone of\nanimation for decades. We propose KeyMotion, that generates plausible human\nmotion sequences corresponding to input text by first generating keyframes\nfollowed by in-filling. We use a Variational Autoencoder (VAE) with\nKullback-Leibler regularization to project the keyframes into a latent space to\nreduce dimensionality and further accelerate the subsequent diffusion process.\nFor the reverse diffusion, we propose a novel Parallel Skip Transformer that\nperforms cross-modal attention between the keyframe latents and text condition.\nTo complete the motion sequence, we propose a text-guided Transformer designed\nto perform motion-in-filling, ensuring the preservation of both fidelity and\nadherence to the physical constraints of human motion. Experiments show that\nour method achieves state-of-theart results on the HumanML3D dataset\noutperforming others on all R-precision metrics and MultiModal Distance.\nKeyMotion also achieves competitive performance on the KIT dataset, achieving\nthe best results on Top3 R-precision, FID, and Diversity metrics.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Zichen Geng",
            "Caren Han",
            "Zeeshan Hayder",
            "Jian Liu",
            "Mubarak Shah",
            "Ajmal Mian"
        ],
        "published": "2024-05-24T11:12:37Z"
    },
    {
        "title": "Comparing remote sensing-based forest biomass mapping approaches using\n  new forest inventory plots in contrasting forests in northeastern and\n  southwestern China",
        "link": "http://arxiv.org/abs/2405.15438v1",
        "abstract": "Large-scale high spatial resolution aboveground biomass (AGB) maps play a\ncrucial role in determining forest carbon stocks and how they are changing,\nwhich is instrumental in understanding the global carbon cycle, and\nimplementing policy to mitigate climate change. The advent of the new\nspace-borne LiDAR sensor, NASA's GEDI instrument, provides unparalleled\npossibilities for the accurate and unbiased estimation of forest AGB at high\nresolution, particularly in dense and tall forests, where Synthetic Aperture\nRadar (SAR) and passive optical data exhibit saturation. However, GEDI is a\nsampling instrument, collecting dispersed footprints, and its data must be\ncombined with that from other continuous cover satellites to create\nhigh-resolution maps, using local machine learning methods. In this study, we\ndeveloped local models to estimate forest AGB from GEDI L2A data, as the models\nused to create GEDI L4 AGB data incorporated minimal field data from China. We\nthen applied LightGBM and random forest regression to generate wall-to-wall AGB\nmaps at 25 m resolution, using extensive GEDI footprints as well as Sentinel-1\ndata, ALOS-2 PALSAR-2 and Sentinel-2 optical data. Through a 5-fold\ncross-validation, LightGBM demonstrated a slightly better performance than\nRandom Forest across two contrasting regions. However, in both regions, the\ncomputation speed of LightGBM is substantially faster than that of the random\nforest model, requiring roughly one-third of the time to compute on the same\nhardware. Through the validation against field data, the 25 m resolution AGB\nmaps generated using the local models developed in this study exhibited higher\naccuracy compared to the GEDI L4B AGB data. We found in both regions an\nincrease in error as slope increased. The trained models were tested on nearby\nbut different regions and exhibited good performance.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "eess.IV"
        ],
        "authors": [
            "Wenquan Dong",
            "Edward T. A. Mitchard",
            "Yuwei Chen",
            "Man Chen",
            "Congfeng Cao",
            "Peilun Hu",
            "Cong Xu",
            "Steven Hancock"
        ],
        "published": "2024-05-24T11:10:58Z"
    },
    {
        "title": "Learning about Data, Algorithms, and Algorithmic Justice on TikTok in\n  Personally Meaningful Ways",
        "link": "http://arxiv.org/abs/2405.15437v1",
        "abstract": "TikTok, a popular short video sharing application, emerged as the dominant\nsocial media platform for young people, with a pronounced influence on how\nyoung women and people of color interact online. The application has become a\nglobal space for youth to connect with each other, offering not only\nentertainment but also opportunities to engage with artificial\nintelligence/machine learning (AI/ML)-driven recommendations and create content\nusing AI/M-powered tools, such as generative AI filters. This provides\nopportunities for youth to explore and question the inner workings of these\nsystems, their implications, and even use them to advocate for causes they are\npassionate about. We present different perspectives on how youth may learn in\npersonally meaningful ways when engaging with TikTok. We discuss how youth\ninvestigate how TikTok works (considering data and algorithms), take into\naccount issues of ethics and algorithmic justice and use their understanding of\nthe platform to advocate for change.",
        "subjects": [
            "cs.CY",
            "K.3; K.4"
        ],
        "authors": [
            "Luis Morales-Navarro",
            "Yasmin B. Kafai",
            "Ha Nguyen",
            "Kayla DesPortes",
            "Ralph Vacca",
            "Camillia Matuk",
            "Megan Silander",
            "Anna Amato",
            "Peter Woods",
            "Francisco Castro",
            "Mia Shaw",
            "Selin Akgun",
            "Christine Greenhow",
            "Antero Garcia"
        ],
        "published": "2024-05-24T11:07:48Z"
    },
    {
        "title": "Hybrid Context Retrieval Augmented Generation Pipeline: LLM-Augmented\n  Knowledge Graphs and Vector Database for Accreditation Reporting Assistance",
        "link": "http://arxiv.org/abs/2405.15436v1",
        "abstract": "In higher education, accreditation is a quality assurance process, where an\ninstitution demonstrates a commitment to delivering high quality programs and\nservices to their students. For business schools nationally and internationally\nthe Association to Advance Collegiate Schools of Business (AACSB) accreditation\nis the gold standard. For a business school to receive and subsequently\nmaintain accreditation, the school must undertake a rigorous, time consuming\nreporting and peer review process, to demonstrate alignment with the AACSB\nStandards. For this project we create a hybrid context retrieval augmented\ngeneration pipeline that can assist in the documentation alignment and\nreporting process necessary for accreditation. We implement both a vector\ndatabase and knowledge graph, as knowledge stores containing both institutional\ndata and AACSB Standard data. The output of the pipeline can be used by\ninstitution stakeholders to build their accreditation report, dually grounded\nby the context from the knowledge stores. To develop our knowledge graphs we\nutilized both a manual construction process as well as an LLM Augmented\nKnowledge Graph approach. We evaluated the pipeline using the RAGAs framework\nand observed optimal performance on answer relevancy and answer correctness\nmetrics.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "authors": [
            "Candace Edwards"
        ],
        "published": "2024-05-24T11:05:45Z"
    },
    {
        "title": "Biometrics and Behavioral Modelling for Detecting Distractions in Online\n  Learning",
        "link": "http://arxiv.org/abs/2405.15434v1",
        "abstract": "In this article, we explore computer vision approaches to detect abnormal\nhead pose during e-learning sessions and we introduce a study on the effects of\nmobile phone usage during these sessions. We utilize behavioral data collected\nfrom 120 learners monitored while participating in a MOOC learning sessions.\nOur study focuses on the influence of phone-usage events on behavior and\nphysiological responses, specifically attention, heart rate, and meditation,\nbefore, during, and after phone usage. Additionally, we propose an approach for\nestimating head pose events using images taken by the webcam during the MOOC\nlearning sessions to detect phone-usage events. Our hypothesis suggests that\nhead posture undergoes significant changes when learners interact with a mobile\nphone, contrasting with the typical behavior seen when learners face a computer\nduring e-learning sessions. We propose an approach designed to detect\ndeviations in head posture from the average observed during a learner's\nsession, operating as a semi-supervised method. This system flags events\nindicating alterations in head posture for subsequent human review and\nselection of mobile phone usage occurrences with a sensitivity over 90%.",
        "subjects": [
            "cs.CV",
            "cs.HC",
            "cs.LG"
        ],
        "authors": [
            "Álvaro Becerra",
            "Javier Irigoyen",
            "Roberto Daza",
            "Ruth Cobos",
            "Aythami Morales",
            "Julian Fierrez",
            "Mutlu Cukurova"
        ],
        "published": "2024-05-24T11:02:55Z"
    },
    {
        "title": "Throughput Requirements for RAN Functional Splits in 3D-Networks",
        "link": "http://arxiv.org/abs/2405.15432v1",
        "abstract": "The rapid growth of non-terrestrial communication necessitates its\nintegration with existing terrestrial networks, as highlighted in 3GPP Releases\n16 and 17. This paper analyses the concept of functional splits in 3D-Networks.\nTo manage this complex structure effectively, the adoption of a Radio Access\nNetwork (RAN) architecture with Functional Split (FS) offers advantages in\nflexibility, scalability, and cost-efficiency. RAN achieves this by\ndisaggregating functionalities into three separate units. Analogous to the\nterrestrial network approach, 3GPP is extending this concept to non-terrestrial\nplatforms as well. This work presents a general analysis of the requested\nFronthaul (FH) data rate on feeder link between a non-terrestrial platform and\nthe ground-station. Each split option is a trade-of between FH data rate and\nthe respected complexity. Since flying nodes face more limitations regarding\npower consumption and complexity on board in comparison to terrestrial ones, we\nare investigating the split options between lower and higher physical layer.",
        "subjects": [
            "eess.SP",
            "cs.NI"
        ],
        "authors": [
            "MohammadAmin Vakilifard",
            "Tim Düe",
            "Mohammad Rihan",
            "Maik Röper",
            "Dirk Wübben",
            "Carsten Bockelmann",
            "Armin Dekorsy"
        ],
        "published": "2024-05-24T10:58:20Z"
    },
    {
        "title": "Counterfactual Explanations for Linear Optimization",
        "link": "http://arxiv.org/abs/2405.15431v1",
        "abstract": "The concept of counterfactual explanations (CE) has emerged as one of the\nimportant concepts to understand the inner workings of complex AI systems. In\nthis paper, we translate the idea of CEs to linear optimization and propose,\nmotivate, and analyze three different types of CEs: strong, weak, and relative.\nWhile deriving strong and weak CEs appears to be computationally intractable,\nwe show that calculating relative CEs can be done efficiently. By detecting and\nexploiting the hidden convex structure of the optimization problem that arises\nin the latter case, we show that obtaining relative CEs can be done in the same\nmagnitude of time as solving the original linear optimization problem. This is\nconfirmed by an extensive numerical experiment study on the NETLIB library.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "authors": [
            "Jannis Kurtz",
            "Ş. İlker Birbil",
            "Dick den Hertog"
        ],
        "published": "2024-05-24T10:58:00Z"
    },
    {
        "title": "Counterexample-Guided Repair of Reinforcement Learning Systems Using\n  Safety Critics",
        "link": "http://arxiv.org/abs/2405.15430v1",
        "abstract": "Naively trained Deep Reinforcement Learning agents may fail to satisfy vital\nsafety constraints. To avoid costly retraining, we may desire to repair a\npreviously trained reinforcement learning agent to obviate unsafe behaviour. We\ndevise a counterexample-guided repair algorithm for repairing reinforcement\nlearning systems leveraging safety critics. The algorithm jointly repairs a\nreinforcement learning agent and a safety critic using gradient-based\nconstrained optimisation.",
        "subjects": [
            "cs.LG",
            "cs.LO"
        ],
        "authors": [
            "David Boetius",
            "Stefan Leue"
        ],
        "published": "2024-05-24T10:56:51Z"
    },
    {
        "title": "E(n) Equivariant Topological Neural Networks",
        "link": "http://arxiv.org/abs/2405.15429v1",
        "abstract": "Graph neural networks excel at modeling pairwise interactions, but they\ncannot flexibly accommodate higher-order interactions and features. Topological\ndeep learning (TDL) has emerged recently as a promising tool for addressing\nthis issue. TDL enables the principled modeling of arbitrary multi-way,\nhierarchical higher-order interactions by operating on combinatorial\ntopological spaces, such as simplicial or cell complexes, instead of graphs.\nHowever, little is known about how to leverage geometric features such as\npositions and velocities for TDL. This paper introduces E(n)-Equivariant\nTopological Neural Networks (ETNNs), which are E(n)-equivariant message-passing\nnetworks operating on combinatorial complexes, formal objects unifying graphs,\nhypergraphs, simplicial, path, and cell complexes. ETNNs incorporate geometric\nnode features while respecting rotation and translation equivariance. Moreover,\nETNNs are natively ready for settings with heterogeneous interactions. We\nprovide a theoretical analysis to show the improved expressiveness of ETNNs\nover architectures for geometric graphs. We also show how several E(n)\nequivariant variants of TDL models can be directly derived from our framework.\nThe broad applicability of ETNNs is demonstrated through two tasks of vastly\ndifferent nature: i) molecular property prediction on the QM9 benchmark and ii)\nland-use regression for hyper-local estimation of air pollution with\nmulti-resolution irregular geospatial data. The experiment results indicate\nthat ETNNs are an effective tool for learning from diverse types of richly\nstructured data, highlighting the benefits of principled geometric inductive\nbias.",
        "subjects": [
            "cs.LG",
            "cs.NE"
        ],
        "authors": [
            "Claudio Battiloro",
            "Ege Karaismailoğlu",
            "Mauricio Tec",
            "George Dasoulas",
            "Michelle Audirac",
            "Francesca Dominici"
        ],
        "published": "2024-05-24T10:55:38Z"
    },
    {
        "title": "Enhancing Pollinator Conservation towards Agriculture 4.0: Monitoring of\n  Bees through Object Recognition",
        "link": "http://arxiv.org/abs/2405.15428v1",
        "abstract": "In an era of rapid climate change and its adverse effects on food production,\ntechnological intervention to monitor pollinator conservation is of paramount\nimportance for environmental monitoring and conservation for global food\nsecurity. The survival of the human species depends on the conservation of\npollinators. This article explores the use of Computer Vision and Object\nRecognition to autonomously track and report bee behaviour from images. A novel\ndataset of 9664 images containing bees is extracted from video streams and\nannotated with bounding boxes. With training, validation and testing sets\n(6722, 1915, and 997 images, respectively), the results of the COCO-based YOLO\nmodel fine-tuning approaches show that YOLOv5m is the most effective approach\nin terms of recognition accuracy. However, YOLOv5s was shown to be the most\noptimal for real-time bee detection with an average processing and inference\ntime of 5.1ms per video frame at the cost of slightly lower ability. The\ntrained model is then packaged within an explainable AI interface, which\nconverts detection events into timestamped reports and charts, with the aim of\nfacilitating use by non-technical users such as expert stakeholders from the\napiculture industry towards informing responsible consumption and production.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Ajay John Alex",
            "Chloe M. Barnes",
            "Pedro Machado",
            "Isibor Ihianle",
            "Gábor Markó",
            "Martin Bencsik",
            "Jordan J. Bird"
        ],
        "published": "2024-05-24T10:45:24Z"
    },
    {
        "title": "AuthNet: Neural Network with Integrated Authentication Logic",
        "link": "http://arxiv.org/abs/2405.15426v1",
        "abstract": "Model stealing, i.e., unauthorized access and exfiltration of deep learning\nmodels, has become one of the major threats. Proprietary models may be\nprotected by access controls and encryption. However, in reality, these\nmeasures can be compromised due to system breaches, query-based model\nextraction or a disgruntled insider. Security hardening of neural networks is\nalso suffering from limits, for example, model watermarking is passive, cannot\nprevent the occurrence of piracy and not robust against transformations. To\nthis end, we propose a native authentication mechanism, called AuthNet, which\nintegrates authentication logic as part of the model without any additional\nstructures. Our key insight is to reuse redundant neurons with low activation\nand embed authentication bits in an intermediate layer, called a gate layer.\nThen, AuthNet fine-tunes the layers after the gate layer to embed\nauthentication logic so that only inputs with special secret key can trigger\nthe correct logic of AuthNet. It exhibits two intuitive advantages. It provides\nthe last line of defense, i.e., even being exfiltrated, the model is not usable\nas the adversary cannot generate valid inputs without the key. Moreover, the\nauthentication logic is difficult to inspect and identify given millions or\nbillions of neurons in the model. We theoretically demonstrate the high\nsensitivity of AuthNet to the secret key and its high confusion for\nunauthorized samples. AuthNet is compatible with any convolutional neural\nnetwork, where our extensive evaluations show that AuthNet successfully\nachieves the goal in rejecting unauthenticated users (whose average accuracy\ndrops to 22.03%) with a trivial accuracy decrease (1.18% on average) for\nlegitimate users, and is robust against model transformation and adaptive\nattacks.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Yuling Cai",
            "Fan Xiang",
            "Guozhu Meng",
            "Yinzhi Cao",
            "Kai Chen"
        ],
        "published": "2024-05-24T10:44:22Z"
    },
    {
        "title": "Volumetric Primitives for Modeling and Rendering Scattering and Emissive\n  Media",
        "link": "http://arxiv.org/abs/2405.15425v1",
        "abstract": "We propose a volumetric representation based on primitives to model\nscattering and emissive media. Accurate scene representations enabling\nefficient rendering are essential for many computer graphics applications.\nGeneral and unified representations that can handle surface and volume-based\nrepresentations simultaneously, allowing for physically accurate modeling,\nremain a research challenge. Inspired by recent methods for scene\nreconstruction that leverage mixtures of 3D Gaussians to model radiance fields,\nwe formalize and generalize the modeling of scattering and emissive media using\nmixtures of simple kernel-based volumetric primitives. We introduce closed-form\nsolutions for transmittance and free-flight distance sampling for 3D Gaussian\nkernels, and propose several optimizations to use our method efficiently within\nany off-the-shelf volumetric path tracer by leveraging ray tracing for\nefficiently querying the medium. We demonstrate our method as an alternative to\nother forms of volume modeling (e.g. voxel grid-based representations) for\nforward and inverse rendering of scattering media. Furthermore, we adapt our\nmethod to the problem of radiance field optimization and rendering, and\ndemonstrate comparable performance to the state of the art, while providing\nadditional flexibility in terms of performance and usability.",
        "subjects": [
            "cs.GR",
            "cs.CV",
            "I.3.2; I.3.3; I.3.6; I.3.5; I.3.7"
        ],
        "authors": [
            "Jorge Condor",
            "Sebastien Speierer",
            "Lukas Bode",
            "Aljaz Bozic",
            "Simon Green",
            "Piotr Didyk",
            "Adrian Jarabo"
        ],
        "published": "2024-05-24T10:42:05Z"
    },
    {
        "title": "Smoothed Online Classification can be Harder than Batch Classification",
        "link": "http://arxiv.org/abs/2405.15424v1",
        "abstract": "We study online classification under smoothed adversaries. In this setting,\nat each time point, the adversary draws an example from a distribution that has\na bounded density with respect to a fixed base measure, which is known apriori\nto the learner. For binary classification and scalar-valued regression,\nprevious works \\citep{haghtalab2020smoothed, block2022smoothed} have shown that\nsmoothed online learning is as easy as learning in the iid batch setting under\nPAC model. However, we show that smoothed online classification can be harder\nthan the iid batch classification when the label space is unbounded. In\nparticular, we construct a hypothesis class that is learnable in the iid batch\nsetting under the PAC model but is not learnable under the smoothed online\nmodel. Finally, we identify a condition that ensures that the PAC learnability\nof a hypothesis class is sufficient for its smoothed online learnability.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Vinod Raman",
            "Unique Subedi",
            "Ambuj Tewari"
        ],
        "published": "2024-05-24T10:37:39Z"
    },
    {
        "title": "Lost in the Averages: A New Specific Setup to Evaluate Membership\n  Inference Attacks Against Machine Learning Models",
        "link": "http://arxiv.org/abs/2405.15423v1",
        "abstract": "Membership Inference Attacks (MIAs) are widely used to evaluate the\npropensity of a machine learning (ML) model to memorize an individual record\nand the privacy risk releasing the model poses. MIAs are commonly evaluated\nsimilarly to ML models: the MIA is performed on a test set of models trained on\ndatasets unseen during training, which are sampled from a larger pool,\n$D_{eval}$. The MIA is evaluated across all datasets in this test set, and is\nthus evaluated across the distribution of samples from $D_{eval}$. While this\nwas a natural extension of ML evaluation to MIAs, recent work has shown that a\nrecord's risk heavily depends on its specific dataset. For example, outliers\nare particularly vulnerable, yet an outlier in one dataset may not be one in\nanother. The sources of randomness currently used to evaluate MIAs may thus\nlead to inaccurate individual privacy risk estimates. We propose a new,\nspecific evaluation setup for MIAs against ML models, using weight\ninitialization as the sole source of randomness. This allows us to accurately\nevaluate the risk associated with the release of a model trained on a specific\ndataset. Using SOTA MIAs, we empirically show that the risk estimates given by\nthe current setup lead to many records being misclassified as low risk. We\nderive theoretical results which, combined with empirical evidence, suggest\nthat the risk calculated in the current setup is an average of the risks\nspecific to each sampled dataset, validating our use of weight initialization\nas the only source of randomness. Finally, we consider an MIA with a stronger\nadversary leveraging information about the target dataset to infer membership.\nTaken together, our results show that current MIA evaluation is averaging the\nrisk across datasets leading to inaccurate risk estimates, and the risk posed\nby attacks leveraging information about the target dataset to be potentially\nunderestimated.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "authors": [
            "Florent Guépin",
            "Nataša Krčo",
            "Matthieu Meeus",
            "Yves-Alexandre de Montjoye"
        ],
        "published": "2024-05-24T10:37:38Z"
    }
]