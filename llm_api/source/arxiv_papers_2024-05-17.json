[
    {
        "title": "Flexible Motion In-betweening with Diffusion Models",
        "link": "http://arxiv.org/abs/2405.11126v2",
        "abstract": "Motion in-betweening, a fundamental task in character animation, consists of\ngenerating motion sequences that plausibly interpolate user-provided keyframe\nconstraints. It has long been recognized as a labor-intensive and challenging\nprocess. We investigate the potential of diffusion models in generating diverse\nhuman motions guided by keyframes. Unlike previous inbetweening methods, we\npropose a simple unified model capable of generating precise and diverse\nmotions that conform to a flexible range of user-specified spatial constraints,\nas well as text conditioning. To this end, we propose Conditional Motion\nDiffusion In-betweening (CondMDI) which allows for arbitrary dense-or-sparse\nkeyframe placement and partial keyframe constraints while generating\nhigh-quality motions that are diverse and coherent with the given keyframes. We\nevaluate the performance of CondMDI on the text-conditioned HumanML3D dataset\nand demonstrate the versatility and efficacy of diffusion models for keyframe\nin-betweening. We further explore the use of guidance and imputation-based\napproaches for inference-time keyframing and compare CondMDI against these\nmethods.",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "cs.LG"
        ],
        "authors": [
            "Setareh Cohan",
            "Guy Tevet",
            "Daniele Reda",
            "Xue Bin Peng",
            "Michiel van de Panne"
        ],
        "published": "2024-05-17T23:55:51Z"
    },
    {
        "title": "A Reproducibility Study on Quantifying Language Similarity: The Impact\n  of Missing Values in the URIEL Knowledge Base",
        "link": "http://arxiv.org/abs/2405.11125v1",
        "abstract": "In the pursuit of supporting more languages around the world, tools that\ncharacterize properties of languages play a key role in expanding the existing\nmultilingual NLP research. In this study, we focus on a widely used typological\nknowledge base, URIEL, which aggregates linguistic information into numeric\nvectors. Specifically, we delve into the soundness and reproducibility of the\napproach taken by URIEL in quantifying language similarity. Our analysis\nreveals URIEL's ambiguity in calculating language distances and in handling\nmissing values. Moreover, we find that URIEL does not provide any information\nabout typological features for 31\\% of the languages it represents, undermining\nthe reliabilility of the database, particularly on low-resource languages. Our\nliterature review suggests URIEL and lang2vec are used in papers on diverse NLP\ntasks, which motivates us to rigorously verify the database as the\neffectiveness of these works depends on the reliability of the information the\ntool provides.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Hasti Toossi",
            "Guo Qing Huai",
            "Jinyu Liu",
            "Eric Khiu",
            "A. Seza Doğruöz",
            "En-Shiun Annie Lee"
        ],
        "published": "2024-05-17T23:53:48Z"
    },
    {
        "title": "AdaWaveNet: Adaptive Wavelet Network for Time Series Analysis",
        "link": "http://arxiv.org/abs/2405.11124v1",
        "abstract": "Time series data analysis is a critical component in various domains such as\nfinance, healthcare, and meteorology. Despite the progress in deep learning for\ntime series analysis, there remains a challenge in addressing the\nnon-stationary nature of time series data. Traditional models, which are built\non the assumption of constant statistical properties over time, often struggle\nto capture the temporal dynamics in realistic time series, resulting in bias\nand error in time series analysis. This paper introduces the Adaptive Wavelet\nNetwork (AdaWaveNet), a novel approach that employs Adaptive Wavelet\nTransformation for multi-scale analysis of non-stationary time series data.\nAdaWaveNet designed a lifting scheme-based wavelet decomposition and\nconstruction mechanism for adaptive and learnable wavelet transforms, which\noffers enhanced flexibility and robustness in analysis. We conduct extensive\nexperiments on 10 datasets across 3 different tasks, including forecasting,\nimputation, and a newly established super-resolution task. The evaluations\ndemonstrate the effectiveness of AdaWaveNet over existing methods in all three\ntasks, which illustrates its potential in various real-world applications.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Han Yu",
            "Peikun Guo",
            "Akane Sano"
        ],
        "published": "2024-05-17T23:52:33Z"
    },
    {
        "title": "A Construction of Interpolating Space Curves with Any Degree of\n  Geometric Continuity",
        "link": "http://arxiv.org/abs/2405.11123v1",
        "abstract": "This paper outlines a methodology for constructing a geometrically smooth\ninterpolatory curve in $\\mathbb{R}^d$ applicable to oriented and flattenable\npoints with $d\\ge 2$. The construction involves four essential components:\nlocal functions, blending functions, redistributing functions, and gluing\nfunctions. The resulting curve possesses favorable attributes, including $G^2$\ngeometric smoothness, locality, the absence of cusps, and no self-intersection.\nMoreover, the algorithm is adaptable to various scenarios, such as preserving\nconvexity, interpolating sharp corners, and ensuring sphere preservation. The\npaper substantiates the efficacy of the proposed method through the\npresentation of numerous numerical examples, offering a practical demonstration\nof its capabilities.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "31A05, 35J25, 30C60, 53A10"
        ],
        "authors": [
            "Tsung-Wei Hu",
            "Ming-Jun Lai"
        ],
        "published": "2024-05-17T23:32:14Z"
    },
    {
        "title": "COVID-19's Unequal Toll: An assessment of small business impact\n  disparities with respect to ethnorace in metropolitan areas in the US using\n  mobility data",
        "link": "http://arxiv.org/abs/2405.11121v1",
        "abstract": "Early in the pandemic, counties and states implemented a variety of\nnon-pharmacological interventions (NPIs) focused on mobility, such as national\nlockdowns or work-from-home strategies, as it became clear that restricting\nmovement was essential to containing the epidemic. Due to these restrictions,\nbusinesses were severely affected and in particular, small, urban restaurant\nbusinesses. In addition to that, COVID-19 has also amplified many of the\nsocioeconomic disparities and systemic racial inequities that exist in our\nsociety. The overarching objective of this study was to examine the changes in\nsmall urban restaurant visitation patterns following the COVID-19 pandemic and\nassociated mobility restrictions, as well as to uncover potential disparities\nacross different racial/ethnic groups in order to understand inequities in the\nimpact and recovery. Specifically, the two key objectives were: 1) to analyze\nthe overall changes in restaurant visitation patterns in US metropolitan areas\nduring the pandemic compared to a pre-pandemic baseline, and 2) to investigate\ndifferences in visitation pattern changes across Census Block Groups with\nmajority Asian, Black, Hispanic, White, and American Indian populations,\nidentifying any disproportionate effects. Using aggregated geolocated cell\nphone data from SafeGraph, we document the overall changes in small urban\nrestaurant businesses' visitation patterns with respect to racial composition\nat a granularity of Census Block Groups. Our results show clear indications of\nreduced visitation patterns after the pandemic, with slow recoveries. Via\nvisualizations and statistical analyses, we show that reductions in visitation\npatterns were the highest for small urban restaurant businesses in majority\nAsian neighborhoods.",
        "subjects": [
            "cs.CY",
            "physics.soc-ph"
        ],
        "authors": [
            "Saad Mohammad Abrar",
            "Kazi Tasnim Zinat",
            "Naman Awasthi",
            "Vanessa Frias-Martinez"
        ],
        "published": "2024-05-17T23:30:20Z"
    },
    {
        "title": "Latent State Estimation Helps UI Agents to Reason",
        "link": "http://arxiv.org/abs/2405.11120v1",
        "abstract": "A common problem for agents operating in real-world environments is that the\nresponse of an environment to their actions may be non-deterministic and\nobserved through noise. This renders environmental state and progress towards\ncompleting a task latent. Despite recent impressive demonstrations of LLM's\nreasoning abilities on various benchmarks, whether LLMs can build estimates of\nlatent state and leverage them for reasoning has not been explicitly studied.\nWe investigate this problem in the real-world domain of autonomous UI agents.\nWe establish that appropriately prompting LLMs in a zero-shot manner can be\nformally understood as forming point estimates of latent state in a textual\nspace. In the context of autonomous UI agents we then show that LLMs used in\nthis manner are more than $76\\%$ accurate at inferring various aspects of\nlatent state, such as performed (vs. commanded) actions and task progression.\nUsing both public and internal benchmarks and three reasoning methods\n(zero-shot, CoT-SC & ReAct), we show that LLM-powered agents that explicitly\nestimate and reason about latent state are able to successfully complete up to\n1.6x more tasks than those that do not.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "William E Bishop",
            "Alice Li",
            "Christopher Rawles",
            "Oriana Riva"
        ],
        "published": "2024-05-17T23:27:33Z"
    },
    {
        "title": "A Simulation-Optimization Framework for Developing Wind-Resilient AAM\n  Networks",
        "link": "http://arxiv.org/abs/2405.11118v1",
        "abstract": "Environmental factors pose a significant challenge to the operational\nefficiency and safety of advanced air mobility (AAM) networks. This paper\npresents a simulation-optimization framework that dynamically integrates wind\nvariability into AAM operations. We employ a nonlinear charging model within a\nmulti-vertiport environment to optimize fleet size and scheduling. Our\nframework assesses the impact of wind on operational parameters, providing\nstrategies to enhance the resilience of AAM ecosystems. The results demonstrate\nthat wind conditions exert significant influence on fleet size even for\nshort-distance flights, their impact on fleet size and energy requirements\nbecomes more pronounced over longer distances. Efficient management of fleet\nsize and charging policies, particularly for long-distance networks, is needed\nto accommodate the variability of wind conditions effectively.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Emin Burak Onat",
            "Shangqing Cao",
            "Raiyan Rizwan",
            "Xuan Jiang",
            "Mark Hansen",
            "Raja Sengupta",
            "Anjan Chakrabarty"
        ],
        "published": "2024-05-17T23:24:08Z"
    },
    {
        "title": "Dynamic Embeddings with Task-Oriented prompting",
        "link": "http://arxiv.org/abs/2405.11117v1",
        "abstract": "This paper introduces Dynamic Embeddings with Task-Oriented prompting\n(DETOT), a novel approach aimed at improving the adaptability and efficiency of\nmachine learning models by implementing a flexible embedding layer. Unlike\ntraditional static embeddings [14], DETOT dynamically adjusts embeddings based\non task-specific requirements and performance feedback, optimizing input data\nrepresentation for individual tasks [4]. This method enhances both accuracy and\ncomputational performance by tailoring the representation layer to meet the\nunique needs of each task. The structure of DETOT is detailed, highlighting its\ntask-specific adaptation, continuous feedback loop, and mechanisms for\npreventing overfitting. Empirical evaluations demonstrate its superiority over\nexisting methods.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Allmin Balloccu",
            "Jack Zhang"
        ],
        "published": "2024-05-17T23:18:15Z"
    },
    {
        "title": "StoryVerse: Towards Co-authoring Dynamic Plot with LLM-based Character\n  Simulation via Narrative Planning",
        "link": "http://dx.doi.org/10.1145/3649921.3656987",
        "abstract": "Automated plot generation for games enhances the player's experience by\nproviding rich and immersive narrative experience that adapts to the player's\nactions. Traditional approaches adopt a symbolic narrative planning method\nwhich limits the scale and complexity of the generated plot by requiring\nextensive knowledge engineering work. Recent advancements use Large Language\nModels (LLMs) to drive the behavior of virtual characters, allowing plots to\nemerge from interactions between characters and their environments. However,\nthe emergent nature of such decentralized plot generation makes it difficult\nfor authors to direct plot progression. We propose a novel plot creation\nworkflow that mediates between a writer's authorial intent and the emergent\nbehaviors from LLM-driven character simulation, through a novel authorial\nstructure called \"abstract acts\". The writers define high-level plot outlines\nthat are later transformed into concrete character action sequences via an\nLLM-based narrative planning process, based on the game world state. The\nprocess creates \"living stories\" that dynamically adapt to various game world\nstates, resulting in narratives co-created by the author, character simulation,\nand player. We present StoryVerse as a proof-of-concept system to demonstrate\nthis plot creation workflow. We showcase the versatility of our approach with\nexamples in different stories and game environments.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Yi Wang",
            "Qian Zhou",
            "David Ledo"
        ],
        "published": "2024-05-17T23:04:51Z"
    },
    {
        "title": "Advancements in Gravity Compensation and Control for the da Vinci\n  Surgical Robot",
        "link": "http://arxiv.org/abs/2405.11114v1",
        "abstract": "This research delves into the enhancement of control mechanisms for the da\nVinci Surgical System, focusing on the implementation of gravity compensation\nand refining the modeling of the master and patient side manipulators.\nLeveraging the Robot Operating System (ROS) the study aimed to fortify the\nprecision and stability of the robots movements essential for intricate\nsurgical procedures. Through rigorous parameter identification and the Euler\nLagrange approach the team successfully derived the necessary torque equations\nand established a robust mathematical model. Implementation of the actual robot\nand simulation in Gazebo highlighted the efficacy of the developed control\nstrategies facilitating accurate positioning and minimizing drift.\nAdditionally, the project extended its contributions by constructing a\ncomprehensive model for the patient side manipulator laying the groundwork for\nfuture research endeavors. This work signifies a significant advancement in the\npursuit of enhanced precision and user control in robotic assisted surgeries.\n  NOTE - This work has been submitted to the IEEE R-AL for possible\npublication. Copyright may be transferred without notice, after which this\nversion may no longer be accessible.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Ankit Shaw"
        ],
        "published": "2024-05-17T23:02:20Z"
    },
    {
        "title": "Enhancing Understanding Through Wildlife Re-Identification",
        "link": "http://arxiv.org/abs/2405.11112v1",
        "abstract": "We explore the field of wildlife re-identification by implementing an MLP\nfrom scratch using NumPy, A DCNN using Keras, and a binary classifier with\nLightGBM for the purpose of learning for an assignment. Analyzing the\nperformance of multiple models on multiple datasets. We attempt to replicate\nprior research in metric learning for wildlife re-identification. Firstly, we\nfind that the usage of MLPs trained for classification, then removing the\noutput layer and using the second last layer as an embedding was not a\nsuccessful strategy for similar learning; it seems like losses designed for\nembeddings such as triplet loss are required. The DCNNS performed well on some\ndatasets but poorly on others, which did not align with findings in previous\nliterature. The LightGBM classifier overfitted too heavily and was not\nsignificantly better than a constant model when trained and evaluated on all\npairs using accuracy as a metric. The technical implementations used seem to\nmatch standards according to comparisons with documentation examples and good\nresults on certain datasets. However, there is still more to explore in regards\nto being able to fully recreate past literature.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "J. Buitenhuis"
        ],
        "published": "2024-05-17T22:28:50Z"
    },
    {
        "title": "Enhancing Watermarked Language Models to Identify Users",
        "link": "http://arxiv.org/abs/2405.11109v1",
        "abstract": "A zero-bit watermarked language model produces text that is indistinguishable\nfrom that of the underlying model, but which can be detected as\nmachine-generated using a secret key. But merely detecting AI-generated spam,\nsay, as watermarked may not prevent future abuses. If we could additionally\ntrace the text to a spammer's API token, we could then cut off their access to\nthe model.\n  We introduce multi-user watermarks, which allow tracing model-generated text\nto individuals or to groups of colluding users. We construct multi-user\nwatermarking schemes from undetectable zero-bit watermarking schemes.\nImportantly, our schemes provide both zero-bit and multi-user assurances at the\nsame time: detecting shorter snippets as well as the original scheme and\ntracing longer excerpts to individuals. Along the way, we give a generic\nconstruction of a watermarking scheme that embeds long messages into generated\ntext.\n  Ours are the first black-box reductions between watermarking schemes for\nlanguage models. A major challenge for black-box reductions is the lack of a\nunified abstraction for robustness -- that marked text is detectable after\nedits. Existing works give incomparable robustness guarantees, based on bespoke\nrequirements on the language model's outputs and the users' edits. We introduce\na new abstraction -- AEB-robustness -- to overcome this challenge.\nAEB-robustness provides that the watermark is detectable whenever the edited\ntext \"approximates enough blocks\" of model-generated output. Specifying the\nrobustness condition amounts to defining approximates, enough, and blocks.\nUsing our new abstraction, we relate the robustness properties of our\nconstructions to that of the underlying zero-bit scheme. Whereas prior works\nonly guarantee robustness for a single text generated in response to a single\nprompt, our schemes are robust against adaptive prompting, a stronger\nadversarial model.",
        "subjects": [
            "cs.CR",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Aloni Cohen",
            "Alexander Hoover",
            "Gabe Schoenbach"
        ],
        "published": "2024-05-17T22:15:30Z"
    },
    {
        "title": "LLM-based Multi-Agent Reinforcement Learning: Current and Future\n  Directions",
        "link": "http://arxiv.org/abs/2405.11106v1",
        "abstract": "In recent years, Large Language Models (LLMs) have shown great abilities in\nvarious tasks, including question answering, arithmetic problem solving, and\npoem writing, among others. Although research on LLM-as-an-agent has shown that\nLLM can be applied to Reinforcement Learning (RL) and achieve decent results,\nthe extension of LLM-based RL to Multi-Agent System (MAS) is not trivial, as\nmany aspects, such as coordination and communication between agents, are not\nconsidered in the RL frameworks of a single agent. To inspire more research on\nLLM-based MARL, in this letter, we survey the existing LLM-based single-agent\nand multi-agent RL frameworks and provide potential research directions for\nfuture research. In particular, we focus on the cooperative tasks of multiple\nagents with a common goal and communication among them. We also consider\nhuman-in/on-the-loop scenarios enabled by the language component in the\nframework.",
        "subjects": [
            "cs.MA",
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "cs.RO"
        ],
        "authors": [
            "Chuanneng Sun",
            "Songjun Huang",
            "Dario Pompili"
        ],
        "published": "2024-05-17T22:10:23Z"
    },
    {
        "title": "Are Large Language Models Moral Hypocrites? A Study Based on Moral\n  Foundations",
        "link": "http://arxiv.org/abs/2405.11100v1",
        "abstract": "Large language models (LLMs) have taken centre stage in debates on Artificial\nIntelligence. Yet there remains a gap in how to assess LLMs' conformity to\nimportant human values. In this paper, we investigate whether state-of-the-art\nLLMs, GPT-4 and Claude 2.1 (Gemini Pro and LLAMA 2 did not generate valid\nresults) are moral hypocrites. We employ two research instruments based on the\nMoral Foundations Theory: (i) the Moral Foundations Questionnaire (MFQ), which\ninvestigates which values are considered morally relevant in abstract moral\njudgements; and (ii) the Moral Foundations Vignettes (MFVs), which evaluate\nmoral cognition in concrete scenarios related to each moral foundation. We\ncharacterise conflicts in values between these different abstractions of moral\nevaluation as hypocrisy. We found that both models displayed reasonable\nconsistency within each instrument compared to humans, but they displayed\ncontradictory and hypocritical behaviour when we compared the abstract values\npresent in the MFQ to the evaluation of concrete moral violations of the MFV.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "José Luiz Nunes",
            "Guilherme F. C. F. Almeida",
            "Marcelo de Araujo",
            "Simone D. J. Barbosa"
        ],
        "published": "2024-05-17T21:27:32Z"
    },
    {
        "title": "Generative AI for 2D Character Animation",
        "link": "http://arxiv.org/abs/2405.11098v2",
        "abstract": "In this pilot project, we teamed up with artists to develop new workflows for\n2D animation while producing a short educational cartoon. We identified several\nworkflows to streamline the animation process, bringing the artists' vision to\nthe screen more effectively.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Jaime Guajardo",
            "Ozgun Bursalioglu",
            "Dan B Goldman"
        ],
        "published": "2024-05-17T21:26:41Z"
    },
    {
        "title": "Flattened one-bit stochastic gradient descent: compressed distributed\n  optimization with controlled variance",
        "link": "http://arxiv.org/abs/2405.11095v1",
        "abstract": "We propose a novel algorithm for distributed stochastic gradient descent\n(SGD) with compressed gradient communication in the parameter-server framework.\nOur gradient compression technique, named flattened one-bit stochastic gradient\ndescent (FO-SGD), relies on two simple algorithmic ideas: (i) a one-bit\nquantization procedure leveraging the technique of dithering, and (ii) a\nrandomized fast Walsh-Hadamard transform to flatten the stochastic gradient\nbefore quantization. As a result, the approximation of the true gradient in\nthis scheme is biased, but it prevents commonly encountered algorithmic\nproblems, such as exploding variance in the one-bit compression regime,\ndeterioration of performance in the case of sparse gradients, and restrictive\nassumptions on the distribution of the stochastic gradients. In fact, we show\nSGD-like convergence guarantees under mild conditions. The compression\ntechnique can be used in both directions of worker-server communication,\ntherefore admitting distributed optimization with full communication\ncompression.",
        "subjects": [
            "cs.LG",
            "cs.NA",
            "math.NA",
            "math.OC"
        ],
        "authors": [
            "Alexander Stollenwerk",
            "Laurent Jacques"
        ],
        "published": "2024-05-17T21:17:27Z"
    },
    {
        "title": "YORI: Autonomous Cooking System Utilizing a Modular Robotic Kitchen and\n  a Dual-Arm Proprioceptive Manipulator",
        "link": "http://arxiv.org/abs/2405.11094v1",
        "abstract": "This article introduces the development and implementation of the Yummy\nOperations Robot Initiative (YORI), an innovative, autonomous robotic cooking\nsystem. YORI marks a major advancement in culinary automation, adept at\nhandling a diverse range of cooking tasks, capable of preparing multiple dishes\nsimultaneously, and offering the flexibility to adapt to an extensive array of\nculinary activities. This versatility is achieved through the use of custom\ntools and appliances operated by a dual arm manipulator utilizing\nproprioceptive actuators. The use of proprioceptive actuators enables fast yet\nprecise movements, while allowing for accurate force control and effectively\nmitigating the inevitable impacts encountered in cooking. These factors\nunderscore this technology's boundless potential. A key to YORI's adaptability\nis its modular kitchen design, which allows for easy adaptations to accommodate\na continuously increasing range of culinary tasks. This article provides a\ncomprehensive look at YORI's design process, and highlights its role in\nrevolutionizing the culinary world by enhancing efficiency, consistency, and\nversatility in food preparation.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Donghun Noh",
            "Hyunwoo Nam",
            "Kyle Gillespie",
            "Yeting Liu",
            "Dennis Hong"
        ],
        "published": "2024-05-17T21:14:50Z"
    },
    {
        "title": "AudioSetMix: Enhancing Audio-Language Datasets with LLM-Assisted\n  Augmentations",
        "link": "http://arxiv.org/abs/2405.11093v1",
        "abstract": "Multi-modal learning in the audio-language domain has seen significant\nadvancements in recent years. However, audio-language learning faces challenges\ndue to limited and lower-quality data compared to image-language tasks.\nExisting audio-language datasets are notably smaller, and manual labeling is\nhindered by the need to listen to entire audio clips for accurate labeling.\n  Our method systematically generates audio-caption pairs by augmenting audio\nclips with natural language labels and corresponding audio signal processing\noperations. Leveraging a Large Language Model, we generate descriptions of\naugmented audio clips with a prompt template. This scalable method produces\nAudioSetMix, a high-quality training dataset for text-and-audio related models.\n  Integration of our dataset improves models performance on benchmarks by\nproviding diversified and better-aligned examples. Notably, our dataset\naddresses the absence of modifiers (adjectives and adverbs) in existing\ndatasets. By enabling models to learn these concepts, and generating hard\nnegative examples during training, we achieve state-of-the-art performance on\nmultiple benchmarks.",
        "subjects": [
            "eess.AS",
            "cs.CL",
            "cs.MM",
            "cs.SD"
        ],
        "authors": [
            "David Xu"
        ],
        "published": "2024-05-17T21:08:58Z"
    },
    {
        "title": "Auditing the Fairness of COVID-19 Forecast Hub Case Prediction Models",
        "link": "http://arxiv.org/abs/2405.14891v1",
        "abstract": "The COVID-19 Forecast Hub, a repository of COVID-19 forecasts from over 50\nindependent research groups, is used by the Centers for Disease Control and\nPrevention (CDC) for their official COVID-19 communications. As such, the\nForecast Hub is a critical centralized resource to promote transparent decision\nmaking. Nevertheless, by focusing exclusively on prediction accuracy, the\nForecast Hub fails to evaluate whether the proposed models have similar\nperformance across social determinants that have been known to play a role in\nthe COVID-19 pandemic including race, ethnicity and urbanization level. In this\npaper, we carry out a comprehensive fairness analysis of the Forecast Hub model\npredictions and we show statistically significant diverse predictive\nperformance across social determinants, with minority racial and ethnic groups\nas well as less urbanized areas often associated with higher prediction errors.\nWe hope this work will encourage COVID-19 modelers and the CDC to report\nfairness metrics together with accuracy, and to reflect on the potential harms\nof the models on specific social groups and contexts.",
        "subjects": [
            "stat.AP",
            "cs.CY",
            "cs.LG"
        ],
        "authors": [
            "Saad Mohammad Abrar",
            "Naman Awasthi",
            "Daniel Smolyak",
            "Vanessa Frias-Martinez"
        ],
        "published": "2024-05-17T21:07:19Z"
    },
    {
        "title": "What metrics of participation balance predict outcomes of collaborative\n  learning with a robot?",
        "link": "http://arxiv.org/abs/2405.11092v1",
        "abstract": "One of the keys to the success of collaborative learning is balanced\nparticipation by all learners, but this does not always happen naturally.\nPedagogical robots have the potential to facilitate balance. However, it\nremains unclear what participation balance robots should aim at; various\nmetrics have been proposed, but it is still an open question whether we should\nbalance human participation in human-human interactions (HHI) or human-robot\ninteractions (HRI) and whether we should consider robots' participation in\ncollaborative learning involving multiple humans and a robot. This paper\nexamines collaborative learning between a pair of students and a teachable\nrobot that acts as a peer tutee to answer the aforementioned question. Through\nan exploratory study, we hypothesize which balance metrics in the literature\nand which portions of dialogues (including vs. excluding robots' participation\nand human participation in HHI vs. HRI) will better predict learning as a\ngroup. We test the hypotheses with another study and replicate them with\nautomatically obtained units of participation to simulate the information\navailable to robots when they adaptively fix imbalances in real-time. Finally,\nwe discuss recommendations on which metrics learning science researchers should\nchoose when trying to understand how to facilitate collaboration.",
        "subjects": [
            "cs.HC",
            "cs.RO"
        ],
        "authors": [
            "Yuya Asano",
            "Diane Litman",
            "Quentin King-Shepard",
            "Tristan Maidment",
            "Tyree Langley",
            "Teresa Davison",
            "Timothy Nokes-Malach",
            "Adriana Kovashka",
            "Erin Walker"
        ],
        "published": "2024-05-17T21:06:34Z"
    },
    {
        "title": "Optimal Update Policy for the Monitoring of Distributed Sources",
        "link": "http://arxiv.org/abs/2405.11089v1",
        "abstract": "When making decisions in a network, it is important to have up-to-date\nknowledge of the current state of the system. Obtaining this information,\nhowever, comes at a cost. In this paper, we determine the optimal finite-time\nupdate policy for monitoring the binary states of remote sources with a\nreporting rate constraint. We first prove an upper and lower bound of the\nminimal probability of error before solving the problem analytically. The error\nprobability is defined as the probability that the system performs differently\nthan it would with full system knowledge. More specifically, an error occurs\nwhen the destination node incorrectly determines which top-K priority sources\nare in the ``free'' state. We find that the optimal policy follows a specific\nordered 3-stage update pattern. We then provide the optimal transition points\nfor each stage for each source.",
        "subjects": [
            "cs.IT",
            "cs.DC",
            "cs.SY",
            "eess.SY",
            "math.IT"
        ],
        "authors": [
            "Eric Graves",
            "Jake B. Perazzone",
            "Kevin Chan"
        ],
        "published": "2024-05-17T20:47:02Z"
    },
    {
        "title": "Multilingual Substitution-based Word Sense Induction",
        "link": "http://arxiv.org/abs/2405.11086v1",
        "abstract": "Word Sense Induction (WSI) is the task of discovering senses of an ambiguous\nword by grouping usages of this word into clusters corresponding to these\nsenses. Many approaches were proposed to solve WSI in English and a few other\nlanguages, but these approaches are not easily adaptable to new languages. We\npresent multilingual substitution-based WSI methods that support any of 100\nlanguages covered by the underlying multilingual language model with minimal to\nno adaptation required. Despite the multilingual capabilities, our methods\nperform on par with the existing monolingual approaches on popular English WSI\ndatasets. At the same time, they will be most useful for lower-resourced\nlanguages which miss lexical resources available for English, thus, have higher\ndemand for unsupervised methods like WSI.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Denis Kokosinskii",
            "Nikolay Arefyev"
        ],
        "published": "2024-05-17T20:38:56Z"
    },
    {
        "title": "Decidability and Complexity of Decision Problems for Affine Continuous\n  VASS",
        "link": "http://arxiv.org/abs/2405.11085v1",
        "abstract": "Vector addition system with states (VASS) is a popular model for the\nverification of concurrent systems. VASS consists of finitely many control\nstates and a set of counters which can be incremented and decremented, but not\ntested for zero. VASS is a relatively well-studied model of computation and\nmany results regarding the decidability of decision problems for VASS are\nwell-known. Given that the complexity of solving almost all problems for VASS\nis very high, various tractable over-approximations of the reachability\nrelation of VASS have been proposed in the literature. One such tractable\nover-approximation is the so-called continuous VASS, in which counters are\nallowed to have non-negative rational values and whenever an update is\nperformed, the update is first scaled by an arbitrary non-zero fraction.\n  In this paper, we consider affine continuous VASS, which extend continuous\nVASS by allowing integer affine operations. Affine continuous VASS serve as an\nover-approximation to the model of affine VASS, in the same way that continuous\nVASS over-approximates the reachability relation of VASS. We investigate the\ntractability of affine continuous VASS with respect to the reachability,\ncoverability and state-reachability problems for different classes of affine\noperations and we prove an almost-complete classification of the decidability\nof these problems. Namely, except for the coverability problem for a single\nfamily of classes of affine operations, we completely determine the\ndecidability status of these problems for all classes. Furthermore, except for\nthis single family, we also complement all of our decidability results with\ntight complexity-theoretic upper and lower bounds.",
        "subjects": [
            "cs.LO"
        ],
        "authors": [
            "A. R. Balasubramanian"
        ],
        "published": "2024-05-17T20:37:52Z"
    },
    {
        "title": "Prompt Exploration with Prompt Regression",
        "link": "http://arxiv.org/abs/2405.11083v1",
        "abstract": "In the advent of democratized usage of large language models (LLMs), there is\na growing desire to systematize LLM prompt creation and selection processes\nbeyond iterative trial-and-error. Prior works majorly focus on searching the\nspace of prompts without accounting for relations between prompt variations.\n  Here we propose a framework, Prompt Exploration with Prompt Regression\n(PEPR), to predict the effect of prompt combinations given results for\nindividual prompt elements as well as a simple method to select an effective\nprompt for a given use-case. We evaluate our approach with open-source LLMs of\ndifferent sizes on several different tasks.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Michael Feffer",
            "Ronald Xu",
            "Yuekai Sun",
            "Mikhail Yurochkin"
        ],
        "published": "2024-05-17T20:30:49Z"
    },
    {
        "title": "What are You Weighting For? Improved Weights for Gaussian Mixture\n  Filtering With Application to Cislunar Orbit Determination",
        "link": "http://arxiv.org/abs/2405.11081v1",
        "abstract": "This work focuses on the critical aspect of accurate weight computation\nduring the measurement incorporation phase of Gaussian mixture filters. The\nproposed novel approach computes weights by linearizing the measurement model\nabout each component's posterior estimate rather than the the prior, as\ntraditionally done. This work proves equivalence with traditional methods for\nlinear models, provides novel sigma-point extensions to the traditional and\nproposed methods, and empirically demonstrates improved performance in\nnonlinear cases. Two illustrative examples, the Avocado and a cislunar single\ntarget tracking scenario, serve to highlight the advantages of the new weight\ncomputation technique by analyzing filter accuracy and consistency through\nvarying the number of Gaussian mixture components.",
        "subjects": [
            "stat.ME",
            "cs.CE",
            "cs.NA",
            "math.NA",
            "math.OC",
            "physics.data-an"
        ],
        "authors": [
            "Dalton Durant",
            "Andrey A. Popov",
            "Renato Zanetti"
        ],
        "published": "2024-05-17T20:28:29Z"
    },
    {
        "title": "FeMLoc: Federated Meta-learning for Adaptive Wireless Indoor\n  Localization Tasks in IoT Networks",
        "link": "http://arxiv.org/abs/2405.11079v1",
        "abstract": "The rapid growth of the Internet of Things fosters collaboration among\nconnected devices for tasks like indoor localization. However, existing indoor\nlocalization solutions struggle with dynamic and harsh conditions, requiring\nextensive data collection and environment-specific calibration. These factors\nimpede cooperation, scalability, and the utilization of prior research efforts.\nTo address these challenges, we propose FeMLoc, a federated meta-learning\nframework for localization. FeMLoc operates in two stages: (i) collaborative\nmeta-training where a global meta-model is created by training on diverse\nlocalization datasets from edge devices. (ii) Rapid adaptation for new\nenvironments, where the pre-trained global meta-model initializes the\nlocalization model, requiring only minimal fine-tuning with a small amount of\nnew data. In this paper, we provide a detailed technical overview of FeMLoc,\nhighlighting its unique approach to privacy-preserving meta-learning in the\ncontext of indoor localization. Our performance evaluation demonstrates the\nsuperiority of FeMLoc over state-of-the-art methods, enabling swift adaptation\nto new indoor environments with reduced calibration effort. Specifically,\nFeMLoc achieves up to 80.95% improvement in localization accuracy compared to\nthe conventional baseline neural network (NN) approach after only 100 gradient\nsteps. Alternatively, for a target accuracy of around 5m, FeMLoc achieves the\nsame level of accuracy up to 82.21% faster than the baseline NN approach. This\ntranslates to FeMLoc requiring fewer training iterations, thereby significantly\nreducing fingerprint data collection and calibration efforts. Moreover, FeMLoc\nexhibits enhanced scalability, making it well-suited for location-aware massive\nconnectivity driven by emerging wireless communication technologies.",
        "subjects": [
            "eess.SP",
            "cs.LG",
            "cs.NI"
        ],
        "authors": [
            "Yaya Etiabi",
            "Wafa Njima",
            "El Mehdi Amhoud"
        ],
        "published": "2024-05-17T20:22:39Z"
    },
    {
        "title": "Equivalence and Conditional Independence in Atomic Sheaf Logic",
        "link": "http://dx.doi.org/10.1145/3661814.3662132",
        "abstract": "We propose a semantic foundation for logics for reasoning in settings that\npossess a distinction between equality of variables, a coarser equivalence of\nvariables, and a notion of conditional independence between variables. We show\nthat such relations can be modelled naturally in atomic sheaf toposes.",
        "subjects": [
            "cs.LO",
            "math.CT",
            "math.LO"
        ],
        "authors": [
            "Alex Simpson"
        ],
        "published": "2024-05-17T20:06:17Z"
    },
    {
        "title": "Next-slot OFDM-CSI Prediction: Multi-head Self-attention or State Space\n  Model?",
        "link": "http://arxiv.org/abs/2405.11072v1",
        "abstract": "The ongoing fifth-generation (5G) standardization is exploring the use of\ndeep learning (DL) methods to enhance the new radio (NR) interface. Both in\nacademia and industry, researchers are investigating the performance and\ncomplexity of multiple DL architecture candidates for specific one-sided and\ntwo-sided use cases such as channel state estimation (CSI) feedback, CSI\nprediction, beam management, and positioning. In this paper, we set focus on\nthe CSI prediction task and study the performance and generalization of the two\nmain DL layers that are being extensively benchmarked within the DL community,\nnamely, multi-head self-attention (MSA) and state-space model (SSM). We train\nand evaluate MSA and SSM layers to predict the next slot for uplink and\ndownlink communication scenarios over urban microcell (UMi) and urban macrocell\n(UMa) OFDM 5G channel models. Our numerical results demonstrate that SSMs\nexhibit better prediction and generalization capabilities than MSAs only for\nSISO cases. For MIMO scenarios, however, the MSA layer outperforms the SSM one.\nWhile both layers represent potential DL architectures for future DL-enabled 5G\nuse cases, the overall investigation of this paper favors MSAs over SSMs.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Mohamed Akrout",
            "Faouzi Bellili",
            "Amine Mezghani",
            "Robert W. Heath"
        ],
        "published": "2024-05-17T20:03:10Z"
    },
    {
        "title": "Boundary element methods for the magnetic field integral equation on\n  polyhedra",
        "link": "http://arxiv.org/abs/2405.11071v1",
        "abstract": "This paper provides a rigorous analysis on boundary element methods for the\nmagnetic field integral equation on Lipschitz polyhedra. The magnetic field\nintegral equation is widely used in practical applications to model\nelectromagnetic scattering by a perfectly conducting body. The governing\noperator is shown to be coercive by means of the electric field integral\noperator with a purely imaginary wave number. Consequently, the continuous\nvariational problem is uniquely solvable, given that the wave number does not\nbelong to the spectrum of the interior Maxwell's problem. A Galerkin\ndiscretization scheme is then introduced, employing Raviart-Thomas basis\nfunctions for the solution space and Buffa-Christiansen functions for the test\nspace. A discrete inf-sup condition is proven, implying the unique solvability\nof the discrete variational problem. An asymptotically quasi-optimal error\nestimate for the numerical solutions is established, and the convergence rate\nof the numerical scheme is examined. In addition, the resulting matrix system\nis shown to be well-conditioned regardless of the mesh refinement. Some\nnumerical results are presented to support the theoretical analysis.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "math-ph",
            "math.MP"
        ],
        "authors": [
            "Van Chien Le",
            "Kristof Cools"
        ],
        "published": "2024-05-17T20:01:43Z"
    },
    {
        "title": "Jill Watson: A Virtual Teaching Assistant powered by ChatGPT",
        "link": "http://arxiv.org/abs/2405.11070v1",
        "abstract": "Conversational AI agents often require extensive datasets for training that\nare not publicly released, are limited to social chit-chat or handling a\nspecific domain, and may not be easily extended to accommodate the latest\nadvances in AI technologies. This paper introduces Jill Watson, a\nconversational Virtual Teaching Assistant (VTA) leveraging the capabilities of\nChatGPT. Jill Watson based on ChatGPT requires no prior training and uses a\nmodular design to allow the integration of new APIs using a skill-based\narchitecture inspired by XiaoIce. Jill Watson is also well-suited for\nintelligent textbooks as it can process and converse using multiple large\ndocuments. We exclusively utilize publicly available resources for\nreproducibility and extensibility. Comparative analysis shows that our system\noutperforms the legacy knowledge-based Jill Watson as well as the OpenAI\nAssistants service. We employ many safety measures that reduce instances of\nhallucinations and toxicity. The paper also includes real-world examples from a\nclassroom setting that demonstrate different features of Jill Watson and its\neffectiveness.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Karan Taneja",
            "Pratyusha Maiti",
            "Sandeep Kakar",
            "Pranav Guruprasad",
            "Sanjeev Rao",
            "Ashok K. Goel"
        ],
        "published": "2024-05-17T19:55:57Z"
    },
    {
        "title": "Bayesian Learning-driven Prototypical Contrastive Loss for\n  Class-Incremental Learning",
        "link": "http://arxiv.org/abs/2405.11067v1",
        "abstract": "The primary objective of methods in continual learning is to learn tasks in a\nsequential manner over time from a stream of data, while mitigating the\ndetrimental phenomenon of catastrophic forgetting. In this paper, we focus on\nlearning an optimal representation between previous class prototypes and newly\nencountered ones. We propose a prototypical network with a Bayesian\nlearning-driven contrastive loss (BLCL) tailored specifically for\nclass-incremental learning scenarios. Therefore, we introduce a contrastive\nloss that incorporates new classes into the latent representation by reducing\nthe intra-class distance and increasing the inter-class distance. Our approach\ndynamically adapts the balance between the cross-entropy and contrastive loss\nfunctions with a Bayesian learning technique. Empirical evaluations conducted\non both the CIFAR-10 dataset for image classification and images of a\nGNSS-based dataset for interference classification validate the efficacy of our\nmethod, showcasing its superiority over existing state-of-the-art approaches.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "62P30, 68T30, 68T05, 68T37",
            "G.3; I.2.4; I.2.6"
        ],
        "authors": [
            "Nisha L. Raichur",
            "Lucas Heublein",
            "Tobias Feigl",
            "Alexander Rügamer",
            "Christopher Mutschler",
            "Felix Ott"
        ],
        "published": "2024-05-17T19:49:02Z"
    },
    {
        "title": "Enabling mixed-precision with the help of tools: A Nekbone case study",
        "link": "http://arxiv.org/abs/2405.11065v1",
        "abstract": "Mixed-precision computing has the potential to significantly reduce the cost\nof exascale computations, but determining when and how to implement it in\nprograms can be challenging. In this article, we consider Nekbone, a\nmini-application for the CFD solver Nek5000, as a case study, and propose a\nmethodology for enabling mixed-precision with the help of computer arithmetic\ntools and roofline model. We evaluate the derived mixed-precision program by\ncombining metrics in three dimensions: accuracy, time-to-solution, and\nenergy-to-solution. Notably, the introduction of mixed-precision in Nekbone,\nreducing time-to-solution by 40.7% and energy-to-solution by 47% on 128 MPI\nranks.",
        "subjects": [
            "cs.MS",
            "cs.DC",
            "cs.SE"
        ],
        "authors": [
            "Yanxiang Chen",
            "Pablo de Oliveira Castro",
            "Paolo Bientinesi",
            "Roman Iakymchuk"
        ],
        "published": "2024-05-17T19:42:10Z"
    },
    {
        "title": "TVCondNet: A Conditional Denoising Neural Network for NMR Spectroscopy",
        "link": "http://arxiv.org/abs/2405.11064v1",
        "abstract": "Nuclear Magnetic Resonance (NMR) spectroscopy is a widely-used technique in\nthe fields of bio-medicine, chemistry, and biology for the analysis of\nchemicals and proteins. The signals from NMR spectroscopy often have low\nsignal-to-noise ratio (SNR) due to acquisition noise, which poses significant\nchallenges for subsequent analysis. Recent work has explored the potential of\ndeep learning (DL) for NMR denoising, showing significant performance gains\nover traditional methods such as total variation (TV) denoising. This paper\nshows that the performance of DL denoising for NMR can be further improved by\ncombining data-driven training with traditional TV denoising. The proposed\nTVCondNet method outperforms both traditional TV and DL methods by including\nthe TV solution as a condition during DL training. Our validation on\nexperimentally collected NMR data shows the superior denoising performance and\nfaster inference speed of TVCondNet compared to existing methods.",
        "subjects": [
            "eess.SP",
            "cs.CV"
        ],
        "authors": [
            "Zihao Zou",
            "Shirin Shoushtari",
            "Jiaming Liu",
            "Jialiang Zhang",
            "Patrick Judge",
            "Emilia Santana",
            "Alison Lim",
            "Marcus Foston",
            "Ulugbek S. Kamilov"
        ],
        "published": "2024-05-17T19:39:15Z"
    },
    {
        "title": "Spectral Difference method with a posteriori limiting: II- Application\n  to low Mach number flows",
        "link": "http://arxiv.org/abs/2405.11063v1",
        "abstract": "Stellar convection poses two main gargantuan challenges for astrophysical\nfluid solvers: low-Mach number flows and minuscule perturbations over steeply\nstratified hydrostatic equilibria. Most methods exhibit excessive numerical\ndiffusion and are unable to capture the correct solution due to large\ntruncation errors. In this paper, we analyze the performance of the Spectral\nDifference (SD) method under these extreme conditions using an arbitrarily\nhigh-order shock capturing scheme with a posteriori limiting. We include both a\nmodification to the HLLC Riemann solver adapted to low Mach number flows\n(L-HLLC) and a well-balanced scheme to properly evolve perturbations over steep\nequilibrium solutions. We evaluate the performance of our method using a series\nof test tailored specifically for stellar convection. We observe that our\nhigh-order SD method is capable of dealing with very subsonic flows without\nnecessarily using the modified Riemann solver. We find however that the\nwell-balanced framework is unavoidable if one wants to capture accurately small\namplitude convective and acoustic modes. Analyzing the temporal and spatial\nevolution of the turbulent kinetic energy, we show that our fourth-order SD\nscheme seems to emerge as an optimal variant to solve this difficult numerical\nproblem.",
        "subjects": [
            "physics.flu-dyn",
            "astro-ph.IM",
            "astro-ph.SR",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "D. A. Velasco-Romero",
            "R. Teyssier"
        ],
        "published": "2024-05-17T19:37:38Z"
    },
    {
        "title": "Vectorization of Gradient Boosting of Decision Trees Prediction in the\n  CatBoost Library for RISC-V Processors",
        "link": "http://arxiv.org/abs/2405.11062v1",
        "abstract": "The emergence and rapid development of the open RISC-V instruction set\narchitecture opens up new horizons on the way to efficient devices, ranging\nfrom existing low-power IoT boards to future high-performance servers. The\neffective use of RISC-V CPUs requires software optimization for the target\nplatform. In this paper, we focus on the RISC-V-specific optimization of the\nCatBoost library, one of the widely used implementations of gradient boosting\nfor decision trees. The CatBoost library is deeply optimized for commodity CPUs\nand GPUs. However, vectorization is required to effectively utilize the\nresources of RISC-V CPUs with the RVV 0.7.1 vector extension, which cannot be\ndone automatically with a C++ compiler yet. The paper reports on our experience\nin benchmarking CatBoost on the Lichee Pi 4a, RISC-V-based board, and shows how\nmanual vectorization of computationally intensive loops with intrinsics can\nspeed up the use of decision trees several times, depending on the specific\nworkload. The developed codes are publicly available on GitHub.",
        "subjects": [
            "cs.DC",
            "cs.PF"
        ],
        "authors": [
            "Evgeny Kozinov",
            "Evgeny Vasiliev",
            "Andrey Gorshkov",
            "Valentina Kustikova",
            "Artem Maklaev",
            "Valentin Volokitin",
            "Iosif Meyerov"
        ],
        "published": "2024-05-17T19:36:19Z"
    },
    {
        "title": "Frugal Algorithm Selection",
        "link": "http://arxiv.org/abs/2405.11059v1",
        "abstract": "When solving decision and optimisation problems, many competing algorithms\n(model and solver choices) have complementary strengths. Typically, there is no\nsingle algorithm that works well for all instances of a problem. Automated\nalgorithm selection has been shown to work very well for choosing a suitable\nalgorithm for a given instance. However, the cost of training can be\nprohibitively large due to running candidate algorithms on a representative set\nof training instances. In this work, we explore reducing this cost by choosing\na subset of the training instances on which to train. We approach this problem\nin three ways: using active learning to decide based on prediction uncertainty,\naugmenting the algorithm predictors with a timeout predictor, and collecting\ntraining data using a progressively increasing timeout. We evaluate\ncombinations of these approaches on six datasets from ASLib and present the\nreduction in labelling cost achieved by each option.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Erdem Kuş",
            "Özgür Akgün",
            "Nguyen Dang",
            "Ian Miguel"
        ],
        "published": "2024-05-17T19:23:30Z"
    },
    {
        "title": "A Comparative Study of Garment Draping Techniques",
        "link": "http://arxiv.org/abs/2405.11056v1",
        "abstract": "We present a comparison review that evaluates popular techniques for garment\ndraping for 3D fashion design, virtual try-ons, and animations. A comparative\nstudy is performed between various methods for garment draping of clothing over\nthe human body. These include numerous models, such as physics and machine\nlearning based techniques, collision handling, and more. Performance\nevaluations and trade-offs are discussed to ensure informed decision-making\nwhen choosing the most appropriate approach. These methods aim to accurately\nrepresent deformations and fine wrinkles of digital garments, considering the\nfactors of data requirements, and efficiency, to produce realistic results. The\nresearch can be insightful to researchers, designers, and developers in\nvisualizing dynamic multi-layered 3D clothing.",
        "subjects": [
            "cs.GR",
            "cs.LG"
        ],
        "authors": [
            "Prerana Achar",
            "Mayank Patel",
            "Anushka Mulik",
            "Neha Katre",
            "Stevina Dias",
            "Chirag Raman"
        ],
        "published": "2024-05-17T19:11:38Z"
    },
    {
        "title": "Leveraging Discourse Structure for Extractive Meeting Summarization",
        "link": "http://arxiv.org/abs/2405.11055v2",
        "abstract": "We introduce an extractive summarization system for meetings that leverages\ndiscourse structure to better identify salient information from complex\nmulti-party discussions. Using discourse graphs to represent semantic relations\nbetween the contents of utterances in a meeting, we train a GNN-based node\nclassification model to select the most important utterances, which are then\ncombined to create an extractive summary. Experimental results on AMI and ICSI\ndemonstrate that our approach surpasses existing text-based and graph-based\nextractive summarization systems, as measured by both classification and\nsummarization metrics. Additionally, we conduct ablation studies on discourse\nstructure and relation type to provide insights for future NLP applications\nleveraging discourse analysis theory.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Virgile Rennard",
            "Guokan Shang",
            "Michalis Vazirgiannis",
            "Julie Hunter"
        ],
        "published": "2024-05-17T19:06:20Z"
    },
    {
        "title": "The MovieLens Beliefs Dataset: Collecting Pre-Choice Data for Online\n  Recommender Systems",
        "link": "http://arxiv.org/abs/2405.11053v2",
        "abstract": "An increasingly important aspect of designing recommender systems involves\nconsidering how recommendations will influence consumer choices. This paper\naddresses this issue by introducing a method for collecting user beliefs about\nun-experienced items - a critical predictor of choice behavior. We implemented\nthis method on the MovieLens platform, resulting in a rich dataset that\ncombines user ratings, beliefs, and observed recommendations. We document\nchallenges to such data collection, including selection bias in response and\nlimited coverage of the product space. This unique resource empowers\nresearchers to delve deeper into user behavior and analyze user choices absent\nrecommendations, measure the effectiveness of recommendations, and prototype\nalgorithms that leverage user belief data, ultimately leading to more impactful\nrecommender systems. The dataset can be found at\nhttps://grouplens.org/datasets/movielens/ml_belief_2024/.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.HC"
        ],
        "authors": [
            "Guy Aridor",
            "Duarte Goncalves",
            "Ruoyan Kong",
            "Daniel Kluver",
            "Joseph Konstan"
        ],
        "published": "2024-05-17T19:06:06Z"
    },
    {
        "title": "Exploring Subjectivity for more Human-Centric Assessment of Social\n  Biases in Large Language Models",
        "link": "http://arxiv.org/abs/2405.11048v1",
        "abstract": "An essential aspect of evaluating Large Language Models (LLMs) is identifying\npotential biases. This is especially relevant considering the substantial\nevidence that LLMs can replicate human social biases in their text outputs and\nfurther influence stakeholders, potentially amplifying harm to already\nmarginalized individuals and communities. Therefore, recent efforts in bias\ndetection invested in automated benchmarks and objective metrics such as\naccuracy (i.e., an LLMs output is compared against a predefined ground truth).\nNonetheless, social biases can be nuanced, oftentimes subjective and\ncontext-dependent, where a situation is open to interpretation and there is no\nground truth. While these situations can be difficult for automated evaluation\nsystems to identify, human evaluators could potentially pick up on these\nnuances. In this paper, we discuss the role of human evaluation and subjective\ninterpretation to augment automated processes when identifying biases in LLMs\nas part of a human-centred approach to evaluate these models.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Paula Akemi Aoyagui",
            "Sharon Ferguson",
            "Anastasia Kuzminykh"
        ],
        "published": "2024-05-17T18:45:23Z"
    },
    {
        "title": "Affine Transformation-based Perfectly Undetectable False Data Injection\n  Attacks on Remote Manipulator Kinematic Control with Attack Detector",
        "link": "http://arxiv.org/abs/2405.11047v1",
        "abstract": "This paper demonstrates the viability of perfectly undetectable affine\ntransformation attacks against robotic manipulators where intelligent attackers\ncan inject multiplicative and additive false data while remaining completely\nhidden from system users. The attacker can implement these communication line\nattacks by satisfying three Conditions presented in this work. These claims are\nexperimentally validated on a FANUC 6 degree of freedom manipulator by\ncomparing a nominal (non-attacked) trial and a detectable attack case against\nthree perfectly undetectable trajectory attack Scenarios: scaling, reflection,\nand shearing. The results show similar observed end effector error for the\nattack Scenarios and the nominal case, indicating that the perfectly\nundetectable affine transformation attack method keeps the attacker perfectly\nhidden while enabling them to attack manipulator trajectories.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Jun Ueda",
            "Jacob Blevins"
        ],
        "published": "2024-05-17T18:45:20Z"
    },
    {
        "title": "Two RSA-based Cryptosystems",
        "link": "http://arxiv.org/abs/2405.11041v1",
        "abstract": "The cryptosystem RSA is a very popular cryptosystem in the study of\nCryptography. In this article, we explore how the idea of a primitive mth root\nof unity in a ring can be integrated into the Discrete Fourier Transform,\nleading to the development of new cryptosystems known as RSA-DFT and RSA-HGR.",
        "subjects": [
            "cs.CR",
            "16S34, 20C05, 11T71"
        ],
        "authors": [
            "A. Telveenus"
        ],
        "published": "2024-05-17T18:35:29Z"
    },
    {
        "title": "From Generalist to Specialist: Improving Large Language Models for\n  Medical Physics Using ARCoT",
        "link": "http://arxiv.org/abs/2405.11040v1",
        "abstract": "Large Language Models (LLMs) have achieved remarkable progress, yet their\napplication in specialized fields, such as medical physics, remains challenging\ndue to the need for domain-specific knowledge. This study introduces ARCoT\n(Adaptable Retrieval-based Chain of Thought), a framework designed to enhance\nthe domain-specific accuracy of LLMs without requiring fine-tuning or extensive\nretraining. ARCoT integrates a retrieval mechanism to access relevant\ndomain-specific information and employs step-back and chain-of-thought\nprompting techniques to guide the LLM's reasoning process, ensuring more\naccurate and context-aware responses. Benchmarking on a medical physics\nmultiple-choice exam, our model outperformed standard LLMs and reported average\nhuman performance, demonstrating improvements of up to 68% and achieving a high\nscore of 90%. This method reduces hallucinations and increases domain-specific\nperformance. The versatility and model-agnostic nature of ARCoT make it easily\nadaptable to various domains, showcasing its significant potential for\nenhancing the accuracy and reliability of LLMs in specialized fields.",
        "subjects": [
            "cs.CL",
            "physics.med-ph"
        ],
        "authors": [
            "Jace Grandinetti",
            "Rafe McBeth"
        ],
        "published": "2024-05-17T18:31:38Z"
    },
    {
        "title": "CC-GPX: Extracting High-Quality Annotated Geospatial Data from Common\n  Crawl",
        "link": "http://arxiv.org/abs/2405.11039v1",
        "abstract": "The Common Crawl (CC) corpus is the largest open web crawl dataset containing\n9.5+ petabytes of data captured since 2008. The dataset is instrumental in\ntraining large language models, and as such it has been studied for\n(un)desirable content, and distilled for smaller, domain-specific datasets.\nHowever, to our knowledge, no research has been dedicated to using CC as a\nsource of annotated geospatial data. In this paper, we introduce an efficient\npipeline to extract annotated user-generated tracks from GPX files found in CC,\nand the resulting multimodal dataset with 1,416 pairings of human-written\ndescriptions and MultiLineString vector data. The dataset can be used to study\npeople's outdoor activity patterns, the way people talk about their outdoor\nexperiences, and for developing trajectory generation or track annotation\nmodels.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Ilya Ilyankou",
            "James Haworth",
            "Stefano Cavazzi"
        ],
        "published": "2024-05-17T18:31:26Z"
    },
    {
        "title": "DeFiTail: DeFi Protocol Inspection through Cross-Contract Execution\n  Analysis",
        "link": "http://arxiv.org/abs/2405.11035v1",
        "abstract": "Decentralized finance (DeFi) protocols are crypto projects developed on the\nblockchain to manage digital assets. Attacks on DeFi have been frequent and\nhave resulted in losses exceeding \\$77 billion. However, detection methods for\nmalicious DeFi events are still lacking. In this paper, we propose DeFiTail,\nthe first framework that utilizes deep learning to detect access control and\nflash loan exploits that may occur on DeFi. Since the DeFi protocol events\ninvolve invocations with multi-account transactions, which requires execution\npath unification with different contracts. Moreover, to mitigate the impact of\nmistakes in Control Flow Graph (CFG) connections, we validate the data path by\nemploying the symbolic execution stack. Furthermore, we feed the data paths\nthrough our model to achieve the inspection of DeFi protocols. Experimental\nresults indicate that DeFiTail achieves the highest accuracy, with 98.39% in\naccess control and 97.43% in flash loan exploits. DeFiTail also demonstrates an\nenhanced capability to detect malicious contracts, identifying 86.67% accuracy\nfrom the CVE dataset.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Wenkai Li",
            "Xiaoqi Li",
            "Yuqing Zhang",
            "Zongwei Li"
        ],
        "published": "2024-05-17T18:14:19Z"
    },
    {
        "title": "Safety in Graph Machine Learning: Threats and Safeguards",
        "link": "http://arxiv.org/abs/2405.11034v1",
        "abstract": "Graph Machine Learning (Graph ML) has witnessed substantial advancements in\nrecent years. With their remarkable ability to process graph-structured data,\nGraph ML techniques have been extensively utilized across diverse applications,\nincluding critical domains like finance, healthcare, and transportation.\nDespite their societal benefits, recent research highlights significant safety\nconcerns associated with the widespread use of Graph ML models. Lacking\nsafety-focused designs, these models can produce unreliable predictions,\ndemonstrate poor generalizability, and compromise data confidentiality. In\nhigh-stakes scenarios such as financial fraud detection, these vulnerabilities\ncould jeopardize both individuals and society at large. Therefore, it is\nimperative to prioritize the development of safety-oriented Graph ML models to\nmitigate these risks and enhance public confidence in their applications. In\nthis survey paper, we explore three critical aspects vital for enhancing safety\nin Graph ML: reliability, generalizability, and confidentiality. We categorize\nand analyze threats to each aspect under three headings: model threats, data\nthreats, and attack threats. This novel taxonomy guides our review of effective\nstrategies to protect against these threats. Our systematic review lays a\ngroundwork for future research aimed at developing practical, safety-centered\nGraph ML models. Furthermore, we highlight the significance of safe Graph ML\npractices and suggest promising avenues for further investigation in this\ncrucial area.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Song Wang",
            "Yushun Dong",
            "Binchi Zhang",
            "Zihan Chen",
            "Xingbo Fu",
            "Yinhan He",
            "Cong Shen",
            "Chuxu Zhang",
            "Nitesh V. Chawla",
            "Jundong Li"
        ],
        "published": "2024-05-17T18:11:11Z"
    },
    {
        "title": "Game-theoretic Energy Management Strategies With Interacting Agents in\n  Formula 1",
        "link": "http://arxiv.org/abs/2405.11032v1",
        "abstract": "This paper presents an interaction-aware energy management optimization\nframework for Formula 1 racing. The considered scenario involves two agents and\na drag reduction model. Strategic interactions between the agents are captured\nby a Stackelberg game formulated as a bilevel program. To address the\ncomputational challenges associated with bilevel optimization, the problem is\nreformulated as a single-level nonlinear program employing the\nKarush-Kuhn-Tucker conditions. The proposed framework contributes towards the\ndevelopment of new energy management and allocation strategies, caused by the\npresence of another agent. For instance, it provides valuable insights on how\nto redistribute the energy in order to optimally exploit the wake effect,\nshowcasing a notable difference with the behavior studied in previous works.\nRobust energy allocations can be identified to reduce the lap time loss\nassociated with unexpected choices of the other agent. It allows to recognize\nthe boundary conditions for the interaction to become relevant, impacting the\nsystem's behavior, and to assess if overtaking is possible and beneficial.\nOverall, the framework provides a comprehensive approach for a two-agent\nFormula 1 racing problem with strategic interactions, offering physically\nintuitive and practical results.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Giona Fieni",
            "Marc-Philippe Neumann",
            "Alessandro Zanardi",
            "Alberto Cerofolini",
            "Christopher H. Onder"
        ],
        "published": "2024-05-17T18:07:09Z"
    },
    {
        "title": "The Unappreciated Role of Intent in Algorithmic Moderation of Social\n  Media Content",
        "link": "http://arxiv.org/abs/2405.11030v1",
        "abstract": "As social media has become a predominant mode of communication globally, the\nrise of abusive content threatens to undermine civil discourse. Recognizing the\ncritical nature of this issue, a significant body of research has been\ndedicated to developing language models that can detect various types of online\nabuse, e.g., hate speech, cyberbullying. However, there exists a notable\ndisconnect between platform policies, which often consider the author's\nintention as a criterion for content moderation, and the current capabilities\nof detection models, which typically lack efforts to capture intent. This paper\nexamines the role of intent in content moderation systems. We review state of\nthe art detection models and benchmark training datasets for online abuse to\nassess their awareness and ability to capture intent. We propose strategic\nchanges to the design and development of automated detection and moderation\nsystems to improve alignment with ethical and policy conceptualizations of\nabuse.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Xinyu Wang",
            "Sai Koneru",
            "Pranav Narayanan Venkit",
            "Brett Frischmann",
            "Sarah Rajtmajer"
        ],
        "published": "2024-05-17T18:05:13Z"
    },
    {
        "title": "Generative Artificial Intelligence: A Systematic Review and Applications",
        "link": "http://arxiv.org/abs/2405.11029v1",
        "abstract": "In recent years, the study of artificial intelligence (AI) has undergone a\nparadigm shift. This has been propelled by the groundbreaking capabilities of\ngenerative models both in supervised and unsupervised learning scenarios.\nGenerative AI has shown state-of-the-art performance in solving perplexing\nreal-world conundrums in fields such as image translation, medical diagnostics,\ntextual imagery fusion, natural language processing, and beyond. This paper\ndocuments the systematic review and analysis of recent advancements and\ntechniques in Generative AI with a detailed discussion of their applications\nincluding application-specific models. Indeed, the major impact that generative\nAI has made to date, has been in language generation with the development of\nlarge language models, in the field of image translation and several other\ninterdisciplinary applications of generative AI. Moreover, the primary\ncontribution of this paper lies in its coherent synthesis of the latest\nadvancements in these areas, seamlessly weaving together contemporary\nbreakthroughs in the field. Particularly, how it shares an exploration of the\nfuture trajectory for generative AI. In conclusion, the paper ends with a\ndiscussion of Responsible AI principles, and the necessary ethical\nconsiderations for the sustainability and growth of these generative models.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "authors": [
            "Sandeep Singh Sengar",
            "Affan Bin Hasan",
            "Sanjay Kumar",
            "Fiona Carroll"
        ],
        "published": "2024-05-17T18:03:59Z"
    },
    {
        "title": "GraSS: Combining Graph Neural Networks with Expert Knowledge for SAT\n  Solver Selection",
        "link": "http://arxiv.org/abs/2405.11024v1",
        "abstract": "Boolean satisfiability (SAT) problems are routinely solved by SAT solvers in\nreal-life applications, yet solving time can vary drastically between solvers\nfor the same instance. This has motivated research into machine learning models\nthat can predict, for a given SAT instance, which solver to select among\nseveral options. Existing SAT solver selection methods all rely on some\nhand-picked instance features, which are costly to compute and ignore the\nstructural information in SAT graphs. In this paper we present GraSS, a novel\napproach for automatic SAT solver selection based on tripartite graph\nrepresentations of instances and a heterogeneous graph neural network (GNN)\nmodel. While GNNs have been previously adopted in other SAT-related tasks, they\ndo not incorporate any domain-specific knowledge and ignore the runtime\nvariation introduced by different clause orders. We enrich the graph\nrepresentation with domain-specific decisions, such as novel node feature\ndesign, positional encodings for clauses in the graph, a GNN architecture\ntailored to our tripartite graphs and a runtime-sensitive loss function.\nThrough extensive experiments, we demonstrate that this combination of raw\nrepresentations and domain-specific choices leads to improvements in runtime\nfor a pool of seven state-of-the-art solvers on both an industrial circuit\ndesign benchmark, and on instances from the 20-year Anniversary Track of the\n2022 SAT Competition.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Zhanguang Zhang",
            "Didier Chetelat",
            "Joseph Cotnareanu",
            "Amur Ghose",
            "Wenyi Xiao",
            "Hui-Ling Zhen",
            "Yingxue Zhang",
            "Jianye Hao",
            "Mark Coates",
            "Mingxuan Yuan"
        ],
        "published": "2024-05-17T18:00:50Z"
    },
    {
        "title": "Photorealistic 3D Urban Scene Reconstruction and Point Cloud Extraction\n  using Google Earth Imagery and Gaussian Splatting",
        "link": "http://arxiv.org/abs/2405.11021v1",
        "abstract": "3D urban scene reconstruction and modelling is a crucial research area in\nremote sensing with numerous applications in academia, commerce, industry, and\nadministration. Recent advancements in view synthesis models have facilitated\nphotorealistic 3D reconstruction solely from 2D images. Leveraging Google Earth\nimagery, we construct a 3D Gaussian Splatting model of the Waterloo region\ncentered on the University of Waterloo and are able to achieve view-synthesis\nresults far exceeding previous 3D view-synthesis results based on neural\nradiance fields which we demonstrate in our benchmark. Additionally, we\nretrieved the 3D geometry of the scene using the 3D point cloud extracted from\nthe 3D Gaussian Splatting model which we benchmarked against our Multi-\nView-Stereo dense reconstruction of the scene, thereby reconstructing both the\n3D geometry and photorealistic lighting of the large-scale urban scene through\n3D Gaussian Splatting",
        "subjects": [
            "cs.CV",
            "I.4, I.3"
        ],
        "authors": [
            "Kyle Gao",
            "Dening Lu",
            "Hongjie He",
            "Linlin Xu",
            "Jonathan Li"
        ],
        "published": "2024-05-17T18:00:07Z"
    },
    {
        "title": "Probabilistic transfer learning methodology to expedite high fidelity\n  simulation of reactive flows",
        "link": "http://arxiv.org/abs/2405.10944v1",
        "abstract": "Reduced order models based on the transport of a lower dimensional manifold\nrepresentation of the thermochemical state, such as Principal Component (PC)\ntransport and Machine Learning (ML) techniques, have been developed to reduce\nthe computational cost associated with the Direct Numerical Simulations (DNS)\nof reactive flows. Both PC transport and ML normally require an abundance of\ndata to exhibit sufficient predictive accuracy, which might not be available\ndue to the prohibitive cost of DNS or experimental data acquisition. To\nalleviate such difficulties, similar data from an existing dataset or domain\n(source domain) can be used to train ML models, potentially resulting in\nadequate predictions in the domain of interest (target domain). This study\npresents a novel probabilistic transfer learning (TL) framework to enhance the\ntrust in ML models in correctly predicting the thermochemical state in a lower\ndimensional manifold and a sparse data setting. The framework uses Bayesian\nneural networks, and autoencoders, to reduce the dimensionality of the state\nspace and diffuse the knowledge from the source to the target domain. The new\nframework is applied to one-dimensional freely-propagating flame solutions\nunder different data sparsity scenarios. The results reveal that there is an\noptimal amount of knowledge to be transferred, which depends on the amount of\ndata available in the target domain and the similarity between the domains. TL\ncan reduce the reconstruction error by one order of magnitude for cases with\nlarge sparsity. The new framework required 10 times less data for the target\ndomain to reproduce the same error as in the abundant data scenario.\nFurthermore, comparisons with a state-of-the-art deterministic TL strategy show\nthat the probabilistic method can require four times less data to achieve the\nsame reconstruction error.",
        "subjects": [
            "physics.chem-ph",
            "cs.LG"
        ],
        "authors": [
            "Bruno S. Soriano",
            "Ki Sung Jung",
            "Tarek Echekki",
            "Jacqueline H. Chen",
            "Mohammad Khalil"
        ],
        "published": "2024-05-17T17:58:52Z"
    },
    {
        "title": "Variational Quantum Algorithm Landscape Reconstruction by Low-Rank\n  Tensor Completion",
        "link": "http://arxiv.org/abs/2405.10941v1",
        "abstract": "Variational quantum algorithms (VQAs) are a broad class of algorithms with\nmany applications in science and industry. Applying a VQA to a problem involves\noptimizing a parameterized quantum circuit by maximizing or minimizing a cost\nfunction. A particular challenge associated with VQAs is understanding the\nproperties of associated cost functions. Having the landscapes of VQA cost\nfunctions can greatly assist in developing and testing new variational quantum\nalgorithms, but they are extremely expensive to compute. Reconstructing the\nlandscape of a VQA using existing techniques requires a large number of cost\nfunction evaluations, especially when the dimension or the resolution of the\nlandscape is high. To address this challenge, we propose a low-rank\ntensor-completion-based approach for local landscape reconstruction. By\nleveraging compact low-rank representations of tensors, our technique can\novercome the curse of dimensionality and handle high-resolution landscapes. We\ndemonstrate the power of landscapes in VQA development by showcasing practical\napplications of analyzing penalty terms for constrained optimization problems\nand examining the probability landscapes of certain basis states.",
        "subjects": [
            "quant-ph",
            "cs.AR",
            "cs.ET"
        ],
        "authors": [
            "Tianyi Hao",
            "Zichang He",
            "Ruslan Shaydulin",
            "Marco Pistoia",
            "Swamit Tannu"
        ],
        "published": "2024-05-17T17:53:38Z"
    },
    {
        "title": "DINO as a von Mises-Fisher mixture model",
        "link": "http://arxiv.org/abs/2405.10939v1",
        "abstract": "Self-distillation methods using Siamese networks are popular for\nself-supervised pre-training. DINO is one such method based on a cross-entropy\nloss between $K$-dimensional probability vectors, obtained by applying a\nsoftmax function to the dot product between representations and learnt\nprototypes. Given the fact that the learned representations are\n$L^2$-normalized, we show that DINO and its derivatives, such as iBOT, can be\ninterpreted as a mixture model of von Mises-Fisher components. With this\ninterpretation, DINO assumes equal precision for all components when the\nprototypes are also $L^2$-normalized. Using this insight we propose DINO-vMF,\nthat adds appropriate normalization constants when computing the cluster\nassignment probabilities. Unlike DINO, DINO-vMF is stable also for the larger\nViT-Base model with unnormalized prototypes. We show that the added flexibility\nof the mixture model is beneficial in terms of better image representations.\nThe DINO-vMF pre-trained model consistently performs better than DINO on a\nrange of downstream tasks. We obtain similar improvements for iBOT-vMF vs iBOT\nand thereby show the relevance of our proposed modification also for other\nmethods derived from DINO.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Hariprasath Govindarajan",
            "Per Sidén",
            "Jacob Roll",
            "Fredrik Lindsten"
        ],
        "published": "2024-05-17T17:49:45Z"
    },
    {
        "title": "Observational Scaling Laws and the Predictability of Language Model\n  Performance",
        "link": "http://arxiv.org/abs/2405.10938v1",
        "abstract": "Understanding how language model performance varies with scale is critical to\nbenchmark and algorithm development. Scaling laws are one approach to building\nthis understanding, but the requirement of training models across many\ndifferent scales has limited their use. We propose an alternative,\nobservational approach that bypasses model training and instead builds scaling\nlaws from ~80 publically available models. Building a single scaling law from\nmultiple model families is challenging due to large variations in their\ntraining compute efficiencies and capabilities. However, we show that these\nvariations are consistent with a simple, generalized scaling law where language\nmodel performance is a function of a low-dimensional capability space, and\nmodel families only vary in their efficiency in converting training compute to\ncapabilities. Using this approach, we show the surprising predictability of\ncomplex scaling phenomena: we show that several emergent phenomena follow a\nsmooth, sigmoidal behavior and are predictable from small models; we show that\nthe agent performance of models such as GPT-4 can be precisely predicted from\nsimpler non-agentic benchmarks; and we show how to predict the impact of\npost-training interventions like Chain-of-Thought and Self-Consistency as\nlanguage model capabilities continue to improve.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL",
            "stat.ML"
        ],
        "authors": [
            "Yangjun Ruan",
            "Chris J. Maddison",
            "Tatsunori Hashimoto"
        ],
        "published": "2024-05-17T17:49:44Z"
    },
    {
        "title": "A Survey on Large Language Models with Multilingualism: Recent Advances\n  and New Frontiers",
        "link": "http://arxiv.org/abs/2405.10936v1",
        "abstract": "The rapid development of Large Language Models (LLMs) demonstrates remarkable\nmultilingual capabilities in natural language processing, attracting global\nattention in both academia and industry. To mitigate potential discrimination\nand enhance the overall usability and accessibility for diverse language user\ngroups, it is important for the development of language-fair technology.\nDespite the breakthroughs of LLMs, the investigation into the multilingual\nscenario remains insufficient, where a comprehensive survey to summarize recent\napproaches, developments, limitations, and potential solutions is desirable. To\nthis end, we provide a survey with multiple perspectives on the utilization of\nLLMs in the multilingual scenario. We first rethink the transitions between\nprevious and current research on pre-trained language models. Then we introduce\nseveral perspectives on the multilingualism of LLMs, including training and\ninference methods, model security, multi-domain with language culture, and\nusage of datasets. We also discuss the major challenges that arise in these\naspects, along with possible solutions. Besides, we highlight future research\ndirections that aim at further enhancing LLMs with multilingualism. The survey\naims to help the research community address multilingual problems and provide a\ncomprehensive understanding of the core concepts, key techniques, and latest\ndevelopments in multilingual natural language processing based on LLMs.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Kaiyu Huang",
            "Fengran Mo",
            "Hongliang Li",
            "You Li",
            "Yuanchi Zhang",
            "Weijian Yi",
            "Yulong Mao",
            "Jinchen Liu",
            "Yuzhuang Xu",
            "Jinan Xu",
            "Jian-Yun Nie",
            "Yang Liu"
        ],
        "published": "2024-05-17T17:47:39Z"
    },
    {
        "title": "Reconstruction of Manipulated Garment with Guided Deformation Prior",
        "link": "http://arxiv.org/abs/2405.10934v1",
        "abstract": "Modeling the shape of garments has received much attention, but most existing\napproaches assume the garments to be worn by someone, which constrains the\nrange of shapes they can assume. In this work, we address shape recovery when\ngarments are being manipulated instead of worn, which gives rise to an even\nlarger range of possible shapes. To this end, we leverage the implicit sewing\npatterns (ISP) model for garment modeling and extend it by adding a\ndiffusion-based deformation prior to represent these shapes. To recover 3D\ngarment shapes from incomplete 3D point clouds acquired when the garment is\nfolded, we map the points to UV space, in which our priors are learned, to\nproduce partial UV maps, and then fit the priors to recover complete UV maps\nand 2D to 3D mappings. Experimental results demonstrate the superior\nreconstruction accuracy of our method compared to previous ones, especially\nwhen dealing with large non-rigid deformations arising from the manipulations.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ren Li",
            "Corentin Dumery",
            "Zhantao Deng",
            "Pascal Fua"
        ],
        "published": "2024-05-17T17:39:29Z"
    },
    {
        "title": "Learning low-degree quantum objects",
        "link": "http://arxiv.org/abs/2405.10933v1",
        "abstract": "We consider the problem of learning low-degree quantum objects up to\n$\\varepsilon$-error in $\\ell_2$-distance. We show the following results: $(i)$\nunknown $n$-qubit degree-$d$ (in the Pauli basis) quantum channels and\nunitaries can be learned using $O(1/\\varepsilon^d)$ queries (independent of\n$n$), $(ii)$ polynomials $p:\\{-1,1\\}^n\\rightarrow [-1,1]$ arising from\n$d$-query quantum algorithms can be classically learned from\n$O((1/\\varepsilon)^d\\cdot \\log n)$ many random examples $(x,p(x))$ (which\nimplies learnability even for $d=O(\\log n)$), and $(iii)$ degree-$d$\npolynomials $p:\\{-1,1\\}^n\\to [-1,1]$ can be learned through\n$O(1/\\varepsilon^d)$ queries to a quantum unitary $U_p$ that block-encodes $p$.\nOur main technical contributions are new Bohnenblust-Hille inequalities for\nquantum channels and completely bounded~polynomials.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "cs.DS",
            "cs.LG",
            "math.FA"
        ],
        "authors": [
            "Srinivasan Arunachalam",
            "Arkopal Dutt",
            "Francisco Escudero Gutiérrez",
            "Carlos Palazuelos"
        ],
        "published": "2024-05-17T17:36:44Z"
    },
    {
        "title": "The Arabic Noun System Generation",
        "link": "http://arxiv.org/abs/2405.11014v1",
        "abstract": "In this paper, we show that the multiple-stem approach to nouns with a broken\nplural pattern allows for greater generalizations to be stated in the\nmorphological system. Such an approach dispenses with truncating/deleting rules\nand other complex rules that are required to account for the highly allomorphic\nbroken plural system. The generation of inflected sound nouns necessitates a\npre-specification of the affixes denoting the sound plural masculine and the\nsound plural feminine, namely uwna and aAt, in the lexicon. The first\nsubsection of section one provides an evaluation of some of the previous\nanalyses of the Arabic broken plural. We provide both linguistic and\nstatistical evidence against deriving broken plurals from the singular or the\nroot. In subsection two, we propose a multiple stem approach to the Arabic Noun\nPlural System within the Lexeme-based Morphology framework. In section two, we\nlook at the noun inflection of Arabic. Section three provides an implementation\nof the Arabic Noun system in MORPHE. In this context, we show how the\ngeneralizations discussed in the linguistic analysis section are captured in\nMorphe using the equivalencing nodes.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Abdelhadi Soudi",
            "Violetta Cavalli-Sforza",
            "Abderrahim Jamari"
        ],
        "published": "2024-05-17T17:33:10Z"
    },
    {
        "title": "FitNets: An Adaptive Framework to Learn Accurate Traffic Distributions",
        "link": "http://arxiv.org/abs/2405.10931v2",
        "abstract": "Learning precise distributions of traffic features (e.g., burst sizes, packet\ninter-arrival time) is still a largely unsolved problem despite being critical\nfor management tasks such as capacity planning or anomaly detection. A key\nlimitation nowadays is the lack of feedback between the control plane and the\ndata plane. Programmable data planes offer the opportunity to create systems\nthat let data- and control plane to work together, compensating their\nrespective shortcomings.\n  We present FitNets, an adaptive network monitoring system leveraging feedback\nbetween the data- and the control plane to learn accurate traffic\ndistributions. In the control plane, FitNets relies on Kernel Density\nEstimators which allow to provably learn distributions of any shape. In the\ndata plane, FitNets tests the accuracy of the learned distributions while\ndynamically adapting data collection to the observed distribution fitness,\nprioritizing under-fitted features.\n  We have implemented FitNets in Python and P4 (including on commercially\navailable programmable switches) and tested it on real and synthetic traffic\ntraces. FitNets is practical: it is able to estimate hundreds of distributions\nfrom up to 60 millions samples per second, while providing accurate error\nestimates and adapting to complex traffic patterns.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Alexander Dietmüller",
            "Albert Gran Alcoz",
            "Laurent Vanbever"
        ],
        "published": "2024-05-17T17:32:52Z"
    },
    {
        "title": "Submodular Information Selection for Hypothesis Testing with\n  Misclassification Penalties",
        "link": "http://arxiv.org/abs/2405.10930v1",
        "abstract": "We consider the problem of selecting an optimal subset of information sources\nfor a hypothesis testing/classification task where the goal is to identify the\ntrue state of the world from a finite set of hypotheses, based on finite\nobservation samples from the sources. In order to characterize the learning\nperformance, we propose a misclassification penalty framework, which enables\nnon-uniform treatment of different misclassification errors. In a centralized\nBayesian learning setting, we study two variants of the subset selection\nproblem: (i) selecting a minimum cost information set to ensure that the\nmaximum penalty of misclassifying the true hypothesis remains bounded and (ii)\nselecting an optimal information set under a limited budget to minimize the\nmaximum penalty of misclassifying the true hypothesis. Under mild assumptions,\nwe prove that the objective (or constraints) of these combinatorial\noptimization problems are weak (or approximate) submodular, and establish\nhigh-probability performance guarantees for greedy algorithms. Further, we\npropose an alternate metric for information set selection which is based on the\ntotal penalty of misclassification. We prove that this metric is submodular and\nestablish near-optimal guarantees for the greedy algorithms for both the\ninformation set selection problems. Finally, we present numerical simulations\nto validate our theoretical results over several randomly generated instances.",
        "subjects": [
            "stat.ML",
            "cs.CC",
            "cs.IT",
            "cs.LG",
            "math.IT",
            "math.OC"
        ],
        "authors": [
            "Jayanth Bhargav",
            "Mahsa Ghasemi",
            "Shreyas Sundaram"
        ],
        "published": "2024-05-17T17:31:02Z"
    },
    {
        "title": "The Local Interaction Basis: Identifying Computationally-Relevant and\n  Sparsely Interacting Features in Neural Networks",
        "link": "http://arxiv.org/abs/2405.10928v2",
        "abstract": "Mechanistic interpretability aims to understand the behavior of neural\nnetworks by reverse-engineering their internal computations. However, current\nmethods struggle to find clear interpretations of neural network activations\nbecause a decomposition of activations into computational features is missing.\nIndividual neurons or model components do not cleanly correspond to distinct\nfeatures or functions. We present a novel interpretability method that aims to\novercome this limitation by transforming the activations of the network into a\nnew basis - the Local Interaction Basis (LIB). LIB aims to identify\ncomputational features by removing irrelevant activations and interactions. Our\nmethod drops irrelevant activation directions and aligns the basis with the\nsingular vectors of the Jacobian matrix between adjacent layers. It also scales\nfeatures based on their importance for downstream computation, producing an\ninteraction graph that shows all computationally-relevant features and\ninteractions in a model. We evaluate the effectiveness of LIB on modular\naddition and CIFAR-10 models, finding that it identifies more\ncomputationally-relevant features that interact more sparsely, compared to\nprincipal component analysis. However, LIB does not yield substantial\nimprovements in interpretability or interaction sparsity when applied to\nlanguage models. We conclude that LIB is a promising theory-driven approach for\nanalyzing neural networks, but in its current form is not applicable to large\nlanguage models.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Lucius Bushnaq",
            "Stefan Heimersheim",
            "Nicholas Goldowsky-Dill",
            "Dan Braun",
            "Jake Mendel",
            "Kaarel Hänni",
            "Avery Griffin",
            "Jörn Stöhler",
            "Magdalena Wache",
            "Marius Hobbhahn"
        ],
        "published": "2024-05-17T17:27:19Z"
    },
    {
        "title": "Using Degeneracy in the Loss Landscape for Mechanistic Interpretability",
        "link": "http://arxiv.org/abs/2405.10927v2",
        "abstract": "Mechanistic Interpretability aims to reverse engineer the algorithms\nimplemented by neural networks by studying their weights and activations. An\nobstacle to reverse engineering neural networks is that many of the parameters\ninside a network are not involved in the computation being implemented by the\nnetwork. These degenerate parameters may obfuscate internal structure. Singular\nlearning theory teaches us that neural network parameterizations are biased\ntowards being more degenerate, and parameterizations with more degeneracy are\nlikely to generalize further. We identify 3 ways that network parameters can be\ndegenerate: linear dependence between activations in a layer; linear dependence\nbetween gradients passed back to a layer; ReLUs which fire on the same subset\nof datapoints. We also present a heuristic argument that modular networks are\nlikely to be more degenerate, and we develop a metric for identifying modules\nin a network that is based on this argument. We propose that if we can\nrepresent a neural network in a way that is invariant to reparameterizations\nthat exploit the degeneracies, then this representation is likely to be more\ninterpretable, and we provide some evidence that such a representation is\nlikely to have sparser interactions. We introduce the Interaction Basis, a\ntractable technique to obtain a representation that is invariant to\ndegeneracies from linear dependence of activations or Jacobians.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Lucius Bushnaq",
            "Jake Mendel",
            "Stefan Heimersheim",
            "Dan Braun",
            "Nicholas Goldowsky-Dill",
            "Kaarel Hänni",
            "Cindy Wu",
            "Marius Hobbhahn"
        ],
        "published": "2024-05-17T17:26:33Z"
    },
    {
        "title": "High-dimensional multiple imputation (HDMI) for partially observed\n  confounders including natural language processing-derived auxiliary\n  covariates",
        "link": "http://arxiv.org/abs/2405.10925v1",
        "abstract": "Multiple imputation (MI) models can be improved by including auxiliary\ncovariates (AC), but their performance in high-dimensional data is not well\nunderstood. We aimed to develop and compare high-dimensional MI (HDMI)\napproaches using structured and natural language processing (NLP)-derived AC in\nstudies with partially observed confounders. We conducted a plasmode simulation\nstudy using data from opioid vs. non-steroidal anti-inflammatory drug (NSAID)\ninitiators (X) with observed serum creatinine labs (Z2) and time-to-acute\nkidney injury as outcome. We simulated 100 cohorts with a null treatment\neffect, including X, Z2, atrial fibrillation (U), and 13 other\ninvestigator-derived confounders (Z1) in the outcome generation. We then\nimposed missingness (MZ2) on 50% of Z2 measurements as a function of Z2 and U\nand created different HDMI candidate AC using structured and NLP-derived\nfeatures. We mimicked scenarios where U was unobserved by omitting it from all\nAC candidate sets. Using LASSO, we data-adaptively selected HDMI covariates\nassociated with Z2 and MZ2 for MI, and with U to include in propensity score\nmodels. The treatment effect was estimated following propensity score matching\nin MI datasets and we benchmarked HDMI approaches against a baseline imputation\nand complete case analysis with Z1 only. HDMI using claims data showed the\nlowest bias (0.072). Combining claims and sentence embeddings led to an\nimprovement in the efficiency displaying the lowest root-mean-squared-error\n(0.173) and coverage (94%). NLP-derived AC alone did not perform better than\nbaseline MI. HDMI approaches may decrease bias in studies with partially\nobserved confounders where missingness depends on unobserved factors.",
        "subjects": [
            "stat.ME",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Janick Weberpals",
            "Pamela A. Shaw",
            "Kueiyu Joshua Lin",
            "Richard Wyss",
            "Joseph M Plasek",
            "Li Zhou",
            "Kerry Ngan",
            "Thomas DeRamus",
            "Sudha R. Raman",
            "Bradley G. Hammill",
            "Hana Lee",
            "Sengwee Toh",
            "John G. Connolly",
            "Kimberly J. Dandreo",
            "Fang Tian",
            "Wei Liu",
            "Jie Li",
            "José J. Hernández-Muñoz",
            "Sebastian Schneeweiss",
            "Rishi J. Desai"
        ],
        "published": "2024-05-17T17:24:52Z"
    },
    {
        "title": "Boosting Few-Pixel Robustness Verification via Covering Verification\n  Designs",
        "link": "http://arxiv.org/abs/2405.10924v1",
        "abstract": "Proving local robustness is crucial to increase the reliability of neural\nnetworks. While many verifiers prove robustness in $L_\\infty$ $\\epsilon$-balls,\nvery little work deals with robustness verification in $L_0$ $\\epsilon$-balls,\ncapturing robustness to few pixel attacks. This verification introduces a\ncombinatorial challenge, because the space of pixels to perturb is discrete and\nof exponential size. A previous work relies on covering designs to identify\nsets for defining $L_\\infty$ neighborhoods, which if proven robust imply that\nthe $L_0$ $\\epsilon$-ball is robust. However, the number of neighborhoods to\nverify remains very high, leading to a high analysis time. We propose covering\nverification designs, a combinatorial design that tailors effective but\nanalysis-incompatible coverings to $L_0$ robustness verification. The challenge\nis that computing a covering verification design introduces a high time and\nmemory overhead, which is intensified in our setting, where multiple candidate\ncoverings are required to identify how to reduce the overall analysis time. We\nintroduce CoVerD, an $L_0$ robustness verifier that selects between different\ncandidate coverings without constructing them, but by predicting their block\nsize distribution. This prediction relies on a theorem providing closed-form\nexpressions for the mean and variance of this distribution. CoVerD constructs\nthe chosen covering verification design on-the-fly, while keeping the memory\nconsumption minimal and enabling to parallelize the analysis. The experimental\nresults show that CoVerD reduces the verification time on average by up to 5.1x\ncompared to prior work and that it scales to larger $L_0$ $\\epsilon$-balls.",
        "subjects": [
            "cs.LG",
            "cs.LO",
            "cs.PL"
        ],
        "authors": [
            "Yuval Shapira",
            "Naor Wiesel",
            "Shahar Shabelman",
            "Dana Drachsler-Cohen"
        ],
        "published": "2024-05-17T17:23:36Z"
    },
    {
        "title": "Randomized Householder QR",
        "link": "http://arxiv.org/abs/2405.10923v2",
        "abstract": "This paper introduces a randomized Householder QR factorization (RHQR). This\nfactorization can be used to obtain a well conditioned basis of a vector space\nand thus can be employed in a variety of applications. The RHQR factorization\nof the input matrix $W$ is equivalent to the standard Householder QR\nfactorization of matrix $\\Psi W$, where $\\Psi$ is a sketching matrix that can\nbe obtained from any subspace embedding technique. For this reason, the RHQR\nfactorization can also be reconstructed from the Householder QR factorization\nof the sketched problem, yielding a single-synchronization randomized QR\nfactorization (recRHQR). In most contexts, left-looking RHQR requires a single\nsynchronization per iteration, with half the computational cost of Householder\nQR, and a similar cost to Randomized Gram-Schmidt (RGS) overall. We discuss the\nusage of RHQR factorization in the Arnoldi process and then in GMRES, showing\nthus how it can be used in Krylov subspace methods to solve systems of linear\nequations. Based on Charles Sheffield's connection between Householder QR and\nModified Gram-Schmidt (MGS), a BLAS2-RGS is also derived. A finite precision\nanalysis shows that, under mild probabilistic assumptions, the RHQR\nfactorization of the input matrix $W$ inherits the stability of the Householder\nQR factorization, producing a well-conditioned basis and a columnwise backward\nstable factorization, all independently of the condition number of the input\n$W$, and with the accuracy of the sketching step. We study the subsampled\nrandomized Hadamard transform (SRHT) as a very stable sketching technique.\n  Numerical experiments show that RHQR produces a well conditioned basis whose\nsketch is numerically orthogonal and an accurate factorization, even for the\nmost difficult inputs and with high-dimensional operations made in\nhalf-precision.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Laura Grigori",
            "Edouard Timsit"
        ],
        "published": "2024-05-17T17:22:14Z"
    },
    {
        "title": "GenToC: Leveraging Partially-Labeled Data for Product Attribute-Value\n  Identification",
        "link": "http://arxiv.org/abs/2405.10918v1",
        "abstract": "In the e-commerce domain, the accurate extraction of attribute-value pairs\nfrom product listings (e.g., Brand: Apple) is crucial for enhancing search and\nrecommendation systems. The automation of this extraction process is\nchallenging due to the vast diversity of product categories and their\nrespective attributes, compounded by the lack of extensive, accurately\nannotated training datasets and the demand for low latency to meet the\nreal-time needs of e-commerce platforms. To address these challenges, we\nintroduce GenToC, a novel two-stage model for extracting attribute-value pairs\nfrom product titles. GenToC is designed to train with partially-labeled data,\nleveraging incomplete attribute-value pairs and obviating the need for a fully\nannotated dataset. Moreover, we introduce a bootstrapping method that enables\nGenToC to progressively refine and expand its training dataset. This\nenhancement substantially improves the quality of data available for training\nother neural network models that are typically faster but are inherently less\ncapable than GenToC in terms of their capacity to handle partially-labeled\ndata. By supplying an enriched dataset for training, GenToC significantly\nadvances the performance of these alternative models, making them more suitable\nfor real-time deployment. Our results highlight the unique capability of GenToC\nto learn from a limited set of labeled data and to contribute to the training\nof more efficient models, marking a significant leap forward in the automated\nextraction of attribute-value pairs from product titles. GenToC has been\nsuccessfully integrated into India's largest B2B e-commerce platform,\nIndiaMART.com, achieving a significant increase of 21.1% in recall over the\nexisting deployed system while maintaining a high precision of 89.5% in this\nchallenging task.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR",
            "cs.LG"
        ],
        "authors": [
            "D. Subhalingam",
            "Keshav Kolluru",
            " Mausam",
            "Saurabh Singal"
        ],
        "published": "2024-05-17T17:09:45Z"
    },
    {
        "title": "Nearly self-similar blowup of generalized axisymmetric Navier-Stokes and\n  Boussinesq equations",
        "link": "http://arxiv.org/abs/2405.10916v1",
        "abstract": "We perform numerical investigation of nearly self-similar blowup of\ngeneralized axisymmetric Navier-Stokes equations and Boussinesq system with a\ntime-dependent fractional dimension. The dynamic change of the space dimension\nis proportional to the ratio R(t)/Z(t), where (R(t),Z(t)) is the position at\nwhich the maximum vorticity achieves its global maximum. This choice of space\ndimension is to ensure that the advection along the r-direction has the same\nscaling as that along the z-direction, thus preventing formation of two-scale\nsolution structure. For the generalized axisymmetric Navier-Stokes equations\nwith solution dependent viscosity, we show that the solution develops a\nself-similar blowup with dimension equal to 3.188 and the self-similar profile\nsatisfies the axisymmetric Navier-Stokes equations with constant viscosity. We\nalso study the nearly self-similar blowup of the axisymmetric Boussinesq system\nwith constant viscosity. The generalized axisymmetric Boussinesq system\npreserves almost all the known properties of the 3D Navier-Stokes equations\nexcept for the conservation of angular momentum. We present convincing\nnumerical evidence that the generalized axisymmetric Boussinesq system develops\na stable nearly self-similar blowup solution with maximum vorticity increased\nby O(10^{30}).",
        "subjects": [
            "math.AP",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Thomas Y. Hou"
        ],
        "published": "2024-05-17T17:07:43Z"
    },
    {
        "title": "Identifying Functionally Important Features with End-to-End Sparse\n  Dictionary Learning",
        "link": "http://arxiv.org/abs/2405.12241v2",
        "abstract": "Identifying the features learned by neural networks is a core challenge in\nmechanistic interpretability. Sparse autoencoders (SAEs), which learn a sparse,\novercomplete dictionary that reconstructs a network's internal activations,\nhave been used to identify these features. However, SAEs may learn more about\nthe structure of the datatset than the computational structure of the network.\nThere is therefore only indirect reason to believe that the directions found in\nthese dictionaries are functionally important to the network. We propose\nend-to-end (e2e) sparse dictionary learning, a method for training SAEs that\nensures the features learned are functionally important by minimizing the KL\ndivergence between the output distributions of the original model and the model\nwith SAE activations inserted. Compared to standard SAEs, e2e SAEs offer a\nPareto improvement: They explain more network performance, require fewer total\nfeatures, and require fewer simultaneously active features per datapoint, all\nwith no cost to interpretability. We explore geometric and qualitative\ndifferences between e2e SAE features and standard SAE features. E2e dictionary\nlearning brings us closer to methods that can explain network behavior\nconcisely and accurately. We release our library for training e2e SAEs and\nreproducing our analysis at https://github.com/ApolloResearch/e2e_sae",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Dan Braun",
            "Jordan Taylor",
            "Nicholas Goldowsky-Dill",
            "Lee Sharkey"
        ],
        "published": "2024-05-17T17:03:46Z"
    },
    {
        "title": "Blackbox Adaptation for Medical Image Segmentation",
        "link": "http://arxiv.org/abs/2405.10913v1",
        "abstract": "In recent years, various large foundation models have been proposed for image\nsegmentation. There models are often trained on large amounts of data\ncorresponding to general computer vision tasks. Hence, these models do not\nperform well on medical data. There have been some attempts in the literature\nto perform parameter-efficient finetuning of such foundation models for medical\nimage segmentation. However, these approaches assume that all the parameters of\nthe model are available for adaptation. But, in many cases, these models are\nreleased as APIs or blackboxes, with no or limited access to the model\nparameters and data. In addition, finetuning methods also require a significant\namount of compute, which may not be available for the downstream task. At the\nsame time, medical data can't be shared with third-party agents for finetuning\ndue to privacy reasons. To tackle these challenges, we pioneer a blackbox\nadaptation technique for prompted medical image segmentation, called BAPS. BAPS\nhas two components - (i) An Image-Prompt decoder (IP decoder) module that\ngenerates visual prompts given an image and a prompt, and (ii) A Zero Order\nOptimization (ZOO) Method, called SPSA-GC that is used to update the IP decoder\nwithout the need for backpropagating through the foundation model. Thus, our\nmethod does not require any knowledge about the foundation model's weights or\ngradients. We test BAPS on four different modalities and show that our method\ncan improve the original model's performance by around 4%.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jay N. Paranjape",
            "Shameema Sikder",
            "S. Swaroop Vedula",
            "Vishal M. Patel"
        ],
        "published": "2024-05-17T17:02:04Z"
    },
    {
        "title": "Synthesis of Temporal Causality",
        "link": "http://arxiv.org/abs/2405.10912v1",
        "abstract": "We present an automata-based algorithm to synthesize omega-regular causes for\nomega-regular effects on executions of a reactive system, such as\ncounterexamples uncovered by a model checker. Our theory is a generalization of\ntemporal causality, which has recently been proposed as a framework for drawing\ncausal relationships between trace properties on a given trace. So far,\nalgorithms exist only for verifying a single causal relationship and, as an\nextension, cause synthesis through enumeration, which is complete only for a\nsmall fragment of effect properties. This work presents the first complete\ncause-synthesis algorithm for the class of omega-regular effects. We show that\nin this case, causes are guaranteed to be omega-regular themselves and can be\ncomputed as, e.g., nondeterministic B\\\"uchi automata. We demonstrate the\npractical feasibility of this algorithm with a prototype tool and evaluate its\nperformance for cause synthesis and cause checking.",
        "subjects": [
            "cs.LO"
        ],
        "authors": [
            "Bernd Finkbeiner",
            "Hadar Frenkel",
            "Niklas Metzger",
            "Julian Siber"
        ],
        "published": "2024-05-17T17:00:26Z"
    },
    {
        "title": "ARDDQN: Attention Recurrent Double Deep Q-Network for UAV Coverage Path\n  Planning and Data Harvesting",
        "link": "http://arxiv.org/abs/2405.11013v1",
        "abstract": "Unmanned Aerial Vehicles (UAVs) have gained popularity in data harvesting\n(DH) and coverage path planning (CPP) to survey a given area efficiently and\ncollect data from aerial perspectives, while data harvesting aims to gather\ninformation from various Internet of Things (IoT) sensor devices, coverage path\nplanning guarantees that every location within the designated area is visited\nwith minimal redundancy and maximum efficiency. We propose the ARDDQN\n(Attention-based Recurrent Double Deep Q Network), which integrates double deep\nQ-networks (DDQN) with recurrent neural networks (RNNs) and an attention\nmechanism to generate path coverage choices that maximize data collection from\nIoT devices and to learn a control scheme for the UAV that generalizes energy\nrestrictions. We employ a structured environment map comprising a compressed\nglobal environment map and a local map showing the UAV agent's locate\nefficiently scaling to large environments. We have compared Long short-term\nmemory (LSTM), Bi-directional long short-term memory (Bi-LSTM), Gated recurrent\nunit (GRU) and Bidirectional gated recurrent unit (Bi-GRU) as recurrent neural\nnetworks (RNN) to the result without RNN We propose integrating the LSTM with\nthe Attention mechanism to the existing DDQN model, which works best on\nevolution parameters, i.e., data collection, landing, and coverage ratios for\nthe CPP and data harvesting scenarios.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Praveen Kumar",
            " Priyadarshni",
            "Rajiv Misra"
        ],
        "published": "2024-05-17T16:53:19Z"
    },
    {
        "title": "POSTER: Testing network-based RTK for GNSS receiver security",
        "link": "http://arxiv.org/abs/2405.10906v1",
        "abstract": "Global Navigation Satellite Systems (GNSS) provide precise location, while\nReal Time Kinematics (RTK) allow mobile receivers (termed rovers), leveraging\nfixed stations, to correct errors in their Position Navigation and Timing (PNT)\nsolution. This allows compensating for multi-path effects, ionospheric errors,\nand observation biases, enabling consumer receivers to achieve centimeter-level\naccuracy. While network distribution of correction streams can be protected\nwith common secure networking practices, the reference stations can still be\nattacked by GNSS spoofing or jamming. This work investigates (i) the effect RTK\nreference station spoofing has on the rover's PNT solution quality and (ii) the\npotential countermeasures towards hardening the RTK infrastructure.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Marco Spanghero",
            "Panos Papadimitratos"
        ],
        "published": "2024-05-17T16:53:04Z"
    },
    {
        "title": "Broadening Privacy and Surveillance: Eliciting Interconnected Values\n  with a Scenarios Workbook on Smart Home Cameras",
        "link": "http://dx.doi.org/10.1145/3563657.3596012",
        "abstract": "We use a design workbook of speculative scenarios as a values elicitation\nactivity with 14 participants. The workbook depicts use case scenarios with\nsmart home camera technologies that involve surveillance and uneven power\nrelations. The scenarios were initially designed by the researchers to explore\nscenarios of privacy and surveillance within three social relationships\ninvolving \"primary\" and \"non-primary\" users: Parents-Children,\nLandlords-Tenants, and Residents-Domestic Workers. When the scenarios were\nutilized as part of a values elicitation activity with participants, we found\nthat they reflected on a broader set of interconnected social values beyond\nprivacy and surveillance, including autonomy and agency, physical safety,\nproperty rights, trust and accountability, and fairness. The paper suggests\nthat future research about ethical issues in smart homes should conceptualize\nprivacy as interconnected with a broader set of social values (which can align\nor be in tension with privacy), and reflects on considerations for doing\nresearch with non-primary users.",
        "subjects": [
            "cs.HC",
            "cs.CY"
        ],
        "authors": [
            "Richmond Y. Wong",
            "Jason Caleb Valdez",
            "Ashten Alexander",
            "Ariel Chiang",
            "Olivia Quesada",
            "James Pierce"
        ],
        "published": "2024-05-17T16:50:49Z"
    },
    {
        "title": "Where do developers admit their security-related concerns?",
        "link": "http://arxiv.org/abs/2405.10902v1",
        "abstract": "Developers use different means to document the security concerns of their\ncode. Because of all of these opportunities, they may forget where the\ninformation is stored, or others may not be aware of it, and leave it\nunmaintained for so long that it becomes obsolete, if not useless. In this\nwork, we analyzed different sources of code documentation from four\nlarge-scale, real-world, open-source projects in an industrial setting to\nunderstand where developers report their security concerns. In particular, we\nmanually inspected 2.559 instances taken from source code comments, commit\nmessages, and issue trackers. Overall, we found that developers prefer to\ndocument security concerns in source code comments and issue trackers. We also\nfound that the longer the comments stay unfixed, the more likely they remain\nunfixed. Thus, to create awareness among developers, we implemented a pipeline\nto remind them about the introduction or removal of comments pointing to a\nsecurity problem.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Moritz Mock",
            "Thomas Forrer",
            "Barbara Russo"
        ],
        "published": "2024-05-17T16:43:58Z"
    },
    {
        "title": "Efficient Line Search Method Based on Regression and Uncertainty\n  Quantification",
        "link": "http://arxiv.org/abs/2405.10897v1",
        "abstract": "Unconstrained optimization problems are typically solved using iterative\nmethods, which often depend on line search techniques to determine optimal step\nlengths in each iteration. This paper introduces a novel line search approach.\nTraditional line search methods, aimed at determining optimal step lengths,\noften discard valuable data from the search process and focus on refining step\nlength intervals. This paper proposes a more efficient method using Bayesian\noptimization, which utilizes all available data points, i.e., function values\nand gradients, to guide the search towards a potential global minimum. This new\napproach more effectively explores the search space, leading to better solution\nquality. It is also easy to implement and integrate into existing frameworks.\nTested on the challenging CUTEst test set, it demonstrates superior performance\ncompared to existing state-of-the-art methods, solving more problems to\noptimality with equivalent resource usage.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "authors": [
            "Sören Laue",
            "Tomislav Prusina"
        ],
        "published": "2024-05-17T16:35:20Z"
    },
    {
        "title": "Labelled Well Quasi Ordered Classes of Bounded Linear Clique Width",
        "link": "http://arxiv.org/abs/2405.10894v1",
        "abstract": "We provide an algorithm to decide whether a class of finite graphs that has\nbounded linear clique width is well-quasi-ordered by the induced subgraph\nrelation in the presence of a labelling of the vertices, where the class is\ngiven by an $\\mathsf{MSO}$-transduction from finite words. This study leverages\ntools from automata theory, and the proof scheme allows to derive a weak\nversion of the Pouzet conjecture for classes of bounded linear clique-width. We\nalso provide an automata based characterization of which classes of\n$\\mathsf{NLC}$ graphs are labelled-well-quasi-ordered by the induced subgraph\nrelation, where we recover the results of Daligault Rao and Thomass\\'e by\nencoding the models into trees with the gap embedding relation of Dershowitz\nand Tzameret.",
        "subjects": [
            "cs.LO"
        ],
        "authors": [
            "Aliaume Lopez"
        ],
        "published": "2024-05-17T16:33:43Z"
    },
    {
        "title": "COGNET-MD, an evaluation framework and dataset for Large Language Model\n  benchmarks in the medical domain",
        "link": "http://arxiv.org/abs/2405.10893v1",
        "abstract": "Large Language Models (LLMs) constitute a breakthrough state-of-the-art\nArtificial Intelligence (AI) technology which is rapidly evolving and promises\nto aid in medical diagnosis either by assisting doctors or by simulating a\ndoctor's workflow in more advanced and complex implementations. In this\ntechnical paper, we outline Cognitive Network Evaluation Toolkit for Medical\nDomains (COGNET-MD), which constitutes a novel benchmark for LLM evaluation in\nthe medical domain. Specifically, we propose a scoring-framework with increased\ndifficulty to assess the ability of LLMs in interpreting medical text. The\nproposed framework is accompanied with a database of Multiple Choice Quizzes\n(MCQs). To ensure alignment with current medical trends and enhance safety,\nusefulness, and applicability, these MCQs have been constructed in\ncollaboration with several associated medical experts in various medical\ndomains and are characterized by varying degrees of difficulty. The current\n(first) version of the database includes the medical domains of Psychiatry,\nDentistry, Pulmonology, Dermatology and Endocrinology, but it will be\ncontinuously extended and expanded to include additional medical domains.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Dimitrios P. Panagoulias",
            "Persephone Papatheodosiou",
            "Anastasios P. Palamidas",
            "Mattheos Sanoudos",
            "Evridiki Tsoureli-Nikita",
            "Maria Virvou",
            "George A. Tsihrintzis"
        ],
        "published": "2024-05-17T16:31:56Z"
    },
    {
        "title": "Neuroscheduling for Remote Estimation",
        "link": "http://arxiv.org/abs/2405.10892v1",
        "abstract": "Many modern distributed systems consist of devices that generate more data\nthan what can be transmitted via a communication link in near real time with\nhigh-fidelity. We consider the scheduling problem in which a device has access\nto multiple data sources, but at any moment, only one of them is revealed in\nreal-time to a remote receiver. Even when the sources are Gaussian, and the\nfidelity criterion is the mean squared error, the globally optimal data\nselection strategy is not known. We propose a data-driven methodology to search\nfor the elusive optimal solution using linear function approximation approach\ncalled neuroscheduling and establish necessary and sufficient conditions for\nthe optimal scheduler to not over fit training data. Additionally, we present\nseveral numerical results that show that the globally optimal scheduler and\nestimator pair to the Gaussian case are nonlinear.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Marcos M. Vasconcelos",
            "Yifei Zhang"
        ],
        "published": "2024-05-17T16:31:44Z"
    },
    {
        "title": "Prioritising GitHub Priority Labels",
        "link": "http://dx.doi.org/10.1145/3663533.3664041",
        "abstract": "Communities on GitHub often use issue labels as a way of triaging issues by\nassigning them priority ratings based on how urgently they should be addressed.\nThe labels used are determined by the repository contributors and not\nstandardised by GitHub. This makes it difficult for priority-related reasoning\nacross repositories for both researchers and contributors. Previous work shows\ninterest in how issues are labelled and what the consequences for those labels\nare. For instance, some previous work has used clustering models and natural\nlanguage processing to categorise labels without a particular emphasis on\npriority. With this publication, we introduce a unique data set of 812 manually\ncategorised labels pertaining to priority; normalised and ranked as low-,\nmedium-, or high-priority. To provide an example of how this data set could be\nused, we have created a tool for GitHub contributors that will create a list of\nthe highest priority issues from the repositories to which they contribute. We\nhave released the data set and the tool for anyone to use on Zenodo because we\nhope that this will help the open source community address high-priority issues\nmore effectively and inspire other uses.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "James Caddy",
            "Christoph Treude"
        ],
        "published": "2024-05-17T16:30:35Z"
    },
    {
        "title": "A Versatile Framework for Analyzing Galaxy Image Data by Implanting\n  Human-in-the-loop on a Large Vision Model",
        "link": "http://arxiv.org/abs/2405.10890v1",
        "abstract": "The exponential growth of astronomical datasets provides an unprecedented\nopportunity for humans to gain insight into the Universe. However, effectively\nanalyzing this vast amount of data poses a significant challenge. Astronomers\nare turning to deep learning techniques to address this, but the methods are\nlimited by their specific training sets, leading to considerable duplicate\nworkloads too. Hence, as an example to present how to overcome the issue, we\nbuilt a framework for general analysis of galaxy images, based on a large\nvision model (LVM) plus downstream tasks (DST), including galaxy morphological\nclassification, image restoration, object detection, parameter extraction, and\nmore. Considering the low signal-to-noise ratio of galaxy images and the\nimbalanced distribution of galaxy categories, we have incorporated a\nHuman-in-the-loop (HITL) module into our large vision model, which leverages\nhuman knowledge to enhance the reliability and interpretability of processing\ngalaxy images interactively. The proposed framework exhibits notable few-shot\nlearning capabilities and versatile adaptability to all the abovementioned\ntasks on galaxy images in the DESI legacy imaging surveys. Expressly, for\nobject detection, trained by 1000 data points, our DST upon the LVM achieves an\naccuracy of 96.7%, while ResNet50 plus Mask R-CNN gives an accuracy of 93.1%;\nfor morphology classification, to obtain AUC ~0.9, LVM plus DST and HITL only\nrequests 1/50 training sets compared to ResNet18. Expectedly, multimodal data\ncan be integrated similarly, which opens up possibilities for conducting joint\nanalyses with datasets spanning diverse domains in the era of multi-message\nastronomy.",
        "subjects": [
            "astro-ph.IM",
            "astro-ph.GA",
            "cs.AI"
        ],
        "authors": [
            "Mingxiang Fu",
            "Yu Song",
            "Jiameng Lv",
            "Liang Cao",
            "Peng Jia",
            "Nan Li",
            "Xiangru Li",
            "Jifeng Liu",
            "A-Li Luo",
            "Bo Qiu",
            "Shiyin Shen",
            "Liangping Tu",
            "Lili Wang",
            "Shoulin Wei",
            "Haifeng Yang",
            "Zhenping Yi",
            "Zhiqiang Zou"
        ],
        "published": "2024-05-17T16:29:27Z"
    },
    {
        "title": "Preservation theorems on sparse classes revisited",
        "link": "http://arxiv.org/abs/2405.10887v2",
        "abstract": "We revisit the work studying homomorphism preservation for first-order logic\nin sparse classes of structures initiated in [Atserias et al., JACM 2006] and\n[Dawar, JCSS 2010]. These established that first-order logic has the\nhomomorphism preservation property in any sparse class that is monotone and\naddable. It turns out that the assumption of addability is not strong enough\nfor the proofs given. We demonstrate this by constructing classes of graphs of\nbounded treewidth which are monotone and addable but fail to have homomorphism\npreservation. We also show that homomorphism preservation fails on the class of\nplanar graphs. On the other hand, the proofs of homomorphism preservation can\nbe recovered by replacing addability by a stronger condition of amalgamation\nover bottlenecks. This is analogous to a similar condition formulated for\nextension preservation in [Atserias et al., SiCOMP 2008].",
        "subjects": [
            "cs.LO",
            "math.LO",
            "03B70, 03C13, 68Q19, 05C10"
        ],
        "authors": [
            "Anuj Dawar",
            "Ioannis Eleftheriadis"
        ],
        "published": "2024-05-17T16:25:40Z"
    },
    {
        "title": "FA-Depth: Toward Fast and Accurate Self-supervised Monocular Depth\n  Estimation",
        "link": "http://arxiv.org/abs/2405.10885v1",
        "abstract": "Most existing methods often rely on complex models to predict scene depth\nwith high accuracy, resulting in slow inference that is not conducive to\ndeployment. To better balance precision and speed, we first designed SmallDepth\nbased on sparsity. Second, to enhance the feature representation ability of\nSmallDepth during training under the condition of equal complexity during\ninference, we propose an equivalent transformation module(ETM). Third, to\nimprove the ability of each layer in the case of a fixed SmallDepth to perceive\ndifferent context information and improve the robustness of SmallDepth to the\nleft-right direction and illumination changes, we propose pyramid loss. Fourth,\nto further improve the accuracy of SmallDepth, we utilized the proposed\nfunction approximation loss (APX) to transfer knowledge in the pretrained\nHQDecv2, obtained by optimizing the previous HQDec to address grid artifacts in\nsome regions, to SmallDepth. Extensive experiments demonstrate that each\nproposed component improves the precision of SmallDepth without changing the\ncomplexity of SmallDepth during inference, and the developed approach achieves\nstate-of-the-art results on KITTI at an inference speed of more than 500 frames\nper second and with approximately 2 M parameters. The code and models will be\npublicly available at https://github.com/fwucas/FA-Depth.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Fei Wang",
            "Jun Cheng"
        ],
        "published": "2024-05-17T16:22:52Z"
    },
    {
        "title": "Application of Artificial Intelligence in Schizophrenia Rehabilitation\n  Management: Systematic Literature Review",
        "link": "http://arxiv.org/abs/2405.10883v1",
        "abstract": "This review aims to systematically assess the current status and prospects of\nartificial intelligence (AI) in the rehabilitation management of patients with\nschizophrenia and their impact on the rehabilitation process. We selected 70\nstudies from 2012 to the present, focusing on application, technology\ncategories, products, and data types of machine learning, deep learning,\nreinforcement learning, and other technologies in mental health interventions\nand management. The results indicate that AI can be widely used in symptom\nmonitoring, relapse risk prediction, and rehabilitation treatment by analyzing\necological momentary assessment, behavioral, and speech data. This review\nfurther explores the potential challenges and future directions of emerging\nproducts, technologies, and analytical methods based on AI, such as social\nmedia analysis, serious games, and large language models in rehabilitation. In\nsummary, this study systematically reviews the application status of AI in\nschizophrenia rehabilitation management and provides valuable insights and\nrecommendations for future research paths.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Hongyi Yang",
            "Fangyuan Chang",
            "Dian Zhu",
            "Muroi Fumie",
            "Zhao Liu"
        ],
        "published": "2024-05-17T16:20:34Z"
    },
    {
        "title": "The MESA Security Model 2.0: A Dynamic Framework for Mitigating Stealth\n  Data Exfiltration",
        "link": "http://arxiv.org/abs/2405.10880v1",
        "abstract": "The rising complexity of cyber threats calls for a comprehensive reassessment\nof current security frameworks in business environments. This research focuses\non Stealth Data Exfiltration, a significant cyber threat characterized by\ncovert infiltration, extended undetectability, and unauthorized dissemination\nof confidential data. Our findings reveal that conventional defense-in-depth\nstrategies often fall short in combating these sophisticated threats,\nhighlighting the immediate need for a shift in information risk management\nacross businesses. The evolving nature of cyber threats, driven by advancements\nin techniques such as social engineering, multi-vector attacks, and Generative\nAI, underscores the need for robust, adaptable, and comprehensive security\nstrategies. As we navigate this complex landscape, it is crucial to anticipate\npotential threats and continually update our defenses. We propose a shift from\ntraditional perimeter-based, prevention-focused models, which depend on a\nstatic attack surface, to a more dynamic framework that prepares for inevitable\nbreaches. This suggested model, known as MESA 2.0 Security Model, prioritizes\nswift detection, immediate response, and ongoing resilience, thereby enhancing\nan organizations ability to promptly identify and neutralize threats,\nsignificantly reducing the consequences of security breaches. This study\nsuggests that businesses adopt a forward-thinking and adaptable approach to\nsecurity management to stay ahead of the ever-changing cyber threat landscape.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Sanjeev Pratap Singh",
            "Naveed Afzal"
        ],
        "published": "2024-05-17T16:14:45Z"
    },
    {
        "title": "One registration is worth two segmentations",
        "link": "http://arxiv.org/abs/2405.10879v1",
        "abstract": "The goal of image registration is to establish spatial correspondence between\ntwo or more images, traditionally through dense displacement fields (DDFs) or\nparametric transformations (e.g., rigid, affine, and splines). Rethinking the\nexisting paradigms of achieving alignment via spatial transformations, we\nuncover an alternative but more intuitive correspondence representation: a set\nof corresponding regions-of-interest (ROI) pairs, which we demonstrate to have\nsufficient representational capability as other correspondence representation\nmethods.Further, it is neither necessary nor sufficient for these ROIs to hold\nspecific anatomical or semantic significance. In turn, we formulate image\nregistration as searching for the same set of corresponding ROIs from both\nmoving and fixed images - in other words, two multi-class segmentation tasks on\na pair of images. For a general-purpose and practical implementation, we\nintegrate the segment anything model (SAM) into our proposed algorithms,\nresulting in a SAM-enabled registration (SAMReg) that does not require any\ntraining data, gradient-based fine-tuning or engineered prompts. We\nexperimentally show that the proposed SAMReg is capable of segmenting and\nmatching multiple ROI pairs, which establish sufficiently accurate\ncorrespondences, in three clinical applications of registering prostate MR,\ncardiac MR and abdominal CT images. Based on metrics including Dice and target\nregistration errors on anatomical structures, the proposed registration\noutperforms both intensity-based iterative algorithms and DDF-predicting\nlearning-based networks, even yielding competitive performance with\nweakly-supervised registration which requires fully-segmented training data.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Shiqi Huang",
            "Tingfa Xu",
            "Ziyi Shen",
            "Shaheer Ullah Saeed",
            "Wen Yan",
            "Dean Barratt",
            "Yipeng Hu"
        ],
        "published": "2024-05-17T16:14:32Z"
    },
    {
        "title": "WEITS: A Wavelet-enhanced residual framework for interpretable time\n  series forecasting",
        "link": "http://arxiv.org/abs/2405.10877v1",
        "abstract": "Time series (TS) forecasting has been an unprecedentedly popular problem in\nrecent years, with ubiquitous applications in both scientific and business\nfields. Various approaches have been introduced to time series analysis,\nincluding both statistical approaches and deep neural networks. Although neural\nnetwork approaches have illustrated stronger ability of representation than\nstatistical methods, they struggle to provide sufficient interpretablility, and\ncan be too complicated to optimize. In this paper, we present WEITS, a\nfrequency-aware deep learning framework that is highly interpretable and\ncomputationally efficient. Through multi-level wavelet decomposition, WEITS\nnovelly infuses frequency analysis into a highly deep learning framework.\nCombined with a forward-backward residual architecture, it enjoys both high\nrepresentation capability and statistical interpretability. Extensive\nexperiments on real-world datasets have demonstrated competitive performance of\nour model, along with its additional advantage of high computation efficiency.\nFurthermore, WEITS provides a general framework that can always seamlessly\nintegrate with state-of-the-art approaches for time series forecast.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Ziyou Guo",
            "Yan Sun",
            "Tieru Wu"
        ],
        "published": "2024-05-17T16:09:51Z"
    },
    {
        "title": "Recursively Feasible Shrinking-Horizon MPC in Dynamic Environments with\n  Conformal Prediction Guarantees",
        "link": "http://arxiv.org/abs/2405.10875v1",
        "abstract": "In this paper, we focus on the problem of shrinking-horizon Model Predictive\nControl (MPC) in uncertain dynamic environments. We consider controlling a\ndeterministic autonomous system that interacts with uncontrollable stochastic\nagents during its mission. Employing tools from conformal prediction, existing\nworks derive high-confidence prediction regions for the unknown agent\ntrajectories, and integrate these regions in the design of suitable safety\nconstraints for MPC. Despite guaranteeing probabilistic safety of the\nclosed-loop trajectories, these constraints do not ensure feasibility of the\nrespective MPC schemes for the entire duration of the mission. We propose a\nshrinking-horizon MPC that guarantees recursive feasibility via a gradual\nrelaxation of the safety constraints as new prediction regions become available\nonline. This relaxation enforces the safety constraints to hold over the least\nrestrictive prediction region from the set of all available prediction regions.\nIn a comparative case study with the state of the art, we empirically show that\nour approach results in tighter prediction regions and verify recursive\nfeasibility of our MPC scheme.",
        "subjects": [
            "eess.SY",
            "cs.SY",
            "stat.ML"
        ],
        "authors": [
            "Charis Stamouli",
            "Lars Lindemann",
            "George J. Pappas"
        ],
        "published": "2024-05-17T16:07:03Z"
    },
    {
        "title": "Square-Root Inverse Filter-based GNSS-Visual-Inertial Navigation",
        "link": "http://arxiv.org/abs/2405.10874v1",
        "abstract": "While Global Navigation Satellite System (GNSS) is often used to provide\nglobal positioning if available, its intermittency and/or inaccuracy calls for\nfusion with other sensors. In this paper, we develop a novel\nGNSS-Visual-Inertial Navigation System (GVINS) that fuses visual, inertial, and\nraw GNSS measurements within the square-root inverse sliding window filtering\n(SRI-SWF) framework in a tightly coupled fashion, which thus is termed\nSRI-GVINS. In particular, for the first time, we deeply fuse the GNSS\npseudorange, Doppler shift, single-differenced pseudorange, and\ndouble-differenced carrier phase measurements, along with the visual-inertial\nmeasurements. Inherited from the SRI-SWF, the proposed SRI-GVINS gains\nsignificant numerical stability and computational efficiency over the\nstart-of-the-art methods. Additionally, we propose to use a filter to\nsequentially initialize the reference frame transformation till converges,\nrather than collecting measurements for batch optimization. We also perform\nonline calibration of GNSS-IMU extrinsic parameters to mitigate the possible\nextrinsic parameter degradation. The proposed SRI-GVINS is extensively\nevaluated on our own collected UAV datasets and the results demonstrate that\nthe proposed method is able to suppress VIO drift in real-time and also show\nthe effectiveness of online GNSS-IMU extrinsic calibration. The experimental\nvalidation on the public datasets further reveals that the proposed SRI-GVINS\noutperforms the state-of-the-art methods in terms of both accuracy and\nefficiency.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Jun Hu",
            "Xiaoming Lang",
            "Feng Zhang",
            "Yinian Mao",
            "Guoquan Huang"
        ],
        "published": "2024-05-17T16:04:40Z"
    },
    {
        "title": "BraTS-Path Challenge: Assessing Heterogeneous Histopathologic Brain\n  Tumor Sub-regions",
        "link": "http://arxiv.org/abs/2405.10871v1",
        "abstract": "Glioblastoma is the most common primary adult brain tumor, with a grim\nprognosis - median survival of 12-18 months following treatment, and 4 months\notherwise. Glioblastoma is widely infiltrative in the cerebral hemispheres and\nwell-defined by heterogeneous molecular and micro-environmental histopathologic\nprofiles, which pose a major obstacle in treatment. Correctly diagnosing these\ntumors and assessing their heterogeneity is crucial for choosing the precise\ntreatment and potentially enhancing patient survival rates. In the\ngold-standard histopathology-based approach to tumor diagnosis, detecting\nvarious morpho-pathological features of distinct histology throughout digitized\ntissue sections is crucial. Such \"features\" include the presence of cellular\ntumor, geographic necrosis, pseudopalisading necrosis, areas abundant in\nmicrovascular proliferation, infiltration into the cortex, wide extension in\nsubcortical white matter, leptomeningeal infiltration, regions dense with\nmacrophages, and the presence of perivascular or scattered lymphocytes. With\nthese features in mind and building upon the main aim of the BraTS Cluster of\nChallenges https://www.synapse.org/brats2024, the goal of the BraTS-Path\nchallenge is to provide a systematically prepared comprehensive dataset and a\nbenchmarking environment to develop and fairly compare deep-learning models\ncapable of identifying tumor sub-regions of distinct histologic profile. These\nmodels aim to further our understanding of the disease and assist in the\ndiagnosis and grading of conditions in a consistent manner.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Spyridon Bakas",
            "Siddhesh P. Thakur",
            "Shahriar Faghani",
            "Mana Moassefi",
            "Ujjwal Baid",
            "Verena Chung",
            "Sarthak Pati",
            "Shubham Innani",
            "Bhakti Baheti",
            "Jake Albrecht",
            "Alexandros Karargyris",
            "Hasan Kassem",
            "MacLean P. Nasrallah",
            "Jared T. Ahrendsen",
            "Valeria Barresi",
            "Maria A. Gubbiotti",
            "Giselle Y. López",
            "Calixto-Hope G. Lucas",
            "Michael L. Miller",
            "Lee A. D. Cooper",
            "Jason T. Huse",
            "William R. Bell"
        ],
        "published": "2024-05-17T16:02:21Z"
    },
    {
        "title": "Multicenter Privacy-Preserving Model Training for Deep Learning Brain\n  Metastases Autosegmentation",
        "link": "http://arxiv.org/abs/2405.10870v1",
        "abstract": "Objectives: This work aims to explore the impact of multicenter data\nheterogeneity on deep learning brain metastases (BM) autosegmentation\nperformance, and assess the efficacy of an incremental transfer learning\ntechnique, namely learning without forgetting (LWF), to improve model\ngeneralizability without sharing raw data.\n  Materials and methods: A total of six BM datasets from University Hospital\nErlangen (UKER), University Hospital Zurich (USZ), Stanford, UCSF, NYU and\nBraTS Challenge 2023 on BM segmentation were used for this evaluation. First,\nthe multicenter performance of a convolutional neural network (DeepMedic) for\nBM autosegmentation was established for exclusive single-center training and\nfor training on pooled data, respectively. Subsequently bilateral collaboration\nwas evaluated, where a UKER pretrained model is shared to another center for\nfurther training using transfer learning (TL) either with or without LWF.\n  Results: For single-center training, average F1 scores of BM detection range\nfrom 0.625 (NYU) to 0.876 (UKER) on respective single-center test data. Mixed\nmulticenter training notably improves F1 scores at Stanford and NYU, with\nnegligible improvement at other centers. When the UKER pretrained model is\napplied to USZ, LWF achieves a higher average F1 score (0.839) than naive TL\n(0.570) and single-center training (0.688) on combined UKER and USZ test data.\nNaive TL improves sensitivity and contouring accuracy, but compromises\nprecision. Conversely, LWF demonstrates commendable sensitivity, precision and\ncontouring accuracy. When applied to Stanford, similar performance was\nobserved.\n  Conclusion: Data heterogeneity results in varying performance in BM\nautosegmentation, posing challenges to model generalizability. LWF is a\npromising approach to peer-to-peer privacy-preserving model training.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Yixing Huang",
            "Zahra Khodabakhshi",
            "Ahmed Gomaa",
            "Manuel Schmidt",
            "Rainer Fietkau",
            "Matthias Guckenberger",
            "Nicolaus Andratschke",
            "Christoph Bert",
            "Stephanie Tanadini-Lang",
            "Florian Putz"
        ],
        "published": "2024-05-17T16:01:11Z"
    },
    {
        "title": "Air Signing and Privacy-Preserving Signature Verification for Digital\n  Documents",
        "link": "http://arxiv.org/abs/2405.10868v1",
        "abstract": "This paper presents a novel approach to the digital signing of electronic\ndocuments through the use of a camera-based interaction system, single-finger\ntracking for sign recognition, and multi commands executing hand gestures. The\nproposed solution, referred to as \"Air Signature,\" involves writing the\nsignature in front of the camera, rather than relying on traditional methods\nsuch as mouse drawing or physically signing on paper and showing it to a web\ncamera. The goal is to develop a state-of-the-art method for detecting and\ntracking gestures and objects in real-time. The proposed methods include\napplying existing gesture recognition and object tracking systems, improving\naccuracy through smoothing and line drawing, and maintaining continuity during\nfast finger movements. An evaluation of the fingertip detection, sketching, and\noverall signing process is performed to assess the effectiveness of the\nproposed solution. The secondary objective of this research is to develop a\nmodel that can effectively recognize the unique signature of a user. This type\nof signature can be verified by neural cores that analyze the movement, speed,\nand stroke pixels of the signing in real time. The neural cores use machine\nlearning algorithms to match air signatures to the individual's stored\nsignatures, providing a secure and efficient method of verification. Our\nproposed System does not require sensors or any hardware other than the camera.",
        "subjects": [
            "cs.CV",
            "cs.HC"
        ],
        "authors": [
            "P. Sarveswarasarma",
            "T. Sathulakjan",
            "V. J. V. Godfrey",
            "Thanuja D. Ambegoda"
        ],
        "published": "2024-05-17T16:00:10Z"
    },
    {
        "title": "Improving face generation quality and prompt following with synthetic\n  captions",
        "link": "http://arxiv.org/abs/2405.10864v1",
        "abstract": "Recent advancements in text-to-image generation using diffusion models have\nsignificantly improved the quality of generated images and expanded the ability\nto depict a wide range of objects. However, ensuring that these models adhere\nclosely to the text prompts remains a considerable challenge. This issue is\nparticularly pronounced when trying to generate photorealistic images of\nhumans. Without significant prompt engineering efforts models often produce\nunrealistic images and typically fail to incorporate the full extent of the\nprompt information. This limitation can be largely attributed to the nature of\ncaptions accompanying the images used in training large scale diffusion models,\nwhich typically prioritize contextual information over details related to the\nperson's appearance. In this paper we address this issue by introducing a\ntraining-free pipeline designed to generate accurate appearance descriptions\nfrom images of people. We apply this method to create approximately 250,000\ncaptions for publicly available face datasets. We then use these synthetic\ncaptions to fine-tune a text-to-image diffusion model. Our results demonstrate\nthat this approach significantly improves the model's ability to generate\nhigh-quality, realistic human faces and enhances adherence to the given\nprompts, compared to the baseline model. We share our synthetic captions,\npretrained checkpoints and training code.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Michail Tarasiou",
            "Stylianos Moschoglou",
            "Jiankang Deng",
            "Stefanos Zafeiriou"
        ],
        "published": "2024-05-17T15:50:53Z"
    },
    {
        "title": "Tailoring Vaccine Messaging with Common-Ground Opinions",
        "link": "http://arxiv.org/abs/2405.10861v1",
        "abstract": "One way to personalize chatbot interactions is by establishing common ground\nwith the intended reader. A domain where establishing mutual understanding\ncould be particularly impactful is vaccine concerns and misinformation. Vaccine\ninterventions are forms of messaging which aim to answer concerns expressed\nabout vaccination. Tailoring responses in this domain is difficult, since\nopinions often have seemingly little ideological overlap. We define the task of\ntailoring vaccine interventions to a Common-Ground Opinion (CGO). Tailoring\nresponses to a CGO involves meaningfully improving the answer by relating it to\nan opinion or belief the reader holds. In this paper we introduce TAILOR-CGO, a\ndataset for evaluating how well responses are tailored to provided CGOs. We\nbenchmark several major LLMs on this task; finding GPT-4-Turbo performs\nsignificantly better than others. We also build automatic evaluation metrics,\nincluding an efficient and accurate BERT model that outperforms finetuned LLMs,\ninvestigate how to successfully tailor vaccine messaging to CGOs, and provide\nactionable recommendations from this investigation.\n  Code and model weights: https://github.com/rickardstureborg/tailor-cgo\nDataset: https://huggingface.co/datasets/DukeNLP/tailor-cgo",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CY",
            "68T50 (Primary) 68T01, 68T37, 91F20 (Secondary)",
            "I.2; I.2.7; I.7"
        ],
        "authors": [
            "Rickard Stureborg",
            "Sanxing Chen",
            "Ruoyu Xie",
            "Aayushi Patel",
            "Christopher Li",
            "Chloe Qinyu Zhu",
            "Tingnan Hu",
            "Jun Yang",
            "Bhuwan Dhingra"
        ],
        "published": "2024-05-17T15:48:30Z"
    },
    {
        "title": "ECR-Chain: Advancing Generative Language Models to Better Emotion-Cause\n  Reasoners through Reasoning Chains",
        "link": "http://arxiv.org/abs/2405.10860v2",
        "abstract": "Understanding the process of emotion generation is crucial for analyzing the\ncauses behind emotions. Causal Emotion Entailment (CEE), an\nemotion-understanding task, aims to identify the causal utterances in a\nconversation that stimulate the emotions expressed in a target utterance.\nHowever, current works in CEE mainly focus on modeling semantic and emotional\ninteractions in conversations, neglecting the exploration of the\nemotion-generation process. This hinders the models from deeply understanding\nemotions, restricting their ability to produce explainable predictions. In this\nwork, inspired by the emotion generation process of\n\"stimulus-appraisal-emotion\" in the cognitive appraisal theory, we introduce a\nstep-by-step reasoning method, Emotion-Cause Reasoning Chain (ECR-Chain), to\ninfer the stimulus from the target emotional expressions in conversations.\nSpecifically, we first introduce the ECR-Chain to ChatGPT via few-shot\nprompting, which significantly improves its performance on the CEE task. We\nfurther propose an automated construction process to utilize ChatGPT in\nbuilding an ECR-Chain set, which can enhance the reasoning abilities of smaller\nmodels through supervised training and assist the Vicuna-7B model in achieving\nstate-of-the-art CEE performance. Moreover, our methods can enable these\ngenerative language models to effectively perform emotion-cause reasoning in an\nexplainable manner. Our code, data and more details are at\nhttps://github.com/hzp3517/ECR-Chain.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Zhaopei Huang",
            "Jinming Zhao",
            "Qin Jin"
        ],
        "published": "2024-05-17T15:45:08Z"
    },
    {
        "title": "A Nonlinear Model Predictive Control for Automated Drifting with a\n  Standard Passenger Vehicle",
        "link": "http://arxiv.org/abs/2405.10859v1",
        "abstract": "This paper presents a novel approach to automated drifting with a standard\npassenger vehicle, which involves a Nonlinear Model Predictive Control to\nstabilise and maintain the vehicle at high sideslip angle conditions. The\nproposed controller architecture is split into three components. The first part\nconsists of the offline computed equilibrium maps, which provide the\nequilibrium points for each vehicle state given the desired sideslip angle and\nradius of the path. The second is the predictive controller minimising the\nerrors between the equilibrium and actual vehicle states. The third is a\npath-following controller, which reduces the path error, altering the\nequilibrium curvature path. In a high-fidelity simulation environment, we\nvalidate the controller architecture capacity to stabilise the vehicle in\nautomated drifting along a desired path, with a maximal lateral path deviation\nof 1 m. In the experiments with a standard passenger vehicle, we demonstrate\nthat the proposed approach is capable of bringing and maintaining the vehicle\nat the desired 30 deg sideslip angle in both high and low friction conditions.",
        "subjects": [
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Stan Meijer",
            "Alberto Bertipaglia",
            "Barys Shyrokau"
        ],
        "published": "2024-05-17T15:42:14Z"
    },
    {
        "title": "Assessing Political Bias in Large Language Models",
        "link": "http://arxiv.org/abs/2405.13041v2",
        "abstract": "The assessment of bias within Large Language Models (LLMs) has emerged as a\ncritical concern in the contemporary discourse surrounding Artificial\nIntelligence (AI) in the context of their potential impact on societal\ndynamics. Especially, recognizing and considering political bias within LLM\napplications is central when closing in on the tipping point toward\nperformative prediction. Then, being educated about potential effects and the\nsocietal behavior LLMs can drive at scale due to their interplay with human\noperators. In this way, the upcoming elections of the European Parliament will\nnot remain unaffected by LLMs. We evaluate the political bias of the currently\nmost popular open-source LLMs (instruct or assistant models) concerning\npolitical issues within the European Union (EU) from a German voter's\nperspective. To do so, we use the \"Wahl-O-Mat\", a voting advice application\nused in Germany. From the voting advice of the \"Wahl-O-Mat\" we quantize the\ndegree of alignment of LLMs with German political parties. We show that larger\nmodels, such as Llama3-70B, tend to align more closely with left-leaning\npolitical parties, while smaller models often remain neutral, particularly when\nprompted in English. The central finding is, that LLMs are similarly biased,\nwith low variances in the alignment with respect to a specific party. Our\nfindings underline the importance of rigorously assessing and making bias\ntransparent in LLMs to safeguard the integrity and trustworthiness of\napplications that employ the capabilities of performative prediction and the\ninvisible hand of machine learning prediction and language generation.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Luca Rettenberger",
            "Markus Reischl",
            "Mark Schutera"
        ],
        "published": "2024-05-17T15:30:18Z"
    },
    {
        "title": "The Future of Large Language Model Pre-training is Federated",
        "link": "http://arxiv.org/abs/2405.10853v1",
        "abstract": "Generative pre-trained large language models (LLMs) have demonstrated\nimpressive performance over a wide range of tasks, thanks to the unprecedented\namount of data they have been trained on. As established scaling laws indicate,\nLLMs' future performance improvement depends on the amount of computing and\ndata sources we can leverage for pre-training. Federated learning (FL) has the\npotential to unleash the majority of the planet's data and computational\nresources, which are underutilized by the data-center-focused training\nmethodology of current LLM practice. Our work presents a robust, flexible,\nreproducible FL approach that enables large-scale collaboration across\ninstitutions to train LLMs. This would mobilize more computational and data\nresources while matching or potentially exceeding centralized performance. We\nfurther show the effectiveness of the federated training scales with model size\nand present our approach for training a billion-scale federated LLM using\nlimited resources. This will help data-rich actors to become the protagonists\nof LLMs pre-training instead of leaving the stage to compute-rich actors alone.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC"
        ],
        "authors": [
            "Lorenzo Sani",
            "Alex Iacob",
            "Zeyu Cao",
            "Bill Marino",
            "Yan Gao",
            "Tomas Paulik",
            "Wanru Zhao",
            "William F. Shen",
            "Preslav Aleksandrov",
            "Xinchi Qiu",
            "Nicholas D. Lane"
        ],
        "published": "2024-05-17T15:27:52Z"
    },
    {
        "title": "KernelSHAP-IQ: Weighted Least-Square Optimization for Shapley\n  Interactions",
        "link": "http://arxiv.org/abs/2405.10852v1",
        "abstract": "The Shapley value (SV) is a prevalent approach of allocating credit to\nmachine learning (ML) entities to understand black box ML models. Enriching\nsuch interpretations with higher-order interactions is inevitable for complex\nsystems, where the Shapley Interaction Index (SII) is a direct axiomatic\nextension of the SV. While it is well-known that the SV yields an optimal\napproximation of any game via a weighted least square (WLS) objective, an\nextension of this result to SII has been a long-standing open problem, which\neven led to the proposal of an alternative index. In this work, we characterize\nhigher-order SII as a solution to a WLS problem, which constructs an optimal\napproximation via SII and $k$-Shapley values ($k$-SII). We prove this\nrepresentation for the SV and pairwise SII and give empirically validated\nconjectures for higher orders. As a result, we propose KernelSHAP-IQ, a direct\nextension of KernelSHAP for SII, and demonstrate state-of-the-art performance\nfor feature interactions.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Fabian Fumagalli",
            "Maximilian Muschalik",
            "Patrick Kolpaczki",
            "Eyke Hüllermeier",
            "Barbara Hammer"
        ],
        "published": "2024-05-17T15:27:35Z"
    },
    {
        "title": "Generative AI for Test Driven Development: Preliminary Results",
        "link": "http://arxiv.org/abs/2405.10849v1",
        "abstract": "Test Driven Development (TDD) is one of the major practices of Extreme\nProgramming for which incremental testing and refactoring trigger the code\ndevelopment. TDD has limited adoption in the industry, as it requires more code\nto be developed and experienced developers. Generative AI (GenAI) may reduce\nthe extra effort imposed by TDD. In this work, we introduce an approach to\nautomatize TDD by embracing GenAI either in a collaborative interaction pattern\nin which developers create tests and supervise the AI generation during each\niteration or a fully-automated pattern in which developers only supervise the\nAI generation at the end of the iterations. We run an exploratory experiment\nwith ChatGPT in which the interaction patterns are compared with the non-AI TDD\nregarding test and code quality and development speed. Overall, we found that,\nfor our experiment and settings, GenAI can be efficiently used in TDD, but it\nrequires supervision of the quality of the produced code. In some cases, it can\neven mislead non-expert developers and propose solutions just for the sake of\nthe query.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Moritz Mock",
            "Jorge Melegati",
            "Barbara Russo"
        ],
        "published": "2024-05-17T15:26:10Z"
    },
    {
        "title": "Model Predictive Contouring Control for Vehicle Obstacle Avoidance at\n  the Limit of Handling Using Torque Vectoring",
        "link": "http://arxiv.org/abs/2405.10847v1",
        "abstract": "This paper presents an original approach to vehicle obstacle avoidance. It\ninvolves the development of a nonlinear Model Predictive Contouring Control,\nwhich uses torque vectoring to stabilise and drive the vehicle in evasive\nmanoeuvres at the limit of handling. The proposed algorithm combines motion\nplanning, path tracking and vehicle stability objectives, prioritising\ncollision avoidance in emergencies. The controller's prediction model is a\nnonlinear double-track vehicle model based on an extended Fiala tyre to capture\nthe nonlinear coupled longitudinal and lateral dynamics. The controller\ncomputes the optimal steering angle and the longitudinal forces per each of the\nfour wheels to minimise tracking error in safe situations and maximise the\nvehicle-to-obstacle distance in emergencies. Thanks to the optimisation of the\nlongitudinal tyre forces, the proposed controller can produce an extra yaw\nmoment, increasing the vehicle's lateral agility to avoid obstacles while\nkeeping the vehicle stable. The optimal forces are constrained in the tyre\nfriction circle not to exceed the tyres and vehicle capabilities. In a\nhigh-fidelity simulation environment, we demonstrate the benefits of torque\nvectoring, showing that our proposed approach is capable of successfully\navoiding obstacles and keeping the vehicle stable while driving a double-lane\nchange manoeuvre, in comparison to baselines lacking torque vectoring or\ncollision avoidance prioritisation.",
        "subjects": [
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Alberto Bertipaglia",
            "Davide Tavernini",
            "Umberto Montanaro",
            "Mohsen Alirezaei",
            "Riender Happee",
            "Aldo Sorniotti",
            "Barys Shyrokau"
        ],
        "published": "2024-05-17T15:22:34Z"
    },
    {
        "title": "Uncertainty Distribution Assessment of Jiles-Atherton Parameter\n  Estimation for Inrush Current Studies",
        "link": "http://dx.doi.org/10.1109/TPWRD.2024.3398790",
        "abstract": "Transformers are one of the key assets in AC distribution grids and renewable\npower integration. During transformer energization inrush currents appear,\nwhich lead to transformer degradation and can cause grid instability events.\nThese inrush currents are a consequence of the transformer's magnetic core\nsaturation during its connection to the grid. Transformer cores are normally\nmodelled by the Jiles-Atherton (JA) model which contains five parameters. These\nparameters can be estimated by metaheuristic-based search algorithms. The\nparameter initialization of these algorithms plays an important role in the\nalgorithm convergence. The most popular strategy used for JA parameter\ninitialization is a random uniform distribution. However, techniques such as\nparameter initialization by Probability Density Functions (PDFs) have shown to\nimprove accuracy over random methods. In this context, this research work\npresents a framework to assess the impact of different parameter initialization\nstrategies on the performance of the JA parameter estimation for inrush current\nstudies. Depending on available data and expert knowledge, uncertainty levels\nare modelled with different PDFs. Moreover, three different\nmetaheuristic-search algorithms are employed on two different core materials\nand their accuracy and computational time are compared. Results show an\nimprovement in the accuracy and computational time of the metaheuristic-based\nalgorithms when PDF parameter initialization is used.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.SY"
        ],
        "authors": [
            "Jone Ugarte-Valdivielso",
            "Jose I. Aizpurua",
            "Manex Barrenetxea-Iñarra"
        ],
        "published": "2024-05-17T15:20:26Z"
    },
    {
        "title": "Natural Language Processing for Requirements Traceability",
        "link": "http://arxiv.org/abs/2405.10845v1",
        "abstract": "Traceability, the ability to trace relevant software artifacts to support\nreasoning about the quality of the software and its development process, plays\na crucial role in requirements and software engineering, particularly for\nsafety-critical systems. In this chapter, we provide a comprehensive overview\nof the representative tasks in requirement traceability for which natural\nlanguage processing (NLP) and related techniques have made considerable\nprogress in the past decade. We first present the definition of traceability in\nthe context of requirements and the overall engineering process, as well as\nother important concepts related to traceability tasks. Then, we discuss two\ntasks in detail, including trace link recovery and trace link maintenance. We\nalso introduce two other related tasks concerning when trace links are used in\npractical contexts. For each task, we explain the characteristics of the task,\nhow it can be approached through NLP techniques, and how to design and conduct\nthe experiment to demonstrate the performance of the NLP techniques. We further\ndiscuss practical considerations on how to effectively apply NLP techniques and\nassess their effectiveness regarding the data set collection, the metrics\nselection, and the role of humans when evaluating the NLP approaches. Overall,\nthis chapter prepares the readers with the fundamental knowledge of designing\nautomated traceability solutions enabled by NLP in practice.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Jin L. C. Guo",
            "Jan-Philipp Steghöfer",
            "Andreas Vogelsang",
            "Jane Cleland-Huang"
        ],
        "published": "2024-05-17T15:17:00Z"
    },
    {
        "title": "Automated Radiology Report Generation: A Review of Recent Advances",
        "link": "http://arxiv.org/abs/2405.10842v1",
        "abstract": "Increasing demands on medical imaging departments are taking a toll on the\nradiologist's ability to deliver timely and accurate reports. Recent\ntechnological advances in artificial intelligence have demonstrated great\npotential for automatic radiology report generation (ARRG), sparking an\nexplosion of research. This survey paper conducts a methodological review of\ncontemporary ARRG approaches by way of (i) assessing datasets based on\ncharacteristics, such as availability, size, and adoption rate, (ii) examining\ndeep learning training methods, such as contrastive learning and reinforcement\nlearning, (iii) exploring state-of-the-art model architectures, including\nvariations of CNN and transformer models, (iv) outlining techniques integrating\nclinical knowledge through multimodal inputs and knowledge graphs, and (v)\nscrutinising current model evaluation techniques, including commonly applied\nNLP metrics and qualitative clinical reviews. Furthermore, the quantitative\nresults of the reviewed models are analysed, where the top performing models\nare examined to seek further insights. Finally, potential new directions are\nhighlighted, with the adoption of additional datasets from other radiological\nmodalities and improved evaluation methods predicted as important areas of\nfuture development.",
        "subjects": [
            "cs.CV",
            "68T99",
            "I.2; I.4; J.3"
        ],
        "authors": [
            "Phillip Sloan",
            "Philip Clatworthy",
            "Edwin Simpson",
            "Majid Mirmehdi"
        ],
        "published": "2024-05-17T15:06:08Z"
    },
    {
        "title": "A Unified Search and Recommendation Framework Based on Multi-Scenario\n  Learning for Ranking in E-commerce",
        "link": "http://dx.doi.org/10.1145/3626772.3661356",
        "abstract": "Search and recommendation (S&R) are the two most important scenarios in\ne-commerce. The majority of users typically interact with products in S&R\nscenarios, indicating the need and potential for joint modeling. Traditional\nmulti-scenario models use shared parameters to learn the similarity of multiple\ntasks, and task-specific parameters to learn the divergence of individual\ntasks. This coarse-grained modeling approach does not effectively capture the\ndifferences between S&R scenarios. Furthermore, this approach does not\nsufficiently exploit the information across the global label space. These\nissues can result in the suboptimal performance of multi-scenario models in\nhandling both S&R scenarios. To address these issues, we propose an effective\nand universal framework for Unified Search and Recommendation (USR), designed\nwith S&R Views User Interest Extractor Layer (IE) and S&R Views Feature\nGenerator Layer (FG) to separately generate user interests and\nscenario-agnostic feature representations for S&R. Next, we introduce a Global\nLabel Space Multi-Task Layer (GLMT) that uses global labels as supervised\nsignals of auxiliary tasks and jointly models the main task and auxiliary tasks\nusing conditional probability. Extensive experimental evaluations on real-world\nindustrial datasets show that USR can be applied to various multi-scenario\nmodels and significantly improve their performance. Online A/B testing also\nindicates substantial performance gains across multiple metrics. Currently, USR\nhas been successfully deployed in the 7Fresh App.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Jinhan Liu",
            "Qiyu Chen",
            "Junjie Xu",
            "Junjie Li",
            "Baoli Li",
            "Sulong Xu"
        ],
        "published": "2024-05-17T14:57:52Z"
    },
    {
        "title": "Automatic segmentation of Organs at Risk in Head and Neck cancer\n  patients from CT and MRI scans",
        "link": "http://arxiv.org/abs/2405.10833v2",
        "abstract": "Background and purpose: Deep Learning (DL) has been widely explored for\nOrgans at Risk (OARs) segmentation; however, most studies have focused on a\nsingle modality, either CT or MRI, not both simultaneously. This study presents\na high-performing DL pipeline for segmentation of 30 OARs from MRI and CT scans\nof Head and Neck (H&N) cancer patients.\n  Materials and methods: Paired CT and MRI-T1 images from 42 H&N cancer\npatients alongside annotation for 30 OARs from the H&N OAR CT & MR segmentation\nchallenge dataset were used to develop a segmentation pipeline. After cropping\nirrelevant regions, rigid followed by non-rigid registration of CT and MRI\nvolumes was performed. Two versions of the CT volume, representing soft tissues\nand bone anatomy, were stacked with the MRI volume and used as input to an\nnnU-Net pipeline. Modality Dropout was used during the training to force the\nmodel to learn from the different modalities. Segmentation masks were predicted\nwith the trained model for an independent set of 14 new patients. The mean Dice\nScore (DS) and Hausdorff Distance (HD) were calculated for each OAR across\nthese patients to evaluate the pipeline.\n  Results: This resulted in an overall mean DS and HD of 0.777 +- 0.118 and\n3.455 +- 1.679, respectively, establishing the state-of-the-art (SOTA) for this\nchallenge at the time of submission.\n  Conclusion: The proposed pipeline achieved the best DS and HD among all\nparticipants of the H&N OAR CT and MR segmentation challenge and sets a new\nSOTA for automated segmentation of H&N OARs.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Sébastien Quetin",
            "Andrew Heschl",
            "Mauricio Murillo",
            "Rohit Murali",
            "Shirin A. Enger",
            "Farhad Maleki"
        ],
        "published": "2024-05-17T14:54:42Z"
    },
    {
        "title": "Open-Vocabulary Spatio-Temporal Action Detection",
        "link": "http://arxiv.org/abs/2405.10832v1",
        "abstract": "Spatio-temporal action detection (STAD) is an important fine-grained video\nunderstanding task. Current methods require box and label supervision for all\naction classes in advance. However, in real-world applications, it is very\nlikely to come across new action classes not seen in training because the\naction category space is large and hard to enumerate. Also, the cost of data\nannotation and model training for new classes is extremely high for traditional\nmethods, as we need to perform detailed box annotations and re-train the whole\nnetwork from scratch. In this paper, we propose a new challenging setting by\nperforming open-vocabulary STAD to better mimic the situation of action\ndetection in an open world. Open-vocabulary spatio-temporal action detection\n(OV-STAD) requires training a model on a limited set of base classes with box\nand label supervision, which is expected to yield good generalization\nperformance on novel action classes. For OV-STAD, we build two benchmarks based\non the existing STAD datasets and propose a simple but effective method based\non pretrained video-language models (VLM). To better adapt the holistic VLM for\nthe fine-grained action detection task, we carefully fine-tune it on the\nlocalized video region-text pairs. This customized fine-tuning endows the VLM\nwith better motion understanding, thus contributing to a more accurate\nalignment between video regions and texts. Local region feature and global\nvideo feature fusion before alignment is adopted to further improve the action\ndetection performance by providing global context. Our method achieves a\npromising performance on novel classes.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Tao Wu",
            "Shuqiu Ge",
            "Jie Qin",
            "Gangshan Wu",
            "Limin Wang"
        ],
        "published": "2024-05-17T14:52:47Z"
    },
    {
        "title": "Combining Teacher-Student with Representation Learning: A Concurrent\n  Teacher-Student Reinforcement Learning Paradigm for Legged Locomotion",
        "link": "http://arxiv.org/abs/2405.10830v1",
        "abstract": "Thanks to the explosive developments of data-driven learning methodologies\nrecently, reinforcement learning (RL) emerges as a promising solution to\naddress the legged locomotion problem in robotics. In this manuscript, we\npropose a novel concurrent teacher-student reinforcement learning architecture\nfor legged locomotion over challenging terrains, based only on proprioceptive\nmeasurements in real-world deployment. Different from convectional\nteacher-student architecture that trains the teacher policy via RL and\ntransfers the knowledge to the student policy through supervised learning, our\nproposed architecture trains teacher and student policy networks concurrently\nunder the reinforcement learning paradigm. To achieve this, we develop a new\ntraining scheme based on conventional proximal policy gradient (PPO) method to\naccommodate the interaction between teacher policy network and student policy\nnetwork. The effectiveness of the proposed architecture as well as the new\ntraining scheme is demonstrated through extensive indoor and outdoor\nexperiments on quadrupedal robots and point-foot bipedal robot, showcasing\nrobust locomotion over challenging terrains and improved performance compared\nto two-stage training methods.",
        "subjects": [
            "cs.RO",
            "68Txx",
            "I.2.9; I.2.6"
        ],
        "authors": [
            "Hongxi Wang",
            "Haoxiang Luo",
            "Wei Zhang",
            "Hua Chen"
        ],
        "published": "2024-05-17T14:51:30Z"
    },
    {
        "title": "The participation of public in knowledge production: a citizen science\n  projects overview",
        "link": "http://arxiv.org/abs/2405.10829v1",
        "abstract": "Citizen Science (CS) is related to public engagement in scientific research.\nThe tasks in which the citizens can be involved are diverse and can range from\ndata collection and tagging images to participation in the planning and\nresearch design. However, little is known about the involvement degree of the\ncitizens to CS projects, and the contribution of those projects to the\nadvancement of knowledge (e.g. scientific outcomes). This study aims to gain a\nbetter understanding by analysing the SciStarter database. A total of 2,346 CS\nprojects were identified, mainly from Ecology and Environmental Sciences. Of\nthese projects, 91% show low participation of the citizens (Level 1 \"citizens\nas sensors\" and 2 \"citizens as interpreters\", from Haklay's scale). In terms of\nscientific output, 918 papers indexed in the Web of Science (WoS) were\nidentified. The most prolific projects were found to have lower levels of\ncitizen involvement, specifically at Levels 1 and 2.",
        "subjects": [
            "cs.DL"
        ],
        "authors": [
            "Nuria Bautista-Puig",
            "Enrique Orduna-Malea",
            "Philippe Mongeon"
        ],
        "published": "2024-05-17T14:49:22Z"
    },
    {
        "title": "Analysis of Impulsive Interference in Digital Audio Broadcasting Systems\n  in Electric Vehicles",
        "link": "http://arxiv.org/abs/2405.10828v1",
        "abstract": "Recently, new types of interference in electric vehicles (EVs), such as\nconverters switching and/or battery chargers, have been found to degrade the\nperformance of wireless digital transmission systems. Measurements show that\nsuch an interference is characterized by impulsive behavior and is widely\nvarying in time. This paper uses recorded data from our EV testbed to analyze\nthe impulsive interference in the digital audio broadcasting band. Moreover, we\nuse our analysis to obtain a corresponding interference model. In particular,\nwe studied the temporal characteristics of the interference and confirmed that\nits amplitude indeed exhibits an impulsive behavior. Our results show that\nimpulsive events span successive received signal samples and thus indicate a\nbursty nature. To this end, we performed a data-driven modification of a\nwell-established model for bursty impulsive interference, the Markov-Middleton\nmodel, to produce synthetic noise realization. We investigate the optimal\nsymbol detector design based on the proposed model and show significant\nperformance gains compared to the conventional detector based on the additive\nwhite Gaussian noise assumption.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "authors": [
            "Chin-Hung Chen",
            "Wen-Hung Huang",
            "Boris Karanov",
            "Alex Young",
            "Yan Wu",
            "Wim van Houtum"
        ],
        "published": "2024-05-17T14:48:37Z"
    },
    {
        "title": "Large Language Model (LLM) for Telecommunications: A Comprehensive\n  Survey on Principles, Key Techniques, and Opportunities",
        "link": "http://arxiv.org/abs/2405.10825v1",
        "abstract": "Large language models (LLMs) have received considerable attention recently\ndue to their outstanding comprehension and reasoning capabilities, leading to\ngreat progress in many fields. The advancement of LLM techniques also offers\npromising opportunities to automate many tasks in the telecommunication\n(telecom) field. After pre-training and fine-tuning, LLMs can perform diverse\ndownstream tasks based on human instructions, paving the way to artificial\ngeneral intelligence (AGI)-enabled 6G. Given the great potential of LLM\ntechnologies, this work aims to provide a comprehensive overview of LLM-enabled\ntelecom networks. In particular, we first present LLM fundamentals, including\nmodel architecture, pre-training, fine-tuning, inference and utilization, model\nevaluation, and telecom deployment. Then, we introduce LLM-enabled key\ntechniques and telecom applications in terms of generation, classification,\noptimization, and prediction problems. Specifically, the LLM-enabled generation\napplications include telecom domain knowledge, code, and network configuration\ngeneration. After that, the LLM-based classification applications involve\nnetwork security, text, image, and traffic classification problems. Moreover,\nmultiple LLM-enabled optimization techniques are introduced, such as automated\nreward function design for reinforcement learning and verbal reinforcement\nlearning. Furthermore, for LLM-aided prediction problems, we discussed\ntime-series prediction models and multi-modality prediction problems for\ntelecom. Finally, we highlight the challenges and identify the future\ndirections of LLM-enabled telecom networks.",
        "subjects": [
            "eess.SY",
            "cs.LG",
            "cs.SY"
        ],
        "authors": [
            "Hao Zhou",
            "Chengming Hu",
            "Ye Yuan",
            "Yufei Cui",
            "Yili Jin",
            "Can Chen",
            "Haolun Wu",
            "Dun Yuan",
            "Li Jiang",
            "Di Wu",
            "Xue Liu",
            "Charlie Zhang",
            "Xianbin Wang",
            "Jiangchuan Liu"
        ],
        "published": "2024-05-17T14:46:13Z"
    },
    {
        "title": "Real-World Graph Analysis: Techniques for Static, Dynamic, and Temporal\n  Communities",
        "link": "http://arxiv.org/abs/2405.10824v1",
        "abstract": "Graphs are widely used in various fields of computer science. They have also\nfound application in unrelated areas, leading to a diverse range of problems.\nThese problems can be modeled as relationships between entities in various\ncontexts, such as social networks, protein interactions in cells, and route\nmaps. Therefore it is logical to analyze these data structures with diverse\napproaches, whether they are numerical or structural, global or local,\napproximate or exact. In particular, the concept of community plays an\nimportant role in local structural analysis, as it is able to highlight the\ncomposition of the underlying graph while providing insights into what the\norganization and importance of the nodes in a network look like. This thesis\npursues the goal of extracting knowledge from different kinds of graphs,\nincluding static, dynamic, and temporal graphs, with a particular focus on\ntheir community substructures. To tackle this task we use combinatorial\nalgorithms that can list all the communities in a graph according to different\nformalizations, such as cliques, $k$-graphlets, and $k$-cores. We first develop\nnew algorithms to enumerate subgraphs, using traditional and novel techniques\nsuch as push-out amortization, and CPU cache analysis to boost their\nefficiency. We then extend these concepts to the analysis of real-world graphs\nacross diverse domains, ranging from social networks to autonomous systems\nmodeled as temporal graphs. In this field, there is currently no widely\naccepted adaptation, even for straightforward subgraphs like $k$-cores, and the\navailable data is expanding both in terms of quantity and scale. As a result,\nour findings advance the state of the art both from a theoretical and a\npractical perspective and can be used in a static or dynamic setting to further\nspeed up and refine graph analysis techniques.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Davide Rucci"
        ],
        "published": "2024-05-17T14:45:50Z"
    },
    {
        "title": "Generative modeling through internal high-dimensional chaotic activity",
        "link": "http://arxiv.org/abs/2405.10822v1",
        "abstract": "Generative modeling aims at producing new datapoints whose statistical\nproperties resemble the ones in a training dataset. In recent years, there has\nbeen a burst of machine learning techniques and settings that can achieve this\ngoal with remarkable performances. In most of these settings, one uses the\ntraining dataset in conjunction with noise, which is added as a source of\nstatistical variability and is essential for the generative task. Here, we\nexplore the idea of using internal chaotic dynamics in high-dimensional chaotic\nsystems as a way to generate new datapoints from a training dataset. We show\nthat simple learning rules can achieve this goal within a set of vanilla\narchitectures and characterize the quality of the generated datapoints through\nstandard accuracy measures.",
        "subjects": [
            "cs.LG",
            "cond-mat.dis-nn"
        ],
        "authors": [
            "Samantha J. Fournier",
            "Pierfrancesco Urbani"
        ],
        "published": "2024-05-17T14:43:30Z"
    },
    {
        "title": "Modeling Supply Chain Interaction and Disruption: Insights from\n  Real-world Data and Complex Adaptive System",
        "link": "http://arxiv.org/abs/2405.10818v1",
        "abstract": "In the rapidly evolving automotive industry, Systems-on-Chips (SoCs) are\nplaying an increasingly crucial role in enhancing vehicle intelligence,\nconnectivity, and safety features. For enterprises whose business encompasses\nautomotive SoCs, the sustained and stable provision and receipt of SoC relevant\ngoods or services are essential. Considering the imperative for a resilient and\nadaptable supply network, enterprises are concentrating their efforts on\nformulating strategies to address risks stemming from supply chain disruptions\ncaused by technological obsolescence, natural disasters, and geopolitical\ntensions. This study presents an open supply knowledge extraction and\ncomplement approach and build a supply chain network of automotive SoC\nenterprises in China, which incorporates cross-domain named entity recognition\nunder limited information, fuzzy matching of firm entities, and supply relation\ninferring based on knowledge graph. Subsequently, we exhibit the degree and\nregistered capital distribution across firms, and analyze the correlations\nbetween centrality metrics in the supply chain network. Finally, based on\nrecovery capacity and risk transfer, two interaction disruption models (IDMs)\nare developed to elucidate the adaptive behaviors and effect of network\ndisruptions under various business and attack strategies. This research not\nonly aids in exploring the complexities of Chinese automotive SoC supply chain\nbut also enriches our understanding of the dynamics of firm behavior in this\ncrucial industry sector.",
        "subjects": [
            "cs.SI"
        ],
        "authors": [
            "Jiawei Feng",
            "Mengsi Cai",
            "Fangze Dai",
            "Tianci Bu",
            "Xiaoyu Zhang",
            "Huijun Zheng",
            "Xin Lu"
        ],
        "published": "2024-05-17T14:37:45Z"
    },
    {
        "title": "Restless Linear Bandits",
        "link": "http://arxiv.org/abs/2405.10817v1",
        "abstract": "A more general formulation of the linear bandit problem is considered to\nallow for dependencies over time. Specifically, it is assumed that there exists\nan unknown $\\mathbb{R}^d$-valued stationary $\\varphi$-mixing sequence of\nparameters $(\\theta_t,~t \\in \\mathbb{N})$ which gives rise to pay-offs. This\ninstance of the problem can be viewed as a generalization of both the classical\nlinear bandits with iid noise, and the finite-armed restless bandits. In light\nof the well-known computational hardness of optimal policies for restless\nbandits, an approximation is proposed whose error is shown to be controlled by\nthe $\\varphi$-dependence between consecutive $\\theta_t$. An optimistic\nalgorithm, called LinMix-UCB, is proposed for the case where $\\theta_t$ has an\nexponential mixing rate. The proposed algorithm is shown to incur a sub-linear\nregret of $\\mathcal{O}\\left(\\sqrt{d n\\mathrm{polylog}(n) }\\right)$ with respect\nto an oracle that always plays a multiple of $\\mathbb{E}\\theta_t$. The main\nchallenge in this setting is to ensure that the exploration-exploitation\nstrategy is robust against long-range dependencies. The proposed method relies\non Berbee's coupling lemma to carefully select near-independent samples and\nconstruct confidence ellipsoids around empirical estimates of\n$\\mathbb{E}\\theta_t$.",
        "subjects": [
            "stat.ML",
            "cs.IT",
            "cs.LG",
            "math.IT"
        ],
        "authors": [
            "Azadeh Khaleghi"
        ],
        "published": "2024-05-17T14:37:39Z"
    },
    {
        "title": "A Functional Model Method for Nonconvex Nonsmooth Conditional Stochastic\n  Optimization",
        "link": "http://arxiv.org/abs/2405.10815v1",
        "abstract": "We consider stochastic optimization problems involving an expected value of a\nnonlinear function of a base random vector and a conditional expectation of\nanother function depending on the base random vector, a dependent random\nvector, and the decision variables. We call such problems conditional\nstochastic optimization problems. They arise in many applications, such as\nuplift modeling, reinforcement learning, and contextual optimization. We\npropose a specialized single time-scale stochastic method for nonconvex\nconstrained conditional stochastic optimization problems with a Lipschitz\nsmooth outer function and a generalized differentiable inner function. In the\nmethod, we approximate the inner conditional expectation with a rich parametric\nmodel whose mean squared error satisfies a stochastic version of a\n{\\L}ojasiewicz condition. The model is used by an inner learning algorithm. The\nmain feature of our approach is that unbiased stochastic estimates of the\ndirections used by the method can be generated with one observation from the\njoint distribution per iteration, which makes it applicable to real-time\nlearning. The directions, however, are not gradients or subgradients of any\noverall objective function. We prove the convergence of the method with\nprobability one, using the method of differential inclusions and a specially\ndesigned Lyapunov function, involving a stochastic generalization of the\nBregman distance. Finally, a numerical illustration demonstrates the viability\nof our approach.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "stat.ML",
            "90C15, 49J52, 60-08"
        ],
        "authors": [
            "Andrzej Ruszczyński",
            "Shangzhe Yang"
        ],
        "published": "2024-05-17T14:35:50Z"
    },
    {
        "title": "Data-Driven Symbol Detection for Intersymbol Interference Channels with\n  Bursty Impulsive Noise",
        "link": "http://arxiv.org/abs/2405.10814v1",
        "abstract": "We developed machine learning approaches for data-driven trellis-based soft\nsymbol detection in coded transmission over intersymbol interference (ISI)\nchannels in presence of bursty impulsive noise (IN), for example encountered in\nwireless digital broadcasting systems and vehicular communications. This\nenabled us to obtain optimized detectors based on the Bahl-Cocke-Jelinek-Raviv\n(BCJR) algorithm while circumventing the use of full channel state information\n(CSI) for computing likelihoods and trellis state transition probabilities.\nFirst, we extended the application of the neural network (NN)-aided BCJR,\nrecently proposed for ISI channels with additive white Gaussian noise (AWGN).\nAlthough suitable for estimating likelihoods via labeling of transmission\nsequences, the BCJR-NN method does not provide a framework for learning the\ntrellis state transitions. In addition to detection over the joint ISI and IN\nstates we also focused on another scenario where trellis transitions are not\ntrivial: detection for the ISI channel with AWGN with inaccurate knowledge of\nthe channel memory at the receiver. Without access to the accurate state\ntransition matrix, the BCJR- NN performance significantly degrades in both\nsettings. To this end, we devised an alternative approach for data-driven BCJR\ndetection based on the unsupervised learning of a hidden Markov model (HMM).\nThe BCJR-HMM allowed us to optimize both the likelihood function and the state\ntransition matrix without labeling. Moreover, we demonstrated the viability of\na hybrid NN and HMM BCJR detection where NN is used for learning the\nlikelihoods, while the state transitions are optimized via HMM. While reducing\nthe required prior channel knowledge, the examined data-driven detectors with\nlearned trellis state transitions achieve bit error rates close to the optimal\nfull CSI-based BCJR, significantly outperforming detection with inaccurate CSI.",
        "subjects": [
            "cs.IT",
            "cs.LG",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Boris Karanov",
            "Chin-Hung Chen",
            "Yan Wu",
            "Alex Young",
            "Wim van Houtum"
        ],
        "published": "2024-05-17T14:35:09Z"
    },
    {
        "title": "ActiveLLM: Large Language Model-based Active Learning for Textual\n  Few-Shot Scenarios",
        "link": "http://arxiv.org/abs/2405.10808v1",
        "abstract": "Active learning is designed to minimize annotation efforts by prioritizing\ninstances that most enhance learning. However, many active learning strategies\nstruggle with a 'cold start' problem, needing substantial initial data to be\neffective. This limitation often reduces their utility for pre-trained models,\nwhich already perform well in few-shot scenarios. To address this, we introduce\nActiveLLM, a novel active learning approach that leverages large language\nmodels such as GPT-4, Llama 3, and Mistral Large for selecting instances. We\ndemonstrate that ActiveLLM significantly enhances the classification\nperformance of BERT classifiers in few-shot scenarios, outperforming both\ntraditional active learning methods and the few-shot learning method SetFit.\nAdditionally, ActiveLLM can be extended to non-few-shot scenarios, allowing for\niterative selections. In this way, ActiveLLM can even help other active\nlearning strategies to overcome their cold start problem. Our results suggest\nthat ActiveLLM offers a promising solution for improving model performance\nacross various learning setups.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Markus Bayer",
            "Christian Reuter"
        ],
        "published": "2024-05-17T14:23:54Z"
    },
    {
        "title": "A Large-scale Multi Domain Leukemia Dataset for the White Blood Cells\n  Detection with Morphological Attributes for Explainability",
        "link": "http://arxiv.org/abs/2405.10803v1",
        "abstract": "Earlier diagnosis of Leukemia can save thousands of lives annually. The\nprognosis of leukemia is challenging without the morphological information of\nWhite Blood Cells (WBC) and relies on the accessibility of expensive\nmicroscopes and the availability of hematologists to analyze Peripheral Blood\nSamples (PBS). Deep Learning based methods can be employed to assist\nhematologists. However, these algorithms require a large amount of labeled\ndata, which is not readily available. To overcome this limitation, we have\nacquired a realistic, generalized, and large dataset. To collect this\ncomprehensive dataset for real-world applications, two microscopes from two\ndifferent cost spectrums (high-cost HCM and low-cost LCM) are used for dataset\ncapturing at three magnifications (100x, 40x, 10x) through different sensors\n(high-end camera for HCM, middle-level camera for LCM and mobile-phone camera\nfor both). The high-sensor camera is 47 times more expensive than the\nmiddle-level camera and HCM is 17 times more expensive than LCM. In this\ncollection, using HCM at high resolution (100x), experienced hematologists\nannotated 10.3k WBC types (14) and artifacts, having 55k morphological labels\n(Cell Size, Nuclear Chromatin, Nuclear Shape, etc.) from 2.4k images of several\nPBS leukemia patients. Later on, these annotations are transferred to other 2\nmagnifications of HCM, and 3 magnifications of LCM, and on each camera captured\nimages. Along with the LeukemiaAttri dataset, we provide baselines over\nmultiple object detectors and Unsupervised Domain Adaptation (UDA) strategies,\nalong with morphological information-based attribute prediction. The dataset\nwill be publicly available after publication to facilitate the research in this\ndirection.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Abdul Rehman",
            "Talha Meraj",
            "Aiman Mahmood Minhas",
            "Ayisha Imran",
            "Mohsen Ali",
            "Waqas Sultani"
        ],
        "published": "2024-05-17T14:20:02Z"
    },
    {
        "title": "Reduced storage direct tensor ring decomposition for convolutional\n  neural networks compression",
        "link": "http://arxiv.org/abs/2405.10802v1",
        "abstract": "Convolutional neural networks (CNNs) are among the most widely used machine\nlearning models for computer vision tasks, such as image classification. To\nimprove the efficiency of CNNs, many CNNs compressing approaches have been\ndeveloped. Low-rank methods approximate the original convolutional kernel with\na sequence of smaller convolutional kernels, which leads to reduced storage and\ntime complexities. In this study, we propose a novel low-rank CNNs compression\nmethod that is based on reduced storage direct tensor ring decomposition\n(RSDTR). The proposed method offers a higher circular mode permutation\nflexibility, and it is characterized by large parameter and FLOPS compression\nrates, while preserving a good classification accuracy of the compressed\nnetwork. The experiments, performed on the CIFAR-10 and ImageNet datasets,\nclearly demonstrate the efficiency of RSDTR in comparison to other\nstate-of-the-art CNNs compression approaches.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Mateusz Gabor",
            "Rafał Zdunek"
        ],
        "published": "2024-05-17T14:16:40Z"
    },
    {
        "title": "The Relational Machine Calculus",
        "link": "http://dx.doi.org/10.1145/3661814.3662091",
        "abstract": "This paper presents the Relational Machine Calculus (RMC): a simple,\nfoundational model of first-order relational programming. The RMC originates\nfrom the Functional Machine Calculus (FMC), which generalizes the\nlambda-calculus and its standard call-by-name stack machine in two directions.\nOne, \"locations\", introduces multiple stacks, which enable effect operators to\nbe encoded into the abstraction and application constructs. The second,\n\"sequencing\", introduces the imperative notions of \"skip\" and \"sequence\",\nsimilar to kappa-calculus and concatenative programming languages. The key\nobservation of the RMC is that the first-order fragment of the FMC exhibits a\nlatent duality which, given a simple decomposition of the relevant\nconstructors, can be concretely expressed as an involution on syntax.\nSemantically, this gives rise to a sound and complete calculus for string\ndiagrams of Frobenius monoids. We consider unification as the corresponding\nsymmetric generalization of beta-reduction. By further including standard\noperators of Kleene algebra, the RMC embeds a range of computational models:\nthe kappa-calculus, logic programming, automata, Interaction Nets, and Petri\nNets, among others. These embeddings preserve operational semantics, which for\nthe RMC is again given by a generalization of the standard stack machine for\nthe lambda-calculus. The equational theory of the RMC (which supports reasoning\nabout its operational semantics) is conservative over both the first-order\nlambda-calculus and Kleene algebra, and can be oriented to give a confluent\nreduction relation.",
        "subjects": [
            "cs.PL",
            "03B70",
            "D.3.1; D.3.2; F.4.1; F.1.1; I.2.3"
        ],
        "authors": [
            "Chris Barrett",
            "Daniel Castle",
            "Willem Heijltjes"
        ],
        "published": "2024-05-17T14:11:59Z"
    },
    {
        "title": "Heterogeneity-Informed Meta-Parameter Learning for Spatiotemporal Time\n  Series Forecasting",
        "link": "http://arxiv.org/abs/2405.10800v1",
        "abstract": "Spatiotemporal time series forecasting plays a key role in a wide range of\nreal-world applications. While significant progress has been made in this area,\nfully capturing and leveraging spatiotemporal heterogeneity remains a\nfundamental challenge. Therefore, we propose a novel Heterogeneity-Informed\nMeta-Parameter Learning scheme. Specifically, our approach implicitly captures\nspatiotemporal heterogeneity through learning spatial and temporal embeddings,\nwhich can be viewed as a clustering process. Then, a novel spatiotemporal\nmeta-parameter learning paradigm is proposed to learn spatiotemporal-specific\nparameters from meta-parameter pools, which is informed by the captured\nheterogeneity. Based on these ideas, we develop a Heterogeneity-Informed\nSpatiotemporal Meta-Network (HimNet) for spatiotemporal time series\nforecasting. Extensive experiments on five widely-used benchmarks demonstrate\nour method achieves state-of-the-art performance while exhibiting superior\ninterpretability. Our code is available at\nhttps://github.com/XDZhelheim/HimNet.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Zheng Dong",
            "Renhe Jiang",
            "Haotian Gao",
            "Hangchen Liu",
            "Jinliang Deng",
            "Qingsong Wen",
            "Xuan Song"
        ],
        "published": "2024-05-17T14:10:34Z"
    },
    {
        "title": "Training Compute Thresholds: Features and Functions in AI Governance",
        "link": "http://arxiv.org/abs/2405.10799v1",
        "abstract": "This paper examines the use of training compute thresholds as a tool for\ngoverning artificial intelligence (AI) systems. We argue that compute\nthresholds serve as a valuable trigger for further evaluation of AI models,\nrather than being the sole determinant of the regulation. Key advantages of\ncompute thresholds include their correlation with model capabilities and risks,\nquantifiability, ease of measurement, robustness to circumvention, knowability\nbefore model development and deployment, potential for external verification,\nand targeted scope. Compute thresholds provide a practical starting point for\nidentifying potentially high-risk models and can be used as an initial filter\nin AI governance frameworks alongside other sector-specific regulations and\nbroader governance measures.",
        "subjects": [
            "cs.CY",
            "cs.LG"
        ],
        "authors": [
            "Lennart Heim"
        ],
        "published": "2024-05-17T14:10:24Z"
    },
    {
        "title": "CCTNet: A Circular Convolutional Transformer Network for LiDAR-based\n  Place Recognition Handling Movable Objects Occlusion",
        "link": "http://arxiv.org/abs/2405.10793v1",
        "abstract": "Place recognition is a fundamental task for robotic application, allowing\nrobots to perform loop closure detection within simultaneous localization and\nmapping (SLAM), and achieve relocalization on prior maps. Current range\nimage-based networks use single-column convolution to maintain feature\ninvariance to shifts in image columns caused by LiDAR viewpoint change.However,\nthis raises the issues such as \"restricted receptive fields\" and \"excessive\nfocus on local regions\", degrading the performance of networks. To address the\naforementioned issues, we propose a lightweight circular convolutional\nTransformer network denoted as CCTNet, which boosts performance by capturing\nstructural information in point clouds and facilitating crossdimensional\ninteraction of spatial and channel information. Initially, a Circular\nConvolution Module (CCM) is introduced, expanding the network's perceptual\nfield while maintaining feature consistency across varying LiDAR perspectives.\nThen, a Range Transformer Module (RTM) is proposed, which enhances place\nrecognition accuracy in scenarios with movable objects by employing a\ncombination of channel and spatial attention mechanisms. Furthermore, we\npropose an Overlap-based loss function, transforming the place recognition task\nfrom a binary loop closure classification into a regression problem linked to\nthe overlap between LiDAR frames. Through extensive experiments on the KITTI\nand Ford Campus datasets, CCTNet surpasses comparable methods, achieving\nRecall@1 of 0.924 and 0.965, and Recall@1% of 0.990 and 0.993 on the test set,\nshowcasing a superior performance. Results on the selfcollected dataset further\ndemonstrate the proposed method's potential for practical implementation in\ncomplex scenarios to handle movable objects, showing improved generalization in\nvarious datasets.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Gang Wang",
            "Chaoran Zhu",
            "Qian Xu",
            "Tongzhou Zhang",
            "Hai Zhang",
            "XiaoPeng Fan",
            "Jue Hu"
        ],
        "published": "2024-05-17T14:04:01Z"
    },
    {
        "title": "On Minimal Transversals of Maximal Cliques in Graphs",
        "link": "http://arxiv.org/abs/2405.10789v1",
        "abstract": "A hypergraph is conformal if it is the family of maximal cliques of a graph.\nIn this paper we are interested in the problem of determining when is the\nfamily of minimal transversal of maximal cliques of a graph conformal. Such\ngraphs are called clique dually conformal (CDC for short). As our main results,\nwe completely characterize CDC graphs within the families of triangle-free\ngraphs and split graphs. Both characterizations lead to polynomial-time\nrecognition algorithms. We also show that the class of CDC graphs is closed\nunder substitution, in the strong sense that substituting a graph $H$ for a\nvertex of a graph $G$ results in a CDC graph if and only if both $G$ and $H$\nare CDC.",
        "subjects": [
            "math.CO",
            "cs.DM",
            "cs.DS",
            "05C75, 05C69 (Primary) 05C65, 05D15, 05C85 (Secondary)"
        ],
        "authors": [
            "Endre Boros",
            "Vladimir Gurvich",
            "Martin Milanič",
            "Dmitry Tikhanovsky",
            "Yushi Uno"
        ],
        "published": "2024-05-17T13:59:54Z"
    },
    {
        "title": "QEdgeProxy: QoS-Aware Load Balancing for IoT Services in the Computing\n  Continuum",
        "link": "http://arxiv.org/abs/2405.10788v1",
        "abstract": "While various service orchestration aspects within Computing Continuum (CC)\nsystems have been extensively addressed, including service placement,\nreplication, and scheduling, an open challenge lies in ensuring uninterrupted\ndata delivery from IoT devices to running service instances in this dynamic\nenvironment, while adhering to specific Quality of Service (QoS) requirements\nand balancing the load on service instances. To address this challenge, we\nintroduce QEdgeProxy, an adaptive and QoS-aware load balancing framework\nspecifically designed for routing client requests to appropriate IoT service\ninstances in the CC. QEdgeProxy integrates naturally within Kubernetes, adapts\nto changes in dynamic environments, and manages to seamlessly deliver data to\nIoT service instances while consistently meeting QoS requirements and\neffectively distributing load across them. This is verified by extensive\nexperiments over a realistic K3s cluster with instance failures and network\nvariability, where QEdgeProxy outperforms both Kubernetes built-in mechanisms\nand a state-of-the-art solution, while introducing minimal computational\noverhead.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Ivan Čilić",
            "Valentin Jukanović",
            "Ivana Podnar Žarko",
            "Pantelis Frangoudis",
            "Schahram Dustdar"
        ],
        "published": "2024-05-17T13:56:49Z"
    },
    {
        "title": "On the Application of Reliability Theory to Cellular Network Mobility\n  Performance Analysis",
        "link": "http://arxiv.org/abs/2405.10787v1",
        "abstract": "Achieving connectivity reliability is one of the significant challenges for\n5G and beyond 5G cellular networks. The present understanding of reliability in\nthe context of mobile communication does not adequately cover the stochastic\ntemporal aspects of the network, such as the duration and spread of packet\nerrors that an outage session may cause. Rather, it simply confines the\ndefinition to the percentage of successful packet delivery. In this letter, we\noffer an elaborate modeling of the outage for a cellular mobile network by\nshowcasing the different types of outages and their contiguity characteristic.\nThereafter, using the outage metrics, we define two new key performance\nindicators (KPIs), namely mean outage time and mean time between outages as\ncounterparts to akin KPIs that already exist in classical reliability theory,\ni.e., mean down time and mean time between failures. Using a system-level\nsimulation where user mobility is a crucial component, it is shown that these\nnewly defined KPIs can be used to quantify the reliability requirements of\ndifferent user applications in cellular services.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Subhyal Bin Iqbal",
            "Behnam Khodapanah",
            "Philipp Schulz",
            "Gerhard P. Fettweis"
        ],
        "published": "2024-05-17T13:54:11Z"
    },
    {
        "title": "Using oxides to compute with heat",
        "link": "http://dx.doi.org/10.1038/s41578-024-00690-1",
        "abstract": "One of the most innovative possibilities offered by oxides is the use of heat\ncurrents for computational purposes. Towards this goal, phase-change oxides,\nincluding ferroelectrics, ferromagnets and related materials, could reproduce\nsources, logic units and memories used in current and future computing schemes.",
        "subjects": [
            "physics.app-ph",
            "cs.ET"
        ],
        "authors": [
            "Guillaume F. Nataf",
            "Sebastian Volz",
            "Jose Ordonez-Miranda",
            "Jorge Íñiguez-González",
            "Riccardo Rurali",
            "Brahim Dkhil"
        ],
        "published": "2024-05-17T13:43:52Z"
    },
    {
        "title": "Baseline Results for Selected Nonlinear System Identification Benchmarks",
        "link": "http://arxiv.org/abs/2405.10779v1",
        "abstract": "Nonlinear system identification remains an important open challenge across\nresearch and academia. Large numbers of novel approaches are seen published\neach year, each presenting improvements or extensions to existing methods. It\nis natural, therefore, to consider how one might choose between these competing\nmodels. Benchmark datasets provide one clear way to approach this question.\nHowever, to make meaningful inference based on benchmark performance it is\nimportant to understand how well a new method performs comparatively to results\navailable with well-established methods. This paper presents a set of ten\nbaseline techniques and their relative performances on five popular benchmarks.\nThe aim of this contribution is to stimulate thought and discussion regarding\nobjective comparison of identification methodologies.",
        "subjects": [
            "eess.SY",
            "cs.LG",
            "cs.SY"
        ],
        "authors": [
            "Max D. Champneys",
            "Gerben I. Beintema",
            "Roland Tóth",
            "Maarten Schoukens",
            "Maarten Schoukens",
            "Timothy J. Rogers"
        ],
        "published": "2024-05-17T13:40:59Z"
    },
    {
        "title": "Injective hardness condition for PCSPs",
        "link": "http://dx.doi.org/10.1145/3661814.3662072",
        "abstract": "We present a template for the Promise Constraint Satisfaction Problem (PCSP)\nwhich is NP-hard but does not satisfy the current state-of-the-art hardness\ncondition [ACMTCT'21]. We introduce a new \"injective\" condition based on the\nsmooth version of the layered PCP Theorem and use this new condition to confirm\nthat the problem is indeed NP-hard. In the second part of the article, we\nestablish a dichotomy for Boolean PCSPs defined by templates with polymorphisms\nin the set of linear threshold functions. The reasoning relies on the new\ninjective condition.",
        "subjects": [
            "cs.CC"
        ],
        "authors": [
            "Demian Banakh",
            "Marcin Kozik"
        ],
        "published": "2024-05-17T13:33:18Z"
    },
    {
        "title": "What should be observed for optimal reward in POMDPs?",
        "link": "http://arxiv.org/abs/2405.10768v1",
        "abstract": "Partially observable Markov Decision Processes (POMDPs) are a standard model\nfor agents making decisions in uncertain environments. Most work on POMDPs\nfocuses on synthesizing strategies based on the available capabilities.\nHowever, system designers can often control an agent's observation\ncapabilities, e.g. by placing or selecting sensors. This raises the question of\nhow one should select an agent's sensors cost-effectively such that it achieves\nthe desired goals. In this paper, we study the novel optimal observability\nproblem OOP: Given a POMDP M, how should one change M's observation\ncapabilities within a fixed budget such that its (minimal) expected reward\nremains below a given threshold? We show that the problem is undecidable in\ngeneral and decidable when considering positional strategies only. We present\ntwo algorithms for a decidable fragment of the OOP: one based on optimal\nstrategies of M's underlying Markov decision process and one based on parameter\nsynthesis with SMT. We report promising results for variants of typical\nexamples from the POMDP literature.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Alyzia-Maria Konsta",
            "Alberto Lluch Lafuente",
            "Christoph Matheja"
        ],
        "published": "2024-05-17T13:27:57Z"
    },
    {
        "title": "Evaluating Saliency Explanations in NLP by Crowdsourcing",
        "link": "http://arxiv.org/abs/2405.10767v1",
        "abstract": "Deep learning models have performed well on many NLP tasks. However, their\ninternal mechanisms are typically difficult for humans to understand. The\ndevelopment of methods to explain models has become a key issue in the\nreliability of deep learning models in many important applications. Various\nsaliency explanation methods, which give each feature of input a score\nproportional to the contribution of output, have been proposed to determine the\npart of the input which a model values most. Despite a considerable body of\nwork on the evaluation of saliency methods, whether the results of various\nevaluation metrics agree with human cognition remains an open question. In this\nstudy, we propose a new human-based method to evaluate saliency methods in NLP\nby crowdsourcing. We recruited 800 crowd workers and empirically evaluated\nseven saliency methods on two datasets with the proposed method. We analyzed\nthe performance of saliency methods, compared our results with existing\nautomated evaluation methods, and identified notable differences between NLP\nand computer vision (CV) fields when using saliency methods. The instance-level\ndata of our crowdsourced experiments and the code to reproduce the explanations\nare available at https://github.com/xtlu/lreccoling_evaluation.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Xiaotian Lu",
            "Jiyi Li",
            "Zhen Wan",
            "Xiaofeng Lin",
            "Koh Takeuchi",
            "Hisashi Kashima"
        ],
        "published": "2024-05-17T13:27:45Z"
    },
    {
        "title": "Fast Collision Probability Estimation for Automated Driving using\n  Multi-circular Shape Approximations",
        "link": "http://arxiv.org/abs/2405.10765v2",
        "abstract": "Many state-of-the-art methods for safety assessment and motion planning for\nautomated driving require estimation of the probability of collision (POC). To\nestimate the POC, a shape approximation of the colliding actors and probability\ndensity functions of the associated uncertain kinematic variables are required.\nEven with such information available, the derivation of the POC is in general,\ni.e., for any shape and density, only possible with Monte Carlo sampling (MCS).\nRandom sampling of the POC, however, is challenging as computational resources\nare limited in real-world applications. We present expressions for the POC in\nthe presence of Gaussian uncertainties, based on multi-circular shape\napproximations. In addition, we show that the proposed approach is\ncomputationally more efficient than MCS. Lastly, we provide a method for upper\nand lower bounding the estimation error for the POC induced by the used shape\napproximations.",
        "subjects": [
            "cs.RO",
            "math.PR"
        ],
        "authors": [
            "Leon Tolksdorf",
            "Christian Birkner",
            "Arturo Tejada",
            "Nathan van de Wouw"
        ],
        "published": "2024-05-17T13:27:14Z"
    },
    {
        "title": "Integer Traffic Assignment Problem: Algorithms and Insights on Random\n  Graphs",
        "link": "http://arxiv.org/abs/2405.10763v1",
        "abstract": "Path optimization is a fundamental concern across various real-world\nscenarios, ranging from traffic congestion issues to efficient data routing\nover the internet. The Traffic Assignment Problem (TAP) is a classic continuous\noptimization problem in this field. This study considers the Integer Traffic\nAssignment Problem (ITAP), a discrete variant of TAP. ITAP involves determining\noptimal routes for commuters in a city represented by a graph, aiming to\nminimize congestion while adhering to integer flow constraints on paths. This\nrestriction makes ITAP an NP-hard problem. While conventional TAP prioritizes\nrepulsive interactions to minimize congestion, this work also explores the case\nof attractive interactions, related to minimizing the number of occupied edges.\nWe present and evaluate multiple algorithms to address ITAP, including a\nmessage passing algorithm, a greedy approach, simulated annealing, and\nrelaxation of ITAP to TAP. Inspired by studies of random ensembles in the\nlarge-size limit in statistical physics, comparisons between these algorithms\nare conducted on large sparse random regular graphs with a random set of\norigin-destination pairs. Our results indicate that while the simplest greedy\nalgorithm performs competitively in the repulsive scenario, in the attractive\ncase the message-passing-based algorithm and simulated annealing demonstrate\nsuperiority. We then investigate the relationship between TAP and ITAP in the\nrepulsive case. We find that, as the number of paths increases, the solution of\nTAP converges toward that of ITAP, and we investigate the speed of this\nconvergence. Depending on the number of paths, our analysis leads us to\nidentify two scaling regimes: in one the average flow per edge is of order one,\nand in another the number of paths scales quadratically with the size of the\ngraph, in which case the continuous relaxation solves the integer problem\nclosely.",
        "subjects": [
            "cond-mat.dis-nn",
            "cs.DM",
            "math.OC",
            "stat.CO"
        ],
        "authors": [
            "Rayan Harfouche",
            "Giovanni Piccioli",
            "Lenka Zdeborová"
        ],
        "published": "2024-05-17T13:21:23Z"
    },
    {
        "title": "Research on Credit Risk Early Warning Model of Commercial Banks Based on\n  Neural Network Algorithm",
        "link": "http://arxiv.org/abs/2405.10762v1",
        "abstract": "In the realm of globalized financial markets, commercial banks are confronted\nwith an escalating magnitude of credit risk, thereby imposing heightened\nrequisites upon the security of bank assets and financial stability. This study\nharnesses advanced neural network techniques, notably the Backpropagation (BP)\nneural network, to pioneer a novel model for preempting credit risk in\ncommercial banks. The discourse initially scrutinizes conventional financial\nrisk preemptive models, such as ARMA, ARCH, and Logistic regression models,\ncritically analyzing their real-world applications. Subsequently, the\nexposition elaborates on the construction process of the BP neural network\nmodel, encompassing network architecture design, activation function selection,\nparameter initialization, and objective function construction. Through\ncomparative analysis, the superiority of neural network models in preempting\ncredit risk in commercial banks is elucidated. The experimental segment selects\nspecific bank data, validating the model's predictive accuracy and\npracticality. Research findings evince that this model efficaciously enhances\nthe foresight and precision of credit risk management.",
        "subjects": [
            "q-fin.RM",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Yu Cheng",
            "Qin Yang",
            "Liyang Wang",
            "Ao Xiang",
            "Jingyu Zhang"
        ],
        "published": "2024-05-17T13:18:46Z"
    },
    {
        "title": "Petri nets in modelling glucose regulating processes in the liver",
        "link": "http://arxiv.org/abs/2405.11009v1",
        "abstract": "Diabetes is a chronic condition, considered one of the civilization diseases,\nthat is characterized by sustained high blood sugar levels. There is no doubt\nthat more and more people is going to suffer from diabetes, hence it is crucial\nto understand better its biological foundations. The essential processes\nrelated to the control of glucose levels in the blood are: glycolysis (process\nof breaking down of glucose) and glucose synthesis, both taking place in the\nliver. The glycolysis occurs during feeding and it is stimulated by insulin. On\nthe other hand, the glucose synthesis arises during fasting and it is\nstimulated by glucagon. In the paper we present a Petri net model of glycolysis\nand glucose synthesis in the liver. The model is created based on medical\nliterature. Standard Petri nets techniques are used to analyse the properties\nof the model: traps, reachability graphs, tokens dynamics, deadlocks analysis.\nThe results are described in the paper. Our analysis shows that the model\ncaptures the interactions between different enzymes and substances, which is\nconsistent with the biological processes occurring during fasting and feeding.\nThe model constitutes the first element of our long-time goal to create the\nwhole body model of the glucose regulation in a healthy human and a person with\ndiabetes.",
        "subjects": [
            "q-bio.OT",
            "cs.CL",
            "68",
            "F.1.1"
        ],
        "authors": [
            "Kamila Barylska",
            "Anna Gogolińska"
        ],
        "published": "2024-05-17T13:15:01Z"
    },
    {
        "title": "Seeing is (Not) Believing: Practical Phishing Attacks Targeting Social\n  Media Sharing Cards",
        "link": "http://arxiv.org/abs/2405.10758v1",
        "abstract": "In the digital era, Online Social Networks (OSNs) play a crucial role in\ninformation dissemination, with sharing cards for link previews emerging as a\nkey feature. These cards offer snapshots of shared content, including titles,\ndescriptions, and images. In this study, we investigate the construction and\ndissemination mechanisms of these cards, focusing on two primary server-side\ngeneration methods based on Share-SDK and HTML meta tags. Our investigation\nreveals a novel type of attack, i.e., Sharing Card Forgery (SCF) attack that\ncan be exploited to create forged benign sharing cards for malicious links. We\ndemonstrate the feasibility of these attacks through practical implementations\nand evaluate their effectiveness across 13 various online social networks. Our\nfindings indicate a significant risk, as the deceptive cards can evade\ndetection and persist on social platforms, thus posing a substantial threat to\nuser security. We also delve into countermeasures and discuss the challenges in\neffectively mitigating these types of attacks. This study not only sheds light\non a novel phishing technique but also calls for heightened awareness and\nimproved defensive strategies in the OSN ecosystem.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Wangchenlu Huang",
            "Shenao Wang",
            "Yanjie Zhao",
            "Guosheng Xu",
            "Haoyu Wang"
        ],
        "published": "2024-05-17T13:13:23Z"
    },
    {
        "title": "Rethinking Graph Backdoor Attacks: A Distribution-Preserving Perspective",
        "link": "http://arxiv.org/abs/2405.10757v1",
        "abstract": "Graph Neural Networks (GNNs) have shown remarkable performance in various\ntasks. However, recent works reveal that GNNs are vulnerable to backdoor\nattacks. Generally, backdoor attack poisons the graph by attaching backdoor\ntriggers and the target class label to a set of nodes in the training graph. A\nGNN trained on the poisoned graph will then be misled to predict test nodes\nattached with trigger to the target class. Despite their effectiveness, our\nempirical analysis shows that triggers generated by existing methods tend to be\nout-of-distribution (OOD), which significantly differ from the clean data.\nHence, these injected triggers can be easily detected and pruned with widely\nused outlier detection methods in real-world applications. Therefore, in this\npaper, we study a novel problem of unnoticeable graph backdoor attacks with\nin-distribution (ID) triggers. To generate ID triggers, we introduce an OOD\ndetector in conjunction with an adversarial learning strategy to generate the\nattributes of the triggers within distribution. To ensure a high attack success\nrate with ID triggers, we introduce novel modules designed to enhance trigger\nmemorization by the victim model trained on poisoned graph. Extensive\nexperiments on real-world datasets demonstrate the effectiveness of the\nproposed method in generating in distribution triggers that can by-pass various\ndefense strategies while maintaining a high attack success rate.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "authors": [
            "Zhiwei Zhang",
            "Minhua Lin",
            "Enyan Dai",
            "Suhang Wang"
        ],
        "published": "2024-05-17T13:09:39Z"
    },
    {
        "title": "Stable Phase Retrieval with Mirror Descent",
        "link": "http://arxiv.org/abs/2405.10754v1",
        "abstract": "In this paper, we aim to reconstruct an n-dimensional real vector from m\nphaseless measurements corrupted by an additive noise. We extend the noiseless\nframework developed in [15], based on mirror descent (or Bregman gradient\ndescent), to deal with noisy measurements and prove that the procedure is\nstable to (small enough) additive noise. In the deterministic case, we show\nthat mirror descent converges to a critical point of the phase retrieval\nproblem, and if the algorithm is well initialized and the noise is small\nenough, the critical point is near the true vector up to a global sign change.\nWhen the measurements are i.i.d Gaussian and the signal-to-noise ratio is large\nenough, we provide global convergence guarantees that ensure that with high\nprobability, mirror descent converges to a global minimizer near the true\nvector (up to a global sign change), as soon as the number of measurements m is\nlarge enough. The sample complexity bound can be improved if a spectral method\nis used to provide a good initial guess. We complement our theoretical study\nwith several numerical results showing that mirror descent is both a\ncomputationally and statistically efficient scheme to solve the phase retrieval\nproblem.",
        "subjects": [
            "math.OC",
            "cs.CV",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Jean-Jacques Godeme",
            "Jalal Fadili",
            "Claude Amra",
            "Myriam Zerrad"
        ],
        "published": "2024-05-17T13:07:14Z"
    },
    {
        "title": "Some remarks on a mathematical model for water flow in porous media with\n  competition between transport and diffusion",
        "link": "http://arxiv.org/abs/2405.10751v1",
        "abstract": "The contribution deals with the mathematical modelling of fluid flow in\nporous media, in particular water flow in soils. The motivation is to describe\nthe competition between gravity and capillarity, or, in other words, between\ntransport and diffusion. The analysis is based on a mathematical model\ndeveloped by B. Detmann, C. Gavioli, and P. Krej\\v{c}\\'i, in which the effects\nof gravity are included in a novel way. The model consists of a nonlinear\npartial differential equation describing both the gravitational transport and\nthe capillary diffusion of water. Although analytical solutions can be obtained\nfor some special cases, only numerical solutions are available in more general\nsituations. The solving algorithm is based on a time discretisation and the\nfinite element method, and is written in Matlab. The results of the numerical\nsimulations are shown and the behaviour of the model is discussed.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "math.AP"
        ],
        "authors": [
            "Judita Runcziková",
            "Jan Chleboun",
            "Chiara Gavioli",
            "Pavel Krejčí"
        ],
        "published": "2024-05-17T13:01:15Z"
    },
    {
        "title": "Parameter Identification for Electrochemical Models of Lithium-Ion\n  Batteries Using Bayesian Optimization",
        "link": "http://arxiv.org/abs/2405.10750v1",
        "abstract": "Efficient parameter identification of electrochemical models is crucial for\naccurate monitoring and control of lithium-ion cells. This process becomes\nchallenging when applied to complex models that rely on a considerable number\nof interdependent parameters that affect the output response. Gradient-based\nand metaheuristic optimization techniques, although previously employed for\nthis task, are limited by their lack of robustness, high computational costs,\nand susceptibility to local minima. In this study, Bayesian Optimization is\nused for tuning the dynamic parameters of an electrochemical equivalent circuit\nbattery model (E-ECM) for a nickel-manganese-cobalt (NMC)-graphite cell. The\nperformance of the Bayesian Optimization is compared with baseline methods\nbased on gradient-based and metaheuristic approaches. The robustness of the\nparameter optimization method is tested by performing verification using an\nexperimental drive cycle. The results indicate that Bayesian Optimization\noutperforms Gradient Descent and PSO optimization techniques, achieving\nreductions on average testing loss by 28.8% and 5.8%, respectively. Moreover,\nBayesian optimization significantly reduces the variance in testing loss by\n95.8% and 72.7%, respectively.",
        "subjects": [
            "eess.SY",
            "cs.LG",
            "cs.SY"
        ],
        "authors": [
            "Jianzong Pi",
            "Samuel Filgueira da Silva",
            "Mehmet Fatih Ozkan",
            "Abhishek Gupta",
            "Marcello Canova"
        ],
        "published": "2024-05-17T12:59:15Z"
    },
    {
        "title": "Deep Data Consistency: a Fast and Robust Diffusion Model-based Solver\n  for Inverse Problems",
        "link": "http://arxiv.org/abs/2405.10748v1",
        "abstract": "Diffusion models have become a successful approach for solving various image\ninverse problems by providing a powerful diffusion prior. Many studies tried to\ncombine the measurement into diffusion by score function replacement, matrix\ndecomposition, or optimization algorithms, but it is hard to balance the data\nconsistency and realness. The slow sampling speed is also a main obstacle to\nits wide application. To address the challenges, we propose Deep Data\nConsistency (DDC) to update the data consistency step with a deep learning\nmodel when solving inverse problems with diffusion models. By analyzing\nexisting methods, the variational bound training objective is used to maximize\nthe conditional posterior and reduce its impact on the diffusion process. In\ncomparison with state-of-the-art methods in linear and non-linear tasks, DDC\ndemonstrates its outstanding performance of both similarity and realness\nmetrics in generating high-quality solutions with only 5 inference steps in\n0.77 seconds on average. In addition, the robustness of DDC is well illustrated\nin the experiments across datasets, with large noise and the capacity to solve\nmultiple tasks in only one pre-trained model.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hanyu Chen",
            "Zhixiu Hao",
            "Liying Xiao"
        ],
        "published": "2024-05-17T12:54:43Z"
    },
    {
        "title": "Causality in the Can: Diet Coke's Impact on Fatness",
        "link": "http://arxiv.org/abs/2405.10746v1",
        "abstract": "Artificially sweetened beverages like Diet Coke are often considered\nhealthier alternatives, but the debate over their impact on obesity persists.\nPrevious research has predominantly relied on observational data or randomized\ncontrolled trials (RCTs), which may not accurately capture the causal\nrelationship between Diet Coke consumption and obesity. This study uses causal\ninference methods, employing data from the National Health and Nutrition\nExamination Survey (NHANES) to examine this relationship across diverse\ndemographics. Instead of relying on RCT data, we constructed a causal graph and\napplied the back-door criterion with its adjustment formula to estimate the RCT\ndistributions. We then calculated the counterfactual quantity, the Probability\nof Necessity and Sufficiency (PNS), using both NHANES data and estimated RCT\ndata. We propose that PNS is the essential metric for assessing the impact of\nDiet Coke on obesity. Our results indicate that between 20% to 50% of\nindividuals, especially those with poor dietary habits, are more likely to gain\nweight from Diet Coke. Conversely, in groups like young females with healthier\ndiets, only a small proportion experience weight gain due to Diet Coke. These\nfindings highlight the influence of individual lifestyle and potential hormonal\nfactors on the varied effects of Diet Coke, providing a new framework for\nunderstanding its nutritional impacts on health.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "authors": [
            "Yicheng Qi",
            "Ang Li"
        ],
        "published": "2024-05-17T12:49:45Z"
    },
    {
        "title": "Empowering Small-Scale Knowledge Graphs: A Strategy of Leveraging\n  General-Purpose Knowledge Graphs for Enriched Embeddings",
        "link": "http://arxiv.org/abs/2405.10745v1",
        "abstract": "Knowledge-intensive tasks pose a significant challenge for Machine Learning\n(ML) techniques. Commonly adopted methods, such as Large Language Models\n(LLMs), often exhibit limitations when applied to such tasks. Nevertheless,\nthere have been notable endeavours to mitigate these challenges, with a\nsignificant emphasis on augmenting LLMs through Knowledge Graphs (KGs). While\nKGs provide many advantages for representing knowledge, their development costs\ncan deter extensive research and applications. Addressing this limitation, we\nintroduce a framework for enriching embeddings of small-scale domain-specific\nKnowledge Graphs with well-established general-purpose KGs. Adopting our\nmethod, a modest domain-specific KG can benefit from a performance boost in\ndownstream tasks when linked to a substantial general-purpose KG. Experimental\nevaluations demonstrate a notable enhancement, with up to a 44% increase\nobserved in the Hits@10 metric. This relatively unexplored research direction\ncan catalyze more frequent incorporation of KGs in knowledge-intensive tasks,\nresulting in more robust, reliable ML implementations, which hallucinates less\nthan prevalent LLM solutions.\n  Keywords: knowledge graph, knowledge graph completion, entity alignment,\nrepresentation learning, machine learning",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Albert Sawczyn",
            "Jakub Binkowski",
            "Piotr Bielak",
            "Tomasz Kajdanowicz"
        ],
        "published": "2024-05-17T12:46:23Z"
    },
    {
        "title": "Occupancy-SLAM: Simultaneously Optimizing Robot Poses and Continuous\n  Occupancy Map",
        "link": "http://dx.doi.org/10.15607/RSS.2022.XVIII.003",
        "abstract": "In this paper, we propose an optimization based SLAM approach to\nsimultaneously optimize the robot trajectory and the occupancy map using 2D\nlaser scans (and odometry) information. The key novelty is that the robot poses\nand the occupancy map are optimized together, which is significantly different\nfrom existing occupancy mapping strategies where the robot poses need to be\nobtained first before the map can be estimated. In our formulation, the map is\nrepresented as a continuous occupancy map where each 2D point in the\nenvironment has a corresponding evidence value. The Occupancy-SLAM problem is\nformulated as an optimization problem where the variables include all the robot\nposes and the occupancy values at the selected discrete grid cell nodes. We\npropose a variation of Gauss-Newton method to solve this new formulated\nproblem, obtaining the optimized occupancy map and robot trajectory together\nwith their uncertainties. Our algorithm is an offline approach since it is\nbased on batch optimization and the number of variables involved is large.\nEvaluations using simulations and publicly available practical 2D laser\ndatasets demonstrate that the proposed approach can estimate the maps and robot\ntrajectories more accurately than the state-of-the-art techniques, when a\nrelatively accurate initial guess is provided to our algorithm. The video shows\nthe convergence process of the proposed Occupancy-SLAM and comparison of\nresults to Cartographer can be found at \\url{https://youtu.be/4oLyVEUC4iY}.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Liang Zhao",
            "Yingyu Wang",
            "Shoudong Huang"
        ],
        "published": "2024-05-17T12:45:31Z"
    },
    {
        "title": "SBAAM! Eliminating Transcript Dependency in Automatic Subtitling",
        "link": "http://arxiv.org/abs/2405.10741v1",
        "abstract": "Subtitling plays a crucial role in enhancing the accessibility of audiovisual\ncontent and encompasses three primary subtasks: translating spoken dialogue,\nsegmenting translations into concise textual units, and estimating timestamps\nthat govern their on-screen duration. Past attempts to automate this process\nrely, to varying degrees, on automatic transcripts, employed diversely for the\nthree subtasks. In response to the acknowledged limitations associated with\nthis reliance on transcripts, recent research has shifted towards\ntranscription-free solutions for translation and segmentation, leaving the\ndirect generation of timestamps as uncharted territory. To fill this gap, we\nintroduce the first direct model capable of producing automatic subtitles,\nentirely eliminating any dependence on intermediate transcripts also for\ntimestamp prediction. Experimental results, backed by manual evaluation,\nshowcase our solution's new state-of-the-art performance across multiple\nlanguage pairs and diverse conditions.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Marco Gaido",
            "Sara Papi",
            "Matteo Negri",
            "Mauro Cettolo",
            "Luisa Bentivogli"
        ],
        "published": "2024-05-17T12:42:56Z"
    },
    {
        "title": "Efficient Multimodal Large Language Models: A Survey",
        "link": "http://arxiv.org/abs/2405.10739v1",
        "abstract": "In the past year, Multimodal Large Language Models (MLLMs) have demonstrated\nremarkable performance in tasks such as visual question answering, visual\nunderstanding and reasoning. However, the extensive model size and high\ntraining and inference costs have hindered the widespread application of MLLMs\nin academia and industry. Thus, studying efficient and lightweight MLLMs has\nenormous potential, especially in edge computing scenarios. In this survey, we\nprovide a comprehensive and systematic review of the current state of efficient\nMLLMs. Specifically, we summarize the timeline of representative efficient\nMLLMs, research state of efficient structures and strategies, and the\napplications. Finally, we discuss the limitations of current efficient MLLM\nresearch and promising future directions. Please refer to our GitHub repository\nfor more details:\nhttps://github.com/lijiannuist/Efficient-Multimodal-LLMs-Survey.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Yizhang Jin",
            "Jian Li",
            "Yexin Liu",
            "Tianjun Gu",
            "Kai Wu",
            "Zhengkai Jiang",
            "Muyang He",
            "Bo Zhao",
            "Xin Tan",
            "Zhenye Gan",
            "Yabiao Wang",
            "Chengjie Wang",
            "Lizhuang Ma"
        ],
        "published": "2024-05-17T12:37:10Z"
    },
    {
        "title": "Feature-Adaptive and Data-Scalable In-Context Learning",
        "link": "http://arxiv.org/abs/2405.10738v1",
        "abstract": "In-context learning (ICL), which promotes inference with several\ndemonstrations, has become a widespread paradigm to stimulate LLM capabilities\nfor downstream tasks. Due to context length constraints, it cannot be further\nimproved in spite of more training data, and general features directly from\nLLMs in ICL are not adaptive to the specific downstream task. In this paper, we\npropose a feature-adaptive and data-scalable in-context learning framework\n(FADS-ICL), which can leverage task-adaptive features to promote inference on\nthe downstream task, with the supervision of beyond-context samples.\nSpecifically, it first extracts general features of beyond-context samples via\nthe LLM with ICL input form one by one, and introduces a task-specific\nmodulator to perform feature refinement and prediction after fitting a specific\ndownstream task. We conduct extensive experiments on FADS-ICL under varying\ndata settings (4$\\sim$128 shots) and LLM scale (0.8$\\sim$70B) settings.\nExperimental results show that FADS-ICL consistently outperforms previous\nstate-of-the-art methods by a significant margin under all settings, verifying\nthe effectiveness and superiority of FADS-ICL. For example, under the 1.5B and\n32 shots setting, FADS-ICL can achieve \\textbf{+14.3} average accuracy from\nfeature adaptation over vanilla ICL on 10 datasets, with \\textbf{+6.2} average\naccuracy over the previous state-of-the-art method, and the performance can\nfurther improve with increasing training data. Code and data are publicly\navailable at \\url{https://github.com/jiahaozhenbang/FADS-ICL}.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Jiahao Li",
            "Quan Wang",
            "Licheng Zhang",
            "Guoqing Jin",
            "Zhendong Mao"
        ],
        "published": "2024-05-17T12:32:53Z"
    },
    {
        "title": "StackOverflowVQA: Stack Overflow Visual Question Answering Dataset",
        "link": "http://arxiv.org/abs/2405.10736v1",
        "abstract": "In recent years, people have increasingly used AI to help them with their\nproblems by asking questions on different topics. One of these topics can be\nsoftware-related and programming questions. In this work, we focus on the\nquestions which need the understanding of images in addition to the question\nitself. We introduce the StackOverflowVQA dataset, which includes questions\nfrom StackOverflow that have one or more accompanying images. This is the first\nVQA dataset that focuses on software-related questions and contains multiple\nhuman-generated full-sentence answers. Additionally, we provide a baseline for\nanswering the questions with respect to images in the introduced dataset using\nthe GIT model. All versions of the dataset are available at\nhttps://huggingface.co/mirzaei2114.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Motahhare Mirzaei",
            "Mohammad Javad Pirhadi",
            "Sauleh Eetemadi"
        ],
        "published": "2024-05-17T12:30:23Z"
    },
    {
        "title": "Contestable AI needs Computational Argumentation",
        "link": "http://arxiv.org/abs/2405.10729v1",
        "abstract": "AI has become pervasive in recent years, but state-of-the-art approaches\npredominantly neglect the need for AI systems to be contestable. Instead,\ncontestability is advocated by AI guidelines (e.g. by the OECD) and regulation\nof automated decision-making (e.g. GDPR). In this position paper we explore how\ncontestability can be achieved computationally in and for AI. We argue that\ncontestable AI requires dynamic (human-machine and/or machine-machine)\nexplainability and decision-making processes, whereby machines can (i) interact\nwith humans and/or other machines to progressively explain their outputs and/or\ntheir reasoning as well as assess grounds for contestation provided by these\nhumans and/or other machines, and (ii) revise their decision-making processes\nto redress any issues successfully raised during contestation. Given that much\nof the current AI landscape is tailored to static AIs, the need to accommodate\ncontestability will require a radical rethinking, that, we argue, computational\nargumentation is ideally suited to support.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Francesco Leofante",
            "Hamed Ayoobi",
            "Adam Dejl",
            "Gabriel Freedman",
            "Deniz Gorur",
            "Junqi Jiang",
            "Guilherme Paulino-Passos",
            "Antonio Rago",
            "Anna Rapberger",
            "Fabrizio Russo",
            "Xiang Yin",
            "Dekai Zhang",
            "Francesca Toni"
        ],
        "published": "2024-05-17T12:23:18Z"
    },
    {
        "title": "INDUS: Effective and Efficient Language Models for Scientific\n  Applications",
        "link": "http://arxiv.org/abs/2405.10725v2",
        "abstract": "Large language models (LLMs) trained on general domain corpora showed\nremarkable results on natural language processing (NLP) tasks. However,\nprevious research demonstrated LLMs trained using domain-focused corpora\nperform better on specialized tasks. Inspired by this pivotal insight, we\ndeveloped INDUS, a comprehensive suite of LLMs tailored for the Earth science,\nbiology, physics, heliophysics, planetary sciences and astrophysics domains and\ntrained using curated scientific corpora drawn from diverse data sources. The\nsuite of models include: (1) an encoder model trained using domain-specific\nvocabulary and corpora to address natural language understanding tasks, (2) a\ncontrastive-learning-based general text embedding model trained using a diverse\nset of datasets drawn from multiple sources to address information retrieval\ntasks and (3) smaller versions of these models created using knowledge\ndistillation techniques to address applications which have latency or resource\nconstraints. We also created three new scientific benchmark datasets namely,\nCLIMATE-CHANGE-NER (entity-recognition), NASA-QA (extractive QA) and NASA-IR\n(IR) to accelerate research in these multi-disciplinary fields. Finally, we\nshow that our models outperform both general-purpose encoders (RoBERTa) and\nexisting domain-specific encoders (SciBERT) on these new tasks as well as\nexisting benchmark tasks in the domains of interest.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "authors": [
            "Bishwaranjan Bhattacharjee",
            "Aashka Trivedi",
            "Masayasu Muraoka",
            "Muthukumaran Ramasubramanian",
            "Takuma Udagawa",
            "Iksha Gurung",
            "Rong Zhang",
            "Bharath Dandala",
            "Rahul Ramachandran",
            "Manil Maskey",
            "Kaylin Bugbee",
            "Mike Little",
            "Elizabeth Fancher",
            "Lauren Sanders",
            "Sylvain Costes",
            "Sergi Blanco-Cuaresma",
            "Kelly Lockhart",
            "Thomas Allen",
            "Felix Grezes",
            "Megan Ansdell",
            "Alberto Accomazzi",
            "Yousef El-Kurdi",
            "Davis Wertheimer",
            "Birgit Pfitzmann",
            "Cesar Berrospi Ramis",
            "Michele Dolfi",
            "Rafael Teixeira de Lima",
            "Panagiotis Vagenas",
            "S. Karthik Mukkavilli",
            "Peter Staar",
            "Sanaz Vahidinia",
            "Ryan McGranaghan",
            "Armin Mehrabian",
            "Tsendgar Lee"
        ],
        "published": "2024-05-17T12:15:07Z"
    },
    {
        "title": "Eddeep: Fast eddy-current distortion correction for diffusion MRI with\n  deep learning",
        "link": "http://arxiv.org/abs/2405.10723v1",
        "abstract": "Modern diffusion MRI sequences commonly acquire a large number of volumes\nwith diffusion sensitization gradients of differing strengths or directions.\nSuch sequences rely on echo-planar imaging (EPI) to achieve reasonable scan\nduration. However, EPI is vulnerable to off-resonance effects, leading to\ntissue susceptibility and eddy-current induced distortions. The latter is\nparticularly problematic because it causes misalignment between volumes,\ndisrupting downstream modelling and analysis. The essential correction of eddy\ndistortions is typically done post-acquisition, with image registration.\nHowever, this is non-trivial because correspondence between volumes can be\nseverely disrupted due to volume-specific signal attenuations induced by\nvarying directions and strengths of the applied gradients. This challenge has\nbeen successfully addressed by the popular FSL~Eddy tool but at considerable\ncomputational cost. We propose an alternative approach, leveraging recent\nadvances in image processing enabled by deep learning (DL). It consists of two\nconvolutional neural networks: 1) An image translator to restore correspondence\nbetween images; 2) A registration model to align the translated images. Results\ndemonstrate comparable distortion estimates to FSL~Eddy, while requiring only\nmodest training sample sizes. This work, to the best of our knowledge, is the\nfirst to tackle this problem with deep learning. Together with recently\ndeveloped DL-based susceptibility correction techniques, they pave the way for\nreal-time preprocessing of diffusion MRI, facilitating its wider uptake in the\nclinic.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Antoine Legouhy",
            "Ross Callaghan",
            "Whitney Stee",
            "Philippe Peigneux",
            "Hojjat Azadbakht",
            "Hui Zhang"
        ],
        "published": "2024-05-17T12:11:58Z"
    },
    {
        "title": "About the Burton-Miller factor in the low frequency region",
        "link": "http://arxiv.org/abs/2405.10722v1",
        "abstract": "The Burton-Miller method is a widely used approach in acoustics to enhance\nthe stability of the boundary element method for exterior Helmholtz problems at\nso-called critical frequencies. This method depends on a coupling parameter\n$\\eta$ and it can be shown that as long as $\\eta$ has an imaginary part\ndifferent from 0, the boundary integral formulation for the Helmholtz equation\nhas a unique solution at all frequencies. A popular choice for this parameter\nis $\\eta = \\frac{\\mathrm{i}}{k}$, where $k$ is the wavenumber. It can be shown\nthat this choice is quasi optimal. However, especially in the low frequency\nregion, where the critical frequencies are still sparsely distributed,\ndifferent choices for this factor result in a smaller condition number and a\nsmaller error of the solution. In this work, alternative choices for this\nfactor are compared based on numerical experiments. Additionally, a way to\nenhance the Burton-Miller solution with $\\eta = \\frac{\\mathrm{i}}{k}$ for a\nsound hard scatterer in the low frequency region by an additional step of a\nmodified Richardson iteration is introduced.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Wolfgang Kreuzer"
        ],
        "published": "2024-05-17T12:10:00Z"
    },
    {
        "title": "SignLLM: Sign Languages Production Large Language Models",
        "link": "http://arxiv.org/abs/2405.10718v1",
        "abstract": "In this paper, we introduce the first comprehensive multilingual sign\nlanguage dataset named Prompt2Sign, which builds from public data including\nAmerican Sign Language (ASL) and seven others. Our dataset transforms a vast\narray of videos into a streamlined, model-friendly format, optimized for\ntraining with translation models like seq2seq and text2text. Building on this\nnew dataset, we propose SignLLM, the first multilingual Sign Language\nProduction (SLP) model, which includes two novel multilingual SLP modes that\nallow for the generation of sign language gestures from input text or prompt.\nBoth of the modes can use a new loss and a module based on reinforcement\nlearning, which accelerates the training by enhancing the model's capability to\nautonomously sample high-quality data. We present benchmark results of SignLLM,\nwhich demonstrate that our model achieves state-of-the-art performance on SLP\ntasks across eight sign languages.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "authors": [
            "Sen Fang",
            "Lei Wang",
            "Ce Zheng",
            "Yapeng Tian",
            "Chen Chen"
        ],
        "published": "2024-05-17T12:01:43Z"
    },
    {
        "title": "Persian Pronoun Resolution: Leveraging Neural Networks and Language\n  Models",
        "link": "http://arxiv.org/abs/2405.10714v1",
        "abstract": "Coreference resolution, critical for identifying textual entities referencing\nthe same entity, faces challenges in pronoun resolution, particularly\nidentifying pronoun antecedents. Existing methods often treat pronoun\nresolution as a separate task from mention detection, potentially missing\nvaluable information. This study proposes the first end-to-end neural network\nsystem for Persian pronoun resolution, leveraging pre-trained Transformer\nmodels like ParsBERT. Our system jointly optimizes both mention detection and\nantecedent linking, achieving a 3.37 F1 score improvement over the previous\nstate-of-the-art system (which relied on rule-based and statistical methods) on\nthe Mehr corpus. This significant improvement demonstrates the effectiveness of\ncombining neural networks with linguistic models, potentially marking a\nsignificant advancement in Persian pronoun resolution and paving the way for\nfurther research in this under-explored area.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Hassan Haji Mohammadi",
            "Alireza Talebpour",
            "Ahmad Mahmoudi Aznaveh",
            "Samaneh Yazdani"
        ],
        "published": "2024-05-17T11:56:00Z"
    },
    {
        "title": "Development of Semantics-Based Distributed Middleware for Heterogeneous\n  Data Integration and its Application for Drought",
        "link": "http://arxiv.org/abs/2405.10713v1",
        "abstract": "Drought is a complex environmental phenomenon that affects millions of people\nand communities all over the globe and is too elusive to be accurately\npredicted. This is mostly due to the scalability and variability of the web of\nenvironmental parameters that directly/indirectly causes the onset of different\ncategories of drought. Since the dawn of man, efforts have been made to\nuniquely understand the natural indicators that provide signs of likely\nenvironmental events. These indicators/signs in the form of indigenous\nknowledge system have been used for generations. The intricate complexity of\ndrought has, however, always been a major stumbling block for accurate drought\nprediction and forecasting systems. Recently, scientists in the field of\nagriculture and environmental monitoring have been discussing the integration\nof indigenous knowledge and scientific knowledge for a more accurate\nenvironmental forecasting system in order to incorporate diverse environmental\ninformation for a reliable drought forecast. Hence, in this research, the core\nobjective is the development of a semantics-based data integration middleware\nthat encompasses and integrates heterogeneous data models of local indigenous\nknowledge and sensor data towards an accurate drought forecasting system for\nthe study areas. The local indigenous knowledge on drought gathered from the\ndomain experts is transformed into rules to be used for performing deductive\ninference in conjunction with sensors data for determining the onset of drought\nthrough an automated inference generation module of the middleware. The\nsemantic middleware incorporates, inter alia, a distributed architecture that\nconsists of a streaming data processing engine based on Apache Kafka for\nreal-time stream processing; a rule-based reasoning module; an ontology module\nfor semantic representation of the knowledge bases.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "authors": [
            "A Akanbi"
        ],
        "published": "2024-05-17T11:44:22Z"
    },
    {
        "title": "Numerical Recovery of the Diffusion Coefficient in Diffusion Equations\n  from Terminal Measurement",
        "link": "http://arxiv.org/abs/2405.10708v1",
        "abstract": "In this work, we investigate a numerical procedure for recovering a\nspace-dependent diffusion coefficient in a (sub)diffusion model from the given\nterminal data, and provide a rigorous numerical analysis of the procedure. By\nexploiting decay behavior of the observation in time, we establish a novel\nH{\\\"o}lder type stability estimate for a large terminal time $T$. This is\nachieved by novel decay estimates of the (fractional) time derivative of the\nsolution. To numerically recover the diffusion coefficient, we employ the\nstandard output least-squares formulation with an $H^1(\\Omega)$-seminorm\npenalty, and discretize the regularized problem by the Galerkin finite element\nmethod with continuous piecewise linear finite elements in space and backward\nEuler convolution quadrature in time. Further, we provide an error analysis of\ndiscrete approximations, and prove a convergence rate that matches the\nstability estimate. The derived $L^2(\\Omega)$ error bound depends explicitly on\nthe noise level, regularization parameter and discretization parameter(s),\nwhich gives a useful guideline of the \\textsl{a priori} choice of\ndiscretization parameters with respect to the noise level in practical\nimplementation. The error analysis is achieved using the conditional stability\nargument and discrete maximum-norm resolvent estimates. Several numerical\nexperiments are also given to illustrate and complement the theoretical\nanalysis.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Bangti Jin",
            "Xiliang Lu",
            "Qimeng Quan",
            "Zhi Zhou"
        ],
        "published": "2024-05-17T11:29:25Z"
    },
    {
        "title": "HARIS: Human-Like Attention for Reference Image Segmentation",
        "link": "http://arxiv.org/abs/2405.10707v2",
        "abstract": "Referring image segmentation (RIS) aims to locate the particular region\ncorresponding to the language expression. Existing methods incorporate features\nfrom different modalities in a \\emph{bottom-up} manner. This design may get\nsome unnecessary image-text pairs, which leads to an inaccurate segmentation\nmask. In this paper, we propose a referring image segmentation method called\nHARIS, which introduces the Human-Like Attention mechanism and uses the\nparameter-efficient fine-tuning (PEFT) framework. To be specific, the\nHuman-Like Attention gets a \\emph{feedback} signal from multi-modal features,\nwhich makes the network center on the specific objects and discard the\nirrelevant image-text pairs. Besides, we introduce the PEFT framework to\npreserve the zero-shot ability of pre-trained encoders. Extensive experiments\non three widely used RIS benchmarks and the PhraseCut dataset demonstrate that\nour method achieves state-of-the-art performance and great zero-shot ability.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Mengxi Zhang",
            "Heqing Lian",
            "Yiming Liu",
            "Jie Chen"
        ],
        "published": "2024-05-17T11:29:23Z"
    },
    {
        "title": "Challenging the Human-in-the-loop in Algorithmic Decision-making",
        "link": "http://arxiv.org/abs/2405.10706v1",
        "abstract": "We discuss the role of humans in algorithmic decision-making (ADM) for\nsocially relevant problems from a technical and philosophical perspective. In\nparticular, we illustrate tensions arising from diverse expectations, values,\nand constraints by and on the humans involved. To this end, we assume that a\nstrategic decision-maker (SDM) introduces ADM to optimize strategic and\nsocietal goals while the algorithms' recommended actions are overseen by a\npractical decision-maker (PDM) - a specific human-in-the-loop - who makes the\nfinal decisions. While the PDM is typically assumed to be a corrective, it can\ncounteract the realization of the SDM's desired goals and societal values not\nleast because of a misalignment of these values and unmet information needs of\nthe PDM. This has significant implications for the distribution of power\nbetween the stakeholders in ADM, their constraints, and information needs. In\nparticular, we emphasize the overseeing PDM's role as a potential political and\nethical decision maker, who acts expected to balance strategic, value-driven\nobjectives and on-the-ground individual decisions and constraints. We\ndemonstrate empirically, on a machine learning benchmark dataset, the\nsignificant impact an overseeing PDM's decisions can have even if the PDM is\nconstrained to performing only a limited amount of actions differing from the\nalgorithms' recommendations. To ensure that the SDM's intended values are\nrealized, the PDM needs to be provided with appropriate information conveyed\nthrough tailored explanations and its role must be characterized clearly. Our\nfindings emphasize the need for an in-depth discussion of the role and power of\nthe PDM and challenge the often-taken view that just including a\nhuman-in-the-loop in ADM ensures the 'correct' and 'ethical' functioning of the\nsystem.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Sebastian Tschiatschek",
            "Eugenia Stamboliev",
            "Timoth ee Schmude",
            "Mark Coeckelbergh",
            "Laura Koesten"
        ],
        "published": "2024-05-17T11:28:52Z"
    },
    {
        "title": "3D Vessel Reconstruction from Sparse-View Dynamic DSA Images via Vessel\n  Probability Guided Attenuation Learning",
        "link": "http://arxiv.org/abs/2405.10705v1",
        "abstract": "Digital Subtraction Angiography (DSA) is one of the gold standards in\nvascular disease diagnosing. With the help of contrast agent, time-resolved 2D\nDSA images deliver comprehensive insights into blood flow information and can\nbe utilized to reconstruct 3D vessel structures. Current commercial DSA systems\ntypically demand hundreds of scanning views to perform reconstruction,\nresulting in substantial radiation exposure. However, sparse-view DSA\nreconstruction, aimed at reducing radiation dosage, is still underexplored in\nthe research community. The dynamic blood flow and insufficient input of\nsparse-view DSA images present significant challenges to the 3D vessel\nreconstruction task. In this study, we propose to use a time-agnostic vessel\nprobability field to solve this problem effectively. Our approach, termed as\nvessel probability guided attenuation learning, represents the DSA imaging as a\ncomplementary weighted combination of static and dynamic attenuation fields,\nwith the weights derived from the vessel probability field. Functioning as a\ndynamic mask, vessel probability provides proper gradients for both static and\ndynamic fields adaptive to different scene types. This mechanism facilitates a\nself-supervised decomposition between static backgrounds and dynamic contrast\nagent flow, and significantly improves the reconstruction quality. Our model is\ntrained by minimizing the disparity between synthesized projections and real\ncaptured DSA images. We further employ two training strategies to improve our\nreconstruction quality: (1) coarse-to-fine progressive training to achieve\nbetter geometry and (2) temporal perturbed rendering loss to enforce temporal\nconsistency. Experimental results have demonstrated superior quality on both 3D\nvessel reconstruction and 2D view synthesis.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Zhentao Liu",
            "Huangxuan Zhao",
            "Wenhui Qin",
            "Zhenghong Zhou",
            "Xinggang Wang",
            "Wenping Wang",
            "Xiaochun Lai",
            "Chuansheng Zheng",
            "Dinggang Shen",
            "Zhiming Cui"
        ],
        "published": "2024-05-17T11:23:33Z"
    },
    {
        "title": "Safe Control using Occupancy Grid Map-based Control Barrier Function\n  (OGM-CBF)",
        "link": "http://arxiv.org/abs/2405.10703v2",
        "abstract": "Safe navigation in unknown environments stands as a significant challenge in\nthe field of robotics. Control Barrier Function (CBF) is a strong mathematical\ntool to guarantee safety requirements. However, a common assumption in many\nworks is that the CBF is already known and obstacles have predefined shapes. In\nthis letter, we present a novel method called Occupancy Grid Map-based Control\nBarrier Function (OGM-CBF), which defines Control Barrier Function based on\nOccupancy Grid Maps. This enables generalization to unknown environments while\ngenerating online local or global maps of the environment using onboard\nperception sensors such as LiDAR or camera. With this method, the system\nguarantees safety via a single, continuously differentiable CBF per time step,\nwhich can be represented as one constraint in the CBF-QP optimization\nformulation while having an arbitrary number of obstacles with unknown shapes\nin the environment. This enables practical real-time implementation of CBF in\nboth unknown and known environments. The efficacy of OGM-CBF is demonstrated in\nthe safe control of an autonomous car in the CARLA simulator and a real-world\nindustrial mobile robot.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Golnaz Raja",
            "Teemu Mökkönen",
            "Reza Ghabcheloo"
        ],
        "published": "2024-05-17T11:22:36Z"
    },
    {
        "title": "Empowering Prior to Court Legal Analysis: A Transparent and Accessible\n  Dataset for Defensive Statement Classification and Interpretation",
        "link": "http://arxiv.org/abs/2405.10702v1",
        "abstract": "The classification of statements provided by individuals during police\ninterviews is a complex and significant task within the domain of natural\nlanguage processing (NLP) and legal informatics. The lack of extensive\ndomain-specific datasets raises challenges to the advancement of NLP methods in\nthe field. This paper aims to address some of the present challenges by\nintroducing a novel dataset tailored for classification of statements made\nduring police interviews, prior to court proceedings. Utilising the curated\ndataset for training and evaluation, we introduce a fine-tuned DistilBERT model\nthat achieves state-of-the-art performance in distinguishing truthful from\ndeceptive statements. To enhance interpretability, we employ explainable\nartificial intelligence (XAI) methods to offer explainability through saliency\nmaps, that interpret the model's decision-making process. Lastly, we present an\nXAI interface that empowers both legal professionals and non-specialists to\ninteract with and benefit from our system. Our model achieves an accuracy of\n86%, and is shown to outperform a custom transformer architecture in a\ncomparative study. This holistic approach advances the accessibility,\ntransparency, and effectiveness of statement analysis, with promising\nimplications for both legal practice and research.",
        "subjects": [
            "cs.CL",
            "cs.CV"
        ],
        "authors": [
            "Yannis Spyridis",
            " Jean-Paul",
            "Haneen Deeb",
            "Vasileios Argyriou"
        ],
        "published": "2024-05-17T11:22:27Z"
    },
    {
        "title": "SynDy: Synthetic Dynamic Dataset Generation Framework for Misinformation\n  Tasks",
        "link": "http://dx.doi.org/10.1145/3626772.3657667",
        "abstract": "Diaspora communities are disproportionately impacted by off-the-radar\nmisinformation and often neglected by mainstream fact-checking efforts,\ncreating a critical need to scale-up efforts of nascent fact-checking\ninitiatives. In this paper we present SynDy, a framework for Synthetic Dynamic\nDataset Generation to leverage the capabilities of the largest frontier Large\nLanguage Models (LLMs) to train local, specialized language models. To the best\nof our knowledge, SynDy is the first paper utilizing LLMs to create\nfine-grained synthetic labels for tasks of direct relevance to misinformation\nmitigation, namely Claim Matching, Topical Clustering, and Claim Relationship\nClassification. SynDy utilizes LLMs and social media queries to automatically\ngenerate distantly-supervised, topically-focused datasets with synthetic labels\non these three tasks, providing essential tools to scale up human-led\nfact-checking at a fraction of the cost of human-annotated data. Training on\nSynDy's generated labels shows improvement over a standard baseline and is not\nsignificantly worse compared to training on human labels (which may be\ninfeasible to acquire). SynDy is being integrated into Meedan's chatbot\ntiplines that are used by over 50 organizations, serve over 230K users\nannually, and automatically distribute human-written fact-checks via messaging\napps such as WhatsApp. SynDy will also be integrated into our deployed\nCo-Insights toolkit, enabling low-resource organizations to launch tiplines for\ntheir communities. Finally, we envision SynDy enabling additional fact-checking\ntools such as matching new misinformation claims to high-quality explainers on\ncommon misinformation topics.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.CL",
            "cs.CY"
        ],
        "authors": [
            "Michael Shliselberg",
            "Ashkan Kazemi",
            "Scott A. Hale",
            "Shiri Dori-Hacohen"
        ],
        "published": "2024-05-17T11:14:55Z"
    },
    {
        "title": "A Systematic Review and Meta-Analysis on Sleep Stage Classification and\n  Sleep Disorder Detection Using Artificial Intelligence",
        "link": "http://arxiv.org/abs/2405.11008v1",
        "abstract": "Sleep is vital for people's physical and mental health, and sound sleep can\nhelp them focus on daily activities. Therefore, a sleep study that includes\nsleep patterns and disorders is crucial to enhancing our knowledge about\nindividuals' health status. The findings on sleep stages and sleep disorders\nrelied on polysomnography and self-report measures, and then the study went\nthrough clinical assessments by expert physicians. However, the evaluation\nprocess of sleep stage classification and sleep disorder has become more\nconvenient with artificial intelligence applications and numerous\ninvestigations focusing on various datasets with advanced algorithms and\ntechniques that offer improved computational ease and accuracy. This study aims\nto provide a comprehensive, systematic review and meta-analysis of the recent\nliterature to analyze the different approaches and their outcomes in sleep\nstudies, which includes works on sleep stages classification and sleep disorder\ndetection using AI. In this review, 183 articles were initially selected from\ndifferent journals, among which 80 records were enlisted for explicit review,\nranging from 2016 to 2023. Brain waves were the most commonly employed body\nparameters for sleep staging and disorder studies. The convolutional neural\nnetwork, the most widely used of the 34 distinct artificial intelligence\nmodels, comprised 27%. The other models included the long short-term memory,\nsupport vector machine, random forest, and recurrent neural network, which\nconsisted of 11%, 6%, 6%, and 5% sequentially. For performance metrics,\naccuracy was widely used for a maximum of 83.75% of the cases, the F1 score of\n45%, Kappa of 36.25%, Sensitivity of 31.25%, and Specificity of 30% of cases,\nalong with the other metrics. This article would help physicians and\nresearchers get the gist of AI's contribution to sleep studies and the\nfeasibility of their intended work.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Tayab Uddin Wara",
            "Ababil Hossain Fahad",
            "Adri Shankar Das",
            "Md. Mehedi Hasan Shawon"
        ],
        "published": "2024-05-17T11:09:33Z"
    },
    {
        "title": "Autonomous AI-enabled Industrial Sorting Pipeline for Advanced Textile\n  Recycling",
        "link": "http://arxiv.org/abs/2405.10696v1",
        "abstract": "The escalating volumes of textile waste globally necessitate innovative waste\nmanagement solutions to mitigate the environmental impact and promote\nsustainability in the fashion industry. This paper addresses the inefficiencies\nof traditional textile sorting methods by introducing an autonomous textile\nanalysis pipeline. Utilising robotics, spectral imaging, and AI-driven\nclassification, our system enhances the accuracy, efficiency, and scalability\nof textile sorting processes, contributing to a more sustainable and circular\napproach to waste management. The integration of a Digital Twin system further\nallows critical evaluation of technical and economic feasibility, providing\nvaluable insights into the sorting system's accuracy and reliability. The\nproposed framework, inspired by Industry 4.0 principles, comprises five\ninterconnected layers facilitating seamless data exchange and coordination\nwithin the system. Preliminary results highlight the potential of our holistic\napproach to mitigate environmental impact and foster a positive shift towards\nrecycling in the textile industry.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yannis Spyridis",
            "Vasileios Argyriou",
            "Antonios Sarigiannidis",
            "Panagiotis Radoglou",
            "Panagiotis Sarigiannidis"
        ],
        "published": "2024-05-17T11:08:47Z"
    },
    {
        "title": "On the Design of Super Constellations",
        "link": "http://arxiv.org/abs/2405.10695v1",
        "abstract": "In the evolving landscape of sixth-generation (6G) wireless networks, which\ndemand ultra high data rates, this study introduces the concept of super\nconstellation communications. Also, we present super amplitude phase shift\nkeying (SAPSK), an innovative modulation technique designed to achieve these\nultra high data rate demands. SAPSK is complemented by the generalized polar\ndistance detector (GPD-D), which approximates the optimal maximum likelihood\ndetector in channels with Gaussian phase noise (GPN). By leveraging the\ndecision regions formulated by GPD-D, a tight closed-form approximation for the\nsymbol error probability (SEP) of SAPSK constellations is derived, while a\ndetection algorithm with O(1) time complexity is developed to ensure fast and\nefficient SAPSK symbol detection. Finally, the theoretical performance of SAPSK\nand the efficiency of the proposed O(1) algorithm are validated by numerical\nsimulations, highlighting both its superiority in terms of SEP compared to\nvarious constellations and its practical advantages in terms of fast and\naccurate symbol detection.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Thrassos K. Oikonomou",
            "Dimitrios Tyrovolas",
            "Sotiris A. Tegos",
            "Panagiotis D. Diamantoulakis",
            "Panagiotis Sarigiannidis",
            "George K. Karagiannidis"
        ],
        "published": "2024-05-17T11:05:24Z"
    },
    {
        "title": "LoCI-DiffCom: Longitudinal Consistency-Informed Diffusion Model for 3D\n  Infant Brain Image Completion",
        "link": "http://arxiv.org/abs/2405.10691v1",
        "abstract": "The infant brain undergoes rapid development in the first few years after\nbirth.Compared to cross-sectional studies, longitudinal studies can depict the\ntrajectories of infants brain development with higher accuracy, statistical\npower and flexibility.However, the collection of infant longitudinal magnetic\nresonance (MR) data suffers a notorious dropout problem, resulting in\nincomplete datasets with missing time points. This limitation significantly\nimpedes subsequent neuroscience and clinical modeling. Yet, existing deep\ngenerative models are facing difficulties in missing brain image completion,\ndue to sparse data and the nonlinear, dramatic contrast/geometric variations in\nthe developing brain. We propose LoCI-DiffCom, a novel Longitudinal\nConsistency-Informed Diffusion model for infant brain image Completion,which\nintegrates the images from preceding and subsequent time points to guide a\ndiffusion model for generating high-fidelity missing data. Our designed LoCI\nmodule can work on highly sparse sequences, relying solely on data from two\ntemporal points. Despite wide separation and diversity between age time points,\nour approach can extract individualized developmental features while ensuring\ncontext-aware consistency. Our experiments on a large infant brain MR dataset\ndemonstrate its effectiveness with consistent performance on missing infant\nbrain MR completion even in big gap scenarios, aiding in better delineation of\nearly developmental trajectories.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Zihao Zhu",
            "Tianli Tao",
            "Yitian Tao",
            "Haowen Deng",
            "Xinyi Cai",
            "Gaofeng Wu",
            "Kaidong Wang",
            "Haifeng Tang",
            "Lixuan Zhu",
            "Zhuoyang Gu",
            "Jiawei Huang",
            "Dinggang Shen",
            "Han Zhang"
        ],
        "published": "2024-05-17T10:53:40Z"
    },
    {
        "title": "CoLeaF: A Contrastive-Collaborative Learning Framework for Weakly\n  Supervised Audio-Visual Video Parsing",
        "link": "http://arxiv.org/abs/2405.10690v2",
        "abstract": "Weakly supervised audio-visual video parsing (AVVP) methods aim to detect\naudible-only, visible-only, and audible-visible events using only video-level\nlabels. Existing approaches tackle this by leveraging unimodal and cross-modal\ncontexts. However, we argue that while cross-modal learning is beneficial for\ndetecting audible-visible events, in the weakly supervised scenario, it\nnegatively impacts unaligned audible or visible events by introducing\nirrelevant modality information. In this paper, we propose CoLeaF, a novel\nlearning framework that optimizes the integration of cross-modal context in the\nembedding space such that the network explicitly learns to combine cross-modal\ninformation for audible-visible events while filtering them out for unaligned\nevents. Additionally, as videos often involve complex class relationships,\nmodelling them improves performance. However, this introduces extra\ncomputational costs into the network. Our framework is designed to leverage\ncross-class relationships during training without incurring additional\ncomputations at inference. Furthermore, we propose new metrics to better\nevaluate a method's capabilities in performing AVVP. Our extensive experiments\ndemonstrate that CoLeaF significantly improves the state-of-the-art results by\nan average of 1.9% and 2.4% F-score on the LLP and UnAV-100 datasets,\nrespectively.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Faegheh Sardari",
            "Armin Mustafa",
            "Philip J. B. Jackson",
            "Adrian Hilton"
        ],
        "published": "2024-05-17T10:51:15Z"
    },
    {
        "title": "Revolutionizing Process Mining: A Novel Architecture for ChatGPT\n  Integration and Enhanced User Experience through Optimized Prompt Engineering",
        "link": "http://arxiv.org/abs/2405.10689v1",
        "abstract": "In the rapidly evolving field of business process management, there is a\ngrowing need for analytical tools that can transform complex data into\nactionable insights. This research introduces a novel approach by integrating\nLarge Language Models (LLMs), such as ChatGPT, into process mining tools,\nmaking process analytics more accessible to a wider audience. The study aims to\ninvestigate how ChatGPT enhances analytical capabilities, improves user\nexperience, increases accessibility, and optimizes the architectural frameworks\nof process mining tools. The key innovation of this research lies in developing\na tailored prompt engineering strategy for each process mining submodule,\nensuring that the AI-generated outputs are accurate and relevant to the\ncontext. The integration architecture follows an Extract, Transform, Load (ETL)\nprocess, which includes various process mining engine modules and utilizes\nzero-shot and optimized prompt engineering techniques. ChatGPT is connected via\nAPIs and receives structured outputs from the process mining modules, enabling\nconversational interactions. To validate the effectiveness of this approach,\nthe researchers used data from 17 companies that employ BehfaLab's Process\nMining Tool. The results showed significant improvements in user experience,\nwith an expert panel rating 72% of the results as \"Good\". This research\ncontributes to the advancement of business process analysis methodologies by\ncombining process mining with artificial intelligence. Future research\ndirections include further optimization of prompt engineering, exploration of\nintegration with other AI technologies, and assessment of scalability across\nvarious business environments. This study paves the way for continuous\ninnovation at the intersection of process mining and artificial intelligence,\npromising to revolutionize the way businesses analyze and optimize their\nprocesses.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Mehrdad Agha Mohammad Ali Kermani",
            "Hamid Reza Seddighi",
            "Mehrdad Maghsoudi"
        ],
        "published": "2024-05-17T10:48:14Z"
    },
    {
        "title": "Know in AdVance: Linear-Complexity Forecasting of Ad Campaign\n  Performance with Evolving User Interest",
        "link": "http://arxiv.org/abs/2405.10681v1",
        "abstract": "Real-time Bidding (RTB) advertisers wish to \\textit{know in advance} the\nexpected cost and yield of ad campaigns to avoid trial-and-error expenses.\nHowever, Campaign Performance Forecasting (CPF), a sequence modeling task\ninvolving tens of thousands of ad auctions, poses challenges of evolving user\ninterest, auction representation, and long context, making coarse-grained and\nstatic-modeling methods sub-optimal. We propose \\textit{AdVance}, a time-aware\nframework that integrates local auction-level and global campaign-level\nmodeling. User preference and fatigue are disentangled using a time-positioned\nsequence of clicked items and a concise vector of all displayed items.\nCross-attention, conditioned on the fatigue vector, captures the dynamics of\nuser interest toward each candidate ad. Bidders compete with each other,\npresenting a complete graph similar to the self-attention mechanism. Hence, we\nemploy a Transformer Encoder to compress each auction into embedding by solving\nauxiliary tasks. These sequential embeddings are then summarized by a\nconditional state space model (SSM) to comprehend long-range dependencies while\nmaintaining global linear complexity. Considering the irregular time intervals\nbetween auctions, we make SSM's parameters dependent on the current auction\nembedding and the time interval. We further condition SSM's global predictions\non the accumulation of local results. Extensive evaluations and ablation\nstudies demonstrate its superiority over state-of-the-art methods. AdVance has\nbeen deployed on the Tencent Advertising platform, and A/B tests show a\nremarkable 4.5\\% uplift in Average Revenue per User (ARPU).",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "XiaoYu Wang",
            "YongHui Guo",
            "Hui Sheng",
            "Peili Lv",
            "Chi Zhou",
            "Wei Huang",
            "ShiQin Ta",
            "Dongbo Huang",
            "XiuJin Yang",
            "Lan Xu",
            "Hao Zhou",
            "Yusheng Ji"
        ],
        "published": "2024-05-17T10:22:36Z"
    },
    {
        "title": "Off-the-Shelf Neural Network Architectures for Forex Time Series\n  Prediction come at a Cost",
        "link": "http://arxiv.org/abs/2405.10679v1",
        "abstract": "Our study focuses on comparing the performance and resource requirements\nbetween different Long Short-Term Memory (LSTM) neural network architectures\nand an ANN specialized architecture for forex market prediction. We analyze the\nexecution time of the models as well as the resources consumed, such as memory\nand computational power. Our aim is to demonstrate that the specialized\narchitecture not only achieves better results in forex market prediction but\nalso executes using fewer resources and in a shorter time frame compared to\nLSTM architectures. This comparative analysis will provide significant insights\ninto the suitability of these two types of architectures for time series\nprediction in the forex market environment.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CE",
            "q-fin.MF"
        ],
        "authors": [
            "Theodoros Zafeiriou",
            "Dimitris Kalles"
        ],
        "published": "2024-05-17T10:20:14Z"
    },
    {
        "title": "Generative modeling of Sparse Approximate Inverse Preconditioners",
        "link": "http://arxiv.org/abs/2405.11007v1",
        "abstract": "We present a new deep learning paradigm for the generation of sparse\napproximate inverse (SPAI) preconditioners for matrix systems arising from the\nmesh-based discretization of elliptic differential operators. Our approach is\nbased upon the observation that matrices generated in this manner are not\narbitrary, but inherit properties from differential operators that they\ndiscretize. Consequently, we seek to represent a learnable distribution of\nhigh-performance preconditioners from a low-dimensional subspace through a\ncarefully-designed autoencoder, which is able to generate SPAI preconditioners\nfor these systems. The concept has been implemented on a variety of finite\nelement discretizations of second- and fourth-order elliptic partial\ndifferential equations with highly promising results.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Mou Li",
            "He Wang",
            "Peter K. Jimack"
        ],
        "published": "2024-05-17T10:19:32Z"
    },
    {
        "title": "IT Strategic alignment in the decentralized finance (DeFi): CBDC and\n  digital currencies",
        "link": "http://arxiv.org/abs/2405.10678v1",
        "abstract": "Cryptocurrency can be understood as a digital asset transacted among\nparticipants in the crypto economy. Every cryptocurrency must have an\nassociated Blockchain. Blockchain is a Distributed Ledger Technology (DLT)\nwhich supports cryptocurrencies, this may be considered as the most promising\ndisruptive technology in the industry 4.0 context. Decentralized finance (DeFi)\nis a Blockchain-based financial infrastructure, the term generally refers to an\nopen, permissionless, and highly interoperable protocol stack built on public\nsmart contract platforms, such as the Ethereum Blockchain. It replicates\nexisting financial services in a more open and transparent way. DeFi does not\nrely on intermediaries and centralized institutions. Instead, it is based on\nopen protocols and decentralized applications (Dapps). Considering that there\nare many digital coins, stablecoins and central bank digital currencies\n(CBDCs), these currencies should interact among each other sometime. For this\ninteraction the Information Technology elements play an important whole as\nenablers and IT strategic alignment. This paper considers the strategic\nalignment model proposed by Henderson and Venkatraman (1993) and Luftman\n(1996). This paper seeks to answer two main questions 1) What are the common IT\nelements in the DeFi? And 2) How the elements connect to the IT strategic\nalignment in DeFi? Through a Systematic Literature Review (SLR). Results point\nout that there are many IT elements already mentioned by literature, however\nthere is a lack in the literature about the connection between IT elements and\nIT strategic alignment in a Decentralized Finance (DeFi) architectural network.\nAfter final considerations, limitations and future research agenda are\npresented. Keywords: IT Strategic alignment, Decentralized Finance (DeFi),\nCryptocurrency, Digital Economy.",
        "subjects": [
            "cs.CY",
            "cs.CR"
        ],
        "authors": [
            "Carlos Alberto Durigan Junior",
            "Fernando Jose Barbin Laurindo"
        ],
        "published": "2024-05-17T10:19:20Z"
    },
    {
        "title": "From Sora What We Can See: A Survey of Text-to-Video Generation",
        "link": "http://arxiv.org/abs/2405.10674v1",
        "abstract": "With impressive achievements made, artificial intelligence is on the path\nforward to artificial general intelligence. Sora, developed by OpenAI, which is\ncapable of minute-level world-simulative abilities can be considered as a\nmilestone on this developmental path. However, despite its notable successes,\nSora still encounters various obstacles that need to be resolved. In this\nsurvey, we embark from the perspective of disassembling Sora in text-to-video\ngeneration, and conducting a comprehensive review of literature, trying to\nanswer the question, \\textit{From Sora What We Can See}. Specifically, after\nbasic preliminaries regarding the general algorithms are introduced, the\nliterature is categorized from three mutually perpendicular dimensions:\nevolutionary generators, excellent pursuit, and realistic panorama.\nSubsequently, the widely used datasets and metrics are organized in detail.\nLast but more importantly, we identify several challenges and open problems in\nthis domain and propose potential future directions for research and\ndevelopment.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Rui Sun",
            "Yumin Zhang",
            "Tejal Shah",
            "Jiahao Sun",
            "Shuoying Zhang",
            "Wenqi Li",
            "Haoran Duan",
            "Bo Wei",
            "Rajiv Ranjan"
        ],
        "published": "2024-05-17T10:09:09Z"
    },
    {
        "title": "Pragmatic Communication for Remote Control of Finite-State Markov\n  Processes",
        "link": "http://arxiv.org/abs/2405.10672v1",
        "abstract": "Pragmatic or goal-oriented communication can optimize communication decisions\nbeyond the reliable transmission of data, instead aiming at directly affecting\napplication performance with the minimum channel utilization. In this paper, we\ndevelop a general theoretical framework for the remote control of finite-state\nMarkov processes, using pragmatic communication over a costly zero-delay\ncommunication channel. To that end, we model a cyber-physical system composed\nof an encoder, which observes and transmits the states of a process in\nreal-time, and a decoder, which receives that information and controls the\nbehavior of the process. The encoder and the decoder should cooperatively\noptimize the trade-off between the control performance (i.e., reward) and the\ncommunication cost (i.e., channel use). This scenario underscores a pragmatic\n(i.e., goal-oriented) communication problem, where the purpose is to convey\nonly the data that is most valuable for the underlying task, taking into\naccount the state of the decoder (hence, the pragmatic aspect). We investigate\ntwo different decision-making architectures: in pull-based remote control, the\ndecoder is the only decision-maker, while in push-based remote control, the\nencoder and the decoder constitute two independent decision-makers, leading to\na multi-agent scenario. We propose three algorithms to optimize our system\n(i.e., design the encoder and the decoder policies), discuss the optimality\nguarantees ofs the algorithms, and shed light on their computational complexity\nand fundamental limits.",
        "subjects": [
            "cs.MA",
            "cs.NI"
        ],
        "authors": [
            "Pietro Talli",
            "Edoardo David Santi",
            "Federico Chiariotti",
            "Touraj Soleymani",
            "Federico Mason",
            "Andrea Zanella",
            "Deniz Gündüz"
        ],
        "published": "2024-05-17T10:06:54Z"
    },
    {
        "title": "Verification Algorithms for Automated Separation Logic Verifiers",
        "link": "http://arxiv.org/abs/2405.10661v1",
        "abstract": "Most automated program verifiers for separation logic use either symbolic\nexecution or verification condition generation to extract proof obligations,\nwhich are then handed over to an SMT solver. Existing verification algorithms\nare designed to be sound, but differ in performance and completeness. These\ncharacteristics may also depend on the programs and properties to be verified.\nConsequently, developers and users of program verifiers have to select a\nverification algorithm carefully for their application domain. Taking an\ninformed decision requires a systematic comparison of the performance and\ncompleteness characteristics of the verification algorithms used by modern\nseparation logic verifiers, but such a comparison does not exist.\n  This paper describes five verification algorithms for separation logic, three\nthat are used in existing tools and two novel algorithms that combine\ncharacteristics of existing symbolic execution and verification condition\ngeneration algorithms. A detailed evaluation of implementations of these five\nalgorithms in the Viper infrastructure assesses their performance and\ncompleteness for different classes of input programs. Based on the experimental\nresults, we identify candidate portfolios of algorithms that maximize\ncompleteness and performance.",
        "subjects": [
            "cs.PL"
        ],
        "authors": [
            "Marco Eilers",
            "Malte Schwerhoff",
            "Peter Müller"
        ],
        "published": "2024-05-17T09:44:55Z"
    },
    {
        "title": "Realistic Evaluation of Toxicity in Large Language Models",
        "link": "http://arxiv.org/abs/2405.10659v2",
        "abstract": "Large language models (LLMs) have become integral to our professional\nworkflows and daily lives. Nevertheless, these machine companions of ours have\na critical flaw: the huge amount of data which endows them with vast and\ndiverse knowledge, also exposes them to the inevitable toxicity and bias. While\nmost LLMs incorporate defense mechanisms to prevent the generation of harmful\ncontent, these safeguards can be easily bypassed with minimal prompt\nengineering. In this paper, we introduce the new Thoroughly Engineered Toxicity\n(TET) dataset, comprising manually crafted prompts designed to nullify the\nprotective layers of such models. Through extensive evaluations, we demonstrate\nthe pivotal role of TET in providing a rigorous benchmark for evaluation of\ntoxicity awareness in several popular LLMs: it highlights the toxicity in the\nLLMs that might remain hidden when using normal prompts, thus revealing subtler\nissues in their behavior.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Tinh Son Luong",
            "Thanh-Thien Le",
            "Linh Ngo Van",
            "Thien Huu Nguyen"
        ],
        "published": "2024-05-17T09:42:59Z"
    },
    {
        "title": "Cost-Effective Fault Tolerance for CNNs Using Parameter Vulnerability\n  Based Hardening and Pruning",
        "link": "http://arxiv.org/abs/2405.10658v1",
        "abstract": "Convolutional Neural Networks (CNNs) have become integral in safety-critical\napplications, thus raising concerns about their fault tolerance. Conventional\nhardware-dependent fault tolerance methods, such as Triple Modular Redundancy\n(TMR), are computationally expensive, imposing a remarkable overhead on CNNs.\nWhereas fault tolerance techniques can be applied either at the hardware level\nor at the model levels, the latter provides more flexibility without\nsacrificing generality. This paper introduces a model-level hardening approach\nfor CNNs by integrating error correction directly into the neural networks. The\napproach is hardware-agnostic and does not require any changes to the\nunderlying accelerator device. Analyzing the vulnerability of parameters\nenables the duplication of selective filters/neurons so that their output\nchannels are effectively corrected with an efficient and robust correction\nlayer. The proposed method demonstrates fault resilience nearly equivalent to\nTMR-based correction but with significantly reduced overhead. Nevertheless,\nthere exists an inherent overhead to the baseline CNNs. To tackle this issue, a\ncost-effective parameter vulnerability based pruning technique is proposed that\noutperforms the conventional pruning method, yielding smaller networks with a\nnegligible accuracy loss. Remarkably, the hardened pruned CNNs perform up to\n24\\% faster than the hardened un-pruned ones.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Mohammad Hasan Ahmadilivani",
            "Seyedhamidreza Mousavi",
            "Jaan Raik",
            "Masoud Daneshtalab",
            "Maksim Jenihhin"
        ],
        "published": "2024-05-17T09:42:44Z"
    },
    {
        "title": "SPOR: A Comprehensive and Practical Evaluation Method for Compositional\n  Generalization in Data-to-Text Generation",
        "link": "http://arxiv.org/abs/2405.10650v4",
        "abstract": "Compositional generalization is an important ability of language models and\nhas many different manifestations. For data-to-text generation, previous\nresearch on this ability is limited to a single manifestation called\nSystematicity and lacks consideration of large language models (LLMs), which\ncannot fully cover practical application scenarios. In this work, we propose\nSPOR, a comprehensive and practical evaluation method for compositional\ngeneralization in data-to-text generation. SPOR includes four aspects of\nmanifestations (Systematicity, Productivity, Order invariance, and Rule\nlearnability) and allows high-quality evaluation without additional manual\nannotations based on existing datasets. We demonstrate SPOR on two different\ndatasets and evaluate some existing language models including LLMs. We find\nthat the models are deficient in various aspects of the evaluation and need\nfurther improvement. Our work shows the necessity for comprehensive research on\ndifferent manifestations of compositional generalization in data-to-text\ngeneration and provides a framework for evaluation.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Ziyao Xu",
            "Houfeng Wang"
        ],
        "published": "2024-05-17T09:25:30Z"
    },
    {
        "title": "A two-phase-ACO algorithm for solving nonlinear optimization problems\n  subjected to fuzzy relational equations",
        "link": "http://arxiv.org/abs/2405.14888v1",
        "abstract": "In this paper, we investigate nonlinear optimization problems whose\nconstraints are defined as fuzzy relational equations (FRE) with max-min\ncomposition. Since the feasible solution set of the FRE is often a non-convex\nset and the resolution of the FREs is an NP-hard problem, conventional\nnonlinear approaches may involve high computational complexity. Based on the\ntheoretical aspects of the problem, an algorithm (called FRE-ACO algorithm) is\npresented which benefits from the structural properties of the FREs, the\nability of discrete ant colony optimization algorithm (denoted by ACO) to\ntackle combinatorial problems, and that of continuous ant colony optimization\nalgorithm (denoted by ACOR) to solve continuous optimization problems. In the\ncurrent method, the fundamental ideas underlying ACO and ACOR are combined and\nform an efficient approach to solve the nonlinear optimization problems\nconstrained with such non-convex regions. Moreover, FRE-ACO algorithm preserves\nthe feasibility of new generated solutions without having to initially find the\nminimal solutions of the feasible region or check the feasibility after\ngenerating the new solutions. FRE-ACO algorithm has been compared with some\nrelated works proposed for solving nonlinear optimization problems with respect\nto maxmin FREs. The obtained results demonstrate that the proposed algorithm\nhas a higher convergence rate and requires a less number of function\nevaluations compared to other considered algorithms.",
        "subjects": [
            "cs.NE"
        ],
        "authors": [
            "Amin Ghodousian",
            "Sara Zal"
        ],
        "published": "2024-05-17T09:24:07Z"
    },
    {
        "title": "Recovery of Sparse Graph Signals",
        "link": "http://arxiv.org/abs/2405.10649v1",
        "abstract": "This paper investigates the recovery of a node-domain sparse graph signal\nfrom the output of a graph filter. This problem, often referred to as the\nidentification of the source of a diffused sparse graph signal, is seminal in\nthe field of graph signal processing (GSP). Sparse graph signals can be used in\nthe modeling of a variety of real-world applications in networks, such as\nsocial, biological, and power systems, and enable various GSP tasks, such as\ngraph signal reconstruction, blind deconvolution, and sampling. In this paper,\nwe assume double sparsity of both the graph signal and the graph topology, as\nwell as a low-order graph filter. We propose three algorithms to reconstruct\nthe support set of the input sparse graph signal from the graph filter output\nsamples, leveraging these assumptions and the generalized information criterion\n(GIC). First, we describe the graph multiple GIC (GM-GIC) method, which is\nbased on partitioning the dictionary elements (graph filter matrix columns)\nthat capture information on the signal into smaller subsets. Then, the local\nGICs are computed for each subset and aggregated to make a global decision.\nSecond, inspired by the well-known branch and bound (BNB) approach, we develop\nthe graph-based branch and bound GIC (graph-BNB-GIC), and incorporate a new\ntractable heuristic bound tailored to the graph and graph filter\ncharacteristics. Finally, we propose the graph-based first order correction\n(GFOC) method, which improves existing sparse recovery methods by iteratively\nexamining potential improvements to the GIC cost function through replacing\nelements from the estimated support set with elements from their one-hop\nneighborhood. We conduct simulations that demonstrate that the proposed sparse\nrecovery methods outperform existing methods in terms of support set recovery\naccuracy, and without a significant computational overhead.",
        "subjects": [
            "eess.SP",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ],
        "authors": [
            "Gal Morgenstern",
            "Tirza Routtenberg"
        ],
        "published": "2024-05-17T09:23:33Z"
    },
    {
        "title": "Optimal Service Placement, Request Routing and CPU Sizing in Cooperative\n  Mobile Edge Computing Networks for Delay-Sensitive Applications",
        "link": "http://arxiv.org/abs/2405.10648v1",
        "abstract": "We study joint optimization of service placement, request routing, and CPU\nsizing in a cooperative MEC system. The problem is considered from the\nperspective of the service provider (SP), which delivers heterogeneous\nMEC-enabled delay-sensitive services, and needs to pay for the used resources\nto the mobile network operators and the cloud provider, while earning revenue\nfrom the served requests. We formulate the problem of maximizing the SP's total\nprofit subject to the computation, storage, and communication constraints of\neach edge node and end-to-end delay requirements of the services as a\nmixed-integer non-convex optimization problem, and prove it to be NP-hard.\n  To tackle the challenges in solving the problem, we first introduce a design\ntrade-off parameter for different delay requirements of each service, which\nmaintains flexibility in prioritizing them, and transform the original\noptimization problem by the new delay constraints. Then, by exploiting a hidden\nconvexity, we reformulate the delay constraints into an equivalent form. Next,\nto handle the challenge of the complicating (integer) variables, using primal\ndecomposition, we decompose the problem into an equivalent form of master and\ninner sub-problems over the mixed and real variables, respectively. We then\nemploy a cutting-plane approach for building up adequate representations of the\nextremal value of the inner problem as a function of the complicating variables\nand the set of values of the complicating variables for which the inner problem\nis feasible. Finally, we propose a solution strategy based on generalized\nBenders decomposition and prove its convergence to the optimal solution within\na limited number of iterations. Extensive simulation results demonstrate that\nthe proposed scheme significantly outperforms the existing mechanisms in terms\nof the SP's profit, cache hit ratio, running time, and end-to-end delay.",
        "subjects": [
            "cs.NI",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Naeimeh Omidvar",
            "Mahdieh Ahmadi",
            "Seyed Mohammad Hosseini"
        ],
        "published": "2024-05-17T09:21:04Z"
    },
    {
        "title": "Cyclical Weight Consolidation: Towards Solving Catastrophic Forgetting\n  in Serial Federated Learning",
        "link": "http://arxiv.org/abs/2405.10647v1",
        "abstract": "Federated Learning (FL) has gained attention for addressing data scarcity and\nprivacy concerns. While parallel FL algorithms like FedAvg exhibit remarkable\nperformance, they face challenges in scenarios with diverse network speeds and\nconcerns about centralized control, especially in multi-institutional\ncollaborations like the medical domain. Serial FL presents an alternative\nsolution, circumventing these challenges by transferring model updates serially\nbetween devices in a cyclical manner. Nevertheless, it is deemed inferior to\nparallel FL in that (1) its performance shows undesirable fluctuations, and (2)\nit converges to a lower plateau, particularly when dealing with non-IID data.\nThe observed phenomenon is attributed to catastrophic forgetting due to\nknowledge loss from previous sites. In this paper, to overcome fluctuation and\nlow efficiency in the iterative learning and forgetting process, we introduce\ncyclical weight consolidation (CWC), a straightforward yet potent approach\nspecifically tailored for serial FL. CWC employs a consolidation matrix to\nregulate local optimization. This matrix tracks the significance of each\nparameter on the overall federation throughout the entire training trajectory,\npreventing abrupt changes in significant weights. During revisitation, to\nmaintain adaptability, old memory undergoes decay to incorporate new\ninformation. Our comprehensive evaluations demonstrate that in various non-IID\nsettings, CWC mitigates the fluctuation behavior of the original serial FL\napproach and enhances the converged performance consistently and significantly.\nThe improved performance is either comparable to or better than the parallel\nvanilla.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC"
        ],
        "authors": [
            "Haoyue Song",
            "Jiacheng Wang",
            "Liansheng Wang"
        ],
        "published": "2024-05-17T09:20:21Z"
    },
    {
        "title": "ChatGPT in Classrooms: Transforming Challenges into Opportunities in\n  Education",
        "link": "http://arxiv.org/abs/2405.10645v1",
        "abstract": "In the era of exponential technology growth, one unexpected guest has claimed\na seat in classrooms worldwide, Artificial Intelligence. Generative AI, such as\nChatGPT, promises a revolution in education, yet it arrives with a double-edged\nsword. Its potential for personalized learning is offset by issues of cheating,\ninaccuracies, and educators struggling to incorporate it effectively into their\nlesson design. We are standing on the brink of this educational frontier, and\nit is clear that we need to navigate this terrain with a lot of care. This is a\nmajor challenge that could undermine the integrity and value of our educational\nprocess. So, how can we turn these challenges into opportunities? When used\ninappropriately, AI tools can become the perfect tool for the cut copy paste\nmentality, and quickly begin to corrode critical thinking, creativity, and deep\nunderstanding, the most important skills in our rapidly changing world.\nTeachers feel that they are not equipped to leverage this technology, widening\nthe digital divide among educators and institutions. Addressing these concerns\ncalls for an in depth research approach. We will employ empirical research,\ndrawing on the Technology Acceptance Model, to assess the attitudes toward\ngenerative AI among educators and students. Understanding their perceptions,\nusage patterns, and hurdles is the first crucial step in creating an effective\nsolution. The present study will be used as a process manual for future\nresearchers to apply, running their own data, based on the steps explained here",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.HC"
        ],
        "authors": [
            "Harris Bin Munawar",
            "Nikolaos Misirlis"
        ],
        "published": "2024-05-17T09:17:59Z"
    },
    {
        "title": "Hi-GMAE: Hierarchical Graph Masked Autoencoders",
        "link": "http://arxiv.org/abs/2405.10642v1",
        "abstract": "Graph Masked Autoencoders (GMAEs) have emerged as a notable self-supervised\nlearning approach for graph-structured data. Existing GMAE models primarily\nfocus on reconstructing node-level information, categorizing them as\nsingle-scale GMAEs. This methodology, while effective in certain contexts,\ntends to overlook the complex hierarchical structures inherent in many\nreal-world graphs. For instance, molecular graphs exhibit a clear hierarchical\norganization in the form of the atoms-functional groups-molecules structure.\nHence, the inability of single-scale GMAE models to incorporate these\nhierarchical relationships often leads to their inadequate capture of crucial\nhigh-level graph information, resulting in a noticeable decline in performance.\nTo address this limitation, we propose Hierarchical Graph Masked AutoEncoders\n(Hi-GMAE), a novel multi-scale GMAE framework designed to handle the\nhierarchical structures within graphs. First, Hi-GMAE constructs a multi-scale\ngraph hierarchy through graph pooling, enabling the exploration of graph\nstructures across different granularity levels. To ensure masking uniformity of\nsubgraphs across these scales, we propose a novel coarse-to-fine strategy that\ninitiates masking at the coarsest scale and progressively back-projects the\nmask to the finer scales. Furthermore, we integrate a gradual recovery strategy\nwith the masking process to mitigate the learning challenges posed by\ncompletely masked subgraphs. Diverging from the standard graph neural network\n(GNN) used in GMAE models, Hi-GMAE modifies its encoder and decoder into\nhierarchical structures. This entails using GNN at the finer scales for\ndetailed local graph analysis and employing a graph transformer at coarser\nscales to capture global information. Our experiments on 15 graph datasets\nconsistently demonstrate that Hi-GMAE outperforms 17 state-of-the-art\nself-supervised competitors.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Chuang Liu",
            "Zelin Yao",
            "Yibing Zhan",
            "Xueqi Ma",
            "Dapeng Tao",
            "Jia Wu",
            "Wenbin Hu",
            "Shirui Pan",
            "Bo Du"
        ],
        "published": "2024-05-17T09:08:37Z"
    },
    {
        "title": "COMET: NFT Price Prediction with Wallet Profiling",
        "link": "http://arxiv.org/abs/2405.10640v1",
        "abstract": "As the non-fungible token (NFT) market flourishes, price prediction emerges\nas a pivotal direction for investors gaining valuable insight to maximize\nreturns. However, existing works suffer from a lack of practical definitions\nand standardized evaluations, limiting their practical application. Moreover,\nthe influence of users' multi-behaviour transactions that are publicly\naccessible on NFT price is still not explored and exhibits challenges. In this\npaper, we address these gaps by presenting a practical and hierarchical problem\ndefinition. This approach unifies both collection-level and token-level task\nand evaluation methods, which cater to varied practical requirements of\ninvestors. To further understand the impact of user behaviours on the variation\nof NFT price, we propose a general wallet profiling framework and develop a\nCOmmunity enhanced Multi-bEhavior Transaction graph model, named COMET. COMET\nprofiles wallets with a comprehensive view and considers the impact of diverse\nrelations and interactions within the NFT ecosystem on NFT price variations,\nthereby improving prediction performance. Extensive experiments conducted in\nour deployed system demonstrate the superiority of COMET, underscoring its\npotential in the insight toolkit for NFT investors.",
        "subjects": [
            "cs.SI"
        ],
        "authors": [
            "Tianfu Wang",
            "Liwei Deng",
            "Chao Wang",
            "Jianxun Lian",
            "Yue Yan",
            "Nicholas Jing Yuan",
            "Qi Zhang",
            "Hui Xiong"
        ],
        "published": "2024-05-17T09:06:09Z"
    },
    {
        "title": "Layer-Condensed KV Cache for Efficient Inference of Large Language\n  Models",
        "link": "http://arxiv.org/abs/2405.10637v1",
        "abstract": "Huge memory consumption has been a major bottleneck for deploying\nhigh-throughput large language models in real-world applications. In addition\nto the large number of parameters, the key-value (KV) cache for the attention\nmechanism in the transformer architecture consumes a significant amount of\nmemory, especially when the number of layers is large for deep language models.\nIn this paper, we propose a novel method that only computes and caches the KVs\nof a small number of layers, thus significantly saving memory consumption and\nimproving inference throughput. Our experiments on large language models show\nthat our method achieves up to 26$\\times$ higher throughput than standard\ntransformers and competitive performance in language modeling and downstream\ntasks. In addition, our method is orthogonal to existing transformer\nmemory-saving techniques, so it is straightforward to integrate them with our\nmodel, achieving further improvement in inference efficiency. Our code is\navailable at https://github.com/whyNLP/LCKV.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Haoyi Wu",
            "Kewei Tu"
        ],
        "published": "2024-05-17T08:59:46Z"
    },
    {
        "title": "Self-Triggered Distributed Model Predictive Control with Synchronization\n  Parameters Interaction",
        "link": "http://arxiv.org/abs/2405.11006v1",
        "abstract": "This paper investigates an aperiodic distributed model predictive control\napproach for multi-agent systems (MASs) in which parameterized synchronization\nconstraints is considered and an innovative self-triggered criterion is\nconstructed. Different from existing coordination methodology, the proposed\nstrategy achieves the cooperation of agents through the synchronization of\none-dimensional parameters related to the control inputs. At each asynchronous\nsampling instant, each agent exchanges the one-dimensional synchronization\nparameters, solves the optimal control problem (OCP) and then determines the\nopen-loop phase. The incorporation of the selftriggered scheme and the\nsynchronization parameter constraints relieves the computational and\ncommunication usage. Sufficient conditions guaranteeing the recursive\nfeasibility of the OCP and the stability of the closed-loop system are proven.\nSimulation results illustrate the validity of the proposed control algorithm.",
        "subjects": [
            "eess.SY",
            "cs.SY",
            "nlin.AO"
        ],
        "authors": [
            "Qianqian Chen",
            "Shaoyuan Li"
        ],
        "published": "2024-05-17T08:58:51Z"
    },
    {
        "title": "Implementation of OpenAPI Wireshark Dissectors to Validate SBI Messages\n  of 5G Core Networks",
        "link": "http://arxiv.org/abs/2405.10635v1",
        "abstract": "This paper introduces a novel Wireshark dissector designed to facilitate the\nanalysis of Service-Based Interface (SBI) communication in 5G Core Networks.\nOur approach involves parsing the OpenAPI schemes provided by the 5G\nspecification to automatically generate the dissector code. Our tool enables\nthe validation of 5G Core Network traces to ensure compliance with the\nspecifications. Through testing against three open-source 5G Core Network\nprojects, we identified several issues where messages deviate from\nspecification standards, highlighting the significance of our implementation in\nensuring protocol conformity and network reliability.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Lukas Schauer",
            "Thorsten Horstmann",
            "Steffen Druesedow",
            "Michael Rademacher"
        ],
        "published": "2024-05-17T08:51:53Z"
    },
    {
        "title": "Harnessing Collective Structure Knowledge in Data Augmentation for Graph\n  Neural Networks",
        "link": "http://arxiv.org/abs/2405.10633v1",
        "abstract": "Graph neural networks (GNNs) have achieved state-of-the-art performance in\ngraph representation learning. Message passing neural networks, which learn\nrepresentations through recursively aggregating information from each node and\nits neighbors, are among the most commonly-used GNNs. However, a wealth of\nstructural information of individual nodes and full graphs is often ignored in\nsuch process, which restricts the expressive power of GNNs. Various graph data\naugmentation methods that enable the message passing with richer structure\nknowledge have been introduced as one main way to tackle this issue, but they\nare often focused on individual structure features and difficult to scale up\nwith more structure features. In this work we propose a novel approach, namely\ncollective structure knowledge-augmented graph neural network (CoS-GNN), in\nwhich a new message passing method is introduced to allow GNNs to harness a\ndiverse set of node- and graph-level structure features, together with original\nnode features/attributes, in augmented graphs. In doing so, our approach\nlargely improves the structural knowledge modeling of GNNs in both node and\ngraph levels, resulting in substantially improved graph representations. This\nis justified by extensive empirical results where CoS-GNN outperforms\nstate-of-the-art models in various graph-level learning tasks, including graph\nclassification, anomaly detection, and out-of-distribution generalization.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Rongrong Ma",
            "Guansong Pang",
            "Ling Chen"
        ],
        "published": "2024-05-17T08:50:00Z"
    },
    {
        "title": "Beyond static AI evaluations: advancing human interaction evaluations\n  for LLM harms and risks",
        "link": "http://arxiv.org/abs/2405.10632v2",
        "abstract": "Model evaluations are central to understanding the safety, risks, and\nsocietal impacts of AI systems. While most real-world AI applications involve\nhuman-AI interaction, most current evaluations (e.g., common benchmarks) of AI\nmodels do not. Instead, they incorporate human factors in limited ways,\nassessing the safety of models in isolation, thereby falling short of capturing\nthe complexity of human-model interactions. In this paper, we discuss and\noperationalize a definition of an emerging category of evaluations -- \"human\ninteraction evaluations\" (HIEs) -- which focus on the assessment of human-model\ninteractions or the process and the outcomes of humans using models. First, we\nargue that HIEs can be used to increase the validity of safety evaluations,\nassess direct human impact and interaction-specific harms, and guide future\nassessments of models' societal impact. Second, we propose a safety-focused HIE\ndesign framework -- containing a human-LLM interaction taxonomy -- with three\nstages: (1) identifying the risk or harm area, (2) characterizing the use\ncontext, and (3) choosing the evaluation parameters. Third, we apply our\nframework to two potential evaluations for overreliance and persuasion risks.\nFinally, we conclude with tangible recommendations for addressing concerns over\ncosts, replicability, and unrepresentativeness of HIEs.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.HC"
        ],
        "authors": [
            "Lujain Ibrahim",
            "Saffron Huang",
            "Lama Ahmad",
            "Markus Anderljung"
        ],
        "published": "2024-05-17T08:49:34Z"
    },
    {
        "title": "Medical Dialogue: A Survey of Categories, Methods, Evaluation and\n  Challenges",
        "link": "http://arxiv.org/abs/2405.10630v1",
        "abstract": "This paper surveys and organizes research works on medical dialog systems,\nwhich is an important yet challenging task. Although these systems have been\nsurveyed in the medical community from an application perspective, a systematic\nreview from a rigorous technical perspective has to date remained noticeably\nabsent. As a result, an overview of the categories, methods, and evaluation of\nmedical dialogue systems remain limited and underspecified, hindering the\nfurther improvement of this area. To fill this gap, we investigate an initial\npool of 325 papers from well-known computer science, and natural language\nprocessing conferences and journals, and make an overview. Recently, large\nlanguage models have shown strong model capacity on downstream tasks, which\nalso reshaped medical dialog systems' foundation. Despite the alluring\npractical application value, current medical dialogue systems still suffer from\nproblems. To this end, this paper lists the grand challenges of medical dialog\nsystems, especially of large language models.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Xiaoming Shi",
            "Zeming Liu",
            "Li Du",
            "Yuxuan Wang",
            "Hongru Wang",
            "Yuhang Guo",
            "Tong Ruan",
            "Jie Xu",
            "Shaoting Zhang"
        ],
        "published": "2024-05-17T08:46:15Z"
    },
    {
        "title": "DeepPavlov at SemEval-2024 Task 8: Leveraging Transfer Learning for\n  Detecting Boundaries of Machine-Generated Texts",
        "link": "http://arxiv.org/abs/2405.10629v1",
        "abstract": "The Multigenerator, Multidomain, and Multilingual Black-Box Machine-Generated\nText Detection shared task in the SemEval-2024 competition aims to tackle the\nproblem of misusing collaborative human-AI writing. Although there are a lot of\nexisting detectors of AI content, they are often designed to give a binary\nanswer and thus may not be suitable for more nuanced problem of finding the\nboundaries between human-written and machine-generated texts, while hybrid\nhuman-AI writing becomes more and more popular. In this paper, we address the\nboundary detection problem. Particularly, we present a pipeline for augmenting\ndata for supervised fine-tuning of DeBERTaV3. We receive new best MAE score,\naccording to the leaderboard of the competition, with this pipeline.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Anastasia Voznyuk",
            "Vasily Konovalov"
        ],
        "published": "2024-05-17T08:44:48Z"
    },
    {
        "title": "Dynamic data sampler for cross-language transfer learning in large\n  language models",
        "link": "http://arxiv.org/abs/2405.10626v1",
        "abstract": "Large Language Models (LLMs) have gained significant attention in the field\nof natural language processing (NLP) due to their wide range of applications.\nHowever, training LLMs for languages other than English poses significant\nchallenges, due to the difficulty in acquiring large-scale corpus and the\nrequisite computing resources. In this paper, we propose ChatFlow, a\ncross-language transfer-based LLM, to address these challenges and train large\nChinese language models in a cost-effective manner. We employ a mix of Chinese,\nEnglish, and parallel corpus to continuously train the LLaMA2 model, aiming to\nalign cross-language representations and facilitate the knowledge transfer\nspecifically to the Chinese language model. In addition, we use a dynamic data\nsampler to progressively transition the model from unsupervised pre-training to\nsupervised fine-tuning. Experimental results demonstrate that our approach\naccelerates model convergence and achieves superior performance. We evaluate\nChatFlow on popular Chinese and English benchmarks, the results indicate that\nit outperforms other Chinese models post-trained on LLaMA-2-7B.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yudong Li",
            "Yuhao Feng",
            "Wen Zhou",
            "Zhe Zhao",
            "Linlin Shen",
            "Cheng Hou",
            "Xianxu Hou"
        ],
        "published": "2024-05-17T08:40:51Z"
    },
    {
        "title": "Specialising and Analysing Instruction-Tuned and Byte-Level Language\n  Models for Organic Reaction Prediction",
        "link": "http://arxiv.org/abs/2405.10625v1",
        "abstract": "Transformer-based encoder-decoder models have demonstrated impressive results\nin chemical reaction prediction tasks. However, these models typically rely on\npretraining using tens of millions of unlabelled molecules, which can be\ntime-consuming and GPU-intensive. One of the central questions we aim to answer\nin this work is: Can FlanT5 and ByT5, the encode-decoder models pretrained\nsolely on language data, be effectively specialised for organic reaction\nprediction through task-specific fine-tuning? We conduct a systematic empirical\nstudy on several key issues of the process, including tokenisation, the impact\nof (SMILES-oriented) pretraining, fine-tuning sample efficiency, and decoding\nalgorithms at inference. Our key findings indicate that although being\npretrained only on language tasks, FlanT5 and ByT5 provide a solid foundation\nto fine-tune for reaction prediction, and thus become `chemistry domain\ncompatible' in the process. This suggests that GPU-intensive and expensive\npretraining on a large dataset of unlabelled molecules may be useful yet not\nessential to leverage the power of language models for chemistry. All our\nmodels achieve comparable Top-1 and Top-5 accuracy although some variation\nacross different models does exist. Notably, tokenisation and vocabulary\ntrimming slightly affect final performance but can speed up training and\ninference; The most efficient greedy decoding strategy is very competitive\nwhile only marginal gains can be achieved from more sophisticated decoding\nalgorithms. In summary, we evaluate FlanT5 and ByT5 across several dimensions\nand benchmark their impact on organic reaction prediction, which may guide more\neffective use of these state-of-the-art language models for chemistry-related\ntasks in the future.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "q-bio.BM"
        ],
        "authors": [
            "Jiayun Pang",
            "Ivan Vulić"
        ],
        "published": "2024-05-17T08:39:56Z"
    },
    {
        "title": "Sample-Efficient Constrained Reinforcement Learning with General\n  Parameterization",
        "link": "http://arxiv.org/abs/2405.10624v1",
        "abstract": "We consider a constrained Markov Decision Problem (CMDP) where the goal of an\nagent is to maximize the expected discounted sum of rewards over an infinite\nhorizon while ensuring that the expected discounted sum of costs exceeds a\ncertain threshold. Building on the idea of momentum-based acceleration, we\ndevelop the Primal-Dual Accelerated Natural Policy Gradient (PD-ANPG) algorithm\nthat guarantees an $\\epsilon$ global optimality gap and $\\epsilon$ constraint\nviolation with $\\mathcal{O}(\\epsilon^{-3})$ sample complexity. This improves\nthe state-of-the-art sample complexity in CMDP by a factor of\n$\\mathcal{O}(\\epsilon^{-1})$.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Washim Uddin Mondal",
            "Vaneet Aggarwal"
        ],
        "published": "2024-05-17T08:39:05Z"
    },
    {
        "title": "Model-free fast charging of lithium-ion batteries by online gradient\n  descent",
        "link": "http://arxiv.org/abs/2405.10623v1",
        "abstract": "A data-driven solution is provided for the fast-charging problem of\nlithium-ion batteries with multiple safety and aging constraints. The proposed\nmethod optimizes the charging current based on the observed history of\nmeasurable battery quantities, such as the input current, terminal voltage, and\ntemperature. The proposed method does not need any detailed battery model or\nfull-charging training episodes. The theoretical convergence is proven under\nmild conditions and is validated numerically on several linear and nonlinear\nbattery models, including single-particle and equivalent-circuit models.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Hamed Taghavian",
            "Malin Andersson",
            "Mikael Johansson"
        ],
        "published": "2024-05-17T08:37:38Z"
    },
    {
        "title": "Differentially Private Machine Learning-powered Combinatorial Auction\n  Design",
        "link": "http://arxiv.org/abs/2405.10622v1",
        "abstract": "We present a new approach to machine learning-powered combinatorial auctions,\nwhich is based on the principles of Differential Privacy. Our methodology\nguarantees that the auction mechanism is truthful, meaning that rational\nbidders have the incentive to reveal their true valuation functions. We achieve\nthis by inducing truthfulness in the auction dynamics, ensuring that bidders\nconsistently provide accurate information about their valuation functions.\n  Our method not only ensures truthfulness but also preserves the efficiency of\nthe original auction. This means that if the initial auction outputs an\nallocation with high social welfare, our modified truthful version of the\nauction will also achieve high social welfare. We use techniques from\nDifferential Privacy, such as the Exponential Mechanism, to achieve these\nresults. Additionally, we examine the application of differential privacy in\nauctions across both asymptotic and non-asymptotic regimes.",
        "subjects": [
            "cs.GT",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Arash Jamshidi",
            "Seyed Mohammad Hosseini",
            "Seyed Mahdi Noormousavi",
            "Mahdi Jafari Siavoshani"
        ],
        "published": "2024-05-17T08:36:55Z"
    },
    {
        "title": "Historically Relevant Event Structuring for Temporal Knowledge Graph\n  Reasoning",
        "link": "http://arxiv.org/abs/2405.10621v1",
        "abstract": "Temporal Knowledge Graph (TKG) reasoning focuses on predicting events through\nhistorical information within snapshots distributed on a timeline. Existing\nstudies mainly concentrate on two perspectives of leveraging the history of\nTKGs, including capturing evolution of each recent snapshot or correlations\namong global historical facts. Despite the achieved significant\naccomplishments, these models still fall short of (1) investigating the\ninfluences of multi-granularity interactions across recent snapshots and (2)\nharnessing the expressive semantics of significant links accorded with queries\nthroughout the entire history, especially events exerting a profound impact on\nthe future. These inadequacies restrict representation ability to reflect\nhistorical dependencies and future trends thoroughly. To overcome these\ndrawbacks, we propose an innovative TKG reasoning approach towards\n\\textbf{His}torically \\textbf{R}elevant \\textbf{E}vents \\textbf{S}tructuring\n($\\mathsf{HisRES}$). Concretely, $\\mathsf{HisRES}$ comprises two distinctive\nmodules excelling in structuring historically relevant events within TKGs,\nincluding a multi-granularity evolutionary encoder that captures structural and\ntemporal dependencies of the most recent snapshots, and a global relevance\nencoder that concentrates on crucial correlations among events relevant to\nqueries from the entire history. Furthermore, $\\mathsf{HisRES}$ incorporates a\nself-gating mechanism for adaptively merging multi-granularity recent and\nhistorically relevant structuring representations. Extensive experiments on\nfour event-based benchmarks demonstrate the state-of-the-art performance of\n$\\mathsf{HisRES}$ and indicate the superiority and effectiveness of structuring\nhistorical relevance for TKG reasoning.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Jinchuan Zhang",
            "Bei Hui",
            "Chong Mu",
            "Ming Sun",
            "Ling Tian"
        ],
        "published": "2024-05-17T08:33:43Z"
    },
    {
        "title": "MC-GPT: Empowering Vision-and-Language Navigation with Memory Map and\n  Reasoning Chains",
        "link": "http://arxiv.org/abs/2405.10620v1",
        "abstract": "In the Vision-and-Language Navigation (VLN) task, the agent is required to\nnavigate to a destination following a natural language instruction. While\nlearning-based approaches have been a major solution to the task, they suffer\nfrom high training costs and lack of interpretability. Recently, Large Language\nModels (LLMs) have emerged as a promising tool for VLN due to their strong\ngeneralization capabilities. However, existing LLM-based methods face\nlimitations in memory construction and diversity of navigation strategies. To\naddress these challenges, we propose a suite of techniques. Firstly, we\nintroduce a method to maintain a topological map that stores navigation\nhistory, retaining information about viewpoints, objects, and their spatial\nrelationships. This map also serves as a global action space. Additionally, we\npresent a Navigation Chain of Thoughts module, leveraging human navigation\nexamples to enrich navigation strategy diversity. Finally, we establish a\npipeline that integrates navigational memory and strategies with perception and\naction prediction modules. Experimental results on the REVERIE and R2R datasets\nshow that our method effectively enhances the navigation ability of the LLM and\nimproves the interpretability of navigation reasoning.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV"
        ],
        "authors": [
            "Zhaohuan Zhan",
            "Lisha Yu",
            "Sijie Yu",
            "Guang Tan"
        ],
        "published": "2024-05-17T08:33:27Z"
    },
    {
        "title": "Distributed Event-Based Learning via ADMM",
        "link": "http://arxiv.org/abs/2405.10618v1",
        "abstract": "We consider a distributed learning problem, where agents minimize a global\nobjective function by exchanging information over a network. Our approach has\ntwo distinct features: (i) It substantially reduces communication by triggering\ncommunication only when necessary, and (ii) it is agnostic to the\ndata-distribution among the different agents. We can therefore guarantee\nconvergence even if the local data-distributions of the agents are arbitrarily\ndistinct. We analyze the convergence rate of the algorithm and derive\naccelerated convergence rates in a convex setting. We also characterize the\neffect of communication drops and demonstrate that our algorithm is robust to\ncommunication failures. The article concludes by presenting numerical results\nfrom a distributed LASSO problem, and distributed learning tasks on MNIST and\nCIFAR-10 datasets. The experiments underline communication savings of 50% or\nmore due to the event-based communication strategy, show resilience towards\nheterogeneous data-distributions, and highlight that our approach outperforms\ncommon baselines such as FedAvg, FedProx, and FedADMM.",
        "subjects": [
            "cs.LG",
            "math.OC",
            "stat.ML"
        ],
        "authors": [
            "Guner Dilsad Er",
            "Sebastian Trimpe",
            "Michael Muehlebach"
        ],
        "published": "2024-05-17T08:30:28Z"
    },
    {
        "title": "Distributed Model Predictive Control for Asynchronous Multi-agent\n  Systems with Self-Triggered Coordinator",
        "link": "http://arxiv.org/abs/2405.11005v1",
        "abstract": "This paper investigates the distributed model predictive control for an\nasynchronous nonlinear multi-agent system with external interference via a\nself-triggered generator and a prediction horizon regulator. First, a shrinking\nconstraint related to the error between the actual state and the predicted\nstate is introduced into the optimal control problem to enable the robustness\nof the system. Then, the trigger interval and the corresponding prediction\nhorizon are determined by altering the expression of the Lyapunov function,\nthus achieving a trade-off between control performance and energy loss. By\nimplementing the proposed algorithm, the coordination objective of the\nmulti-agent system is achieved under asynchronous communication. Finally, the\nrecursive feasibility and stability are proven successively. An illustrative\nexample is conducted to demonstrate the merits of the presented approach.",
        "subjects": [
            "eess.SY",
            "cs.SY",
            "nlin.AO"
        ],
        "authors": [
            "Qianqian Chen",
            "Shaoyuan Li"
        ],
        "published": "2024-05-17T08:30:03Z"
    },
    {
        "title": "Feature-based Low-Rank Compression of Large Language Models via Bayesian\n  Optimization",
        "link": "http://arxiv.org/abs/2405.10616v1",
        "abstract": "In recent years, large language models (LLMs) have driven advances in natural\nlanguage processing. Still, their growing scale has increased the computational\nburden, necessitating a balance between efficiency and performance. Low-rank\ncompression, a promising technique, reduces non-essential parameters by\ndecomposing weight matrices into products of two low-rank matrices. Yet, its\napplication in LLMs has not been extensively studied. The key to low-rank\ncompression lies in low-rank factorization and low-rank dimensions allocation.\nTo address the challenges of low-rank compression in LLMs, we conduct empirical\nresearch on the low-rank characteristics of large models. We propose a low-rank\ncompression method suitable for LLMs. This approach involves precise estimation\nof feature distributions through pooled covariance matrices and a Bayesian\noptimization strategy for allocating low-rank dimensions. Experiments on the\nLLaMA-2 models demonstrate that our method outperforms existing strong\nstructured pruning and low-rank compression techniques in maintaining model\nperformance at the same compression ratio.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Yixin Ji",
            "Yang Xiang",
            "Juntao Li",
            "Wei Chen",
            "Zhongyi Liu",
            "Kehai Chen",
            "Min Zhang"
        ],
        "published": "2024-05-17T08:27:12Z"
    },
    {
        "title": "Not All Prompts Are Secure: A Switchable Backdoor Attack Against\n  Pre-trained Vision Transformers",
        "link": "http://arxiv.org/abs/2405.10612v1",
        "abstract": "Given the power of vision transformers, a new learning paradigm, pre-training\nand then prompting, makes it more efficient and effective to address downstream\nvisual recognition tasks. In this paper, we identify a novel security threat\ntowards such a paradigm from the perspective of backdoor attacks. Specifically,\nan extra prompt token, called the switch token in this work, can turn the\nbackdoor mode on, i.e., converting a benign model into a backdoored one. Once\nunder the backdoor mode, a specific trigger can force the model to predict a\ntarget class. It poses a severe risk to the users of cloud API, since the\nmalicious behavior can not be activated and detected under the benign mode,\nthus making the attack very stealthy. To attack a pre-trained model, our\nproposed attack, named SWARM, learns a trigger and prompt tokens including a\nswitch token. They are optimized with the clean loss which encourages the model\nalways behaves normally even the trigger presents, and the backdoor loss that\nensures the backdoor can be activated by the trigger when the switch is on.\nBesides, we utilize the cross-mode feature distillation to reduce the effect of\nthe switch token on clean samples. The experiments on diverse visual\nrecognition tasks confirm the success of our switchable backdoor attack, i.e.,\nachieving 95%+ attack success rate, and also being hard to be detected and\nremoved. Our code is available at https://github.com/20000yshust/SWARM.",
        "subjects": [
            "cs.CV",
            "cs.CR",
            "cs.LG"
        ],
        "authors": [
            "Sheng Yang",
            "Jiawang Bai",
            "Kuofeng Gao",
            "Yong Yang",
            "Yiming Li",
            "Shu-tao Xia"
        ],
        "published": "2024-05-17T08:19:48Z"
    },
    {
        "title": "A Certified Proof Checker for Deep Neural Network Verification",
        "link": "http://arxiv.org/abs/2405.10611v1",
        "abstract": "Recent advances in the verification of deep neural networks (DNNs) have\nopened the way for broader usage of DNN verification technology in many\napplication areas, including safety-critical ones. DNN verifiers are themselves\ncomplex programs that have been shown to be susceptible to errors and\nimprecisions; this in turn has raised the question of trust in DNN verifiers.\nOne prominent attempt to address this issue is enhancing DNN verifiers with the\ncapability of producing proofs of their results that are subject to independent\nalgorithmic certification (proof checking). Formulations of proof production\nand proof checking already exist on top of the state-of-the-art Marabou DNN\nverifier. The native implementation of the proof checking algorithm for Marabou\nwas done in C++ and itself raised the question of trust in the code (e.g., in\nthe precision of floating point calculations or guarantees for implementation\nsoundness). Here, we present an alternative implementation of the Marabou proof\nchecking algorithm in Imandra -- an industrial functional programming language\nand prover -- that allows us to obtain an implementation with formal\nguarantees, including proofs of mathematical results underlying the algorithm,\nsuch as the use of the Farkas lemma.",
        "subjects": [
            "cs.LO",
            "cs.AI",
            "cs.PL"
        ],
        "authors": [
            "Remi Desmartin",
            "Omri Isac",
            "Ekaterina Komendantskaya",
            "Kathrin Stark",
            "Grant Passmore",
            "Guy Katz"
        ],
        "published": "2024-05-17T08:16:32Z"
    },
    {
        "title": "Driving Referring Video Object Segmentation with Vision-Language\n  Pre-trained Models",
        "link": "http://arxiv.org/abs/2405.10610v1",
        "abstract": "The crux of Referring Video Object Segmentation (RVOS) lies in modeling dense\ntext-video relations to associate abstract linguistic concepts with dynamic\nvisual contents at pixel-level. Current RVOS methods typically use vision and\nlanguage models pre-trained independently as backbones. As images and texts are\nmapped to uncoupled feature spaces, they face the arduous task of learning\nVision-Language~(VL) relation modeling from scratch. Witnessing the success of\nVision-Language Pre-trained (VLP) models, we propose to learn relation modeling\nfor RVOS based on their aligned VL feature space. Nevertheless, transferring\nVLP models to RVOS is a deceptively challenging task due to the substantial gap\nbetween the pre-training task (image/region-level prediction) and the RVOS task\n(pixel-level prediction in videos). In this work, we introduce a framework\nnamed VLP-RVOS to address this transfer challenge. We first propose a\ntemporal-aware prompt-tuning method, which not only adapts pre-trained\nrepresentations for pixel-level prediction but also empowers the vision encoder\nto model temporal clues. We further propose to perform multi-stage VL relation\nmodeling while and after feature extraction for comprehensive VL understanding.\nBesides, we customize a cube-frame attention mechanism for spatial-temporal\nreasoning. Extensive experiments demonstrate that our method outperforms\nstate-of-the-art algorithms and exhibits strong generalization abilities.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zikun Zhou",
            "Wentao Xiong",
            "Li Zhou",
            "Xin Li",
            "Zhenyu He",
            "Yaowei Wang"
        ],
        "published": "2024-05-17T08:14:22Z"
    },
    {
        "title": "ECATS: Explainable-by-design concept-based anomaly detection for time\n  series",
        "link": "http://arxiv.org/abs/2405.10608v1",
        "abstract": "Deep learning methods for time series have already reached excellent\nperformances in both prediction and classification tasks, including anomaly\ndetection. However, the complexity inherent in Cyber Physical Systems (CPS)\ncreates a challenge when it comes to explainability methods. To overcome this\ninherent lack of interpretability, we propose ECATS, a concept-based\nneuro-symbolic architecture where concepts are represented as Signal Temporal\nLogic (STL) formulae. Leveraging kernel-based methods for STL, concept\nembeddings are learnt in an unsupervised manner through a cross-attention\nmechanism. The network makes class predictions through these concept\nembeddings, allowing for a meaningful explanation to be naturally extracted for\neach input. Our preliminary experiments with a simple CPS-based dataset show\nthat our model is able to achieve great classification performance while\nensuring local interpretability.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Irene Ferfoglia",
            "Gaia Saveri",
            "Laura Nenzi",
            "Luca Bortolussi"
        ],
        "published": "2024-05-17T08:12:53Z"
    },
    {
        "title": "Learning Object-Centric Representation via Reverse Hierarchy Guidance",
        "link": "http://arxiv.org/abs/2405.10598v1",
        "abstract": "Object-Centric Learning (OCL) seeks to enable Neural Networks to identify\nindividual objects in visual scenes, which is crucial for interpretable visual\ncomprehension and reasoning. Most existing OCL models adopt auto-encoding\nstructures and learn to decompose visual scenes through specially designed\ninductive bias, which causes the model to miss small objects during\nreconstruction. Reverse hierarchy theory proposes that human vision corrects\nperception errors through a top-down visual pathway that returns to\nbottom-level neurons and acquires more detailed information, inspired by which\nwe propose Reverse Hierarchy Guided Network (RHGNet) that introduces a top-down\npathway that works in different ways in the training and inference processes.\nThis pathway allows for guiding bottom-level features with top-level object\nrepresentations during training, as well as encompassing information from\nbottom-level features into perception during inference. Our model achieves SOTA\nperformance on several commonly used datasets including CLEVR, CLEVRTex and\nMOVi-C. We demonstrate with experiments that our method promotes the discovery\nof small objects and also generalizes well on complex real-world scenes. Code\nwill be available at https://anonymous.4open.science/r/RHGNet-6CEF.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Junhong Zou",
            "Xiangyu Zhu",
            "Zhaoxiang Zhang",
            "Zhen Lei"
        ],
        "published": "2024-05-17T07:48:27Z"
    },
    {
        "title": "UniCL: A Universal Contrastive Learning Framework for Large Time Series\n  Models",
        "link": "http://arxiv.org/abs/2405.10597v1",
        "abstract": "Time-series analysis plays a pivotal role across a range of critical\napplications, from finance to healthcare, which involves various tasks, such as\nforecasting and classification. To handle the inherent complexities of\ntime-series data, such as high dimensionality and noise, traditional supervised\nlearning methods first annotate extensive labels for time-series data in each\ntask, which is very costly and impractical in real-world applications. In\ncontrast, pre-trained foundation models offer a promising alternative by\nleveraging unlabeled data to capture general time series patterns, which can\nthen be fine-tuned for specific tasks. However, existing approaches to\npre-training such models typically suffer from high-bias and low-generality\nissues due to the use of predefined and rigid augmentation operations and\ndomain-specific data training. To overcome these limitations, this paper\nintroduces UniCL, a universal and scalable contrastive learning framework\ndesigned for pretraining time-series foundation models across cross-domain\ndatasets. Specifically, we propose a unified and trainable time-series\naugmentation operation to generate pattern-preserved, diverse, and low-bias\ntime-series data by leveraging spectral information. Besides, we introduce a\nscalable augmentation algorithm capable of handling datasets with varying\nlengths, facilitating cross-domain pretraining. Extensive experiments on two\nbenchmark datasets across eleven domains validate the effectiveness of UniCL,\ndemonstrating its high generalization on time-series analysis across various\nfields.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Jiawei Li",
            "Jingshu Peng",
            "Haoyang Li",
            "Lei Chen"
        ],
        "published": "2024-05-17T07:47:11Z"
    },
    {
        "title": "Enhancing the analysis of murine neonatal ultrasonic vocalizations:\n  Development, evaluation, and application of different mathematical models",
        "link": "http://arxiv.org/abs/2405.12957v1",
        "abstract": "Rodents employ a broad spectrum of ultrasonic vocalizations (USVs) for social\ncommunication. As these vocalizations offer valuable insights into affective\nstates, social interactions, and developmental stages of animals, various deep\nlearning approaches have aimed to automate both the quantitative (detection)\nand qualitative (classification) analysis of USVs. Here, we present the first\nsystematic evaluation of different types of neural networks for USV\nclassification. We assessed various feedforward networks, including a\ncustom-built, fully-connected network and convolutional neural network,\ndifferent residual neural networks (ResNets), an EfficientNet, and a Vision\nTransformer (ViT). Paired with a refined, entropy-based detection algorithm\n(achieving recall of 94.9% and precision of 99.3%), the best architecture\n(achieving 86.79% accuracy) was integrated into a fully automated pipeline\ncapable of analyzing extensive USV datasets with high reliability.\nAdditionally, users can specify an individual minimum accuracy threshold based\non their research needs. In this semi-automated setup, the pipeline selectively\nclassifies calls with high pseudo-probability, leaving the rest for manual\ninspection. Our study focuses exclusively on neonatal USVs. As part of an\nongoing phenotyping study, our pipeline has proven to be a valuable tool for\nidentifying key differences in USVs produced by mice with autism-like\nbehaviors.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "authors": [
            "Rudolf Herdt",
            "Louisa Kinzel",
            "Johann Georg Maaß",
            "Marvin Walther",
            "Henning Fröhlich",
            "Tim Schubert",
            "Peter Maass",
            "Christian Patrick Schaaf"
        ],
        "published": "2024-05-17T07:46:05Z"
    },
    {
        "title": "CELA: Cost-Efficient Language Model Alignment for CTR Prediction",
        "link": "http://arxiv.org/abs/2405.10596v1",
        "abstract": "Click-Through Rate (CTR) prediction holds a paramount position in recommender\nsystems. The prevailing ID-based paradigm underperforms in cold-start scenarios\ndue to the skewed distribution of feature frequency. Additionally, the\nutilization of a single modality fails to exploit the knowledge contained\nwithin textual features. Recent efforts have sought to mitigate these\nchallenges by integrating Pre-trained Language Models (PLMs). They design hard\nprompts to structure raw features into text for each interaction and then apply\nPLMs for text processing. With external knowledge and reasoning capabilities,\nPLMs extract valuable information even in cases of sparse interactions.\nNevertheless, compared to ID-based models, pure text modeling degrades the\nefficacy of collaborative filtering, as well as feature scalability and\nefficiency during both training and inference. To address these issues, we\npropose \\textbf{C}ost-\\textbf{E}fficient \\textbf{L}anguage Model\n\\textbf{A}lignment (\\textbf{CELA}) for CTR prediction. CELA incorporates\ntextual features and language models while preserving the collaborative\nfiltering capabilities of ID-based models. This model-agnostic framework can be\nequipped with plug-and-play textual features, with item-level alignment\nenhancing the utilization of external information while maintaining training\nand inference efficiency. Through extensive offline experiments, CELA\ndemonstrates superior performance compared to state-of-the-art methods.\nFurthermore, an online A/B test conducted on an industrial App recommender\nsystem showcases its practical effectiveness, solidifying the potential for\nreal-world applications of CELA.",
        "subjects": [
            "cs.IR",
            "68T07"
        ],
        "authors": [
            "Xingmei Wang",
            "Weiwen Liu",
            "Xiaolong Chen",
            "Qi Liu",
            "Xu Huang",
            "Defu Lian",
            "Xiangyang Li",
            "Yasheng Wang",
            "Zhenhua Dong",
            "Ruiming Tang"
        ],
        "published": "2024-05-17T07:43:25Z"
    },
    {
        "title": "Surgical Feature-Space Decomposition of LLMs: Why, When and How?",
        "link": "http://arxiv.org/abs/2405.13039v1",
        "abstract": "Low-rank approximations, of the weight and feature space can enhance the\nperformance of deep learning models, whether in terms of improving\ngeneralization or reducing the latency of inference. However, there is no clear\nconsensus yet on \\emph{how}, \\emph{when} and \\emph{why} these approximations\nare helpful for large language models (LLMs). In this work, we empirically\nstudy the efficacy of weight and feature space decomposition in\ntransformer-based LLMs. We demonstrate that surgical decomposition not only\nprovides critical insights into the trade-off between compression and language\nmodelling performance, but also sometimes enhances commonsense reasoning\nperformance of LLMs. Our empirical analysis identifies specific network\nsegments that intrinsically exhibit a low-rank structure. Furthermore, we\nextend our investigation to the implications of low-rank approximations on\nmodel bias. Overall, our findings offer a novel perspective on optimizing LLMs,\npresenting the low-rank approximation not only as a tool for performance\nenhancements, but also as a means to potentially rectify biases within these\nmodels. Our code is available at\n\\href{https://github.com/nyunAI/SFSD-LLM}{GitHub}.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Arnav Chavan",
            "Nahush Lele",
            "Deepak Gupta"
        ],
        "published": "2024-05-17T07:34:03Z"
    },
    {
        "title": "GEOcc: Geometrically Enhanced 3D Occupancy Network with\n  Implicit-Explicit Depth Fusion and Contextual Self-Supervision",
        "link": "http://arxiv.org/abs/2405.10591v1",
        "abstract": "3D occupancy perception holds a pivotal role in recent vision-centric\nautonomous driving systems by converting surround-view images into integrated\ngeometric and semantic representations within dense 3D grids. Nevertheless,\ncurrent models still encounter two main challenges: modeling depth accurately\nin the 2D-3D view transformation stage, and overcoming the lack of\ngeneralizability issues due to sparse LiDAR supervision. To address these\nissues, this paper presents GEOcc, a Geometric-Enhanced Occupancy network\ntailored for vision-only surround-view perception. Our approach is three-fold:\n1) Integration of explicit lift-based depth prediction and implicit\nprojection-based transformers for depth modeling, enhancing the density and\nrobustness of view transformation. 2) Utilization of mask-based encoder-decoder\narchitecture for fine-grained semantic predictions; 3) Adoption of\ncontext-aware self-training loss functions in the pertaining stage to\ncomplement LiDAR supervision, involving the re-rendering of 2D depth maps from\n3D occupancy features and leveraging image reconstruction loss to obtain denser\ndepth supervision besides sparse LiDAR ground-truths. Our approach achieves\nState-Of-The-Art performance on the Occ3D-nuScenes dataset with the least image\nresolution needed and the most weightless image backbone compared with current\nmodels, marking an improvement of 3.3% due to our proposed contributions.\nComprehensive experimentation also demonstrates the consistent superiority of\nour method over baselines and alternative approaches.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xin Tan",
            "Wenbin Wu",
            "Zhiwei Zhang",
            "Chaojie Fan",
            "Yong Peng",
            "Zhizhong Zhang",
            "Yuan Xie",
            "Lizhuang Ma"
        ],
        "published": "2024-05-17T07:31:20Z"
    },
    {
        "title": "An Explanatory Model Steering System for Collaboration between Domain\n  Experts and AI",
        "link": "http://dx.doi.org/10.1145/3631700.3664886",
        "abstract": "With the increasing adoption of Artificial Intelligence (AI) systems in\nhigh-stake domains, such as healthcare, effective collaboration between domain\nexperts and AI is imperative. To facilitate effective collaboration between\ndomain experts and AI systems, we introduce an Explanatory Model Steering\nsystem that allows domain experts to steer prediction models using their domain\nknowledge. The system includes an explanation dashboard that combines different\ntypes of data-centric and model-centric explanations and allows prediction\nmodels to be steered through manual and automated data configuration\napproaches. It allows domain experts to apply their prior knowledge for\nconfiguring the underlying training data and refining prediction models.\nAdditionally, our model steering system has been evaluated for a\nhealthcare-focused scenario with 174 healthcare experts through three extensive\nuser studies. Our findings highlight the importance of involving domain experts\nduring model steering, ultimately leading to improved human-AI collaboration.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Aditya Bhattacharya",
            "Simone Stumpf",
            "Katrien Verbert"
        ],
        "published": "2024-05-17T07:27:48Z"
    },
    {
        "title": "Improving Point-based Crowd Counting and Localization Based on Auxiliary\n  Point Guidance",
        "link": "http://arxiv.org/abs/2405.10589v1",
        "abstract": "Crowd counting and localization have become increasingly important in\ncomputer vision due to their wide-ranging applications. While point-based\nstrategies have been widely used in crowd counting methods, they face a\nsignificant challenge, i.e., the lack of an effective learning strategy to\nguide the matching process. This deficiency leads to instability in matching\npoint proposals to target points, adversely affecting overall performance. To\naddress this issue, we introduce an effective approach to stabilize the\nproposal-target matching in point-based methods. We propose Auxiliary Point\nGuidance (APG) to provide clear and effective guidance for proposal selection\nand optimization, addressing the core issue of matching uncertainty.\nAdditionally, we develop Implicit Feature Interpolation (IFI) to enable\nadaptive feature extraction in diverse crowd scenarios, further enhancing the\nmodel's robustness and accuracy. Extensive experiments demonstrate the\neffectiveness of our approach, showing significant improvements in crowd\ncounting and localization performance, particularly under challenging\nconditions. The source codes and trained models will be made publicly\navailable.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "eess.IV"
        ],
        "authors": [
            "I-Hsiang Chen",
            "Wei-Ting Chen",
            "Yu-Wei Liu",
            "Ming-Hsuan Yang",
            "Sy-Yen Kuo"
        ],
        "published": "2024-05-17T07:23:27Z"
    },
    {
        "title": "RDRec: Rationale Distillation for LLM-based Recommendation",
        "link": "http://arxiv.org/abs/2405.10587v1",
        "abstract": "Large language model (LLM)-based recommender models that bridge users and\nitems through textual prompts for effective semantic reasoning have gained\nconsiderable attention. However, few methods consider the underlying rationales\nbehind interactions, such as user preferences and item attributes, limiting the\nreasoning capability of LLMs for recommendations. This paper proposes a\nrationale distillation recommender (RDRec), a compact model designed to learn\nrationales generated by a larger language model (LM). By leveraging rationales\nfrom reviews related to users and items, RDRec remarkably specifies their\nprofiles for recommendations. Experiments show that RDRec achieves\nstate-of-the-art (SOTA) performance in both top-N and sequential\nrecommendations. Our source code is released at\nhttps://github.com/WangXFng/RDRec.",
        "subjects": [
            "cs.CL",
            "cs.IR"
        ],
        "authors": [
            "Xinfeng Wang",
            "Jin Cui",
            "Yoshimi Suzuki",
            "Fumiyo Fukumoto"
        ],
        "published": "2024-05-17T07:22:02Z"
    },
    {
        "title": "A Hybrid Deep Learning Framework for Stock Price Prediction Considering\n  the Investor Sentiment of Online Forum Enhanced by Popularity",
        "link": "http://arxiv.org/abs/2405.10584v1",
        "abstract": "Stock price prediction has always been a difficult task for forecasters.\nUsing cutting-edge deep learning techniques, stock price prediction based on\ninvestor sentiment extracted from online forums has become feasible. We propose\na novel hybrid deep learning framework for predicting stock prices. The\nframework leverages the XLNET model to analyze the sentiment conveyed in user\nposts on online forums, combines these sentiments with the post popularity\nfactor to compute daily group sentiments, and integrates this information with\nstock technical indicators into an improved BiLSTM-highway model for stock\nprice prediction. Through a series of comparative experiments involving four\nstocks on the Chinese stock market, it is demonstrated that the hybrid\nframework effectively predicts stock prices. This study reveals the necessity\nof analyzing investors' textual views for stock price prediction.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "q-fin.ST"
        ],
        "authors": [
            "Huiyu Li",
            "Junhua Hu"
        ],
        "published": "2024-05-17T07:18:08Z"
    },
    {
        "title": "Future Aware Safe Active Learning of Time Varying Systems using Gaussian\n  Processes",
        "link": "http://arxiv.org/abs/2405.10581v1",
        "abstract": "Experimental exploration of high-cost systems with safety constraints, common\nin engineering applications, is a challenging endeavor. Data-driven models\noffer a promising solution, but acquiring the requisite data remains expensive\nand is potentially unsafe. Safe active learning techniques prove essential,\nenabling the learning of high-quality models with minimal expensive data points\nand high safety. This paper introduces a safe active learning framework\ntailored for time-varying systems, addressing drift, seasonal changes, and\ncomplexities due to dynamic behavior. The proposed Time-aware Integrated Mean\nSquared Prediction Error (T-IMSPE) method minimizes posterior variance over\ncurrent and future states, optimizing information gathering also in the time\ndomain. Empirical results highlight T-IMSPE's advantages in model quality\nthrough toy and real-world examples. State of the art Gaussian processes are\ncompatible with T-IMSPE. Our theoretical contributions include a clear\ndelineation which Gaussian process kernels, domains, and weighting measures are\nsuitable for T-IMSPE and even beyond for its non-time aware predecessor IMSPE.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.OC",
            "math.PR",
            "I.2.6; G.3; J.2; I.1.4"
        ],
        "authors": [
            "Markus Lange-Hegermann",
            "Christoph Zimmer"
        ],
        "published": "2024-05-17T07:09:52Z"
    },
    {
        "title": "A Hard Nut to Crack: Idiom Detection with Conversational Large Language\n  Models",
        "link": "http://arxiv.org/abs/2405.10579v1",
        "abstract": "In this work, we explore idiomatic language processing with Large Language\nModels (LLMs). We introduce the Idiomatic language Test Suite IdioTS, a new\ndataset of difficult examples specifically designed by language experts to\nassess the capabilities of LLMs to process figurative language at sentence\nlevel. We propose a comprehensive evaluation methodology based on an idiom\ndetection task, where LLMs are prompted with detecting an idiomatic expression\nin a given English sentence. We present a thorough automatic and manual\nevaluation of the results and an extensive error analysis.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Francesca De Luca Fornaciari",
            "Begoña Altuna",
            "Itziar Gonzalez-Dios",
            "Maite Melero"
        ],
        "published": "2024-05-17T07:08:13Z"
    },
    {
        "title": "Jacobi Stability Analysis for Systems of ODEs Using Symbolic Computation",
        "link": "http://arxiv.org/abs/2405.10578v2",
        "abstract": "The classical theory of Kosambi-Cartan-Chern (KCC) developed in differential\ngeometry provides a powerful method for analyzing the behaviors of dynamical\nsystems. In the KCC theory, the properties of a dynamical system are described\nin terms of five geometrical invariants, of which the second corresponds to the\nso-called Jacobi stability of the system. Different from that of the Lyapunov\nstability that has been studied extensively in the literature, the analysis of\nthe Jacobi stability has been investigated more recently using geometrical\nconcepts and tools. It turns out that the existing work on the Jacobi stability\nanalysis remains theoretical and the problem of algorithmic and symbolic\ntreatment of Jacobi stability analysis has yet to be addressed. In this paper,\nwe initiate our study on the problem for a class of ODE systems of arbitrary\ndimension and propose two algorithmic schemes using symbolic computation to\ncheck whether a nonlinear dynamical system may exhibit Jacobi stability. The\nfirst scheme, based on the construction of the complex root structure of a\ncharacteristic polynomial and on the method of quantifier elimination, is\ncapable of detecting the existence of the Jacobi stability of the given\ndynamical system. The second algorithmic scheme exploits the method of\nsemi-algebraic system solving and allows one to determine conditions on the\nparameters for a given dynamical system to have a prescribed number of Jacobi\nstable fixed points. Several examples are presented to demonstrate the\neffectiveness of the proposed algorithmic schemes.",
        "subjects": [
            "cs.SC",
            "34C07, 68W30"
        ],
        "authors": [
            "Bo Huang",
            "Dongming Wang",
            "Jing Yang"
        ],
        "published": "2024-05-17T07:05:21Z"
    },
    {
        "title": "DuoSpaceNet: Leveraging Both Bird's-Eye-View and Perspective View\n  Representations for 3D Object Detection",
        "link": "http://arxiv.org/abs/2405.10577v1",
        "abstract": "Recent advances in multi-view camera-only 3D object detection either rely on\nan accurate reconstruction of bird's-eye-view (BEV) 3D features or on\ntraditional 2D perspective view (PV) image features. While both have their own\npros and cons, few have found a way to stitch them together in order to benefit\nfrom \"the best of both worlds\". To this end, we explore a duo space (i.e., BEV\nand PV) 3D perception framework, in conjunction with some useful duo space\nfusion strategies that allow effective aggregation of the two feature\nrepresentations. To the best of our knowledge, our proposed method,\nDuoSpaceNet, is the first to leverage two distinct feature spaces and achieves\nthe state-of-the-art 3D object detection and BEV map segmentation results on\nnuScenes dataset.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Zhe Huang",
            "Yizhe Zhao",
            "Hao Xiao",
            "Chenyan Wu",
            "Lingting Ge"
        ],
        "published": "2024-05-17T07:04:29Z"
    },
    {
        "title": "An Efficient Learning Control Framework With Sim-to-Real for String-Type\n  Artificial Muscle-Driven Robotic Systems",
        "link": "http://arxiv.org/abs/2405.10576v1",
        "abstract": "Robotic systems driven by artificial muscles present unique challenges due to\nthe nonlinear dynamics of actuators and the complex designs of mechanical\nstructures. Traditional model-based controllers often struggle to achieve\ndesired control performance in such systems. Deep reinforcement learning (DRL),\na trending machine learning technique widely adopted in robot control, offers a\npromising alternative. However, integrating DRL into these robotic systems\nfaces significant challenges, including the requirement for large amounts of\ntraining data and the inevitable sim-to-real gap when deployed to real-world\nrobots. This paper proposes an efficient reinforcement learning control\nframework with sim-to-real transfer to address these challenges. Bootstrap and\naugmentation enhancements are designed to improve the data efficiency of\nbaseline DRL algorithms, while a sim-to-real transfer technique, namely\nrandomization of muscle dynamics, is adopted to bridge the gap between\nsimulation and real-world deployment. Extensive experiments and ablation\nstudies are conducted utilizing two string-type artificial muscle-driven\nrobotic systems including a two degree-of-freedom robotic eye and a parallel\nrobotic wrist, the results of which demonstrate the effectiveness of the\nproposed learning control strategy.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Jiyue Tao",
            "Yunsong Zhang",
            "Sunil Kumar Rajendran",
            "Feitian Zhang",
            "Dexin Zhao",
            "Tongsheng Shen"
        ],
        "published": "2024-05-17T07:01:36Z"
    },
    {
        "title": "Accurate Training Data for Occupancy Map Prediction in Automated Driving\n  Using Evidence Theory",
        "link": "http://arxiv.org/abs/2405.10575v1",
        "abstract": "Automated driving fundamentally requires knowledge about the surrounding\ngeometry of the scene. Modern approaches use only captured images to predict\noccupancy maps that represent the geometry. Training these approaches requires\naccurate data that may be acquired with the help of LiDAR scanners. We show\nthat the techniques used for current benchmarks and training datasets to\nconvert LiDAR scans into occupancy grid maps yield very low quality, and\nsubsequently present a novel approach using evidence theory that yields more\naccurate reconstructions. We demonstrate that these are superior by a large\nmargin, both qualitatively and quantitatively, and that we additionally obtain\nmeaningful uncertainty estimates. When converting the occupancy maps back to\ndepth estimates and comparing them with the raw LiDAR measurements, our method\nyields a MAE improvement of 30% to 52% on nuScenes and 53% on Waymo over other\noccupancy ground-truth data. Finally, we use the improved occupancy maps to\ntrain a state-of-the-art occupancy prediction method and demonstrate that it\nimproves the MAE by 25% on nuScenes.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jonas Kälble",
            "Sascha Wirges",
            "Maxim Tatarchenko",
            "Eddy Ilg"
        ],
        "published": "2024-05-17T07:00:58Z"
    },
    {
        "title": "Enhancing Dialogue State Tracking Models through LLM-backed User-Agents\n  Simulation",
        "link": "http://arxiv.org/abs/2405.13037v1",
        "abstract": "Dialogue State Tracking (DST) is designed to monitor the evolving dialogue\nstate in the conversations and plays a pivotal role in developing task-oriented\ndialogue systems. However, obtaining the annotated data for the DST task is\nusually a costly endeavor. In this paper, we focus on employing LLMs to\ngenerate dialogue data to reduce dialogue collection and annotation costs.\nSpecifically, GPT-4 is used to simulate the user and agent interaction,\ngenerating thousands of dialogues annotated with DST labels. Then a two-stage\nfine-tuning on LLaMA 2 is performed on the generated data and the real data for\nthe DST prediction. Experimental results on two public DST benchmarks show that\nwith the generated dialogue data, our model performs better than the baseline\ntrained solely on real data. In addition, our approach is also capable of\nadapting to the dynamic demands in real-world scenarios, generating dialogues\nin new domains swiftly. After replacing dialogue segments in any domain with\nthe corresponding generated ones, the model achieves comparable performance to\nthe model trained on real data.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Cheng Niu",
            "Xingguang Wang",
            "Xuxin Cheng",
            "Juntong Song",
            "Tong Zhang"
        ],
        "published": "2024-05-17T07:00:05Z"
    },
    {
        "title": "Resonances as a computational tool",
        "link": "http://arxiv.org/abs/2405.10572v1",
        "abstract": "A large toolbox of numerical schemes for dispersive equations has been\nestablished, based on different discretization techniques such as discretizing\nthe variation-of-constants formula (e.g., exponential integrators) or splitting\nthe full equation into a series of simpler subproblems (e.g., splitting\nmethods). In many situations these classical schemes allow a precise and\nefficient approximation. This, however, drastically changes whenever non-smooth\nphenomena enter the scene such as for problems at low regularity and high\noscillations. Classical schemes fail to capture the oscillatory nature of the\nsolution, and this may lead to severe instabilities and loss of convergence. In\nthis article we review a new class of resonance-based schemes. The key idea in\nthe construction of the new schemes is to tackle and deeply embed the\nunderlying nonlinear structure of resonances into the numerical discretization.\nAs in the continuous case, these terms are central to structure preservation\nand offer the new schemes strong properties at low regularity.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Frédéric Rousset",
            "Katharina Schratz"
        ],
        "published": "2024-05-17T06:53:56Z"
    },
    {
        "title": "Simultaneous Deep Learning of Myocardium Segmentation and T2\n  Quantification for Acute Myocardial Infarction MRI",
        "link": "http://arxiv.org/abs/2405.10570v1",
        "abstract": "In cardiac Magnetic Resonance Imaging (MRI) analysis, simultaneous myocardial\nsegmentation and T2 quantification are crucial for assessing myocardial\npathologies. Existing methods often address these tasks separately, limiting\ntheir synergistic potential. To address this, we propose SQNet, a dual-task\nnetwork integrating Transformer and Convolutional Neural Network (CNN)\ncomponents. SQNet features a T2-refine fusion decoder for quantitative\nanalysis, leveraging global features from the Transformer, and a segmentation\ndecoder with multiple local region supervision for enhanced accuracy. A tight\ncoupling module aligns and fuses CNN and Transformer branch features, enabling\nSQNet to focus on myocardium regions. Evaluation on healthy controls (HC) and\nacute myocardial infarction patients (AMI) demonstrates superior segmentation\ndice scores (89.3/89.2) compared to state-of-the-art methods (87.7/87.9). T2\nquantification yields strong linear correlations (Pearson coefficients:\n0.84/0.93) with label values for HC/AMI, indicating accurate mapping.\nRadiologist evaluations confirm SQNet's superior image quality scores\n(4.60/4.58 for segmentation, 4.32/4.42 for T2 quantification) over\nstate-of-the-art methods (4.50/4.44 for segmentation, 3.59/4.37 for T2\nquantification). SQNet thus offers accurate simultaneous segmentation and\nquantification, enhancing cardiac disease diagnosis, such as AMI.",
        "subjects": [
            "eess.IV",
            "cs.AI"
        ],
        "authors": [
            "Yirong Zhou",
            "Chengyan Wang",
            "Mengtian Lu",
            "Kunyuan Guo",
            "Zi Wang",
            "Dan Ruan",
            "Rui Guo",
            "Peijun Zhao",
            "Jianhua Wang",
            "Naiming Wu",
            "Jianzhong Lin",
            "Yinyin Chen",
            "Hang Jin",
            "Lianxin Xie",
            "Lilan Wu",
            "Liuhong Zhu",
            "Jianjun Zhou",
            "Congbo Cai",
            "He Wang",
            "Xiaobo Qu"
        ],
        "published": "2024-05-17T06:50:37Z"
    },
    {
        "title": "Team Samsung-RAL: Technical Report for 2024 RoboDrive Challenge-Robust\n  Map Segmentation Track",
        "link": "http://arxiv.org/abs/2405.10567v1",
        "abstract": "In this report, we describe the technical details of our submission to the\n2024 RoboDrive Challenge Robust Map Segmentation Track. The Robust Map\nSegmentation track focuses on the segmentation of complex driving scene\nelements in BEV maps under varied driving conditions. Semantic map segmentation\nprovides abundant and precise static environmental information crucial for\nautonomous driving systems' planning and navigation. While current methods\nexcel in ideal circumstances, e.g., clear daytime conditions and fully\nfunctional sensors, their resilience to real-world challenges like adverse\nweather and sensor failures remains unclear, raising concerns about system\nsafety. In this paper, we explored several methods to improve the robustness of\nthe map segmentation task. The details are as follows: 1) Robustness analysis\nof utilizing temporal information; 2) Robustness analysis of utilizing\ndifferent backbones; and 3) Data Augmentation to boost corruption robustness.\nBased on the evaluation results, we draw several important findings including\n1) The temporal fusion module is effective in improving the robustness of the\nmap segmentation model; 2) A strong backbone is effective for improving the\ncorruption robustness; and 3) Some data augmentation methods are effective in\nimproving the robustness of map segmentation models. These novel findings\nallowed us to achieve promising results in the 2024 RoboDrive Challenge-Robust\nMap Segmentation Track.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xiaoshuai Hao",
            "Yifan Yang",
            "Hui Zhang",
            "Mengchuan Wei",
            "Yi Zhou",
            "Haimei Zhao",
            "Jing Zhang"
        ],
        "published": "2024-05-17T06:40:02Z"
    },
    {
        "title": "Real-time Level-of-Detail Strand-based Hair Rendering",
        "link": "http://arxiv.org/abs/2405.10565v1",
        "abstract": "Strand-based hair rendering has become increasingly popular in production for\nits realistic appearance. However, the prevailing level-of-detail solution\nemploying hair cards for distant hair models introduces a significant\ndiscontinuity in dynamics and appearance during the transition from strands to\ncards. We introduce an innovative real-time framework for strand-based hair\nrendering that ensures seamless transitions between different levels of detail\n(LOD) while maintaining a consistent hair appearance. Our method uses\nelliptical thick hairs that contain multiple hair strands at each LOD to\nmaintain the shapes of hair clusters. In addition to geometric fitting, we\nformulate an elliptical Bidirectional Curve Scattering Distribution Functions\n(BCSDF) model for a thick hair, accurately capturing single scattering and\nmultiple scattering within the hair cluster, accommodating a spectrum from\nsparse to dense hair distributions. Our framework, tested on various hairstyles\nwith dynamics as well as knits, shows that it can produce highly similar\nappearances to full hair geometries at different viewing distances with\nseamless LOD transitions, while achieving up to a 3x speedup.",
        "subjects": [
            "cs.GR",
            "I.3.5; I.3.3"
        ],
        "authors": [
            "Tao Huang",
            "Yang Zhou",
            "Daqi Lin",
            "Junqiu Zhu",
            "Ling-Qi Yan",
            "Kui Wu"
        ],
        "published": "2024-05-17T06:24:43Z"
    },
    {
        "title": "Function Extrapolation with Neural Networks and Its Application for\n  Manifolds",
        "link": "http://arxiv.org/abs/2405.10563v1",
        "abstract": "This paper addresses the problem of accurately estimating a function on one\ndomain when only its discrete samples are available on another domain. To\nanswer this challenge, we utilize a neural network, which we train to\nincorporate prior knowledge of the function. In addition, by carefully\nanalyzing the problem, we obtain a bound on the error over the extrapolation\ndomain and define a condition number for this problem that quantifies the level\nof difficulty of the setup. Compared to other machine learning methods that\nprovide time series prediction, such as transformers, our approach is suitable\nfor setups where the interpolation and extrapolation regions are general\nsubdomains and, in particular, manifolds. In addition, our construction leads\nto an improved loss function that helps us boost the accuracy and robustness of\nour neural network. We conduct comprehensive numerical tests and comparisons of\nour extrapolation versus standard methods. The results illustrate the\neffectiveness of our approach in various scenarios.",
        "subjects": [
            "cs.LG",
            "cs.NA",
            "math.NA",
            "65K05"
        ],
        "authors": [
            "Guy Hay",
            "Nir Sharon"
        ],
        "published": "2024-05-17T06:15:26Z"
    },
    {
        "title": "Infrared Image Super-Resolution via Lightweight Information Split\n  Network",
        "link": "http://arxiv.org/abs/2405.10561v2",
        "abstract": "Single image super-resolution (SR) is an established pixel-level vision task\naimed at reconstructing a high-resolution image from its degraded\nlow-resolution counterpart. Despite the notable advancements achieved by\nleveraging deep neural networks for SR, most existing deep learning\narchitectures feature an extensive number of layers, leading to high\ncomputational complexity and substantial memory demands. These issues become\nparticularly pronounced in the context of infrared image SR, where infrared\ndevices often have stringent storage and computational constraints. To mitigate\nthese challenges, we introduce a novel, efficient, and precise single infrared\nimage SR model, termed the Lightweight Information Split Network (LISN). The\nLISN comprises four main components: shallow feature extraction, deep feature\nextraction, dense feature fusion, and high-resolution infrared image\nreconstruction. A key innovation within this model is the introduction of the\nLightweight Information Split Block (LISB) for deep feature extraction. The\nLISB employs a sequential process to extract hierarchical features, which are\nthen aggregated based on the relevance of the features under consideration. By\nintegrating channel splitting and shift operations, the LISB successfully\nstrikes an optimal balance between enhanced SR performance and a lightweight\nframework. Comprehensive experimental evaluations reveal that the proposed LISN\nachieves superior performance over contemporary state-of-the-art methods in\nterms of both SR quality and model complexity, affirming its efficacy for\npractical deployment in resource-constrained infrared imaging applications.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Shijie Liu",
            "Kang Yan",
            "Feiwei Qin",
            "Changmiao Wang",
            "Ruiquan Ge",
            "Kai Zhang",
            "Jie Huang",
            "Yong Peng",
            "Jin Cao"
        ],
        "published": "2024-05-17T06:10:42Z"
    },
    {
        "title": "CACL: Community-Aware Heterogeneous Graph Contrastive Learning for\n  Social Media Bot Detection",
        "link": "http://arxiv.org/abs/2405.10558v2",
        "abstract": "Social media bot detection is increasingly crucial with the rise of social\nmedia platforms. Existing methods predominantly construct social networks as\ngraph and utilize graph neural networks (GNNs) for bot detection. However, most\nof these methods focus on how to improve the performance of GNNs while\nneglecting the community structure within social networks. Moreover, GNNs based\nmethods still face problems such as poor model generalization due to the\nrelatively small scale of the dataset and over-smoothness caused by information\npropagation mechanism. To address these problems, we propose a Community-Aware\nHeterogeneous Graph Contrastive Learning framework (CACL), which constructs\nsocial network as heterogeneous graph with multiple node types and edge types,\nand then utilizes community-aware module to dynamically mine both hard positive\nsamples and hard negative samples for supervised graph contrastive learning\nwith adaptive graph enhancement algorithms. Extensive experiments demonstrate\nthat our framework addresses the previously mentioned challenges and\noutperforms competitive baselines on three social media bot benchmarks.",
        "subjects": [
            "cs.SI"
        ],
        "authors": [
            "Sirry Chen",
            "Shuo Feng",
            "Songsong Liang",
            "Chen-Chen Zong",
            "Jing Li",
            "Piji Li"
        ],
        "published": "2024-05-17T05:51:23Z"
    },
    {
        "title": "Resolving Symmetry Ambiguity in Correspondence-based Methods for\n  Instance-level Object Pose Estimation",
        "link": "http://arxiv.org/abs/2405.10557v1",
        "abstract": "Estimating the 6D pose of an object from a single RGB image is a critical\ntask that becomes additionally challenging when dealing with symmetric objects.\nRecent approaches typically establish one-to-one correspondences between image\npixels and 3D object surface vertices. However, the utilization of one-to-one\ncorrespondences introduces ambiguity for symmetric objects. To address this, we\npropose SymCode, a symmetry-aware surface encoding that encodes the object\nsurface vertices based on one-to-many correspondences, eliminating the problem\nof one-to-one correspondence ambiguity. We also introduce SymNet, a fast\nend-to-end network that directly regresses the 6D pose parameters without\nsolving a PnP problem. We demonstrate faster runtime and comparable accuracy\nachieved by our method on the T-LESS and IC-BIN benchmarks of mostly symmetric\nobjects. Our source code will be released upon acceptance.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yongliang Lin",
            "Yongzhi Su",
            "Sandeep Inuganti",
            "Yan Di",
            "Naeem Ajilforoushan",
            "Hanqing Yang",
            "Yu Zhang",
            "Jason Rambach"
        ],
        "published": "2024-05-17T05:48:56Z"
    },
    {
        "title": "Parameterized Complexity of Dominating Set Variants in Almost Cluster\n  and Split Graphs",
        "link": "http://arxiv.org/abs/2405.10556v1",
        "abstract": "We consider structural parameterizations of the fundamental Dominating Set\nproblem and its variants in the parameter ecology program. We give improved FPT\nalgorithms and lower bounds under well-known conjectures for dominating set in\ngraphs that are k vertices away from a cluster graph or a split graph. These\nare graphs in which there is a set of k vertices (called the modulator) whose\ndeletion results in a cluster graph or a split graph. We also call k as the\ndeletion distance (to the appropriate class of graphs). When parameterized by\nthe deletion distance k to cluster graphs - we can find a minimum dominating\nset (DS) in 3^k n^{O(1)}-time. Within the same time, we can also find a minimum\nindependent dominating set (IDS) or a minimum dominating clique (DC) or a\nminimum efficient dominating set (EDS) or a minimum total dominating set (TDS).\nWe also show that most of these variants of dominating set do not have\npolynomial sized kernel. Additionally, we show that when parameterized by the\ndeletion distance k to split graphs - IDS can be solved in 2^k n^{O(1)}-time\nand EDS can be solved in 3^{k/2}n^{O(1)}.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Dishant Goyal",
            "Ashwin Jacob",
            "Kaushtubh Kumar",
            "Diptapriyo Majumdar",
            "Venkatesh Raman"
        ],
        "published": "2024-05-17T05:47:26Z"
    },
    {
        "title": "NeRO: Neural Road Surface Reconstruction",
        "link": "http://arxiv.org/abs/2405.10554v1",
        "abstract": "In computer vision and graphics, the accurate reconstruction of road surfaces\nis pivotal for various applications, especially in autonomous driving. This\npaper introduces a novel method leveraging the Multi-Layer Perceptrons (MLPs)\nframework to reconstruct road surfaces in height, color, and semantic\ninformation by input world coordinates x and y. Our approach NeRO uses encoding\ntechniques based on MLPs, significantly improving the performance of the\ncomplex details, speeding up the training speed, and reducing neural network\nsize. The effectiveness of this method is demonstrated through its superior\nperformance, which indicates a promising direction for rendering road surfaces\nwith semantics applications, particularly in applications demanding\nvisualization of road conditions, 4D labeling, and semantic groupings.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ruibo Wang",
            "Song Zhang",
            "Ping Huang",
            "Donghai Zhang",
            "Haoyu Chen"
        ],
        "published": "2024-05-17T05:41:45Z"
    },
    {
        "title": "Data Science Principles for Interpretable and Explainable AI",
        "link": "http://arxiv.org/abs/2405.10552v1",
        "abstract": "Society's capacity for algorithmic problem-solving has never been greater.\nArtificial Intelligence is now applied across more domains than ever, a\nconsequence of powerful abstractions, abundant data, and accessible software.\nAs capabilities have expanded, so have risks, with models often deployed\nwithout fully understanding their potential impacts. Interpretable and\ninteractive machine learning aims to make complex models more transparent and\ncontrollable, enhancing user agency. This review synthesizes key principles\nfrom the growing literature in this field.\n  We first introduce precise vocabulary for discussing interpretability, like\nthe distinction between glass box and explainable algorithms. We then explore\nconnections to classical statistical and design principles, like parsimony and\nthe gulfs of interaction. Basic explainability techniques -- including learned\nembeddings, integrated gradients, and concept bottlenecks -- are illustrated\nwith a simple case study. We also review criteria for objectively evaluating\ninterpretability approaches. Throughout, we underscore the importance of\nconsidering audience goals when designing interactive algorithmic systems.\nFinally, we outline open challenges and discuss the potential role of data\nscience in addressing them. Code to reproduce all examples can be found at\nhttps://go.wisc.edu/3k1ewe.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Kris Sankaran"
        ],
        "published": "2024-05-17T05:32:27Z"
    },
    {
        "title": "LighTDiff: Surgical Endoscopic Image Low-Light Enhancement with\n  T-Diffusion",
        "link": "http://arxiv.org/abs/2405.10550v1",
        "abstract": "Advances in endoscopy use in surgeries face challenges like inadequate\nlighting. Deep learning, notably the Denoising Diffusion Probabilistic Model\n(DDPM), holds promise for low-light image enhancement in the medical field.\nHowever, DDPMs are computationally demanding and slow, limiting their practical\nmedical applications. To bridge this gap, we propose a lightweight DDPM, dubbed\nLighTDiff. It adopts a T-shape model architecture to capture global structural\ninformation using low-resolution images and gradually recover the details in\nsubsequent denoising steps. We further prone the model to significantly reduce\nthe model size while retaining performance. While discarding certain\ndownsampling operations to save parameters leads to instability and low\nefficiency in convergence during the training, we introduce a Temporal Light\nUnit (TLU), a plug-and-play module, for more stable training and better\nperformance. TLU associates time steps with denoised image features,\nestablishing temporal dependencies of the denoising steps and improving\ndenoising outcomes. Moreover, while recovering images using the diffusion\nmodel, potential spectral shifts were noted. We further introduce a Chroma\nBalancer (CB) to mitigate this issue. Our LighTDiff outperforms many\ncompetitive LLIE methods with exceptional computational efficiency.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Tong Chen",
            "Qingcheng Lyu",
            "Long Bai",
            "Erjian Guo",
            "Huxin Gao",
            "Xiaoxiao Yang",
            "Hongliang Ren",
            "Luping Zhou"
        ],
        "published": "2024-05-17T05:31:19Z"
    },
    {
        "title": "Language Models can Exploit Cross-Task In-context Learning for\n  Data-Scarce Novel Tasks",
        "link": "http://arxiv.org/abs/2405.10548v2",
        "abstract": "Large Language Models (LLMs) have transformed NLP with their remarkable\nIn-context Learning (ICL) capabilities. Automated assistants based on LLMs are\ngaining popularity; however, adapting them to novel tasks is still challenging.\nWhile colossal models excel in zero-shot performance, their computational\ndemands limit widespread use, and smaller language models struggle without\ncontext. This paper investigates whether LLMs can generalize from labeled\nexamples of predefined tasks to novel tasks. Drawing inspiration from\nbiological neurons and the mechanistic interpretation of the Transformer\narchitecture, we explore the potential for information sharing across tasks. We\ndesign a cross-task prompting setup with three LLMs and show that LLMs achieve\nsignificant performance improvements despite no examples from the target task\nin the context. Cross-task prompting leads to a remarkable performance boost of\n107% for LLaMA-2 7B, 18.6% for LLaMA-2 13B, and 3.2% for GPT 3.5 on average\nover zero-shot prompting, and performs comparable to standard in-context\nlearning. The effectiveness of generating pseudo-labels for in-task examples is\ndemonstrated, and our analyses reveal a strong correlation between the effect\nof cross-task examples and model activation similarities in source and target\ninput tokens. This paper offers a first-of-its-kind exploration of LLMs'\nability to solve novel tasks based on contextual signals from different task\nexamples.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Anwoy Chatterjee",
            "Eshaan Tanwar",
            "Subhabrata Dutta",
            "Tanmoy Chakraborty"
        ],
        "published": "2024-05-17T05:20:49Z"
    },
    {
        "title": "GPTs Window Shopping: An analysis of the Landscape of Custom ChatGPT\n  Models",
        "link": "http://arxiv.org/abs/2405.10547v1",
        "abstract": "OpenAI's ChatGPT initiated a wave of technical iterations in the space of\nLarge Language Models (LLMs) by demonstrating the capability and disruptive\npower of LLMs. OpenAI has prompted large organizations to respond with their\nown advancements and models to push the LLM performance envelope. OpenAI has\nprompted large organizations to respond with their own advancements and models\nto push the LLM performance envelope. OpenAI's success in spotlighting AI can\nbe partially attributed to decreased barriers to entry, enabling any individual\nwith an internet-enabled device to interact with LLMs. What was previously\nrelegated to a few researchers and developers with necessary computing\nresources is now available to all. A desire to customize LLMs to better\naccommodate individual needs prompted OpenAI's creation of the GPT Store, a\ncentral platform where users can create and share custom GPT models.\nCustomization comes in the form of prompt-tuning, analysis of reference\nresources, browsing, and external API interactions, alongside a promise of\nrevenue sharing for created custom GPTs. In this work, we peer into the window\nof the GPT Store and measure its impact. Our analysis constitutes a large-scale\noverview of the store exploring community perception, GPT details, and the GPT\nauthors, in addition to a deep-dive into a 3rd party storefront indexing\nuser-submitted GPTs, exploring if creators seek to monetize their creations in\nthe absence of OpenAI's revenue sharing.",
        "subjects": [
            "cs.SI"
        ],
        "authors": [
            "Benjamin Zi Hao Zhao",
            "Muhammad Ikram",
            "Mohamed Ali Kaafar"
        ],
        "published": "2024-05-17T05:19:34Z"
    },
    {
        "title": "You Can't Solve These Super Mario Bros. Levels: Undecidable Mario Games",
        "link": "http://arxiv.org/abs/2405.10546v1",
        "abstract": "We prove RE-completeness (and thus undecidability) of several 2D games in the\nSuper Mario Bros. platform video game series: the New Super Mario Bros. series\n(original, Wii, U, and 2), and both Super Mario Maker games in all five game\nstyles (Super Mario Bros. 1 and 3, Super Mario World, New Super Mario Bros. U,\nand Super Mario 3D World). These results hold even when we restrict to\nconstant-size levels and screens, but they do require generalizing to allow\narbitrarily many enemies at each location and onscreen, as well as allowing for\nexponentially large (or no) timer. Our New Super Mario Bros. constructions fit\nwithin one standard screen size. In our Super Mario Maker reductions, we work\nwithin the standard screen size and use the property that the game engine\nremembers offscreen objects that are global because they are supported by\n\"global ground\". To prove these Mario results, we build a new theory of counter\ngadgets in the motion-planning-through-gadgets framework, and provide a suite\nof simple gadgets for which reachability is RE-complete.",
        "subjects": [
            "cs.CC"
        ],
        "authors": [
            " MIT Hardness Group",
            "Hayashi Ani",
            "Erik D. Demaine",
            "Holden Hall",
            "Ricardo Ruiz",
            "Naveen Venkat"
        ],
        "published": "2024-05-17T05:15:33Z"
    },
    {
        "title": "Dynamic Cluster Analysis to Detect and Track Novelty in Network\n  Telescopes",
        "link": "http://arxiv.org/abs/2405.10545v1",
        "abstract": "In the context of cybersecurity, tracking the activities of coordinated hosts\nover time is a daunting task because both participants and their behaviours\nevolve at a fast pace. We address this scenario by solving a dynamic novelty\ndiscovery problem with the aim of both re-identifying patterns seen in the past\nand highlighting new patterns. We focus on traffic collected by Network\nTelescopes, a primary and noisy source for cybersecurity analysis. We propose a\n3-stage pipeline: (i) we learn compact representations (embeddings) of hosts\nthrough their traffic in a self-supervised fashion; (ii) via clustering, we\ndistinguish groups of hosts performing similar activities; (iii) we track the\ncluster temporal evolution to highlight novel patterns. We apply our\nmethodology to 20 days of telescope traffic during which we observe more than 8\nthousand active hosts. Our results show that we efficiently identify 50-70\nwell-shaped clusters per day, 60-70% of which we associate with already\nanalysed cases, while we pinpoint 10-20 previously unseen clusters per day.\nThese correspond to activity changes and new incidents, of which we document\nsome. In short, our novelty discovery methodology enormously simplifies the\nmanual analysis the security analysts have to conduct to gain insights to\ninterpret novel coordinated activities.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Kai Huang",
            "Luca Gioacchini",
            "Marco Mellia",
            "Luca Vassio"
        ],
        "published": "2024-05-17T05:15:17Z"
    },
    {
        "title": "SMARD: A Cost Effective Smart Agro Development Technology for Crops\n  Disease Classification",
        "link": "http://arxiv.org/abs/2405.10543v1",
        "abstract": "Agriculture has a significant role in a country's economy. The \"SMARD\"\nproject aims to strengthen the country's agricultural sector by giving farmers\nwith the information and tools they need to solve common difficulties and\nincrease productivity. The project provides farmers with information on crop\ncare, seed selection, and disease management best practices, as well as access\nto tools for recognizing and treating crop diseases. Farmers can also contact\nthe expert panel through text message, voice call, or video call to purchase\nfertilizer, seeds, and pesticides at low prices, as well as secure bank loans.\nThe project's goal is to empower farmers and rural communities by providing\nthem with the resources they need to increase crop yields. Additionally, the\n\"SMARD\" will not only help farmers and rural communities live better lives, but\nit will also have a good effect on the economy of the nation. Farmers are now\nable to recognize plant illnesses more quickly because of the application of\nmachine learning techniques based on image processing categorization. Our\nexperiments' results show that our system \"SMARD\" outperforms the cutting-edge\nweb applications by attaining 97.3% classification accuracy and 96% F1-score in\ncrop disease classification. Overall, our project is an important endeavor for\nthe nation's agricultural sector because its main goal is to give farmers the\ninformation, resources, and tools they need to increase crop yields, improve\neconomic outcomes, and improve livelihoods.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Tanoy Debnath",
            "Shadman Wadith",
            "Anichur Rahman"
        ],
        "published": "2024-05-17T05:14:39Z"
    },
    {
        "title": "Benchmarking Large Language Models on CFLUE -- A Chinese Financial\n  Language Understanding Evaluation Dataset",
        "link": "http://arxiv.org/abs/2405.10542v1",
        "abstract": "In light of recent breakthroughs in large language models (LLMs) that have\nrevolutionized natural language processing (NLP), there is an urgent need for\nnew benchmarks to keep pace with the fast development of LLMs. In this paper,\nwe propose CFLUE, the Chinese Financial Language Understanding Evaluation\nbenchmark, designed to assess the capability of LLMs across various dimensions.\nSpecifically, CFLUE provides datasets tailored for both knowledge assessment\nand application assessment. In knowledge assessment, it consists of 38K+\nmultiple-choice questions with associated solution explanations. These\nquestions serve dual purposes: answer prediction and question reasoning. In\napplication assessment, CFLUE features 16K+ test instances across distinct\ngroups of NLP tasks such as text classification, machine translation, relation\nextraction, reading comprehension, and text generation. Upon CFLUE, we conduct\na thorough evaluation of representative LLMs. The results reveal that only\nGPT-4 and GPT-4-turbo achieve an accuracy exceeding 60\\% in answer prediction\nfor knowledge assessment, suggesting that there is still substantial room for\nimprovement in current LLMs. In application assessment, although GPT-4 and\nGPT-4-turbo are the top two performers, their considerable advantage over\nlightweight LLMs is noticeably diminished. The datasets and scripts associated\nwith CFLUE are openly accessible at https://github.com/aliyun/cflue.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Jie Zhu",
            "Junhui Li",
            "Yalong Wen",
            "Lifan Guo"
        ],
        "published": "2024-05-17T05:03:40Z"
    },
    {
        "title": "Time-Varying Constraint-Aware Reinforcement Learning for Energy Storage\n  Control",
        "link": "http://arxiv.org/abs/2405.10536v1",
        "abstract": "Energy storage devices, such as batteries, thermal energy storages, and\nhydrogen systems, can help mitigate climate change by ensuring a more stable\nand sustainable power supply. To maximize the effectiveness of such energy\nstorage, determining the appropriate charging and discharging amounts for each\ntime period is crucial. Reinforcement learning is preferred over traditional\noptimization for the control of energy storage due to its ability to adapt to\ndynamic and complex environments. However, the continuous nature of charging\nand discharging levels in energy storage poses limitations for discrete\nreinforcement learning, and time-varying feasible charge-discharge range based\non state of charge (SoC) variability also limits the conventional continuous\nreinforcement learning. In this paper, we propose a continuous reinforcement\nlearning approach that takes into account the time-varying feasible\ncharge-discharge range. An additional objective function was introduced for\nlearning the feasible action range for each time period, supplementing the\nobjectives of training the actor for policy learning and the critic for value\nlearning. This actively promotes the utilization of energy storage by\npreventing them from getting stuck in suboptimal states, such as continuous\nfull charging or discharging. This is achieved through the enforcement of the\ncharging and discharging levels into the feasible action range. The\nexperimental results demonstrated that the proposed method further maximized\nthe effectiveness of energy storage by actively enhancing its utilization.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Jaeik Jeong",
            "Tai-Yeon Ku",
            "Wan-Ki Park"
        ],
        "published": "2024-05-17T04:28:54Z"
    },
    {
        "title": "CMA-ES for Safe Optimization",
        "link": "http://arxiv.org/abs/2405.10534v1",
        "abstract": "In several real-world applications in medical and control engineering, there\nare unsafe solutions whose evaluations involve inherent risk. This optimization\nsetting is known as safe optimization and formulated as a specialized type of\nconstrained optimization problem with constraints for safety functions. Safe\noptimization requires performing efficient optimization without evaluating\nunsafe solutions. A few studies have proposed the optimization methods for safe\noptimization based on Bayesian optimization and the evolutionary algorithm.\nHowever, Bayesian optimization-based methods often struggle to achieve superior\nsolutions, and the evolutionary algorithm-based method fails to effectively\nreduce unsafe evaluations. This study focuses on CMA-ES as an efficient\nevolutionary algorithm and proposes an optimization method termed safe CMA-ES.\nThe safe CMA-ES is designed to achieve both safety and efficiency in safe\noptimization. The safe CMA-ES estimates the Lipschitz constants of safety\nfunctions transformed with the distribution parameters using the maximum norm\nof the gradient in Gaussian process regression. Subsequently, the safe CMA-ES\nprojects the samples to the nearest point in the safe region constructed with\nthe estimated Lipschitz constants. The numerical simulation using the benchmark\nfunctions shows that the safe CMA-ES successfully performs optimization,\nsuppressing the unsafe evaluations, while the existing methods struggle to\nsignificantly reduce the unsafe evaluations.",
        "subjects": [
            "cs.NE"
        ],
        "authors": [
            "Kento Uchida",
            "Ryoki Hamano",
            "Masahiro Nomura",
            "Shota Saito",
            "Shinichi Shirakawa"
        ],
        "published": "2024-05-17T04:24:56Z"
    },
    {
        "title": "Nonparametric Teaching of Implicit Neural Representations",
        "link": "http://arxiv.org/abs/2405.10531v1",
        "abstract": "We investigate the learning of implicit neural representation (INR) using an\noverparameterized multilayer perceptron (MLP) via a novel nonparametric\nteaching perspective. The latter offers an efficient example selection\nframework for teaching nonparametrically defined (viz. non-closed-form) target\nfunctions, such as image functions defined by 2D grids of pixels. To address\nthe costly training of INRs, we propose a paradigm called Implicit Neural\nTeaching (INT) that treats INR learning as a nonparametric teaching problem,\nwhere the given signal being fitted serves as the target function. The teacher\nthen selects signal fragments for iterative training of the MLP to achieve fast\nconvergence. By establishing a connection between MLP evolution through\nparameter-based gradient descent and that of function evolution through\nfunctional gradient descent in nonparametric teaching, we show for the first\ntime that teaching an overparameterized MLP is consistent with teaching a\nnonparametric learner. This new discovery readily permits a convenient drop-in\nof nonparametric teaching algorithms to broadly enhance INR training\nefficiency, demonstrating 30%+ training time savings across various input\nmodalities.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Chen Zhang",
            "Steven Tin Sui Luo",
            "Jason Chun Lok Li",
            "Yik-Chung Wu",
            "Ngai Wong"
        ],
        "published": "2024-05-17T04:20:39Z"
    },
    {
        "title": "CM-UNet: Hybrid CNN-Mamba UNet for Remote Sensing Image Semantic\n  Segmentation",
        "link": "http://arxiv.org/abs/2405.10530v1",
        "abstract": "Due to the large-scale image size and object variations, current CNN-based\nand Transformer-based approaches for remote sensing image semantic segmentation\nare suboptimal for capturing the long-range dependency or limited to the\ncomplex computational complexity. In this paper, we propose CM-UNet, comprising\na CNN-based encoder for extracting local image features and a Mamba-based\ndecoder for aggregating and integrating global information, facilitating\nefficient semantic segmentation of remote sensing images. Specifically, a\nCSMamba block is introduced to build the core segmentation decoder, which\nemploys channel and spatial attention as the gate activation condition of the\nvanilla Mamba to enhance the feature interaction and global-local information\nfusion. Moreover, to further refine the output features from the CNN encoder, a\nMulti-Scale Attention Aggregation (MSAA) module is employed to merge the\ndifferent scale features. By integrating the CSMamba block and MSAA module,\nCM-UNet effectively captures the long-range dependencies and multi-scale global\ncontextual information of large-scale remote-sensing images. Experimental\nresults obtained on three benchmarks indicate that the proposed CM-UNet\noutperforms existing methods in various performance metrics. The codes are\navailable at https://github.com/XiaoBuL/CM-UNet.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Mushui Liu",
            "Jun Dan",
            "Ziqian Lu",
            "Yunlong Yu",
            "Yingming Li",
            "Xi Li"
        ],
        "published": "2024-05-17T04:20:12Z"
    },
    {
        "title": "Safeguarding Vision-Language Models Against Patched Visual Prompt\n  Injectors",
        "link": "http://arxiv.org/abs/2405.10529v1",
        "abstract": "Large language models have become increasingly prominent, also signaling a\nshift towards multimodality as the next frontier in artificial intelligence,\nwhere their embeddings are harnessed as prompts to generate textual content.\nVision-language models (VLMs) stand at the forefront of this advancement,\noffering innovative ways to combine visual and textual data for enhanced\nunderstanding and interaction. However, this integration also enlarges the\nattack surface. Patch-based adversarial attack is considered the most realistic\nthreat model in physical vision applications, as demonstrated in many existing\nliterature. In this paper, we propose to address patched visual prompt\ninjection, where adversaries exploit adversarial patches to generate target\ncontent in VLMs. Our investigation reveals that patched adversarial prompts\nexhibit sensitivity to pixel-wise randomization, a trait that remains robust\neven against adaptive attacks designed to counteract such defenses. Leveraging\nthis insight, we introduce SmoothVLM, a defense mechanism rooted in smoothing\ntechniques, specifically tailored to protect VLMs from the threat of patched\nvisual prompt injectors. Our framework significantly lowers the attack success\nrate to a range between 0% and 5.0% on two leading VLMs, while achieving around\n67.3% to 95.0% context recovery of the benign images, demonstrating a balance\nbetween security and usability.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "I.2.7; I.4"
        ],
        "authors": [
            "Jiachen Sun",
            "Changsheng Wang",
            "Jiongxiao Wang",
            "Yiwei Zhang",
            "Chaowei Xiao"
        ],
        "published": "2024-05-17T04:19:19Z"
    },
    {
        "title": "Guidelines for evaluation of complex multi agent test scenarios",
        "link": "http://arxiv.org/abs/2405.10526v1",
        "abstract": "To support the testing of AVs, CETRAN has created a guideline for the\nevaluation of complex multi agent test scenarios presented in this report. This\nallows for a clear structured manner in evaluating complexity elements based on\nthe corresponding difficulties an AV might encounter in Singapore traffic. This\nstudy aims to understand the source of complexity for AVs from traffic hazard,\nby breaking down the difficulties on AV capabilities as perception, situation\nawareness and decision-making. Guidelines created through this study are\ncomposed by a list of elements to be considered in the future as selection\ncriteria to evaluate complexity of scenarios to support AV behaviour\nassessment. This study is intended to be a guide to understand the sources of\ncomplexity for Avs and can be used to challenge the risk management ability of\nautonomous vehicles in a scenario-based test approach or traffic situations\nfaced on road trials.\n  The report includes the usage of the guidelines created as application to\nevaluate the complexity of a set of 5 real events that occur on Singapore roads\nfrom Resembler webtool which is a database of real human accidents/incidents.\nFour scenarios were also designed for creation in simulation by the CETRAN\nteam, applying the guidelines for complexity elements created in this work, to\nillustrate the difficulties an ADS could experience with such scenarios.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Ana Isabel Garcia Guerra",
            "Teng Sung Shiuan"
        ],
        "published": "2024-05-17T04:08:49Z"
    },
    {
        "title": "Smart Expert System: Large Language Models as Text Classifiers",
        "link": "http://arxiv.org/abs/2405.10523v1",
        "abstract": "Text classification is a fundamental task in Natural Language Processing\n(NLP), and the advent of Large Language Models (LLMs) has revolutionized the\nfield. This paper introduces the Smart Expert System, a novel approach that\nleverages LLMs as text classifiers. The system simplifies the traditional text\nclassification workflow, eliminating the need for extensive preprocessing and\ndomain expertise. The performance of several LLMs, machine learning (ML)\nalgorithms, and neural network (NN) based structures is evaluated on four\ndatasets. Results demonstrate that certain LLMs surpass traditional methods in\nsentiment analysis, spam SMS detection and multi-label classification.\nFurthermore, it is shown that the system's performance can be further enhanced\nthrough few-shot or fine-tuning strategies, making the fine-tuned model the top\nperformer across all datasets. Source code and datasets are available in this\nGitHub repository: https://github.com/yeyimilk/llm-zero-shot-classifiers.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Zhiqiang Wang",
            "Yiran Pang",
            "Yanbin Lin"
        ],
        "published": "2024-05-17T04:05:05Z"
    },
    {
        "title": "Generative AI for Secure and Privacy-Preserving Mobile Crowdsensing",
        "link": "http://arxiv.org/abs/2405.10521v1",
        "abstract": "Recently, generative AI has attracted much attention from both academic and\nindustrial fields, which has shown its potential, especially in the data\ngeneration and synthesis aspects. Simultaneously, secure and privacy-preserving\nmobile crowdsensing (SPPMCS) has been widely applied in data collection/\nacquirement due to an advantage on low deployment cost, flexible\nimplementation, and high adaptability. Since generative AI can generate new\nsynthetic data to replace the original data to be analyzed and processed, it\ncan lower data attacks and privacy leakage risks for the original data.\nTherefore, integrating generative AI into SPPMCS is feasible and significant.\nMoreover, this paper investigates an integration of generative AI in SPPMCS,\nwhere we present potential research focuses, solutions, and case studies.\nSpecifically, we firstly review the preliminaries for generative AI and SPPMCS,\nwhere their integration potential is presented. Then, we discuss research\nissues and solutions for generative AI-enabled SPPMCS, including security\ndefense of malicious data injection, illegal authorization, malicious spectrum\nmanipulation at the physical layer, and privacy protection on sensing data\ncontent, sensing terminals' identification and location. Next, we propose a\nframework for sensing data content protection with generative AI, and\nsimulations results have clearly demonstrated the effectiveness of the proposed\nframework. Finally, we present major research directions for generative\nAI-enabled SPPMCS.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Yaoqi Yang",
            "Bangning Zhang",
            "Daoxing Guo",
            "Hongyang Du",
            "Zehui Xiong",
            "Dusit Niyato",
            "Zhu Han"
        ],
        "published": "2024-05-17T04:00:58Z"
    },
    {
        "title": "Enhancing Perception Quality in Remote Sensing Image Compression via\n  Invertible Neural Network",
        "link": "http://arxiv.org/abs/2405.10518v1",
        "abstract": "Decoding remote sensing images to achieve high perceptual quality,\nparticularly at low bitrates, remains a significant challenge. To address this\nproblem, we propose the invertible neural network-based remote sensing image\ncompression (INN-RSIC) method. Specifically, we capture compression distortion\nfrom an existing image compression algorithm and encode it as a set of\nGaussian-distributed latent variables via INN. This ensures that the\ncompression distortion in the decoded image becomes independent of the ground\ntruth. Therefore, by leveraging the inverse mapping of INN, we can input the\ndecoded image along with a set of randomly resampled Gaussian distributed\nvariables into the inverse network, effectively generating enhanced images with\nbetter perception quality. To effectively learn compression distortion, channel\nexpansion, Haar transformation, and invertible blocks are employed to construct\nthe INN. Additionally, we introduce a quantization module (QM) to mitigate the\nimpact of format conversion, thus enhancing the framework's generalization and\nimproving the perceptual quality of enhanced images. Extensive experiments\ndemonstrate that our INN-RSIC significantly outperforms the existing\nstate-of-the-art traditional and deep learning-based image compression methods\nin terms of perception quality.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Junhui Li",
            "Xingsong Hou"
        ],
        "published": "2024-05-17T03:52:37Z"
    },
    {
        "title": "Towards Better Question Generation in QA-Based Event Extraction",
        "link": "http://arxiv.org/abs/2405.10517v1",
        "abstract": "Event Extraction (EE) is an essential information extraction task that aims\nto extract event-related information from unstructured texts. The paradigm of\nthis task has shifted from conventional classification-based methods to more\ncontemporary question-answering (QA)-based approaches. However, in QA-based EE,\nthe questions' quality dramatically affects the extraction accuracy, and how to\ngenerate high-quality questions for QA-based EE still remains a challenge. In\nthis work, to tackle this challenge, we suggest four criteria to evaluate the\nquality of a question and propose a reinforcement learning method for QA-Based\nEE that can generate fluent, generalizable, and context-dependent questions and\nprovides clear guidance to QA models. The extensive experiments conducted on\nACE and RAMS datasets have strongly validated our approach's effectiveness,\nwhich also demonstrates its robustness in scenarios with limited training data.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Zijin Hong",
            "Jian Liu"
        ],
        "published": "2024-05-17T03:52:01Z"
    },
    {
        "title": "Language Models can Evaluate Themselves via Probability Discrepancy",
        "link": "http://arxiv.org/abs/2405.10516v1",
        "abstract": "In this paper, we initiate our discussion by demonstrating how Large Language\nModels (LLMs), when tasked with responding to queries, display a more even\nprobability distribution in their answers if they are more adept, as opposed to\ntheir less skilled counterparts. Expanding on this foundational insight, we\npropose a new self-evaluation method ProbDiff for assessing the efficacy of\nvarious LLMs. This approach obviates the necessity for an additional evaluation\nmodel or the dependence on external, proprietary models like GPT-4 for\njudgment. It uniquely utilizes the LLMs being tested to compute the probability\ndiscrepancy between the initial response and its revised versions. A higher\ndiscrepancy for a given query between two LLMs indicates a relatively weaker\ncapability. Our findings reveal that ProbDiff achieves results on par with\nthose obtained from evaluations based on GPT-4, spanning a range of scenarios\nthat include natural language generation (NLG) tasks such as translation,\nsummarization, and our proposed Xiaohongshu blog writing task, and benchmarks\nfor LLM evaluation like AlignBench, MT-Bench, and AlpacaEval, across LLMs of\nvarying magnitudes.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Tingyu Xia",
            "Bowen Yu",
            "Yuan Wu",
            "Yi Chang",
            "Chang Zhou"
        ],
        "published": "2024-05-17T03:50:28Z"
    },
    {
        "title": "Improved AdaBoost for Virtual Reality Experience Prediction Based on\n  Long Short-Term Memory Network",
        "link": "http://arxiv.org/abs/2405.10515v1",
        "abstract": "A classification prediction algorithm based on Long Short-Term Memory Network\n(LSTM) improved AdaBoost is used to predict virtual reality (VR) user\nexperience. The dataset is randomly divided into training and test sets in the\nratio of 7:3.During the training process, the model's loss value decreases from\n0.65 to 0.31, which shows that the model gradually reduces the discrepancy\nbetween the prediction results and the actual labels, and improves the accuracy\nand generalisation ability.The final loss value of 0.31 indicates that the\nmodel fits the training data well, and is able to make predictions and\nclassifications more accurately. The confusion matrix for the training set\nshows a total of 177 correct predictions and 52 incorrect predictions, with an\naccuracy of 77%, precision of 88%, recall of 77% and f1 score of 82%. The\nconfusion matrix for the test set shows a total of 167 correct and 53 incorrect\npredictions with 75% accuracy, 87% precision, 57% recall and 69% f1 score. In\nsummary, the classification prediction algorithm based on LSTM with improved\nAdaBoost shows good prediction ability for virtual reality user experience.\nThis study is of great significance to enhance the application of virtual\nreality technology in user experience. By combining LSTM and AdaBoost\nalgorithms, significant progress has been made in user experience prediction,\nwhich not only improves the accuracy and generalisation ability of the model,\nbut also provides useful insights for related research in the field of virtual\nreality. This approach can help developers better understand user requirements,\noptimise virtual reality product design, and enhance user satisfaction,\npromoting the wide application of virtual reality technology in various fields.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Wenhan Fan",
            "Zhicheng Ding",
            "Ruixin Huang",
            "Chang Zhou",
            "Xuyang Zhang"
        ],
        "published": "2024-05-17T03:47:30Z"
    },
    {
        "title": "Secrecy Performance Analysis of Multi-Functional RIS-Assisted NOMA\n  Networks",
        "link": "http://arxiv.org/abs/2405.10514v1",
        "abstract": "Although reconfigurable intelligent surface (RIS) can improve the secrecy\ncommunication performance of wireless users, it still faces challenges such as\nlimited coverage and double-fading effect. To address these issues, in this\npaper, we utilize a novel multi-functional RIS (MF-RIS) to enhance the secrecy\nperformance of wireless users, and investigate the physical layer secrecy\nproblem in non-orthogonal multiple access (NOMA) networks. Specifically, we\nderive closed-form expressions for the secrecy outage probability (SOP) and\nsecrecy throughput of users in the MF-RIS-assisted NOMA networks with external\nand internal eavesdroppers. The asymptotic expressions for SOP and secrecy\ndiversity order are also analyzed under high signal-to-noise ratio (SNR)\nconditions. Additionally, we examine the impact of receiver hardware\nlimitations and error transmission-induced imperfect successive interference\ncancellation (SIC) on the secrecy performance. Numerical results indicate that:\ni) under the same power budget, the secrecy performance achieved by MF-RIS\nsignificantly outperforms active RIS and simultaneously transmitting and\nreflecting RIS; ii) with increasing power budget, residual interference caused\nby imperfect SIC surpasses thermal noise as the primary factor affecting\nsecrecy capacity; and iii) deploying additional elements at the MF-RIS brings\nsignificant secrecy enhancements for the external eavesdropping scenario, in\ncontrast to the internal eavesdropping case.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Yingjie Pei",
            "Wanli Ni",
            "Jin Xu",
            "Xinwei Yue",
            "Xiaofeng Tao",
            "Dusit Niyato"
        ],
        "published": "2024-05-17T03:43:07Z"
    },
    {
        "title": "Federated Learning With Energy Harvesting Devices: An MDP Framework",
        "link": "http://arxiv.org/abs/2405.10513v1",
        "abstract": "Federated learning (FL) requires edge devices to perform local training and\nexchange information with a parameter server, leading to substantial energy\nconsumption. A critical challenge in practical FL systems is the rapid energy\ndepletion of battery-limited edge devices, which curtails their operational\nlifespan and affects the learning performance. To address this issue, we apply\nenergy harvesting technique in FL systems to extract ambient energy for\ncontinuously powering edge devices. We first establish the convergence bound\nfor the wireless FL system with energy harvesting devices, illustrating that\nthe convergence is impacted by partial device participation and packet drops,\nboth of which depend on the energy supply. To accelerate the convergence, we\nformulate a joint device scheduling and power control problem and model it as a\nMarkov decision process (MDP). By solving this MDP, we derive the optimal\ntransmission policy and demonstrate that it possesses a monotone structure with\nrespect to the battery and channel states. To overcome the curse of\ndimensionality caused by the exponential complexity of computing the optimal\npolicy, we propose a low-complexity algorithm, which is asymptotically optimal\nas the number of devices increases. Furthermore, for unknown channels and\nharvested energy statistics, we develop a structure-enhanced deep reinforcement\nlearning algorithm that leverages the monotone structure of the optimal policy\nto improve the training performance. Finally, extensive numerical experiments\non real-world datasets are presented to validate the theoretical results and\ncorroborate the effectiveness of the proposed algorithms.",
        "subjects": [
            "cs.LG",
            "eess.SP"
        ],
        "authors": [
            "Kai Zhang",
            "Xuanyu Cao"
        ],
        "published": "2024-05-17T03:41:40Z"
    },
    {
        "title": "In-context Contrastive Learning for Event Causality Identification",
        "link": "http://arxiv.org/abs/2405.10512v1",
        "abstract": "Event Causality Identification (ECI) aims at determining the existence of a\ncausal relation between two events. Although recent prompt learning-based\napproaches have shown promising improvements on the ECI task, their performance\nare often subject to the delicate design of multiple prompts and the positive\ncorrelations between the main task and derivate tasks. The in-context learning\nparadigm provides explicit guidance for label prediction in the prompt learning\nparadigm, alleviating its reliance on complex prompts and derivative tasks.\nHowever, it does not distinguish between positive and negative demonstrations\nfor analogy learning. Motivated from such considerations, this paper proposes\nan In-Context Contrastive Learning (ICCL) model that utilizes contrastive\nlearning to enhance the effectiveness of both positive and negative\ndemonstrations. Additionally, we apply contrastive learning to event pairs to\nbetter facilitate event causality identification. Our ICCL is evaluated on the\nwidely used corpora, including the EventStoryLine and Causal-TimeBank, and\nresults show significant performance improvements over the state-of-the-art\nalgorithms.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "authors": [
            "Chao Liang",
            "Wei Xiang",
            "Bang Wang"
        ],
        "published": "2024-05-17T03:32:15Z"
    },
    {
        "title": "Defect Category Prediction Based on Multi-Source Domain Adaptation",
        "link": "http://dx.doi.org/10.13328/j.cnki.jos.007109",
        "abstract": "In recent years, defect prediction techniques based on deep learning have\nbecome a prominent research topic in the field of software engineering. These\ntechniques can identify potential defects without executing the code. However,\nexisting approaches mostly concentrate on determining the presence of defects\nat the method-level code, lacking the ability to precisely classify specific\ndefect categories. Consequently, this undermines the efficiency of developers\nin locating and rectifying defects. Furthermore, in practical software\ndevelopment, new projects often lack sufficient defect data to train\nhigh-accuracy deep learning models. Models trained on historical data from\nexisting projects frequently struggle to achieve satisfactory generalization\nperformance on new projects. Hence, this paper initially reformulates the\ntraditional binary defect prediction task into a multi-label classification\nproblem, employing defect categories described in the Common Weakness\nEnumeration (CWE) as fine-grained predictive labels. To enhance the model\nperformance in cross-project scenarios, this paper proposes a multi-source\ndomain adaptation framework that integrates adversarial training and attention\nmechanisms. Specifically, the proposed framework employs adversarial training\nto mitigate domain (i.e., software projects) discrepancies, and further\nutilizes domain-invariant features to capture feature correlations between each\nsource domain and the target domain. Simultaneously, the proposed framework\nemploys a weighted maximum mean discrepancy as an attention mechanism to\nminimize the representation distance between source and target domain features,\nfacilitating model in learning more domain-independent features. The\nexperiments on 8 real-world open-source projects show that the proposed\napproach achieves significant performance improvements compared to\nstate-of-the-art baselines.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Ying Xing",
            "Mengci Zhao",
            "Bin Yang",
            "Yuwei Zhang",
            "Wenjin Li",
            "Jiawei Gu",
            "Jun Yuan"
        ],
        "published": "2024-05-17T03:30:31Z"
    },
    {
        "title": "ART3D: 3D Gaussian Splatting for Text-Guided Artistic Scenes Generation",
        "link": "http://arxiv.org/abs/2405.10508v1",
        "abstract": "In this paper, we explore the existing challenges in 3D artistic scene\ngeneration by introducing ART3D, a novel framework that combines diffusion\nmodels and 3D Gaussian splatting techniques. Our method effectively bridges the\ngap between artistic and realistic images through an innovative image semantic\ntransfer algorithm. By leveraging depth information and an initial artistic\nimage, we generate a point cloud map, addressing domain differences.\nAdditionally, we propose a depth consistency module to enhance 3D scene\nconsistency. Finally, the 3D scene serves as initial points for optimizing\nGaussian splats. Experimental results demonstrate ART3D's superior performance\nin both content and structural consistency metrics when compared to existing\nmethods. ART3D significantly advances the field of AI in art creation by\nproviding an innovative solution for generating high-quality 3D artistic\nscenes.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Pengzhi Li",
            "Chengshuai Tang",
            "Qinxuan Huang",
            "Zhiheng Li"
        ],
        "published": "2024-05-17T03:19:36Z"
    },
    {
        "title": "Lock-Free Augmented Trees",
        "link": "http://arxiv.org/abs/2405.10506v1",
        "abstract": "Augmenting an existing sequential data structure with extra information to\nsupport greater functionality is a widely used technique. For example, search\ntrees are augmented to build sequential data structures like order-statistic\ntrees, interval trees, tango trees, link/cut trees and many others.\n  We study how to design concurrent augmented tree data structures. We present\na new, general technique that can augment a lock-free tree to add any new\nfields to each tree node, provided the new fields' values can be computed from\ninformation in the node and its children. This enables the design of lock-free,\nlinearizable analogues of a wide variety of classical augmented data\nstructures. As a first example, we give a wait-free trie that stores a set $S$\nof elements drawn from $\\{1,\\ldots,N\\}$ and supports linearizable\norder-statistic queries such as finding the $k$th smallest element of $S$.\nUpdates and queries take $O(\\log N)$ steps. We also apply our technique to a\nlock-free binary search tree (BST), where changes to the structure of the tree\nmake the linearization argument more challenging. Our augmented BST supports\norder statistic queries in $O(h)$ steps on a tree of height $h$. The\naugmentation does not affect the asymptotic running time of the updates.\n  For both our trie and BST, we give an alternative augmentation to improve\nsearches and order-statistic queries to run in $O(\\log |S|)$ steps (with a\nsmall increase in step complexity of updates). As an added bonus, our technique\nsupports arbitrary multi-point queries (such as range queries) with the same\ntime complexity as they would have in the corresponding sequential data\nstructure.",
        "subjects": [
            "cs.DS",
            "cs.DC"
        ],
        "authors": [
            "Panagiota Fatourou",
            "Eric Ruppert"
        ],
        "published": "2024-05-17T03:17:32Z"
    },
    {
        "title": "Local Time-Stepping for the Shallow Water Equations using CFL Optimized\n  Forward-Backward Runge-Kutta Schemes",
        "link": "http://arxiv.org/abs/2405.10505v1",
        "abstract": "The Courant-Friedrichs-Lewy (CFL) condition is a well known, necessary\ncondition for the stability of explicit time-stepping schemes that effectively\nplaces a limit on the size of the largest admittable time-step for a given\nproblem. We formulate and present a new local time-stepping (LTS) scheme\noptimized, in the CFL sense, for the shallow water equations (SWEs). This new\nscheme, called FB-LTS, is based on the CFL optimized forward-backward\nRunge-Kutta schemes from Lilly et al. (2023). We show that FB-LTS maintains\nexact conservation of mass and absolute vorticity when applied to the TRiSK\nspatial discretization (Ringler et al., 2010), and provide numerical\nexperiments showing that it retains the temporal order of the scheme on which\nit is based (second order). In terms of computational performance, we show that\nwhen applied to a real-world test case on a highly-variable resolution mesh,\nthe MPAS-Ocean implementation of FB-LTS is up to 10 times faster than the\nclassical four-stage, fourth-order Runge-Kutta method (RK4), and 2.3 times\nfaster than an existing strong stability preserving Runge-Kutta based LTS\nscheme (LTS3). Despite this significant increase in efficiency, the solutions\nproduced by FB-LTS are qualitatively equivalent to those produced by both RK4\nand LTS3.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "physics.comp-ph"
        ],
        "authors": [
            "Jeremy R. Lilly",
            "Giacomo Capodaglio",
            "Darren Engwirda",
            "Robert L. Higdon",
            "Mark R. Petersen"
        ],
        "published": "2024-05-17T03:09:59Z"
    },
    {
        "title": "Multi-scale Semantic Prior Features Guided Deep Neural Network for Urban\n  Street-view Image",
        "link": "http://arxiv.org/abs/2405.10504v1",
        "abstract": "Street-view image has been widely applied as a crucial mobile mapping data\nsource. The inpainting of street-view images is a critical step for street-view\nimage processing, not only for the privacy protection, but also for the urban\nenvironment mapping applications. This paper presents a novel Deep Neural\nNetwork (DNN), multi-scale semantic prior Feature guided image inpainting\nNetwork (MFN) for inpainting street-view images, which generate static\nstreet-view images without moving objects (e.g., pedestrians, vehicles). To\nenhance global context understanding, a semantic prior prompter is introduced\nto learn rich semantic priors from large pre-trained model. We design the\nprompter by stacking multiple Semantic Pyramid Aggregation (SPA) modules,\ncapturing a broad range of visual feature patterns. A semantic-enhanced image\ngenerator with a decoder is proposed that incorporates a novel cascaded\nLearnable Prior Transferring (LPT) module at each scale level. For each decoder\nblock, an attention transfer mechanism is applied to capture long-term\ndependencies, and the semantic prior features are fused with the image features\nto restore plausible structure in an adaptive manner. Additionally, a\nbackground-aware data processing scheme is adopted to prevent the generation of\nhallucinated objects within holes. Experiments on Apolloscapes and Cityscapes\ndatasets demonstrate better performance than state-of-the-art methods, with\nMAE, and LPIPS showing improvements of about 9.5% and 41.07% respectively.\nVisual comparison survey among multi-group person is also conducted to provide\nperformance evaluation, and the results suggest that the proposed MFN offers a\npromising solution for privacy protection and generate more reliable scene for\nurban applications with street-view images.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jianshun Zeng",
            "Wang Li",
            "Yanjie Lv",
            "Shuai Gao",
            "YuChu Qin"
        ],
        "published": "2024-05-17T03:02:18Z"
    },
    {
        "title": "Large Language Models in Wireless Application Design: In-Context\n  Learning-enhanced Automatic Network Intrusion Detection",
        "link": "http://arxiv.org/abs/2405.11002v1",
        "abstract": "Large language models (LLMs), especially generative pre-trained transformers\n(GPTs), have recently demonstrated outstanding ability in information\ncomprehension and problem-solving. This has motivated many studies in applying\nLLMs to wireless communication networks. In this paper, we propose a\npre-trained LLM-empowered framework to perform fully automatic network\nintrusion detection. Three in-context learning methods are designed and\ncompared to enhance the performance of LLMs. With experiments on a real network\nintrusion detection dataset, in-context learning proves to be highly beneficial\nin improving the task processing performance in a way that no further training\nor fine-tuning of LLMs is required. We show that for GPT-4, testing accuracy\nand F1-Score can be improved by 90%. Moreover, pre-trained LLMs demonstrate big\npotential in performing wireless communication-related tasks. Specifically, the\nproposed framework can reach an accuracy and F1-Score of over 95% on different\ntypes of attacks with GPT-4 using only 10 in-context learning examples.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "authors": [
            "Han Zhang",
            "Akram Bin Sediq",
            "Ali Afana",
            "Melike Erol-Kantarci"
        ],
        "published": "2024-05-17T02:56:31Z"
    },
    {
        "title": "Enhancing DMI Interactions by Integrating Haptic Feedback for Intricate\n  Vibrato Technique",
        "link": "http://arxiv.org/abs/2405.10502v1",
        "abstract": "This paper investigates the integration of force feedback in Digital Musical\nInstruments (DMI), specifically evaluating the reproduction of intricate\nvibrato techniques using haptic feedback controllers. We introduce our system\nfor vibrato modulation using force feedback, composed of Bend-aid (a web-based\nsequencer platform using pre-designed haptic feedback models) and TorqueTuner\n(an open-source 1 Degree-of-Freedom (DoF) rotary haptic device for generating\nprogrammable haptic effects). We designed a formal user study to assess the\nimpact of each haptic mode on user experience in a vibrato mimicry task. Twenty\nmusically trained participants rated their user experience for the three haptic\nmodes (Smooth, Detent, and Spring) using four Likert-scale scores: comfort,\nflexibility, ease of control, and helpfulness for the task. Finally, we asked\nparticipants to share their reflections. Our research indicates that while the\nSpring mode can help with light vibrato, preferences for haptic modes vary\nbased on musical training background. This emphasizes the need for adaptable\ntask interfaces and flexible haptic feedback in DMI design.",
        "subjects": [
            "cs.HC",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Ziyue Piao",
            "Christian Frisson",
            "Bavo Van Kerrebroeck",
            "Marcelo M. Wanderley"
        ],
        "published": "2024-05-17T02:54:44Z"
    },
    {
        "title": "Predictive Monitoring with Strong Trace Prefixes",
        "link": "http://arxiv.org/abs/2405.10499v1",
        "abstract": "Runtime predictive analyses enhance coverage of traditional dynamic analyses\nbased bug detection techniques by identifying a space of feasible reorderings\nof the observed execution and determining if any of these witnesses the\nviolation of some desired safety property. The most popular approach for\nmodelling the space of feasible reorderings is through Mazurkiewicz's trace\nequivalence. The simplicity of the framework also gives rise to efficient\npredictive analyses, and has been the de facto means for obtaining space and\ntime efficient algorithms for monitoring concurrent programs. In this work, we\ninvestigate how to enhance the predictive power of trace-based reasoning, while\nstill retaining the algorithmic benefits it offers. Towards this, we extend\ntrace theory by naturally embedding a class of prefixes, which we call strong\ntrace prefixes. We formally characterize strong trace prefixes using an\nenhanced dependence relation, study its predictive power and establish a tight\nconnection to the previously proposed notion of synchronization preserving\ncorrect reorderings developed in the context of data race and deadlock\nprediction. We then show that despite the enhanced predictive power, strong\ntrace prefixes continue to enjoy the algorithmic benefits of Mazurkiewicz\ntraces in the context of prediction against co-safety properties, and derive\nnew algorithms for synchronization preserving data races and deadlocks with\nbetter asymptotic space and time usage. We also show that strong trace prefixes\ncan capture more violations of pattern languages. We implement our proposed\nalgorithms and our evaluation confirms the practical utility of reasoning based\non strong prefix traces.",
        "subjects": [
            "cs.PL"
        ],
        "authors": [
            "Zhendong Ang",
            "Umang Mathur"
        ],
        "published": "2024-05-17T02:43:21Z"
    },
    {
        "title": "SMP Challenge: An Overview and Analysis of Social Media Prediction\n  Challenge",
        "link": "http://arxiv.org/abs/2405.10497v1",
        "abstract": "Social Media Popularity Prediction (SMPP) is a crucial task that involves\nautomatically predicting future popularity values of online posts, leveraging\nvast amounts of multimodal data available on social media platforms. Studying\nand investigating social media popularity becomes central to various online\napplications and requires novel methods of comprehensive analysis, multimodal\ncomprehension, and accurate prediction.\n  SMP Challenge is an annual research activity that has spurred academic\nexploration in this area. This paper summarizes the challenging task, data, and\nresearch progress. As a critical resource for evaluating and benchmarking\npredictive models, we have released a large-scale SMPD benchmark encompassing\napproximately half a million posts authored by around 70K users. The research\nprogress analysis provides an overall analysis of the solutions and trends in\nrecent years. The SMP Challenge website (www.smp-challenge.com) provides the\nlatest information and news.",
        "subjects": [
            "cs.MM",
            "cs.AI",
            "cs.CV",
            "cs.SI"
        ],
        "authors": [
            "Bo Wu",
            "Peiye Liu",
            "Wen-Huang Cheng",
            "Bei Liu",
            "Zhaoyang Zeng",
            "Jia Wang",
            "Qiushi Huang",
            "Jiebo Luo"
        ],
        "published": "2024-05-17T02:36:14Z"
    },
    {
        "title": "Using physics-based simulation towards eliminating empiricism in\n  extraterrestrial terramechanics applications",
        "link": "http://arxiv.org/abs/2405.11001v1",
        "abstract": "Recently, there has been a surge of international interest in\nextraterrestrial exploration targeting the Moon, Mars, the moons of Mars, and\nvarious asteroids. This contribution discusses how current state-of-the-art\nEarth-based testing for designing rovers and landers for these missions\ncurrently leads to overly optimistic conclusions about the behavior of these\ndevices upon deployment on the targeted celestial bodies. The key misconception\nis that gravitational offset is necessary during the \\textit{terramechanics}\ntesting of rover and lander prototypes on Earth. The body of evidence\nsupporting our argument is tied to a small number of studies conducted during\nparabolic flights and insights derived from newly revised scaling laws. We\nargue that what has prevented the community from fully diagnosing the problem\nat hand is the absence of effective physics-based models capable of simulating\nterramechanics under low gravity conditions. We developed such a physics-based\nsimulator and utilized it to gauge the mobility of early prototypes of the\nVolatiles Investigating Polar Exploration Rover (VIPER), which is slated to\ndepart for the Moon in November 2024. This contribution discusses the results\ngenerated by this simulator, how they correlate with physical test results from\nthe NASA-Glenn SLOPE lab, and the fallacy of the gravitational offset in rover\nand lander testing. The simulator developed is open sourced and made publicly\navailable for unfettered use; it can support principled studies that extend\nbeyond trafficability analysis to provide insights into in-situ resource\nutilization activities, e.g., digging, bulldozing, and berming in low gravity.",
        "subjects": [
            "astro-ph.IM",
            "astro-ph.EP",
            "cs.RO"
        ],
        "authors": [
            "Wei Hu",
            "Pei Li",
            "Arno Rogg",
            "Alexander Schepelmann",
            "Colin Creager",
            "Samuel Chandler",
            "Ken Kamrin",
            "Dan Negrut"
        ],
        "published": "2024-05-17T02:33:45Z"
    },
    {
        "title": "Electromagnetic Information Theory for Holographic MIMO Communications",
        "link": "http://arxiv.org/abs/2405.10496v2",
        "abstract": "Holographic multiple-input multiple-output (HMIMO) utilizes a compact antenna\narray to form a nearly continuous aperture, thereby enhancing higher capacity\nand more flexible configurations compared with conventional MIMO systems,\nmaking it attractive in current scientific research. Key questions naturally\narise regarding the potential of HMIMO to surpass Shannon's theoretical limits\nand how far its capabilities can be extended. However, the traditional Shannon\ninformation theory falls short in addressing these inquiries because it only\nfocuses on the information itself while neglecting the underlying carrier,\nelectromagnetic (EM) waves, and environmental interactions. To fill up the gap\nbetween the theoretical analysis and the practical application for HMIMO\nsystems, we introduce electromagnetic information theory (EIT) in this paper.\nThis paper begins by laying the foundation for HMIMO-oriented EIT, encompassing\nEM wave equations and communication regions. In the context of HMIMO systems,\nthe resultant physical limitations are presented, involving Chu's limit,\nHarrington's limit, Hannan's limit, and the evaluation of coupling effects.\nField sampling and HMIMO-assisted oversampling are also discussed to guide the\noptimal HMIMO design within the EIT framework. To comprehensively depict the\nEM-compliant propagation process, we present the approximate and exact channel\nmodeling approaches in near-/far-field zones. Furthermore, we discuss both\ntraditional Shannon's information theory, employing the probabilistic method,\nand Kolmogorov information theory, utilizing the functional analysis, for\nHMIMO-oriented EIT systems.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Li Wei",
            "Tierui Gong",
            "Chongwen Huang",
            "Zhaoyang Zhang",
            "Wei E. I. Sha",
            "Zhi Ning Chen",
            "Linglong Dai",
            "Merouane Debbah",
            "Chau Yuen"
        ],
        "published": "2024-05-17T02:33:28Z"
    },
    {
        "title": "Automatic News Generation and Fact-Checking System Based on Language\n  Processing",
        "link": "http://arxiv.org/abs/2405.10492v2",
        "abstract": "This paper explores an automatic news generation and fact-checking system\nbased on language processing, aimed at enhancing the efficiency and quality of\nnews production while ensuring the authenticity and reliability of the news\ncontent. With the rapid development of Natural Language Processing (NLP) and\ndeep learning technologies, automatic news generation systems are capable of\nextracting key information from massive data and generating well-structured,\nfluent news articles. Meanwhile, by integrating fact-checking technology, the\nsystem can effectively prevent the spread of false news and improve the\naccuracy and credibility of news. This study details the key technologies\ninvolved in automatic news generation and factchecking, including text\ngeneration, information extraction, and the application of knowledge graphs,\nand validates the effectiveness of these technologies through experiments.\nAdditionally, the paper discusses the future development directions of\nautomatic news generation and fact-checking systems, emphasizing the importance\nof further integration and innovation of technologies. The results show that\nwith continuous technological optimization and practical application, these\nsystems will play an increasingly important role in the future news industry,\nproviding more efficient and reliable news services.",
        "subjects": [
            "cs.CL",
            "cs.LG",
            "I.5; H.4"
        ],
        "authors": [
            "Xirui Peng",
            "Qiming Xu",
            "Zheng Feng",
            "Haopeng Zhao",
            "Lianghao Tan",
            "Yan Zhou",
            "Zecheng Zhang",
            "Chenwei Gong",
            "Yingqiao Zheng"
        ],
        "published": "2024-05-17T01:58:23Z"
    },
    {
        "title": "Neural Optimization with Adaptive Heuristics for Intelligent Marketing\n  System",
        "link": "http://arxiv.org/abs/2405.10490v2",
        "abstract": "Computational marketing has become increasingly important in today's digital\nworld, facing challenges such as massive heterogeneous data, multi-channel\ncustomer journeys, and limited marketing budgets. In this paper, we propose a\ngeneral framework for marketing AI systems, the Neural Optimization with\nAdaptive Heuristics (NOAH) framework. NOAH is the first general framework for\nmarketing optimization that considers both to-business (2B) and to-consumer\n(2C) products, as well as both owned and paid channels. We describe key modules\nof the NOAH framework, including prediction, optimization, and adaptive\nheuristics, providing examples for bidding and content optimization. We then\ndetail the successful application of NOAH to LinkedIn's email marketing system,\nshowcasing significant wins over the legacy ranking system. Additionally, we\nshare details and insights that are broadly useful, particularly on: (i)\naddressing delayed feedback with lifetime value, (ii) performing large-scale\nlinear programming with randomization, (iii) improving retrieval with audience\nexpansion, (iv) reducing signal dilution in targeting tests, and (v) handling\nzero-inflated heavy-tail metrics in statistical testing.",
        "subjects": [
            "stat.ME",
            "cs.AI",
            "cs.IR",
            "cs.LG",
            "math.OC",
            "G.3; G.1.6; I.2"
        ],
        "authors": [
            "Changshuai Wei",
            "Benjamin Zelditch",
            "Joyce Chen",
            "Andre Assuncao Silva T Ribeiro",
            "Jingyi Kenneth Tay",
            "Borja Ocejo Elizondo",
            "Keerthi Selvaraj",
            "Aman Gupta",
            "Licurgo Benemann De Almeida"
        ],
        "published": "2024-05-17T01:44:30Z"
    },
    {
        "title": "MixCut:A Data Augmentation Method for Facial Expression Recognition",
        "link": "http://arxiv.org/abs/2405.10489v1",
        "abstract": "In the facial expression recognition task, researchers always get low\naccuracy of expression classification due to a small amount of training\nsamples. In order to solve this kind of problem, we proposes a new data\naugmentation method named MixCut. In this method, we firstly interpolate the\ntwo original training samples at the pixel level in a random ratio to generate\nnew samples. Then, pixel removal is performed in random square regions on the\nnew samples to generate the final training samples. We evaluated the MixCut\nmethod on Fer2013Plus and RAF-DB. With MixCut, we achieved 85.63% accuracy in\neight-label classification on Fer2013Plus and 87.88% accuracy in seven-label\nclassification on RAF-DB, effectively improving the classification accuracy of\nfacial expression image recognition. Meanwhile, on Fer2013Plus, MixCut achieved\nperformance improvements of +0.59%, +0.36%, and +0.39% compared to the other\nthree data augmentation methods: CutOut, Mixup, and CutMix, respectively.\nMixCut improves classification accuracy on RAF-DB by +0.22%, +0.65%, and +0.5%\nover these three data augmentation methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jiaxiang Yu",
            "Yiyang Liu",
            "Ruiyang Fan",
            "Guobing Sun"
        ],
        "published": "2024-05-17T01:36:33Z"
    },
    {
        "title": "CNER: A tool Classifier of Named-Entity Relationships",
        "link": "http://arxiv.org/abs/2405.10485v1",
        "abstract": "We introduce CNER, an ensemble of capable tools for extraction of semantic\nrelationships between named entities in Spanish language. Built upon a\ncontainer-based architecture, CNER integrates different Named entity\nrecognition and relation extraction tools with a user-friendly interface that\nallows users to input free text or files effortlessly, facilitating streamlined\nanalysis. Developed as a prototype version for the Natural Language Processing\n(NLP) Group at Universidad del Valle, CNER serves as a practical educational\nresource, illustrating how machine learning techniques can effectively tackle\ndiverse NLP tasks in Spanish. Our preliminary results reveal the promising\npotential of CNER in advancing the understanding and development of NLP tools,\nparticularly within Spanish-language contexts.",
        "subjects": [
            "cs.CL",
            "cs.HC"
        ],
        "authors": [
            "Jefferson A. Peña Torres",
            "Raúl E. Gutiérrez De Piñerez"
        ],
        "published": "2024-05-17T01:16:58Z"
    },
    {
        "title": "Multi-Evidence based Fact Verification via A Confidential Graph Neural\n  Network",
        "link": "http://arxiv.org/abs/2405.10481v1",
        "abstract": "Fact verification tasks aim to identify the integrity of textual contents\naccording to the truthful corpus. Existing fact verification models usually\nbuild a fully connected reasoning graph, which regards claim-evidence pairs as\nnodes and connects them with edges. They employ the graph to propagate the\nsemantics of the nodes. Nevertheless, the noisy nodes usually propagate their\nsemantics via the edges of the reasoning graph, which misleads the semantic\nrepresentations of other nodes and amplifies the noise signals. To mitigate the\npropagation of noisy semantic information, we introduce a Confidential Graph\nAttention Network (CO-GAT), which proposes a node masking mechanism for\nmodeling the nodes. Specifically, CO-GAT calculates the node confidence score\nby estimating the relevance between the claim and evidence pieces. Then, the\nnode masking mechanism uses the node confidence scores to control the noise\ninformation flow from the vanilla node to the other graph nodes. CO-GAT\nachieves a 73.59% FEVER score on the FEVER dataset and shows the generalization\nability by broadening the effectiveness to the science-specific domain.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Yuqing Lan",
            "Zhenghao Liu",
            "Yu Gu",
            "Xiaoyuan Yi",
            "Xiaohua Li",
            "Liner Yang",
            "Ge Yu"
        ],
        "published": "2024-05-17T01:02:03Z"
    },
    {
        "title": "Lean Attention: Hardware-Aware Scalable Attention Mechanism for the\n  Decode-Phase of Transformers",
        "link": "http://arxiv.org/abs/2405.10480v1",
        "abstract": "Transformer-based models have emerged as one of the most widely used\narchitectures for natural language processing, natural language generation, and\nimage generation. The size of the state-of-the-art models has increased\nsteadily reaching billions of parameters. These huge models are memory hungry\nand incur significant inference latency even on cutting edge AI-accelerators,\nsuch as GPUs. Specifically, the time and memory complexity of the attention\noperation is quadratic in terms of the total context length, i.e., prompt and\noutput tokens. Thus, several optimizations such as key-value tensor caching and\nFlashAttention computation have been proposed to deliver the low latency\ndemands of applications relying on such large models. However, these techniques\ndo not cater to the computationally distinct nature of different phases during\ninference.\n  To that end, we propose LeanAttention, a scalable technique of computing\nself-attention for the token-generation phase (decode-phase) of decoder-only\ntransformer models. LeanAttention enables scaling the attention mechanism\nimplementation for the challenging case of long context lengths by re-designing\nthe execution flow for the decode-phase. We identify that the associative\nproperty of online softmax can be treated as a reduction operation thus\nallowing us to parallelize the attention computation over these large context\nlengths. We extend the \"stream-K\" style reduction of tiled calculation to\nself-attention to enable parallel computation resulting in an average of 2.6x\nattention execution speedup over FlashAttention-2 and up to 8.33x speedup for\n512k context lengths.",
        "subjects": [
            "cs.AR",
            "cs.LG",
            "I.2.7; C.1.4"
        ],
        "authors": [
            "Rya Sanovar",
            "Srikant Bharadwaj",
            "Renee St. Amant",
            "Victor Rühle",
            "Saravan Rajmohan"
        ],
        "published": "2024-05-17T00:52:39Z"
    },
    {
        "title": "Convexification for a Coefficient Inverse Problem for a System of Two\n  Coupled Nonlinear Parabolic Equations",
        "link": "http://arxiv.org/abs/2405.10479v1",
        "abstract": "A system of two coupled nonlinear parabolic partial differential equations\nwith two opposite directions of time is considered. In fact, this is the\nso-called \"Mean Field Games System\" (MFGS), which is derived in the mean field\ngames (MFG) theory. This theory has numerous applications in social sciences.\nThe topic of Coefficient Inverse Problems (CIPs) in the MFG theory is in its\ninfant age, both in theory and computations. A numerical method for this CIP is\ndeveloped. Convergence analysis ensures the global convergence of this method.\nNumerical experiments are presented.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Michael V. Klibanov",
            "Jingzhi Li",
            "Zhipeng Yang"
        ],
        "published": "2024-05-17T00:41:46Z"
    },
    {
        "title": "GridapTopOpt.jl: A scalable Julia toolbox for level set-based topology\n  optimisation",
        "link": "http://arxiv.org/abs/2405.10478v1",
        "abstract": "In this paper we present GridapTopOpt, an extendable framework for level\nset-based topology optimisation that can be readily distributed across a\npersonal computer or high-performance computing cluster. The package is written\nin Julia and uses the Gridap package ecosystem for parallel finite element\nassembly from arbitrary weak formulations of partial differential equation\n(PDEs) along with the scalable solvers from the Portable and Extendable Toolkit\nfor Scientific Computing (PETSc). The resulting user interface is intuitive and\neasy-to-use, allowing for the implementation of a wide range of topology\noptimisation problems with a syntax that is near one-to-one with the\nmathematical notation. Furthermore, we implement automatic differentiation to\nhelp mitigate the bottleneck associated with the analytic derivation of\nsensitivities for complex problems. GridapTopOpt is capable of solving a range\nof benchmark and research topology optimisation problems with large numbers of\ndegrees of freedom. This educational article demonstrates the usability and\nversatility of the package by describing the formulation and step-by-step\nimplementation of several distinct topology optimisation problems. The driver\nscripts for these problems are provided and the package source code is\navailable at https://github$.$com/zjwegert/GridapTopOpt.jl.",
        "subjects": [
            "cs.MS"
        ],
        "authors": [
            "Zachary J. Wegert",
            "Jordi Manyer",
            "Connor Mallon",
            "Santiago Badia",
            "Vivien J. Challis"
        ],
        "published": "2024-05-17T00:36:26Z"
    },
    {
        "title": "Analysis, Modeling and Design of Personalized Digital Learning\n  Environment",
        "link": "http://arxiv.org/abs/2405.10476v1",
        "abstract": "This research analyzes, models and develops a novel Digital Learning\nEnvironment (DLE) fortified by the innovative Private Learning Intelligence\n(PLI) framework. The proposed PLI framework leverages federated machine\nlearning (FL) techniques to autonomously construct and continuously refine\npersonalized learning models for individual learners, ensuring robust privacy\nprotection. Our approach is pivotal in advancing DLE capabilities, empowering\nlearners to actively participate in personalized real-time learning\nexperiences. The integration of PLI within a DLE also streamlines instructional\ndesign and development demands for personalized teaching/learning. We seek ways\nto establish a foundation for the seamless integration of FL into learning\nsystems, offering a transformative approach to personalized learning in digital\nenvironments. Our implementation details and code are made public.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.SE"
        ],
        "authors": [
            "Sanjaya Khanal",
            "Shiva Raj Pokhrel"
        ],
        "published": "2024-05-17T00:26:16Z"
    },
    {
        "title": "Rethinking ChatGPT's Success: Usability and Cognitive Behaviors Enabled\n  by Auto-regressive LLMs' Prompting",
        "link": "http://arxiv.org/abs/2405.10474v1",
        "abstract": "Over the last decade, a wide range of training and deployment strategies for\nLarge Language Models (LLMs) have emerged. Among these, the prompting paradigms\nof Auto-regressive LLMs (AR-LLMs) have catalyzed a significant surge in\nArtificial Intelligence (AI). This paper aims to emphasize the significance of\nutilizing free-form modalities (forms of input and output) and verbal free-form\ncontexts as user-directed channels (methods for transforming modalities) for\ndownstream deployment. Specifically, we analyze the structure of modalities\nwithin both two types of LLMs and six task-specific channels during deployment.\nFrom the perspective of users, our analysis introduces and applies the\nanalytical metrics of task customizability, transparency, and complexity to\ngauge their usability, highlighting the superior nature of AR-LLMs' prompting\nparadigms. Moreover, we examine the stimulation of diverse cognitive behaviors\nin LLMs through the adoption of free-form text and verbal contexts, mirroring\nhuman linguistic expressions of such behaviors. We then detail four common\ncognitive behaviors to underscore how AR-LLMs' prompting successfully imitate\nhuman-like behaviors using this free-form modality and channel. Lastly, the\npotential for improving LLM deployment, both as autonomous agents and within\nmulti-agent systems, is identified via cognitive behavior concepts and\nprinciples.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Xinzhe Li",
            "Ming Liu"
        ],
        "published": "2024-05-17T00:19:41Z"
    },
    {
        "title": "Infrastructure Engineering: A Still Missing, Undervalued Role in the\n  Research Ecosystem",
        "link": "http://arxiv.org/abs/2405.10473v1",
        "abstract": "Research has become increasingly reliant on software, serving as the driving\nforce behind bioinformatics, high performance computing, physics, machine\nlearning and artificial intelligence, to name a few. While substantial progress\nhas been made in advocating for the research software engineer, a kind of\nsoftware engineer that typically works directly on software and associated\nassets that go into research, little attention has been placed on the workforce\nbehind research infrastructure and innovation, namely compilers and\ncompatibility tool development, orchestration and scheduling infrastructure,\ndeveloper environments, container technologies, and workflow managers. As\neconomic incentives are moving toward different models of cloud computing and\ninnovating is required to develop new paradigms that represent the best of both\nworlds, an effort called \"converged computing,\" the need for such a role is not\njust ideal, but essential for the continued success of science. While scattered\nstaff in non-traditional roles have found time to work on some facets of this\nspace, the lack of a larger workforce and incentive to support it has led to\nthe scientific community falling behind. In this article we will highlight the\nimportance of this missing layer, providing examples of how a missing role of\ninfrastructure engineer has led to inefficiencies in the interoperability,\nportability, and reproducibility of science. We suggest that an inability to\nallocate, provide resources for, and sustain individuals to work explicitly on\nthese technologies could lead to possible futures that are sub-optimal for the\ncontinued success of our scientific communities.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Vanessa Sochat"
        ],
        "published": "2024-05-17T00:15:43Z"
    }
]