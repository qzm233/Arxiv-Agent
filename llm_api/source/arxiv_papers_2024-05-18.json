[
    {
        "title": "High-Resolution Agent-Based Modeling of Campus Population Behaviors for\n  Pandemic Response Planning",
        "link": "http://arxiv.org/abs/2405.11414v1",
        "abstract": "This paper reports a case study of an application of high-resolution\nagent-based modeling and simulation to pandemic response planning on a\nuniversity campus. In the summer of 2020, we were tasked with a COVID-19\npandemic response project to create a detailed behavioral simulation model of\nthe entire campus population at Binghamton University. We conceptualized this\nproblem as an agent migration process on a multilayer transportation network,\nin which each layer represented a different transportation mode. As no direct\ndata were available about people's behaviors on campus, we collected as much\nindirect information as possible to inform the agents' behavioral rules. Each\nagent was assumed to move along the shortest path between two locations within\neach transportation layer and switch layers at a parking lot or a bus stop,\nalong with several other behavioral assumptions. Using this model, we conducted\nsimulations of the whole campus population behaviors on a typical weekday,\ninvolving more than 25,000 agents. We measured the frequency of close social\ncontacts at each spatial location and identified several busy locations and\ncorridors on campus that needed substantial behavioral intervention. Moreover,\nsystematic simulations with varying population density revealed that the effect\nof population density reduction was nonlinear, and that reducing the population\ndensity to 40-45% would be optimal and sufficient to suppress disease spreading\non campus. These results were reported to the university administration and\nutilized in the pandemic response planning, which led to successful outcomes.",
        "subjects": [
            "cs.CY",
            "cs.CE",
            "cs.MA",
            "physics.soc-ph"
        ],
        "authors": [
            "Hiroki Sayama",
            "Shun Cao"
        ],
        "published": "2024-05-18T23:22:41Z"
    },
    {
        "title": "Exploring speech style spaces with language models: Emotional TTS\n  without emotion labels",
        "link": "http://arxiv.org/abs/2405.11413v1",
        "abstract": "Many frameworks for emotional text-to-speech (E-TTS) rely on human-annotated\nemotion labels that are often inaccurate and difficult to obtain. Learning\nemotional prosody implicitly presents a tough challenge due to the subjective\nnature of emotions. In this study, we propose a novel approach that leverages\ntext awareness to acquire emotional styles without the need for explicit\nemotion labels or text prompts. We present TEMOTTS, a two-stage framework for\nE-TTS that is trained without emotion labels and is capable of inference\nwithout auxiliary inputs. Our proposed method performs knowledge transfer\nbetween the linguistic space learned by BERT and the emotional style space\nconstructed by global style tokens. Our experimental results demonstrate the\neffectiveness of our proposed framework, showcasing improvements in emotional\naccuracy and naturalness. This is one of the first studies to leverage the\nemotional correlation between spoken content and expressive delivery for\nemotional TTS.",
        "subjects": [
            "eess.AS",
            "cs.LG"
        ],
        "authors": [
            "Shreeram Suresh Chandra",
            "Zongyang Du",
            "Berrak Sisman"
        ],
        "published": "2024-05-18T23:21:39Z"
    },
    {
        "title": "Simulating Petri nets with Boolean Matrix Logic Programming",
        "link": "http://arxiv.org/abs/2405.11412v1",
        "abstract": "Recent attention to relational knowledge bases has sparked a demand for\nunderstanding how relations change between entities. Petri nets can represent\nknowledge structure and dynamically simulate interactions between entities, and\nthus they are well suited for achieving this goal. However, logic programs\nstruggle to deal with extensive Petri nets due to the limitations of high-level\nsymbol manipulations. To address this challenge, we introduce a novel approach\ncalled Boolean Matrix Logic Programming (BMLP), utilising boolean matrices as\nan alternative computation mechanism for Prolog to evaluate logic programs.\nWithin this framework, we propose two novel BMLP algorithms for simulating a\nclass of Petri nets known as elementary nets. This is done by transforming\nelementary nets into logically equivalent datalog programs. We demonstrate\nempirically that BMLP algorithms can evaluate these programs 40 times faster\nthan tabled B-Prolog, SWI-Prolog, XSB-Prolog and Clingo. Our work enables the\nefficient simulation of elementary nets using Prolog, expanding the scope of\nanalysis, learning and verification of complex systems with logic programming\ntechniques.",
        "subjects": [
            "cs.AI",
            "cs.SC"
        ],
        "authors": [
            "Lun Ai",
            "Stephen H. Muggleton",
            "Shi-Shun Liang",
            "Geoff S. Baldwin"
        ],
        "published": "2024-05-18T23:17:00Z"
    },
    {
        "title": "SmartAntenna: Enhancing Wireless Range with Autonomous Orientation",
        "link": "http://arxiv.org/abs/2405.11411v1",
        "abstract": "The SmartAntenna proposes a novel approach to extend wireless communication,\nfocusing on autonomous orientation to extend range and optimize performance.\nThrough meticulous evaluation, various aspects of its functionality were\nassessed, revealing both strengths and areas for improvement. Notably, the\nantenna tracking mechanism exhibited remarkable efficacy. The SmartAntenna\ndemonstrated robust functionality throughout extensive testing, underscoring\nits reliability even amidst complex operational scenarios. However, challenges\nemerged during target tracking, particularly evident in 360-degree sweeps,\nnecessitating further refinement to enhance accuracy. Despite reliance on the\nHC-12 module, LoRa, performance limitations surfaced, prompting concerns\nregarding its suitability for production systems, especially within noisy\nfrequency bands. Nevertheless, the SmartAntenna's adaptability across various\nwireless technologies holds promise, opening avenues for extended communication\nranges and diverse applications. SmartAntenna research contributes valuable\ninsights into optimizing wireless communication systems, paving the way for\nenhanced performance and expanded capabilities in diverse operational\nenvironments.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Michael Swann",
            "Pedro Machado",
            "Isibor Kennedy Ihianle",
            "Salisu Yahaya",
            "Farbod Zorriassatine",
            "Andreas Oikonomou"
        ],
        "published": "2024-05-18T23:16:52Z"
    },
    {
        "title": "Characterizing the Complexity of Social Robot Navigation Scenarios",
        "link": "http://arxiv.org/abs/2405.11410v1",
        "abstract": "Social robot navigation algorithms are often demonstrated in overly\nsimplified scenarios, prohibiting the extraction of practical insights about\ntheir relevance to real world domains. Our key insight is that an understanding\nof the inherent complexity of a social robot navigation scenario could help\ncharacterize the limitations of existing navigation algorithms and provide\nactionable directions for improvement. Through an exploration of recent\nliterature, we identify a series of factors contributing to the complexity of a\nscenario, disambiguating between contextual and robot-related ones. We then\nconduct a simulation study investigating how manipulations of contextual\nfactors impact the performance of a variety of navigation algorithms. We find\nthat dense and narrow environments correlate most strongly with performance\ndrops, while the heterogeneity of agent policies and directionality of\ninteractions have a less pronounced effect. This motivates a shift towards\ndeveloping and testing algorithms under higher-complexity settings.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Andrew Stratton",
            "Kris Hauser",
            "Christoforos Mavrogiannis"
        ],
        "published": "2024-05-18T23:03:22Z"
    },
    {
        "title": "On Tuza's Conjecture in Dense Graphs",
        "link": "http://arxiv.org/abs/2405.11409v1",
        "abstract": "In 1982, Tuza conjectured that the size $\\tau(G)$ of a minimum set of edges\nthat intersects every triangle of a graph $G$ is at most twice the size\n$\\nu(G)$ of a maximum set of edge-disjoint triangles of $G$. This conjecture\nwas proved for several graph classes. In this paper, we present three results\nregarding Tuza's Conjecture for dense graphs. By using a probabilistic\nargument, Tuza proved its conjecture for graphs on $n$ vertices with minimum\ndegree at least $\\frac{7n}{8}$. We extend this technique to show that Tuza's\nconjecture is valid for split graphs with minimum degree at least\n$\\frac{3n}{5}$; and that $\\tau(G) < \\frac{28}{15}\\nu(G)$ for every tripartite\ngraph with minimum degree more than $\\frac{33n}{56}$. Finally, we show that\n$\\tau(G)\\leq \\frac{3}{2}\\nu(G)$ when $G$ is a complete 4-partite graph.\nMoreover, this bound is tight.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "authors": [
            "Luis Chahua",
            "Juan Gutierrez"
        ],
        "published": "2024-05-18T23:01:39Z"
    },
    {
        "title": "Workload Prediction in P4 Programmable Switches: Smart Resource\n  Scheduling",
        "link": "http://arxiv.org/abs/2405.11408v1",
        "abstract": "The rapid expansion of cloud services and their unpredictable workload\ndemands present significant challenges in resource management. Traditional\nresource management approaches, primarily based on static rules and thresholds,\noften fail to ensure cost-effectiveness and optimal resource utilization. This\nresearch introduces a predictive model designed to forecast traffic demand,\naiming to shift from a reactive to a proactive resource management approach. By\nintegrating advanced predictive analytics with the capabilities of P4\nprogrammable switches, this study seeks to enhance the efficiency of resource\nutilization and improve system robustness. The goal is to equip organizations\nwith the agility and economic efficiency required to navigate the complexities\nof dynamic cloud environments effectively. This approach not only promises to\nrefine microservice resource allocation but also supports the broader objective\nof fostering more resilient and efficient cloud infrastructures.",
        "subjects": [
            "cs.NI",
            "C.2.3"
        ],
        "authors": [
            "Boyang Yan"
        ],
        "published": "2024-05-18T22:54:39Z"
    },
    {
        "title": "Can Public LLMs be used for Self-Diagnosis of Medical Conditions ?",
        "link": "http://arxiv.org/abs/2405.11407v1",
        "abstract": "The advancements in the development of Large Language Models have evolved as\na transformative paradigm in conversational tasks which has led to its\nintegration in the critical domain of healthcare. With LLMs becoming widely\npopular and their public access through open-source models, there is a need to\ninvestigate their potential and limitations. One such critical task where LLMs\nare applied but require a deeper understanding is that of self-diagnosis of\nmedical conditions in the interest of public health. The widespread integration\nof Gemini with Google search, GPT-4.0 with Bing search, has led to shift in\ntrend of self-diagnosis from search engine LLMs. In this paper, we prepare a\nprompt engineered dataset of 10000 samples and test the performance on the\ngeneral task of self-diagnosis. We compare the performance of GPT-4.0 and\nGemini model on the task of self-diagnosis and record accuracies of 63.07% and\n6.01% respectively. We also discuss the challenges, limitations, and potential\nof both Gemini and GPT-4.0 for the task of self-diagnosis to facilitate future\nresearch and towards the broader impact of general public knowledge.\nFurthermore, we demonstrate the potential and improvement in performance for\nthe task of self-diagnosis using Retrieval Augmented Generation.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Nikil Sharan Prabahar Balasubramanian",
            "Sagnik Dakshit"
        ],
        "published": "2024-05-18T22:43:44Z"
    },
    {
        "title": "LeaPformer: Enabling Linear Transformers for Autoregressive and\n  Simultaneous Tasks via Learned Proportions",
        "link": "http://arxiv.org/abs/2405.13046v1",
        "abstract": "A promising approach to preserving model performance in linearized\ntransformers is to employ position-based re-weighting functions. However,\nstate-of-the-art re-weighting functions rely heavily on target sequence\nlengths, making it difficult or impossible to apply them to autoregressive and\nsimultaneous tasks, where the target and sometimes even the input sequence\nlength are unknown. To address this issue, we propose Learned Proportions\n(LeaP) and LeaPformers. Our contribution is built on two major components.\nFirst, we generalize the dependence on explicit positional representations and\nsequence lengths into dependence on sequence proportions for re-weighting.\nSecond, we replace static positional representations with dynamic proportions\nderived via a compact module, enabling more flexible attention concentration\npatterns. We evaluate LeaPformer against eight representative efficient\ntransformers on the Long-Range Arena benchmark, showing that LeaPformer\nachieves the best quality-throughput trade-off, as well as LeaPformer to\nWikitext-103 autoregressive language modeling and simultaneous speech-to-text\ntranslation for two language pairs, achieving competitive results.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Victor Agostinelli",
            "Sanghyun Hong",
            "Lizhong Chen"
        ],
        "published": "2024-05-18T22:23:07Z"
    },
    {
        "title": "On the Rate-Distortion Function for Sampled Cyclostationary Gaussian\n  Processes with Memory: Extended Version with Proofs",
        "link": "http://arxiv.org/abs/2405.11405v2",
        "abstract": "In this work we study the rate-distortion function (RDF) for lossy\ncompression of asynchronously-sampled continuous-time (CT) wide-sense\ncyclostationary (WSCS) Gaussian processes with memory. As the case of\nsynchronous sampling, i.e., when the sampling interval is commensurate with the\nperiod of the cyclostationary statistics, has already been studied, we focus on\ndiscrete-time (DT) processes obtained by asynchronous sampling, i.e., when the\nsampling interval is incommensurate with the period of the cyclostationary\nstatistics of the CT WSCS source process. It is further assumed that the\nsampling interval is smaller than the maximal autocorrelation length of the CT\nsource process, which implies that the DT process possesses memory. Thus, the\nsampled process is a DT wide-sense almost cyclostationary (WSACS) processes\nwith memory. This problem is motivated by the fact that man-made communications\nsignals are modelled as CT WSCS processes; hence, applications of such sampling\ninclude, e.g., compress-and-forward relaying and recording systems. The main\nchallenge follows because, with asynchronous sampling, the DT sampled process\nis not information-stable, and hence the characterization of its RDF should be\ncarried out within the information-spectrum framework instead of using\nconventional information-theoretic arguments. This work expands upon our\nprevious work which addressed the special case in which the DT process is\nindependent across time. The existence of dependence between the samples\nrequires new tools to obtain the characterization of the RDF.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Zikun Tan",
            "Ron Dabora",
            "H. Vincent Poor"
        ],
        "published": "2024-05-18T22:22:49Z"
    },
    {
        "title": "How big is Big Data?",
        "link": "http://arxiv.org/abs/2405.11404v1",
        "abstract": "Big data has ushered in a new wave of predictive power using machine learning\nmodels. In this work, we assess what {\\it big} means in the context of typical\nmaterials-science machine-learning problems. This concerns not only data\nvolume, but also data quality and veracity as much as infrastructure issues.\nWith selected examples, we ask (i) how models generalize to similar datasets,\n(ii) how high-quality datasets can be gathered from heterogenous sources, (iii)\nhow the feature set and complexity of a model can affect expressivity, and (iv)\nwhat infrastructure requirements are needed to create larger datasets and train\nmodels on them. In sum, we find that big data present unique challenges along\nvery different aspects that should serve to motivate further work.",
        "subjects": [
            "stat.ML",
            "cond-mat.mtrl-sci",
            "cs.LG",
            "physics.comp-ph"
        ],
        "authors": [
            "Daniel T. Speckhard",
            "Tim Bechtel",
            "Luca M. Ghiringhelli",
            "Martin Kuban",
            "Santiago Rigamonti",
            "Claudia Draxl"
        ],
        "published": "2024-05-18T22:13:55Z"
    },
    {
        "title": "MapCoder: Multi-Agent Code Generation for Competitive Problem Solving",
        "link": "http://arxiv.org/abs/2405.11403v1",
        "abstract": "Code synthesis, which requires a deep understanding of complex natural\nlanguage problem descriptions, generation of code instructions for complex\nalgorithms and data structures, and the successful execution of comprehensive\nunit tests, presents a significant challenge. While large language models\n(LLMs) demonstrate impressive proficiency in natural language processing, their\nperformance in code generation tasks remains limited. In this paper, we\nintroduce a new approach to code generation tasks leveraging multi-agent\nprompting that uniquely replicates the full cycle of program synthesis as\nobserved in human developers. Our framework, MapCoder, consists of four LLM\nagents specifically designed to emulate the stages of this cycle: recalling\nrelevant examples, planning, code generation, and debugging. After conducting\nthorough experiments, with multiple LLM ablations and analyses across eight\nchallenging competitive problem-solving and program synthesis benchmarks,\nMapCoder showcases remarkable code generation capabilities, achieving new\nstate-of-the-art results (pass@1) on HumanEval (93.9%), MBPP (83.1%), APPS\n(22.0%), CodeContests (28.5%), and xCodeEval (45.3%). Moreover, our method\nconsistently delivers superior performance across various programming languages\nand varying problem difficulties. We open-source our framework at\nhttps://github.com/Md-Ashraful-Pramanik/MapCoder.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Md. Ashraful Islam",
            "Mohammed Eunus Ali",
            "Md Rizwan Parvez"
        ],
        "published": "2024-05-18T22:10:15Z"
    },
    {
        "title": "A Model for Optimal Resilient Planning Subject to Fallible Actuators",
        "link": "http://arxiv.org/abs/2405.11402v1",
        "abstract": "Robots incurring component failures ought to adapt their behavior to best\nrealize still-attainable goals under reduced capacity. We formulate the problem\nof planning with actuators known a priori to be susceptible to failure within\nthe Markov Decision Processes (MDP) framework. The model captures\nutilization-driven malfunction and state-action dependent likelihoods of\nactuator failure in order to enable reasoning about potential impairment and\nthe long-term implications of impoverished future control. This leads to\nbehavior differing qualitatively from plans which ignore failure. As actuators\nmalfunction, there are combinatorially many configurations which can arise. We\nidentify opportunities to save computation through re-use, exploiting the\nobservation that differing configurations yield closely related problems. Our\nresults show how strategic solutions are obtained so robots can respond when\nfailures do occur -- for instance, in prudently scheduling utilization in order\nto keep critical actuators in reserve.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "authors": [
            "Kyle Baldes",
            "Diptanil Chaudhuri",
            "Jason M. O'Kane",
            "Dylan A. Shell"
        ],
        "published": "2024-05-18T22:07:38Z"
    },
    {
        "title": "PDE Control Gym: A Benchmark for Data-Driven Boundary Control of Partial\n  Differential Equations",
        "link": "http://arxiv.org/abs/2405.11401v2",
        "abstract": "Over the last decade, data-driven methods have surged in popularity, emerging\nas valuable tools for control theory. As such, neural network approximations of\ncontrol feedback laws, system dynamics, and even Lyapunov functions have\nattracted growing attention. With the ascent of learning based control, the\nneed for accurate, fast, and easy-to-use benchmarks has increased. In this\nwork, we present the first learning-based environment for boundary control of\nPDEs. In our benchmark, we introduce three foundational PDE problems - a 1D\ntransport PDE, a 1D reaction-diffusion PDE, and a 2D Navier-Stokes PDE - whose\nsolvers are bundled in an user-friendly reinforcement learning gym. With this\ngym, we then present the first set of model-free, reinforcement learning\nalgorithms for solving this series of benchmark problems, achieving stability,\nalthough at a higher cost compared to model-based PDE backstepping. With the\nset of benchmark environments and detailed examples, this work significantly\nlowers the barrier to entry for learning-based PDE control - a topic largely\nunexplored by the data-driven control community. The entire benchmark is\navailable on Github along with detailed documentation and the presented\nreinforcement learning models are open sourced.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.CE",
            "cs.LG",
            "cs.SY",
            "math.OC"
        ],
        "authors": [
            "Luke Bhan",
            "Yuexin Bian",
            "Miroslav Krstic",
            "Yuanyuan Shi"
        ],
        "published": "2024-05-18T22:01:55Z"
    },
    {
        "title": "An exact coverage path planning algorithm for UAV-based search and\n  rescue operations",
        "link": "http://arxiv.org/abs/2405.11399v1",
        "abstract": "Unmanned aerial vehicles (UAVs) are increasingly utilized in global search\nand rescue efforts, enhancing operational efficiency. In these missions, a\ncoordinated swarm of UAVs is deployed to efficiently cover expansive areas by\ncapturing and analyzing aerial imagery and footage. Rapid coverage is paramount\nin these scenarios, as swift discovery can mean the difference between life and\ndeath for those in peril. This paper focuses on optimizing flight path planning\nfor multiple UAVs in windy conditions to efficiently cover rectangular search\nareas in minimal time. We address this challenge by dividing the search area\ninto a grid network and formulating it as a mixed-integer program (MIP). Our\nresearch introduces a precise lower bound for the objective function and an\nexact algorithm capable of finding either the optimal solution or a\nnear-optimal solution with a constant absolute gap to optimality. Notably, as\nthe problem complexity increases, our solution exhibits a diminishing relative\noptimality gap while maintaining negligible computational costs compared to the\nMIP approach.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Sina Kazemdehbashi",
            "Yanchao Liu"
        ],
        "published": "2024-05-18T21:58:06Z"
    },
    {
        "title": "Preparing for Black Swans: The Antifragility Imperative for Machine\n  Learning",
        "link": "http://arxiv.org/abs/2405.11397v1",
        "abstract": "Operating safely and reliably despite continual distribution shifts is vital\nfor high-stakes machine learning applications. This paper builds upon the\ntransformative concept of ``antifragility'' introduced by (Taleb, 2014) as a\nconstructive design paradigm to not just withstand but benefit from volatility.\nWe formally define antifragility in the context of online decision making as\ndynamic regret's strictly concave response to environmental variability,\nrevealing limitations of current approaches focused on resisting rather than\nbenefiting from nonstationarity. Our contribution lies in proposing potential\ncomputational pathways for engineering antifragility, grounding the concept in\nonline learning theory and drawing connections to recent advancements in areas\nsuch as meta-learning, safe exploration, continual learning,\nmulti-objective/quality-diversity optimization, and foundation models. By\nidentifying promising mechanisms and future research directions, we aim to put\nantifragility on a rigorous theoretical foundation in machine learning. We\nfurther emphasize the need for clear guidelines, risk assessment frameworks,\nand interdisciplinary collaboration to ensure responsible application.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Ming Jin"
        ],
        "published": "2024-05-18T21:32:29Z"
    },
    {
        "title": "Quantum Network Tomography",
        "link": "http://arxiv.org/abs/2405.11396v1",
        "abstract": "Errors are the fundamental barrier to the development of quantum systems.\nQuantum networks are complex systems formed by the interconnection of multiple\ncomponents and suffer from error accumulation. Characterizing errors introduced\nby quantum network components becomes a fundamental task to overcome their\ndepleting effects in quantum communication. Quantum Network Tomography (QNT)\naddresses end-to-end characterization of link errors in quantum networks. It is\na tool for building error-aware applications, network management, and system\nvalidation. We provide an overview of QNT and its initial results for\ncharacterizing quantum star networks. We apply a previously defined QNT\nprotocol for estimating bit-flip channels to estimate depolarizing channels. We\nanalyze the performance of our estimators numerically by assessing the Quantum\nCram\\`er-Rao Bound (QCRB) and the Mean Square Error (MSE) in the finite sample\nregime. Finally, we provide a discussion on current challenges in the field of\nQNT and elicit exciting research directions for future investigation.",
        "subjects": [
            "quant-ph",
            "cs.NI"
        ],
        "authors": [
            "Matheus Guedes de Andrade",
            "Jake Navas",
            "Saikat Guha",
            "Inès Montaño",
            "Michael Raymer",
            "Brian Smith",
            "Don Towsley"
        ],
        "published": "2024-05-18T21:24:52Z"
    },
    {
        "title": "Optimal control barrier functions for RL based safe powertrain control",
        "link": "http://dx.doi.org/10.1016/j.ifacol.2023.12.054",
        "abstract": "Reinforcement learning (RL) can improve control performance by seeking to\nlearn optimal control policies in the end-use environment for vehicles and\nother systems. To accomplish this, RL algorithms need to sufficiently explore\nthe state and action spaces. This presents inherent safety risks, and applying\nRL on safety-critical systems like vehicle powertrain control requires safety\nenforcement approaches. In this paper, we seek control-barrier function\n(CBF)-based safety certificates that demarcate safe regions where the RL agent\ncould optimize the control performance. In particular, we derive optimal\nhigh-order CBFs that avoid conservatism while ensuring safety for a vehicle in\ntraffic. We demonstrate the workings of the high-order CBF with an RL agent\nwhich uses a deep actor-critic architecture to learn to optimize fuel economy\nand other driver accommodation metrics. We find that the optimized high-order\nCBF allows the RL-based powertrain control agent to achieve higher total\nrewards without any crashes in training and evaluation while achieving better\naccommodation of driver demands compared to previously proposed exponential\nbarrier function filters and model-based baseline controllers.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Habtamu Hailemichael",
            "Beshah Ayalew",
            "Andrej Ivanco"
        ],
        "published": "2024-05-18T20:53:05Z"
    },
    {
        "title": "Adjacent Leader Decentralized Stochastic Gradient Descent",
        "link": "http://arxiv.org/abs/2405.11389v1",
        "abstract": "This work focuses on the decentralized deep learning optimization framework.\nWe propose Adjacent Leader Decentralized Gradient Descent (AL-DSGD), for\nimproving final model performance, accelerating convergence, and reducing the\ncommunication overhead of decentralized deep learning optimizers. AL-DSGD\nrelies on two main ideas. Firstly, to increase the influence of the strongest\nlearners on the learning system it assigns weights to different neighbor\nworkers according to both their performance and the degree when averaging among\nthem, and it applies a corrective force on the workers dictated by both the\ncurrently best-performing neighbor and the neighbor with the maximal degree.\nSecondly, to alleviate the problem of the deterioration of the convergence\nspeed and performance of the nodes with lower degrees, AL-DSGD relies on\ndynamic communication graphs, which effectively allows the workers to\ncommunicate with more nodes while keeping the degrees of the nodes low.\nExperiments demonstrate that AL-DSGD accelerates the convergence of the\ndecentralized state-of-the-art techniques and improves their test performance\nespecially in the communication constrained environments. We also theoretically\nprove the convergence of the proposed scheme. Finally, we release to the\ncommunity a highly general and concise PyTorch-based library for distributed\ntraining of deep learning models that supports easy implementation of any\ndistributed deep learning approach ((a)synchronous, (de)centralized).",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Haoze He",
            "Jing Wang",
            "Anna Choromanska"
        ],
        "published": "2024-05-18T20:24:11Z"
    },
    {
        "title": "Combined film and pulse heating of lithium ion batteries to improve\n  performance in low ambient temperature",
        "link": "http://dx.doi.org/10.1016/j.ifacol.2023.12.061",
        "abstract": "Low ambient temperatures significantly reduce Lithium ion batteries' (LIBs')\ncharge/discharge power and energy capacity, and cause rapid degradation through\nlithium plating. These limitations can be addressed by preheating the LIB with\nan external heat source or by exploiting the internal heat generation through\nthe LIB's internal impedance. Fast external heating generates large temperature\ngradients across the LIB due to the low thermal conductivity of the cell, while\ninternal impedance heating (usually through AC or pulse charge/discharging)\ntends to be relatively slow, although it can achieve more uniform temperature\ndistribution. This paper investigates the potential of combining externally\nsourced resistive film heating with bidirectional pulse heating to achieve fast\npreheating without causing steep temperature gradients. The LIB is modeled with\nthe Doyle Fuller Newman (DFN) electrochemical model and 1D thermal model, and\nreinforcement learning (RL) is used to optimize the pulse current amplitude and\nfilm voltage concurrently. The results indicate that the optimal policy for\nmaximizing the rate of temperature rise while limiting temperature gradients\nhas the film heating dominate the initial phases and create the ideal\nconditions for pulse heating to take over. In addition, the pulse component\nshares the heating load and reduces the energy rating of the auxiliary power\nsource.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Habtamu Hailemichael",
            "Beshah Ayalew"
        ],
        "published": "2024-05-18T20:22:54Z"
    },
    {
        "title": "Liver Fat Quantification Network with Body Shape",
        "link": "http://arxiv.org/abs/2405.11386v1",
        "abstract": "It is clinically important to detect liver fat content as it is related to\ncardiac complications and cardiovascular disease mortality. However, existing\nmethods are associated with high cost and/or medical complications (e.g., liver\nbiopsy, medical imaging technology) or only roughly estimate the grades of\nsteatosis. In this paper, we propose a deep neural network to accurately\nestimate liver fat percentage using only body shapes. The proposed framework is\ncomposed of a flexible baseline regression network and a lightweight attention\nmodule. The attention module is trained to generate discriminative and diverse\nfeatures, thus significantly improving performance. To validate our proposed\nmethod, we perform extensive tests on medical datasets. The experimental\nresults validate our method and prove the efficacy of designing neural networks\nto predict liver fat using only body shape. Since body shapes can be acquired\nusing inexpensive and readily available optical scanners, the proposed method\npromised to make accurate assessment of hepatic steatosis more accessible.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Qiyue Wang",
            "Wu Xue",
            "Xiaoke Zhang",
            "Fang Jin",
            "James Hahn"
        ],
        "published": "2024-05-18T20:22:22Z"
    },
    {
        "title": "Investigating KAN-Based Physics-Informed Neural Networks for EMI/EMC\n  Simulations",
        "link": "http://arxiv.org/abs/2405.11383v2",
        "abstract": "The main objective of this paper is to investigate the feasibility of\nemploying Physics-Informed Neural Networks (PINNs) techniques, in particular\nKolmogorovArnold Networks (KANs), for facilitating Electromagnetic Interference\n(EMI) simulations. It introduces some common EM problem formulations and how\nthey can be solved using AI-driven solutions instead of lengthy and complex\nfull-wave numerical simulations. This research may open new horizons for green\nEMI simulation workflows with less energy consumption and feasible\ncomputational capacity.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Kun Qian",
            "Mohamed Kheir"
        ],
        "published": "2024-05-18T20:12:16Z"
    },
    {
        "title": "Meta-Control: Automatic Model-based Control Synthesis for Heterogeneous\n  Robot Skills",
        "link": "http://arxiv.org/abs/2405.11380v1",
        "abstract": "The requirements for real-world manipulation tasks are diverse and often\nconflicting; some tasks necessitate force constraints or collision avoidance,\nwhile others demand high-frequency feedback. Satisfying these varied\nrequirements with a fixed state-action representation and control strategy is\nchallenging, impeding the development of a universal robotic foundation model.\nIn this work, we propose Meta-Control, the first LLM-enabled automatic control\nsynthesis approach that creates customized state representations and control\nstrategies tailored to specific tasks. Meta-Control leverages a generic\nhierarchical control framework to address a wide range of heterogeneous tasks.\nOur core insight is the decomposition of the state space into an abstract task\nspace and a concrete tracking space. By harnessing LLM's extensive common sense\nand control knowledge, we enable the LLM to design these spaces, including\nstates, dynamic models, and controllers, using pre-defined but abstract\ntemplates. Meta-Control stands out for its fully model-based nature, allowing\nfor rigorous analysis, efficient parameter tuning, and reliable execution. It\nnot only utilizes decades of control expertise encapsulated within LLMs to\nfacilitate heterogeneous control but also ensures formal guarantees such as\nsafety and stability. Our method is validated both in real-world scenarios and\nsimulations across diverse tasks with conflicting requirements, such as\ncollision avoidance versus convergence and compliance versus high precision.\nVideos and additional results are at meta-control-paper.github.io",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Tianhao Wei",
            "Liqian Ma",
            "Rui Chen",
            "Weiye Zhao",
            "Changliu Liu"
        ],
        "published": "2024-05-18T19:58:44Z"
    },
    {
        "title": "Causal Customer Churn Analysis with Low-rank Tensor Block Hazard Model",
        "link": "http://arxiv.org/abs/2405.11377v1",
        "abstract": "This study introduces an innovative method for analyzing the impact of\nvarious interventions on customer churn, using the potential outcomes\nframework. We present a new causal model, the tensorized latent factor block\nhazard model, which incorporates tensor completion methods for a principled\ncausal analysis of customer churn. A crucial element of our approach is the\nformulation of a 1-bit tensor completion for the parameter tensor. This\ncaptures hidden customer characteristics and temporal elements from churn\nrecords, effectively addressing the binary nature of churn data and its\ntime-monotonic trends. Our model also uniquely categorizes interventions by\ntheir similar impacts, enhancing the precision and practicality of implementing\ncustomer retention strategies. For computational efficiency, we apply a\nprojected gradient descent algorithm combined with spectral clustering. We lay\ndown the theoretical groundwork for our model, including its non-asymptotic\nproperties. The efficacy and superiority of our model are further validated\nthrough comprehensive experiments on both simulated and real-world\napplications.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "authors": [
            "Chenyin Gao",
            "Zhiming Zhang",
            "Shu Yang"
        ],
        "published": "2024-05-18T19:54:14Z"
    },
    {
        "title": "ReModels: Quantile Regression Averaging models",
        "link": "http://arxiv.org/abs/2405.11372v1",
        "abstract": "Electricity price forecasts play a crucial role in making key business\ndecisions within the electricity markets. A focal point in this domain are\nprobabilistic predictions, which delineate future price values in a more\ncomprehensive manner than simple point forecasts. The golden standard in\nprobabilistic approaches to predict energy prices is the Quantile Regression\nAveraging (QRA) method. In this paper, we present a Python package that\nencompasses the implementation of QRA, along with modifications of this\napproach that have appeared in the literature over the past few years. The\nproposed package also facilitates the acquisition and preparation of data\nrelated to electricity markets, as well as the evaluation of model predictions.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Grzegorz Zakrzewski",
            "Kacper Skonieczka",
            "Mikołaj Małkiński",
            "Jacek Mańdziuk"
        ],
        "published": "2024-05-18T19:13:49Z"
    },
    {
        "title": "Security of Cloud Services with Low-Performance Devices in Critical\n  Infrastructures",
        "link": "http://arxiv.org/abs/2405.11368v1",
        "abstract": "As part of the Internet of Things (IoT) and Industry 4.0 Cloud services are\nincreasingly interacting with low-performance devices that are used in\nautomation. This results in security issues that will be presented in this\npaper. Particular attention is paid to so-called critical infrastructures. The\nauthors intend to work on the addressed security challenges as part of a funded\nresearch project, using electrical actuators and battery storages as specific\napplications. The core ideas of this research project are also presented in\nthis paper.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "authors": [
            "Michael Molle",
            "Ulrich Raithel",
            "Dirk Kraemer",
            "Norbert Graß",
            "Matthias Söllner",
            "Andreas Aßmuth"
        ],
        "published": "2024-05-18T18:33:04Z"
    },
    {
        "title": "Optimal recovery of linear operators from information of random\n  functions",
        "link": "http://arxiv.org/abs/2405.11363v1",
        "abstract": "The paper concerns problems of the recovery of linear operators defined on\nsets of functions from information of these functions given with stochastic\nerrors. The constructed optimal recovery methods, in general, do not use all\nthe available information. As a consequence, optimal methods are obtained for\nrecovering derivatives of functions from Sobolev classes by the information of\ntheir Fourier transforms given with stochastic errors. A similar problem is\nconsidered for solutions of the heat equation.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "41A65, 41A46, 49N30, 60G35"
        ],
        "authors": [
            "K. Yu. Osipenko"
        ],
        "published": "2024-05-18T18:15:12Z"
    },
    {
        "title": "An Opportunistically Parallel Lambda Calculus for Performant Composition\n  of Large Language Models",
        "link": "http://arxiv.org/abs/2405.11361v1",
        "abstract": "Large language models (LLMs) have shown impressive results at a wide-range of\ntasks. However, they have limitations, such as hallucinating facts and\nstruggling with arithmetic. Recent work has addressed these issues with\nsophisticated decoding techniques. However, performant decoding, particularly\nfor sophisticated techniques, relies crucially on parallelization and batching,\nwhich are difficult for developers.\n  We make two observations: 1) existing approaches are high-level\ndomain-specific languages for gluing expensive black-box calls, but are not\ngeneral or compositional; 2) LLM programs are essentially pure (all effects\ncommute). Guided by these observations, we develop a novel, general-purpose\nlambda calculus for automatically parallelizing a wide-range of LLM\ninteractions, without user intervention. The key difference versus standard\nlambda calculus is a novel \"opportunistic\" evaluation strategy, which steps\nindependent parts of a program in parallel, dispatching black-box external\ncalls as eagerly as possible, even while data-independent parts of the program\nare waiting for their own external calls to return. To maintain the simplicity\nof the language and to ensure uniformity of opportunistic evaluation,\ncontrol-flow and looping constructs are implemented in-language, via Church\nencodings.\n  We implement this approach in a framework called EPIC, embedded in--and\ninteroperating closely with--Python. We demonstrate its versatility and\nperformance with three case studies drawn from the machine learning literature:\nTree-of-Thoughts (LLMs embedded in classic search procedures), nested tool use,\nand constrained decoding. Our experiments show that opportunistic evaluation\noffers a $1.5\\times$ to $4.8\\times$ speedup over sequential evaluation, while\nstill allowing practitioners to write straightforward and composable programs,\nwithout any manual parallelism or batching.",
        "subjects": [
            "cs.PL"
        ],
        "authors": [
            "Stephen Mell",
            "Steve Zdancewic",
            "Osbert Bastani"
        ],
        "published": "2024-05-18T18:13:31Z"
    },
    {
        "title": "Optimizing Layerwise Microservice Management in Heterogeneous Wireless\n  Networks",
        "link": "http://arxiv.org/abs/2405.11359v1",
        "abstract": "Small cells with edge computing are densely deployed in 5G mobile networks to\nprovide high throughput communication and low-latency computation. The\nflexibility of edge computation is empowered by the deployment of lightweight\ncontainer-based microservices. In this paper, we take the first step toward\noptimizing the microservice management in small-cell networks. The prominent\nfeature is that each microservice consists of multiple image layers and\ndifferent microservices may share some basic layers, thus bringing deep\ncoupling in their placement and service provision. Our objective is to minimize\nthe expected total latency of microservice requests under the storage,\ncommunication and computing constraints of the sparsely interconnected small\ncell nodes. We formulate a binary quadratic program (BQP) with the\nmulti-dimensional strategy of the image layer placement, the access selection\nand the task assignment. The BQP problem is then transformed into an ILP\nproblem, and is solved by use of a novel sphere-box alternating direction\nmultipliers method (ADMM) with reasonable complexity $O(q^{4})$, where $q$ is\nthe number of variables in the transformed problem. Trace-driven experiments\nshow that the gap between our proposed algorithm and the optimal is reduced by\n35$\\%$ compared with benchmark algorithms.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Haojie Yan",
            "Yuedong Xu",
            "Lianggui Dai"
        ],
        "published": "2024-05-18T18:10:53Z"
    },
    {
        "title": "Large Language Models Lack Understanding of Character Composition of\n  Words",
        "link": "http://arxiv.org/abs/2405.11357v1",
        "abstract": "Large language models (LLMs) have demonstrated remarkable performances on a\nwide range of natural language tasks. Yet, LLMs' successes have been largely\nrestricted to tasks concerning words, sentences, or documents, and it remains\nquestionable how much they understand the minimal units of text, namely\ncharacters. In this paper, we examine contemporary LLMs regarding their ability\nto understand character composition of words, and show that most of them fail\nto reliably carry out even the simple tasks that can be handled by humans with\nperfection. We analyze their behaviors with comparison to token level\nperformances, and discuss the potential directions for future research.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Andrew Shin",
            "Kunitake Kaneko"
        ],
        "published": "2024-05-18T18:08:58Z"
    },
    {
        "title": "Control-Aware Transmit Power Allocation for 6G In-Factory Subnetwork\n  Control Systems",
        "link": "http://arxiv.org/abs/2405.11355v1",
        "abstract": "In this paper, we develop a novel power control solution for\nsubnetworks-enabled distributed control systems in factory settings. We propose\na channel-independent control-aware (CICA) policy based on the logistic model\nand learn the parameters using Bayesian optimization with a multi-objective\ntree-structured Parzen estimator. The objective is to minimize the control cost\nof the plants, measured as a finite horizon linear quadratic regulator cost.\nThe proposed policy can be executed in a fully distributed manner and does not\nrequire cumbersome measurement of channel gain information, hence it is\nscalable for large-scale deployment of subnetworks for distributed control\napplications. With extensive numerical simulation and considering different\ndensities of subnetworks, we show that the proposed method can achieve\ncompetitive stability performance and high availability for large-scale\ndistributed control plants with limited radio resources.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Daniel Abode",
            "Pedro Maia de Sant Ana",
            "Alexander Artemenko",
            "Ramoni Adeogun",
            "Gilberto Berardinelli"
        ],
        "published": "2024-05-18T17:58:40Z"
    },
    {
        "title": "NTTSuite: Number Theoretic Transform Benchmarks for Accelerating\n  Encrypted Computation",
        "link": "http://arxiv.org/abs/2405.11353v1",
        "abstract": "Privacy concerns have thrust privacy-preserving computation into the\nspotlight. Homomorphic encryption (HE) is a cryptographic system that enables\ncomputation to occur directly on encrypted data, providing users with strong\nprivacy (and security) guarantees while using the same services they enjoy\ntoday unprotected. While promising, HE has seen little adoption due to\nextremely high computational overheads, rendering it impractical. Homomorphic\nencryption (HE) is a cryptographic system that enables computation to occur\ndirectly on encrypted data. In this paper we develop a benchmark suite, named\nNTTSuite, to enable researchers to better address these overheads by studying\nthe primary source of HE's slowdown: the number theoretic transform (NTT).\nNTTSuite constitutes seven unique NTT algorithms with support for CPUs (C++),\nGPUs (CUDA), and custom hardware (Catapult HLS).In addition, we propose\noptimizations to improve the performance of NTT running on FPGAs. We find our\nimplementation outperforms the state-of-the-art by 30%.",
        "subjects": [
            "cs.CR",
            "cs.AR"
        ],
        "authors": [
            "Juran Ding",
            "Yuanzhe Liu",
            "Lingbin Sun",
            "Brandon Reagen"
        ],
        "published": "2024-05-18T17:44:17Z"
    },
    {
        "title": "Hierarchical Reinforcement Learning Empowered Task Offloading in V2I\n  Networks",
        "link": "http://arxiv.org/abs/2405.11352v1",
        "abstract": "Edge computing plays an essential role in the vehicle-to-infrastructure (V2I)\nnetworks, where vehicles offload their intensive computation tasks to the\nroad-side units for saving energy and reduce the latency. This paper designs\nthe optimal task offloading policy to address the concerns involving processing\ndelay, energy consumption and edge computing cost. Each computation task\nconsisting of some interdependent sub-tasks is characterized as a directed\nacyclic graph (DAG). In such dynamic networks, a novel hierarchical Offloading\nscheme is proposed by leveraging deep reinforcement learning (DRL). The\ninter-dependencies among the DAGs of the computation tasks are extracted using\na graph neural network with attention mechanism. A parameterized DRL algorithm\nis developed to deal with the hierarchical action space containing both\ndiscrete and continuous actions. Simulation results with a real-world car speed\ndataset demonstrate that the proposed scheme can effectively reduce the system\noverhead.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "authors": [
            "Xinyu You",
            "Haojie Yan",
            "Yuedong Xu",
            "Lifeng Wang",
            "Liangui Dai"
        ],
        "published": "2024-05-18T17:44:02Z"
    },
    {
        "title": "PlantTracing: Tracing Arabidopsis Thaliana Apex with CenterTrack",
        "link": "http://arxiv.org/abs/2405.11351v1",
        "abstract": "This work applies an encoder-decoder-based machine learning network to detect\nand track the motion and growth of the flowering stem apex of Arabidopsis\nThaliana. Based on the CenterTrack, a machine learning back-end network, we\ntrained a model based on ten time-lapsed labeled videos and tested against\nthree videos.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yuanzhe Liu",
            "Yixiang Mao",
            "Yao Wang"
        ],
        "published": "2024-05-18T17:43:50Z"
    },
    {
        "title": "Cloud Security and Security Challenges Revisited",
        "link": "http://arxiv.org/abs/2405.11350v1",
        "abstract": "In recent years, Cloud Computing has transformed local businesses and created\nnew business models on the Internet- and Cloud services are still flourishing.\nBut after the emphatic hype in the early years, a more realistic perception of\nCloud services has emerged. One reason for this surely is that today, Cloud\nComputing is considered as an established and well-accepted technology and no\nlonger as a technical novelty. But the second reason for this assessment might\nalso be numerous security issues that Cloud Computing in general or specific\nCloud services have experienced since then. In this paper, we revisit attacks\non Cloud services and Cloud-related attack vectors that have been published in\nrecent years. We then consider successful or proposed solutions to cope with\nthese challenges. Based on these findings, we apply a security metric in order\nto rank all these Cloud-related security challenges concerning their severity.\nThis should assist security professionals to prioritize their efforts toward\naddressing these issues.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "authors": [
            "Fabian Süß",
            "Marco Freimuth",
            "Andreas Aßmuth",
            "George R. S. Weir",
            "Bob Duncan"
        ],
        "published": "2024-05-18T17:42:02Z"
    },
    {
        "title": "Unlock the Power of Algorithm Features: A Generalization Analysis for\n  Algorithm Selection",
        "link": "http://arxiv.org/abs/2405.11349v1",
        "abstract": "In the field of algorithm selection research, the discussion surrounding\nalgorithm features has been significantly overshadowed by the emphasis on\nproblem features. Although a few empirical studies have yielded evidence\nregarding the effectiveness of algorithm features, the potential benefits of\nincorporating algorithm features into algorithm selection models and their\nsuitability for different scenarios remain unclear. It is evident that relying\nsolely on empirical research cannot adequately elucidate the mechanisms\nunderlying performance variations. In this paper, we address this gap by\nproposing the first provable guarantee for algorithm selection based on\nalgorithm features, taking a generalization perspective. We analyze the\nbenefits and costs associated with algorithm features and investigate how the\ngeneralization error is affected by several factors. Specifically, we examine\nadaptive and predefined algorithm features under transductive and inductive\nlearning paradigms, respectively, and derive upper bounds for the\ngeneralization error based on their model's Rademacher complexity. Our\ntheoretical findings not only provide tight upper bounds, but also offer\nanalytical insights into the impact of various factors, including model\ncomplexity, the number of problem instances and candidate algorithms, model\nparameters and feature values, and distributional differences between the\ntraining and test sets. Notably, we demonstrate that algorithm feature-based\nmodels outperform traditional models relying solely on problem features in\ncomplex multi-algorithm scenarios in terms of generalization, and are\nparticularly well-suited for deployment in scenarios under distribution shifts,\nwhere the generalization error exhibits a positive correlation with the\nchi-square distance between training and test sets.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Xingyu Wu",
            "Yan Zhong",
            "Jibin Wu",
            "Yuxiao Huang",
            "Shenghao Wu",
            "Kay Chen Tan"
        ],
        "published": "2024-05-18T17:38:25Z"
    },
    {
        "title": "Cooperative Multi-agent Approach for Automated Computer Game Testing",
        "link": "http://arxiv.org/abs/2405.11347v1",
        "abstract": "Automated testing of computer games is a challenging problem, especially when\nlengthy scenarios have to be tested. Automating such a scenario boils down to\nfinding the right sequence of interactions given an abstract description of the\nscenario. Recent works have shown that an agent-based approach works well for\nthe purpose, e.g. due to agents' reactivity, hence enabling a test agent to\nimmediately react to game events and changing state. Many games nowadays are\nmulti-player. This opens up an interesting possibility to deploy multiple\ncooperative test agents to test such a game, for example to speed up the\nexecution of multiple testing tasks. This paper offers a cooperative\nmulti-agent testing approach and a study of its performance based on a case\nstudy on a 3D game called Lab Recruits.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "authors": [
            "Samira Shirzadeh-hajimahmood",
            "I. S. W. B. Prasteya",
            "Mehdi Dastani",
            "Frank Dignum"
        ],
        "published": "2024-05-18T17:31:26Z"
    },
    {
        "title": "CoLay: Controllable Layout Generation through Multi-conditional Latent\n  Diffusion",
        "link": "http://arxiv.org/abs/2405.13045v1",
        "abstract": "Layout design generation has recently gained significant attention due to its\npotential applications in various fields, including UI, graphic, and floor plan\ndesign. However, existing models face two main challenges that limits their\nadoption in practice. Firstly, the limited expressiveness of individual\ncondition types used in previous works restricts designers' ability to convey\ncomplex design intentions and constraints. Secondly, most existing models focus\non generating labels and coordinates, while real layouts contain a range of\nstyle properties. To address these limitations, we propose a novel framework,\nCoLay, that integrates multiple condition types and generates complex layouts\nwith diverse style properties. Our approach outperforms prior works in terms of\ngeneration quality and condition satisfaction while empowering users to express\ntheir design intents using a flexible combination of modalities, including\nnatural language prompts, layout guidelines, element types, and partially\ncompleted designs.",
        "subjects": [
            "cs.HC",
            "cs.AI"
        ],
        "authors": [
            "Chin-Yi Cheng",
            "Ruiqi Gao",
            "Forrest Huang",
            "Yang Li"
        ],
        "published": "2024-05-18T17:30:48Z"
    },
    {
        "title": "Decision support system for Forest fire management using Ontology with\n  Big Data and LLMs",
        "link": "http://arxiv.org/abs/2405.11346v1",
        "abstract": "Forests are crucial for ecological balance, but wildfires, a major cause of\nforest loss, pose significant risks. Fire weather indices, which assess\nwildfire risk and predict resource demands, are vital. With the rise of sensor\nnetworks in fields like healthcare and environmental monitoring, semantic\nsensor networks are increasingly used to gather climatic data such as wind\nspeed, temperature, and humidity. However, processing these data streams to\ndetermine fire weather indices presents challenges, underscoring the growing\nimportance of effective forest fire detection. This paper discusses using\nApache Spark for early forest fire detection, enhancing fire risk prediction\nwith meteorological and geographical data. Building on our previous development\nof Semantic Sensor Network (SSN) ontologies and Semantic Web Rules Language\n(SWRL) for managing forest fires in Monesterial Natural Park, we expanded SWRL\nto improve a Decision Support System (DSS) using a Large Language Models (LLMs)\nand Spark framework. We implemented real-time alerts with Spark streaming,\ntailored to various fire scenarios, and validated our approach using ontology\nmetrics, query-based evaluations, LLMs score precision, F1 score, and recall\nmeasures.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Ritesh Chandra",
            "Shashi Shekhar Kumar",
            "Rushil Patra",
            "Sonali Agarwal"
        ],
        "published": "2024-05-18T17:30:30Z"
    },
    {
        "title": "City-Scale Multi-Camera Vehicle Tracking System with Improved\n  Self-Supervised Camera Link Model",
        "link": "http://arxiv.org/abs/2405.11345v1",
        "abstract": "Multi-Target Multi-Camera Tracking (MTMCT) has broad applications and forms\nthe basis for numerous future city-wide systems (e.g. traffic management, crash\ndetection, etc.). However, the challenge of matching vehicle trajectories\nacross different cameras based solely on feature extraction poses significant\ndifficulties. This article introduces an innovative multi-camera vehicle\ntracking system that utilizes a self-supervised camera link model. In contrast\nto related works that rely on manual spatial-temporal annotations, our model\nautomatically extracts crucial multi-camera relationships for vehicle matching.\nThe camera link is established through a pre-matching process that evaluates\nfeature similarities, pair numbers, and time variance for high-quality tracks.\nThis process calculates the probability of spatial linkage for all camera\ncombinations, selecting the highest scoring pairs to create camera links. Our\napproach significantly improves deployment times by eliminating the need for\nhuman annotation, offering substantial improvements in efficiency and\ncost-effectiveness when it comes to real-world application. This pairing\nprocess supports cross camera matching by setting spatial-temporal constraints,\nreducing the searching space for potential vehicle matches. According to our\nexperimental results, the proposed method achieves a new state-of-the-art among\nautomatic camera-link based methods in CityFlow V2 benchmarks with 61.07% IDF1\nScore.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Yuqiang Lin",
            "Sam Lockyer",
            "Adrian Evans",
            "Markus Zarbock",
            "Nic Zhang"
        ],
        "published": "2024-05-18T17:28:35Z"
    },
    {
        "title": "Improved Content Understanding With Effective Use of Multi-task\n  Contrastive Learning",
        "link": "http://arxiv.org/abs/2405.11344v2",
        "abstract": "In enhancing LinkedIn core content recommendation models, a significant\nchallenge lies in improving their semantic understanding capabilities. This\npaper addresses the problem by leveraging multi-task learning, a method that\nhas shown promise in various domains. We fine-tune a pre-trained,\ntransformer-based LLM using multi-task contrastive learning with data from a\ndiverse set of semantic labeling tasks. We observe positive transfer, leading\nto superior performance across all tasks when compared to training\nindependently on each. Our model outperforms the baseline on zero shot learning\nand offers improved multilingual support, highlighting its potential for\nbroader application. The specialized content embeddings produced by our model\noutperform generalized embeddings offered by OpenAI on Linkedin dataset and\ntasks. This work provides a robust foundation for vertical teams across\nLinkedIn to customize and fine-tune the LLM to their specific applications. Our\nwork offers insights and best practices for the field to build on.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Akanksha Bindal",
            "Sudarshan Ramanujam",
            "Dave Golland",
            "TJ Hazen",
            "Tina Jiang",
            "Fengyu Zhang",
            "Peng Yan"
        ],
        "published": "2024-05-18T17:28:29Z"
    },
    {
        "title": "A Secure and Privacy-Friendly Logging Scheme",
        "link": "http://arxiv.org/abs/2405.11341v1",
        "abstract": "Finding a robust security mechanism for audit trail logging has long been a\npoorly satisfied goal. There are many reasons for this. The most significant of\nthese is that the audit trail is a highly sought after goal of attackers to\nensure that they do not get caught. Thus they have an incredibly strong\nincentive to prevent companies from succeeding in this worthy aim. Regulation,\nsuch as the European Union General Data Protection Regulation, has brought a\nstrong incentive for companies to achieve success in this area due to the\npunitive level of fines that can now be levied in the event of a successful\nbreach by an attacker. We seek to resolve this issue through the use of an\nencrypted audit trail process that saves encrypted records to a true immutable\ndatabase, which can ensure audit trail records are permanently retained in\nencrypted form, with no possibility of the records being compromised. This\nensures compliance with the General Data Protection Regulation can be achieved.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "authors": [
            "Andreas Aßmuth",
            "Robert Duncan",
            "Simon Liebl",
            "Matthias Söllner"
        ],
        "published": "2024-05-18T17:10:48Z"
    },
    {
        "title": "Lowest-order Nonstandard Finite Element Methods for Time-Fractional\n  Biharmonic Problem",
        "link": "http://arxiv.org/abs/2405.11339v1",
        "abstract": "In this work, we consider an initial-boundary value problem for a\ntime-fractional biharmonic equation in a bounded convex polygonal domain in\n$\\mathbb{R}^2$ with clamped boundary conditions. After establishing the\nwell-posedness, we focus on some regularity results of the solution with\nrespect to the regularity of the problem data. The spatially semidiscrete\nscheme covers several popular lowest-order piecewise-quadratic finite element\nschemes, namely, Morley, discontinuous Galerkin, and $C^0$ interior penalty\nmethods, and includes both smooth and nonsmooth initial data. Optimal order\nerror bounds with respect to the regularity assumptions on the data are proved\nfor both homogeneous and nonhomogeneous problems. The numerical experiments\nvalidate the theoretical convergence rate results.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Shantiram Mahata",
            "Neela Nataraj",
            "Jean-Pierre Raymond"
        ],
        "published": "2024-05-18T17:09:57Z"
    },
    {
        "title": "EyeFound: A Multimodal Generalist Foundation Model for Ophthalmic\n  Imaging",
        "link": "http://arxiv.org/abs/2405.11338v2",
        "abstract": "Artificial intelligence (AI) is vital in ophthalmology, tackling tasks like\ndiagnosis, classification, and visual question answering (VQA). However,\nexisting AI models in this domain often require extensive annotation and are\ntask-specific, limiting their clinical utility. While recent developments have\nbrought about foundation models for ophthalmology, they are limited by the need\nto train separate weights for each imaging modality, preventing a comprehensive\nrepresentation of multi-modal features. This highlights the need for versatile\nfoundation models capable of handling various tasks and modalities in\nophthalmology. To address this gap, we present EyeFound, a multimodal\nfoundation model for ophthalmic images. Unlike existing models, EyeFound learns\ngeneralizable representations from unlabeled multimodal retinal images,\nenabling efficient model adaptation across multiple applications. Trained on\n2.78 million images from 227 hospitals across 11 ophthalmic modalities,\nEyeFound facilitates generalist representations and diverse multimodal\ndownstream tasks, even for detecting challenging rare diseases. It outperforms\nprevious work RETFound in diagnosing eye diseases, predicting systemic disease\nincidents, and zero-shot multimodal VQA. EyeFound provides a generalizable\nsolution to improve model performance and lessen the annotation burden on\nexperts, facilitating widespread clinical AI applications for retinal imaging.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Danli Shi",
            "Weiyi Zhang",
            "Xiaolan Chen",
            "Yexin Liu",
            "Jiancheng Yang",
            "Siyu Huang",
            "Yih Chung Tham",
            "Yingfeng Zheng",
            "Mingguang He"
        ],
        "published": "2024-05-18T17:03:39Z"
    },
    {
        "title": "A Unified Approach Towards Active Learning and Out-of-Distribution\n  Detection",
        "link": "http://arxiv.org/abs/2405.11337v1",
        "abstract": "When applying deep learning models in open-world scenarios, active learning\n(AL) strategies are crucial for identifying label candidates from a nearly\ninfinite amount of unlabeled data. In this context, robust out-of-distribution\n(OOD) detection mechanisms are essential for handling data outside the target\ndistribution of the application. However, current works investigate both\nproblems separately. In this work, we introduce SISOM as the first unified\nsolution for both AL and OOD detection. By leveraging feature space distance\nmetrics SISOM combines the strengths of the currently independent tasks to\nsolve both effectively. We conduct extensive experiments showing the problems\narising when migrating between both tasks. In these evaluations SISOM\nunderlined its effectiveness by achieving first place in two of the widely used\nOpenOOD benchmarks and second place in the remaining one. In AL, SISOM\noutperforms others and delivers top-1 performance in three benchmarks",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Sebastian Schmidt",
            "Leonard Schenk",
            "Leo Schwinn",
            "Stephan Günnemann"
        ],
        "published": "2024-05-18T17:02:57Z"
    },
    {
        "title": "UPAM: Unified Prompt Attack in Text-to-Image Generation Models Against\n  Both Textual Filters and Visual Checkers",
        "link": "http://arxiv.org/abs/2405.11336v1",
        "abstract": "Text-to-Image (T2I) models have raised security concerns due to their\npotential to generate inappropriate or harmful images. In this paper, we\npropose UPAM, a novel framework that investigates the robustness of T2I models\nfrom the attack perspective. Unlike most existing attack methods that focus on\ndeceiving textual defenses, UPAM aims to deceive both textual and visual\ndefenses in T2I models. UPAM enables gradient-based optimization, offering\ngreater effectiveness and efficiency than previous methods. Given that T2I\nmodels might not return results due to defense mechanisms, we introduce a\nSphere-Probing Learning (SPL) scheme to support gradient optimization even when\nno results are returned. Additionally, we devise a Semantic-Enhancing Learning\n(SEL) scheme to finetune UPAM for generating target-aligned images. Our\nframework also ensures attack stealthiness. Extensive experiments demonstrate\nUPAM's effectiveness and efficiency.",
        "subjects": [
            "cs.CV",
            "I.2.6"
        ],
        "authors": [
            "Duo Peng",
            "Qiuhong Ke",
            "Jun Liu"
        ],
        "published": "2024-05-18T16:47:36Z"
    },
    {
        "title": "Detecting Complex Multi-step Attacks with Explainable Graph Neural\n  Network",
        "link": "http://arxiv.org/abs/2405.11335v1",
        "abstract": "Complex multi-step attacks have caused significant damage to numerous\ncritical infrastructures. To detect such attacks, graph neural network based\nmethods have shown promising results by modeling the system's events as a\ngraph. However, existing methods still face several challenges when deployed in\npractice. First, there is a lack of sufficient real attack data especially\nconsidering the large volume of normal data. Second, the modeling of event\ngraphs is challenging due to their dynamic and heterogeneous nature. Third, the\nlack of explanation in learning models undermines the trustworthiness of such\nmethods in production environments. To address the above challenges, in this\npaper, we propose an attack detection method, Trace2Vec. The approach first\ndesigns an erosion function to augment rare attack samples, and integrates them\ninto the event graphs. Next, it models the event graphs via a continuous-time\ndynamic heterogeneous graph neural network. Finally, it employs the Monte Carlo\ntree search algorithm to identify events with greater contributions to the\nattack, thus enhancing the explainability of the detection result. We have\nimplemented a prototype for Trace2Vec, and the experimental evaluations\ndemonstrate its superior detection and explanation performance compared to\nexisting methods.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Wei Liu",
            "Peng Gao",
            "Haotian Zhang",
            "Ke Li",
            "Weiyong Yang",
            "Xingshen Wei",
            "Shuji Wu"
        ],
        "published": "2024-05-18T16:47:21Z"
    },
    {
        "title": "GinAR: An End-To-End Multivariate Time Series Forecasting Model Suitable\n  for Variable Missing",
        "link": "http://arxiv.org/abs/2405.11333v1",
        "abstract": "Multivariate time series forecasting (MTSF) is crucial for decision-making to\nprecisely forecast the future values/trends, based on the complex relationships\nidentified from historical observations of multiple sequences. Recently,\nSpatial-Temporal Graph Neural Networks (STGNNs) have gradually become the theme\nof MTSF model as their powerful capability in mining spatial-temporal\ndependencies, but almost of them heavily rely on the assumption of historical\ndata integrity. In reality, due to factors such as data collector failures and\ntime-consuming repairment, it is extremely challenging to collect the whole\nhistorical observations without missing any variable. In this case, STGNNs can\nonly utilize a subset of normal variables and easily suffer from the incorrect\nspatial-temporal dependency modeling issue, resulting in the degradation of\ntheir forecasting performance. To address the problem, in this paper, we\npropose a novel Graph Interpolation Attention Recursive Network (named GinAR)\nto precisely model the spatial-temporal dependencies over the limited collected\ndata for forecasting. In GinAR, it consists of two key components, that is,\ninterpolation attention and adaptive graph convolution to take place of the\nfully connected layer of simple recursive units, and thus are capable of\nrecovering all missing variables and reconstructing the correct\nspatial-temporal dependencies for recursively modeling of multivariate time\nseries data, respectively. Extensive experiments conducted on five real-world\ndatasets demonstrate that GinAR outperforms 11 SOTA baselines, and even when\n90% of variables are missing, it can still accurately predict the future values\nof all variables.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Chengqing Yu",
            "Fei Wang",
            "Zezhi Shao",
            "Tangwen Qian",
            "Zhao Zhang",
            "Wei Wei",
            "Yongjun Xu"
        ],
        "published": "2024-05-18T16:42:44Z"
    },
    {
        "title": "Generalized Multi-Objective Reinforcement Learning with Envelope Updates\n  in URLLC-enabled Vehicular Networks",
        "link": "http://arxiv.org/abs/2405.11331v1",
        "abstract": "We develop a novel multi-objective reinforcement learning (MORL) framework to\njointly optimize wireless network selection and autonomous driving policies in\na multi-band vehicular network operating on conventional sub-6GHz spectrum and\nTerahertz frequencies. The proposed framework is designed to 1. maximize the\ntraffic flow and 2. minimize collisions by controlling the vehicle's motion\ndynamics (i.e., speed and acceleration), and enhance the ultra-reliable\nlow-latency communication (URLLC) while minimizing handoffs (HOs). We cast this\nproblem as a multi-objective Markov Decision Process (MOMDP) and develop\nsolutions for both predefined and unknown preferences of the conflicting\nobjectives. Specifically, deep-Q-network and double deep-Q-network-based\nsolutions are developed first that consider scalarizing the transportation and\ntelecommunication rewards using predefined preferences. We then develop a novel\nenvelope MORL solution which develop policies that address multiple objectives\nwith unknown preferences to the agent. While this approach reduces reliance on\nscalar rewards, policy effectiveness varying with different preferences is a\nchallenge. To address this, we apply a generalized version of the Bellman\nequation and optimize the convex envelope of multi-objective Q values to learn\na unified parametric representation capable of generating optimal policies\nacross all possible preference configurations. Following an initial learning\nphase, our agent can execute optimal policies under any specified preference or\ninfer preferences from minimal data samples.Numerical results validate the\nefficacy of the envelope-based MORL solution and demonstrate interesting\ninsights related to the inter-dependency of vehicle motion dynamics, HOs, and\nthe communication data rate. The proposed policies enable autonomous vehicles\nto adopt safe driving behaviors with improved connectivity.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.NI"
        ],
        "authors": [
            "Zijiang Yan",
            "Hina Tabassum"
        ],
        "published": "2024-05-18T16:31:32Z"
    },
    {
        "title": "SMT-based Symbolic Model-Checking for Operator Precedence Languages",
        "link": "http://arxiv.org/abs/2405.11327v1",
        "abstract": "Operator Precedence Languages (OPL) have been recently identified as a\nsuitable formalism for model checking recursive procedural programs, thanks to\ntheir ability of modeling the program stack. OPL requirements can be expressed\nin the Precedence Oriented Temporal Logic (POTL), which features modalities to\nreason on the natural matching between function calls and returns, exceptions,\nand other advanced programming constructs that previous approaches, such as\nVisibly Pushdown Languages, cannot model effectively. Existing approaches for\nmodel checking of POTL have been designed following the explicit-state,\nautomata-based approach, a feature that severely limits their scalability. In\nthis paper, we give the first symbolic, SMT-based approach for model checking\nPOTL properties. While previous approaches construct the automaton for both the\nPOTL formula and the model of the program, we encode them into a (sequence of)\nSMT formulas. The search of a trace of the model witnessing a violation of the\nformula is then carried out by an SMT-solver, in a Bounded Model Checking\nfashion. We carried out an experimental evaluation, which shows the\neffectiveness of the proposed solution.",
        "subjects": [
            "cs.LO",
            "F.3.1; D.2.4"
        ],
        "authors": [
            "Michele Chiari",
            "Luca Geatti",
            "Nicola Gigante",
            "Matteo Pradella"
        ],
        "published": "2024-05-18T16:07:49Z"
    },
    {
        "title": "On the Trajectory Regularity of ODE-based Diffusion Sampling",
        "link": "http://arxiv.org/abs/2405.11326v1",
        "abstract": "Diffusion-based generative models use stochastic differential equations\n(SDEs) and their equivalent ordinary differential equations (ODEs) to establish\na smooth connection between a complex data distribution and a tractable prior\ndistribution. In this paper, we identify several intriguing trajectory\nproperties in the ODE-based sampling process of diffusion models. We\ncharacterize an implicit denoising trajectory and discuss its vital role in\nforming the coupled sampling trajectory with a strong shape regularity,\nregardless of the generated content. We also describe a dynamic\nprogramming-based scheme to make the time schedule in sampling better fit the\nunderlying trajectory structure. This simple strategy requires minimal\nmodification to any given ODE-based numerical solvers and incurs negligible\ncomputational cost, while delivering superior performance in image generation,\nespecially in $5\\sim 10$ function evaluations.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Defang Chen",
            "Zhenyu Zhou",
            "Can Wang",
            "Chunhua Shen",
            "Siwei Lyu"
        ],
        "published": "2024-05-18T15:59:41Z"
    },
    {
        "title": "Sampling Strategies for Mitigating Bias in Face Synthesis Methods",
        "link": "http://arxiv.org/abs/2405.11320v1",
        "abstract": "Synthetically generated images can be used to create media content or to\ncomplement datasets for training image analysis models. Several methods have\nrecently been proposed for the synthesis of high-fidelity face images; however,\nthe potential biases introduced by such methods have not been sufficiently\naddressed. This paper examines the bias introduced by the widely popular\nStyleGAN2 generative model trained on the Flickr Faces HQ dataset and proposes\ntwo sampling strategies to balance the representation of selected attributes in\nthe generated face images. We focus on two protected attributes, gender and\nage, and reveal that biases arise in the distribution of randomly sampled\nimages against very young and very old age groups, as well as against female\nfaces. These biases are also assessed for different image quality levels based\non the GIQA score. To mitigate bias, we propose two alternative methods for\nsampling on selected lines or spheres of the latent space to increase the\nnumber of generated samples from the under-represented classes. The\nexperimental results show a decrease in bias against underrepresented groups\nand a more uniform distribution of the protected features at different levels\nof image quality.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "68T99",
            "I.2; I.5"
        ],
        "authors": [
            "Emmanouil Maragkoudakis",
            "Symeon Papadopoulos",
            "Iraklis Varlamis",
            "Christos Diou"
        ],
        "published": "2024-05-18T15:30:14Z"
    },
    {
        "title": "Smooth Kolmogorov Arnold networks enabling structural knowledge\n  representation",
        "link": "http://arxiv.org/abs/2405.11318v1",
        "abstract": "Kolmogorov-Arnold Networks (KANs) offer an efficient and interpretable\nalternative to traditional multi-layer perceptron (MLP) architectures due to\ntheir finite network topology. However, according to the results of Kolmogorov\nand Vitushkin, the representation of generic smooth functions by KAN\nimplementations using analytic functions constrained to a finite number of\ncutoff points cannot be exact. Hence, the convergence of KAN throughout the\ntraining process may be limited. This paper explores the relevance of\nsmoothness in KANs, proposing that smooth, structurally informed KANs can\nachieve equivalence to MLPs in specific function classes. By leveraging\ninherent structural knowledge, KANs may reduce the data required for training\nand mitigate the risk of generating hallucinated predictions, thereby enhancing\nmodel reliability and performance in computational biomedicine.",
        "subjects": [
            "cs.LG",
            "cond-mat.dis-nn",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Moein E. Samadi",
            "Younes Müller",
            "Andreas Schuppert"
        ],
        "published": "2024-05-18T15:27:14Z"
    },
    {
        "title": "Neural Randomized Planning for Whole Body Robot Motion",
        "link": "http://arxiv.org/abs/2405.11317v1",
        "abstract": "Robot motion planning has made vast advances over the past decades, but the\nchallenge remains: robot mobile manipulators struggle to plan long-range\nwhole-body motion in common household environments in real time, because of\nhigh-dimensional robot configuration space and complex environment geometry. To\ntackle the challenge, this paper proposes Neural Randomized Planner (NRP),\nwhich combines a global sampling-based motion planning (SBMP) algorithm and a\nlocal neural sampler. Intuitively, NRP uses the search structure inside the\nglobal planner to stitch together learned local sampling distributions to form\na global sampling distribution adaptively. It benefits from both learning and\nplanning. Locally, it tackles high dimensionality by learning to sample in\npromising regions from data, with a rich neural network representation.\nGlobally, it composes the local sampling distributions through planning and\nexploits local geometric similarity to scale up to complex environments.\nExperiments both in simulation and on a real robot show \\NRP yields superior\nperformance compared to some of the best classical and learning-enhanced SBMP\nalgorithms. Further, despite being trained in simulation, NRP demonstrates\nzero-shot transfer to a real robot operating in novel household environments,\nwithout any fine-tuning or manual adaptation.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Yunfan Lu",
            "Yuchen Ma",
            "David Hsu",
            "Caicai Pan"
        ],
        "published": "2024-05-18T15:26:41Z"
    },
    {
        "title": "Securing 3rd Party App Integration in Docker-based Cloud Software\n  Ecosystems",
        "link": "http://arxiv.org/abs/2405.11316v1",
        "abstract": "Open software ecosystems are beneficial for customers; they benefit from 3rd\nparty services and applications, e.g. analysis of data using apps, developed\nand deployed by other companies or open-source communities. One significant\nadvantage of this approach is that other customers may benefit from these newly\ndeveloped applications as well. Especially software ecosystems utilizing\ncontainer technologies are prone to certain risks. Docker, in particular, is\nmore vulnerable to attacks than hypervisor based virtualisation as it directly\noperates on the host system. Docker is a popular representative of\ncontainerisation technology which offers a lightweight architecture in order to\nfacilitate the set-up and creation of such software ecosystems. Popular\nInfrastructure as a Service cloud service providers, like Amazon Web Services\nor Microsoft Azure, jump on the containerisation bandwagon and provide\ninterfaces for provisioning and managing containers. Companies can benefit from\nthat change of technology and create software ecosystems more efficiently. In\nthis paper, we present a new concept for significant security improvements for\ncloud-based software ecosystems using Docker for 3rd party app integration.\nBased on the security features of Docker we describe a secure integration of\napplications in the cloud environment securely. Our approach considers the\nwhole software lifecycle and includes sandbox testing of potentially dangerous\n3rd party apps before these became available to the customers.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "authors": [
            "Christian Binkowski",
            "Stefan Appel",
            "Andreas Aßmuth"
        ],
        "published": "2024-05-18T15:26:38Z"
    },
    {
        "title": "MediCLIP: Adapting CLIP for Few-shot Medical Image Anomaly Detection",
        "link": "http://arxiv.org/abs/2405.11315v1",
        "abstract": "In the field of medical decision-making, precise anomaly detection in medical\nimaging plays a pivotal role in aiding clinicians. However, previous work is\nreliant on large-scale datasets for training anomaly detection models, which\nincreases the development cost. This paper first focuses on the task of medical\nimage anomaly detection in the few-shot setting, which is critically\nsignificant for the medical field where data collection and annotation are both\nvery expensive. We propose an innovative approach, MediCLIP, which adapts the\nCLIP model to few-shot medical image anomaly detection through self-supervised\nfine-tuning. Although CLIP, as a vision-language model, demonstrates\noutstanding zero-/fewshot performance on various downstream tasks, it still\nfalls short in the anomaly detection of medical images. To address this, we\ndesign a series of medical image anomaly synthesis tasks to simulate common\ndisease patterns in medical imaging, transferring the powerful generalization\ncapabilities of CLIP to the task of medical image anomaly detection. When only\nfew-shot normal medical images are provided, MediCLIP achieves state-of-the-art\nperformance in anomaly detection and location compared to other methods.\nExtensive experiments on three distinct medical anomaly detection tasks have\ndemonstrated the superiority of our approach. The code is available at\nhttps://github.com/cnulab/MediCLIP.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ximiao Zhang",
            "Min Xu",
            "Dehui Qiu",
            "Ruixin Yan",
            "Ning Lang",
            "Xiuzhuang Zhou"
        ],
        "published": "2024-05-18T15:24:58Z"
    },
    {
        "title": "Multi-indices coproducts from ODEs to singular SPDEs",
        "link": "http://arxiv.org/abs/2405.11314v1",
        "abstract": "In this work, we introduce explicit formulae for the coproducts at play for\nmulti-indices in ODEs and in singular SPDEs. The two coproducts described\ncorrespond to versions of the Butcher-Connes-Kreimer and extraction/contraction\ncoproducts with multi-indices. The main idea is to use the fact that these\ncoproducts are the adjoints of dual products for which one has explicit simple\nformulae. We are able to derive the explicit formulae via an inner product\ndefined from a symmetry factor easily computable for multi-indices.",
        "subjects": [
            "math.PR",
            "cs.NA",
            "math.AP",
            "math.NA",
            "math.RA"
        ],
        "authors": [
            "Yvain Bruned",
            "Yingtong Hou"
        ],
        "published": "2024-05-18T15:10:10Z"
    },
    {
        "title": "A Dual Power Grid Cascading Failure Model for the Vulnerability Analysis",
        "link": "http://arxiv.org/abs/2405.11311v1",
        "abstract": "Considering the attacks against the power grid, one of the most effective\napproaches could be the attack to the transmission lines that leads to large\ncascading failures. Hence, the problem of locating the most critical or\nvulnerable transmission lines for a Power Grid Cascading Failure (PGCF) has\ndrawn much attention from the research society. There exists many deterministic\nsolutions and stochastic approximation algorithms aiming to analyze the power\ngrid vulnerability. However, it has been challenging to reveal the correlations\nbetween the transmission lines to identify the critical ones. In this paper, we\npropose a novel approach of learning such correlations via attention mechanism\ninspired by the Transformer based models that were initially designated to\nlearn the correlation of words in sentences. Multiple modifications and\nadjustments are proposed to support the attention mechanism producing an\ninformative correlation matrix, the Attention Matrix. With the Attention\nRanking algorithm, we are able to identify the most critical lines. The\nproposed Dual PGCF model provide a novel and effective analysis to improve the\npower grid resilience against cascading failure, which is proved by extensive\nexperiment results.",
        "subjects": [
            "cs.LG",
            "cs.ET"
        ],
        "authors": [
            "Tianxin Zhou",
            "Xiang Li",
            "Haibing Lu"
        ],
        "published": "2024-05-18T15:04:44Z"
    },
    {
        "title": "Propositional dynamic logic and asynchronous cascade decompositions for\n  regular trace languages",
        "link": "http://dx.doi.org/10.1145/3661814.3662110",
        "abstract": "We propose a local, past-oriented fragment of propositional dynamic logic to\nreason about concurrent scenarios modelled as Mazurkiewicz traces, and prove it\nto be expressively complete with respect to regular trace languages. Because of\nlocality, specifications in this logic are efficiently translated into\nasynchronous automata, in a way that reflects the structure of formulas. In\nparticular, we obtain a new proof of Zielonka's fundamental theorem and we\nprove that any regular trace language can be implemented by a cascade product\nof localized asynchronous automata, which essentially operate on a single\nprocess.\n  These results refine earlier results by Adsul et al. which involved a larger\nfragment of past propositional dynamic logic and used Mukund and Sohoni's\ngossip automaton. Our new results avoid using this automaton, or Zielonka's\ntimestamping mechanism and, in particular, they show how to implement a gossip\nautomaton as a cascade product.",
        "subjects": [
            "cs.FL",
            "cs.LO",
            "68Q10, 68Q45, 68Q70",
            "F.1.1; F.4.1; F.4.3"
        ],
        "authors": [
            "Bharat Adsul",
            "Paul Gastin",
            "Shantanu Kulkarni",
            "Pascal Weil"
        ],
        "published": "2024-05-18T14:52:22Z"
    },
    {
        "title": "Large Neighborhood Prioritized Search for Combinatorial Optimization\n  with Answer Set Programming",
        "link": "http://arxiv.org/abs/2405.11305v1",
        "abstract": "We propose Large Neighborhood Prioritized Search (LNPS) for solving\ncombinatorial optimization problems in Answer Set Programming (ASP). LNPS is a\nmetaheuristic that starts with an initial solution and then iteratively tries\nto find better solutions by alternately destroying and prioritized searching\nfor a current solution. Due to the variability of neighborhoods, LNPS allows\nfor flexible search without strongly depending on the destroy operators. We\npresent an implementation of LNPS based on ASP. The resulting heulingo solver\ndemonstrates that LNPS can significantly enhance the solving performance of ASP\nfor optimization. Furthermore, we establish the competitiveness of our LNPS\napproach by empirically contrasting it to (adaptive) large neighborhood search.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Irumi Sugimori",
            "Katsumi Inoue",
            "Hidetomo Nabeshima",
            "Torsten Schaub",
            "Takehide Soh",
            "Naoyuki Tamura",
            "Mutsunori Banbara"
        ],
        "published": "2024-05-18T14:37:43Z"
    },
    {
        "title": "Enhancing Fine-Grained Image Classifications via Cascaded Vision\n  Language Models",
        "link": "http://arxiv.org/abs/2405.11301v1",
        "abstract": "Fine-grained image classification, particularly in zero/few-shot scenarios,\npresents a significant challenge for vision-language models (VLMs), such as\nCLIP. These models often struggle with the nuanced task of distinguishing\nbetween semantically similar classes due to limitations in their pre-trained\nrecipe, which lacks supervision signals for fine-grained categorization. This\npaper introduces CascadeVLM, an innovative framework that overcomes the\nconstraints of previous CLIP-based methods by effectively leveraging the\ngranular knowledge encapsulated within large vision-language models (LVLMs).\nExperiments across various fine-grained image datasets demonstrate that\nCascadeVLM significantly outperforms existing models, specifically on the\nStanford Cars dataset, achieving an impressive 85.6% zero-shot accuracy.\nPerformance gain analysis validates that LVLMs produce more accurate\npredictions for challenging images that CLIPs are uncertain about, bringing the\noverall accuracy boost. Our framework sheds light on a holistic integration of\nVLMs and LVLMs for effective and efficient fine-grained image classification.",
        "subjects": [
            "cs.CL",
            "cs.CV"
        ],
        "authors": [
            "Canshi Wei"
        ],
        "published": "2024-05-18T14:12:04Z"
    },
    {
        "title": "Ensuring Safety at Intelligent Intersections: Temporal Logic Meets\n  Reachability Analysis",
        "link": "http://arxiv.org/abs/2405.11300v1",
        "abstract": "In this work, we propose an approach for ensuring the safety of vehicles\npassing through an intelligent intersection. There are many proposals for the\ndesign of intelligent intersections that introduce central decision-makers to\nintersections for enhancing the efficiency and safety of the vehicles. To\nguarantee the safety of such designs, we develop a safety framework for\nintersections based on temporal logic and reachability analysis. We start by\nspecifying the required behavior for all the vehicles that need to pass through\nthe intersection as linear temporal logic formula. Then, using temporal logic\ntrees, we break down the linear temporal logic specification into a series of\nHamilton-Jacobi reachability analyses in an automated fashion. By successfully\nconstructing the temporal logic tree through reachability analysis, we verify\nthe feasibility of the intersection specification. By taking this approach, we\nenable a safety framework that is able to automatically provide safety\nguarantees on new intersection behavior specifications. To evaluate our\napproach, we implement the framework on a simulated T-intersection, where we\nshow that we can check and guarantee the safety of vehicles with potentially\nconflicting paths.",
        "subjects": [
            "eess.SY",
            "cs.RO",
            "cs.SY"
        ],
        "authors": [
            "Kaj Munhoz Arfvidsson",
            "Frank J. Jiang",
            "Karl H. Johansson",
            "Jonas Mårtensson"
        ],
        "published": "2024-05-18T14:10:31Z"
    },
    {
        "title": "The CAP Principle for LLM Serving",
        "link": "http://arxiv.org/abs/2405.11299v1",
        "abstract": "We survey the large language model (LLM) serving area to understand the\nintricate dynamics between cost-efficiency and accuracy, which is magnified by\nthe growing need for longer contextual understanding when deploying models at a\nmassive scale. Our findings reveal that works in this space optimize along\nthree distinct but conflicting goals: improving serving context length (C),\nimproving serving accuracy (A), and improving serving performance (P). Drawing\ninspiration from the CAP theorem in databases, we propose a CAP principle for\nLLM serving, which suggests that any optimization can improve at most two of\nthese three goals simultaneously. Our survey categorizes existing works within\nthis framework. We find the definition and continuity of user-perceived\nmeasurement metrics are crucial in determining whether a goal has been met,\nakin to prior CAP databases in the wild. We recognize the CAP principle for LLM\nserving as a guiding principle, rather than a formal theorem, to inform\ndesigners of the inherent and dynamic trade-offs in serving models. As serving\naccuracy and performance have been extensively studied, this survey focuses on\nworks that extend serving context length and address the resulting challenges.",
        "subjects": [
            "cs.DB",
            "cs.LG"
        ],
        "authors": [
            "Pai Zeng",
            "Zhenyu Ning",
            "Jieru Zhao",
            "Weihao Cui",
            "Mengwei Xu",
            "Liwei Guo",
            "Xusheng Chen",
            "Yizhou Shan"
        ],
        "published": "2024-05-18T14:00:04Z"
    },
    {
        "title": "Visual Episodic Memory-based Exploration",
        "link": "http://arxiv.org/abs/2405.11298v1",
        "abstract": "In humans, intrinsic motivation is an important mechanism for open-ended\ncognitive development; in robots, it has been shown to be valuable for\nexploration. An important aspect of human cognitive development is\n$\\textit{episodic memory}$ which enables both the recollection of events from\nthe past and the projection of subjective future. This paper explores the use\nof visual episodic memory as a source of intrinsic motivation for robotic\nexploration problems. Using a convolutional recurrent neural network\nautoencoder, the agent learns an efficient representation for spatiotemporal\nfeatures such that accurate sequence prediction can only happen once\nspatiotemporal features have been learned. Structural similarity between ground\ntruth and autoencoder generated images is used as an intrinsic motivation\nsignal to guide exploration. Our proposed episodic memory model also implicitly\naccounts for the agent's actions, motivating the robot to seek new interactive\nexperiences rather than just areas that are visually dissimilar. When guiding\nrobotic exploration, our proposed method outperforms the Curiosity-driven\nVariational Autoencoder (CVAE) at finding dynamic anomalies.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "I.2.9"
        ],
        "authors": [
            "Jack Vice",
            "Natalie Ruiz-Sanchez",
            "Pamela K. Douglas",
            "Gita Sukthankar"
        ],
        "published": "2024-05-18T13:58:47Z"
    },
    {
        "title": "Unveiling Key Aspects of Fine-Tuning in Sentence Embeddings: A\n  Representation Rank Analysis",
        "link": "http://arxiv.org/abs/2405.11297v1",
        "abstract": "The latest advancements in unsupervised learning of sentence embeddings\npredominantly involve employing contrastive learning-based (CL-based)\nfine-tuning over pre-trained language models. In this study, we analyze the\nlatest sentence embedding methods by adopting representation rank as the\nprimary tool of analysis. We first define Phase 1 and Phase 2 of fine-tuning\nbased on when representation rank peaks. Utilizing these phases, we conduct a\nthorough analysis and obtain essential findings across key aspects, including\nalignment and uniformity, linguistic abilities, and correlation between\nperformance and rank. For instance, we find that the dynamics of the key\naspects can undergo significant changes as fine-tuning transitions from Phase 1\nto Phase 2. Based on these findings, we experiment with a rank reduction (RR)\nstrategy that facilitates rapid and stable fine-tuning of the latest CL-based\nmethods. Through empirical investigations, we showcase the efficacy of RR in\nenhancing the performance and stability of five state-of-the-art sentence\nembedding methods.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Euna Jung",
            "Jaeill Kim",
            "Jungmin Ko",
            "Jinwoo Park",
            "Wonjong Rhee"
        ],
        "published": "2024-05-18T13:51:27Z"
    },
    {
        "title": "Medical Image Analysis for Detection, Treatment and Planning of Disease\n  using Artificial Intelligence Approaches",
        "link": "http://dx.doi.org/10.5281/zenodo.10057577",
        "abstract": "X-ray is one of the prevalent image modalities for the detection and\ndiagnosis of the human body. X-ray provides an actual anatomical structure of\nan organ present with disease or absence of disease. Segmentation of disease in\nchest X-ray images is essential for the diagnosis and treatment. In this paper,\na framework for the segmentation of X-ray images using artificial intelligence\ntechniques has been discussed. Here data has been pre-processed and cleaned\nfollowed by segmentation using SegNet and Residual Net approaches to X-ray\nimages. Finally, segmentation has been evaluated using well known metrics like\nLoss, Dice Coefficient, Jaccard Coefficient, Precision, Recall, Binary\nAccuracy, and Validation Accuracy. The experimental results reveal that the\nproposed approach performs better in all respect of well-known parameters with\n16 batch size and 50 epochs. The value of validation accuracy, precision, and\nrecall of SegNet and Residual Unet models are 0.9815, 0.9699, 0.9574, and\n0.9901, 0.9864, 0.9750 respectively.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG",
            "cs.MM"
        ],
        "authors": [
            "Nand Lal Yadav",
            "Satyendra Singh",
            "Rajesh Kumar",
            "Sudhakar Singh"
        ],
        "published": "2024-05-18T13:43:43Z"
    },
    {
        "title": "Serializing Java Objects in Plain Code",
        "link": "http://arxiv.org/abs/2405.11294v2",
        "abstract": "In managed languages, serialization of objects is typically done in bespoke\nbinary formats such as Protobuf, or markup languages such as XML or JSON. The\nmajor limitation of these formats is readability. Human developers cannot read\nbinary code, and in most cases, suffer from the syntax of XML or JSON. This is\na major issue when objects are meant to be embedded and read in source code,\nsuch as in test cases. To address this problem, we propose plain-code\nserialization. Our core idea is to serialize objects observed at runtime in the\nnative syntax of a programming language. We realize this vision in the context\nof Java, and demonstrate a prototype which serializes Java objects to Java\nsource code. The resulting source faithfully reconstructs the objects seen at\nruntime. Our prototype is called ProDJ and is publicly available. We experiment\nwith ProDJ to successfully plain-code serialize 174,699 objects observed during\nthe execution of 4 open-source Java applications. Our performance measurement\nshows that the performance impact is not noticeable.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Julian Wachter",
            "Deepika Tiwari",
            "Martin Monperrus",
            "Benoit Baudry"
        ],
        "published": "2024-05-18T13:40:36Z"
    },
    {
        "title": "InfRS: Incremental Few-Shot Object Detection in Remote Sensing Images",
        "link": "http://arxiv.org/abs/2405.11293v1",
        "abstract": "Recently, the field of few-shot detection within remote sensing imagery has\nwitnessed significant advancements. Despite these progresses, the capacity for\ncontinuous conceptual learning still poses a significant challenge to existing\nmethodologies. In this paper, we explore the intricate task of incremental\nfew-shot object detection in remote sensing images. We introduce a pioneering\nfine-tuningbased technique, termed InfRS, designed to facilitate the\nincremental learning of novel classes using a restricted set of examples, while\nconcurrently preserving the performance on established base classes without the\nneed to revisit previous datasets. Specifically, we pretrain the model using\nabundant data from base classes and then generate a set of class-wise\nprototypes that represent the intrinsic characteristics of the data. In the\nincremental learning stage, we introduce a Hybrid Prototypical Contrastive\n(HPC) encoding module for learning discriminative representations. Furthermore,\nwe develop a prototypical calibration strategy based on the Wasserstein\ndistance to mitigate the catastrophic forgetting problem. Comprehensive\nevaluations on the NWPU VHR-10 and DIOR datasets demonstrate that our model can\neffectively solve the iFSOD problem in remote sensing images. Code will be\nreleased.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Wuzhou Li",
            "Jiawei Zhou",
            "Xiang Li",
            "Yi Cao",
            "Guang Jin",
            "Xuemin Zhang"
        ],
        "published": "2024-05-18T13:39:50Z"
    },
    {
        "title": "MBIAS: Mitigating Bias in Large Language Models While Retaining Context",
        "link": "http://arxiv.org/abs/2405.11290v2",
        "abstract": "In addressing the critical need for safety in Large Language Models (LLMs),\nit is crucial to ensure that the outputs are not only safe but also retain\ntheir contextual accuracy. Many existing LLMs are safe fine-tuned either with\nsafety demonstrations, or rely only on adversarial testing. While able to get\nsafe outputs, they often risk losing contextual meaning as they mitigate bias\nand toxicity. In response, we present MBIAS, a LLM framework instruction\nfine-tuned on a custom dataset specifically designed for safety interventions.\nMBIAS aims to address the significant issues of bias and toxicity in LLMs\ngenerations that typically manifest as underrepresentation or negative\nportrayals across various demographics, including inappropriate linguistic\nmentions and biased content in social media. We experiment on MBIAS for safety\ninterventions using various configurations, and demonstrate more than a 30\\%\nreduction in overall bias and toxicity while successfully retaining key\ninformation. Additionally, a demographic analysis on an out-of-distribution\ntest set confirms the robustness of our approach, with reductions in bias and\ntoxicity exceeding 90\\% across various demographics. The dataset and\ninstruction fine-tuned MBIAS are made available to the research community at\nhttps://huggingface.co/newsmediabias/MBIAS.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Shaina Raza",
            "Ananya Raval",
            "Veronica Chatrath"
        ],
        "published": "2024-05-18T13:31:12Z"
    },
    {
        "title": "Diffusion Model Driven Test-Time Image Adaptation for Robust Skin Lesion\n  Classification",
        "link": "http://arxiv.org/abs/2405.11289v1",
        "abstract": "Deep learning-based diagnostic systems have demonstrated potential in skin\ndisease diagnosis. However, their performance can easily degrade on test\ndomains due to distribution shifts caused by input-level corruptions, such as\nimaging equipment variability, brightness changes, and image blur. This will\nreduce the reliability of model deployment in real-world scenarios. Most\nexisting solutions focus on adapting the source model through retraining on\ndifferent target domains. Although effective, this retraining process is\nsensitive to the amount of data and the hyperparameter configuration for\noptimization. In this paper, we propose a test-time image adaptation method to\nenhance the accuracy of the model on test data by simultaneously updating and\npredicting test images. We modify the target test images by projecting them\nback to the source domain using a diffusion model. Specifically, we design a\nstructure guidance module that adds refinement operations through low-pass\nfiltering during reverse sampling, regularizing the diffusion to preserve\nstructural information. Additionally, we introduce a self-ensembling scheme\nautomatically adjusts the reliance on adapted and unadapted inputs, enhancing\nadaptation robustness by rejecting inappropriate generative modeling results.\nTo facilitate this study, we constructed the ISIC2019-C and Dermnet-C\ncorruption robustness evaluation benchmarks. Extensive experiments on the\nproposed benchmarks demonstrate that our method makes the classifier more\nrobust across various corruptions, architectures, and data regimes. Our\ndatasets and code will be available at\n\\url{https://github.com/minghu0830/Skin-TTA_Diffusion}.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Ming Hu",
            "Siyuan Yan",
            "Peng Xia",
            "Feilong Tang",
            "Wenxue Li",
            "Peibo Duan",
            "Lin Zhang",
            "Zongyuan Ge"
        ],
        "published": "2024-05-18T13:28:51Z"
    },
    {
        "title": "Motion Avatar: Generate Human and Animal Avatars with Arbitrary Motion",
        "link": "http://arxiv.org/abs/2405.11286v1",
        "abstract": "In recent years, there has been significant interest in creating 3D avatars\nand motions, driven by their diverse applications in areas like film-making,\nvideo games, AR/VR, and human-robot interaction. However, current efforts\nprimarily concentrate on either generating the 3D avatar mesh alone or\nproducing motion sequences, with integrating these two aspects proving to be a\npersistent challenge. Additionally, while avatar and motion generation\npredominantly target humans, extending these techniques to animals remains a\nsignificant challenge due to inadequate training data and methods. To bridge\nthese gaps, our paper presents three key contributions. Firstly, we proposed a\nnovel agent-based approach named Motion Avatar, which allows for the automatic\ngeneration of high-quality customizable human and animal avatars with motions\nthrough text queries. The method significantly advanced the progress in dynamic\n3D character generation. Secondly, we introduced a LLM planner that coordinates\nboth motion and avatar generation, which transforms a discriminative planning\ninto a customizable Q&A fashion. Lastly, we presented an animal motion dataset\nnamed Zoo-300K, comprising approximately 300,000 text-motion pairs across 65\nanimal categories and its building pipeline ZooGen, which serves as a valuable\nresource for the community. See project website\nhttps://steve-zeyu-zhang.github.io/MotionAvatar/",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zeyu Zhang",
            "Yiran Wang",
            "Biao Wu",
            "Shuo Chen",
            "Zhiyuan Zhang",
            "Shiya Huang",
            "Wenbo Zhang",
            "Meng Fang",
            "Ling Chen",
            "Yang Zhao"
        ],
        "published": "2024-05-18T13:21:14Z"
    },
    {
        "title": "The Logic of Counterfactuals and the Epistemology of Causal Inference",
        "link": "http://arxiv.org/abs/2405.11284v1",
        "abstract": "The 2021 Nobel Prize in Economics recognized a theory of causal inference,\nwhich deserves more attention from philosophers. To that end, I develop a\ndialectic that extends the Lewis-Stalnaker debate on a logical principle called\nConditional Excluded Middle (CEM). I first play the good cop for CEM, and give\na new argument for it: a Quine-Putnam indispensability argument based on the\nNobel-Prize winning theory. But then I switch sides and play the bad cop: I\nundermine that argument with a new theory of causal inference that preserves\nthe success of the original theory but dispenses with CEM.",
        "subjects": [
            "cs.AI",
            "stat.OT"
        ],
        "authors": [
            "Hanti Lin"
        ],
        "published": "2024-05-18T13:09:33Z"
    },
    {
        "title": "Estimating the Level of Dialectness Predicts Interannotator Agreement in\n  Multi-dialect Arabic Datasets",
        "link": "http://arxiv.org/abs/2405.11282v1",
        "abstract": "On annotating multi-dialect Arabic datasets, it is common to randomly assign\nthe samples across a pool of native Arabic speakers. Recent analyses\nrecommended routing dialectal samples to native speakers of their respective\ndialects to build higher-quality datasets. However, automatically identifying\nthe dialect of samples is hard. Moreover, the pool of annotators who are native\nspeakers of specific Arabic dialects might be scarce. Arabic Level of\nDialectness (ALDi) was recently introduced as a quantitative variable that\nmeasures how sentences diverge from Standard Arabic. On randomly assigning\nsamples to annotators, we hypothesize that samples of higher ALDi scores are\nharder to label especially if they are written in dialects that the annotators\ndo not speak. We test this by analyzing the relation between ALDi scores and\nthe annotators' agreement, on 15 public datasets having raw individual sample\nannotations for various sentence-classification tasks. We find strong evidence\nsupporting our hypothesis for 11 of them. Consequently, we recommend\nprioritizing routing samples of high ALDi scores to native speakers of each\nsample's dialect, for which the dialect could be automatically identified at\nhigher accuracies.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Amr Keleg",
            "Walid Magdy",
            "Sharon Goldwater"
        ],
        "published": "2024-05-18T12:58:02Z"
    },
    {
        "title": "Cooperative Cognitive Dynamic System in UAV Swarms: Reconfigurable\n  Mechanism and Framework",
        "link": "http://arxiv.org/abs/2405.11281v1",
        "abstract": "As the demands for immediate and effective responses increase in both\ncivilian and military domains, the unmanned aerial vehicle (UAV) swarms emerge\nas effective solutions, in which multiple cooperative UAVs can work together to\nachieve specific goals. However, how to manage such complex systems to ensure\nreal-time adaptability lack sufficient researches. Hence, in this paper, we\npropose the cooperative cognitive dynamic system (CCDS), to optimize the\nmanagement for UAV swarms. CCDS leverages a hierarchical and cooperative\ncontrol structure that enables real-time data processing and decision.\nAccordingly, CCDS optimizes the UAV swarm management via dynamic\nreconfigurability and adaptive intelligent optimization. In addition, CCDS can\nbe integrated with the biomimetic mechanism to efficiently allocate tasks for\nUAV swarms. Further, the distributed coordination of CCDS ensures reliable and\nresilient control, thus enhancing the adaptability and robustness. Finally, the\npotential challenges and future directions are analyzed, to provide insights\ninto managing UAV swarms in dynamic heterogeneous networking.",
        "subjects": [
            "cs.DC",
            "cs.AI"
        ],
        "authors": [
            "Ziye Jia",
            "Jiahao You",
            "Chao Dong",
            "Qihui Wu",
            "Fuhui Zhou",
            "Dusit Niyato",
            "Zhu Han"
        ],
        "published": "2024-05-18T12:45:00Z"
    },
    {
        "title": "Joint Analysis of Single-Cell Data across Cohorts with Missing\n  Modalities",
        "link": "http://arxiv.org/abs/2405.11280v1",
        "abstract": "Joint analysis of multi-omic single-cell data across cohorts has\nsignificantly enhanced the comprehensive analysis of cellular processes.\nHowever, most of the existing approaches for this purpose require access to\nsamples with complete modality availability, which is impractical in many\nreal-world scenarios. In this paper, we propose (Single-Cell Cross-Cohort\nCross-Category) integration, a novel framework that learns unified cell\nrepresentations under domain shift without requiring full-modality reference\nsamples. Our generative approach learns rich cross-modal and cross-domain\nrelationships that enable imputation of these missing modalities. Through\nexperiments on real-world multi-omic datasets, we demonstrate that offers a\nrobust solution to single-cell tasks such as cell type clustering, cell type\nclassification, and feature imputation.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Marianne Arriola",
            "Weishen Pan",
            "Manqi Zhou",
            "Qiannan Zhang",
            "Chang Su",
            "Fei Wang"
        ],
        "published": "2024-05-18T12:32:21Z"
    },
    {
        "title": "Action Controlled Paraphrasing",
        "link": "http://arxiv.org/abs/2405.11277v1",
        "abstract": "Recent studies have demonstrated the potential to control paraphrase\ngeneration, such as through syntax, which has broad applications in various\ndownstream tasks. However, these methods often require detailed parse trees or\nsyntactic exemplars, which are not user-friendly. Furthermore, an inference gap\nexists, as control specifications are only available during training but not\ninference. In this work, we propose a new setup for controlled paraphrasing.\nSpecifically, we represent user-intended actions as action tokens, allowing\nembedding and concatenating them with text embeddings, thus flowing together to\na self-attention encoder for representation fusion. To address the inference\ngap, we introduce an optional action token as a placeholder that encourages the\nmodel to determine the appropriate action when control specifications are\ninaccessible. Experimental results show that our method successfully enables\nspecific action-controlled paraphrasing and preserves the same or even better\nperformance compared to conventional uncontrolled methods when actions are not\ngiven. Our findings thus promote the concept of optional action control for a\nmore user-centered design via representation learning.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Ning Shi",
            "Zijun Wu",
            "Lili Mou"
        ],
        "published": "2024-05-18T12:26:31Z"
    },
    {
        "title": "Visible and Clear: Finding Tiny Objects in Difference Map",
        "link": "http://arxiv.org/abs/2405.11276v1",
        "abstract": "Tiny object detection is one of the key challenges in the field of object\ndetection. The performance of most generic detectors dramatically decreases in\ntiny object detection tasks. The main challenge lies in extracting effective\nfeatures of tiny objects. Existing methods usually perform generation-based\nfeature enhancement, which is seriously affected by spurious textures and\nartifacts, making it difficult to make the tiny-object-specific features\nvisible and clear for detection. To address this issue, we propose a\nself-reconstructed tiny object detection (SR-TOD) framework. We for the first\ntime introduce a self-reconstruction mechanism in the detection model, and\ndiscover the strong correlation between it and the tiny objects. Specifically,\nwe impose a reconstruction head in-between the neck of a detector, constructing\na difference map of the reconstructed image and the input, which shows high\nsensitivity to tiny objects. This inspires us to enhance the weak\nrepresentations of tiny objects under the guidance of the difference maps.\nThus, improving the visibility of tiny objects for the detectors. Building on\nthis, we further develop a Difference Map Guided Feature Enhancement (DGFE)\nmodule to make the tiny feature representation more clear. In addition, we\nfurther propose a new multi-instance anti-UAV dataset, which is called\nDroneSwarms dataset and contains a large number of tiny drones with the\nsmallest average size to date. Extensive experiments on the DroneSwarms dataset\nand other datasets demonstrate the effectiveness of the proposed method. The\ncode and dataset will be publicly available.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Bing Cao",
            "Haiyu Yao",
            "Pengfei Zhu",
            "Qinghua Hu"
        ],
        "published": "2024-05-18T12:22:26Z"
    },
    {
        "title": "Predicting and Explaining Hearing Aid Usage Using Encoder-Decoder with\n  Attention Mechanism and SHAP",
        "link": "http://dx.doi.org/10.1109/SITIS57111.2022.00053",
        "abstract": "It is essential to understand the personal, behavioral, environmental, and\nother factors that correlate with optimal hearing aid fitting and hearing aid\nusers' experiences in order to improve hearing loss patient satisfaction and\nquality of life, as well as reduce societal and financial burdens. This work\nproposes a novel framework that uses Encoder-decoder with attention mechanism\n(attn-ED) for predicting future hearing aid usage and SHAP to explain the\nfactors contributing to this prediction. It has been demonstrated in\nexperiments that attn-ED performs well at predicting future hearing aid usage,\nand that SHAP can be utilized to calculate the contribution of different\nfactors affecting hearing aid usage. This framework aims to establish\nconfidence that AI models can be utilized in the medical domain with the use of\nXAI methods. Moreover, the proposed framework can also assist clinicians in\ndetermining the nature of interventions.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Qiqi Su",
            "Eleftheria Iliadou"
        ],
        "published": "2024-05-18T12:19:16Z"
    },
    {
        "title": "Uni-MoE: Scaling Unified Multimodal LLMs with Mixture of Experts",
        "link": "http://arxiv.org/abs/2405.11273v1",
        "abstract": "Recent advancements in Multimodal Large Language Models (MLLMs) underscore\nthe significance of scalable models and data to boost performance, yet this\noften incurs substantial computational costs. Although the Mixture of Experts\n(MoE) architecture has been employed to efficiently scale large language and\nimage-text models, these efforts typically involve fewer experts and limited\nmodalities. To address this, our work presents the pioneering attempt to\ndevelop a unified MLLM with the MoE architecture, named Uni-MoE that can handle\na wide array of modalities. Specifically, it features modality-specific\nencoders with connectors for a unified multimodal representation. We also\nimplement a sparse MoE architecture within the LLMs to enable efficient\ntraining and inference through modality-level data parallelism and expert-level\nmodel parallelism. To enhance the multi-expert collaboration and\ngeneralization, we present a progressive training strategy: 1) Cross-modality\nalignment using various connectors with different cross-modality data, 2)\nTraining modality-specific experts with cross-modality instruction data to\nactivate experts' preferences, and 3) Tuning the Uni-MoE framework utilizing\nLow-Rank Adaptation (LoRA) on mixed multimodal instruction data. We evaluate\nthe instruction-tuned Uni-MoE on a comprehensive set of multimodal datasets.\nThe extensive experimental results demonstrate Uni-MoE's principal advantage of\nsignificantly reducing performance bias in handling mixed multimodal datasets,\nalongside improved multi-expert collaboration and generalization. Our findings\nhighlight the substantial potential of MoE frameworks in advancing MLLMs and\nthe code is available at\nhttps://github.com/HITsz-TMG/UMOE-Scaling-Unified-Multimodal-LLMs.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "cs.MM"
        ],
        "authors": [
            "Yunxin Li",
            "Shenyuan Jiang",
            "Baotian Hu",
            "Longyue Wang",
            "Wanqi Zhong",
            "Wenhan Luo",
            "Lin Ma",
            "Min Zhang"
        ],
        "published": "2024-05-18T12:16:01Z"
    },
    {
        "title": "Double Correction Framework for Denoising Recommendation",
        "link": "http://arxiv.org/abs/2405.11272v1",
        "abstract": "As its availability and generality in online services, implicit feedback is\nmore commonly used in recommender systems. However, implicit feedback usually\npresents noisy samples in real-world recommendation scenarios (such as\nmisclicks or non-preferential behaviors), which will affect precise user\npreference learning. To overcome the noisy samples problem, a popular solution\nis based on dropping noisy samples in the model training phase, which follows\nthe observation that noisy samples have higher training losses than clean\nsamples. Despite the effectiveness, we argue that this solution still has\nlimits. (1) High training losses can result from model optimization instability\nor hard samples, not just noisy samples. (2) Completely dropping of noisy\nsamples will aggravate the data sparsity, which lacks full data exploitation.\nTo tackle the above limitations, we propose a Double Correction Framework for\nDenoising Recommendation (DCF), which contains two correction components from\nviews of more precise sample dropping and avoiding more sparse data. In the\nsample dropping correction component, we use the loss value of the samples over\ntime to determine whether it is noise or not, increasing dropping stability.\nInstead of averaging directly, we use the damping function to reduce the bias\neffect of outliers. Furthermore, due to the higher variance exhibited by hard\nsamples, we derive a lower bound for the loss through concentration inequality\nto identify and reuse hard samples. In progressive label correction, we\niteratively re-label highly deterministic noisy samples and retrain them to\nfurther improve performance. Finally, extensive experimental results on three\ndatasets and four backbones demonstrate the effectiveness and generalization of\nour proposed framework.",
        "subjects": [
            "cs.IR",
            "cs.AI"
        ],
        "authors": [
            "Zhuangzhuang He",
            "Yifan Wang",
            "Yonghui Yang",
            "Peijie Sun",
            "Le Wu",
            "Haoyue Bai",
            "Jinqi Gong",
            "Richang Hong",
            "Min Zhang"
        ],
        "published": "2024-05-18T12:15:10Z"
    },
    {
        "title": "HR Human: Modeling Human Avatars with Triangular Mesh and\n  High-Resolution Textures from Videos",
        "link": "http://arxiv.org/abs/2405.11270v1",
        "abstract": "Recently, implicit neural representation has been widely used to generate\nanimatable human avatars. However, the materials and geometry of those\nrepresentations are coupled in the neural network and hard to edit, which\nhinders their application in traditional graphics engines. We present a\nframework for acquiring human avatars that are attached with high-resolution\nphysically-based material textures and triangular mesh from monocular video.\nOur method introduces a novel information fusion strategy to combine the\ninformation from the monocular video and synthesize virtual multi-view images\nto tackle the sparsity of the input view. We reconstruct humans as deformable\nneural implicit surfaces and extract triangle mesh in a well-behaved pose as\nthe initial mesh of the next stage. In addition, we introduce an approach to\ncorrect the bias for the boundary and size of the coarse mesh extracted.\nFinally, we adapt prior knowledge of the latent diffusion model at\nsuper-resolution in multi-view to distill the decomposed texture. Experiments\nshow that our approach outperforms previous representations in terms of high\nfidelity, and this explicit result supports deployment on common renderers.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Qifeng Chen",
            "Rengan Xie",
            "Kai Huang",
            "Qi Wang",
            "Wenting Zheng",
            "Rong Li",
            "Yuchi Huo"
        ],
        "published": "2024-05-18T11:49:09Z"
    },
    {
        "title": "Concurrent Games over Relational Structures: The Origin of Game Comonads",
        "link": "http://arxiv.org/abs/2405.11267v1",
        "abstract": "Spoiler-Duplicator games are used in finite model theory to examine the\nexpressive power of logics. Their strategies have recently been reformulated as\ncoKleisli maps of game comonads over relational structures, providing new\nresults in finite model theory via categorical techniques. We present a novel\nframework for studying Spoiler-Duplicator games by viewing them as event\nstructures. We introduce a first systematic method for constructing comonads\nfor all one-sided Spoiler-Duplicator games: game comonads are now realised by\nadjunctions to a category of games, generically constructed from a comonad in a\nbicategory of game schema (called signature games). Maps of the constructed\ncategories of games are strategies and generalise coKleisli maps of game\ncomonads; in the case of one-sided games they are shown to coincide with\nsuitably generalised homomorphisms. Finally, we provide characterisations of\nstrategies on two-sided Spoiler-Duplicator games; in a common special case they\ncoincide with spans of event structures.",
        "subjects": [
            "cs.LO",
            "cs.PL",
            "math.CT"
        ],
        "authors": [
            "Yoàv Montacute",
            "Glynn Winskel"
        ],
        "published": "2024-05-18T11:34:05Z"
    },
    {
        "title": "EnviroExam: Benchmarking Environmental Science Knowledge of Large\n  Language Models",
        "link": "http://arxiv.org/abs/2405.11265v1",
        "abstract": "In the field of environmental science, it is crucial to have robust\nevaluation metrics for large language models to ensure their efficacy and\naccuracy. We propose EnviroExam, a comprehensive evaluation method designed to\nassess the knowledge of large language models in the field of environmental\nscience. EnviroExam is based on the curricula of top international\nuniversities, covering undergraduate, master's, and doctoral courses, and\nincludes 936 questions across 42 core courses. By conducting 0-shot and 5-shot\ntests on 31 open-source large language models, EnviroExam reveals the\nperformance differences among these models in the domain of environmental\nscience and provides detailed evaluation standards. The results show that 61.3%\nof the models passed the 5-shot tests, while 48.39% passed the 0-shot tests. By\nintroducing the coefficient of variation as an indicator, we evaluate the\nperformance of mainstream open-source large language models in environmental\nscience from multiple perspectives, providing effective criteria for selecting\nand fine-tuning language models in this field. Future research will involve\nconstructing more domain-specific test sets using specialized environmental\nscience textbooks to further enhance the accuracy and specificity of the\nevaluation.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Yu Huang",
            "Liang Guo",
            "Wanqian Guo",
            "Zhe Tao",
            "Yang Lv",
            "Zhihao Sun",
            "Dongfang Zhao"
        ],
        "published": "2024-05-18T11:31:03Z"
    },
    {
        "title": "Cross-Language Assessment of Mathematical Capability of ChatGPT",
        "link": "http://arxiv.org/abs/2405.11264v1",
        "abstract": "This paper presents an evaluation of the mathematical capability of ChatGPT\nacross diverse languages like Hindi, Gujarati, and Marathi. ChatGPT, based on\nGPT-3.5 by OpenAI, has garnered significant attention for its natural language\nunderstanding and generation abilities. However, its performance in solving\nmathematical problems across multiple natural languages remains a comparatively\nunexplored area, especially in regional Indian languages. In this paper, we\nexplore those capabilities as well as using chain-of-thought prompting to\nfigure out if it increases the accuracy of responses as much as it does in the\nEnglish language and provide insights into the current limitations.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Gargi Sathe",
            "Aneesh Shamraj",
            "Aditya Surve",
            "Nahush Patil",
            "Kumkum Saxena"
        ],
        "published": "2024-05-18T11:29:19Z"
    },
    {
        "title": "Few-Shot API Attack Detection: Overcoming Data Scarcity with\n  GAN-Inspired Learning",
        "link": "http://arxiv.org/abs/2405.11258v1",
        "abstract": "Web applications and APIs face constant threats from malicious actors seeking\nto exploit vulnerabilities for illicit gains. These threats necessitate robust\nanomaly detection systems capable of identifying malicious API traffic\nefficiently despite limited and diverse datasets. This paper proposes a novel\nfew-shot detection approach motivated by Natural Language Processing (NLP) and\nadvanced Generative Adversarial Network (GAN)-inspired techniques. Leveraging\nstate-of-the-art Transformer architectures, particularly RoBERTa, our method\nenhances the contextual understanding of API requests, leading to improved\nanomaly detection compared to traditional methods. We showcase the technique's\nversatility by demonstrating its effectiveness with both Out-of-Distribution\n(OOD) and Transformer-based binary classification methods on two distinct\ndatasets: CSIC 2010 and ATRDF 2023. Our evaluations reveal consistently\nenhanced or, at worst, equivalent detection rates across various metrics in\nmost vectors, highlighting the promise of our approach for improving API\nsecurity.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Udi Aharon",
            "Revital Marbel",
            "Ran Dubin",
            "Amit Dvir",
            "Chen Hajaj"
        ],
        "published": "2024-05-18T11:10:45Z"
    },
    {
        "title": "PS6D: Point Cloud Based Symmetry-Aware 6D Object Pose Estimation in\n  Robot Bin-Picking",
        "link": "http://arxiv.org/abs/2405.11257v1",
        "abstract": "6D object pose estimation holds essential roles in various fields,\nparticularly in the grasping of industrial workpieces. Given challenges like\nrust, high reflectivity, and absent textures, this paper introduces a point\ncloud based pose estimation framework (PS6D). PS6D centers on slender and\nmulti-symmetric objects. It extracts multi-scale features through an\nattention-guided feature extraction module, designs a symmetry-aware rotation\nloss and a center distance sensitive translation loss to regress the pose of\neach point to the centroid of the instance, and then uses a two-stage\nclustering method to complete instance segmentation and pose estimation.\nObjects from the Sil\\'eane and IPA datasets and typical workpieces from\nindustrial practice are used to generate data and evaluate the algorithm. In\ncomparison to the state-of-the-art approach, PS6D demonstrates an 11.5\\%\nimprovement in F$_{1_{inst}}$ and a 14.8\\% improvement in Recall. The main part\nof PS6D has been deployed to the software of Mech-Mind, and achieves a 91.7\\%\nsuccess rate in bin-picking experiments, marking its application in industrial\npose estimation tasks.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Yifan Yang",
            "Zhihao Cui",
            "Qianyi Zhang",
            "Jingtai Liu"
        ],
        "published": "2024-05-18T11:09:56Z"
    },
    {
        "title": "WisPerMed at \"Discharge Me!\": Advancing Text Generation in Healthcare\n  with Large Language Models, Dynamic Expert Selection, and Priming Techniques\n  on MIMIC-IV",
        "link": "http://arxiv.org/abs/2405.11255v1",
        "abstract": "This study aims to leverage state of the art language models to automate\ngenerating the \"Brief Hospital Course\" and \"Discharge Instructions\" sections of\nDischarge Summaries from the MIMIC-IV dataset, reducing clinicians'\nadministrative workload. We investigate how automation can improve\ndocumentation accuracy, alleviate clinician burnout, and enhance operational\nefficacy in healthcare facilities. This research was conducted within our\nparticipation in the Shared Task Discharge Me! at BioNLP @ ACL 2024. Various\nstrategies were employed, including few-shot learning, instruction tuning, and\nDynamic Expert Selection (DES), to develop models capable of generating the\nrequired text sections. Notably, utilizing an additional clinical\ndomain-specific dataset demonstrated substantial potential to enhance clinical\nlanguage processing. The DES method, which optimizes the selection of text\noutputs from multiple predictions, proved to be especially effective. It\nachieved the highest overall score of 0.332 in the competition, surpassing\nsingle-model outputs. This finding suggests that advanced deep learning methods\nin combination with DES can effectively automate parts of electronic health\nrecord documentation. These advancements could enhance patient care by freeing\nclinician time for patient interactions. The integration of text selection\nstrategies represents a promising avenue for further research.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Hendrik Damm",
            "Tabea M. G. Pakull",
            "Bahadır Eryılmaz",
            "Helmut Becker",
            "Ahmad Idrissi-Yaghir",
            "Henning Schäfer",
            "Sergej Schultenkämper",
            "Christoph M. Friedrich"
        ],
        "published": "2024-05-18T10:56:45Z"
    },
    {
        "title": "Dreamer XL: Towards High-Resolution Text-to-3D Generation via Trajectory\n  Score Matching",
        "link": "http://arxiv.org/abs/2405.11252v1",
        "abstract": "In this work, we propose a novel Trajectory Score Matching (TSM) method that\naims to solve the pseudo ground truth inconsistency problem caused by the\naccumulated error in Interval Score Matching (ISM) when using the Denoising\nDiffusion Implicit Models (DDIM) inversion process. Unlike ISM which adopts the\ninversion process of DDIM to calculate on a single path, our TSM method\nleverages the inversion process of DDIM to generate two paths from the same\nstarting point for calculation. Since both paths start from the same starting\npoint, TSM can reduce the accumulated error compared to ISM, thus alleviating\nthe problem of pseudo ground truth inconsistency. TSM enhances the stability\nand consistency of the model's generated paths during the distillation process.\nWe demonstrate this experimentally and further show that ISM is a special case\nof TSM. Furthermore, to optimize the current multi-stage optimization process\nfrom high-resolution text to 3D generation, we adopt Stable Diffusion XL for\nguidance. In response to the issues of abnormal replication and splitting\ncaused by unstable gradients during the 3D Gaussian splatting process when\nusing Stable Diffusion XL, we propose a pixel-by-pixel gradient clipping\nmethod. Extensive experiments show that our model significantly surpasses the\nstate-of-the-art models in terms of visual quality and performance. Code:\n\\url{https://github.com/xingy038/Dreamer-XL}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xingyu Miao",
            "Haoran Duan",
            "Varun Ojha",
            "Jun Song",
            "Tejal Shah",
            "Yang Long",
            "Rajiv Ranjan"
        ],
        "published": "2024-05-18T10:41:57Z"
    },
    {
        "title": "Argumentative Causal Discovery",
        "link": "http://arxiv.org/abs/2405.11250v1",
        "abstract": "Causal discovery amounts to unearthing causal relationships amongst features\nin data. It is a crucial companion to causal inference, necessary to build\nscientific knowledge without resorting to expensive or impossible randomised\ncontrol trials. In this paper, we explore how reasoning with symbolic\nrepresentations can support causal discovery. Specifically, we deploy\nassumption-based argumentation (ABA), a well-established and powerful knowledge\nrepresentation formalism, in combination with causality theories, to learn\ngraphs which reflect causal dependencies in the data. We prove that our method\nexhibits desirable properties, notably that, under natural conditions, it can\nretrieve ground-truth causal graphs. We also conduct experiments with an\nimplementation of our method in answer set programming (ASP) on four datasets\nfrom standard benchmarks in causal discovery, showing that our method compares\nwell against established baselines.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Fabrizio Russo",
            "Anna Rapberger",
            "Francesca Toni"
        ],
        "published": "2024-05-18T10:34:34Z"
    },
    {
        "title": "Few-Shot API Attack Anomaly Detection in a Classification-by-Retrieval\n  Framework",
        "link": "http://arxiv.org/abs/2405.11247v1",
        "abstract": "Application Programming Interface (API) attacks refer to the unauthorized or\nmalicious use of APIs, which are often exploited to gain access to sensitive\ndata or manipulate online systems for illicit purposes. Identifying actors that\ndeceitfully utilize an API poses a demanding problem. Although there have been\nnotable advancements and contributions in the field of API security, there\nstill remains a significant challenge when dealing with attackers who use novel\napproaches that don't match the well-known payloads commonly seen in attacks.\nAlso, attackers may exploit standard functionalities in unconventional manners\nand with objectives surpassing their intended boundaries. This means API\nsecurity needs to be more sophisticated and dynamic than ever, with advanced\ncomputational intelligence methods, such as machine learning models that can\nquickly identify and respond to anomalous behavior. In response to these\nchallenges, we propose a novel few-shot anomaly detection framework, named\nFT-ANN. This framework is composed of two parts: First, we train a dedicated\ngeneric language model for API based on FastText embedding. Next, we use\nApproximate Nearest Neighbor search in a classification-by-retrieval approach.\nOur framework enables the development of a lightweight model that can be\ntrained with minimal examples per class or even a model capable of classifying\nmultiple classes. The results show that our framework effectively improves API\nattack detection accuracy compared to various baselines.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Udi Aharon",
            "Ran Dubin",
            "Amit Dvir",
            "Chen Hajaj"
        ],
        "published": "2024-05-18T10:15:31Z"
    },
    {
        "title": "Dynamic Quantum Key Distribution for Microgrids with Distributed Error\n  Correction",
        "link": "http://arxiv.org/abs/2405.11245v1",
        "abstract": "Quantum key distribution (QKD) has often been hailed as a reliable technology\nfor secure communication in cyber-physical microgrids. Even though unauthorized\nkey measurements are not possible in QKD, attempts to read them can disturb\nquantum states leading to mutations in the transmitted value. Further,\ninaccurate quantum keys can lead to erroneous decryption producing garbage\nvalues, destabilizing microgrid operation. QKD can also be vulnerable to\nnode-level manipulations incorporating attack values into measurements before\nthey are encrypted at the communication layer. To address these issues, this\npaper proposes a secure QKD protocol that can identify errors in keys and/or\nnodal measurements by observing violations in control dynamics. Additionally,\nthe protocol uses a dynamic adjacency matrix-based formulation strategy\nenabling the affected nodes to reconstruct a trustworthy signal and replace it\nwith the attacked signal in a multi-hop manner. This enables microgrids to\nperform nominal operations in the presence of adversaries who try to eavesdrop\non the system causing an increase in the quantum bit error rate (QBER). We\nprovide several case studies to showcase the robustness of the proposed\nstrategy against eavesdroppers and node manipulations. The results demonstrate\nthat it can resist unwanted observation and attack vectors that manipulate\nsignals before encryption.",
        "subjects": [
            "cs.CR",
            "quant-ph"
        ],
        "authors": [
            "Suman Rath",
            "Neel Kanth Kundu",
            "Subham Sahoo"
        ],
        "published": "2024-05-18T10:10:47Z"
    },
    {
        "title": "Case-Based Reasoning Approach for Solving Financial Question Answering",
        "link": "http://arxiv.org/abs/2405.13044v1",
        "abstract": "Measuring a machine's understanding of human language often involves\nassessing its reasoning skills, i.e. logical process of deriving answers to\nquestions. While recent language models have shown remarkable proficiency in\ntext based tasks, their efficacy in complex reasoning problems involving\nheterogeneous information such as text, tables, and numbers remain uncertain.\nAddressing this gap, FinQA introduced a numerical reasoning dataset for\nfinancial documents and simultaneously proposed a program generation approach .\nOur investigation reveals that half of the errors (48%) stem from incorrect\noperations being generated. To address this issue, we propose a novel approach\nto tackle numerical reasoning problems using case based reasoning (CBR), an\nartificial intelligence paradigm that provides problem solving guidance by\noffering similar cases (i.e. similar questions and corresponding logical\nprograms). Our model retrieves relevant cases to address a given question, and\nthen generates an answer based on the retrieved cases and contextual\ninformation. Through experiments on the FinQA dataset, we demonstrate\ncompetitive performance of our approach and additionally show that by expanding\ncase repository, we can help solving complex multi step programs which FinQA\nshowed weakness of.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR",
            "cs.LG"
        ],
        "authors": [
            "Yikyung Kim",
            "Jay-Yoon Lee"
        ],
        "published": "2024-05-18T10:06:55Z"
    },
    {
        "title": "Strided Difference Bound Matrices",
        "link": "http://arxiv.org/abs/2405.11244v1",
        "abstract": "A wide range of symbolic analysis and optimization problems can be formalized\nusing polyhedra. Sub-classes of polyhedra, also known as sub-polyhedral\ndomains, are sought for their lower space and time complexity. We introduce the\nStrided Difference Bound Matrix (SDBM) domain, which represents a sweet spot in\nthe context of optimizing compilers. Its expressiveness and efficient\nalgorithms are particularly well suited to the construction of machine learning\ncompilers. We present decision algorithms, abstract domain operators and\ncomputational complexity proofs for SDBM. We also conduct an empirical study\nwith the MLIR compiler framework to validate the domain's practical\napplicability. We characterize a sub-class of SDBMs that frequently occurs in\npractice, and demonstrate even faster algorithms on this sub-class.",
        "subjects": [
            "cs.SC",
            "cs.PL"
        ],
        "authors": [
            "Arjun Pitchanathan",
            "Albert Cohen",
            "Oleksandr Zinenko",
            "Tobias Grosser"
        ],
        "published": "2024-05-18T10:05:31Z"
    },
    {
        "title": "A User Interface Study on Sustainable City Trip Recommendations",
        "link": "http://arxiv.org/abs/2405.11243v1",
        "abstract": "The importance of promoting sustainable and environmentally responsible\npractices is becoming increasingly recognized in all domains, including\ntourism. The impact of tourism extends beyond its immediate stakeholders and\naffects passive participants such as the environment, local businesses, and\nresidents. City trips, in particular, offer significant opportunities to\nencourage sustainable tourism practices by directing travelers towards\ndestinations that minimize environmental impact while providing enriching\nexperiences. Tourism Recommender Systems (TRS) can play a critical role in\nthis. By integrating sustainability features in TRS, travelers can be guided\ntowards destinations that meet their preferences and align with sustainability\nobjectives.\n  This paper investigates how different user interface design elements affect\nthe promotion of sustainable city trip choices. We explore the impact of\nvarious features on user decisions, including sustainability labels for\ntransportation modes and their emissions, popularity indicators for\ndestinations, seasonality labels reflecting crowd levels for specific months,\nand an overall sustainability composite score. Through a user study involving\nmockups, participants evaluated the helpfulness of these features in guiding\nthem toward more sustainable travel options.\n  Our findings indicate that sustainability labels significantly influence\nusers towards lower-carbon footprint options, while popularity and seasonality\nindicators guide users to less crowded and more seasonally appropriate\ndestinations. This study emphasizes the importance of providing users with\nclear and informative sustainability information, which can help them make more\nsustainable travel choices. It lays the groundwork for future applications that\ncan recommend sustainable destinations in real-time.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Ashmi Banerjee",
            "Tunar Mahmudov",
            "Wolfgang Wörndl"
        ],
        "published": "2024-05-18T10:04:28Z"
    },
    {
        "title": "Advancing fNIRS Neuroimaging through Synthetic Data Generation and\n  Machine Learning Applications",
        "link": "http://arxiv.org/abs/2405.11242v1",
        "abstract": "This study presents an integrated approach for advancing functional\nNear-Infrared Spectroscopy (fNIRS) neuroimaging through the synthesis of data\nand application of machine learning models. By addressing the scarcity of\nhigh-quality neuroimaging datasets, this work harnesses Monte Carlo simulations\nand parametric head models to generate a comprehensive synthetic dataset,\nreflecting a wide spectrum of conditions. We developed a containerized\nenvironment employing Docker and Xarray for standardized and reproducible data\nanalysis, facilitating meaningful comparisons across different signal\nprocessing modalities. Additionally, a cloud-based infrastructure is\nestablished for scalable data generation and processing, enhancing the\naccessibility and quality of neuroimaging data. The combination of synthetic\ndata generation with machine learning techniques holds promise for improving\nthe accuracy, efficiency, and applicability of fNIRS tomography, potentially\nrevolutionizing diagnostics and treatment strategies for neurological\nconditions. The methodologies and infrastructure developed herein set new\nstandards in data simulation and analysis, paving the way for future research\nin neuroimaging and the broader biomedical engineering field.",
        "subjects": [
            "eess.SP",
            "cs.LG",
            "physics.med-ph",
            "stat.ML"
        ],
        "authors": [
            "Eitan Waks"
        ],
        "published": "2024-05-18T09:50:19Z"
    },
    {
        "title": "Testing the Performance of Face Recognition for People with Down\n  Syndrome",
        "link": "http://arxiv.org/abs/2405.11240v1",
        "abstract": "The fairness of biometric systems, in particular facial recognition, is often\nanalysed for larger demographic groups, e.g. female vs. male or black vs.\nwhite. In contrast to this, minority groups are commonly ignored. This paper\ninvestigates the performance of facial recognition algorithms on individuals\nwith Down syndrome, a common chromosomal abnormality that affects approximately\none in 1,000 births per year. To do so, a database of 98 individuals with Down\nsyndrome, each represented by at least five facial images, is\nsemi-automatically collected from YouTube. Subsequently, two facial image\nquality assessment algorithms and five recognition algorithms are evaluated on\nthe newly collected database and on the public facial image databases CelebA\nand FRGCv2. The results show that the quality scores of facial images for\nindividuals with Down syndrome are comparable to those of individuals without\nDown syndrome captured under similar conditions. Furthermore, it is observed\nthat face recognition performance decreases significantly for individuals with\nDown syndrome, which is largely attributed to the increased likelihood of false\nmatches.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Christian Rathgeb",
            "Mathias Ibsen",
            "Denise Hartmann",
            "Simon Hradetzky",
            "Berglind Ólafsdóttir"
        ],
        "published": "2024-05-18T09:41:51Z"
    },
    {
        "title": "SimAD: A Simple Dissimilarity-based Approach for Time Series Anomaly\n  Detection",
        "link": "http://arxiv.org/abs/2405.11238v1",
        "abstract": "Despite the prevalence of reconstruction-based deep learning methods, time\nseries anomaly detection remains challenging. Existing approaches often\nstruggle with limited temporal contexts, inadequate representation of normal\npatterns, and flawed evaluation metrics, hindering their effectiveness in\nidentifying aberrant behavior. To address these issues, we introduce\n$\\textbf{{SimAD}}$, a $\\textbf{{Sim}}$ple dissimilarity-based approach for time\nseries $\\textbf{{A}}$nomaly $\\textbf{{D}}$etection. SimAD incorporates an\nadvanced feature extractor adept at processing extended temporal windows,\nutilizes the EmbedPatch encoder to integrate normal behavioral patterns\ncomprehensively, and introduces an innovative ContrastFusion module designed to\naccentuate distributional divergences between normal and abnormal data, thereby\nenhancing the robustness of anomaly discrimination. Additionally, we propose\ntwo robust evaluation metrics, UAff and NAff, addressing the limitations of\nexisting metrics and demonstrating their reliability through theoretical and\nexperimental analyses. Experiments across $\\textbf{seven}$ diverse time series\ndatasets demonstrate SimAD's superior performance compared to state-of-the-art\nmethods, achieving relative improvements of $\\textbf{19.85%}$ on F1,\n$\\textbf{4.44%}$ on Aff-F1, $\\textbf{77.79%}$ on NAff-F1, and $\\textbf{9.69%}$\non AUC on six multivariate datasets. Code and pre-trained models are available\nat https://github.com/EmorZz1G/SimAD.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Zhijie Zhong",
            "Zhiwen Yu",
            "Xing Xi",
            "Yue Xu",
            "Jiahui Chen",
            "Kaixiang Yang"
        ],
        "published": "2024-05-18T09:37:04Z"
    },
    {
        "title": "Lag Selection for Univariate Time Series Forecasting using Deep\n  Learning: An Empirical Study",
        "link": "http://arxiv.org/abs/2405.11237v1",
        "abstract": "Most forecasting methods use recent past observations (lags) to model the\nfuture values of univariate time series. Selecting an adequate number of lags\nis important for training accurate forecasting models. Several approaches and\nheuristics have been devised to solve this task. However, there is no consensus\nabout what the best approach is. Besides, lag selection procedures have been\ndeveloped based on local models and classical forecasting techniques such as\nARIMA. We bridge this gap in the literature by carrying out an extensive\nempirical analysis of different lag selection methods. We focus on deep\nlearning methods trained in a global approach, i.e., on datasets comprising\nmultiple univariate time series. The experiments were carried out using three\nbenchmark databases that contain a total of 2411 univariate time series. The\nresults indicate that the lag size is a relevant parameter for accurate\nforecasts. In particular, excessively small or excessively large lag sizes have\na considerable negative impact on forecasting performance. Cross-validation\napproaches show the best performance for lag selection, but this performance is\ncomparable with simple heuristics.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "José Leites",
            "Vitor Cerqueira",
            "Carlos Soares"
        ],
        "published": "2024-05-18T09:31:54Z"
    },
    {
        "title": "TriLoRA: Integrating SVD for Advanced Style Personalization in\n  Text-to-Image Generation",
        "link": "http://arxiv.org/abs/2405.11236v1",
        "abstract": "As deep learning technology continues to advance, image generation models,\nespecially models like Stable Diffusion, are finding increasingly widespread\napplication in visual arts creation. However, these models often face\nchallenges such as overfitting, lack of stability in generated results, and\ndifficulties in accurately capturing the features desired by creators during\nthe fine-tuning process. In response to these challenges, we propose an\ninnovative method that integrates Singular Value Decomposition (SVD) into the\nLow-Rank Adaptation (LoRA) parameter update strategy, aimed at enhancing the\nfine-tuning efficiency and output quality of image generation models. By\nincorporating SVD within the LoRA framework, our method not only effectively\nreduces the risk of overfitting but also enhances the stability of model\noutputs, and captures subtle, creator-desired feature adjustments more\naccurately. We evaluated our method on multiple datasets, and the results show\nthat, compared to traditional fine-tuning methods, our approach significantly\nimproves the model's generalization ability and creative flexibility while\nmaintaining the quality of generation. Moreover, this method maintains LoRA's\nexcellent performance under resource-constrained conditions, allowing for\nsignificant improvements in image generation quality without sacrificing the\noriginal efficiency and resource advantages.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Chengcheng Feng",
            "Mu He",
            "Qiuyu Tian",
            "Haojie Yin",
            "Xiaofang Zhao",
            "Hongwei Tang",
            "Xingqiang Wei"
        ],
        "published": "2024-05-18T09:29:00Z"
    },
    {
        "title": "Parallel Approximations for High-Dimensional Multivariate Normal\n  Probability Computation in Confidence Region Detection Applications",
        "link": "http://arxiv.org/abs/2405.14892v1",
        "abstract": "Addressing the statistical challenge of computing the multivariate normal\n(MVN) probability in high dimensions holds significant potential for enhancing\nvarious applications. One common way to compute high-dimensional MVN\nprobabilities is the Separation-of-Variables (SOV) algorithm. This algorithm is\nknown for its high computational complexity of O(n^3) and space complexity of\nO(n^2), mainly due to a Cholesky factorization operation for an n X n\ncovariance matrix, where $n$ represents the dimensionality of the MVN problem.\nThis work proposes a high-performance computing framework that allows scaling\nthe SOV algorithm and, subsequently, the confidence region detection algorithm.\nThe framework leverages parallel linear algebra algorithms with a task-based\nprogramming model to achieve performance scalability in computing process\nprobabilities, especially on large-scale systems. In addition, we enhance our\nimplementation by incorporating Tile Low-Rank (TLR) approximation techniques to\nreduce algorithmic complexity without compromising the necessary accuracy. To\nevaluate the performance and accuracy of our framework, we conduct assessments\nusing simulated data and a wind speed dataset. Our proposed implementation\neffectively handles high-dimensional multivariate normal (MVN) probability\ncomputations on shared and distributed-memory systems using finite precision\narithmetics and TLR approximation computation. Performance results show a\nsignificant speedup of up to 20X in solving the MVN problem using TLR\napproximation compared to the reference dense solution without sacrificing the\napplication's accuracy. The qualitative results on synthetic and real datasets\ndemonstrate how we maintain high accuracy in detecting confidence regions even\nwhen relying on TLR approximation to perform the underlying linear algebra\noperations.",
        "subjects": [
            "cs.DC",
            "stat.CO"
        ],
        "authors": [
            "Xiran Zhang",
            "Sameh Abdulah",
            "Jian Cao",
            "Hatem Ltaief",
            "Ying Sun",
            "Marc G. Genton",
            "David E. Keyes"
        ],
        "published": "2024-05-18T09:16:37Z"
    },
    {
        "title": "Bridge and Hint: Extending Pre-trained Language Models for Long-Range\n  Code",
        "link": "http://arxiv.org/abs/2405.11233v1",
        "abstract": "In the field of code intelligence, effectively modeling long-range code poses\na significant challenge. Existing pre-trained language models (PLMs) such as\nUniXcoder have achieved remarkable success, but they still face difficulties\nwith long code inputs. This is mainly due to their limited capacity to maintain\ncontextual continuity and memorize the key information over long-range code. To\nalleviate the difficulties, we propose EXPO, a framework for EXtending\nPre-trained language models for lOng-range code. EXPO incorporates two\ninnovative memory mechanisms we propose in this paper: Bridge Memory and Hint\nMemory. Bridge Memory uses a tagging mechanism to connect disparate snippets of\nlong-range code, helping the model maintain contextual coherence. Hint Memory\nfocuses on crucial code elements throughout the global context, such as package\nimports, by integrating a kNN attention layer to adaptively select the relevant\ncode elements. This dual-memory approach bridges the gap between understanding\nlocal code snippets and maintaining global code coherence, thereby enhancing\nthe model overall comprehension of long code sequences. We validate the\neffectiveness of EXPO on five popular pre-trained language models such as\nUniXcoder and two code intelligence tasks including API recommendation and\nvulnerability detection. Experimental results demonstrate that EXPO\nsignificantly improves the pre-training language models.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Yujia Chen",
            "Cuiyun Gao",
            "Zezhou Yang",
            "Hongyu Zhang",
            "Qing Liao"
        ],
        "published": "2024-05-18T09:06:41Z"
    },
    {
        "title": "OTLP: Output Thresholding Using Mixed Integer Linear Programming",
        "link": "http://arxiv.org/abs/2405.11230v1",
        "abstract": "Output thresholding is the technique to search for the best threshold to be\nused during inference for any classifiers that can produce probability\nestimates on train and testing datasets. It is particularly useful in high\nimbalance classification problems where the default threshold is not able to\nrefer to imbalance in class distributions and fail to give the best\nperformance. This paper proposes OTLP, a thresholding framework using mixed\ninteger linear programming which is model agnostic, can support different\nobjective functions and different set of constraints for a diverse set of\nproblems including both balanced and imbalanced classification problems. It is\nparticularly useful in real world applications where the theoretical\nthresholding techniques are not able to address to product related requirements\nand complexity of the applications which utilize machine learning models.\nThrough the use of Credit Card Fraud Detection Dataset, we evaluate the\nusefulness of the framework.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Baran Koseoglu",
            "Luca Traverso",
            "Mohammed Topiwalla",
            "Egor Kraev",
            "Zoltan Szopory"
        ],
        "published": "2024-05-18T08:51:42Z"
    },
    {
        "title": "Low Complexity Successive Cancellation Decoding of Polar Codes based on\n  Pruning Strategy in Deletion Error Channels",
        "link": "http://arxiv.org/abs/2405.12245v1",
        "abstract": "A novel SC decoding method of polar codes is proposed in $d$-deletion\nchannels, where a new pruning strategy is designed to reduce decoding\ncomplexity. Considering the difference of the scenario weight distributions,\npruning thresholds for each node are designed separately according to a uniform\nconstraint on the pruning error probability, which further reduce the number of\nscenarios that need to be calculated during the decoding procedure. In\naddition, by exploiting the properties of the joint weight distribution, a\nsimplified calculation method of thresholds is proposed. Using this simplified\ncalculation method, the number of scenarios that required to be calculated is\nreduced from $(d+1)(d+2)/2$ to $d+1$.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "He Sun",
            "Rongke Liu",
            "Bin Dai"
        ],
        "published": "2024-05-18T08:41:31Z"
    },
    {
        "title": "BadActs: A Universal Backdoor Defense in the Activation Space",
        "link": "http://arxiv.org/abs/2405.11227v1",
        "abstract": "Backdoor attacks pose an increasingly severe security threat to Deep Neural\nNetworks (DNNs) during their development stage. In response, backdoor sample\npurification has emerged as a promising defense mechanism, aiming to eliminate\nbackdoor triggers while preserving the integrity of the clean content in the\nsamples. However, existing approaches have been predominantly focused on the\nword space, which are ineffective against feature-space triggers and\nsignificantly impair performance on clean data. To address this, we introduce a\nuniversal backdoor defense that purifies backdoor samples in the activation\nspace by drawing abnormal activations towards optimized minimum clean\nactivation distribution intervals. The advantages of our approach are twofold:\n(1) By operating in the activation space, our method captures from\nsurface-level information like words to higher-level semantic concepts such as\nsyntax, thus counteracting diverse triggers; (2) the fine-grained continuous\nnature of the activation space allows for more precise preservation of clean\ncontent while removing triggers. Furthermore, we propose a detection module\nbased on statistical information of abnormal activations, to achieve a better\ntrade-off between clean accuracy and defending performance.",
        "subjects": [
            "cs.CR",
            "cs.CL"
        ],
        "authors": [
            "Biao Yi",
            "Sishuo Chen",
            "Yiming Li",
            "Tong Li",
            "Baolei Zhang",
            "Zheli Liu"
        ],
        "published": "2024-05-18T08:32:37Z"
    },
    {
        "title": "The Power of Active Multi-Task Learning in Reinforcement Learning from\n  Human Feedback",
        "link": "http://arxiv.org/abs/2405.11226v1",
        "abstract": "Reinforcement learning from human feedback (RLHF) has contributed to\nperformance improvements in large language models. To tackle its reliance on\nsubstantial amounts of human-labeled data, a successful approach is multi-task\nrepresentation learning, which involves learning a high-quality,\nlow-dimensional representation from a wide range of source tasks. In this\npaper, we formulate RLHF as the contextual dueling bandit problem and assume a\ncommon linear representation. We demonstrate that the sample complexity of\nsource tasks in multi-task RLHF can be reduced by considering task relevance\nand allocating different sample sizes to source tasks with varying task\nrelevance. We further propose an algorithm to estimate task relevance by a\nsmall number of additional data and then learn a policy. We prove that to\nachieve $\\varepsilon-$optimal, the sample complexity of the source tasks can be\nsignificantly reduced compared to uniform sampling. Additionally, the sample\ncomplexity of the target task is only linear in the dimension of the latent\nspace, thanks to representation learning.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ruitao Chen",
            "Liwei Wang"
        ],
        "published": "2024-05-18T08:29:15Z"
    },
    {
        "title": "SeBot: Structural Entropy Guided Multi-View Contrastive Learning for\n  Social Bot Detection",
        "link": "http://arxiv.org/abs/2405.11225v1",
        "abstract": "Recent advancements in social bot detection have been driven by the adoption\nof Graph Neural Networks. The social graph, constructed from social network\ninteractions, contains benign and bot accounts that influence each other.\nHowever, previous graph-based detection methods that follow the transductive\nmessage-passing paradigm may not fully utilize hidden graph information and are\nvulnerable to adversarial bot behavior. The indiscriminate message passing\nbetween nodes from different categories and communities results in excessively\nhomogeneous node representations, ultimately reducing the effectiveness of\nsocial bot detectors. In this paper, we propose SEBot, a novel multi-view\ngraph-based contrastive learning-enabled social bot detector. In particular, we\nuse structural entropy as an uncertainty metric to optimize the entire graph's\nstructure and subgraph-level granularity, revealing the implicitly existing\nhierarchical community structure. And we design an encoder to enable message\npassing beyond the homophily assumption, enhancing robustness to adversarial\nbehaviors of social bots. Finally, we employ multi-view contrastive learning to\nmaximize mutual information between different views and enhance the detection\nperformance through multi-task learning. Experimental results demonstrate that\nour approach significantly improves the performance of social bot detection\ncompared with SOTA methods.",
        "subjects": [
            "cs.SI",
            "cs.AI"
        ],
        "authors": [
            "Yingguang Yang",
            "Qi Wu",
            "Buyun He",
            "Hao Peng",
            "Renyu Yang",
            "Zhifeng Hao",
            "Yong Liao"
        ],
        "published": "2024-05-18T08:16:11Z"
    },
    {
        "title": "A class of new linear, efficient and high-order implicit-explicit\n  methods for the coupled free flow-porous media system based on nonlinear\n  Lions interface condition",
        "link": "http://arxiv.org/abs/2405.11223v1",
        "abstract": "In this paper, we construct and analyze new first- and second-order\nimplicit-explicit (IMEX) schemes for the unsteady Navier-Stokes-Darcy model to\ndescribe the coupled free flow-porous media system, which is based on the\nscalar auxiliary variable (SAV) approach in time and finite element method in\nspace. The constructed schemes are linear, only require solving a sequence of\nlinear differential equations with constant coefficients at each time step, and\ncan decouple the Navier-Stokes and Darcy systems. The unconditional stability\nof both the first- and second-order IMEX schemes can be derived for the coupled\nsystem equipped with the Lions interface condition, where the key point is that\nwe should construct a new trilinear form to balance the fully explicit\ndiscretizations of the nonlinear terms in the complex system. We can also\nestablish rigorous error estimates for the velocity and hydraulic head of the\nfirst-order scheme without any time step restriction. Numerical examples are\npresented to validate the proposed schemes.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Xinhui Wang",
            "Xu Guo",
            "Xiaoli Li"
        ],
        "published": "2024-05-18T08:06:53Z"
    },
    {
        "title": "Transformer based neural networks for emotion recognition in\n  conversations",
        "link": "http://arxiv.org/abs/2405.11222v1",
        "abstract": "This paper outlines the approach of the ISDS-NLP team in the SemEval 2024\nTask 10: Emotion Discovery and Reasoning its Flip in Conversation (EDiReF). For\nSubtask 1 we obtained a weighted F1 score of 0.43 and placed 12 in the\nleaderboard. We investigate two distinct approaches: Masked Language Modeling\n(MLM) and Causal Language Modeling (CLM). For MLM, we employ pre-trained\nBERT-like models in a multilingual setting, fine-tuning them with a classifier\nto predict emotions. Experiments with varying input lengths, classifier\narchitectures, and fine-tuning strategies demonstrate the effectiveness of this\napproach. Additionally, we utilize Mistral 7B Instruct V0.2, a state-of-the-art\nmodel, applying zero-shot and few-shot prompting techniques. Our findings\nindicate that while Mistral shows promise, MLMs currently outperform them in\nsentence-level emotion classification.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Claudiu Creanga",
            "Liviu P. Dinu"
        ],
        "published": "2024-05-18T08:05:05Z"
    },
    {
        "title": "Towards Specialized Supercomputers for Climate Sciences: Computational\n  Requirements of the Icosahedral Nonhydrostatic Weather and Climate Model",
        "link": "http://arxiv.org/abs/2405.13043v1",
        "abstract": "We discuss the computational challenges and requirements for high-resolution\nclimate simulations using the Icosahedral Nonhydrostatic Weather and Climate\nModel (ICON). We define a detailed requirements model for ICON which emphasizes\nthe need for specialized supercomputers to accurately predict climate change\nimpacts and extreme weather events. Based on the requirements model, we outline\ncomputational demands for km-scale simulations, and suggests machine learning\ntechniques to enhance model accuracy and efficiency. Our findings aim to guide\nthe design of future supercomputers for advanced climate science.",
        "subjects": [
            "physics.ao-ph",
            "cs.AR",
            "cs.DC",
            "physics.comp-ph"
        ],
        "authors": [
            "Torsten Hoefler",
            "Alexandru Calotoiu",
            "Anurag Dipankar",
            "Thomas Schulthess",
            "Xavier Lapillonne",
            "Oliver Fuhrer"
        ],
        "published": "2024-05-18T08:03:31Z"
    },
    {
        "title": "Identifying and Aligning Medical Claims Made on Social Media with\n  Medical Evidence",
        "link": "http://arxiv.org/abs/2405.11219v1",
        "abstract": "Evidence-based medicine is the practice of making medical decisions that\nadhere to the latest, and best known evidence at that time. Currently, the best\nevidence is often found in the form of documents, such as randomized control\ntrials, meta-analyses and systematic reviews. This research focuses on aligning\nmedical claims made on social media platforms with this medical evidence. By\ndoing so, individuals without medical expertise can more effectively assess the\nveracity of such medical claims. We study three core tasks: identifying medical\nclaims, extracting medical vocabulary from these claims, and retrieving\nevidence relevant to those identified medical claims. We propose a novel system\nthat can generate synthetic medical claims to aid each of these core tasks. We\nadditionally introduce a novel dataset produced by our synthetic generator\nthat, when applied to these tasks, demonstrates not only a more flexible and\nholistic approach, but also an improvement in all comparable metrics. We make\nour dataset, the Expansive Medical Claim Corpus (EMCC), available at\nhttps://zenodo.org/records/8321460",
        "subjects": [
            "cs.CL",
            "cs.SI"
        ],
        "authors": [
            "Anthony Hughes",
            "Xingyi Song"
        ],
        "published": "2024-05-18T07:50:43Z"
    },
    {
        "title": "MemeMQA: Multimodal Question Answering for Memes via Rationale-Based\n  Inferencing",
        "link": "http://arxiv.org/abs/2405.11215v1",
        "abstract": "Memes have evolved as a prevalent medium for diverse communication, ranging\nfrom humour to propaganda. With the rising popularity of image-focused content,\nthere is a growing need to explore its potential harm from different aspects.\nPrevious studies have analyzed memes in closed settings - detecting harm,\napplying semantic labels, and offering natural language explanations. To extend\nthis research, we introduce MemeMQA, a multimodal question-answering framework\naiming to solicit accurate responses to structured questions while providing\ncoherent explanations. We curate MemeMQACorpus, a new dataset featuring 1,880\nquestions related to 1,122 memes with corresponding answer-explanation pairs.\nWe further propose ARSENAL, a novel two-stage multimodal framework that\nleverages the reasoning capabilities of LLMs to address MemeMQA. We benchmark\nMemeMQA using competitive baselines and demonstrate its superiority - ~18%\nenhanced answer prediction accuracy and distinct text generation lead across\nvarious metrics measuring lexical and semantic alignment over the best\nbaseline. We analyze ARSENAL's robustness through diversification of\nquestion-set, confounder-based evaluation regarding MemeMQA's generalizability,\nand modality-specific assessment, enhancing our understanding of meme\ninterpretation in the multimodal communication landscape.",
        "subjects": [
            "cs.CL",
            "cs.CY"
        ],
        "authors": [
            "Siddhant Agarwal",
            "Shivam Sharma",
            "Preslav Nakov",
            "Tanmoy Chakraborty"
        ],
        "published": "2024-05-18T07:44:41Z"
    },
    {
        "title": "Real-Time Go-Around Prediction: A case study of JFK airport",
        "link": "http://arxiv.org/abs/2405.12244v1",
        "abstract": "In this paper, we employ the long-short-term memory model (LSTM) to predict\nthe real-time go-around probability as an arrival flight is approaching JFK\nairport and within 10 nm of the landing runway threshold. We further develop\nmethods to examine the causes to go-around occurrences both from a global view\nand an individual flight perspective. According to our results, in-trail\nspacing, and simultaneous runway operation appear to be the top factors that\ncontribute to overall go-around occurrences. We then integrate these\npre-trained models and analyses with real-time data streaming, and finally\ndevelop a demo web-based user interface that integrates the different\ncomponents designed previously into a real-time tool that can eventually be\nused by flight crews and other line personnel to identify situations in which\nthere is a high risk of a go-around.",
        "subjects": [
            "physics.soc-ph",
            "cs.LG"
        ],
        "authors": [
            "Ke Liu",
            "Kaijing Ding",
            "Lu Dai",
            "Mark Hansen",
            "Kennis Chan",
            "John Schade"
        ],
        "published": "2024-05-18T07:39:45Z"
    },
    {
        "title": "Automated Text Identification Using CNN and Training Dynamics",
        "link": "http://arxiv.org/abs/2405.11212v1",
        "abstract": "We used Data Maps to model and characterize the AuTexTification dataset. This\nprovides insights about the behaviour of individual samples during training\nacross epochs (training dynamics). We characterized the samples across 3\ndimensions: confidence, variability and correctness. This shows the presence of\n3 regions: easy-to-learn, ambiguous and hard-to-learn examples. We used a\nclassic CNN architecture and found out that training the model only on a subset\nof ambiguous examples improves the model's out-of-distribution generalization.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Claudiu Creanga",
            "Liviu Petrisor Dinu"
        ],
        "published": "2024-05-18T07:37:17Z"
    },
    {
        "title": "Excess Delay from GDP: Measurement and Causal Analysis",
        "link": "http://arxiv.org/abs/2405.11211v1",
        "abstract": "Ground Delay Programs (GDPs) have been widely used to resolve excessive\ndemand-capacity imbalances at arrival airports by shifting foreseen airborne\ndelay to pre-departure ground delay. While offering clear safety and efficiency\nbenefits, GDPs may also create additional delay because of imperfect execution\nand uncertainty in predicting arrival airport capacity. This paper presents a\nmethodology for measuring excess delay resulting from individual GDPs and\ninvestigates factors that influence excess delay using regularized regression\nmodels. We measured excess delay for 1210 GDPs from 33 U.S. airports in 2019.\nOn a per-restricted flight basis, the mean excess delay is 35.4 min with std of\n20.6 min. In our regression analysis of the variation in excess delay, ridge\nregression is found to perform best. The factors affecting excess delay include\ntime variations during gate out and taxi out for flights subject to the GDP,\nprogram rate setting and revisions, and GDP time duration.",
        "subjects": [
            "eess.SY",
            "cs.LG",
            "cs.SY"
        ],
        "authors": [
            "Ke Liu",
            "Mark Hansen"
        ],
        "published": "2024-05-18T07:35:38Z"
    },
    {
        "title": "Computational predictions of hydrogen-assisted fatigue crack growth",
        "link": "http://arxiv.org/abs/2405.11210v1",
        "abstract": "A new model is presented to predict hydrogen-assisted fatigue. The model\ncombines a phase field description of fracture and fatigue, stress-assisted\nhydrogen diffusion, and a toughness degradation formulation with cyclic and\nhydrogen contributions. Hydrogen-assisted fatigue crack growth predictions\nexhibit an excellent agreement with experiments over all the scenarios\nconsidered, spanning multiple load ratios, H2 pressures and loading\nfrequencies. These are obtained without any calibration with hydrogen-assisted\nfatigue data, taking as input only mechanical and hydrogen transport material\nproperties, the material's fatigue characteristics (from a single test in air),\nand the sensitivity of fracture toughness to hydrogen content. Furthermore, the\nmodel is used to determine: (i) what are suitable test loading frequencies to\nobtain conservative data, and (ii) the underestimation made when not\npre-charging samples. The model can handle both laboratory specimens and\nlarge-scale engineering components, enabling the Virtual Testing paradigm in\ninfrastructure exposed to hydrogen environments and cyclic loading.",
        "subjects": [
            "cs.CE",
            "cond-mat.mtrl-sci",
            "physics.app-ph",
            "physics.chem-ph"
        ],
        "authors": [
            "C. Cui",
            "P. Bortot",
            "M. Ortolani",
            "E. Martínez-Pañeda"
        ],
        "published": "2024-05-18T07:34:48Z"
    },
    {
        "title": "Discovering Physics-Informed Neural Networks Model for Solving Partial\n  Differential Equations through Evolutionary Computation",
        "link": "http://dx.doi.org/10.1016/j.swevo.2024.101589",
        "abstract": "In recent years, the researches about solving partial differential equations\n(PDEs) based on artificial neural network have attracted considerable\nattention. In these researches, the neural network models are usually designed\ndepend on human experience or trial and error. Despite the emergence of several\nmodel searching methods, these methods primarily concentrate on optimizing the\nhyperparameters of fully connected neural network model based on the framework\nof physics-informed neural networks (PINNs), and the corresponding search\nspaces are relatively restricted, thereby limiting the exploration of superior\nmodels. This article proposes an evolutionary computation method aimed at\ndiscovering the PINNs model with higher approximation accuracy and faster\nconvergence rate. In addition to searching the numbers of layers and neurons\nper hidden layer, this method concurrently explores the optimal shortcut\nconnections between the layers and the novel parametric activation functions\nexpressed by the binary trees. In evolution, the strategy about dynamic\npopulation size and training epochs (DPSTE) is adopted, which significantly\nincreases the number of models to be explored and facilitates the discovery of\nmodels with fast convergence rate. In experiments, the performance of different\nmodels that are searched through Bayesian optimization, random search and\nevolution is compared in solving Klein-Gordon, Burgers, and Lam\\'e equations.\nThe experimental results affirm that the models discovered by the proposed\nevolutionary computation method generally exhibit superior approximation\naccuracy and convergence rate, and these models also show commendable\ngeneralization performance with respect to the source term, initial and\nboundary conditions, equation coefficient and computational domain. The\ncorresponding code is available at\nhttps://github.com/MathBon/Discover-PINNs-Model.",
        "subjects": [
            "cs.NE",
            "cs.LG"
        ],
        "authors": [
            "Bo Zhang",
            "Chao Yang"
        ],
        "published": "2024-05-18T07:32:02Z"
    },
    {
        "title": "Towards Robust Policy: Enhancing Offline Reinforcement Learning with\n  Adversarial Attacks and Defenses",
        "link": "http://arxiv.org/abs/2405.11206v1",
        "abstract": "Offline reinforcement learning (RL) addresses the challenge of expensive and\nhigh-risk data exploration inherent in RL by pre-training policies on vast\namounts of offline data, enabling direct deployment or fine-tuning in\nreal-world environments. However, this training paradigm can compromise policy\nrobustness, leading to degraded performance in practical conditions due to\nobservation perturbations or intentional attacks. While adversarial attacks and\ndefenses have been extensively studied in deep learning, their application in\noffline RL is limited. This paper proposes a framework to enhance the\nrobustness of offline RL models by leveraging advanced adversarial attacks and\ndefenses. The framework attacks the actor and critic components by perturbing\nobservations during training and using adversarial defenses as regularization\nto enhance the learned policy. Four attacks and two defenses are introduced and\nevaluated on the D4RL benchmark. The results show the vulnerability of both the\nactor and critic to attacks and the effectiveness of the defenses in improving\npolicy robustness. This framework holds promise for enhancing the reliability\nof offline RL models in practical scenarios.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.RO"
        ],
        "authors": [
            "Thanh Nguyen",
            "Tung M. Luu",
            "Tri Ton",
            "Chang D. Yoo"
        ],
        "published": "2024-05-18T07:23:44Z"
    },
    {
        "title": "Fuse & Calibrate: A bi-directional Vision-Language Guided Framework for\n  Referring Image Segmentation",
        "link": "http://arxiv.org/abs/2405.11205v1",
        "abstract": "Referring Image Segmentation (RIS) aims to segment an object described in\nnatural language from an image, with the main challenge being a text-to-pixel\ncorrelation. Previous methods typically rely on single-modality features, such\nas vision or language features, to guide the multi-modal fusion process.\nHowever, this approach limits the interaction between vision and language,\nleading to a lack of fine-grained correlation between the language description\nand pixel-level details during the decoding process. In this paper, we\nintroduce FCNet, a framework that employs a bi-directional guided fusion\napproach where both vision and language play guiding roles. Specifically, we\nuse a vision-guided approach to conduct initial multi-modal fusion, obtaining\nmulti-modal features that focus on key vision information. We then propose a\nlanguage-guided calibration module to further calibrate these multi-modal\nfeatures, ensuring they understand the context of the input sentence. This\nbi-directional vision-language guided approach produces higher-quality\nmulti-modal features sent to the decoder, facilitating adaptive propagation of\nfine-grained semantic information from textual features to visual features.\nExperiments on RefCOCO, RefCOCO+, and G-Ref datasets with various backbones\nconsistently show our approach outperforming state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yichen Yan",
            "Xingjian He",
            "Sihan Chen",
            "Shichen Lu",
            "Jing Liu"
        ],
        "published": "2024-05-18T07:21:12Z"
    },
    {
        "title": "Learning from Imperfect Human Feedback: a Tale from Corruption-Robust\n  Dueling",
        "link": "http://arxiv.org/abs/2405.11204v1",
        "abstract": "This paper studies Learning from Imperfect Human Feedback (LIHF), motivated\nby humans' potential irrationality or imperfect perception of true preference.\nWe revisit the classic dueling bandit problem as a model of learning from\ncomparative human feedback, and enrich it by casting the imperfection in human\nfeedback as agnostic corruption to user utilities. We start by identifying the\nfundamental limits of LIHF and prove a regret lower bound of\n$\\Omega(\\max\\{T^{1/2},C\\})$, even when the total corruption $C$ is known and\nwhen the corruption decays gracefully over time (i.e., user feedback becomes\nincreasingly more accurate). We then turn to design robust algorithms\napplicable in real-world scenarios with arbitrary corruption and unknown $C$.\nOur key finding is that gradient-based algorithms enjoy a smooth\nefficiency-robustness tradeoff under corruption by varying their learning\nrates. Specifically, under general concave user utility, Dueling Bandit\nGradient Descent (DBGD) of Yue and Joachims (2009) can be tuned to achieve\nregret $O(T^{1-\\alpha} + T^{ \\alpha} C)$ for any given parameter $\\alpha \\in\n(0, \\frac{1}{4}]$. Additionally, this result enables us to pin down the regret\nlower bound of the standard DBGD (the $\\alpha=1/4$ case) as $\\Omega(T^{3/4})$\nfor the first time, to the best of our knowledge. For strongly concave user\nutility we show a better tradeoff: there is an algorithm that achieves\n$O(T^{\\alpha} + T^{\\frac{1}{2}(1-\\alpha)}C)$ for any given $\\alpha \\in\n[\\frac{1}{2},1)$. Our theoretical insights are corroborated by extensive\nexperiments on real-world recommendation data.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Yuwei Cheng",
            "Fan Yao",
            "Xuefeng Liu",
            "Haifeng Xu"
        ],
        "published": "2024-05-18T07:18:43Z"
    },
    {
        "title": "A robust solver for H(curl) convection-diffusion and its local Fourier\n  analysis",
        "link": "http://arxiv.org/abs/2405.11203v1",
        "abstract": "In this paper, we present a robust and efficient multigrid solver based on an\nexponential-fitting discretization for 2D H(curl) convection-diffusion\nproblems. By leveraging an exponential identity, we characterize the kernel of\nH(curl) convection-diffusion problems and design a suitable hybrid smoother.\nThis smoother incorporates a lexicographic Gauss-Seidel smoother within a\ndownwind type and smoothing over an auxiliary problem, corresponding to H(grad)\nconvection-diffusion problems for kernel correction. We analyze the convergence\nproperties of the smoothers and the two-level method using local Fourier\nanalysis (LFA). The performance of the algorithms demonstrates robustness in\nboth convection-dominated and diffusion-dominated cases.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "65F10, 65N30, 65N55, 35Q60"
        ],
        "authors": [
            "Jindong Wang",
            "Shuonan Wu"
        ],
        "published": "2024-05-18T07:12:38Z"
    },
    {
        "title": "LexGen: Domain-aware Multilingual Lexicon Generation",
        "link": "http://arxiv.org/abs/2405.11200v1",
        "abstract": "Lexicon or dictionary generation across domains is of significant societal\nimportance, as it can potentially enhance information accessibility for a\ndiverse user base while preserving language identity. Prior work in the field\nprimarily focuses on bilingual lexical induction, which deals with word\nalignments using mapping-based or corpora-based approaches. Though initiated by\nresearchers, the research associated with lexicon generation is limited, even\nmore so with domain-specific lexicons. This task becomes particularly important\nin atypical medical, engineering, and other technical domains, owing to the\nhighly infrequent usage of the terms and negligibly low data availability of\ntechnical terms in many low-resource languages. Owing to the research gap in\nlexicon generation, especially with a limited focus on the domain-specific\narea, we propose a new model to generate dictionary words for 6 Indian\nlanguages in the multi-domain setting. Our model consists of domain-specific\nand domain-generic layers that encode information, and these layers are invoked\nvia a learnable routing technique. Further, we propose an approach to\nexplicitly leverage the relatedness between these Indian languages toward\ncoherent translation. We also release a new benchmark dataset across 6 Indian\nlanguages that span 8 diverse domains that can propel further research in\ndomain-specific lexicon induction. We conduct both zero-shot and few-shot\nexperiments across multiple domains to show the efficacy of our proposed model\nin generalizing to unseen domains and unseen languages.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Karthika NJ",
            "Ayush Maheshwari",
            "Atul Kumar Singh",
            "Preethi Jyothi",
            "Ganesh Ramakrishnan",
            "Krishnakant Bhatt"
        ],
        "published": "2024-05-18T07:02:43Z"
    },
    {
        "title": "Adaptive Stabilization Based on Machine Learning for Column Generation",
        "link": "http://arxiv.org/abs/2405.11198v1",
        "abstract": "Column generation (CG) is a well-established method for solving large-scale\nlinear programs. It involves iteratively optimizing a subproblem containing a\nsubset of columns and using its dual solution to generate new columns with\nnegative reduced costs. This process continues until the dual values converge\nto the optimal dual solution to the original problem. A natural phenomenon in\nCG is the heavy oscillation of the dual values during iterations, which can\nlead to a substantial slowdown in the convergence rate. Stabilization\ntechniques are devised to accelerate the convergence of dual values by using\ninformation beyond the state of the current subproblem. However, there remains\na significant gap in obtaining more accurate dual values at an earlier stage.\nTo further narrow this gap, this paper introduces a novel approach consisting\nof 1) a machine learning approach for accurate prediction of optimal dual\nsolutions and 2) an adaptive stabilization technique that effectively\ncapitalizes on accurate predictions. On the graph coloring problem, we show\nthat our method achieves a significantly improved convergence rate compared to\ntraditional methods.",
        "subjects": [
            "math.OC",
            "cs.AI"
        ],
        "authors": [
            "Yunzhuang Shen",
            "Yuan Sun",
            "Xiaodong Li",
            "Zhiguang Cao",
            "Andrew Eberhard",
            "Guangquan Zhang"
        ],
        "published": "2024-05-18T06:52:50Z"
    },
    {
        "title": "Designing NLP Systems That Adapt to Diverse Worldviews",
        "link": "http://arxiv.org/abs/2405.11197v1",
        "abstract": "Natural Language Inference (NLI) is foundational for evaluating language\nunderstanding in AI. However, progress has plateaued, with models failing on\nambiguous examples and exhibiting poor generalization. We argue that this stems\nfrom disregarding the subjective nature of meaning, which is intrinsically tied\nto an individual's \\textit{weltanschauung} (which roughly translates to\nworldview). Existing NLP datasets often obscure this by aggregating labels or\nfiltering out disagreement. We propose a perspectivist approach: building\ndatasets that capture annotator demographics, values, and justifications for\ntheir labels. Such datasets would explicitly model diverse worldviews. Our\ninitial experiments with a subset of the SBIC dataset demonstrate that even\nlimited annotator metadata can improve model performance.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Claudiu Creanga",
            "Liviu P. Dinu"
        ],
        "published": "2024-05-18T06:48:09Z"
    },
    {
        "title": "Natural Is The Best: Model-Agnostic Code Simplification for Pre-trained\n  Large Language Models",
        "link": "http://arxiv.org/abs/2405.11196v1",
        "abstract": "Pre-trained Large Language Models (LLM) have achieved remarkable successes in\nseveral domains. However, code-oriented LLMs are heavy in computational\ncomplexity, and quadratically with the length of the input. Toward simplifying\nthe input program of an LLM, the state-of-the-art approach has the strategies\nto filter the input code tokens based on the attention scores given by the LLM.\nThe decision to simplify the input should not rely on the attention patterns of\nan LLM, as these patterns are influenced by both the model architecture and the\npre-training dataset. Since the model and dataset are part of the solution\ndomain, not the problem domain where the input belongs, the outcome may differ\nwhen the model is pre-trained on a different dataset. We propose SlimCode, a\nmodel-agnostic code simplification solution for LLMs that depends on the nature\nof input code tokens. As an empirical study on the LLMs including CodeBERT,\nCodeT5, and GPT-4 for two main tasks: code search and summarization, we\nreported that 1) the removal ratio of code has a linear-like relation with the\nsaving ratio on training time, 2) the impact of categorized tokens on code\nsimplification can vary significantly, 3) the impact of categorized tokens on\ncode simplification is task-specific but model-agnostic, and 4) the above\nfindings hold for the paradigm-prompt engineering and interactive in-context\nlearning. The empirical results showed that SlimCode can improve the\nstate-of-the-art technique by 9.46% and 5.15% in terms of MRR and BLEU score on\ncode search and summarization. Moreover, SlimCode is 133 times faster than the\nstate-of-the-art approach. Additionally, SlimCode can reduce the cost of\ninvoking GPT-4 by up to 24% per API query, while still producing comparable\nresults to those with the original code.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Yan Wang",
            "Xiaoning Li",
            "Tien Nguyen",
            "Shaohua Wang",
            "Chao Ni",
            "Ling Ding"
        ],
        "published": "2024-05-18T06:15:52Z"
    },
    {
        "title": "Trustworthy Actionable Perturbations",
        "link": "http://arxiv.org/abs/2405.11195v1",
        "abstract": "Counterfactuals, or modified inputs that lead to a different outcome, are an\nimportant tool for understanding the logic used by machine learning classifiers\nand how to change an undesirable classification. Even if a counterfactual\nchanges a classifier's decision, however, it may not affect the true underlying\nclass probabilities, i.e. the counterfactual may act like an adversarial attack\nand ``fool'' the classifier. We propose a new framework for creating modified\ninputs that change the true underlying probabilities in a beneficial way which\nwe call Trustworthy Actionable Perturbations (TAP). This includes a novel\nverification procedure to ensure that TAP change the true class probabilities\ninstead of acting adversarially. Our framework also includes new cost, reward,\nand goal definitions that are better suited to effectuating change in the real\nworld. We present PAC-learnability results for our verification procedure and\ntheoretically analyze our new method for measuring reward. We also develop a\nmethodology for creating TAP and compare our results to those achieved by\nprevious counterfactual methods.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Jesse Friedbaum",
            "Sudarshan Adiga",
            "Ravi Tandon"
        ],
        "published": "2024-05-18T06:14:00Z"
    },
    {
        "title": "BrainStorm @ iREL at SMM4H 2024: Leveraging Translation and Topical\n  Embeddings for Annotation Detection in Tweets",
        "link": "http://arxiv.org/abs/2405.11192v1",
        "abstract": "The proliferation of LLMs in various NLP tasks has sparked debates regarding\ntheir reliability, particularly in annotation tasks where biases and\nhallucinations may arise. In this shared task, we address the challenge of\ndistinguishing annotations made by LLMs from those made by human domain experts\nin the context of COVID-19 symptom detection from tweets in Latin American\nSpanish. This paper presents BrainStorm @ iREL's approach to the SMM4H 2024\nShared Task, leveraging the inherent topical information in tweets, we propose\na novel approach to identify and classify annotations, aiming to enhance the\ntrustworthiness of annotated data.",
        "subjects": [
            "cs.CL",
            "cs.SI"
        ],
        "authors": [
            "Manav Chaudhary",
            "Harshit Gupta",
            "Vasudeva Varma"
        ],
        "published": "2024-05-18T06:08:07Z"
    },
    {
        "title": "Biathlon: Harnessing Model Resilience for Accelerating ML Inference\n  Pipelines",
        "link": "http://arxiv.org/abs/2405.11191v1",
        "abstract": "Machine learning inference pipelines commonly encountered in data science and\nindustries often require real-time responsiveness due to their user-facing\nnature. However, meeting this requirement becomes particularly challenging when\ncertain input features require aggregating a large volume of data online.\nRecent literature on interpretable machine learning reveals that most machine\nlearning models exhibit a notable degree of resilience to variations in input.\nThis suggests that machine learning models can effectively accommodate\napproximate input features with minimal discernible impact on accuracy. In this\npaper, we introduce Biathlon, a novel ML serving system that leverages the\ninherent resilience of models and determines the optimal degree of\napproximation for each aggregation feature. This approach enables maximum\nspeedup while ensuring a guaranteed bound on accuracy loss. We evaluate\nBiathlon on real pipelines from both industry applications and data science\ncompetitions, demonstrating its ability to meet real-time latency requirements\nby achieving 5.3x to 16.6x speedup with almost no accuracy loss.",
        "subjects": [
            "cs.DB",
            "cs.LG"
        ],
        "authors": [
            "Chaokun Chang",
            "Eric Lo",
            "Chunxiao Ye"
        ],
        "published": "2024-05-18T06:07:54Z"
    },
    {
        "title": "ReasonPix2Pix: Instruction Reasoning Dataset for Advanced Image Editing",
        "link": "http://arxiv.org/abs/2405.11190v1",
        "abstract": "Instruction-based image editing focuses on equipping a generative model with\nthe capacity to adhere to human-written instructions for editing images.\nCurrent approaches typically comprehend explicit and specific instructions.\nHowever, they often exhibit a deficiency in executing active reasoning\ncapacities required to comprehend instructions that are implicit or\ninsufficiently defined. To enhance active reasoning capabilities and impart\nintelligence to the editing model, we introduce ReasonPix2Pix, a comprehensive\nreasoning-attentive instruction editing dataset. The dataset is characterized\nby 1) reasoning instruction, 2) more realistic images from fine-grained\ncategories, and 3) increased variances between input and edited images. When\nfine-tuned with our dataset under supervised conditions, the model demonstrates\nsuperior performance in instructional editing tasks, independent of whether the\ntasks require reasoning or not. The code, model, and dataset will be publicly\navailable.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ying Jin",
            "Pengyang Ling",
            "Xiaoyi Dong",
            "Pan Zhang",
            "Jiaqi Wang",
            "Dahua Lin"
        ],
        "published": "2024-05-18T06:03:42Z"
    },
    {
        "title": "Wind Power Prediction across Different Locations using Deep Domain\n  Adaptive Learning",
        "link": "http://arxiv.org/abs/2405.11188v1",
        "abstract": "Accurate prediction of wind power is essential for the grid integration of\nthis intermittent renewable source and aiding grid planners in forecasting\navailable wind capacity. Spatial differences lead to discrepancies in\nclimatological data distributions between two geographically dispersed regions,\nconsequently making the prediction task more difficult. Thus, a prediction\nmodel that learns from the data of a particular climatic region can suffer from\nbeing less robust. A deep neural network (DNN) based domain adaptive approach\nis proposed to counter this drawback. Effective weather features from a large\nset of weather parameters are selected using a random forest approach. A\npre-trained model from the source domain is utilized to perform the prediction\ntask, assuming no source data is available during target domain prediction. The\nweights of only the last few layers of the DNN model are updated throughout the\ntask, keeping the rest of the network unchanged, making the model faster\ncompared to the traditional approaches. The proposed approach demonstrates\nhigher accuracy ranging from 6.14% to even 28.44% compared to the traditional\nnon-adaptive method.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Md Saiful Islam Sajol",
            "Md Shazid Islam",
            "A S M Jahid Hasan",
            "Md Saydur Rahman",
            "Jubair Yusuf"
        ],
        "published": "2024-05-18T05:57:52Z"
    },
    {
        "title": "MultiPaxos Made Complete",
        "link": "http://arxiv.org/abs/2405.11183v1",
        "abstract": "MultiPaxos, while a fundamental Replicated State Machine algorithm, suffers\nfrom a dearth of comprehensive guidelines for achieving a complete and correct\nimplementation. This deficiency has hindered MultiPaxos' practical utility and\nadoption and has resulted in flawed claims about its capabilities. Our paper\naims to bridge the gap between MultiPaxos' complexity and practical\nimplementation through a meticulous and detailed design process spanning more\nthan a year. It carefully dissects each phase of MultiPaxos and offers detailed\nstep-by-step pseudocode -- in addition to a complete open-source implementation\n-- for all components, including the leader election, the failure detector, and\nthe commit phase.\n  The implementation of our complete design also provides better performance\nstability, resource usage, and network partition tolerance than naive\nMultiPaxos versions. Our specification includes a lightweight log compaction\napproach that avoids taking repeated snapshots, significantly improving\nresource usage and performance stability. Our failure detector, integrated into\nthe commit phase of the algorithm, uses variable and adaptive heartbeat\nintervals to settle on a better leader under partial connectivity and network\npartitions, improving liveness under such conditions.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Zhiying Liang",
            "Vahab Jabrayilov",
            "Aleksey Charapko",
            "Abutalib Aghayev"
        ],
        "published": "2024-05-18T05:31:48Z"
    },
    {
        "title": "The Cost of Garbage Collection for State Machine Replication",
        "link": "http://arxiv.org/abs/2405.11182v1",
        "abstract": "State Machine Replication (SMR) protocols form the backbone of many\ndistributed systems. Enterprises and startups increasingly build their\ndistributed systems on the cloud due to its many advantages, such as\nscalability and cost-effectiveness. One of the first technical questions\ncompanies face when building a system on the cloud is which programming\nlanguage to use. Among many factors that go into this decision is whether to\nuse a language with garbage collection (GC), such as Java or Go, or a language\nwith manual memory management, such as C++ or Rust. Today, companies\npredominantly prefer languages with GC, like Go, Kotlin, or even Python, due to\nease of development; however, there is no free lunch: GC costs resources\n(memory and CPU) and performance (long tail latencies due to GC pauses). While\nthere have been anecdotal reports of reduced cloud cost and improved tail\nlatencies when switching from a language with GC to a language with manual\nmemory management, so far, there has not been a systematic study of the GC\noverhead of running an SMR-based cloud system.\n  This paper studies the overhead of running an SMR-based cloud system written\nin a language with GC. To this end, we design from scratch a canonical SMR\nsystem -- a MultiPaxos-based replicated in-memory key-value store -- and we\nimplement it in C++, Java, Rust, and Go. We compare the performance and\nresource usage of these implementations when running on the cloud under\ndifferent workloads and resource constraints and report our results. Our\nfindings have implications for the design of cloud systems.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Zhiying Liang",
            "Vahab Jabrayilov",
            "Aleksey Charapko",
            "Abutalib Aghayev"
        ],
        "published": "2024-05-18T05:29:22Z"
    },
    {
        "title": "Towards Knowledge-Infused Automated Disease Diagnosis Assistant",
        "link": "http://arxiv.org/abs/2405.11181v1",
        "abstract": "With the advancement of internet communication and telemedicine, people are\nincreasingly turning to the web for various healthcare activities. With an\never-increasing number of diseases and symptoms, diagnosing patients becomes\nchallenging. In this work, we build a diagnosis assistant to assist doctors,\nwhich identifies diseases based on patient-doctor interaction. During\ndiagnosis, doctors utilize both symptomatology knowledge and diagnostic\nexperience to identify diseases accurately and efficiently. Inspired by this,\nwe investigate the role of medical knowledge in disease diagnosis through\ndoctor-patient interaction. We propose a two-channel, knowledge-infused,\ndiscourse-aware disease diagnosis model (KI-DDI), where the first channel\nencodes patient-doctor communication using a transformer-based encoder, while\nthe other creates an embedding of symptom-disease using a graph attention\nnetwork (GAT). In the next stage, the conversation and knowledge graph\nembeddings are infused together and fed to a deep neural network for disease\nidentification. Furthermore, we first develop an empathetic conversational\nmedical corpus comprising conversations between patients and doctors, annotated\nwith intent and symptoms information. The proposed model demonstrates a\nsignificant improvement over the existing state-of-the-art models, establishing\nthe crucial roles of (a) a doctor's effort for additional symptom extraction\n(in addition to patient self-report) and (b) infusing medical knowledge in\nidentifying diseases effectively. Many times, patients also show their medical\nconditions, which acts as crucial evidence in diagnosis. Therefore, integrating\nvisual sensory information would represent an effective avenue for enhancing\nthe capabilities of diagnostic assistants.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Mohit Tomar",
            "Abhisek Tiwari",
            "Sriparna Saha"
        ],
        "published": "2024-05-18T05:18:50Z"
    },
    {
        "title": "GestFormer: Multiscale Wavelet Pooling Transformer Network for Dynamic\n  Hand Gesture Recognition",
        "link": "http://arxiv.org/abs/2405.11180v1",
        "abstract": "Transformer model have achieved state-of-the-art results in many applications\nlike NLP, classification, etc. But their exploration in gesture recognition\ntask is still limited. So, we propose a novel GestFormer architecture for\ndynamic hand gesture recognition. The motivation behind this design is to\npropose a resource efficient transformer model, since transformers are\ncomputationally expensive and very complex. So, we propose to use a pooling\nbased token mixer named PoolFormer, since it uses only pooling layer which is a\nnon-parametric layer instead of quadratic attention. The proposed model also\nleverages the space-invariant features of the wavelet transform and also the\nmultiscale features are selected using multi-scale pooling. Further, a gated\nmechanism helps to focus on fine details of the gesture with the contextual\ninformation. This enhances the performance of the proposed model compared to\nthe traditional transformer with fewer parameters, when evaluated on dynamic\nhand gesture datasets, NVidia Dynamic Hand Gesture and Briareo datasets. To\nprove the efficacy of the proposed model, we have experimented on single as\nwell multimodal inputs such as infrared, normals, depth, optical flow and color\nimages. We have also compared the proposed GestFormer in terms of resource\nefficiency and number of operations. The source code is available at\nhttps://github.com/mallikagarg/GestFormer.",
        "subjects": [
            "cs.CV",
            "cs.HC"
        ],
        "authors": [
            "Mallika Garg",
            "Debashis Ghosh",
            "Pyari Mohan Pradhan"
        ],
        "published": "2024-05-18T05:16:32Z"
    },
    {
        "title": "Accelerating Multilevel Markov Chain Monte Carlo Using Machine Learning\n  Models",
        "link": "http://arxiv.org/abs/2405.11179v1",
        "abstract": "This work presents an efficient approach for accelerating multilevel Markov\nChain Monte Carlo (MCMC) sampling for large-scale problems using low-fidelity\nmachine learning models. While conventional techniques for large-scale Bayesian\ninference often substitute computationally expensive high-fidelity models with\nmachine learning models, thereby introducing approximation errors, our approach\noffers a computationally efficient alternative by augmenting high-fidelity\nmodels with low-fidelity ones within a hierarchical framework. The multilevel\napproach utilizes the low-fidelity machine learning model (MLM) for inexpensive\nevaluation of proposed samples thereby improving the acceptance of samples by\nthe high-fidelity model. The hierarchy in our multilevel algorithm is derived\nfrom geometric multigrid hierarchy. We utilize an MLM to acclerate the coarse\nlevel sampling. Training machine learning model for the coarsest level\nsignificantly reduces the computational cost associated with generating\ntraining data and training the model. We present an MCMC algorithm to\naccelerate the coarsest level sampling using MLM and account for the\napproximation error introduced. We provide theoretical proofs of detailed\nbalance and demonstrate that our multilevel approach constitutes a consistent\nMCMC algorithm. Additionally, we derive conditions on the accuracy of the\nmachine learning model to facilitate more efficient hierarchical sampling. Our\ntechnique is demonstrated on a standard benchmark inference problem in\ngroundwater flow, where we estimate the probability density of a quantity of\ninterest using a four-level MCMC algorithm. Our proposed algorithm accelerates\nmultilevel sampling by a factor of two while achieving similar accuracy\ncompared to sampling using the standard multilevel algorithm.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "cs.NA",
            "math.NA",
            "math.PR"
        ],
        "authors": [
            "Sohail Reddy",
            "Hillary Fairbanks"
        ],
        "published": "2024-05-18T05:13:11Z"
    },
    {
        "title": "Automating PTSD Diagnostics in Clinical Interviews: Leveraging Large\n  Language Models for Trauma Assessments",
        "link": "http://arxiv.org/abs/2405.11178v1",
        "abstract": "The shortage of clinical workforce presents significant challenges in mental\nhealthcare, limiting access to formal diagnostics and services. We aim to\ntackle this shortage by integrating a customized large language model (LLM)\ninto the workflow, thus promoting equity in mental healthcare for the general\npopulation. Although LLMs have showcased their capability in clinical\ndecision-making, their adaptation to severe conditions like Post-traumatic\nStress Disorder (PTSD) remains largely unexplored. Therefore, we collect 411\nclinician-administered diagnostic interviews and devise a novel approach to\nobtain high-quality data. Moreover, we build a comprehensive framework to\nautomate PTSD diagnostic assessments based on interview contents by leveraging\ntwo state-of-the-art LLMs, GPT-4 and Llama-2, with potential for broader\nclinical diagnoses. Our results illustrate strong promise for LLMs, tested on\nour dataset, to aid clinicians in diagnostic validation. To the best of our\nknowledge, this is the first AI system that fully automates assessments for\nmental illness based on clinician-administered interviews.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Sichang Tu",
            "Abigail Powers",
            "Natalie Merrill",
            "Negar Fani",
            "Sierra Carter",
            "Stephen Doogan",
            "Jinho D. Choi"
        ],
        "published": "2024-05-18T05:04:18Z"
    },
    {
        "title": "Outlier-Robust Long-Term Robotic Mapping Leveraging Ground Segmentation",
        "link": "http://arxiv.org/abs/2405.11176v2",
        "abstract": "Despite the remarkable advancements in deep learning-based perception\ntechnologies and simultaneous localization and mapping (SLAM), one can face the\nfailure of these approaches when robots encounter scenarios outside their\nmodeled experiences (here, the term modeling encompasses both conventional\npattern finding and data-driven approaches). In particular, because\nlearning-based methods are prone to catastrophic failure when operated in\nuntrained scenes, there is still a demand for conventional yet robust\napproaches that work out of the box in diverse scenarios, such as real-world\nrobotic services and SLAM competitions. In addition, the dynamic nature of\nreal-world environments, characterized by changing surroundings over time and\nthe presence of moving objects, leads to undesirable data points that hinder a\nrobot from localization and path planning. Consequently, methodologies that\nenable long-term map management, such as multi-session SLAM and static map\nbuilding, become essential. Therefore, to achieve a robust long-term robotic\nmapping system that can work out of the box, first, I propose (i) fast and\nrobust ground segmentation to reject the ground points, which are featureless\nand thus not helpful for localization and mapping. Then, by employing the\nconcept of graduated non-convexity (GNC), I propose (ii) outlier-robust\nregistration with ground segmentation that overcomes the presence of gross\noutliers within the feature matching results, and (iii) hierarchical\nmulti-session SLAM that not only uses our proposed GNC-based registration but\nalso employs a GNC solver to be robust against outlier loop candidates.\nFinally, I propose (iv) instance-aware static map building that can handle the\npresence of moving objects in the environment based on the observation that\nmost moving objects in urban environments are inevitably in contact with the\nground.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "authors": [
            "Hyungtae Lim"
        ],
        "published": "2024-05-18T04:56:15Z"
    },
    {
        "title": "Graph Feedback Bandits with Similar Arms",
        "link": "http://arxiv.org/abs/2405.11171v1",
        "abstract": "In this paper, we study the stochastic multi-armed bandit problem with graph\nfeedback. Motivated by the clinical trials and recommendation problem, we\nassume that two arms are connected if and only if they are similar (i.e., their\nmeans are close enough). We establish a regret lower bound for this novel\nfeedback structure and introduce two UCB-based algorithms: D-UCB with\nproblem-independent regret upper bounds and C-UCB with problem-dependent upper\nbounds. Leveraging the similarity structure, we also consider the scenario\nwhere the number of arms increases over time. Practical applications related to\nthis scenario include Q\\&A platforms (Reddit, Stack Overflow, Quora) and\nproduct reviews in Amazon and Flipkart. Answers (product reviews) continually\nappear on the website, and the goal is to display the best answers (product\nreviews) at the top. When the means of arms are independently generated from\nsome distribution, we provide regret upper bounds for both algorithms and\ndiscuss the sub-linearity of bounds in relation to the distribution of means.\nFinally, we conduct experiments to validate the theoretical results.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Han Qi",
            "Guo Fei",
            "Li Zhu"
        ],
        "published": "2024-05-18T04:20:14Z"
    },
    {
        "title": "A fast and robust discrete FFT-based solver for computational\n  homogenization",
        "link": "http://arxiv.org/abs/2405.11168v1",
        "abstract": "We propose a new discrete FFT-based method for computational homogenization\nof micromechanics on a regular grid that is simple, fast and robust. The\ndiscretization scheme is based on a tetrahedral stencil that displays three\ncrucial properties. First, and most importantly, the Fourier representation of\nthe associated Green operator is defined for any finite q-vector generated by\nthe periodic boundary conditions and that does not belong to the Reciprocal\nLattice of the discrete grids. As shown in the paper, this property guaranties\nthat, for any elastic contrats, even infinite, mechanical equilibrium is always\nmathematically stable, i.e. free of any unphysical patterns, such as\noscillations, ringing or checkerboarding, a property which is not shared by the\noriginal Moulinec-Suquet method \\cite{moulinec1994fast,moulinec1998numerical}\nnor by the rotated scheme proposed by Willot \\cite{willot2015fourier}. Second,\nthe components of tensorial quantities are all defined on the same location,\nwhich permits the use of any elastic anisotropy and any spatial variation of\nthe material fields. Third, convergence to equilibrium using the simplest\niterative scheme, the \"basic scheme\", is fast and the number of iterates\nstabilizes at high contrasts, so that infinite contrast is obtained without\nadditional computational cost.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Alphonse Finel"
        ],
        "published": "2024-05-18T04:05:47Z"
    },
    {
        "title": "On the Computation of Square Roots and Inverse Square Roots of Gram\n  Matrices for Surface Integral Equations in Electromagnetics",
        "link": "http://arxiv.org/abs/2405.11167v1",
        "abstract": "Surface integral equations (SIEs)-based boundary element methods are widely\nused for analyzing electromagnetic scattering scenarii. However, after\ndiscretization of SIEs, the spectrum and eigenvectors of the boundary element\nmatrices are not usually representative of the spectrum and eigenfunctions of\nthe underlying surface integral operators, which can be problematic for methods\nthat rely heavily on spectral properties. To address this issue, we delineate\nsome efficient algorithms that allow for the computation of matrix square roots\nand inverse square roots of the Gram matrices corresponding to the\ndiscretization scheme, which can be used for revealing the spectrum of standard\nelectromagnetic integral operators. The algorithms, which are based on properly\nchosen expansions of the square root and inverse square root functions, are\nquite effective when applied to several of the most relevant Gram matrices used\nfor boundary element discretizations in electromagnetics. Tables containing\ndifferent sets of expansion coefficients are provided along with comparative\nnumerical experiments that evidence advantages and disadvantages of the\ndifferent approaches. In addition, to demonstrate the spectrum-revealing\nproperties of the proposed techniques, they are applied to the discretization\nof the problem of scattering by a sphere for which the analytic spectrum is\nknown.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Rui Chen",
            "Adrien Merlini",
            "Francesco P. Andriulli"
        ],
        "published": "2024-05-18T04:02:28Z"
    },
    {
        "title": "Automated Multi-level Preference for MLLMs",
        "link": "http://arxiv.org/abs/2405.11165v1",
        "abstract": "Current multimodal Large Language Models (MLLMs) suffer from\n``hallucination'', occasionally generating responses that are not grounded in\nthe input images. To tackle this challenge, one promising path is to utilize\nreinforcement learning from human feedback (RLHF), which steers MLLMs towards\nlearning superior responses while avoiding inferior ones. We rethink the common\npractice of using binary preferences (\\emph{i.e.}, superior, inferior), and\nfind that adopting multi-level preferences (\\emph{e.g.}, superior, medium,\ninferior) is better for two benefits: 1) It narrows the gap between adjacent\nlevels, thereby encouraging MLLMs to discern subtle differences. 2) It further\nintegrates cross-level comparisons (beyond adjacent-level comparisons), thus\nproviding a broader range of comparisons with hallucination examples. To verify\nour viewpoint, we present the Automated Multi-level Preference (\\textbf{AMP})\nframework for MLLMs. To facilitate this framework, we first develop an\nautomated dataset generation pipeline that provides high-quality multi-level\npreference datasets without any human annotators. Furthermore, we design the\nMulti-level Direct Preference Optimization (MDPO) algorithm to robustly conduct\ncomplex multi-level preference learning. Additionally, we propose a new\nhallucination benchmark, MRHal-Bench. Extensive experiments across public\nhallucination and general benchmarks, as well as our MRHal-Bench, demonstrate\nthe effectiveness of our proposed method.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Mengxi Zhang",
            "Kang Rong"
        ],
        "published": "2024-05-18T03:49:37Z"
    },
    {
        "title": "Domain Generalization for Zero-calibration BCIs with Knowledge\n  Distillation-based Phase Invariant Feature Extraction",
        "link": "http://arxiv.org/abs/2405.11163v1",
        "abstract": "The distribution shift of electroencephalography (EEG) data causes poor\ngeneralization of braincomputer interfaces (BCIs) in unseen domains. Some\nmethods try to tackle this challenge by collecting a portion of user data for\ncalibration. However, it is time-consuming, mentally fatiguing, and\nuser-unfriendly. To achieve zerocalibration BCIs, most studies employ domain\ngeneralization (DG) techniques to learn invariant features across different\ndomains in the training set. However, they fail to fully explore invariant\nfeatures within the same domain, leading to limited performance. In this paper,\nwe present an novel method to learn domain-invariant features from both\ninterdomain and intra-domain perspectives. For intra-domain invariant features,\nwe propose a knowledge distillation framework to extract EEG phase-invariant\nfeatures within one domain. As for inter-domain invariant features, correlation\nalignment is used to bridge distribution gaps across multiple domains.\nExperimental results on three public datasets validate the effectiveness of our\nmethod, showcasing stateof-the-art performance. To the best of our knowledge,\nthis is the first domain generalization study that exploit Fourier phase\ninformation as an intra-domain invariant feature to facilitate EEG\ngeneralization. More importantly, the zerocalibration BCI based on inter- and\nintra-domain invariant features has significant potential to advance the\npractical applications of BCIs in real world.",
        "subjects": [
            "cs.HC",
            "eess.SP"
        ],
        "authors": [
            "Zilin Liang",
            "Zheng Zheng",
            "Weihai Chen",
            "Xinzhi Ma",
            "Zhongcai Pei",
            "Xiantao Sun"
        ],
        "published": "2024-05-18T03:35:53Z"
    },
    {
        "title": "LG AI Research & KAIST at EHRSQL 2024: Self-Training Large Language\n  Models with Pseudo-Labeled Unanswerable Questions for a Reliable Text-to-SQL\n  System on EHRs",
        "link": "http://arxiv.org/abs/2405.11162v1",
        "abstract": "Text-to-SQL models are pivotal for making Electronic Health Records (EHRs)\naccessible to healthcare professionals without SQL knowledge. With the\nadvancements in large language models, these systems have become more adept at\ntranslating complex questions into SQL queries. Nonetheless, the critical need\nfor reliability in healthcare necessitates these models to accurately identify\nunanswerable questions or uncertain predictions, preventing misinformation. To\naddress this problem, we present a self-training strategy using pseudo-labeled\nunanswerable questions to enhance the reliability of text-to-SQL models for\nEHRs. This approach includes a two-stage training process followed by a\nfiltering method based on the token entropy and query execution. Our\nmethodology's effectiveness is validated by our top performance in the EHRSQL\n2024 shared task, showcasing the potential to improve healthcare\ndecision-making through more reliable text-to-SQL systems.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yongrae Jo",
            "Seongyun Lee",
            "Minju Seo",
            "Sung Ju Hwang",
            "Moontae Lee"
        ],
        "published": "2024-05-18T03:25:44Z"
    },
    {
        "title": "Dusk Till Dawn: Self-supervised Nighttime Stereo Depth Estimation using\n  Visual Foundation Models",
        "link": "http://arxiv.org/abs/2405.11158v1",
        "abstract": "Self-supervised depth estimation algorithms rely heavily on frame-warping\nrelationships, exhibiting substantial performance degradation when applied in\nchallenging circumstances, such as low-visibility and nighttime scenarios with\nvarying illumination conditions. Addressing this challenge, we introduce an\nalgorithm designed to achieve accurate self-supervised stereo depth estimation\nfocusing on nighttime conditions. Specifically, we use pretrained visual\nfoundation models to extract generalised features across challenging scenes and\npresent an efficient method for matching and integrating these features from\nstereo frames. Moreover, to prevent pixels violating photometric consistency\nassumption from negatively affecting the depth predictions, we propose a novel\nmasking approach designed to filter out such pixels. Lastly, addressing\nweaknesses in the evaluation of current depth estimation algorithms, we present\nnovel evaluation metrics. Our experiments, conducted on challenging datasets\nincluding Oxford RobotCar and Multi-Spectral Stereo, demonstrate the robust\nimprovements realized by our approach. Code is available at:\nhttps://github.com/madhubabuv/dtd",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Madhu Vankadari",
            "Samuel Hodgson",
            "Sangyun Shin",
            "Kaichen Zhou Andrew Markham",
            "Niki Trigoni"
        ],
        "published": "2024-05-18T03:07:23Z"
    },
    {
        "title": "Towards Modular LLMs by Building and Reusing a Library of LoRAs",
        "link": "http://arxiv.org/abs/2405.11157v1",
        "abstract": "The growing number of parameter-efficient adaptations of a base large\nlanguage model (LLM) calls for studying whether we can reuse such trained\nadapters to improve performance for new tasks. We study how to best build a\nlibrary of adapters given multi-task data and devise techniques for both\nzero-shot and supervised task generalization through routing in such library.\nWe benchmark existing approaches to build this library and introduce\nmodel-based clustering, MBC, a method that groups tasks based on the similarity\nof their adapter parameters, indirectly optimizing for transfer across the\nmulti-task dataset. To re-use the library, we present a novel zero-shot routing\nmechanism, Arrow, which enables dynamic selection of the most relevant adapters\nfor new inputs without the need for retraining. We experiment with several\nLLMs, such as Phi-2 and Mistral, on a wide array of held-out tasks, verifying\nthat MBC-based adapters and Arrow routing lead to superior generalization to\nnew tasks. We make steps towards creating modular, adaptable LLMs that can\nmatch or outperform traditional joint training.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "authors": [
            "Oleksiy Ostapenko",
            "Zhan Su",
            "Edoardo Maria Ponti",
            "Laurent Charlin",
            "Nicolas Le Roux",
            "Matheus Pereira",
            "Lucas Caccia",
            "Alessandro Sordoni"
        ],
        "published": "2024-05-18T03:02:23Z"
    },
    {
        "title": "Inner-approximate Reachability Computation via Zonotopic Boundary\n  Analysis",
        "link": "http://arxiv.org/abs/2405.11155v2",
        "abstract": "Inner-approximate reachability analysis involves calculating subsets of\nreachable sets, known as inner-approximations. This analysis is crucial in the\nfields of dynamic systems analysis and control theory as it provides a reliable\nestimation of the set of states that a system can reach from given initial\nstates at a specific time instant. In this paper, we study the\ninner-approximate reachability analysis problem based on the set-boundary\nreachability method for systems modelled by ordinary differential equations, in\nwhich the computed inner-approximations are represented with zonotopes. The\nset-boundary reachability method computes an inner-approximation by excluding\nstates reached from the initial set's boundary. The effectiveness of this\nmethod is highly dependent on the efficient extraction of the exact boundary of\nthe initial set. To address this, we propose methods leveraging boundary and\ntiling matrices that can efficiently extract and refine the exact boundary of\nthe initial set represented by zonotopes. Additionally, we enhance the\nexclusion strategy by contracting the outer-approximations in a flexible way,\nwhich allows for the computation of less conservative inner-approximations. To\nevaluate the proposed method, we compare it with state-of-the-art methods\nagainst a series of benchmarks. The numerical results demonstrate that our\nmethod is not only efficient but also accurate in computing\ninner-approximations.",
        "subjects": [
            "eess.SY",
            "cs.CC",
            "cs.SY"
        ],
        "authors": [
            "Dejin Ren",
            "Zhen Liang",
            "Chenyu Wu",
            "Jianqiang Ding",
            "Taoran Wu",
            "Bai Xue"
        ],
        "published": "2024-05-18T02:59:32Z"
    },
    {
        "title": "Revisiting the Robust Generalization of Adversarial Prompt Tuning",
        "link": "http://arxiv.org/abs/2405.11154v1",
        "abstract": "Understanding the vulnerability of large-scale pre-trained vision-language\nmodels like CLIP against adversarial attacks is key to ensuring zero-shot\ngeneralization capacity on various downstream tasks. State-of-the-art defense\nmechanisms generally adopt prompt learning strategies for adversarial\nfine-tuning to improve the adversarial robustness of the pre-trained model\nwhile keeping the efficiency of adapting to downstream tasks. Such a setup\nleads to the problem of over-fitting which impedes further improvement of the\nmodel's generalization capacity on both clean and adversarial examples. In this\nwork, we propose an adaptive Consistency-guided Adversarial Prompt Tuning\n(i.e., CAPT) framework that utilizes multi-modal prompt learning to enhance the\nalignment of image and text features for adversarial examples and leverage the\nstrong generalization of pre-trained CLIP to guide the model-enhancing its\nrobust generalization on adversarial examples while maintaining its accuracy on\nclean ones. We also design a novel adaptive consistency objective function to\nbalance the consistency of adversarial inputs and clean inputs between the\nfine-tuning model and the pre-trained model. We conduct extensive experiments\nacross 14 datasets and 4 data sparsity schemes (from 1-shot to full training\ndata settings) to show the superiority of CAPT over other state-of-the-art\nadaption methods. CAPT demonstrated excellent performance in terms of the\nin-distribution performance and the generalization under input distribution\nshift and across datasets.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Fan Yang",
            "Mingxuan Xia",
            "Sangzhou Xia",
            "Chicheng Ma",
            "Hui Hui"
        ],
        "published": "2024-05-18T02:54:41Z"
    },
    {
        "title": "Multi-scale Information Sharing and Selection Network with Boundary\n  Attention for Polyp Segmentation",
        "link": "http://arxiv.org/abs/2405.11151v1",
        "abstract": "Polyp segmentation for colonoscopy images is of vital importance in clinical\npractice. It can provide valuable information for colorectal cancer diagnosis\nand surgery. While existing methods have achieved relatively good performance,\npolyp segmentation still faces the following challenges: (1) Varying lighting\nconditions in colonoscopy and differences in polyp locations, sizes, and\nmorphologies. (2) The indistinct boundary between polyps and surrounding\ntissue. To address these challenges, we propose a Multi-scale information\nsharing and selection network (MISNet) for polyp segmentation task. We design a\nSelectively Shared Fusion Module (SSFM) to enforce information sharing and\nactive selection between low-level and high-level features, thereby enhancing\nmodel's ability to capture comprehensive information. We then design a Parallel\nAttention Module (PAM) to enhance model's attention to boundaries, and a\nBalancing Weight Module (BWM) to facilitate the continuous refinement of\nboundary segmentation in the bottom-up process. Experiments on five polyp\nsegmentation datasets demonstrate that MISNet successfully improved the\naccuracy and clarity of segmentation result, outperforming state-of-the-art\nmethods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Xiaolu Kang",
            "Zhuoqi Ma",
            "Kang Liu",
            "Yunan Li",
            "Qiguang Miao"
        ],
        "published": "2024-05-18T02:48:39Z"
    },
    {
        "title": "Election Polls on Social Media: Prevalence, Biases, and Voter Fraud\n  Beliefs",
        "link": "http://arxiv.org/abs/2405.11146v2",
        "abstract": "Social media platforms allow users to create polls to gather public opinion\non diverse topics. However, we know little about what such polls are used for\nand how reliable they are, especially in significant contexts like elections.\nFocusing on the 2020 presidential elections in the U.S., this study shows that\noutcomes of election polls on Twitter deviate from election results despite\ntheir prevalence. Leveraging demographic inference and statistical analysis, we\nfind that Twitter polls are disproportionately authored by older males and\nexhibit a large bias towards candidate Donald Trump relative to representative\nmainstream polls. We investigate potential sources of biased outcomes from the\npoint of view of inauthentic, automated, and counter-normative behavior. Using\nsocial media experiments and interviews with poll authors, we identify\ninconsistencies between public vote counts and those privately visible to poll\nauthors, with the gap potentially attributable to purchased votes. We also find\nthat Twitter accounts participating in election polls are more likely to be\nbots, and election poll outcomes tend to be more biased, before the election\nday than after. Finally, we identify instances of polls spreading voter fraud\nconspiracy theories and estimate that a couple thousand of such polls were\nposted in 2020. The study discusses the implications of biased election polls\nin the context of transparency and accountability of social media platforms.",
        "subjects": [
            "cs.SI"
        ],
        "authors": [
            "Stephen Scarano",
            "Vijayalakshmi Vasudevan",
            "Mattia Samory",
            "Kai-Cheng Yang",
            "JungHwan Yang",
            "Przemyslaw A. Grabowicz"
        ],
        "published": "2024-05-18T02:29:35Z"
    },
    {
        "title": "Detecting Multimodal Situations with Insufficient Context and Abstaining\n  from Baseless Predictions",
        "link": "http://arxiv.org/abs/2405.11145v2",
        "abstract": "Despite the widespread adoption of Vision-Language Understanding (VLU)\nbenchmarks such as VQA v2, OKVQA, A-OKVQA, GQA, VCR, SWAG, and VisualCOMET, our\nanalysis reveals a pervasive issue affecting their integrity: these benchmarks\ncontain samples where answers rely on assumptions unsupported by the provided\ncontext. Training models on such data foster biased learning and hallucinations\nas models tend to make similar unwarranted assumptions. To address this issue,\nwe collect contextual data for each sample whenever available and train a\ncontext selection module to facilitate evidence-based model predictions. Strong\nimprovements across multiple benchmarks demonstrate the effectiveness of our\napproach. Further, we develop a general-purpose Context-AwaRe Abstention (CARA)\ndetector to identify samples lacking sufficient context and enhance model\naccuracy by abstaining from responding if the required context is absent. CARA\nexhibits generalization to new benchmarks it wasn't trained on, underscoring\nits utility for future VLU benchmarks in detecting or cleaning samples with\ninadequate context. Finally, we curate a Context Ambiguity and Sufficiency\nEvaluation (CASE) set to benchmark the performance of insufficient context\ndetectors. Overall, our work represents a significant advancement in ensuring\nthat vision-language models generate trustworthy and evidence-based outputs in\ncomplex real-world scenarios.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.MM"
        ],
        "authors": [
            "Junzhang Liu",
            "Zhecan Wang",
            "Hammad Ayyubi",
            "Haoxuan You",
            "Chris Thomas",
            "Rui Sun",
            "Shih-Fu Chang",
            "Kai-Wei Chang"
        ],
        "published": "2024-05-18T02:21:32Z"
    },
    {
        "title": "Enhancing Automata Learning with Statistical Machine Learning: A Network\n  Security Case Study",
        "link": "http://arxiv.org/abs/2405.11141v1",
        "abstract": "Intrusion detection systems are crucial for network security. Verification of\nthese systems is complicated by various factors, including the heterogeneity of\nnetwork platforms and the continuously changing landscape of cyber threats. In\nthis paper, we use automata learning to derive state machines from\nnetwork-traffic data with the objective of supporting behavioural verification\nof intrusion detection systems. The most innovative aspect of our work is\naddressing the inability to directly apply existing automata learning\ntechniques to network-traffic data due to the numeric nature of such data.\nSpecifically, we use interpretable machine learning (ML) to partition numeric\nranges into intervals that strongly correlate with a system's decisions\nregarding intrusion detection. These intervals are subsequently used to\nabstract numeric ranges before automata learning. We apply our ML-enhanced\nautomata learning approach to a commercial network intrusion detection system\ndeveloped by our industry partner, RabbitRun Technologies. Our approach results\nin an average 67.5% reduction in the number of states and transitions of the\nlearned state machines, while achieving an average 28% improvement in accuracy\ncompared to using expertise-based numeric data abstraction. Furthermore, the\nresulting state machines help practitioners in verifying system-level security\nrequirements and exploring previously unknown system behaviours through model\nchecking and temporal query checking. We make our implementation and\nexperimental data available online.",
        "subjects": [
            "cs.CR",
            "cs.SE"
        ],
        "authors": [
            "Negin Ayoughi",
            "Shiva Nejati",
            "Mehrdad Sabetzadeh",
            "Patricio Saavedra"
        ],
        "published": "2024-05-18T02:10:41Z"
    },
    {
        "title": "RuleFuser: Injecting Rules in Evidential Networks for Robust\n  Out-of-Distribution Trajectory Prediction",
        "link": "http://arxiv.org/abs/2405.11139v1",
        "abstract": "Modern neural trajectory predictors in autonomous driving are developed using\nimitation learning (IL) from driving logs. Although IL benefits from its\nability to glean nuanced and multi-modal human driving behaviors from large\ndatasets, the resulting predictors often struggle with out-of-distribution\n(OOD) scenarios and with traffic rule compliance. On the other hand, classical\nrule-based predictors, by design, can predict traffic rule satisfying behaviors\nwhile being robust to OOD scenarios, but these predictors fail to capture\nnuances in agent-to-agent interactions and human driver's intent. In this\npaper, we present RuleFuser, a posterior-net inspired evidential framework that\ncombines neural predictors with classical rule-based predictors to draw on the\ncomplementary benefits of both, thereby striking a balance between performance\nand traffic rule compliance. The efficacy of our approach is demonstrated on\nthe real-world nuPlan dataset where RuleFuser leverages the higher performance\nof the neural predictor in in-distribution (ID) scenarios and the higher safety\noffered by the rule-based predictor in OOD scenarios.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Jay Patrikar",
            "Sushant Veer",
            "Apoorva Sharma",
            "Marco Pavone",
            "Sebastian Scherer"
        ],
        "published": "2024-05-18T01:49:16Z"
    },
    {
        "title": "Spatial Models for Crowdsourced Internet Access Network Performance\n  Measurements",
        "link": "http://arxiv.org/abs/2405.11138v2",
        "abstract": "Despite significant investments in access network infrastructure, universal\naccess to high-quality Internet connectivity remains a challenge. Policymakers\noften rely on large-scale, crowdsourced measurement datasets to assess the\ndistribution of access network performance across geographic areas. These\ndecisions typically rest on the assumption that Internet performance is\nuniformly distributed within predefined social boundaries, such as zip codes,\ncensus tracts, or community areas. However, this assumption may not be valid\nfor two reasons: (1) crowdsourced measurements often exhibit non-uniform\nsampling densities within geographic areas; and (2) predefined social\nboundaries may not align with the actual boundaries of Internet infrastructure.\n  In this paper, we model Internet performance as a spatial process. We apply\nand evaluate a series of statistical techniques to: (1) aggregate Internet\nperformance over a geographic region; (2) overlay interpolated maps with\nvarious sampling boundary choices; and (3) spatially cluster boundary units to\nidentify areas with similar performance characteristics. We evaluated the\neffectiveness of these using a 17-month-long crowdsourced dataset from Ookla\nSpeedtest. We evaluate several leading interpolation methods at varying spatial\nscales. Further, we examine the similarity between the resulting boundaries for\nsmaller realizations of the dataset. Our findings suggest that our combination\nof techniques achieves a 56% gain in similarity score over traditional methods\nthat rely on aggregates over raw measurement values for performance\nsummarization. Our work highlights an urgent need for more sophisticated\nstrategies in understanding and addressing Internet access disparities.",
        "subjects": [
            "cs.NI",
            "cs.CY"
        ],
        "authors": [
            "Taveesh Sharma",
            "Paul Schmitt",
            "Francesco Bronzino",
            "Nick Feamster",
            "Nicole Marwell"
        ],
        "published": "2024-05-18T01:39:22Z"
    },
    {
        "title": "AquaLoRA: Toward White-box Protection for Customized Stable Diffusion\n  Models via Watermark LoRA",
        "link": "http://arxiv.org/abs/2405.11135v1",
        "abstract": "Diffusion models have achieved remarkable success in generating high-quality\nimages. Recently, the open-source models represented by Stable Diffusion (SD)\nare thriving and are accessible for customization, giving rise to a vibrant\ncommunity of creators and enthusiasts. However, the widespread availability of\ncustomized SD models has led to copyright concerns, like unauthorized model\ndistribution and unconsented commercial use. To address it, recent works aim to\nlet SD models output watermarked content for post-hoc forensics. Unfortunately,\nnone of them can achieve the challenging white-box protection, wherein the\nmalicious user can easily remove or replace the watermarking module to fail the\nsubsequent verification. For this, we propose \\texttt{\\method} as the first\nimplementation under this scenario. Briefly, we merge watermark information\ninto the U-Net of Stable Diffusion Models via a watermark Low-Rank Adaptation\n(LoRA) module in a two-stage manner. For watermark LoRA module, we devise a\nscaling matrix to achieve flexible message updates without retraining. To\nguarantee fidelity, we design Prior Preserving Fine-Tuning (PPFT) to ensure\nwatermark learning with minimal impacts on model distribution, validated by\nproofs. Finally, we conduct extensive experiments and ablation studies to\nverify our design.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Weitao Feng",
            "Wenbo Zhou",
            "Jiyan He",
            "Jie Zhang",
            "Tianyi Wei",
            "Guanlin Li",
            "Tianwei Zhang",
            "Weiming Zhang",
            "Nenghai Yu"
        ],
        "published": "2024-05-18T01:25:47Z"
    },
    {
        "title": "XCAT-2.0: A Comprehensive Library of Personalized Digital Twins Derived\n  from CT Scans",
        "link": "http://arxiv.org/abs/2405.11133v1",
        "abstract": "Virtual Imaging Trials (VIT) offer a cost-effective and scalable approach for\nevaluating medical imaging technologies. Computational phantoms, which mimic\nreal patient anatomy and physiology, play a central role in VIT. However, the\ncurrent libraries of computational phantoms face limitations, particularly in\nterms of sample size and diversity. Insufficient representation of the\npopulation hampers accurate assessment of imaging technologies across different\npatient groups. Traditionally, phantoms were created by manual segmentation,\nwhich is a laborious and time-consuming task, impeding the expansion of phantom\nlibraries. This study presents a framework for realistic computational phantom\nmodeling using a suite of four deep learning segmentation models, followed by\nthree forms of automated organ segmentation quality control. Over 2500\ncomputational phantoms with up to 140 structures illustrating a sophisticated\napproach to detailed anatomical modeling are released. Phantoms are available\nin both voxelized and surface mesh formats. The framework is aggregated with an\nin-house CT scanner simulator to produce realistic CT images. The framework can\npotentially advance virtual imaging trials, facilitating comprehensive and\nreliable evaluations of medical imaging technologies. Phantoms may be requested\nat https://cvit.duke.edu/resources/, code, model weights, and sample CT images\nare available at https://xcat-2.github.io.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Lavsen Dahal",
            "Mobina Ghojoghnejad",
            "Dhrubajyoti Ghosh",
            "Yubraj Bhandari",
            "David Kim",
            "Fong Chi Ho",
            "Fakrul Islam Tushar",
            "Ehsan Abadi",
            "Ehsan Samei",
            "Joseph Lo",
            "Paul Segars"
        ],
        "published": "2024-05-18T01:09:02Z"
    },
    {
        "title": "Gallium Nitride (GaN) based High-Power Multilevel H-Bridge Inverter for\n  Wireless Power Transfer of Electric Vehicles",
        "link": "http://arxiv.org/abs/2405.11131v1",
        "abstract": "This paper presents a design and implementation of a high-power Gallium\nNitride (GaN)-based multilevel Hbridge inverter to excite wireless charging\ncoils for the wireless power transfer of electric vehicles (EVs). Compared to\nthe traditional conductive charging, wireless charging technology offers a\nsafer and more convenient way to charge EVs. Due to the increasing demand of\nfast charging, high-power inverters play a crucial role in exciting the\nwireless charging coils within a wireless power transfer system. This paper\ndetails the system specifications for the wireless charging of EVs, providing\ntheoretical analysis and a control strategy for the modular design of a 75-kW\n3-level and 4-level Hbridge inverter. The goal is to deliver a low-distortion\nexcitation voltage to the wireless charging coils. LTspice simulation results,\nincluding output voltage, Fast Fourier Transform (FFT) analysis for both\n3-level and 4-level H-bridge inverters, are presented to validate the control\nstrategy and demonstrate the elimination of output harmonic components in the\nmodular design. A GaNbased inverter prototype was employed to deliver a 85-kHz\npower to the wireless charging pads of the wireless power transfer system.\nExperimental results at two different voltage and power levels, 100V-215W and\n150V-489W, validate the successful performance of the GaN inverter in the\nwireless charging system.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Javad Chevinly",
            "Shervin Salehi Rad",
            "Elias Nadi",
            "Bogdan Proca",
            "John Wolgemuth",
            "Anthony Calabro",
            "Hua Zhang",
            "Fei Lu"
        ],
        "published": "2024-05-18T01:05:03Z"
    },
    {
        "title": "WIP: A Unit Testing Framework for Self-Guided Personalized Online\n  Robotics Learning",
        "link": "http://arxiv.org/abs/2405.11130v1",
        "abstract": "Our ongoing development and deployment of an online robotics education\nplatform highlighted a gap in providing an interactive, feedback-rich learning\nenvironment essential for mastering programming concepts in robotics, which\nthey were not getting with the traditional code-simulate-turn in workflow.\nSince teaching resources are limited, students would benefit from feedback in\nreal-time to find and fix their mistakes in the programming assignments. To\naddress these concerns, this paper will focus on creating a system for unit\ntesting while integrating it into the course workflow. We facilitate this\nreal-time feedback by including unit testing in the design of programming\nassignments so students can understand and fix their errors on their own and\nwithout the prior help of instructors/TAs serving as a bottleneck. In line with\nthe framework's personalized student-centered approach, this method makes it\neasier for students to revise, and debug their programming work, encouraging\nhands-on learning. The course workflow updated to include unit tests will\nstrengthen the learning environment and make it more interactive so that\nstudents can learn how to program robots in a self-guided fashion.",
        "subjects": [
            "cs.RO",
            "cs.HC",
            "cs.SE"
        ],
        "authors": [
            "Ponkoj Chandra Shill",
            "David Feil-Seifer",
            "Jiullian-Lee Vargas Ruiz",
            "Rui Wu"
        ],
        "published": "2024-05-18T00:56:46Z"
    },
    {
        "title": "MotionGS : Compact Gaussian Splatting SLAM by Motion Filter",
        "link": "http://arxiv.org/abs/2405.11129v1",
        "abstract": "With their high-fidelity scene representation capability, the attention of\nSLAM field is deeply attracted by the Neural Radiation Field (NeRF) and 3D\nGaussian Splatting (3DGS). Recently, there has been a Surge in NeRF-based SLAM,\nwhile 3DGS-based SLAM is sparse. A novel 3DGS-based SLAM approach with a fusion\nof deep visual feature, dual keyframe selection and 3DGS is presented in this\npaper. Compared with the existing methods, the proposed selectively tracking is\nachieved by feature extraction and motion filter on each frame. The joint\noptimization of pose and 3D Gaussian runs through the entire mapping process.\nAdditionally, the coarse-to-fine pose estimation and compact Gaussian scene\nrepresentation are implemented by dual keyfeature selection and novel loss\nfunctions. Experimental results demonstrate that the proposed algorithm not\nonly outperforms the existing methods in tracking and mapping, but also has\nless memory usage.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xinli Guo",
            "Peng Han",
            "Weidong Zhang",
            "Hongtian Chen"
        ],
        "published": "2024-05-18T00:47:29Z"
    },
    {
        "title": "Parsimonious Optimal Dynamic Partial Order Reduction",
        "link": "http://arxiv.org/abs/2405.11128v1",
        "abstract": "Stateless model checking is a fully automatic verification technique for\nconcurrent programs that checks for safety violations by exploring all possible\nthread schedulings. It becomes effective when coupled with Dynamic Partial\nOrder Reduction (DPOR), which introduces an equivalence on schedulings and\nreduces the amount of needed exploration. DPOR algorithms that are\n\\emph{optimal} are particularly effective in that they guarantee to explore\n\\emph{exactly} one execution from each equivalence class. Unfortunately,\nexisting sequence-based optimal algorithms may in the worst case consume memory\nthat is exponential in the size of the analyzed program. In this paper, we\npresent Parsimonious-OPtimal (POP) DPOR, an optimal DPOR algorithm for\nanalyzing multi-threaded programs under sequential consistency, whose space\nconsumption is polynomial in the worst case. POP combines several novel\nalgorithmic techniques, including (i) a parsimonious race reversal strategy,\nwhich avoids multiple reversals of the same race, (ii) an eager race reversal\nstrategy to avoid storing initial fragments of to-be-explored executions, and\n(iii) a space-efficient scheme for preventing redundant exploration, which\nreplaces the use of sleep sets. Our implementation in Nidhugg shows that these\ntechniques can significantly speed up the analysis of concurrent programs, and\ndo so with low memory consumption. Comparison to a related optimal DPOR\nalgorithm for a different representation of concurrent executions as graphs\nshows that POP has comparable worst-case performance for smaller benchmarks and\noutperforms the other one for larger programs.",
        "subjects": [
            "cs.PL",
            "cs.SE"
        ],
        "authors": [
            "Parosh Aziz Abdulla",
            "Mohamed Faouzi Atig",
            "Sarbojit Das",
            "Bengt Jonsson",
            "Konstantinos Sagonas"
        ],
        "published": "2024-05-18T00:07:26Z"
    }
]