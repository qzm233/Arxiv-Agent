[
    {
        "title": "Lifelong Learning and Selective Forgetting via Contrastive Strategy",
        "link": "http://arxiv.org/abs/2405.18663v1",
        "abstract": "Lifelong learning aims to train a model with good performance for new tasks\nwhile retaining the capacity of previous tasks. However, some practical\nscenarios require the system to forget undesirable knowledge due to privacy\nissues, which is called selective forgetting. The joint task of the two is\ndubbed Learning with Selective Forgetting (LSF). In this paper, we propose a\nnew framework based on contrastive strategy for LSF. Specifically, for the\npreserved classes (tasks), we make features extracted from different samples\nwithin a same class compacted. And for the deleted classes, we make the\nfeatures from different samples of a same class dispersed and irregular, i.e.,\nthe network does not have any regular response to samples from a specific\ndeleted class as if the network has no training at all. Through maintaining or\ndisturbing the feature distribution, the forgetting and memory of different\nclasses can be or independent of each other. Experiments are conducted on four\nbenchmark datasets, and our method acieves new state-of-the-art.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Lianlei Shan",
            "Wenzhang Zhou",
            "Wei Li",
            "Xingyu Ding"
        ],
        "published": "2024-05-28T23:57:48Z"
    },
    {
        "title": "Understanding Intrinsic Socioeconomic Biases in Large Language Models",
        "link": "http://arxiv.org/abs/2405.18662v1",
        "abstract": "Large Language Models (LLMs) are increasingly integrated into critical\ndecision-making processes, such as loan approvals and visa applications, where\ninherent biases can lead to discriminatory outcomes. In this paper, we examine\nthe nuanced relationship between demographic attributes and socioeconomic\nbiases in LLMs, a crucial yet understudied area of fairness in LLMs. We\nintroduce a novel dataset of one million English sentences to systematically\nquantify socioeconomic biases across various demographic groups. Our findings\nreveal pervasive socioeconomic biases in both established models such as GPT-2\nand state-of-the-art models like Llama 2 and Falcon. We demonstrate that these\nbiases are significantly amplified when considering intersectionality, with\nLLMs exhibiting a remarkable capacity to extract multiple demographic\nattributes from names and then correlate them with specific socioeconomic\nbiases. This research highlights the urgent necessity for proactive and robust\nbias mitigation techniques to safeguard against discriminatory outcomes when\ndeploying these powerful models in critical real-world applications.",
        "subjects": [
            "cs.CL",
            "cs.CY",
            "cs.LG"
        ],
        "authors": [
            "Mina Arzaghi",
            "Florian Carichon",
            "Golnoosh Farnadi"
        ],
        "published": "2024-05-28T23:54:44Z"
    },
    {
        "title": "D-CoRP: Differentiable Connectivity Refinement for Functional Brain\n  Networks",
        "link": "http://arxiv.org/abs/2405.18658v1",
        "abstract": "Brain network is an important tool for understanding the brain, offering\ninsights for scientific research and clinical diagnosis. Existing models for\nbrain networks typically primarily focus on brain regions or overlook the\ncomplexity of brain connectivities. MRI-derived brain network data is commonly\nsusceptible to connectivity noise, underscoring the necessity of incorporating\nconnectivities into the modeling of brain networks. To address this gap, we\nintroduce a differentiable module for refining brain connectivity. We develop\nthe multivariate optimization based on information bottleneck theory to address\nthe complexity of the brain network and filter noisy or redundant connections.\nAlso, our method functions as a flexible plugin that is adaptable to most graph\nneural networks. Our extensive experimental results show that the proposed\nmethod can significantly improve the performance of various baseline models and\noutperform other state-of-the-art methods, indicating the effectiveness and\ngeneralizability of the proposed method in refining brain network connectivity.\nThe code will be released for public availability.",
        "subjects": [
            "q-bio.NC",
            "cs.AI"
        ],
        "authors": [
            "Haoyu Hu",
            "Hongrun Zhang",
            "Chao Li"
        ],
        "published": "2024-05-28T23:49:52Z"
    },
    {
        "title": "The Efficacy of the Connect America Fund in Addressing US Internet\n  Access Inequities",
        "link": "http://arxiv.org/abs/2405.18657v1",
        "abstract": "Residential fixed broadband internet access in the United States (US) has\nlong been distributed inequitably, drawing significant attention from\nresearchers and policymakers. This paper evaluates the efficacy of the Connect\nAmerica Fund (CAF), a key policy intervention aimed at addressing disparities\nin US internet access. CAF subsidizes the creation of new regulated broadband\nmonopolies in underserved areas, aiming to provide comparable internet access,\nin terms of price and speed, to that available in urban regions. Oversight of\nCAF largely relies on data self-reported by internet service providers (ISPs),\nwhich is often questionable. We use the broadband-plan querying tool (BQT) to\ncurate a novel dataset that complements ISP-reported information with\nISP-advertised broadband plan details (download speed and monthly cost) on\npublicly accessible websites. Specifically, we query advertised broadband plans\nfor 687k residential addresses across 15 states, certified as served by ISPs to\nregulators. Our analysis reveals significant discrepancies between ISP-reported\ndata and actual broadband availability. We find that the serviceability\nrate-defined as the fraction of addresses ISPs actively serve out of the total\nqueried, weighted by the number of CAF addresses in a census block group-is\nonly 55%, dropping to as low as 18% in some states. Additionally, the\ncompliance rate-defined as the weighted fraction of addresses where ISPs\nactively serve and advertise download speeds above the FCC's 10 Mbps\nthreshold-is only 33%. We also observe that in a subset of census blocks,\nCAF-funded addresses receive higher broadband speeds than their monopoly-served\nneighbors. These results indicate that while a few users have benefited from\nthis multi-billion dollar program, it has largely failed to achieve its\nintended goal, leaving many targeted rural communities with inadequate or no\nbroadband connectivity.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Haarika Manda",
            "Varshika Srinivasavaradhan",
            "Laasya Koduru",
            "Kevin Zhang",
            "Xuanhe Zhou",
            "Udit Paul",
            "Elizabeth Belding",
            "Arpit Gupta",
            "Tejas N. Narechania"
        ],
        "published": "2024-05-28T23:46:45Z"
    },
    {
        "title": "CAVACHON: a hierarchical variational autoencoder to integrate\n  multi-modal single-cell data",
        "link": "http://arxiv.org/abs/2405.18655v1",
        "abstract": "Paired single-cell sequencing technologies enable the simultaneous\nmeasurement of complementary modalities of molecular data at single-cell\nresolution. Along with the advances in these technologies, many methods based\non variational autoencoders have been developed to integrate these data.\nHowever, these methods do not explicitly incorporate prior biological\nrelationships between the data modalities, which could significantly enhance\nmodeling and interpretation. We propose a novel probabilistic learning\nframework that explicitly incorporates conditional independence relationships\nbetween multi-modal data as a directed acyclic graph using a generalized\nhierarchical variational autoencoder. We demonstrate the versatility of our\nframework across various applications pertinent to single-cell multi-omics data\nintegration. These include the isolation of common and distinct information\nfrom different modalities, modality-specific differential analysis, and\nintegrated cell clustering. We anticipate that the proposed framework can\nfacilitate the construction of highly flexible graphical models that can\ncapture the complexities of biological hypotheses and unravel the connections\nbetween different biological data types, such as different modalities of paired\nsingle-cell multi-omics data. The implementation of the proposed framework can\nbe found in the repository https://github.com/kuijjerlab/CAVACHON.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.GN"
        ],
        "authors": [
            "Ping-Han Hsieh",
            "Ru-Xiu Hsiao",
            "Katalin Ferenc",
            "Anthony Mathelier",
            "Rebekka Burkholz",
            "Chien-Yu Chen",
            "Geir Kjetil Sandve",
            "Tatiana Belova",
            "Marieke Lydia Kuijjer"
        ],
        "published": "2024-05-28T23:44:09Z"
    },
    {
        "title": "Mitigating Object Hallucination via Data Augmented Contrastive Tuning",
        "link": "http://arxiv.org/abs/2405.18654v1",
        "abstract": "Despite their remarkable progress, Multimodal Large Language Models (MLLMs)\ntend to hallucinate factually inaccurate information. In this work, we address\nobject hallucinations in MLLMs, where information is offered about an object\nthat is not present in the model input. We introduce a contrastive tuning\nmethod that can be applied to a pretrained off-the-shelf MLLM for mitigating\nhallucinations while preserving its general vision-language capabilities. For a\ngiven factual token, we create a hallucinated token through generative data\naugmentation by selectively altering the ground-truth information. The proposed\ncontrastive tuning is applied at the token level to improve the relative\nlikelihood of the factual token compared to the hallucinated one. Our thorough\nevaluation confirms the effectiveness of contrastive tuning in mitigating\nhallucination. Moreover, the proposed contrastive tuning is simple, fast, and\nrequires minimal training with no additional overhead at inference.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Pritam Sarkar",
            "Sayna Ebrahimi",
            "Ali Etemad",
            "Ahmad Beirami",
            "Sercan Ö. Arık",
            "Tomas Pfister"
        ],
        "published": "2024-05-28T23:36:00Z"
    },
    {
        "title": "Recent Advances of Foundation Language Models-based Continual Learning:\n  A Survey",
        "link": "http://arxiv.org/abs/2405.18653v1",
        "abstract": "Recently, foundation language models (LMs) have marked significant\nachievements in the domains of natural language processing (NLP) and computer\nvision (CV). Unlike traditional neural network models, foundation LMs obtain a\ngreat ability for transfer learning by acquiring rich commonsense knowledge\nthrough pre-training on extensive unsupervised datasets with a vast number of\nparameters. However, they still can not emulate human-like continuous learning\ndue to catastrophic forgetting. Consequently, various continual learning\n(CL)-based methodologies have been developed to refine LMs, enabling them to\nadapt to new tasks without forgetting previous knowledge. However, a systematic\ntaxonomy of existing approaches and a comparison of their performance are still\nlacking, which is the gap that our survey aims to fill. We delve into a\ncomprehensive review, summarization, and classification of the existing\nliterature on CL-based approaches applied to foundation language models, such\nas pre-trained language models (PLMs), large language models (LLMs) and\nvision-language models (VLMs). We divide these studies into offline CL and\nonline CL, which consist of traditional methods, parameter-efficient-based\nmethods, instruction tuning-based methods and continual pre-training methods.\nOffline CL encompasses domain-incremental learning, task-incremental learning,\nand class-incremental learning, while online CL is subdivided into hard task\nboundary and blurry task boundary settings. Additionally, we outline the\ntypical datasets and metrics employed in CL research and provide a detailed\nanalysis of the challenges and future work for LMs-based continual learning.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yutao Yang",
            "Jie Zhou",
            "Xuanwen Ding",
            "Tianyu Huai",
            "Shunyu Liu",
            "Qin Chen",
            "Liang He",
            "Yuan Xie"
        ],
        "published": "2024-05-28T23:32:46Z"
    },
    {
        "title": "A Dynamical Systems Approach to Bots and Online Political Communication",
        "link": "http://arxiv.org/abs/2405.18652v1",
        "abstract": "Bots have become increasingly prevalent in the digital sphere and have taken\nup a proactive role in shaping democratic processes. While previous studies\nhave focused on their influence at the individual level, their potential\nmacro-level impact on communication dynamics is still little understood. This\nstudy adopts an information theoretic approach from dynamical systems theory to\nexamine the role of political bots shaping the dynamics of an online political\ndiscussion on Twitter. We quantify the components of this dynamic process in\nterms of its complexity, predictability, and the remaining uncertainty. Our\nfindings suggest that bot activity is associated with increased complexity and\nuncertainty in the structural dynamics of online political communication. This\nwork serves as a showcase for the use of information-theoretic measures from\ndynamical systems theory in modeling human-bot dynamics as a computational\nprocess that unfolds over time.",
        "subjects": [
            "cs.CY",
            "cs.HC",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Beril Bulat",
            "Martin Hilbert"
        ],
        "published": "2024-05-28T23:31:21Z"
    },
    {
        "title": "Approximating Human Models During Argumentation-based Dialogues",
        "link": "http://arxiv.org/abs/2405.18650v1",
        "abstract": "Explainable AI Planning (XAIP) aims to develop AI agents that can effectively\nexplain their decisions and actions to human users, fostering trust and\nfacilitating human-AI collaboration. A key challenge in XAIP is model\nreconciliation, which seeks to align the mental models of AI agents and humans.\nWhile existing approaches often assume a known and deterministic human model,\nthis simplification may not capture the complexities and uncertainties of\nreal-world interactions. In this paper, we propose a novel framework that\nenables AI agents to learn and update a probabilistic human model through\nargumentation-based dialogues. Our approach incorporates trust-based and\ncertainty-based update mechanisms, allowing the agent to refine its\nunderstanding of the human's mental state based on the human's expressed trust\nin the agent's arguments and certainty in their own arguments. We employ a\nprobability weighting function inspired by prospect theory to capture the\nrelationship between trust and perceived probability, and use a Bayesian\napproach to update the agent's probability distribution over possible human\nmodels. We conduct a human-subject study to empirically evaluate the\neffectiveness of our approach in an argumentation scenario, demonstrating its\nability to capture the dynamics of human belief formation and adaptation.",
        "subjects": [
            "cs.AI",
            "cs.HC",
            "cs.LO"
        ],
        "authors": [
            "Yinxu Tang",
            "Stylianos Loukas Vasileiou",
            "William Yeoh"
        ],
        "published": "2024-05-28T23:22:18Z"
    },
    {
        "title": "Training LLMs to Better Self-Debug and Explain Code",
        "link": "http://arxiv.org/abs/2405.18649v1",
        "abstract": "In the domain of code generation, self-debugging is crucial. It allows LLMs\nto refine their generated code based on execution feedback. This is\nparticularly important because generating correct solutions in one attempt\nproves challenging for complex tasks. Prior works on self-debugging mostly\nfocus on prompting methods by providing LLMs with few-shot examples, which work\npoorly on small open-sourced LLMs. In this work, we propose a training\nframework that significantly improves self-debugging capability of LLMs.\nIntuitively, we observe that a chain of explanations on the wrong code followed\nby code refinement helps LLMs better analyze the wrong code and do refinement.\nWe thus propose an automated pipeline to collect a high-quality dataset for\ncode explanation and refinement by generating a number of explanations and\nrefinement trajectories and filtering via execution verification. We perform\nsupervised fine-tuning (SFT) and further reinforcement learning (RL) on both\nsuccess and failure trajectories with a novel reward design considering code\nexplanation and refinement quality. SFT improves the pass@1 by up to 15.92% and\npass@10 by 9.30% over four benchmarks. RL training brings additional up to\n3.54% improvement on pass@1 and 2.55% improvement on pass@10. The trained LLMs\nshow iterative refinement ability, and can keep refining code continuously.\nLastly, our human evaluation shows that the LLMs trained with our framework\ngenerate more useful code explanations and help developers better understand\nbugs in source code.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.SE"
        ],
        "authors": [
            "Nan Jiang",
            "Xiaopeng Li",
            "Shiqi Wang",
            "Qiang Zhou",
            "Soneya Binta Hossain",
            "Baishakhi Ray",
            "Varun Kumar",
            "Xiaofei Ma",
            "Anoop Deoras"
        ],
        "published": "2024-05-28T23:20:24Z"
    },
    {
        "title": "JADS: A Framework for Self-supervised Joint Aspect Discovery and\n  Summarization",
        "link": "http://arxiv.org/abs/2405.18642v1",
        "abstract": "To generate summaries that include multiple aspects or topics for text\ndocuments, most approaches use clustering or topic modeling to group relevant\nsentences and then generate a summary for each group. These approaches struggle\nto optimize the summarization and clustering algorithms jointly. On the other\nhand, aspect-based summarization requires known aspects. Our solution\nintegrates topic discovery and summarization into a single step. Given text\ndata, our Joint Aspect Discovery and Summarization algorithm (JADS) discovers\naspects from the input and generates a summary of the topics, in one step. We\npropose a self-supervised framework that creates a labeled dataset by first\nmixing sentences from multiple documents (e.g., CNN/DailyMail articles) as the\ninput and then uses the article summaries from the mixture as the labels. The\nJADS model outperforms the two-step baselines. With pretraining, the model\nachieves better performance and stability. Furthermore, embeddings derived from\nJADS exhibit superior clustering capabilities. Our proposed method achieves\nhigher semantic alignment with ground truth and is factual.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Xiaobo Guo",
            "Jay Desai",
            "Srinivasan H. Sengamedu"
        ],
        "published": "2024-05-28T23:01:57Z"
    },
    {
        "title": "Lazy Safety Alignment for Large Language Models against Harmful\n  Fine-tuning",
        "link": "http://arxiv.org/abs/2405.18641v1",
        "abstract": "Recent studies show that Large Language Models (LLMs) with safety alignment\ncan be jail-broken by fine-tuning on a dataset mixed with harmful data. First\ntime in the literature, we show that the jail-broken effect can be mitigated by\nseparating states in the finetuning stage to optimize the alignment and user\ndatasets. Unfortunately, our subsequent study shows that this simple Bi-State\nOptimization (BSO) solution experiences convergence instability when steps\ninvested in its alignment state is too small, leading to downgraded alignment\nperformance. By statistical analysis, we show that the \\textit{excess drift}\ntowards consensus could be a probable reason for the instability. To remedy\nthis issue, we propose \\textbf{L}azy(\\textbf{i}) \\textbf{s}afety\n\\textbf{a}lignment (\\textbf{Lisa}), which introduces a proximal term to\nconstraint the drift of each state. Theoretically, the benefit of the proximal\nterm is supported by the convergence analysis, wherein we show that a\nsufficient large proximal factor is necessary to guarantee Lisa's convergence.\nEmpirically, our results on four downstream finetuning tasks show that Lisa\nwith a proximal term can significantly increase alignment performance while\nmaintaining the LLM's accuracy on the user tasks. Code is available at\n\\url{https://github.com/git-disl/Lisa}.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Tiansheng Huang",
            "Sihao Hu",
            "Fatih Ilhan",
            "Selim Furkan Tekin",
            "Ling Liu"
        ],
        "published": "2024-05-28T22:53:43Z"
    },
    {
        "title": "HoloDevice: Holographic Cross-Device Interactions for Remote\n  Collaboration",
        "link": "http://arxiv.org/abs/2405.19377v1",
        "abstract": "This paper introduces holographic cross-device interaction, a new class of\nremote cross-device interactions between local physical devices and\nholographically rendered remote devices. Cross-device interactions have enabled\na rich set of interactions with device ecologies. Most existing research\nfocuses on co-located settings (meaning when users and devices are in the same\nphysical space) to achieve these rich interactions and affordances. In\ncontrast, holographic cross-device interaction allows remote interactions\nbetween devices at distant locations by providing a rich visual affordance\nthrough real-time holographic rendering of the device's motion, content, and\ninteractions on mixed reality head-mounted displays. This maintains the\nadvantages of having a physical device, such as precise input through touch and\npen interaction. Through holographic rendering, not only can remote devices\ninteract as if they are co-located, but they can also be virtually augmented to\nfurther enrich interactions, going beyond what is possible with existing\ncross-device systems. To demonstrate this concept, we developed HoloDevice, a\nprototype system for holographic cross-device interaction using the Microsoft\nHololens 2 augmented reality headset. Our contribution is threefold. First, we\nintroduce the concept of holographic cross-device interaction. Second, we\npresent a design space containing three unique benefits, which include: (1)\nspatial visualization of interaction and motion, (2) rich visual affordances\nfor intermediate transition, and (3) dynamic and fluid configuration. Last we\ndiscuss a set of implementation demonstrations and use-case scenarios that\nfurther explore the space.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Neil Chulpongsatorn",
            "Thien-Kim Nguyen",
            "Nicolai Marquardt",
            "Ryo Suzuki"
        ],
        "published": "2024-05-28T22:49:01Z"
    },
    {
        "title": "Improving Speech Decoding from ECoG with Self-Supervised Pretraining",
        "link": "http://arxiv.org/abs/2405.18639v1",
        "abstract": "Recent work on intracranial brain-machine interfaces has demonstrated that\nspoken speech can be decoded with high accuracy, essentially by treating the\nproblem as an instance of supervised learning and training deep neural networks\nto map from neural activity to text. However, such networks pay for their\nexpressiveness with very large numbers of labeled data, a requirement that is\nparticularly burdensome for invasive neural recordings acquired from human\npatients. On the other hand, these patients typically produce speech outside of\nthe experimental blocks used for training decoders. Making use of such data,\nand data from other patients, to improve decoding would ease the burden of data\ncollection -- especially onerous for dys- and anarthric patients. Here we\ndemonstrate that this is possible, by reengineering wav2vec -- a simple,\nself-supervised, fully convolutional model that learns latent representations\nof audio using a noise-contrastive loss -- for electrocorticographic (ECoG)\ndata. We train this model on unlabelled ECoG recordings, and subsequently use\nit to transform ECoG from labeled speech sessions into wav2vec's representation\nspace, before finally training a supervised encoder-decoder to map these\nrepresentations to text. We experiment with various numbers of labeled blocks;\nfor almost all choices, the new representations yield superior decoding\nperformance to the original ECoG data, and in no cases do they yield worse.\nPerformance can also be improved in some cases by pretraining wav2vec on\nanother patient's data. In the best cases, wav2vec's representations decrease\nword error rates over the original data by upwards of 50%.",
        "subjects": [
            "q-bio.NC",
            "cs.CL",
            "cs.LG",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Brian A. Yuan",
            "Joseph G. Makin"
        ],
        "published": "2024-05-28T22:48:53Z"
    },
    {
        "title": "ConSiDERS-The-Human Evaluation Framework: Rethinking Human Evaluation\n  for Generative Large Language Models",
        "link": "http://arxiv.org/abs/2405.18638v1",
        "abstract": "In this position paper, we argue that human evaluation of generative large\nlanguage models (LLMs) should be a multidisciplinary undertaking that draws\nupon insights from disciplines such as user experience research and human\nbehavioral psychology to ensure that the experimental design and results are\nreliable. The conclusions from these evaluations, thus, must consider factors\nsuch as usability, aesthetics, and cognitive biases. We highlight how cognitive\nbiases can conflate fluent information and truthfulness, and how cognitive\nuncertainty affects the reliability of rating scores such as Likert.\nFurthermore, the evaluation should differentiate the capabilities and\nweaknesses of increasingly powerful large language models -- which requires\neffective test sets. The scalability of human evaluation is also crucial to\nwider adoption. Hence, to design an effective human evaluation system in the\nage of generative NLP, we propose the ConSiDERS-The-Human evaluation framework\nconsisting of 6 pillars --Consistency, Scoring Critera, Differentiating, User\nExperience, Responsible, and Scalability.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Aparna Elangovan",
            "Ling Liu",
            "Lei Xu",
            "Sravan Bodapati",
            "Dan Roth"
        ],
        "published": "2024-05-28T22:45:28Z"
    },
    {
        "title": "ChatGPT as the Marketplace of Ideas: Should Truth-Seeking Be the Goal of\n  AI Content Governance?",
        "link": "http://arxiv.org/abs/2405.18636v1",
        "abstract": "As one of the most enduring metaphors within legal discourse, the marketplace\nof ideas has wielded considerable influence over the jurisprudential landscape\nfor decades. A century after the inception of this theory, ChatGPT emerged as a\nrevolutionary technological advancement in the twenty-first century. This\nresearch finds that ChatGPT effectively manifests the marketplace metaphor. It\nnot only instantiates the promises envisaged by generations of legal scholars\nbut also lays bare the perils discerned through sustained academic critique.\nSpecifically, the workings of ChatGPT and the marketplace of ideas theory\nexhibit at least four common features: arena, means, objectives, and flaws.\nThese shared attributes are sufficient to render ChatGPT historically the most\nqualified engine for actualizing the marketplace of ideas theory.\n  The comparison of the marketplace theory and ChatGPT merely marks a starting\npoint. A more meaningful undertaking entails reevaluating and reframing both\ninternal and external AI policies by referring to the accumulated experience,\ninsights, and suggestions researchers have raised to fix the marketplace\ntheory. Here, a pivotal issue is: should truth-seeking be set as the goal of AI\ncontent governance? Given the unattainability of the absolute truth-seeking\ngoal, I argue against adopting zero-risk policies. Instead, a more judicious\napproach would be to embrace a knowledge-based alternative wherein large\nlanguage models (LLMs) are trained to generate competing and divergent\nviewpoints based on sufficient justifications. This research also argues that\nso-called AI content risks are not created by AI companies but are inherent in\nthe entire information ecosystem. Thus, the burden of managing these risks\nshould be distributed among different social actors, rather than being solely\nshouldered by chatbot companies.",
        "subjects": [
            "cs.AI",
            "cs.CY",
            "cs.ET",
            "cs.IT",
            "math.IT",
            "I.2.4"
        ],
        "authors": [
            "Jiawei Zhang"
        ],
        "published": "2024-05-28T22:38:24Z"
    },
    {
        "title": "When and How Does In-Distribution Label Help Out-of-Distribution\n  Detection?",
        "link": "http://arxiv.org/abs/2405.18635v1",
        "abstract": "Detecting data points deviating from the training distribution is pivotal for\nensuring reliable machine learning. Extensive research has been dedicated to\nthe challenge, spanning classical anomaly detection techniques to contemporary\nout-of-distribution (OOD) detection approaches. While OOD detection commonly\nrelies on supervised learning from a labeled in-distribution (ID) dataset,\nanomaly detection may treat the entire ID data as a single class and disregard\nID labels. This fundamental distinction raises a significant question that has\nyet to be rigorously explored: when and how does ID label help OOD detection?\nThis paper bridges this gap by offering a formal understanding to theoretically\ndelineate the impact of ID labels on OOD detection. We employ a graph-theoretic\napproach, rigorously analyzing the separability of ID data from OOD data in a\nclosed-form manner. Key to our approach is the characterization of data\nrepresentations through spectral decomposition on the graph. Leveraging these\nrepresentations, we establish a provable error bound that compares the OOD\ndetection performance with and without ID labels, unveiling conditions for\nachieving enhanced OOD detection. Lastly, we present empirical results on both\nsimulated and real datasets, validating theoretical guarantees and reinforcing\nour insights. Code is publicly available at\nhttps://github.com/deeplearning-wisc/id_label.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Xuefeng Du",
            "Yiyou Sun",
            "Yixuan Li"
        ],
        "published": "2024-05-28T22:34:53Z"
    },
    {
        "title": "A Theoretical Understanding of Self-Correction through In-context\n  Alignment",
        "link": "http://arxiv.org/abs/2405.18634v1",
        "abstract": "Going beyond mimicking limited human experiences, recent studies show initial\nevidence that, like humans, large language models (LLMs) are capable of\nimproving their abilities purely by self-correction, i.e., correcting previous\nresponses through self-examination, in certain circumstances. Nevertheless,\nlittle is known about how such capabilities arise. In this work, based on a\nsimplified setup akin to an alignment task, we theoretically analyze\nself-correction from an in-context learning perspective, showing that when LLMs\ngive relatively accurate self-examinations as rewards, they are capable of\nrefining responses in an in-context way. Notably, going beyond previous\ntheories on over-simplified linear transformers, our theoretical construction\nunderpins the roles of several key designs of realistic transformers for\nself-correction: softmax attention, multi-head attention, and the MLP block. We\nvalidate these findings extensively on synthetic datasets. Inspired by these\nfindings, we also illustrate novel applications of self-correction, such as\ndefending against LLM jailbreaks, where a simple self-correction step does make\na large difference. We believe that these findings will inspire further\nresearch on understanding, exploiting, and enhancing self-correction for\nbuilding better foundation models.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "stat.ML"
        ],
        "authors": [
            "Yifei Wang",
            "Yuyang Wu",
            "Zeming Wei",
            "Stefanie Jegelka",
            "Yisen Wang"
        ],
        "published": "2024-05-28T22:33:02Z"
    },
    {
        "title": "PureEBM: Universal Poison Purification via Mid-Run Dynamics of\n  Energy-Based Models",
        "link": "http://arxiv.org/abs/2405.19376v1",
        "abstract": "Data poisoning attacks pose a significant threat to the integrity of machine\nlearning models by leading to misclassification of target distribution test\ndata by injecting adversarial examples during training. Existing\nstate-of-the-art (SoTA) defense methods suffer from a variety of limitations,\nsuch as significantly reduced generalization performance, specificity to\nparticular attack types and classifiers, and significant overhead during\ntraining, making them impractical or limited for real-world applications. In\nresponse to this challenge, we introduce a universal data purification method\nthat defends naturally trained classifiers from malicious white-, gray-, and\nblack-box image poisons by applying a universal stochastic preprocessing step\n$\\Psi_{T}(x)$, realized by iterative Langevin sampling of a convergent Energy\nBased Model (EBM) initialized with an image $x.$ Mid-run dynamics of\n$\\Psi_{T}(x)$ purify poison information with minimal impact on features\nimportant to the generalization of a classifier network. We show that the\ncontrastive learning process of EBMs allows them to remain universal purifiers,\neven in the presence of poisoned EBM training data, and to achieve SoTA defense\non leading triggered poison Narcissus and triggerless poisons Gradient Matching\nand Bullseye Polytope. This work is a subset of a larger framework introduced\nin PureGen with a more detailed focus on EBM purification and poison defense.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Omead Pooladzandi",
            "Jeffrey Jiang",
            "Sunay Bhat",
            "Gregory Pottie"
        ],
        "published": "2024-05-28T22:31:56Z"
    },
    {
        "title": "Large Language Models as Partners in Student Essay Evaluation",
        "link": "http://arxiv.org/abs/2405.18632v1",
        "abstract": "As the importance of comprehensive evaluation in workshop courses increases,\nthere is a growing demand for efficient and fair assessment methods that reduce\nthe workload for faculty members. This paper presents an evaluation conducted\nwith Large Language Models (LLMs) using actual student essays in three\nscenarios: 1) without providing guidance such as rubrics, 2) with pre-specified\nrubrics, and 3) through pairwise comparison of essays. Quantitative analysis of\nthe results revealed a strong correlation between LLM and faculty member\nassessments in the pairwise comparison scenario with pre-specified rubrics,\nalthough concerns about the quality and stability of evaluations remained.\nTherefore, we conducted a qualitative analysis of LLM assessment comments,\nshowing that: 1) LLMs can match the assessment capabilities of faculty members,\n2) variations in LLM assessments should be interpreted as diversity rather than\nconfusion, and 3) assessments by humans and LLMs can differ and complement each\nother. In conclusion, this paper suggests that LLMs should not be seen merely\nas assistants to faculty members but as partners in evaluation committees and\noutlines directions for further research.",
        "subjects": [
            "cs.CY",
            "cs.AI"
        ],
        "authors": [
            "Toru Ishida",
            "Tongxi Liu",
            "Hailong Wang",
            "William K. Cheung"
        ],
        "published": "2024-05-28T22:28:50Z"
    },
    {
        "title": "A linear bound for the size of the finite terminal assembly of a\n  directed non-cooperative tile assembly system",
        "link": "http://arxiv.org/abs/2405.18630v1",
        "abstract": "The abstract tile assembly model (aTam) is a model of DNA self-assembly. Most\nof the studies focus on cooperative aTam where a form of synchronization\nbetween the tiles is possible. Simulating Turing machines is achievable in this\ncontext. Few results and constructions are known for the non-cooperative case\n(a variant of Wang tilings where assemblies do not need to cover the whole\nplane and some mismatches may occur).\n  Introduced by P.E. Meunier and D. Regnault, efficient paths are a non-trivial\nconstruction for non-cooperative aTam. These paths of width nlog(n) are\ndesigned with n different tile types. Assembling them relies heavily on a form\nof ``non-determinism''. Indeed, the set of tiles may produced different finite\nterminal assemblies but they all contain the same efficient path. Directed\nnon-cooperative aTam does not allow this non-determinism as only one assembly\nmay be produced by a tile assembly system. This variant of aTam is the only one\nwho was shown to be decidable.\n  In this paper, we show that if the terminal assembly of a directed\nnon-cooperative tile assembly system is finite then its width and length are of\nlinear size according to the size of the tile assembly system. This result\nimplies that the construction of efficient paths cannot be generalized to the\ndirected case and that some computation must rely on a competition between\ndifferent paths. It also implies that the construction of a square of width n\nusing 2n-1 tiles types is asymptotically optimal. Moreover, we hope that the\ntechniques introduced here will lead to a better comprehension of the\nnon-directed case.",
        "subjects": [
            "cs.CC"
        ],
        "authors": [
            "Sergiu Ivanov",
            "Damien Regnault"
        ],
        "published": "2024-05-28T22:25:21Z"
    },
    {
        "title": "Improving global awareness of linkset predictions using Cross-Attentive\n  Modulation tokens",
        "link": "http://arxiv.org/abs/2405.19375v1",
        "abstract": "Most of multiple link prediction or graph generation techniques rely on the\nattention mechanism or on Graph Neural Networks (GNNs), which consist in\nleveraging node-level information exchanges in order to form proper link\npredictions. Such node-level interactions do not process nodes as an ordered\nsequence, which would imply some kind of natural ordering of the nodes: they\nare said to be permutation invariant mechanisms. They are well suited for graph\nproblems, but struggle at providing a global orchestration of the predicted\nlinks, which can result in a loss of performance. Some typical issues can be\nthe difficulty to ensure high-level properties such as global connectedness,\nfixed diameter or to avoid information bottleneck effects such as oversmoothing\nand oversquashing, which respectively consist in abundant smoothing in dense\nareas leading to a loss of information and a tendency to exclude isolated nodes\nfrom the message passing scheme, and often result in irrelevant, unbalanced\nlink predictions. To tackle this problem, we hereby present Cross-Attentive\nModulation (CAM) tokens, which introduce cross-attentive units used to\ncondition node and edge-level modulations in order to enable context-aware\ncomputations that improve the global consistency of the prediction links. We\nwill implement it on a few permutation invariant architectures, and showcase\nbenchmarks that prove the merits of our work.",
        "subjects": [
            "cs.SI",
            "cs.LG",
            "I.2.6"
        ],
        "authors": [
            "Félix Marcoccia",
            "Cédric Adjih",
            "Paul Mühlethaler"
        ],
        "published": "2024-05-28T22:25:17Z"
    },
    {
        "title": "Hardware-Aware Parallel Prompt Decoding for Memory-Efficient\n  Acceleration of LLM Inference",
        "link": "http://arxiv.org/abs/2405.18628v1",
        "abstract": "The auto-regressive decoding of Large Language Models (LLMs) results in\nsignificant overheads in their hardware performance. While recent research has\ninvestigated various speculative decoding techniques for multi-token\ngeneration, these efforts have primarily focused on improving processing speed\nsuch as throughput. Crucially, they often neglect other metrics essential for\nreal-life deployments, such as memory consumption and training cost. To\novercome these limitations, we propose a novel parallel prompt decoding that\nrequires only $0.0002$% trainable parameters, enabling efficient training on a\nsingle A100-40GB GPU in just 16 hours. Inspired by the human natural language\ngeneration process, $PPD$ approximates outputs generated at future timesteps in\nparallel by using multiple prompt tokens. This approach partially recovers the\nmissing conditional dependency information necessary for multi-token\ngeneration, resulting in up to a 28% higher acceptance rate for long-range\npredictions. Furthermore, we present a hardware-aware dynamic sparse tree\ntechnique that adaptively optimizes this decoding scheme to fully leverage the\ncomputational capacities on different GPUs. Through extensive experiments\nacross LLMs ranging from MobileLlama to Vicuna-13B on a wide range of\nbenchmarks, our approach demonstrates up to 2.49$\\times$ speedup and maintains\na minimal runtime memory overhead of just $0.0004$%. More importantly, our\nparallel prompt decoding can serve as an orthogonal optimization for\nsynergistic integration with existing speculative decoding, showing up to\n$1.22\\times$ further speed improvement. Our code is available at\nhttps://github.com/hmarkc/parallel-prompt-decoding.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "authors": [
            " Hao",
            " Chen",
            "Wayne Luk",
            "Ka Fai Cedric Yiu",
            "Rui Li",
            "Konstantin Mishchenko",
            "Stylianos I. Venieris",
            "Hongxiang Fan"
        ],
        "published": "2024-05-28T22:19:30Z"
    },
    {
        "title": "PureGen: Universal Data Purification for Train-Time Poison Defense via\n  Generative Model Dynamics",
        "link": "http://arxiv.org/abs/2405.18627v1",
        "abstract": "Train-time data poisoning attacks threaten machine learning models by\nintroducing adversarial examples during training, leading to misclassification.\nCurrent defense methods often reduce generalization performance, are\nattack-specific, and impose significant training overhead. To address this, we\nintroduce a set of universal data purification methods using a stochastic\ntransform, $\\Psi(x)$, realized via iterative Langevin dynamics of Energy-Based\nModels (EBMs), Denoising Diffusion Probabilistic Models (DDPMs), or both. These\napproaches purify poisoned data with minimal impact on classifier\ngeneralization. Our specially trained EBMs and DDPMs provide state-of-the-art\ndefense against various attacks (including Narcissus, Bullseye Polytope,\nGradient Matching) on CIFAR-10, Tiny-ImageNet, and CINIC-10, without needing\nattack or classifier-specific information. We discuss performance trade-offs\nand show that our methods remain highly effective even with poisoned or\ndistributionally shifted generative model training data.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "authors": [
            "Sunay Bhat",
            "Jeffrey Jiang",
            "Omead Pooladzandi",
            "Alexander Branch",
            "Gregory Pottie"
        ],
        "published": "2024-05-28T22:19:26Z"
    },
    {
        "title": "Causal Contextual Bandits with Adaptive Context",
        "link": "http://arxiv.org/abs/2405.18626v1",
        "abstract": "We study a variant of causal contextual bandits where the context is chosen\nbased on an initial intervention chosen by the learner. At the beginning of\neach round, the learner selects an initial action, depending on which a\nstochastic context is revealed by the environment. Following this, the learner\nthen selects a final action and receives a reward. Given $T$ rounds of\ninteractions with the environment, the objective of the learner is to learn a\npolicy (of selecting the initial and the final action) with maximum expected\nreward. In this paper we study the specific situation where every action\ncorresponds to intervening on a node in some known causal graph. We extend\nprior work from the deterministic context setting to obtain simple regret\nminimization guarantees. This is achieved through an instance-dependent causal\nparameter, $\\lambda$, which characterizes our upper bound. Furthermore, we\nprove that our simple regret is essentially tight for a large class of\ninstances. A key feature of our work is that we use convex optimization to\naddress the bandit exploration problem. We also conduct experiments to validate\nour theoretical results, and release our code at our project GitHub repository:\nhttps://github.com/adaptiveContextualCausalBandits/aCCB.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Rahul Madhavan",
            "Aurghya Maiti",
            "Gaurav Sinha",
            "Siddharth Barman"
        ],
        "published": "2024-05-28T22:17:57Z"
    },
    {
        "title": "Enhancing IoT Security with CNN and LSTM-Based Intrusion Detection\n  Systems",
        "link": "http://arxiv.org/abs/2405.18624v1",
        "abstract": "Protecting Internet of things (IoT) devices against cyber attacks is\nimperative owing to inherent security vulnerabilities. These vulnerabilities\ncan include a spectrum of sophisticated attacks that pose significant damage to\nboth individuals and organizations. Employing robust security measures like\nintrusion detection systems (IDSs) is essential to solve these problems and\nprotect IoT systems from such attacks. In this context, our proposed IDS model\nconsists on a combination of convolutional neural network (CNN) and long\nshort-term memory (LSTM) deep learning (DL) models. This fusion facilitates the\ndetection and classification of IoT traffic into binary categories, benign and\nmalicious activities by leveraging the spatial feature extraction capabilities\nof CNN for pattern recognition and the sequential memory retention of LSTM for\ndiscerning complex temporal dependencies in achieving enhanced accuracy and\nefficiency. In assessing the performance of our proposed model, the authors\nemployed the new CICIoT2023 dataset for both training and final testing, while\nfurther validating the model's performance through a conclusive testing phase\nutilizing the CICIDS2017 dataset. Our proposed model achieves an accuracy rate\nof 98.42%, accompanied by a minimal loss of 0.0275. False positive rate(FPR) is\nequally important, reaching 9.17% with an F1-score of 98.57%. These results\ndemonstrate the effectiveness of our proposed CNN-LSTM IDS model in fortifying\nIoT environments against potential cyber threats.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "authors": [
            "Afrah Gueriani",
            "Hamza Kheddar",
            "Ahmed Cherif Mazari"
        ],
        "published": "2024-05-28T22:12:15Z"
    },
    {
        "title": "I See You: Teacher Analytics with GPT-4 Vision-Powered Observational\n  Assessment",
        "link": "http://arxiv.org/abs/2405.18623v2",
        "abstract": "This preliminary study explores the integration of GPT-4 Vision (GPT-4V)\ntechnology into teacher analytics, focusing on its applicability in\nobservational assessment to enhance reflective teaching practice. This research\nis grounded in developing a Video-based Automatic Assessment System (VidAAS)\nempowered by GPT-4V. Our approach aims to revolutionize teachers' assessment of\nstudents' practices by leveraging Generative Artificial Intelligence (GenAI) to\noffer detailed insights into classroom dynamics. Our research methodology\nencompasses a comprehensive literature review, prototype development of the\nVidAAS, and usability testing with in-service teachers. The study findings\nprovide future research avenues for VidAAS design, implementation, and\nintegration in teacher analytics, underscoring the potential of GPT-4V to\nprovide real-time, scalable feedback and a deeper understanding of the\nclassroom.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Unggi Lee",
            "Yeil Jeong",
            "Junbo Koh",
            "Gyuri Byun",
            "Yunseo Lee",
            "Hyunwoong Lee",
            "Seunmin Eun",
            "Jewoong Moon",
            "Cheolil Lim",
            "Hyeoncheol Kim"
        ],
        "published": "2024-05-28T22:08:20Z"
    },
    {
        "title": "Biclustering a dataset using photonic quantum computing",
        "link": "http://arxiv.org/abs/2405.18622v1",
        "abstract": "Biclustering is a problem in machine learning and data mining that seeks to\ngroup together rows and columns of a dataset according to certain criteria. In\nthis work, we highlight the natural relation that quantum computing models like\nboson and Gaussian boson sampling (GBS) have to this problem. We first explore\nthe use of boson sampling to identify biclusters based on matrix permanents. We\nthen propose a heuristic that finds clusters in a dataset using Gaussian boson\nsampling by (i) converting the dataset into a bipartite graph and then (ii)\nrunning GBS to find the densest sub-graph(s) within the larger bipartite graph.\nOur simulations for the above proposed heuristics show promising results for\nfuture exploration in this area.",
        "subjects": [
            "quant-ph",
            "cs.ET",
            "cs.LG",
            "physics.optics"
        ],
        "authors": [
            "Ajinkya Borle",
            "Ameya Bhave"
        ],
        "published": "2024-05-28T22:04:29Z"
    },
    {
        "title": "Multi-Armed Bandits with Network Interference",
        "link": "http://arxiv.org/abs/2405.18621v1",
        "abstract": "Online experimentation with interference is a common challenge in modern\napplications such as e-commerce and adaptive clinical trials in medicine. For\nexample, in online marketplaces, the revenue of a good depends on discounts\napplied to competing goods. Statistical inference with interference is widely\nstudied in the offline setting, but far less is known about how to adaptively\nassign treatments to minimize regret. We address this gap by studying a\nmulti-armed bandit (MAB) problem where a learner (e-commerce platform)\nsequentially assigns one of possible $\\mathcal{A}$ actions (discounts) to $N$\nunits (goods) over $T$ rounds to minimize regret (maximize revenue). Unlike\ntraditional MAB problems, the reward of each unit depends on the treatments\nassigned to other units, i.e., there is interference across the underlying\nnetwork of units. With $\\mathcal{A}$ actions and $N$ units, minimizing regret\nis combinatorially difficult since the action space grows as $\\mathcal{A}^N$.\nTo overcome this issue, we study a sparse network interference model, where the\nreward of a unit is only affected by the treatments assigned to $s$ neighboring\nunits. We use tools from discrete Fourier analysis to develop a sparse linear\nrepresentation of the unit-specific reward $r_n: [\\mathcal{A}]^N \\rightarrow\n\\mathbb{R} $, and propose simple, linear regression-based algorithms to\nminimize regret. Importantly, our algorithms achieve provably low regret both\nwhen the learner observes the interference neighborhood for all units and when\nit is unknown. This significantly generalizes other works on this topic which\nimpose strict conditions on the strength of interference on a known network,\nand also compare regret to a markedly weaker optimal action. Empirically, we\ncorroborate our theoretical findings via numerical simulations.",
        "subjects": [
            "cs.LG",
            "stat.ME",
            "stat.ML"
        ],
        "authors": [
            "Abhineet Agarwal",
            "Anish Agarwal",
            "Lorenzo Masoero",
            "Justin Whitehouse"
        ],
        "published": "2024-05-28T22:01:50Z"
    },
    {
        "title": "RealitySummary: On-Demand Mixed Reality Document Enhancement using Large\n  Language Models",
        "link": "http://arxiv.org/abs/2405.18620v1",
        "abstract": "We introduce RealitySummary, a mixed reality reading assistant that can\nenhance any printed or digital document using on-demand text extraction,\nsummarization, and augmentation. While augmented reading tools promise to\nenhance physical reading experiences with overlaid digital content, prior\nsystems have typically required pre-processed documents, which limits their\ngeneralizability and real-world use cases. In this paper, we explore on-demand\ndocument augmentation by leveraging large language models. To understand\ngeneralizable techniques for diverse documents, we first conducted an\nexploratory design study which identified five categories of document\nenhancements (summarization, augmentation, navigation, comparison, and\nextraction). Based on this, we developed a proof-of-concept system that can\nautomatically extract and summarize text using Google Cloud OCR and GPT-4, then\nembed information around documents using a Microsoft Hololens 2 and Apple\nVision Pro. We demonstrate real-time examples of six specific document\naugmentations: 1) summaries, 2) comparison tables, 3) timelines, 4) keyword\nlists, 5) summary highlighting, and 6) information cards. Results from a\nusability study (N=12) and in-the-wild study (N=11) highlight the potential\nbenefits of on-demand MR document enhancement and opportunities for future\nresearch.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Aditya Gunturu",
            "Shivesh Jadon",
            "Nandi Zhang",
            "Jarin Thundathil",
            "Wesley Willett",
            "Ryo Suzuki"
        ],
        "published": "2024-05-28T21:59:56Z"
    },
    {
        "title": "Stability of the Rao-Nakra sandwich beam with a dissipation of\n  fractional derivative type: theoretical and numerical study",
        "link": "http://arxiv.org/abs/2405.18619v1",
        "abstract": "This paper is devoted to the solution and stability of a one-dimensional\nmodel depicting Rao--Nakra sandwich beams, incorporating damping terms\ncharacterized by fractional derivative types within the domain, specifically a\ngeneralized Caputo derivative with exponential weight. To address existence,\nuniqueness, stability, and numerical results, fractional derivatives are\nsubstituted by diffusion equations relative to a new independent variable,\n$\\xi$, resulting in an augmented model with a dissipative semigroup operator.\nPolynomial decay of energy is achieved, with a decay rate depending on the\nfractional derivative parameters. Both the polynomial decay and its dependency\non the parameters of the generalized Caputo derivative are numerically\nvalidated. To this end, an energy-conserving finite difference numerical scheme\nis employed.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "math.AP"
        ],
        "authors": [
            "Kaïs Ammari",
            "Vilmos Komornik",
            "Mauricio Sepúlveda",
            "Octavio Vera"
        ],
        "published": "2024-05-28T21:58:09Z"
    },
    {
        "title": "Wavelet-Based Image Tokenizer for Vision Transformers",
        "link": "http://arxiv.org/abs/2405.18616v1",
        "abstract": "Non-overlapping patch-wise convolution is the default image tokenizer for all\nstate-of-the-art vision Transformer (ViT) models. Even though many ViT variants\nhave been proposed to improve its efficiency and accuracy, little research on\nimproving the image tokenizer itself has been reported in the literature. In\nthis paper, we propose a new image tokenizer based on wavelet transformation.\nWe show that ViT models with the new tokenizer achieve both higher training\nthroughput and better top-1 precision for the ImageNet validation set. We\npresent a theoretical analysis on why the proposed tokenizer improves the\ntraining throughput without any change to ViT model architecture. Our analysis\nsuggests that the new tokenizer can effectively handle high-resolution images\nand is naturally resistant to adversarial attack. Furthermore, the proposed\nimage tokenizer offers a fresh perspective on important new research directions\nfor ViT-based model design, such as image tokens on a non-uniform grid for\nimage understanding.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhenhai Zhu",
            "Radu Soricut"
        ],
        "published": "2024-05-28T21:45:46Z"
    },
    {
        "title": "An Algorithm for the Euclidean Bounded Multiple Traveling Salesman\n  Problem",
        "link": "http://arxiv.org/abs/2405.18615v1",
        "abstract": "In the Bounded Multiple Traveling Salesman Problem (BMTSP), a tour for each\nsalesman, that starts and ends at the depot and that respects the bounds on the\nnumber of cities that a feasible salesman tour should satisfy, is to be\nconstructed. The objective is to minimize the total length of all tours.\nAlready Euclidean traveling salesman problem is NP-hard. We propose a 3-Phase\nheuristic algorithm for the Euclidean BMTSP. We tested the algorithm for the 22\nbenchmark instances and 168 new problem instances that we created. We report 19\nbest known solutions for the 22 benchmark instances including the 12 largest\nones. For the newly created instances, we compared the performance of our\nalgorithm with that of an ILP-solver CPLEX, which was able to construct a\nfeasible solution for 71% of the instances within the time limit of two hours\nimposed by us. For about 10% of the smallest new instances, CPLEX delivered\nslightly better solutions, where our algorithm took less than 180 seconds for\nthe largest of these instances. For the remaining 61% of the instances solved\nby CPLEX, the solutions by our heuristic were, on average, about 21.5% better\nthan those obtained by CPLEX.",
        "subjects": [
            "cs.DM",
            "11A05, 52B55"
        ],
        "authors": [
            "Víctor Pacheco-Valencia",
            "Nodari Vakhania"
        ],
        "published": "2024-05-28T21:45:35Z"
    },
    {
        "title": "Augmented Physics: A Machine Learning-Powered Tool for Creating\n  Interactive Physics Simulations from Static Diagrams",
        "link": "http://arxiv.org/abs/2405.18614v1",
        "abstract": "We introduce Augmented Physics, a machine learning-powered tool designed for\ncreating interactive physics simulations from static textbook diagrams.\nLeveraging computer vision techniques, such as Segment Anything and OpenCV, our\nweb-based system enables users to semi-automatically extract diagrams from\nphysics textbooks and then generate interactive simulations based on the\nextracted content. These interactive diagrams are seamlessly integrated into\nscanned textbook pages, facilitating interactive and personalized learning\nexperiences across various physics concepts, including gravity, optics,\ncircuits, and kinematics. Drawing on an elicitation study with seven physics\ninstructors, we explore four key augmentation techniques: 1) augmented\nexperiments, 2) animated diagrams, 3) bi-directional manipulatives, and 4)\nparameter visualization. We evaluate our system through technical evaluation, a\nusability study (N=12), and expert interviews (N=12). The study findings\nsuggest that our system can facilitate more engaging and personalized learning\nexperiences in physics education.",
        "subjects": [
            "cs.HC",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Aditya Gunturu",
            "Yi Wen",
            "Jarin Thundathil",
            "Nandi Zhang",
            "Rubaiat Habib Kazi",
            "Ryo Suzuki"
        ],
        "published": "2024-05-28T21:45:20Z"
    },
    {
        "title": "GLOCON Database: Design Decisions and User Manual (v1.0)",
        "link": "http://arxiv.org/abs/2405.18613v1",
        "abstract": "GLOCON is a database of contentious events automatically extracted from\nnational news sources from various countries in multiple languages. National\nnews sources are utilized, and complete news archives are processed to create\nan event list for each source. Automation is achieved using a gold standard\ncorpus sampled randomly from complete news archives (Y\\\"or\\\"uk et al. 2022) and\nall annotated by at least two domain experts based on the event definition\nprovided in Duru\\c{s}an et al. (2022).",
        "subjects": [
            "cs.CL",
            "cs.CY",
            "cs.DB",
            "cs.LG"
        ],
        "authors": [
            "Ali Hürriyetoğlu",
            "Osman Mutlu",
            "Fırat Duruşan",
            "Erdem Yörük"
        ],
        "published": "2024-05-28T21:42:35Z"
    },
    {
        "title": "DTR-Bench: An in silico Environment and Benchmark Platform for\n  Reinforcement Learning Based Dynamic Treatment Regime",
        "link": "http://arxiv.org/abs/2405.18610v1",
        "abstract": "Reinforcement learning (RL) has garnered increasing recognition for its\npotential to optimise dynamic treatment regimes (DTRs) in personalised\nmedicine, particularly for drug dosage prescriptions and medication\nrecommendations. However, a significant challenge persists: the absence of a\nunified framework for simulating diverse healthcare scenarios and a\ncomprehensive analysis to benchmark the effectiveness of RL algorithms within\nthese contexts. To address this gap, we introduce \\textit{DTR-Bench}, a\nbenchmarking platform comprising four distinct simulation environments tailored\nto common DTR applications, including cancer chemotherapy, radiotherapy,\nglucose management in diabetes, and sepsis treatment. We evaluate various\nstate-of-the-art RL algorithms across these settings, particularly highlighting\ntheir performance amidst real-world challenges such as\npharmacokinetic/pharmacodynamic (PK/PD) variability, noise, and missing data.\nOur experiments reveal varying degrees of performance degradation among RL\nalgorithms in the presence of noise and patient variability, with some\nalgorithms failing to converge. Additionally, we observe that using temporal\nobservation representations does not consistently lead to improved performance\nin DTR settings. Our findings underscore the necessity of developing robust,\nadaptive RL algorithms capable of effectively managing these complexities to\nenhance patient-specific healthcare. We have open-sourced our benchmark and\ncode at https://github.com/GilesLuo/DTR-Bench.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Zhiyao Luo",
            "Mingcheng Zhu",
            "Fenglin Liu",
            "Jiali Li",
            "Yangchen Pan",
            "Jiandong Zhou",
            "Tingting Zhu"
        ],
        "published": "2024-05-28T21:40:00Z"
    },
    {
        "title": "Actuators À La Mode: Modal Actuations for Soft Body Locomotion",
        "link": "http://arxiv.org/abs/2405.18609v1",
        "abstract": "Traditional character animation specializes in characters with a rigidly\narticulated skeleton and a bipedal/quadripedal morphology. This assumption\nsimplifies many aspects for designing physically based animations, like\nlocomotion, but comes with the price of excluding characters of arbitrary\ndeformable geometries. To remedy this, our framework makes use of a\nspatio-temporal actuation subspace built off of the natural vibration modes of\nthe character geometry. The resulting actuation is coupled to a reduced fast\nsoft body simulation, allowing us to formulate a locomotion optimization\nproblem that is tractable for a wide variety of high resolution deformable\ncharacters.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Otman Benchekroun",
            "Kaixiang Xie",
            "Hsueh-Ti Derek Liu",
            "Eitan Grinspun",
            "Sheldon Andrews",
            "Victor Zordan"
        ],
        "published": "2024-05-28T21:39:29Z"
    },
    {
        "title": "Track Initialization and Re-Identification for~3D Multi-View\n  Multi-Object Tracking",
        "link": "http://arxiv.org/abs/2405.18606v1",
        "abstract": "We propose a 3D multi-object tracking (MOT) solution using only 2D detections\nfrom monocular cameras, which automatically initiates/terminates tracks as well\nas resolves track appearance-reappearance and occlusions. Moreover, this\napproach does not require detector retraining when cameras are reconfigured but\nonly the camera matrices of reconfigured cameras need to be updated. Our\napproach is based on a Bayesian multi-object formulation that integrates track\ninitiation/termination, re-identification, occlusion handling, and data\nassociation into a single Bayes filtering recursion. However, the exact filter\nthat utilizes all these functionalities is numerically intractable due to the\nexponentially growing number of terms in the (multi-object) filtering density,\nwhile existing approximations trade-off some of these functionalities for\nspeed. To this end, we develop a more efficient approximation suitable for\nonline MOT by incorporating object features and kinematics into the measurement\nmodel, which improves data association and subsequently reduces the number of\nterms. Specifically, we exploit the 2D detections and extracted features from\nmultiple cameras to provide a better approximation of the multi-object\nfiltering density to realize the track initiation/termination and\nre-identification functionalities. Further, incorporating a tractable geometric\nocclusion model based on 2D projections of 3D objects on the camera planes\nrealizes the occlusion handling functionality of the filter. Evaluation of the\nproposed solution on challenging datasets demonstrates significant improvements\nand robustness when camera configurations change on-the-fly, compared to\nexisting multi-view MOT solutions. The source code is publicly available at\nhttps://github.com/linh-gist/mv-glmb-ab.",
        "subjects": [
            "cs.CV",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Linh Van Ma",
            "Tran Thien Dat Nguyen",
            "Ba-Ngu Vo",
            "Hyunsung Jang",
            "Moongu Jeon"
        ],
        "published": "2024-05-28T21:36:16Z"
    },
    {
        "title": "BioBERT-based Deep Learning and Merged ChemProt-DrugProt for Enhanced\n  Biomedical Relation Extraction",
        "link": "http://arxiv.org/abs/2405.18605v1",
        "abstract": "This paper presents a methodology for enhancing relation extraction from\nbiomedical texts, focusing specifically on chemical-gene interactions.\nLeveraging the BioBERT model and a multi-layer fully connected network\narchitecture, our approach integrates the ChemProt and DrugProt datasets using\na novel merging strategy. Through extensive experimentation, we demonstrate\nsignificant performance improvements, particularly in CPR groups shared between\nthe datasets. The findings underscore the importance of dataset merging in\naugmenting sample counts and improving model accuracy. Moreover, the study\nhighlights the potential of automated information extraction in biomedical\nresearch and clinical practice.",
        "subjects": [
            "cs.CL",
            "cs.IR",
            "q-bio.MN"
        ],
        "authors": [
            "Bridget T. McInnes",
            "Jiawei Tang",
            "Darshini Mahendran",
            "Mai H. Nguyen"
        ],
        "published": "2024-05-28T21:34:01Z"
    },
    {
        "title": "SST-GCN: The Sequential based Spatio-Temporal Graph Convolutional\n  networks for Minute-level and Road-level Traffic Accident Risk Predictio",
        "link": "http://arxiv.org/abs/2405.18602v1",
        "abstract": "Traffic accidents are recognized as a major social issue worldwide, causing\nnumerous injuries and significant costs annually. Consequently, methods for\npredicting and preventing traffic accidents have been researched for many\nyears. With advancements in the field of artificial intelligence, various\nstudies have applied Machine Learning and Deep Learning techniques to traffic\naccident prediction. Modern traffic conditions change rapidly by the minute,\nand these changes vary significantly across different roads. In other words,\nthe risk of traffic accidents changes minute by minute in various patterns for\neach road. Therefore, it is desirable to predict traffic accident risk at the\nMinute-Level and Road-Level. However, because roads have close and complex\nrelationships with adjacent roads, research on predicting traffic accidents at\nthe Minute-Level and Road-Level is challenging. Thus, it is essential to build\na model that can reflect the spatial and temporal characteristics of roads for\ntraffic accident prediction. Consequently, recent attempts have been made to\nuse Graph Convolutional Networks to capture the spatial characteristics of\nroads and Recurrent Neural Networks to capture their temporal characteristics\nfor predicting traffic accident risk. This paper proposes the Sequential based\nSpatio-Temporal Graph Convolutional Networks (SST-GCN), which combines GCN and\nLSTM, to predict traffic accidents at the Minute-Level and Road-Level using a\nroad dataset constructed in Seoul, the capital of South Korea. Experiments have\ndemonstrated that SST-GCN outperforms other state-of-the-art models in\nMinute-Level predictions.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Tae-wook Kim",
            "Han-jin Lee",
            "Hyeon-Jin Jung",
            "Ji-Woong Yang",
            "Ellen J. Hong"
        ],
        "published": "2024-05-28T21:33:18Z"
    },
    {
        "title": "From Conformal Predictions to Confidence Regions",
        "link": "http://arxiv.org/abs/2405.18601v1",
        "abstract": "Conformal prediction methodologies have significantly advanced the\nquantification of uncertainties in predictive models. Yet, the construction of\nconfidence regions for model parameters presents a notable challenge, often\nnecessitating stringent assumptions regarding data distribution or merely\nproviding asymptotic guarantees. We introduce a novel approach termed CCR,\nwhich employs a combination of conformal prediction intervals for the model\noutputs to establish confidence regions for model parameters. We present\ncoverage guarantees under minimal assumptions on noise and that is valid in\nfinite sample regime. Our approach is applicable to both split conformal\npredictions and black-box methodologies including full or cross-conformal\napproaches. In the specific case of linear models, the derived confidence\nregion manifests as the feasible set of a Mixed-Integer Linear Program (MILP),\nfacilitating the deduction of confidence intervals for individual parameters\nand enabling robust optimization. We empirically compare CCR to recent\nadvancements in challenging settings such as with heteroskedastic and\nnon-Gaussian noise.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "authors": [
            "Charles Guille-Escuret",
            "Eugene Ndiaye"
        ],
        "published": "2024-05-28T21:33:12Z"
    },
    {
        "title": "OpenConvoy: Universal Platform for Real-World Testing of Cooperative\n  Driving Systems",
        "link": "http://arxiv.org/abs/2405.18600v1",
        "abstract": "Cooperative driving, enabled by communication between automated vehicle\nsystems, promises significant benefits to fuel efficiency, road capacity, and\nsafety over single-vehicle driver assistance systems such as adaptive cruise\ncontrol (ACC). However, the responsible development and implementation of these\nalgorithms poses substantial challenges due to the need for extensive\nreal-world testing. We address this issue and introduce OpenConvoy, an open and\nextensible framework designed for the implementation and assessment of\ncooperative driving policies on physical connected and autonomous vehicles\n(CAVs). We demonstrate the capabilities of OpenConvoy through a series of\nexperiments on a convoy of multi-scale vehicles controlled by Platooning to\nshow the stability of our system across vehicle configurations and its ability\nto effectively measure convoy cohesion across driving scenarios including\nvarying degrees of communication loss.",
        "subjects": [
            "cs.RO",
            "cs.AR",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Owen Burns",
            "Hossein Maghsoumi",
            "Yaser Fallah",
            "Israel Charles"
        ],
        "published": "2024-05-28T21:32:11Z"
    },
    {
        "title": "An Explainable XGBoost-based Approach on Assessing Detection of\n  Deception and Disinformation",
        "link": "http://arxiv.org/abs/2405.18596v1",
        "abstract": "Threat actors continue to exploit geopolitical and global public events\nlaunch aggressive campaigns propagating disinformation over the Internet. In\nthis paper we extend our prior research in detecting disinformation using\npsycholinguistic and computational linguistic processes linked to deception and\ncybercrime to gain an understanding of the features impact the predictive\noutcome of machine learning models. In this paper we attempt to determine\npatterns of deception in disinformation in hybrid models trained on\ndisinformation and scams, fake positive and negative online reviews, or fraud\nusing the eXtreme Gradient Boosting machine learning algorithm. Four hybrid\nmodels are generated which are models trained on disinformation and fraud\n(DIS+EN), disinformation and scams (DIS+FB), disinformation and favorable fake\nreviews (DIS+POS) and disinformation and unfavorable fake reviews (DIS+NEG).\nThe four hybrid models detected deception and disinformation with predictive\naccuracies ranging from 75% to 85%. The outcome of the models was evaluated\nwith SHAP to determine the impact of the features.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Alex V Mbaziira",
            "Maha F Sabir"
        ],
        "published": "2024-05-28T21:16:14Z"
    },
    {
        "title": "Metaheuristic approaches to the placement of suicide bomber detectors",
        "link": "http://dx.doi.org/10.1007/s10732-017-9335-z",
        "abstract": "Suicide bombing is an infamous form of terrorism that is becoming\nincreasingly prevalent in the current era of global terror warfare. We consider\nthe case of targeted attacks of this kind, and the use of detectors distributed\nover the area under threat as a protective countermeasure. Such detectors are\nnon-fully reliable, and must be strategically placed in order to maximize the\nchances of detecting the attack, hence minimizing the expected number of\ncasualties. To this end, different metaheuristic approaches based on local\nsearch and on population-based search are considered and benchmarked against a\npowerful greedy heuristic from the literature. We conduct an extensive\nempirical evaluation on synthetic instances featuring very diverse properties.\nMost metaheuristics outperform the greedy algorithm, and a hill-climber is\nshown to be superior to remaining approaches. This hill-climber is subsequently\nsubject to a sensitivity analysis to determine which problem features make it\nstand above the greedy approach, and is finally deployed on a number of problem\ninstances built after realistic scenarios, corroborating the good performance\nof the heuristic.",
        "subjects": [
            "cs.NE"
        ],
        "authors": [
            "Carlos Cotta",
            "José E. Gallardo"
        ],
        "published": "2024-05-28T21:14:01Z"
    },
    {
        "title": "A Margin-based Multiclass Generalization Bound via Geometric Complexity",
        "link": "http://arxiv.org/abs/2405.18590v1",
        "abstract": "There has been considerable effort to better understand the generalization\ncapabilities of deep neural networks both as a means to unlock a theoretical\nunderstanding of their success as well as providing directions for further\nimprovements. In this paper, we investigate margin-based multiclass\ngeneralization bounds for neural networks which rely on a recent complexity\nmeasure, the geometric complexity, developed for neural networks. We derive a\nnew upper bound on the generalization error which scales with the\nmargin-normalized geometric complexity of the network and which holds for a\nbroad family of data distributions and model classes. Our generalization bound\nis empirically investigated for a ResNet-18 model trained with SGD on the\nCIFAR-10 and CIFAR-100 datasets with both original and random labels.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Michael Munn",
            "Benoit Dherin",
            "Javier Gonzalvo"
        ],
        "published": "2024-05-28T21:08:58Z"
    },
    {
        "title": "A Verifiable Computing Scheme for Encrypted Control Systems",
        "link": "http://arxiv.org/abs/2405.18586v1",
        "abstract": "The proliferation of cloud computing technologies has paved the way for\ndeploying networked encrypted control systems, offering high performance,\nremote accessibility and privacy. However, in scenarios where the control\nalgorithms run on third-party cloud service providers, the control logic might\nbe changed by a malicious agent on the cloud. Consequently, it is imperative to\nverify the correctness of the control signals received from the cloud.\nTraditional verification methods, like zero-knowledge proof techniques, are\ncomputationally demanding in both proof generation and verification, may\nrequire several rounds of interactions between the prover and verifier and,\nconsequently, are inapplicable in realtime control system applications. In this\npaper, we present a novel computationally inexpensive verifiable computing\nsolution inspired by the probabilistic cut-and-choose approach. The proposed\nscheme allows the plant's actuator to validate the computations accomplished by\nthe encrypted cloud-based networked controller without compromising the control\nscheme's performance. We showcase the effectiveness and real-time applicability\nof the proposed verifiable computation scheme using a remotely controlled\nKhepera IV differential-drive robot.",
        "subjects": [
            "eess.SY",
            "cs.CR",
            "cs.SY"
        ],
        "authors": [
            "Francesca Stabile",
            "Walter Lucia",
            "Amr Youssef",
            "Giuseppe Franze"
        ],
        "published": "2024-05-28T21:06:39Z"
    },
    {
        "title": "Automatic Calibration for an Open-source Magnetic Tactile Sensor",
        "link": "http://arxiv.org/abs/2405.18582v1",
        "abstract": "Tactile sensing can enable robots to perform complex, contact-rich tasks.\nMagnetic sensors offer accurate three-axis force measurements while using\naffordable materials. Calibrating such a sensor involves either manual data\ncollection, or automated procedures with precise mounting of the sensor\nrelative to an actuator. We present an open-source magnetic tactile sensor with\nan automatic, in situ, gripper-agnostic calibration method, after which the\nsensor is immediately ready for use. Our goal is to lower the barrier to entry\nfor tactile sensing, fostering collaboration in robotics. Design files and\nreadout code can be found at\nhttps://github.com/LowiekVDS/Open-source-Magnetic-Tactile-Sensor}{https://github.com/LowiekVDS/Open-source-Magnetic-Tactile-Sensor.",
        "subjects": [
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Lowiek Van den Stockt",
            "Remko Proesmans",
            "Francis wyffels"
        ],
        "published": "2024-05-28T20:56:23Z"
    },
    {
        "title": "Unleashing the Potential of Text-attributed Graphs: Automatic Relation\n  Decomposition via Large Language Models",
        "link": "http://arxiv.org/abs/2405.18581v1",
        "abstract": "Recent advancements in text-attributed graphs (TAGs) have significantly\nimproved the quality of node features by using the textual modeling\ncapabilities of language models. Despite this success, utilizing text\nattributes to enhance the predefined graph structure remains largely\nunexplored. Our extensive analysis reveals that conventional edges on TAGs,\ntreated as a single relation (e.g., hyperlinks) in previous literature,\nactually encompass mixed semantics (e.g., \"advised by\" and \"participates in\").\nThis simplification hinders the representation learning process of Graph Neural\nNetworks (GNNs) on downstream tasks, even when integrated with advanced node\nfeatures. In contrast, we discover that decomposing these edges into distinct\nsemantic relations significantly enhances the performance of GNNs. Despite\nthis, manually identifying and labeling of edges to corresponding semantic\nrelations is labor-intensive, often requiring domain expertise. To this end, we\nintroduce RoSE (Relation-oriented Semantic Edge-decomposition), a novel\nframework that leverages the capability of Large Language Models (LLMs) to\ndecompose the graph structure by analyzing raw text attributes - in a fully\nautomated manner. RoSE operates in two stages: (1) identifying meaningful\nrelations using an LLM-based generator and discriminator, and (2) categorizing\neach edge into corresponding relations by analyzing textual contents associated\nwith connected nodes via an LLM-based decomposer. Extensive experiments\ndemonstrate that our model-agnostic framework significantly enhances node\nclassification performance across various datasets, with improvements of up to\n16% on the Wisconsin dataset.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Hyunjin Seo",
            "Taewon Kim",
            "June Yong Yang",
            "Eunho Yang"
        ],
        "published": "2024-05-28T20:54:47Z"
    },
    {
        "title": "Artificial Intelligence in Industry 4.0: A Review of Integration\n  Challenges for Industrial Systems",
        "link": "http://arxiv.org/abs/2405.18580v1",
        "abstract": "In Industry 4.0, Cyber-Physical Systems (CPS) generate vast data sets that\ncan be leveraged by Artificial Intelligence (AI) for applications including\npredictive maintenance and production planning. However, despite the\ndemonstrated potential of AI, its widespread adoption in sectors like\nmanufacturing remains limited. Our comprehensive review of recent literature,\nincluding standards and reports, pinpoints key challenges: system integration,\ndata-related issues, managing workforce-related concerns and ensuring\ntrustworthy AI. A quantitative analysis highlights particular challenges and\ntopics that are important for practitioners but still need to be sufficiently\ninvestigated by academics. The paper briefly discusses existing solutions to\nthese challenges and proposes avenues for future research. We hope that this\nsurvey serves as a resource for practitioners evaluating the cost-benefit\nimplications of AI in CPS and for researchers aiming to address these urgent\nchallenges.",
        "subjects": [
            "cs.AI",
            "cs.LG",
            "I.2.1"
        ],
        "authors": [
            "Alexander Windmann",
            "Philipp Wittenberg",
            "Marvin Schieseck",
            "Oliver Niggemann"
        ],
        "published": "2024-05-28T20:54:41Z"
    },
    {
        "title": "Public Technologies Transforming Work of the Public and the Public\n  Sector",
        "link": "http://dx.doi.org/10.1145/3663384.3663407",
        "abstract": "Technologies adopted by the public sector have transformed the work practices\nof employees in public agencies by creating different means of communication\nand decision-making. Although much of the recent research in the future of work\ndomain has concentrated on the effects of technological advancements on public\nsector employees, the influence on work practices of external stakeholders\nengaging with this sector remains under-explored. In this paper, we focus on a\ndigital platform called OneStop which is deployed by several building\ndepartments across the U.S. and aims to integrate various steps and services\ninto a single point of online contact between public sector employees and the\npublic. Drawing on semi-structured interviews with 22 stakeholders, including\nlocal business owners, experts involved in the construction process, community\nrepresentatives, and building department employees, we investigate how this\ntechnology transition has impacted the work of these different stakeholders. We\nobserve a multifaceted perspective and experience caused by the adoption of\nOneStop. OneStop exacerbated inequitable practices for local business owners\ndue to a lack of face-to-face interactions with the department employees. For\nthe public sector employees, OneStop standardized the work practices,\nrepresenting the building department's priorities and values. Based on our\nfindings, we discuss tensions around standardization, equality, and equity in\ntechnology transition, as well as design implications for equitable practices\nin the public sector.",
        "subjects": [
            "cs.CY",
            "cs.HC"
        ],
        "authors": [
            "Seyun Kim",
            "Bonnie Fan",
            "Willa Yunqi Yang",
            "Jessie Ramey",
            "Sarah E Fox",
            "Haiyi Zhu",
            "John Zimmerman",
            "Motahhare Eslami"
        ],
        "published": "2024-05-28T20:54:31Z"
    },
    {
        "title": "Single-loop Stochastic Algorithms for Difference of Max-Structured\n  Weakly Convex Functions",
        "link": "http://arxiv.org/abs/2405.18577v2",
        "abstract": "In this paper, we study a class of non-smooth non-convex problems in the form\nof $\\min_{x}[\\max_{y\\in Y}\\phi(x, y) - \\max_{z\\in Z}\\psi(x, z)]$, where both\n$\\Phi(x) = \\max_{y\\in Y}\\phi(x, y)$ and $\\Psi(x)=\\max_{z\\in Z}\\psi(x, z)$ are\nweakly convex functions, and $\\phi(x, y), \\psi(x, z)$ are strongly concave\nfunctions in terms of $y$ and $z$, respectively. It covers two families of\nproblems that have been studied but are missing single-loop stochastic\nalgorithms, i.e., difference of weakly convex functions and weakly convex\nstrongly-concave min-max problems. We propose a stochastic Moreau envelope\napproximate gradient method dubbed SMAG, the first single-loop algorithm for\nsolving these problems, and provide a state-of-the-art non-asymptotic\nconvergence rate. The key idea of the design is to compute an approximate\ngradient of the Moreau envelopes of $\\Phi, \\Psi$ using only one step of\nstochastic gradient update of the primal and dual variables. Empirically, we\nconduct experiments on positive-unlabeled (PU) learning and partial area under\nROC curve (pAUC) optimization with an adversarial fairness regularizer to\nvalidate the effectiveness of our proposed algorithms.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Quanqi Hu",
            "Qi Qi",
            "Zhaosong Lu",
            "Tianbao Yang"
        ],
        "published": "2024-05-28T20:52:46Z"
    },
    {
        "title": "Lost in Interpretation: Navigating Challenges in Validating Persistency\n  Models Amid Vague Specs and Stubborn Machines, All with a Sense of Humour",
        "link": "http://arxiv.org/abs/2405.18575v1",
        "abstract": "Memory persistency models provide a foundation for persistent programming by\nspecifying which (and when) writes to non-volatile memory (NVM) become\npersistent. Memory persistency models for the Intel-x86 and Arm architectures\nhave been formalised, but not empirically validated against real machines.\nTraditional validation methods %such as %extensive litmus testing used for\nmemory \\emph{consistency} models do not straightforwardly apply because a test\nprogram cannot directly observe when its data has become persistent: it cannot\ndistinguish between reading data from a volatile cache and from NVM. We\ninvestigate addressing this challenge using a commercial off-the-shelf device\nthat intercepts data on the memory bus and logs all writes in the order they\nreach the memory. Using this technique we conducted a litmus-testing campaign\naimed at empirically validating the persistency guarantees of Intel-x86 and Arm\nmachines. We observed writes propagating to memory out of order, and took steps\nto build confidence that these observations were not merely artefacts of our\ntesting setup. However, despite gaining high confidence in the trustworthiness\nof our observation method, our conclusions remain largely negative. We found\nthat the Intel-x86 architecture is not amenable to our approach, and on\nconsulting Intel engineers discovered that there are currently no reliable\nmethods of validating their persistency guarantees. For Arm, we found that even\na machine recommended to us by a persistency expert at Arm did not match the\nformal Arm persistency model, due to a loophole in the specification.",
        "subjects": [
            "cs.PL"
        ],
        "authors": [
            "Vasileios Klimis",
            "Alastair F. Donaldson",
            "Viktor Vafeiadis",
            "John Wickerson",
            "Azalea Raad"
        ],
        "published": "2024-05-28T20:48:35Z"
    },
    {
        "title": "SpecTra: Enhancing the Code Translation Ability of Language Models by\n  Generating Multi-Modal Specifications",
        "link": "http://arxiv.org/abs/2405.18574v1",
        "abstract": "Large language models (LLMs) are increasingly being used for the task of\nautomated code translation, which has important real-world applications.\nHowever, most existing approaches use only the source code of a program as an\ninput to an LLM, and do not consider the different kinds of specifications that\ncan be extracted from a program. In this paper, we propose SpecTra, a\nmulti-stage approach that uses a novel self-consistency filter to first\ngenerate high-quality invariants, test cases, and natural language descriptions\nfrom a given program, and then uses these along with the source code to improve\nthe quality of LLM-generated translations. We evaluate SpecTra on two code\ntranslation tasks - C to Rust, and C to Go - and show that it can enhance the\nperformance of four popular LLMs on these tasks by up to 10 percentage points\nand a relative improvement of up to 23%. Our research suggests that generating\nhigh-quality specifications could be a promising and efficient way to improve\nthe performance of LLMs for code translation.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Vikram Nitin",
            "Baishakhi Ray"
        ],
        "published": "2024-05-28T20:48:30Z"
    },
    {
        "title": "Programmer Visual Attention During Context-Aware Code Summarization",
        "link": "http://arxiv.org/abs/2405.18573v1",
        "abstract": "Abridged: Programmer attention represents the visual focus of programmers on\nparts of the source code in pursuit of programming tasks. We conducted an\nin-depth human study with XY Java programmers, where each programmer generated\nsummaries for 40 methods from five large Java projects over five one-hour\nsessions. We used eye-tracking equipment to map the visual attention of\nprogrammers while they wrote the summaries. We also rate the quality of each\nsummary. We found eye-gaze patterns and metrics that define common behaviors\nbetween programmer attention during context-aware code summarization.\nSpecifically, we found that programmers need to read significantly (p<0.01)\nfewer words and make significantly fewer revisits to words (p\\textless0.03) as\nthey summarize more methods during a session, while maintaining the quality of\nsummaries. We also found that the amount of source code a participant looks at\ncorrelates with a higher quality summary, but this trend follows a bell-shaped\ncurve, such that after a threshold reading more source code leads to a\nsignificant decrease (p<0.01) in the quality of summaries. We also gathered\ninsight into the type of methods in the project that provide the most\ncontextual information for code summarization based on programmer attention.\nSpecifically, we observed that programmers spent a majority of their time\nlooking at methods inside the same class as the target method to be summarized.\nSurprisingly, we found that programmers spent significantly less time looking\nat methods in the call graph of the target method. We discuss how our empirical\nobservations may aid future studies towards modeling programmer attention and\nimproving context-aware automatic source code summarization.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Aakash Bansal",
            "Robert Wallace",
            "Zachary Karas",
            "Ningzhi Tang",
            "Yu Huang",
            "Toby Jia-Jun Li",
            "Collin McMillan"
        ],
        "published": "2024-05-28T20:48:07Z"
    },
    {
        "title": "Low-rank finetuning for LLMs: A fairness perspective",
        "link": "http://arxiv.org/abs/2405.18572v1",
        "abstract": "Low-rank approximation techniques have become the de facto standard for\nfine-tuning Large Language Models (LLMs) due to their reduced computational and\nmemory requirements. This paper investigates the effectiveness of these methods\nin capturing the shift of fine-tuning datasets from the initial pre-trained\ndata distribution. Our findings reveal that there are cases in which low-rank\nfine-tuning falls short in learning such shifts. This, in turn, produces\nnon-negligible side effects, especially when fine-tuning is adopted for\ntoxicity mitigation in pre-trained models, or in scenarios where it is\nimportant to provide fair models. Through comprehensive empirical evidence on\nseveral models, datasets, and tasks, we show that low-rank fine-tuning\ninadvertently preserves undesirable biases and toxic behaviors. We also show\nthat this extends to sequential decision-making tasks, emphasizing the need for\ncareful evaluation to promote responsible LLMs development.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Saswat Das",
            "Marco Romanelli",
            "Cuong Tran",
            "Zarreen Reza",
            "Bhavya Kailkhura",
            "Ferdinando Fioretto"
        ],
        "published": "2024-05-28T20:43:53Z"
    },
    {
        "title": "Optimal Multiclass U-Calibration Error and Beyond",
        "link": "http://arxiv.org/abs/2405.19374v1",
        "abstract": "We consider the problem of online multiclass U-calibration, where a\nforecaster aims to make sequential distributional predictions over $K$ classes\nwith low U-calibration error, that is, low regret with respect to all bounded\nproper losses simultaneously. Kleinberg et al. (2023) developed an algorithm\nwith U-calibration error $O(K\\sqrt{T})$ after $T$ rounds and raised the open\nquestion of what the optimal bound is. We resolve this question by showing that\nthe optimal U-calibration error is $\\Theta(\\sqrt{KT})$ -- we start with a\nsimple observation that the Follow-the-Perturbed-Leader algorithm of Daskalakis\nand Syrgkanis (2016) achieves this upper bound, followed by a matching lower\nbound constructed with a specific proper loss (which, as a side result, also\nproves the optimality of the algorithm of Daskalakis and Syrgkanis (2016) in\nthe context of online learning against an adversary with finite choices). We\nalso strengthen our results under natural assumptions on the loss functions,\nincluding $\\Theta(\\log T)$ U-calibration error for Lipschitz proper losses,\n$O(\\log T)$ U-calibration error for a certain class of decomposable proper\nlosses, U-calibration error bounds for proper losses with a low covering\nnumber, and others.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Haipeng Luo",
            "Spandan Senapati",
            "Vatsal Sharan"
        ],
        "published": "2024-05-28T20:33:18Z"
    },
    {
        "title": "Its Not a Modality Gap: Characterizing and Addressing the Contrastive\n  Gap",
        "link": "http://arxiv.org/abs/2405.18570v1",
        "abstract": "Multi-modal contrastive models such as CLIP achieve state-of-the-art\nperformance in zero-shot classification by embedding input images and texts on\na joint representational space. Recently, a modality gap has been reported in\ntwo-encoder contrastive models like CLIP, meaning that the image and text\nembeddings reside in disjoint areas of the latent space. Previous studies\nsuggest that this gap exists due to 1) the cone effect, 2) mismatched pairs in\nthe dataset, and 3) insufficient training. We show that, even when accounting\nfor all these factors, and even when using the same modality, the contrastive\nloss actually creates a gap during training. As a result, We propose that the\nmodality gap is inherent to the two-encoder contrastive loss and rename it the\ncontrastive gap. We present evidence that attributes this contrastive gap to\nlow uniformity in CLIP space, resulting in embeddings that occupy only a small\nportion of the latent space. To close the gap, we adapt the uniformity and\nalignment properties of unimodal contrastive loss to the multi-modal setting\nand show that simply adding these terms to the CLIP loss distributes the\nembeddings more uniformly in the representational space, closing the gap. In\nour experiments, we show that the modified representational space achieves\nbetter performance than default CLIP loss in downstream tasks such as zero-shot\nimage classification and multi-modal arithmetic.",
        "subjects": [
            "cs.CV",
            "cs.CL",
            "cs.IR",
            "cs.LG"
        ],
        "authors": [
            "Abrar Fahim",
            "Alex Murphy",
            "Alona Fyshe"
        ],
        "published": "2024-05-28T20:28:07Z"
    },
    {
        "title": "Minimum Strict Consistent Subset in Paths, Spiders, Combs and Trees",
        "link": "http://arxiv.org/abs/2405.18569v2",
        "abstract": "In a connected simple graph G = (V,E), each vertex of V is colored by a color\nfrom the set of colors C={c_1, c_2,..., c_{\\alpha}}. We take a subset S of V,\nsuch that for every vertex v in V\\S, at least one vertex of the same color is\npresent in its set of nearest neighbors in S. We refer to such a S as a\nconsistent subset (CS) The Minimum Consistent Subset (MCS) problem is the\ncomputation of a consistent subset of the minimum size. It is established that\nMCS is NP-complete for general graphs, including planar graphs. We expand our\nstudy to interval graphs and circle graphs in an attempt to gain a complete\nunderstanding of the computational complexity of the MCS problem across various\ngraph classes. The strict consistent subset is a variant of consistent subset\nproblems. We take a subset S^{\\prime} of V, such that for every vertex v in\nV\\S^{\\prime}, all the vertices in its set of nearest neighbors in S have the\nsame color as v. We refer to such a S^{\\prime} as a strict consistent subset\n(SCS). The Minimum Strict Consistent Subset (MSCS) problem is the computation\nof a consistent subset of the minimum size.\n  We demonstrate that MSCS is NP-hard in general graphs. We show a\n2-approximation in trees. Later, we show polynomial-time algorithms in trees.\nLater, we demonstrate faster polynomial-time algorithms in paths, spiders, and\ncombs.",
        "subjects": [
            "cs.CG"
        ],
        "authors": [
            "Bubai Manna"
        ],
        "published": "2024-05-28T20:26:34Z"
    },
    {
        "title": "Warm-starting Push-Relabel",
        "link": "http://arxiv.org/abs/2405.18568v1",
        "abstract": "Push-Relabel is one of the most celebrated network flow algorithms.\nMaintaining a pre-flow that saturates a cut, it enjoys better theoretical and\nempirical running time than other flow algorithms, such as Ford-Fulkerson. In\npractice, Push-Relabel is even faster than what theoretical guarantees can\npromise, in part because of the use of good heuristics for seeding and updating\nthe iterative algorithm. However, it remains unclear how to run Push-Relabel on\nan arbitrary initialization that is not necessarily a pre-flow or\ncut-saturating. We provide the first theoretical guarantees for warm-starting\nPush-Relabel with a predicted flow, where our learning-augmented version\nbenefits from fast running time when the predicted flow is close to an optimal\nflow, while maintaining robust worst-case guarantees. Interestingly, our\nalgorithm uses the gap relabeling heuristic, which has long been employed in\npractice, even though prior to our work there was no rigorous theoretical\njustification for why it can lead to run-time improvements. We then provide\nexperiments that show our warm-started Push-Relabel also works well in\npractice.",
        "subjects": [
            "cs.DS",
            "cs.LG"
        ],
        "authors": [
            "Sami Davies",
            "Sergei Vassilvitskii",
            "Yuyan Wang"
        ],
        "published": "2024-05-28T20:26:05Z"
    },
    {
        "title": "Locally different models in a checkerboard pattern with mesh adaptation\n  and error control for multiple quantities of interest",
        "link": "http://arxiv.org/abs/2405.18567v1",
        "abstract": "In this work, we apply multi-goal oriented error estimation to the finite\nelement method. In particular, we use the dual weighted residual method and\napply it to a model problem. This model problem consist of locally different\ncoercive partial differential equations in a checkerboard pattern, where the\nsolution is continuous across the interface. In addition to the error\nestimation, the error can be localized using a partition of unity technique.\nThe resulting adaptive algorithm is substantiated with a numerical example.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Bernhard Endtmayer"
        ],
        "published": "2024-05-28T20:24:51Z"
    },
    {
        "title": "A faster heuristic for the Traveling Salesman Problem with Drone",
        "link": "http://arxiv.org/abs/2405.18566v1",
        "abstract": "Given a set of customers, the Flying Sidekick Traveling Salesman Problem\n(FSTSP) consists of using one truck and one drone to perform deliveries to\nthem. The drone is limited to delivering to one customer at a time, after which\nit returns to the truck, from where it can be launched again. The goal is to\nminimize the time required to service all customers and return both vehicles to\nthe depot. In the literature, we can find heuristics for this problem that\nfollow the order-first split-second approach: find a Hamiltonian cycle h with\nall customers, and then remove some customers to be handled by the drone while\ndeciding from where the drone will be launched and where it will be retrieved.\nIndeed, they optimally solve the h-FSTSP, which is a variation that consists of\nsolving the FSTSP while respecting a given initial cycle h. We present the Lazy\nDrone Property, which guarantees that only some combinations of nodes for\nlaunch and retrieval of the drone need to be considered by algorithms for the\nh-FSTSP. We also present an algorithm that uses the property, and we show\nexperimental results which corroborate its effectiveness in decreasing the\nrunning time of such algorithms. Our algorithm was shown to be more than 84\ntimes faster than the previously best-known ones over the literature benchmark.\nMoreover, on average, it considered a number of launch and retrieval pairs that\nis linear on the number of customers, indicating that the algorithm's\nperformance should be sustainable for larger instances.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Pedro H. D. B. Hokama",
            "Carla N. Lintzmayer",
            "Mário C. San Felice"
        ],
        "published": "2024-05-28T20:20:41Z"
    },
    {
        "title": "Video2MR: Automatically Generating Mixed Reality 3D Instructions by\n  Augmenting Extracted Motion from 2D Videos",
        "link": "http://arxiv.org/abs/2405.18565v1",
        "abstract": "This paper introduces Video2MR, a mixed reality system that automatically\ngenerates 3D sports and exercise instructions from 2D videos. Mixed reality\ninstructions have great potential for physical training, but existing works\nrequire substantial time and cost to create these 3D experiences. Video2MR\novercomes this limitation by transforming arbitrary instructional videos\navailable online into MR 3D avatars with AI-enabled motion capture\n(DeepMotion). Then, it automatically enhances the avatar motion through the\nfollowing augmentation techniques: 1) contrasting and highlighting differences\nbetween the user and avatar postures, 2) visualizing key trajectories and\nmovements of specific body parts, 3) manipulation of time and speed using body\nmotion, and 4) spatially repositioning avatars for different perspectives.\nDeveloped on Hololens 2 and Azure Kinect, we showcase various use cases,\nincluding yoga, dancing, soccer, tennis, and other physical exercises. The\nstudy results confirm that Video2MR provides more engaging and playful learning\nexperiences, compared to existing 2D video instructions.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Keiichi Ihara",
            "Kyzyl Monteiro",
            "Mehrad Faridan",
            "Rubaiat Habib Kazi",
            "Ryo Suzuki"
        ],
        "published": "2024-05-28T20:19:38Z"
    },
    {
        "title": "Counterfactual Explanations for Multivariate Time-Series without\n  Training Datasets",
        "link": "http://arxiv.org/abs/2405.18563v1",
        "abstract": "Machine learning (ML) methods have experienced significant growth in the past\ndecade, yet their practical application in high-impact real-world domains has\nbeen hindered by their opacity. When ML methods are responsible for making\ncritical decisions, stakeholders often require insights into how to alter these\ndecisions. Counterfactual explanations (CFEs) have emerged as a solution,\noffering interpretations of opaque ML models and providing a pathway to\ntransition from one decision to another. However, most existing CFE methods\nrequire access to the model's training dataset, few methods can handle\nmultivariate time-series, and none can handle multivariate time-series without\ntraining datasets. These limitations can be formidable in many scenarios. In\nthis paper, we present CFWoT, a novel reinforcement-learning-based CFE method\nthat generates CFEs when training datasets are unavailable. CFWoT is\nmodel-agnostic and suitable for both static and multivariate time-series\ndatasets with continuous and discrete features. Users have the flexibility to\nspecify non-actionable, immutable, and preferred features, as well as causal\nconstraints which CFWoT guarantees will be respected. We demonstrate the\nperformance of CFWoT against four baselines on several datasets and find that,\ndespite not having access to a training dataset, CFWoT finds CFEs that make\nsignificantly fewer and significantly smaller changes to the input time-series.\nThese properties make CFEs more actionable, as the magnitude of change required\nto alter an outcome is vastly reduced.",
        "subjects": [
            "cs.LG",
            "stat.ME"
        ],
        "authors": [
            "Xiangyu Sun",
            "Raquel Aoki",
            "Kevin H. Wilson"
        ],
        "published": "2024-05-28T20:15:09Z"
    },
    {
        "title": "Potential Field Based Deep Metric Learning",
        "link": "http://arxiv.org/abs/2405.18560v1",
        "abstract": "Deep metric learning (DML) involves training a network to learn a\nsemantically meaningful representation space. Many current approaches mine\nn-tuples of examples and model interactions within each tuplets. We present a\nnovel, compositional DML model, inspired by electrostatic fields in physics\nthat, instead of in tuples, represents the influence of each example\n(embedding) by a continuous potential field, and superposes the fields to\nobtain their combined global potential field. We use attractive/repulsive\npotential fields to represent interactions among embeddings from images of the\nsame/different classes. Contrary to typical learning methods, where mutual\ninfluence of samples is proportional to their distance, we enforce reduction in\nsuch influence with distance, leading to a decaying field. We show that such\ndecay helps improve performance on real world datasets with large intra-class\nvariations and label noise. Like other proxy-based methods, we also use proxies\nto succinctly represent sub-populations of examples. We evaluate our method on\nthree standard DML benchmarks- Cars-196, CUB-200-2011, and SOP datasets where\nit outperforms state-of-the-art baselines.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.IR",
            "cs.LG",
            "eess.IV"
        ],
        "authors": [
            "Shubhang Bhatnagar",
            "Narendra Ahuja"
        ],
        "published": "2024-05-28T20:10:06Z"
    },
    {
        "title": "\"Golden Ratio Yoshimura\" for Meta-Stable and Massively Reconfigurable\n  Deployment",
        "link": "http://arxiv.org/abs/2405.18558v1",
        "abstract": "Yoshimura origami is a classical folding pattern that has inspired many\ndeployable structure designs. Its applications span from space exploration,\nkinetic architectures, and soft robots to even everyday household items.\nHowever, despite its wide usage, Yoshimura has been fixated on a set of design\nconstraints to ensure its flat-foldability. Through extensive kinematic\nanalysis and prototype tests, this study presents a new Yoshimura that\nintentionally defies these constraints. Remarkably, one can impart a unique\nmeta-stability by using the Golden Ratio angle to define the triangular facets\nof a generalized Yoshimura. As a result, when its facets are strategically\npopped out, a ``Golden Ratio Yoshimura'' boom with $m$ modules can be\ntheoretically reconfigured into $8^m$ geometrically unique and load-bearing\nshapes. This result not only challenges the existing design norms but also\nopens up a new avenue to create deployable and versatile structural systems.",
        "subjects": [
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Vishrut Deshpande",
            "Yogesh Phalak",
            "Ziyang Zhou",
            "Ian Walker",
            "Suyi Li"
        ],
        "published": "2024-05-28T20:05:20Z"
    },
    {
        "title": "Reinforcement Learning in Dynamic Treatment Regimes Needs Critical\n  Reexamination",
        "link": "http://arxiv.org/abs/2405.18556v1",
        "abstract": "In the rapidly changing healthcare landscape, the implementation of offline\nreinforcement learning (RL) in dynamic treatment regimes (DTRs) presents a mix\nof unprecedented opportunities and challenges. This position paper offers a\ncritical examination of the current status of offline RL in the context of\nDTRs. We argue for a reassessment of applying RL in DTRs, citing concerns such\nas inconsistent and potentially inconclusive evaluation metrics, the absence of\nnaive and supervised learning baselines, and the diverse choice of RL\nformulation in existing research. Through a case study with more than 17,000\nevaluation experiments using a publicly available Sepsis dataset, we\ndemonstrate that the performance of RL algorithms can significantly vary with\nchanges in evaluation metrics and Markov Decision Process (MDP) formulations.\nSurprisingly, it is observed that in some instances, RL algorithms can be\nsurpassed by random baselines subjected to policy evaluation methods and reward\ndesign. This calls for more careful policy evaluation and algorithm development\nin future DTR works. Additionally, we discussed potential enhancements toward\nmore reliable development of RL-based dynamic treatment regimes and invited\nfurther discussion within the community. Code is available at\nhttps://github.com/GilesLuo/ReassessDTR.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Zhiyao Luo",
            "Yangchen Pan",
            "Peter Watkinson",
            "Tingting Zhu"
        ],
        "published": "2024-05-28T20:03:18Z"
    },
    {
        "title": "Scalable Surrogate Verification of Image-based Neural Network Control\n  Systems using Composition and Unrolling",
        "link": "http://arxiv.org/abs/2405.18554v1",
        "abstract": "Verifying safety of neural network control systems that use images as input\nis a difficult problem because, from a given system state, there is no known\nway to mathematically model what images are possible in the real-world. We\nbuild on recent work that considers a surrogate verification approach, training\na conditional generative adversarial network (cGAN) as an image generator in\nplace of the real world. This enables set-based formal analysis of the\nclosed-loop system, providing analysis beyond simulation and testing. While\nexisting work is effective on small examples, excessive overapproximation both\nwithin a single control period and across multiple control periods limits its\nscalability. We propose approaches to overcome these two sources of error.\nFirst, we overcome one-step error by composing the system's dynamics along with\nthe cGAN and neural network controller, without losing the dependencies between\ninput states and the control outputs as in the monotonic analysis of the system\ndynamics. Second, we reduce multi-step error by repeating the single-step\ncomposition, essentially unrolling multiple steps of the control loop into a\nlarge neural network. We then leverage existing network verification tools to\ncompute accurate reachable sets for multiple steps, avoiding the accumulation\nof abstraction error at each step. We demonstrate the effectiveness of our\napproach in terms of both accuracy and scalability using two case studies: an\nautonomous aircraft taxiing system and an advanced emergency braking system. On\nthe aircraft taxiing system, the converged reachable set is 175% larger using\nthe prior baseline method compared with our proposed approach. On the emergency\nbraking system, with 24x the number of image output variables from the cGAN,\nthe baseline method fails to prove any states are safe, whereas our\nimprovements enable set-based safety analysis.",
        "subjects": [
            "cs.LG",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Feiyang Cai",
            "Chuchu Fan",
            "Stanley Bak"
        ],
        "published": "2024-05-28T19:56:53Z"
    },
    {
        "title": "The FAIIR Tool: A Conversational AI Agent Assistant for Youth Mental\n  Health Service Provision",
        "link": "http://arxiv.org/abs/2405.18553v1",
        "abstract": "World's healthcare systems and mental health agencies face both a growing\ndemand for youth mental health services, alongside a simultaneous challenge of\nlimited resources. Given these constraints, this work presents our experience\nin the creation and evaluation of the FAIIR (Frontline Assistant: Issue\nIdentification and Recommendation) tool, an ensemble of domain-adapted and\nfine-tuned transformer models, leveraging natural language processing to\nidentify issues that youth may be experiencing. We explore the technical\ndevelopment, performance, and validation processes leveraged for the FAIIR tool\nin application to situations of frontline crisis response via Kids Help Phone.\nFrontline Crisis Responders assign an issue tag from a defined list following\neach conversation. Assisting with the identification of issues of relevance\nhelps reduce the burden on CRs, ensuring that appropriate resources can be\nprovided and that active rescues and mandatory reporting can take place in\ncritical situations requiring immediate de-escalation.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Stephen Obadinma",
            "Alia Lachana",
            "Maia Norman",
            "Jocelyn Rankin",
            "Joanna Yu",
            "Xiaodan Zhu",
            "Darren Mastropaolo",
            "Deval Pandya",
            "Roxana Sultan",
            "Elham Dolatabadi"
        ],
        "published": "2024-05-28T19:54:46Z"
    },
    {
        "title": "SGD method for entropy error function with smoothing l0 regularization\n  for neural networks",
        "link": "http://arxiv.org/abs/2405.18552v1",
        "abstract": "The entropy error function has been widely used in neural networks.\nNevertheless, the network training based on this error function generally leads\nto a slow convergence rate, and can easily be trapped in a local minimum or\neven with the incorrect saturation problem in practice. In fact, there are many\nresults based on entropy error function in neural network and its applications.\nHowever, the theory of such an algorithm and its convergence have not been\nfully studied so far. To tackle the issue, we propose a novel entropy function\nwith smoothing l0 regularization for feed-forward neural networks. Using\nreal-world datasets, we performed an empirical evaluation to demonstrate that\nthe newly conceived algorithm allows us to substantially improve the prediction\nperformance of the considered neural networks. More importantly, the\nexperimental results also show that our proposed function brings in more\nprecise classifications, compared to well-founded baselines. Our work is novel\nas it enables neural networks to learn effectively, producing more accurate\npredictions compared to state-of-the-art algorithms. In this respect, we expect\nthat the algorithm will contribute to existing studies in the field, advancing\nresearch in Machine Learning and Deep Learning.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Trong-Tuan Nguyen",
            "Van-Dat Thang",
            "Nguyen Van Thin",
            "Phuong T. Nguyen"
        ],
        "published": "2024-05-28T19:54:26Z"
    },
    {
        "title": "Photorealistic Robotic Simulation using Unreal Engine 5 for Agricultural\n  Applications",
        "link": "http://arxiv.org/abs/2405.18551v1",
        "abstract": "This work presents a new robotics simulation environment built upon Unreal\nEngine 5 (UE5) for agricultural image data generation. The simulation utilizes\nthe state-of-the-art real-time rendering engine to provide realistic plant\nimages which are often used in agricultural applications. This study showcases\nthe rendering accuracy of UE5 in comparison to existing tools and assesses its\npositional accuracy when integrated with Robot Operating Systems (ROS). The\nresults indicate that UE5 achieves an impressive average distance error of\n0.021mm when compared to predetermined setpoints in a multi-robot setup\ninvolving two UR10 arms.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Xingjian Li",
            "Lirong Xiang"
        ],
        "published": "2024-05-28T19:40:27Z"
    },
    {
        "title": "Unisolvence of unsymmetric random Kansa collocation by Gaussians and\n  other analytic RBF vanishing at infinity",
        "link": "http://arxiv.org/abs/2405.18550v1",
        "abstract": "We give a short proof of almost sure invertibility of unsymmetric random\nKansa collocation matrices by a class of analytic RBF vanishing at infinity,\nfor the Poisson equation with Dirichlet boundary conditions. Such a class\nincludes popular Positive Definite instances such as Gaussians, Generalized\nInverse MultiQuadrics and Matern RBF. The proof works on general domains in any\ndimension, with any distribution of boundary collocation points and any\ncontinuous random distribution of internal collocation points.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "math.PR",
            "65D12, 65N35"
        ],
        "authors": [
            "Alvise Sommariva",
            "Marco Vianello"
        ],
        "published": "2024-05-28T19:39:09Z"
    },
    {
        "title": "Learning from Uncertain Data: From Possible Worlds to Possible Models",
        "link": "http://arxiv.org/abs/2405.18549v1",
        "abstract": "We introduce an efficient method for learning linear models from uncertain\ndata, where uncertainty is represented as a set of possible variations in the\ndata, leading to predictive multiplicity. Our approach leverages abstract\ninterpretation and zonotopes, a type of convex polytope, to compactly represent\nthese dataset variations, enabling the symbolic execution of gradient descent\non all possible worlds simultaneously. We develop techniques to ensure that\nthis process converges to a fixed point and derive closed-form solutions for\nthis fixed point. Our method provides sound over-approximations of all possible\noptimal models and viable prediction ranges. We demonstrate the effectiveness\nof our approach through theoretical and empirical analysis, highlighting its\npotential to reason about model and prediction uncertainty due to data quality\nissues in training data.",
        "subjects": [
            "cs.LG",
            "cs.DB",
            "cs.SC"
        ],
        "authors": [
            "Jiongli Zhu",
            "Su Feng",
            "Boris Glavic",
            "Babak Salimi"
        ],
        "published": "2024-05-28T19:36:55Z"
    },
    {
        "title": "The Computational Complexity of Formal Reasoning for Encoder-Only\n  Transformers",
        "link": "http://arxiv.org/abs/2405.18548v1",
        "abstract": "We investigate challenges and possibilities of formal reasoning for\nencoder-only transformers (EOT), meaning sound and complete methods for\nverifying or interpreting behaviour. In detail, we condense related formal\nreasoning tasks in the form of a naturally occurring satisfiability problem\n(SAT). We find that SAT is undecidable if we consider EOT, commonly considered\nin the expressiveness community. Furthermore, we identify practical scenarios\nwhere SAT is decidable and establish corresponding complexity bounds. Besides\ntrivial cases, we find that quantized EOT, namely those restricted by some\nfixed-width arithmetic, lead to the decidability of SAT due to their limited\nattention capabilities. However, the problem remains difficult, as we establish\nthose scenarios where SAT is NEXPTIME-hard and those where we can show that it\nis solvable in NEXPTIME for quantized EOT. To complement our theoretical\nresults, we put our findings and their implications in the overall perspective\nof formal reasoning.",
        "subjects": [
            "cs.LO",
            "cs.AI",
            "cs.CC",
            "cs.LG"
        ],
        "authors": [
            "Marco Sälzer",
            "Eric Alsmann",
            "Martin Lange"
        ],
        "published": "2024-05-28T19:30:43Z"
    },
    {
        "title": "User Perception of CAPTCHAs: A Comparative Study between University and\n  Internet Users",
        "link": "http://arxiv.org/abs/2405.18547v1",
        "abstract": "CAPTCHAs are commonly used to distinguish between human and bot users on the\nweb. However, despite having various types of CAPTCHAs, there are still\nconcerns about their security and usability. To address these concerns, we\nsurveyed over 250 participants from a university campus and Amazon Mechanical\nTurk. Our goal was to gather user perceptions regarding the security and\nusability of current CAPTCHA implementations. After analyzing the data using\nstatistical and thematic methods, we found that users struggle to navigate\ncurrent CAPTCHA challenges due to increasing difficulty levels. As a result,\nthey experience frustration, which negatively impacts their user experience.\nAdditionally, participants expressed concerns about the reliability and\nsecurity of these systems. Our findings can offer valuable insights for\ncreating more secure and user-friendly CAPTCHA technologies.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Arun Reddy",
            "Yuan Cheng"
        ],
        "published": "2024-05-28T19:28:04Z"
    },
    {
        "title": "Capacity-Maximizing Dynamic User Association in Double RIS-Aided\n  Broadcast Networks",
        "link": "http://arxiv.org/abs/2405.18546v1",
        "abstract": "We introduce an information-theoretic framework to dynamically pair up\ndifferent reconfigurable intelligent surfaces (RISs) with wireless users with\ngoal of maximizing the fundamental network capacity. We focus on a double\nRIS-aided broadcast packet network with two users. We show using a dynamic\nRIS-user association and an opportunistic protocol, the network capacity could\nbe significantly enhanced and superior to other benchmarks with static\nassociations. The results include new outer-bounds on network capacity and\ntheir achievability. We discuss the optimal RIS-user association.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Alireza Vahid"
        ],
        "published": "2024-05-28T19:27:44Z"
    },
    {
        "title": "Automatic detection of cognitive impairment in elderly people using an\n  entertainment chatbot with Natural Language Processing capabilities",
        "link": "http://dx.doi.org/10.1007/s12652-022-03849-2",
        "abstract": "Previous researchers have proposed intelligent systems for therapeutic\nmonitoring of cognitive impairments. However, most existing practical\napproaches for this purpose are based on manual tests. This raises issues such\nas excessive caretaking effort and the white-coat effect. To avoid these\nissues, we present an intelligent conversational system for entertaining\nelderly people with news of their interest that monitors cognitive impairment\ntransparently. Automatic chatbot dialogue stages allow assessing content\ndescription skills and detecting cognitive impairment with Machine Learning\nalgorithms. We create these dialogue flows automatically from updated news\nitems using Natural Language Generation techniques. The system also infers the\ngold standard of the answers to the questions, so it can assess cognitive\ncapabilities automatically by comparing these answers with the user responses.\nIt employs a similarity metric with values in [0, 1], in increasing level of\nsimilarity. To evaluate the performance and usability of our approach, we have\nconducted field tests with a test group of 30 elderly people in the earliest\nstages of dementia, under the supervision of gerontologists. In the\nexperiments, we have analysed the effect of stress and concentration in these\nusers. Those without cognitive impairment performed up to five times better. In\nparticular, the similarity metric varied between 0.03, for stressed and\nunfocused participants, and 0.36, for relaxed and focused users. Finally, we\ndeveloped a Machine Learning algorithm based on textual analysis features for\nautomatic cognitive impairment detection, which attained accuracy, F-measure\nand recall levels above 80%. We have thus validated the automatic approach to\ndetect cognitive impairment in elderly people based on entertainment content.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.HC",
            "cs.LG"
        ],
        "authors": [
            "Francisco de Arriba-Pérez",
            "Silvia García-Méndez",
            "Francisco J. González-Castaño",
            "Enrique Costa-Montenegro"
        ],
        "published": "2024-05-28T19:17:48Z"
    },
    {
        "title": "Low-Rank Few-Shot Adaptation of Vision-Language Models",
        "link": "http://arxiv.org/abs/2405.18541v1",
        "abstract": "Recent progress in the few-shot adaptation of Vision-Language Models (VLMs)\nhas further pushed their generalization capabilities, at the expense of just a\nfew labeled samples within the target downstream task. However, this promising,\nalready quite abundant few-shot literature has focused principally on prompt\nlearning and, to a lesser extent, on adapters, overlooking the recent advances\nin Parameter-Efficient Fine-Tuning (PEFT). Furthermore, existing few-shot\nlearning methods for VLMs often rely on heavy training procedures and/or\ncarefully chosen, task-specific hyper-parameters, which might impede their\napplicability. In response, we introduce Low-Rank Adaptation (LoRA) in few-shot\nlearning for VLMs, and show its potential on 11 datasets, in comparison to\ncurrent state-of-the-art prompt- and adapter-based approaches. Surprisingly,\nour simple CLIP-LoRA method exhibits substantial improvements, while reducing\nthe training times and keeping the same hyper-parameters in all the target\ntasks, i.e., across all the datasets and numbers of shots. Certainly, our\nsurprising results do not dismiss the potential of prompt-learning and\nadapter-based research. However, we believe that our strong baseline could be\nused to evaluate progress in these emergent subjects in few-shot VLMs.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Maxime Zanella",
            "Ismail Ben Ayed"
        ],
        "published": "2024-05-28T19:16:59Z"
    },
    {
        "title": "Learning diverse attacks on large language models for robust red-teaming\n  and safety tuning",
        "link": "http://arxiv.org/abs/2405.18540v1",
        "abstract": "Red-teaming, or identifying prompts that elicit harmful responses, is a\ncritical step in ensuring the safe and responsible deployment of large language\nmodels (LLMs). Developing effective protection against many modes of attack\nprompts requires discovering diverse attacks. Automated red-teaming typically\nuses reinforcement learning to fine-tune an attacker language model to generate\nprompts that elicit undesirable responses from a target LLM, as measured, for\nexample, by an auxiliary toxicity classifier. We show that even with explicit\nregularization to favor novelty and diversity, existing approaches suffer from\nmode collapse or fail to generate effective attacks. As a flexible and\nprobabilistically principled alternative, we propose to use GFlowNet\nfine-tuning, followed by a secondary smoothing phase, to train the attacker\nmodel to generate diverse and effective attack prompts. We find that the\nattacks generated by our method are effective against a wide range of target\nLLMs, both with and without safety tuning, and transfer well between target\nLLMs. Finally, we demonstrate that models safety-tuned using a dataset of\nred-teaming prompts generated by our method are robust to attacks from other\nRL-based red-teaming approaches.",
        "subjects": [
            "cs.CL",
            "cs.CR",
            "cs.LG"
        ],
        "authors": [
            "Seanie Lee",
            "Minsu Kim",
            "Lynn Cherif",
            "David Dobre",
            "Juho Lee",
            "Sung Ju Hwang",
            "Kenji Kawaguchi",
            "Gauthier Gidel",
            "Yoshua Bengio",
            "Nikolay Malkin",
            "Moksh Jain"
        ],
        "published": "2024-05-28T19:16:17Z"
    },
    {
        "title": "The Past, Present, and Future of Automation in Model-Driven Engineering",
        "link": "http://arxiv.org/abs/2405.18539v1",
        "abstract": "Model-Driven Engineering (MDE) provides a huge body of knowledge of\nautomation for many different engineering tasks, especially those involving\ntransitioning from design to implementation. With the huge progress made on\nArtificial Intelligence (AI) techniques, questions arise for the future of MDE\nsuch as how existing MDE techniques and technologies can be improved or how\nother activities which currently lack dedicated support can also be automated.\nHowever, at the same time, it has to be revisited where and how models should\nbe used to keep the engineers in the loop for creating, operating, and\nmaintaining complex systems. To trigger dedicated research on these open\npoints, we discuss the history of automation in MDE and present perspectives on\nhow automation in MDE can be further improved and which obstacles have to be\novercome in the medium and long term perspective.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Lola Burgueño",
            "Davide Di Ruscio",
            "Houari Sahraoui",
            "Manuel Wimmer"
        ],
        "published": "2024-05-28T19:14:16Z"
    },
    {
        "title": "Augmented Conversation with Embedded Speech-Driven On-the-Fly\n  Referencing in AR",
        "link": "http://arxiv.org/abs/2405.18537v1",
        "abstract": "This paper introduces the concept of augmented conversation, which aims to\nsupport co-located in-person conversations via embedded speech-driven\non-the-fly referencing in augmented reality (AR). Today computing technologies\nlike smartphones allow quick access to a variety of references during the\nconversation. However, these tools often create distractions, reducing eye\ncontact and forcing users to focus their attention on phone screens and\nmanually enter keywords to access relevant information. In contrast, AR-based\non-the-fly referencing provides relevant visual references in real-time, based\non keywords extracted automatically from the spoken conversation. By embedding\nthese visual references in AR around the conversation partner, augmented\nconversation reduces distraction and friction, allowing users to maintain eye\ncontact and supporting more natural social interactions. To demonstrate this\nconcept, we developed \\system, a Hololens-based interface that leverages\nreal-time speech recognition, natural language processing and gaze-based\ninteractions for on-the-fly embedded visual referencing. In this paper, we\nexplore the design space of visual referencing for conversations, and describe\nour our implementation -- building on seven design guidelines identified\nthrough a user-centered design process. An initial user study confirms that our\nsystem decreases distraction and friction in conversations compared to\nsmartphone searches, while providing highly useful and relevant information.",
        "subjects": [
            "cs.HC",
            "cs.LG"
        ],
        "authors": [
            "Shivesh Jadon",
            "Mehrad Faridan",
            "Edward Mah",
            "Rajan Vaish",
            "Wesley Willett",
            "Ryo Suzuki"
        ],
        "published": "2024-05-28T19:10:47Z"
    },
    {
        "title": "Data-Driven Simulator for Mechanical Circulatory Support with Domain\n  Adversarial Neural Process",
        "link": "http://arxiv.org/abs/2405.18536v1",
        "abstract": "Mechanical Circulatory Support (MCS) devices, implemented as a probabilistic\ndeep sequence model. Existing mechanical simulators for MCS rely on\noversimplifying assumptions and are insensitive to patient-specific behavior,\nlimiting their applicability to real-world treatment scenarios. To address\nthese shortcomings, our model Domain Adversarial Neural Process (DANP) employs\na neural process architecture, allowing it to capture the probabilistic\nrelationship between MCS pump levels and aortic pressure measurements with\nuncertainty. We use domain adversarial training to combine simulation data with\nreal-world observations, resulting in a more realistic and diverse\nrepresentation of potential outcomes. Empirical results with an improvement of\n19% in non-stationary trend prediction establish DANP as an effective tool for\nclinicians to understand and make informed decisions regarding MCS patient\ntreatment.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Sophia Sun",
            "Wenyuan Chen",
            "Zihao Zhou",
            "Sonia Fereidooni",
            "Elise Jortberg",
            "Rose Yu"
        ],
        "published": "2024-05-28T19:07:12Z"
    },
    {
        "title": "Individualized Privacy Accounting via Subsampling with Applications in\n  Combinatorial Optimization",
        "link": "http://arxiv.org/abs/2405.18534v1",
        "abstract": "In this work, we give a new technique for analyzing individualized privacy\naccounting via the following simple observation: if an algorithm is one-sided\nadd-DP, then its subsampled variant satisfies two-sided DP. From this, we\nobtain several improved algorithms for private combinatorial optimization\nproblems, including decomposable submodular maximization and set cover. Our\nerror guarantees are asymptotically tight and our algorithm satisfies pure-DP\nwhile previously known algorithms (Gupta et al., 2010; Chaturvedi et al., 2021)\nare approximate-DP. We also show an application of our technique beyond\ncombinatorial optimization by giving a pure-DP algorithm for the shifting heavy\nhitter problem in a stream; previously, only an approximateDP algorithm was\nknown (Kaplan et al., 2021; Cohen & Lyu, 2023).",
        "subjects": [
            "cs.DS",
            "cs.CR"
        ],
        "authors": [
            "Badih Ghazi",
            "Pritish Kamath",
            "Ravi Kumar",
            "Pasin Manurangsi",
            "Adam Sealfon"
        ],
        "published": "2024-05-28T19:02:30Z"
    },
    {
        "title": "Cardiovascular Disease Detection from Multi-View Chest X-rays with\n  BI-Mamba",
        "link": "http://arxiv.org/abs/2405.18533v1",
        "abstract": "Accurate prediction of Cardiovascular disease (CVD) risk in medical imaging\nis central to effective patient health management. Previous studies have\ndemonstrated that imaging features in computed tomography (CT) can help predict\nCVD risk. However, CT entails notable radiation exposure, which may result in\nadverse health effects for patients. In contrast, chest X-ray emits\nsignificantly lower levels of radiation, offering a safer option. This\nrationale motivates our investigation into the feasibility of using chest X-ray\nfor predicting CVD risk. Convolutional Neural Networks (CNNs) and Transformers\nare two established network architectures for computer-aided diagnosis.\nHowever, they struggle to model very high resolution chest X-ray due to the\nlack of large context modeling power or quadratic time complexity. Inspired by\nstate space sequence models (SSMs), a new class of network architectures with\ncompetitive sequence modeling power as Transfomers and linear time complexity,\nwe propose Bidirectional Image Mamba (BI-Mamba) to complement the\nunidirectional SSMs with opposite directional information. BI-Mamba utilizes\nparallel forward and backwark blocks to encode longe-range dependencies of\nmulti-view chest X-rays. We conduct extensive experiments on images from 10,395\nsubjects in National Lung Screening Trail (NLST). Results show that BI-Mamba\noutperforms ResNet-50 and ViT-S with comparable parameter size, and saves\nsignificant amount of GPU memory during training. Besides, BI-Mamba achieves\npromising performance compared with previous state of the art in CT, unraveling\nthe potential of chest X-ray for CVD risk prediction.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Zefan Yang",
            "Jiajin Zhang",
            "Ge Wang",
            "Mannudeep K. Kalra",
            "Pingkun Yan"
        ],
        "published": "2024-05-28T18:56:39Z"
    },
    {
        "title": "Task-Driven Uncertainty Quantification in Inverse Problems via Conformal\n  Prediction",
        "link": "http://arxiv.org/abs/2405.18527v1",
        "abstract": "In imaging inverse problems, one seeks to recover an image from\nmissing/corrupted measurements. Because such problems are ill-posed, there is\ngreat motivation to quantify the uncertainty induced by the\nmeasurement-and-recovery process. Motivated by applications where the recovered\nimage is used for a downstream task, such as soft-output classification, we\npropose a task-centered approach to uncertainty quantification. In particular,\nwe use conformal prediction to construct an interval that is guaranteed to\ncontain the task output from the true image up to a user-specified probability,\nand we use the width of that interval to quantify the uncertainty contributed\nby measurement-and-recovery. For posterior-sampling-based image recovery, we\nconstruct locally adaptive prediction intervals. Furthermore, we propose to\ncollect measurements over multiple rounds, stopping as soon as the task\nuncertainty falls below an acceptable level. We demonstrate our methodology on\naccelerated magnetic resonance imaging (MRI).",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Jeffrey Wen",
            "Rizwan Ahmad",
            "Philip Schniter"
        ],
        "published": "2024-05-28T18:49:17Z"
    },
    {
        "title": "Unlocking the Potential of Renewable Energy Through Curtailment\n  Prediction",
        "link": "http://arxiv.org/abs/2405.18526v1",
        "abstract": "A significant fraction (5-15%) of renewable energy generated goes into waste\nin the grids around the world today due to oversupply issues and transmission\nconstraints. Being able to predict when and where renewable curtailment occurs\nwould improve renewable utilization. The core of this work is to enable the\nmachine learning community to help decarbonize electricity grids by unlocking\nthe potential of renewable energy through curtailment prediction.",
        "subjects": [
            "eess.SY",
            "cs.SY",
            "physics.soc-ph"
        ],
        "authors": [
            "Bilge Acun",
            "Brent Morgan",
            "Henry Richardson",
            "Nat Steinsultz",
            "Carole-Jean Wu"
        ],
        "published": "2024-05-28T18:48:39Z"
    },
    {
        "title": "REPARO: Compositional 3D Assets Generation with Differentiable 3D Layout\n  Alignment",
        "link": "http://arxiv.org/abs/2405.18525v1",
        "abstract": "Traditional image-to-3D models often struggle with scenes containing multiple\nobjects due to biases and occlusion complexities. To address this challenge, we\npresent REPARO, a novel approach for compositional 3D asset generation from\nsingle images. REPARO employs a two-step process: first, it extracts individual\nobjects from the scene and reconstructs their 3D meshes using off-the-shelf\nimage-to-3D models; then, it optimizes the layout of these meshes through\ndifferentiable rendering techniques, ensuring coherent scene composition. By\nintegrating optimal transport-based long-range appearance loss term and\nhigh-level semantic loss term in the differentiable rendering, REPARO can\neffectively recover the layout of 3D assets. The proposed method can\nsignificantly enhance object independence, detail accuracy, and overall scene\ncoherence. Extensive evaluation of multi-object scenes demonstrates that our\nREPARO offers a comprehensive approach to address the complexities of\nmulti-object 3D scene generation from single images.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Haonan Han",
            "Rui Yang",
            "Huan Liao",
            "Jiankai Xing",
            "Zunnan Xu",
            "Xiaoming Yu",
            "Junwei Zha",
            "Xiu Li",
            "Wanhua Li"
        ],
        "published": "2024-05-28T18:45:10Z"
    },
    {
        "title": "Aligning in a Compact Space: Contrastive Knowledge Distillation between\n  Heterogeneous Architectures",
        "link": "http://arxiv.org/abs/2405.18524v1",
        "abstract": "Knowledge distillation is commonly employed to compress neural networks,\nreducing the inference costs and memory footprint. In the scenario of\nhomogenous architecture, feature-based methods have been widely validated for\ntheir effectiveness. However, in scenarios where the teacher and student models\nare of heterogeneous architectures, the inherent differences in feature\nrepresentation significantly degrade the performance of these methods. Recent\nstudies have highlighted that low-frequency components constitute the majority\nof image features. Motivated by this, we propose a Low-Frequency\nComponents-based Contrastive Knowledge Distillation (LFCC) framework that\nsignificantly enhances the performance of feature-based distillation between\nheterogeneous architectures. Specifically, we designe a set of multi-scale\nlow-pass filters to extract the low-frequency components of intermediate\nfeatures from both the teacher and student models, aligning them in a compact\nspace to overcome architectural disparities. Moreover, leveraging the intrinsic\npairing characteristic of the teacher-student framework, we design an\ninnovative sample-level contrastive learning framework that adeptly\nrestructures the constraints of within-sample feature similarity and\nbetween-sample feature divergence into a contrastive learning task. This\nstrategy enables the student model to capitalize on intra-sample feature\ncongruence while simultaneously enhancing the discrimination of features among\ndisparate samples. Consequently, our LFCC framework accurately captures the\ncommonalities in feature representation across heterogeneous architectures.\nExtensive evaluations and empirical analyses across three architectures (CNNs,\nTransformers, and MLPs) demonstrate that LFCC achieves superior performance on\nthe challenging benchmarks of ImageNet-1K and CIFAR-100. All codes will be\npublicly available.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hongjun Wu",
            "Li Xiao",
            "Xingkuo Zhang",
            "Yining Miao"
        ],
        "published": "2024-05-28T18:44:42Z"
    },
    {
        "title": "TripletMix: Triplet Data Augmentation for 3D Understanding",
        "link": "http://arxiv.org/abs/2405.18523v1",
        "abstract": "Data augmentation has proven to be a vital tool for enhancing the\ngeneralization capabilities of deep learning models, especially in the context\nof 3D vision where traditional datasets are often limited. Despite previous\nadvancements, existing methods primarily cater to unimodal data scenarios,\nleaving a gap in the augmentation of multimodal triplet data, which integrates\ntext, images, and point clouds. Simultaneously augmenting all three modalities\nenhances diversity and improves alignment across modalities, resulting in more\ncomprehensive and robust 3D representations. To address this gap, we propose\nTripletMix, a novel approach to address the previously unexplored issue of\nmultimodal data augmentation in 3D understanding. TripletMix innovatively\napplies the principles of mixed-based augmentation to multimodal triplet data,\nallowing for the preservation and optimization of cross-modal connections. Our\nproposed TripletMix combines feature-level and input-level augmentations to\nachieve dual enhancement between raw data and latent features, significantly\nimproving the model's cross-modal understanding and generalization capabilities\nby ensuring feature consistency and providing diverse and realistic training\nsamples. We demonstrate that TripletMix not only improves the baseline\nperformance of models in various learning scenarios including zero-shot and\nlinear probing classification but also significantly enhances model\ngeneralizability. Notably, we improved the zero-shot classification accuracy on\nScanObjectNN from 51.3 percent to 61.9 percent, and on Objaverse-LVIS from 46.8\npercent to 51.4 percent. Our findings highlight the potential of multimodal\ndata augmentation to significantly advance 3D object recognition and\nunderstanding.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Jiaze Wang",
            "Yi Wang",
            "Ziyu Guo",
            "Renrui Zhang",
            "Donghao Zhou",
            "Guangyong Chen",
            "Anfeng Liu",
            "Pheng-Ann Heng"
        ],
        "published": "2024-05-28T18:44:15Z"
    },
    {
        "title": "Falsifiable Test Design in Coordination Games",
        "link": "http://arxiv.org/abs/2405.18521v1",
        "abstract": "A principal can propose a project to an agent, who then decides whether to\naccept. Their payoffs from launching the project depend on an unknown binary\nstate. The principal can obtain more precise information about the state\nthrough a test at no cost, but crucially, it is common knowledge that she can\nfalsify the test result. In the most interesting case where players have\nconflicted interests, the optimal test is a binary lemon-detecting test. We\nalso find that coordination is possible when the principal is pessimistic but\nnot when the agent is pessimistic. Moreover, when the agent has private\ninformation about the state, a single binary lemon-detecting test remains\noptimal even though the principal has the option to screen the agent by\nproviding a menu of tests. Our finding is consistent with observed tests in\nreal practice.",
        "subjects": [
            "econ.TH",
            "cs.GT"
        ],
        "authors": [
            "Yingkai Li",
            "Boli Xu"
        ],
        "published": "2024-05-28T18:39:54Z"
    },
    {
        "title": "Offline-Boosted Actor-Critic: Adaptively Blending Optimal Historical\n  Behaviors in Deep Off-Policy RL",
        "link": "http://arxiv.org/abs/2405.18520v1",
        "abstract": "Off-policy reinforcement learning (RL) has achieved notable success in\ntackling many complex real-world tasks, by leveraging previously collected data\nfor policy learning. However, most existing off-policy RL algorithms fail to\nmaximally exploit the information in the replay buffer, limiting sample\nefficiency and policy performance. In this work, we discover that concurrently\ntraining an offline RL policy based on the shared online replay buffer can\nsometimes outperform the original online learning policy, though the occurrence\nof such performance gains remains uncertain. This motivates a new possibility\nof harnessing the emergent outperforming offline optimal policy to improve\nonline policy learning. Based on this insight, we present Offline-Boosted\nActor-Critic (OBAC), a model-free online RL framework that elegantly identifies\nthe outperforming offline policy through value comparison, and uses it as an\nadaptive constraint to guarantee stronger policy learning performance. Our\nexperiments demonstrate that OBAC outperforms other popular model-free RL\nbaselines and rivals advanced model-based RL methods in terms of sample\nefficiency and asymptotic performance across 53 tasks spanning 6 task suites.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Yu Luo",
            "Tianying Ji",
            "Fuchun Sun",
            "Jianwei Zhang",
            "Huazhe Xu",
            "Xianyuan Zhan"
        ],
        "published": "2024-05-28T18:38:46Z"
    },
    {
        "title": "LSTM-COX Model: A Concise and Efficient Deep Learning Approach for\n  Handling Recurrent Events",
        "link": "http://arxiv.org/abs/2405.18518v1",
        "abstract": "In the current field of clinical medicine, traditional methods for analyzing\nrecurrent events have limitations when dealing with complex time-dependent\ndata. This study combines Long Short-Term Memory networks (LSTM) with the Cox\nmodel to enhance the model's performance in analyzing recurrent events with\ndynamic temporal information. Compared to classical models, the LSTM-Cox model\nsignificantly improves the accuracy of extracting clinical risk features and\nexhibits lower Akaike Information Criterion (AIC) values, while maintaining\ngood performance on simulated datasets. In an empirical analysis of bladder\ncancer recurrence data, the model successfully reduced the mean squared error\nduring the training phase and achieved a Concordance index of up to 0.90 on the\ntest set. Furthermore, the model effectively distinguished between high and\nlow-risk patient groups, and the identified recurrence risk features such as\nthe number of tumor recurrences and maximum size were consistent with other\nresearch and clinical trial results. This study not only provides a\nstraightforward and efficient method for analyzing recurrent data and\nextracting features but also offers a convenient pathway for integrating deep\nlearning techniques into clinical risk prediction systems.",
        "subjects": [
            "cs.LG",
            "stat.ME",
            "stat.ML"
        ],
        "authors": [
            "Zhang Runquan",
            "Shi Xiaoping"
        ],
        "published": "2024-05-28T18:38:15Z"
    },
    {
        "title": "Atlas3D: Physically Constrained Self-Supporting Text-to-3D for\n  Simulation and Fabrication",
        "link": "http://arxiv.org/abs/2405.18515v1",
        "abstract": "Existing diffusion-based text-to-3D generation methods primarily focus on\nproducing visually realistic shapes and appearances, often neglecting the\nphysical constraints necessary for downstream tasks. Generated models\nfrequently fail to maintain balance when placed in physics-based simulations or\n3D printed. This balance is crucial for satisfying user design intentions in\ninteractive gaming, embodied AI, and robotics, where stable models are needed\nfor reliable interaction. Additionally, stable models ensure that 3D-printed\nobjects, such as figurines for home decoration, can stand on their own without\nrequiring additional supports. To fill this gap, we introduce Atlas3D, an\nautomatic and easy-to-implement method that enhances existing Score\nDistillation Sampling (SDS)-based text-to-3D tools. Atlas3D ensures the\ngeneration of self-supporting 3D models that adhere to physical laws of\nstability under gravity, contact, and friction. Our approach combines a novel\ndifferentiable simulation-based loss function with physically inspired\nregularization, serving as either a refinement or a post-processing module for\nexisting frameworks. We verify Atlas3D's efficacy through extensive generation\ntasks and validate the resulting 3D models in both simulated and real-world\nenvironments.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yunuo Chen",
            "Tianyi Xie",
            "Zeshun Zong",
            "Xuan Li",
            "Feng Gao",
            "Yin Yang",
            "Ying Nian Wu",
            "Chenfanfu Jiang"
        ],
        "published": "2024-05-28T18:33:18Z"
    },
    {
        "title": "Understanding Transformer Reasoning Capabilities via Graph Algorithms",
        "link": "http://arxiv.org/abs/2405.18512v1",
        "abstract": "Which transformer scaling regimes are able to perfectly solve different\nclasses of algorithmic problems? While tremendous empirical advances have been\nattained by transformer-based neural networks, a theoretical understanding of\ntheir algorithmic reasoning capabilities in realistic parameter regimes is\nlacking. We investigate this question in terms of the network's depth, width,\nand number of extra tokens for algorithm execution. Our novel representational\nhierarchy separates 9 algorithmic reasoning problems into classes solvable by\ntransformers in different realistic parameter scaling regimes. We prove that\nlogarithmic depth is necessary and sufficient for tasks like graph\nconnectivity, while single-layer transformers with small embedding dimensions\ncan solve contextual retrieval tasks. We also support our theoretical analysis\nwith ample empirical evidence using the GraphQA benchmark. These results show\nthat transformers excel at many graph reasoning tasks, even outperforming\nspecialized graph neural networks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Clayton Sanford",
            "Bahare Fatemi",
            "Ethan Hall",
            "Anton Tsitsulin",
            "Mehran Kazemi",
            "Jonathan Halcrow",
            "Bryan Perozzi",
            "Vahab Mirrokni"
        ],
        "published": "2024-05-28T18:31:14Z"
    },
    {
        "title": "Feasibility and benefits of joint learning from MRI databases with\n  different brain diseases and modalities for segmentation",
        "link": "http://arxiv.org/abs/2405.18511v1",
        "abstract": "Models for segmentation of brain lesions in multi-modal MRI are commonly\ntrained for a specific pathology using a single database with a predefined set\nof MRI modalities, determined by a protocol for the specific disease. This work\nexplores the following open questions: Is it feasible to train a model using\nmultiple databases that contain varying sets of MRI modalities and annotations\nfor different brain pathologies? Will this joint learning benefit performance\non the sets of modalities and pathologies available during training? Will it\nenable analysis of new databases with different sets of modalities and\npathologies? We develop and compare different methods and show that promising\nresults can be achieved with appropriate, simple and practical alterations to\nthe model and training framework. We experiment with 7 databases containing 5\ntypes of brain pathologies and different sets of MRI modalities. Results\ndemonstrate, for the first time, that joint training on multi-modal MRI\ndatabases with different brain pathologies and sets of modalities is feasible\nand offers practical benefits. It enables a single model to segment pathologies\nencountered during training in diverse sets of modalities, while facilitating\nsegmentation of new types of pathologies such as via follow-up fine-tuning. The\ninsights this study provides into the potential and limitations of this\nparadigm should prove useful for guiding future advances in the direction. Code\nand pretrained models: https://github.com/WenTXuL/MultiUnet",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Wentian Xu",
            "Matthew Moffat",
            "Thalia Seale",
            "Ziyun Liang",
            "Felix Wagner",
            "Daniel Whitehouse",
            "David Menon",
            "Virginia Newcombe",
            "Natalie Voets",
            "Abhirup Banerjee",
            "Konstantinos Kamnitsas"
        ],
        "published": "2024-05-28T18:28:10Z"
    },
    {
        "title": "Improved Emotional Alignment of AI and Humans: Human Ratings of Emotions\n  Expressed by Stable Diffusion v1, DALL-E 2, and DALL-E 3",
        "link": "http://arxiv.org/abs/2405.18510v1",
        "abstract": "Generative AI systems are increasingly capable of expressing emotions via\ntext and imagery. Effective emotional expression will likely play a major role\nin the efficacy of AI systems -- particularly those designed to support human\nmental health and wellbeing. This motivates our present research to better\nunderstand the alignment of AI expressed emotions with the human perception of\nemotions. When AI tries to express a particular emotion, how might we assess\nwhether they are successful? To answer this question, we designed a survey to\nmeasure the alignment between emotions expressed by generative AI and human\nperceptions. Three generative image models (DALL-E 2, DALL-E 3 and Stable\nDiffusion v1) were used to generate 240 examples of images, each of which was\nbased on a prompt designed to express five positive and five negative emotions\nacross both humans and robots. 24 participants recruited from the Prolific\nwebsite rated the alignment of AI-generated emotional expressions with a text\nprompt used to generate the emotion (i.e., \"A robot expressing the emotion\namusement\"). The results of our evaluation suggest that generative AI models\nare indeed capable of producing emotional expressions that are well-aligned\nwith a range of human emotions; however, we show that the alignment\nsignificantly depends upon the AI model used and the emotion itself. We analyze\nvariations in the performance of these systems to identify gaps for future\nimprovement. We conclude with a discussion of the implications for future AI\nsystems designed to support mental health and wellbeing.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "James Derek Lomas",
            "Willem van der Maden",
            "Sohhom Bandyopadhyay",
            "Giovanni Lion",
            "Nirmal Patel",
            "Gyanesh Jain",
            "Yanna Litowsky",
            "Haian Xue",
            "Pieter Desmet"
        ],
        "published": "2024-05-28T18:26:57Z"
    },
    {
        "title": "Injecting Hierarchical Biological Priors into Graph Neural Networks for\n  Flow Cytometry Prediction",
        "link": "http://arxiv.org/abs/2405.18507v1",
        "abstract": "In the complex landscape of hematologic samples such as peripheral blood or\nbone marrow derived from flow cytometry (FC) data, cell-level prediction\npresents profound challenges. This work explores injecting hierarchical prior\nknowledge into graph neural networks (GNNs) for single-cell multi-class\nclassification of tabular cellular data. By representing the data as graphs and\nencoding hierarchical relationships between classes, we propose our\nhierarchical plug-in method to be applied to several GNN models, namely,\nFCHC-GNN, and effectively designed to capture neighborhood information crucial\nfor single-cell FC domain. Extensive experiments on our cohort of 19 distinct\npatients, demonstrate that incorporating hierarchical biological constraints\nboosts performance significantly across multiple metrics compared to baseline\nGNNs without such priors. The proposed approach highlights the importance of\nstructured inductive biases for gaining improved generalization in complex\nbiological prediction tasks.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.QM"
        ],
        "authors": [
            "Fatemeh Nassajian Mojarrad",
            "Lorenzo Bini",
            "Thomas Matthes",
            "Stéphane Marchand-Maillet"
        ],
        "published": "2024-05-28T18:24:16Z"
    },
    {
        "title": "An Algorithm for the Decomposition of Complete Graph into Minimum Number\n  of Edge-disjoint Trees",
        "link": "http://arxiv.org/abs/2405.18506v1",
        "abstract": "In this work, we study methodical decomposition of an undirected, unweighted\ncomplete graph ($K_n$ of order $n$, size $m$) into minimum number of\nedge-disjoint trees. We find that $x$, a positive integer, is minimum and\n$x=\\lceil\\frac{n}{2}\\rceil$ as the edge set of $K_n$ is decomposed into\nedge-disjoint trees of size sequence $M = \\{m_1,m_2,...,m_x\\}$ where\n$m_i\\le(n-1)$ and $\\Sigma_{i=1}^{x} m_i$ = $\\frac{n(n-1)}{2}$. For decomposing\nthe edge set of $K_n$ into minimum number of edge-disjoint trees, our proposed\nalgorithm takes total $O(m)$ time.",
        "subjects": [
            "cs.DM"
        ],
        "authors": [
            "Antika Sinha",
            "Sanjoy Kumar Saha",
            "Partha Basuchowdhuri"
        ],
        "published": "2024-05-28T18:23:46Z"
    },
    {
        "title": "SoundCTM: Uniting Score-based and Consistency Models for Text-to-Sound\n  Generation",
        "link": "http://arxiv.org/abs/2405.18503v1",
        "abstract": "Sound content is an indispensable element for multimedia works such as video\ngames, music, and films. Recent high-quality diffusion-based sound generation\nmodels can serve as valuable tools for the creators. However, despite producing\nhigh-quality sounds, these models often suffer from slow inference speeds. This\ndrawback burdens creators, who typically refine their sounds through trial and\nerror to align them with their artistic intentions. To address this issue, we\nintroduce Sound Consistency Trajectory Models (SoundCTM). Our model enables\nflexible transitioning between high-quality 1-step sound generation and\nsuperior sound quality through multi-step generation. This allows creators to\ninitially control sounds with 1-step samples before refining them through\nmulti-step generation. While CTM fundamentally achieves flexible 1-step and\nmulti-step generation, its impressive performance heavily depends on an\nadditional pretrained feature extractor and an adversarial loss, which are\nexpensive to train and not always available in other domains. Thus, we reframe\nCTM's training framework and introduce a novel feature distance by utilizing\nthe teacher's network for a distillation loss. Additionally, while distilling\nclassifier-free guided trajectories, we train conditional and unconditional\nstudent models simultaneously and interpolate between these models during\ninference. We also propose training-free controllable frameworks for SoundCTM,\nleveraging its flexible sampling capability. SoundCTM achieves both promising\n1-step and multi-step real-time sound generation without using any extra\noff-the-shelf networks. Furthermore, we demonstrate SoundCTM's capability of\ncontrollable sound generation in a training-free manner.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "authors": [
            "Koichi Saito",
            "Dongjun Kim",
            "Takashi Shibuya",
            "Chieh-Hsin Lai",
            "Zhi Zhong",
            "Yuhta Takida",
            "Yuki Mitsufuji"
        ],
        "published": "2024-05-28T18:14:52Z"
    },
    {
        "title": "Large Margin Discriminative Loss for Classification",
        "link": "http://arxiv.org/abs/2405.18499v1",
        "abstract": "In this paper, we introduce a novel discriminative loss function with large\nmargin in the context of Deep Learning. This loss boosts the discriminative\npower of neural nets, represented by intra-class compactness and inter-class\nseparability. On the one hand, the class compactness is ensured by close\ndistance of samples of the same class to each other. On the other hand, the\ninter-class separability is boosted by a margin loss that ensures the minimum\ndistance of each class to its closest boundary. All the terms in our loss have\nan explicit meaning, giving a direct view of the feature space obtained. We\nanalyze mathematically the relation between compactness and margin term, giving\na guideline about the impact of the hyper-parameters on the learned features.\nMoreover, we also analyze properties of the gradient of the loss with respect\nto the parameters of the neural net. Based on this, we design a strategy called\npartial momentum updating that enjoys simultaneously stability and consistency\nin training. Furthermore, we also investigate generalization errors to have\nbetter theoretical insights. Our loss function systematically boosts the test\naccuracy of models compared to the standard softmax loss in our experiments.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Hai-Vy Nguyen",
            "Fabrice Gamboa",
            "Sixin Zhang",
            "Reda Chhaibi",
            "Serge Gratton",
            "Thierry Giaccone"
        ],
        "published": "2024-05-28T18:10:45Z"
    },
    {
        "title": "The Unified Balance Theory of Second-Moment Exponential Scaling\n  Optimizers in Visual Tasks",
        "link": "http://arxiv.org/abs/2405.18498v1",
        "abstract": "We have identified a potential method for unifying first-order optimizers\nthrough the use of variable Second-Moment Exponential Scaling(SMES). We begin\nwith back propagation, addressing classic phenomena such as gradient vanishing\nand explosion, as well as issues related to dataset sparsity, and introduce the\ntheory of balance in optimization. Through this theory, we suggest that SGD and\nadaptive optimizers can be unified under a broader inference, employing\nvariable moving exponential scaling to achieve a balanced approach within a\ngeneralized formula for first-order optimizers. We conducted tests on some\nclassic datasets and networks to confirm the impact of different balance\ncoefficients on the overall training process.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Gongyue Zhang",
            "Honghai Liu"
        ],
        "published": "2024-05-28T18:09:22Z"
    },
    {
        "title": "Capacity Results for Non-Ergodic Multi-Modal Broadcast Channels with\n  Controllable Statistics",
        "link": "http://arxiv.org/abs/2405.18497v1",
        "abstract": "Movable antennas and reconfigurable intelligent surfaces enable a new\nparadigm in which channel statistics can be controlled and altered. Further,\nthe known trajectory and operation protocol of communication satellites results\nin networks with predictable statistics. The predictability of future changes\nresults in a non-ergodic model for which the fundamentals are largely unknown.\nWe consider the canonical two-user broadcast erasure channel in which channel\nstatistics vary at a priori known points. We consider a multi-modal setting\nwith two non-transient modes (whose lengths scale linearly with the\nblocklength) and an arbitrary number of transient modes. We provide a new set\nof outer-bounds on the capacity region of this problem when the encoder has\naccess to causal ACK/NACK feedback. The outer-bounds reveal the significant\nrole of the non-transient mode with higher erasure probability both on the\nouter and the inner bounds. We show the outer-bounds are achievable in\nnon-trivial regimes, characterizing the capacity region for a wide range of\nparameters. We also discuss the regimes where the inner and outer bounds\ndiverge and analyze the gap between the two. A key finding of this work is the\nsignificant gain of inter-modal coding over the separate treating of individual\nmodes.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Alireza Vahid",
            "Shih-Chun Lin"
        ],
        "published": "2024-05-28T18:08:34Z"
    },
    {
        "title": "LLMs and Memorization: On Quality and Specificity of Copyright\n  Compliance",
        "link": "http://arxiv.org/abs/2405.18492v1",
        "abstract": "Memorization in large language models (LLMs) is a growing concern. LLMs have\nbeen shown to easily reproduce parts of their training data, including\ncopyrighted work. This is an important problem to solve, as it may violate\nexisting copyright laws as well as the European AI Act. In this work, we\npropose a systematic analysis to quantify the extent of potential copyright\ninfringements in LLMs using European law as an example. Unlike previous work,\nwe evaluate instruction-finetuned models in a realistic end-user scenario. Our\nanalysis builds on a proposed threshold of 160 characters, which we borrow from\nthe German Copyright Service Provider Act and a fuzzy text matching algorithm\nto identify potentially copyright-infringing textual reproductions. The\nspecificity of countermeasures against copyright infringement is analyzed by\ncomparing model behavior on copyrighted and public domain data. We investigate\nwhat behaviors models show instead of producing protected text (such as refusal\nor hallucination) and provide a first legal assessment of these behaviors. We\nfind that there are huge differences in copyright compliance, specificity, and\nappropriate refusal among popular LLMs. Alpaca, GPT 4, GPT 3.5, and Luminous\nperform best in our comparison, with OpenGPT-X, Alpaca, and Luminous producing\na particularly low absolute number of potential copyright violations. Code will\nbe published soon.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "I.2.7"
        ],
        "authors": [
            "Felix B Mueller",
            "Rebekka Görge",
            "Anna K Bernzen",
            "Janna C Pirk",
            "Maximilian Poretschkin"
        ],
        "published": "2024-05-28T18:01:52Z"
    },
    {
        "title": "Predicting Ground State Properties: Constant Sample Complexity and Deep\n  Learning Algorithms",
        "link": "http://arxiv.org/abs/2405.18489v1",
        "abstract": "A fundamental problem in quantum many-body physics is that of finding ground\nstates of local Hamiltonians. A number of recent works gave provably efficient\nmachine learning (ML) algorithms for learning ground states. Specifically,\n[Huang et al. Science 2022], introduced an approach for learning properties of\nthe ground state of an $n$-qubit gapped local Hamiltonian $H$ from only\n$n^{\\mathcal{O}(1)}$ data points sampled from Hamiltonians in the same phase of\nmatter. This was subsequently improved by [Lewis et al. Nature Communications\n2024], to $\\mathcal{O}(\\log n)$ samples when the geometry of the $n$-qubit\nsystem is known. In this work, we introduce two approaches that achieve a\nconstant sample complexity, independent of system size $n$, for learning ground\nstate properties. Our first algorithm consists of a simple modification of the\nML model used by Lewis et al. and applies to a property of interest known\nbeforehand. Our second algorithm, which applies even if a description of the\nproperty is not known, is a deep neural network model. While empirical results\nshowing the performance of neural networks have been demonstrated, to our\nknowledge, this is the first rigorous sample complexity bound on a neural\nnetwork model for predicting ground state properties. We also perform numerical\nexperiments that confirm the improved scaling of our approach compared to\nearlier results.",
        "subjects": [
            "quant-ph",
            "cs.LG",
            "physics.comp-ph"
        ],
        "authors": [
            "Marc Wanner",
            "Laura Lewis",
            "Chiranjib Bhattacharyya",
            "Devdatt Dubhashi",
            "Alexandru Gheorghiu"
        ],
        "published": "2024-05-28T18:00:32Z"
    },
    {
        "title": "Anomaly detection for the identification of volcanic unrest in satellite\n  imagery",
        "link": "http://arxiv.org/abs/2405.18487v1",
        "abstract": "Satellite images have the potential to detect volcanic deformation prior to\neruptions, but while a vast number of images are routinely acquired, only a\nsmall percentage contain volcanic deformation events. Manual inspection could\nmiss these anomalies, and an automatic system modelled with supervised learning\nrequires suitably labelled datasets. To tackle these issues, this paper\nexplores the use of unsupervised deep learning on satellite data for the\npurpose of identifying volcanic deformation as anomalies. Our detector is based\non Patch Distribution Modeling (PaDiM), and the detection performance is\nenhanced with a weighted distance, assigning greater importance to features\nfrom deeper layers. Additionally, we propose a preprocessing approach to handle\nnoisy and incomplete data points. The final framework was tested with five\nvolcanoes, which have different deformation characteristics and its performance\nwas compared against the supervised learning method for volcanic deformation\ndetection.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Robert Gabriel Popescu",
            "Nantheera Anantrasirichai",
            "Juliet Biggs"
        ],
        "published": "2024-05-28T18:00:10Z"
    },
    {
        "title": "Towards Open Domain Text-Driven Synthesis of Multi-Person Motions",
        "link": "http://arxiv.org/abs/2405.18483v1",
        "abstract": "This work aims to generate natural and diverse group motions of multiple\nhumans from textual descriptions. While single-person text-to-motion generation\nis extensively studied, it remains challenging to synthesize motions for more\nthan one or two subjects from in-the-wild prompts, mainly due to the lack of\navailable datasets. In this work, we curate human pose and motion datasets by\nestimating pose information from large-scale image and video datasets. Our\nmodels use a transformer-based diffusion framework that accommodates multiple\ndatasets with any number of subjects or frames. Experiments explore both\ngeneration of multi-person static poses and generation of multi-person motion\nsequences. To our knowledge, our method is the first to generate multi-subject\nmotion sequences with high diversity and fidelity from a large variety of\ntextual prompts.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Mengyi Shan",
            "Lu Dong",
            "Yutao Han",
            "Yuan Yao",
            "Tao Liu",
            "Ifeoma Nwogu",
            "Guo-Jun Qi",
            "Mitch Hill"
        ],
        "published": "2024-05-28T18:00:06Z"
    },
    {
        "title": "Symbolic Regression for Beyond the Standard Model Physics",
        "link": "http://arxiv.org/abs/2405.18471v1",
        "abstract": "We propose symbolic regression as a powerful tool for studying Beyond the\nStandard Model physics. As a benchmark model, we consider the so-called\nConstrained Minimal Supersymmetric Standard Model, which has a four-dimensional\nparameter space defined at the GUT scale. We provide a set of analytical\nexpressions that reproduce three low-energy observables of interest in terms of\nthe parameters of the theory: the Higgs mass, the contribution to the anomalous\nmagnetic moment of the muon, and the cold dark matter relic density. To\ndemonstrate the power of the approach, we employ the symbolic expressions in a\nglobal fits analysis to derive the posterior probability densities of the\nparameters, which are obtained extremely rapidly in comparison with\nconventional methods.",
        "subjects": [
            "hep-ph",
            "cs.AI",
            "cs.LG",
            "hep-th",
            "physics.comp-ph"
        ],
        "authors": [
            "Shehu AbdusSalam",
            "Steve Abel",
            "Miguel Crispim Romao"
        ],
        "published": "2024-05-28T18:00:01Z"
    },
    {
        "title": "Notes on Applicability of GPT-4 to Document Understanding",
        "link": "http://arxiv.org/abs/2405.18433v1",
        "abstract": "We perform a missing, reproducible evaluation of all publicly available GPT-4\nfamily models concerning the Document Understanding field, where it is\nfrequently required to comprehend text spacial arrangement and visual clues in\naddition to textual semantics. Benchmark results indicate that though it is\nhard to achieve satisfactory results with text-only models, GPT-4 Vision Turbo\nperforms well when one provides both text recognized by an external OCR engine\nand document images on the input. Evaluation is followed by analyses that\nsuggest possible contamination of textual GPT-4 models and indicate the\nsignificant performance drop for lengthy documents.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Łukasz Borchmann"
        ],
        "published": "2024-05-28T17:59:53Z"
    },
    {
        "title": "On the Origin of Llamas: Model Tree Heritage Recovery",
        "link": "http://arxiv.org/abs/2405.18432v1",
        "abstract": "The rapid growth of neural network models shared on the internet has made\nmodel weights an important data modality. However, this information is\nunderutilized as the weights are uninterpretable, and publicly available models\nare disorganized. Inspired by Darwin's tree of life, we define the Model Tree\nwhich describes the origin of models i.e., the parent model that was used to\nfine-tune the target model. Similarly to the natural world, the tree structure\nis unknown. In this paper, we introduce the task of Model Tree Heritage\nRecovery (MoTHer Recovery) for discovering Model Trees in the ever-growing\nuniverse of neural networks. Our hypothesis is that model weights encode this\ninformation, the challenge is to decode the underlying tree structure given the\nweights. Beyond the immediate application of model authorship attribution,\nMoTHer recovery holds exciting long-term applications akin to indexing the\ninternet by search engines. Practically, for each pair of models, this task\nrequires: i) determining if they are related, and ii) establishing the\ndirection of the relationship. We find that certain distributional properties\nof the weights evolve monotonically during training, which enables us to\nclassify the relationship between two given models. MoTHer recovery\nreconstructs entire model hierarchies, represented by a directed tree, where a\nparent model gives rise to multiple child models through additional training.\nOur approach successfully reconstructs complex Model Trees, as well as the\nstructure of \"in-the-wild\" model families such as Llama 2 and Stable Diffusion.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Eliahu Horwitz",
            "Asaf Shul",
            "Yedid Hoshen"
        ],
        "published": "2024-05-28T17:59:51Z"
    },
    {
        "title": "Feasibility of Privacy-Preserving Entity Resolution on Confidential\n  Healthcare Datasets Using Homomorphic Encryption",
        "link": "http://arxiv.org/abs/2405.18430v1",
        "abstract": "Patient datasets contain confidential information which is protected by laws\nand regulations such as HIPAA and GDPR. Ensuring comprehensive patient\ninformation necessitates privacy-preserving entity resolution (PPER), which\nidentifies identical patient entities across multiple databases from different\nhealthcare organizations while maintaining data privacy. Existing methods often\nlack cryptographic security or are computationally impractical for real-world\ndatasets. We introduce a PPER pipeline based on AMPPERE, a secure abstract\ncomputation model utilizing cryptographic tools like homomorphic encryption.\nOur tailored approach incorporates extensive parallelization techniques and\noptimal parameters specifically for patient datasets. Experimental results\ndemonstrate the proposed method's effectiveness in terms of accuracy and\nefficiency compared to various baselines.",
        "subjects": [
            "cs.CE"
        ],
        "authors": [
            "Yixiang Yao",
            "Joseph Cecil",
            "Praveen Angyan",
            "Neil Bahroos",
            "Srivatsan Ravi"
        ],
        "published": "2024-05-28T17:59:42Z"
    },
    {
        "title": "DiG: Scalable and Efficient Diffusion Models with Gated Linear Attention",
        "link": "http://arxiv.org/abs/2405.18428v1",
        "abstract": "Diffusion models with large-scale pre-training have achieved significant\nsuccess in the field of visual content generation, particularly exemplified by\nDiffusion Transformers (DiT). However, DiT models have faced challenges with\nscalability and quadratic complexity efficiency. In this paper, we aim to\nleverage the long sequence modeling capability of Gated Linear Attention (GLA)\nTransformers, expanding its applicability to diffusion models. We introduce\nDiffusion Gated Linear Attention Transformers (DiG), a simple, adoptable\nsolution with minimal parameter overhead, following the DiT design, but\noffering superior efficiency and effectiveness. In addition to better\nperformance than DiT, DiG-S/2 exhibits $2.5\\times$ higher training speed than\nDiT-S/2 and saves $75.7\\%$ GPU memory at a resolution of $1792 \\times 1792$.\nMoreover, we analyze the scalability of DiG across a variety of computational\ncomplexity. DiG models, with increased depth/width or augmentation of input\ntokens, consistently exhibit decreasing FID. We further compare DiG with other\nsubquadratic-time diffusion models. With the same model size, DiG-XL/2 is\n$4.2\\times$ faster than the recent Mamba-based diffusion model at a $1024$\nresolution, and is $1.8\\times$ faster than DiT with CUDA-optimized\nFlashAttention-2 under the $2048$ resolution. All these results demonstrate its\nsuperior efficiency among the latest diffusion models. Code is released at\nhttps://github.com/hustvl/DiG.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Lianghui Zhu",
            "Zilong Huang",
            "Bencheng Liao",
            "Jun Hao Liew",
            "Hanshu Yan",
            "Jiashi Feng",
            "Xinggang Wang"
        ],
        "published": "2024-05-28T17:59:33Z"
    },
    {
        "title": "Classifying Overlapping Gaussian Mixtures in High Dimensions: From\n  Optimal Classifiers to Neural Nets",
        "link": "http://arxiv.org/abs/2405.18427v1",
        "abstract": "We derive closed-form expressions for the Bayes optimal decision boundaries\nin binary classification of high dimensional overlapping Gaussian mixture model\n(GMM) data, and show how they depend on the eigenstructure of the class\ncovariances, for particularly interesting structured data. We empirically\ndemonstrate, through experiments on synthetic GMMs inspired by real-world data,\nthat deep neural networks trained for classification, learn predictors which\napproximate the derived optimal classifiers. We further extend our study to\nnetworks trained on authentic data, observing that decision thresholds\ncorrelate with the covariance eigenvectors rather than the eigenvalues,\nmirroring our GMM analysis. This provides theoretical insights regarding neural\nnetworks' ability to perform probabilistic inference and distill statistical\npatterns from intricate distributions.",
        "subjects": [
            "stat.ML",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Khen Cohen",
            "Noam Levi",
            "Yaron Oz"
        ],
        "published": "2024-05-28T17:59:31Z"
    },
    {
        "title": "GFlow: Recovering 4D World from Monocular Video",
        "link": "http://arxiv.org/abs/2405.18426v1",
        "abstract": "Reconstructing 4D scenes from video inputs is a crucial yet challenging task.\nConventional methods usually rely on the assumptions of multi-view video\ninputs, known camera parameters, or static scenes, all of which are typically\nabsent under in-the-wild scenarios. In this paper, we relax all these\nconstraints and tackle a highly ambitious but practical task, which we termed\nas AnyV4D: we assume only one monocular video is available without any camera\nparameters as input, and we aim to recover the dynamic 4D world alongside the\ncamera poses. To this end, we introduce GFlow, a new framework that utilizes\nonly 2D priors (depth and optical flow) to lift a video (3D) to a 4D explicit\nrepresentation, entailing a flow of Gaussian splatting through space and time.\nGFlow first clusters the scene into still and moving parts, then applies a\nsequential optimization process that optimizes camera poses and the dynamics of\n3D Gaussian points based on 2D priors and scene clustering, ensuring fidelity\namong neighboring points and smooth movement across frames. Since dynamic\nscenes always introduce new content, we also propose a new pixel-wise\ndensification strategy for Gaussian points to integrate new visual content.\nMoreover, GFlow transcends the boundaries of mere 4D reconstruction; it also\nenables tracking of any points across frames without the need for prior\ntraining and segments moving objects from the scene in an unsupervised way.\nAdditionally, the camera poses of each frame can be derived from GFlow,\nallowing for rendering novel views of a video scene through changing camera\npose. By employing the explicit representation, we may readily conduct\nscene-level or object-level editing as desired, underscoring its versatility\nand power. Visit our project website at: https://littlepure2333.github.io/GFlow",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Shizun Wang",
            "Xingyi Yang",
            "Qiuhong Shen",
            "Zhenxiang Jiang",
            "Xinchao Wang"
        ],
        "published": "2024-05-28T17:59:22Z"
    },
    {
        "title": "ViG: Linear-complexity Visual Sequence Learning with Gated Linear\n  Attention",
        "link": "http://arxiv.org/abs/2405.18425v2",
        "abstract": "Recently, linear complexity sequence modeling networks have achieved modeling\ncapabilities similar to Vision Transformers on a variety of computer vision\ntasks, while using fewer FLOPs and less memory. However, their advantage in\nterms of actual runtime speed is not significant. To address this issue, we\nintroduce Gated Linear Attention (GLA) for vision, leveraging its superior\nhardware-awareness and efficiency. We propose direction-wise gating to capture\n1D global context through bidirectional modeling and a 2D gating locality\ninjection to adaptively inject 2D local details into 1D global context. Our\nhardware-aware implementation further merges forward and backward scanning into\na single kernel, enhancing parallelism and reducing memory cost and latency.\nThe proposed model, ViG, offers a favorable trade-off in accuracy, parameters,\nand FLOPs on ImageNet and downstream tasks, outperforming popular Transformer\nand CNN-based models. Notably, ViG-S matches DeiT-B's accuracy while using only\n27% of the parameters and 20% of the FLOPs, running 2$\\times$ faster on\n$224\\times224$ images. At $1024\\times1024$ resolution, ViG-T uses 5.2$\\times$\nfewer FLOPs, saves 90% GPU memory, runs 4.8$\\times$ faster, and achieves 20.7%\nhigher top-1 accuracy than DeiT-T. These results position ViG as an efficient\nand scalable solution for visual representation learning. Code is available at\n\\url{https://github.com/hustvl/ViG}.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Bencheng Liao",
            "Xinggang Wang",
            "Lianghui Zhu",
            "Qian Zhang",
            "Chang Huang"
        ],
        "published": "2024-05-28T17:59:21Z"
    },
    {
        "title": "3DitScene: Editing Any Scene via Language-guided Disentangled Gaussian\n  Splatting",
        "link": "http://arxiv.org/abs/2405.18424v1",
        "abstract": "Scene image editing is crucial for entertainment, photography, and\nadvertising design. Existing methods solely focus on either 2D individual\nobject or 3D global scene editing. This results in a lack of a unified approach\nto effectively control and manipulate scenes at the 3D level with different\nlevels of granularity. In this work, we propose 3DitScene, a novel and unified\nscene editing framework leveraging language-guided disentangled Gaussian\nSplatting that enables seamless editing from 2D to 3D, allowing precise control\nover scene composition and individual objects. We first incorporate 3D\nGaussians that are refined through generative priors and optimization\ntechniques. Language features from CLIP then introduce semantics into 3D\ngeometry for object disentanglement. With the disentangled Gaussians, 3DitScene\nallows for manipulation at both the global and individual levels,\nrevolutionizing creative expression and empowering control over scenes and\nobjects. Experimental results demonstrate the effectiveness and versatility of\n3DitScene in scene image editing. Code and online demo can be found at our\nproject homepage: https://zqh0253.github.io/3DitScene/.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Qihang Zhang",
            "Yinghao Xu",
            "Chaoyang Wang",
            "Hsin-Ying Lee",
            "Gordon Wetzstein",
            "Bolei Zhou",
            "Ceyuan Yang"
        ],
        "published": "2024-05-28T17:59:01Z"
    },
    {
        "title": "Bifurcations in Latch-Mediated Spring Actuation (LaMSA) Systems",
        "link": "http://arxiv.org/abs/2405.18421v1",
        "abstract": "In nature, different species of smaller animals produce ultra-fast movements\nto aid in their locomotion or protect themselves against predators. These\nultra-fast impulsive motions are possible, as often times, there exist a small\nlatch in the organism that could hold the potential energy of the system, and\nonce released, generate an impulsive motion. These types of systems are\nclassified as Latch Mediated Spring Actuated (LaMSA) systems, a\nmulti-dimensional, multi-mode hybrid system that switches between a latched and\nan unlatched state. The LaMSA mechanism has been studied extensively in the\nfield of biology and is observed in a wide range of animal species, such as the\nmantis shrimp, grasshoppers, and trap-jaw ants. In recent years, research has\nbeen done in mathematically modeling the LaMSA behavior with physical\nimplementations of the mechanism. A significant focus is given to mimicking the\nphysiological behavior of the species and following an end-to-end trajectory of\nimpulsive motion. This paper introduces a foundational analysis of the\ntheoretical dynamics of the contact latch-based LaMSA mechanism. The authors\nanswer the question on what makes these small-scale systems impulsive, with a\nfocus on the intrinsic properties of the system using bifurcations. Necessary\nand sufficient conditions are derived for the existence of the saddle fixed\npoints. The authors propose a mathematical explanation for mediating the latch\nwhen a saddle node exists, and the impulsive behavior after the bifurcation\nhappens.",
        "subjects": [
            "eess.SY",
            "cs.SY",
            "math.DS"
        ],
        "authors": [
            "Vittal Srinivasan",
            "Nak-seung Patrick Hyun"
        ],
        "published": "2024-05-28T17:58:46Z"
    },
    {
        "title": "Hierarchical World Models as Visual Whole-Body Humanoid Controllers",
        "link": "http://arxiv.org/abs/2405.18418v1",
        "abstract": "Whole-body control for humanoids is challenging due to the high-dimensional\nnature of the problem, coupled with the inherent instability of a bipedal\nmorphology. Learning from visual observations further exacerbates this\ndifficulty. In this work, we explore highly data-driven approaches to visual\nwhole-body humanoid control based on reinforcement learning, without any\nsimplifying assumptions, reward design, or skill primitives. Specifically, we\npropose a hierarchical world model in which a high-level agent generates\ncommands based on visual observations for a low-level agent to execute, both of\nwhich are trained with rewards. Our approach produces highly performant control\npolicies in 8 tasks with a simulated 56-DoF humanoid, while synthesizing\nmotions that are broadly preferred by humans. Code and videos:\nhttps://nicklashansen.com/rlpuppeteer",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Nicklas Hansen",
            "Jyothir S V",
            "Vlad Sobal",
            "Yann LeCun",
            "Xiaolong Wang",
            "Hao Su"
        ],
        "published": "2024-05-28T17:57:23Z"
    },
    {
        "title": "3D StreetUnveiler with Semantic-Aware 2DGS",
        "link": "http://arxiv.org/abs/2405.18416v2",
        "abstract": "Unveiling an empty street from crowded observations captured by in-car\ncameras is crucial for autonomous driving. However, removing all temporarily\nstatic objects, such as stopped vehicles and standing pedestrians, presents a\nsignificant challenge. Unlike object-centric 3D inpainting, which relies on\nthorough observation in a small scene, street scene cases involve long\ntrajectories that differ from previous 3D inpainting tasks. The camera-centric\nmoving environment of captured videos further complicates the task due to the\nlimited degree and time duration of object observation. To address these\nobstacles, we introduce StreetUnveiler to reconstruct an empty street.\nStreetUnveiler learns a 3D representation of the empty street from crowded\nobservations. Our representation is based on the hard-label semantic 2D\nGaussian Splatting (2DGS) for its scalability and ability to identify Gaussians\nto be removed. We inpaint rendered image after removing unwanted Gaussians to\nprovide pseudo-labels and subsequently re-optimize the 2DGS. Given its temporal\ncontinuous movement, we divide the empty street scene into observed,\npartial-observed, and unobserved regions, which we propose to locate through a\nrendered alpha map. This decomposition helps us to minimize the regions that\nneed to be inpainted. To enhance the temporal consistency of the inpainting, we\nintroduce a novel time-reversal framework to inpaint frames in reverse order\nand use later frames as references for earlier frames to fully utilize the\nlong-trajectory observations. Our experiments conducted on the street scene\ndataset successfully reconstructed a 3D representation of the empty street. The\nmesh representation of the empty street can be extracted for further\napplications. The project page and more visualizations can be found at:\nhttps://streetunveiler.github.io",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jingwei Xu",
            "Yikai Wang",
            "Yiqun Zhao",
            "Yanwei Fu",
            "Shenghua Gao"
        ],
        "published": "2024-05-28T17:57:12Z"
    },
    {
        "title": "Why are Visually-Grounded Language Models Bad at Image Classification?",
        "link": "http://arxiv.org/abs/2405.18415v1",
        "abstract": "Image classification is one of the most fundamental capabilities of machine\nvision intelligence. In this work, we revisit the image classification task\nusing visually-grounded language models (VLMs) such as GPT-4V and LLaVA. We\nfind that existing proprietary and public VLMs, despite often using CLIP as a\nvision encoder and having many more parameters, significantly underperform CLIP\non standard image classification benchmarks like ImageNet. To understand the\nreason, we explore several hypotheses concerning the inference algorithms,\ntraining objectives, and data processing in VLMs. Our analysis reveals that the\nprimary cause is data-related: critical information for image classification is\nencoded in the VLM's latent space but can only be effectively decoded with\nenough training data. Specifically, there is a strong correlation between the\nfrequency of class exposure during VLM training and instruction-tuning and the\nVLM's performance in those classes; when trained with sufficient data, VLMs can\nmatch the accuracy of state-of-the-art classification models. Based on these\nfindings, we enhance a VLM by integrating classification-focused datasets into\nits training, and demonstrate that the enhanced classification performance of\nthe VLM transfers to its general capabilities, resulting in an improvement of\n11.8% on the newly collected ImageWikiQA dataset.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Yuhui Zhang",
            "Alyssa Unell",
            "Xiaohan Wang",
            "Dhruba Ghosh",
            "Yuchang Su",
            "Ludwig Schmidt",
            "Serena Yeung-Levy"
        ],
        "published": "2024-05-28T17:57:06Z"
    },
    {
        "title": "Don't Forget to Connect! Improving RAG with Graph-based Reranking",
        "link": "http://arxiv.org/abs/2405.18414v1",
        "abstract": "Retrieval Augmented Generation (RAG) has greatly improved the performance of\nLarge Language Model (LLM) responses by grounding generation with context from\nexisting documents. These systems work well when documents are clearly relevant\nto a question context. But what about when a document has partial information,\nor less obvious connections to the context? And how should we reason about\nconnections between documents? In this work, we seek to answer these two core\nquestions about RAG generation. We introduce G-RAG, a reranker based on graph\nneural networks (GNNs) between the retriever and reader in RAG. Our method\ncombines both connections between documents and semantic information (via\nAbstract Meaning Representation graphs) to provide a context-informed ranker\nfor RAG. G-RAG outperforms state-of-the-art approaches while having smaller\ncomputational footprint. Additionally, we assess the performance of PaLM 2 as a\nreranker and find it to significantly underperform G-RAG. This result\nemphasizes the importance of reranking for RAG even when using Large Language\nModels.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.SI"
        ],
        "authors": [
            "Jialin Dong",
            "Bahare Fatemi",
            "Bryan Perozzi",
            "Lin F. Yang",
            "Anton Tsitsulin"
        ],
        "published": "2024-05-28T17:56:46Z"
    },
    {
        "title": "Tensor Methods in High Dimensional Data Analysis: Opportunities and\n  Challenges",
        "link": "http://arxiv.org/abs/2405.18412v1",
        "abstract": "Large amount of multidimensional data represented by multiway arrays or\ntensors are prevalent in modern applications across various fields such as\nchemometrics, genomics, physics, psychology, and signal processing. The\nstructural complexity of such data provides vast new opportunities for modeling\nand analysis, but efficiently extracting information content from them, both\nstatistically and computationally, presents unique and fundamental challenges.\nAddressing these challenges requires an interdisciplinary approach that brings\ntogether tools and insights from statistics, optimization and numerical linear\nalgebra among other fields. Despite these hurdles, significant progress has\nbeen made in the last decade. This review seeks to examine some of the key\nadvancements and identify common threads among them, under eight different\nstatistical settings.",
        "subjects": [
            "math.ST",
            "cs.NA",
            "math.NA",
            "stat.ME",
            "stat.ML",
            "stat.TH"
        ],
        "authors": [
            "Arnab Auddy",
            "Dong Xia",
            "Ming Yuan"
        ],
        "published": "2024-05-28T17:54:03Z"
    },
    {
        "title": "Towards a Sampling Theory for Implicit Neural Representations",
        "link": "http://arxiv.org/abs/2405.18410v1",
        "abstract": "Implicit neural representations (INRs) have emerged as a powerful tool for\nsolving inverse problems in computer vision and computational imaging. INRs\nrepresent images as continuous domain functions realized by a neural network\ntaking spatial coordinates as inputs. However, unlike traditional pixel\nrepresentations, little is known about the sample complexity of estimating\nimages using INRs in the context of linear inverse problems. Towards this end,\nwe study the sampling requirements for recovery of a continuous domain image\nfrom its low-pass Fourier coefficients by fitting a single hidden-layer INR\nwith ReLU activation and a Fourier features layer using a generalized form of\nweight decay regularization. Our key insight is to relate minimizers of this\nnon-convex parameter space optimization problem to minimizers of a convex\npenalty defined over an infinite-dimensional space of measures. We identify a\nsufficient number of samples for which an image realized by a width-1 INR is\nexactly recoverable by solving the INR training problem, and give a conjecture\nfor the general width-$W$ case. To validate our theory, we empirically assess\nthe probability of achieving exact recovery of images realized by low-width\nsingle hidden-layer INRs, and illustrate the performance of INR on\nsuper-resolution recovery of more realistic continuous domain phantom images.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Mahrokh Najaf",
            "Gregory Ongie"
        ],
        "published": "2024-05-28T17:53:47Z"
    },
    {
        "title": "Sections of Submonoids of Nilpotent Groups",
        "link": "http://arxiv.org/abs/2405.18409v1",
        "abstract": "We show that every product of f.g.\\ submonoids of a group $G$ is a section of\na f.g.\\ submonoid of $G{\\times}H_5(\\mathbb{Z})$, where $H_5(\\mathbb{Z})$ is a\nHeisenberg group. This gives us a converse of a reduction of Bodart, and a new\nsimple proof of the existence of a submonoid of a nilpotent group of class 2\nwith undecidable membership problem.",
        "subjects": [
            "math.GR",
            "cs.FL"
        ],
        "authors": [
            "Doron Shafrir"
        ],
        "published": "2024-05-28T17:51:04Z"
    },
    {
        "title": "Why Algorithms Remain Unjust: Power Structures Surrounding Algorithmic\n  Activity",
        "link": "http://arxiv.org/abs/2405.18461v1",
        "abstract": "Algorithms play an increasingly-significant role in our social lives.\nUnfortunately, they often perpetuate social injustices while doing so. The\npopular means of addressing these algorithmic injustices has been through\nalgorithmic reformism: fine-tuning the algorithm itself to be more fair,\naccountable, and transparent. While commendable, the emerging discipline of\ncritical algorithm studies shows that reformist approaches have failed to\ncurtail algorithmic injustice because they ignore the power structure\nsurrounding algorithms. Heeding calls from critical algorithm studies to\nanalyze this power structure, I employ a framework developed by Erik Olin\nWright to examine the configuration of power surrounding Algorithmic Activity:\nthe ways in which algorithms are researched, developed, trained, and deployed\nwithin society. I argue that the reason Algorithmic Activity is unequal,\nundemocratic, and unsustainable is that the power structure shaping it is one\nof economic empowerment rather than social empowerment. For Algorithmic\nActivity to be socially just, we need to transform this power configuration to\nempower the people at the other end of an algorithm. To this end, I explore\nWright's symbiotic, interstitial, and raptural transformations in the context\nof Algorithmic Activity, as well as how they may be applied in a hypothetical\nresearch project that uses algorithms to address a social issue. I conclude\nwith my vision for socially just Algorithmic Activity, asking that future work\nstrives to integrate the proposed transformations and develop new mechanisms\nfor social empowerment.",
        "subjects": [
            "cs.CY",
            "cs.LG",
            "K.4.1; K.4.0"
        ],
        "authors": [
            "Andrew Balch"
        ],
        "published": "2024-05-28T17:49:24Z"
    },
    {
        "title": "Phased Consistency Model",
        "link": "http://arxiv.org/abs/2405.18407v1",
        "abstract": "The consistency model (CM) has recently made significant progress in\naccelerating the generation of diffusion models. However, its application to\nhigh-resolution, text-conditioned image generation in the latent space (a.k.a.,\nLCM) remains unsatisfactory. In this paper, we identify three key flaws in the\ncurrent design of LCM. We investigate the reasons behind these limitations and\npropose the Phased Consistency Model (PCM), which generalizes the design space\nand addresses all identified limitations. Our evaluations demonstrate that PCM\nsignificantly outperforms LCM across 1--16 step generation settings. While PCM\nis specifically designed for multi-step refinement, it achieves even superior\nor comparable 1-step generation results to previously state-of-the-art\nspecifically designed 1-step methods. Furthermore, we show that PCM's\nmethodology is versatile and applicable to video generation, enabling us to\ntrain the state-of-the-art few-step text-to-video generator. More details are\navailable at https://g-u-n.github.io/projects/pcm/.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Fu-Yun Wang",
            "Zhaoyang Huang",
            "Alexander William Bergman",
            "Dazhong Shen",
            "Peng Gao",
            "Michael Lingelbach",
            "Keqiang Sun",
            "Weikang Bian",
            "Guanglu Song",
            "Yu Liu",
            "Hongsheng Li",
            "Xiaogang Wang"
        ],
        "published": "2024-05-28T17:47:19Z"
    },
    {
        "title": "RACCooN: Remove, Add, and Change Video Content with Auto-Generated\n  Narratives",
        "link": "http://arxiv.org/abs/2405.18406v1",
        "abstract": "Recent video generative models primarily rely on carefully written text\nprompts for specific tasks, like inpainting or style editing. They require\nlabor-intensive textual descriptions for input videos, hindering their\nflexibility to adapt personal/raw videos to user specifications. This paper\nproposes RACCooN, a versatile and user-friendly video-to-paragraph-to-video\ngenerative framework that supports multiple video editing capabilities such as\nremoval, addition, and modification, through a unified pipeline. RACCooN\nconsists of two principal stages: Video-to-Paragraph (V2P) and\nParagraph-to-Video (P2V). In the V2P stage, we automatically describe video\nscenes in well-structured natural language, capturing both the holistic context\nand focused object details. Subsequently, in the P2V stage, users can\noptionally refine these descriptions to guide the video diffusion model,\nenabling various modifications to the input video, such as removing, changing\nsubjects, and/or adding new objects. The proposed approach stands out from\nother methods through several significant contributions: (1) RACCooN suggests a\nmulti-granular spatiotemporal pooling strategy to generate well-structured\nvideo descriptions, capturing both the broad context and object details without\nrequiring complex human annotations, simplifying precise video content editing\nbased on text for users. (2) Our video generative model incorporates\nauto-generated narratives or instructions to enhance the quality and accuracy\nof the generated content. It supports the addition of video objects,\ninpainting, and attribute modification within a unified framework, surpassing\nexisting video editing and inpainting benchmarks. The proposed framework\ndemonstrates impressive versatile capabilities in video-to-paragraph\ngeneration, video content editing, and can be incorporated into other SoTA\nvideo generative models for further enhancement.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Jaehong Yoon",
            "Shoubin Yu",
            "Mohit Bansal"
        ],
        "published": "2024-05-28T17:46:36Z"
    },
    {
        "title": "WIDIn: Wording Image for Domain-Invariant Representation in\n  Single-Source Domain Generalization",
        "link": "http://arxiv.org/abs/2405.18405v1",
        "abstract": "Language has been useful in extending the vision encoder to data from diverse\ndistributions without empirical discovery in training domains. However, as the\nimage description is mostly at coarse-grained level and ignores visual details,\nthe resulted embeddings are still ineffective in overcoming complexity of\ndomains at inference time. We present a self-supervision framework WIDIn,\nWording Images for Domain-Invariant representation, to disentangle\ndiscriminative visual representation, by only leveraging data in a single\ndomain and without any test prior. Specifically, for each image, we first\nestimate the language embedding with fine-grained alignment, which can be\nconsequently used to adaptively identify and then remove domain-specific\ncounterpart from the raw visual embedding. WIDIn can be applied to both\npretrained vision-language models like CLIP, and separately trained uni-modal\nmodels like MoCo and BERT. Experimental studies on three domain generalization\ndatasets demonstrate the effectiveness of our approach.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Jiawei Ma",
            "Yulei Niu",
            "Shiyuan Huang",
            "Guangxing Han",
            "Shih-Fu Chang"
        ],
        "published": "2024-05-28T17:46:27Z"
    },
    {
        "title": "Probing the Information Theoretical Roots of Spatial Dependence Measures",
        "link": "http://arxiv.org/abs/2405.18459v1",
        "abstract": "Intuitively, there is a relation between measures of spatial dependence and\ninformation theoretical measures of entropy. For instance, we can provide an\nintuition of why spatial data is special by stating that, on average, spatial\ndata samples contain less than expected information. Similarly, spatial data,\ne.g., remotely sensed imagery, that is easy to compress is also likely to show\nsignificant spatial autocorrelation. Formulating our (highly specific) core\nconcepts of spatial information theory in the widely used language of\ninformation theory opens new perspectives on their differences and similarities\nand also fosters cross-disciplinary collaboration, e.g., with the broader AI/ML\ncommunities. Interestingly, however, this intuitive relation is challenging to\nformalize and generalize, leading prior work to rely mostly on experimental\nresults, e.g., for describing landscape patterns. In this work, we will explore\nthe information theoretical roots of spatial autocorrelation, more specifically\nMoran's I, through the lens of self-information (also known as surprisal) and\nprovide both formal proofs and experiments.",
        "subjects": [
            "cs.IT",
            "cs.AI",
            "cs.LG",
            "math.IT",
            "stat.ME"
        ],
        "authors": [
            "Zhangyu Wang",
            "Krzysztof Janowicz",
            "Gengchen Mai",
            "Ivan Majic"
        ],
        "published": "2024-05-28T17:44:35Z"
    },
    {
        "title": "Explicit Formulae to Interchangeably use Hyperplanes and Hyperballs\n  using Inversive Geometry",
        "link": "http://arxiv.org/abs/2405.18401v1",
        "abstract": "Many algorithms require discriminative boundaries, such as separating\nhyperplanes or hyperballs, or are specifically designed to work on spherical\ndata. By applying inversive geometry, we show that the two discriminative\nboundaries can be used interchangeably, and that general Euclidean data can be\ntransformed into spherical data, whenever a change in point distances is\nacceptable. We provide explicit formulae to embed general Euclidean data into\nspherical data and to unembed it back. We further show a duality between\nhyperspherical caps, i.e., the volume created by a separating hyperplane on\nspherical data, and hyperballs and provide explicit formulae to map between the\ntwo. We further provide equations to translate inner products and Euclidean\ndistances between the two spaces, to avoid explicit embedding and unembedding.\nWe also provide a method to enforce projections of the general Euclidean space\nonto hemi-hyperspheres and propose an intrinsic dimensionality based method to\nobtain \"all-purpose\" parameters. To show the usefulness of the\ncap-ball-duality, we discuss example applications in machine learning and\nvector similarity search.",
        "subjects": [
            "cs.LG",
            "cs.CG",
            "stat.ML"
        ],
        "authors": [
            "Erik Thordsen",
            "Erich Schubert"
        ],
        "published": "2024-05-28T17:43:16Z"
    },
    {
        "title": "Superposed Decoding: Multiple Generations from a Single Autoregressive\n  Inference Pass",
        "link": "http://arxiv.org/abs/2405.18400v2",
        "abstract": "Many applications today provide users with multiple auto-complete drafts as\nthey type, including GitHub's code completion, Gmail's smart compose, and\nApple's messaging auto-suggestions. Under the hood, language models support\nthis by running an autoregressive inference pass to provide a draft.\nConsequently, providing $k$ drafts to the user requires running an expensive\nlanguage model $k$ times. To alleviate the computation cost of running $k$\ninference passes, we propose Superposed Decoding, a new decoding algorithm that\ngenerates $k$ drafts at the computation cost of one autoregressive inference\npass. We achieve this by feeding a superposition of the most recent token\nembeddings from the $k$ drafts as input to the next decoding step of the\nlanguage model. At every inference step we combine the $k$ drafts with the\ntop-$k$ tokens to get $k^2$ new drafts and cache the $k$ most likely options,\nusing an n-gram interpolation with minimal compute overhead to filter out\nincoherent generations. Our experiments show that $k$ drafts from Superposed\nDecoding are at least as coherent and factual as Nucleus Sampling and Greedy\nDecoding respectively, while being at least $2.44\\times$ faster for $k\\ge3$. In\na compute-normalized setting, user evaluations demonstrably favor text\ngenerated by Superposed Decoding over Nucleus Sampling. Code and more examples\nopen-sourced at https://github.com/RAIVNLab/SuperposedDecoding.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Ethan Shen",
            "Alan Fan",
            "Sarah M Pratt",
            "Jae Sung Park",
            "Matthew Wallingford",
            "Sham M. Kakade",
            "Ari Holtzman",
            "Ranjay Krishna",
            "Ali Farhadi",
            "Aditya Kusupati"
        ],
        "published": "2024-05-28T17:40:48Z"
    },
    {
        "title": "A simple, randomized algorithm for diagonalizing normal matrices",
        "link": "http://arxiv.org/abs/2405.18399v1",
        "abstract": "We present and analyze a simple numerical method that diagonalizes a complex\nnormal matrix A by diagonalizing the Hermitian matrix obtained from a random\nlinear combination of the Hermitian and skew-Hermitian parts of A.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "65F15, 15B57, 15A18"
        ],
        "authors": [
            "Haoze He",
            "Daniel Kressner"
        ],
        "published": "2024-05-28T17:39:37Z"
    },
    {
        "title": "MC-GTA: Metric-Constrained Model-Based Clustering using Goodness-of-fit\n  Tests with Autocorrelations",
        "link": "http://arxiv.org/abs/2405.18395v1",
        "abstract": "A wide range of (multivariate) temporal (1D) and spatial (2D) data analysis\ntasks, such as grouping vehicle sensor trajectories, can be formulated as\nclustering with given metric constraints. Existing metric-constrained\nclustering algorithms overlook the rich correlation between feature similarity\nand metric distance, i.e., metric autocorrelation. The model-based variations\nof these clustering algorithms (e.g. TICC and STICC) achieve SOTA performance,\nyet suffer from computational instability and complexity by using a\nmetric-constrained Expectation-Maximization procedure. In order to address\nthese two problems, we propose a novel clustering algorithm, MC-GTA\n(Model-based Clustering via Goodness-of-fit Tests with Autocorrelations). Its\nobjective is only composed of pairwise weighted sums of feature similarity\nterms (square Wasserstein-2 distance) and metric autocorrelation terms (a novel\nmultivariate generalization of classic semivariogram). We show that MC-GTA is\neffectively minimizing the total hinge loss for intra-cluster observation pairs\nnot passing goodness-of-fit tests, i.e., statistically not originating from the\nsame distribution. Experiments on 1D/2D synthetic and real-world datasets\ndemonstrate that MC-GTA successfully incorporates metric autocorrelation. It\noutperforms strong baselines by large margins (up to 14.3% in ARI and 32.1% in\nNMI) with faster and stabler optimization (>10x speedup).",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.AP"
        ],
        "authors": [
            "Zhangyu Wang",
            "Gengchen Mai",
            "Krzysztof Janowicz",
            "Ni Lao"
        ],
        "published": "2024-05-28T17:35:05Z"
    },
    {
        "title": "A Critique of Snapshot Isolation",
        "link": "http://dx.doi.org/10.1145/2168836.2168853",
        "abstract": "The support for transactions is an essential part of a database management\nsystem (DBMS). Without this support, the developers are burdened with ensuring\natomic execution of a transaction despite failures as well as concurrent\naccesses to the database by other transactions. Ideally, a transactional system\nprovides serializability, which means that the outcome of concurrent\ntransactions is equivalent to a serial execution of them. Based on experiences\non lock-based implementations, nevertheless, serializability is known as an\nexpensive feature that comes with high overhead and low concurrency. Commercial\nsystems, hence, compromise serializability by implementing weaker guarantees\nsuch as snapshot isolation. The developers, therefore, are still burdened with\nthe anomalies that could arise due to the lack of serializability.\n  There have been recent attempts to enrich large-scale data stores, such as\nHBase and BigTable, with transactional support. Not surprisingly, inspired by\ntraditional database management systems, serializability is usually compromised\nfor the benefit of efficiency. For example, Google Percolator, implements\nlock-based snapshot isolation on top of BigTable. We show in this paper that\nthis compromise is not necessary in lock-free implementations of transactional\nsupport. We introduce write-snapshot isolation, a novel isolation level that\nhas a performance comparable with that of snapshot isolation, and yet provides\nserializability. The main insight in write-snapshot isolation is to prevent\nread-write conflicts in contrast to write-write conflicts that are prevented by\nsnapshot isolation.",
        "subjects": [
            "cs.DB"
        ],
        "authors": [
            "Daniel Gómez Ferro",
            "Maysam Yabandeh"
        ],
        "published": "2024-05-28T17:33:57Z"
    },
    {
        "title": "Scaling Laws and Compute-Optimal Training Beyond Fixed Training\n  Durations",
        "link": "http://arxiv.org/abs/2405.18392v2",
        "abstract": "Scale has become a main ingredient in obtaining strong machine learning\nmodels. As a result, understanding a model's scaling properties is key to\neffectively designing both the right training setup as well as future\ngenerations of architectures. In this work, we argue that scale and training\nresearch has been needlessly complex due to reliance on the cosine schedule,\nwhich prevents training across different lengths for the same model size. We\ninvestigate the training behavior of a direct alternative - constant learning\nrate and cooldowns - and find that it scales predictably and reliably similar\nto cosine. Additionally, we show that stochastic weight averaging yields\nimproved performance along the training trajectory, without additional training\ncosts, across different scales. Importantly, with these findings we demonstrate\nthat scaling experiments can be performed with significantly reduced compute\nand GPU hours by utilizing fewer but reusable training runs. Our code is\navailable at https://github.com/epfml/schedules-and-scaling.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Alexander Hägele",
            "Elie Bakouch",
            "Atli Kosson",
            "Loubna Ben Allal",
            "Leandro Von Werra",
            "Martin Jaggi"
        ],
        "published": "2024-05-28T17:33:54Z"
    },
    {
        "title": "Natural numbers from integers",
        "link": "http://arxiv.org/abs/2405.18388v1",
        "abstract": "In homotopy type theory, a natural number type is freely generated by an\nelement and an endomorphism. Similarly, an integer type is freely generated by\nan element and an automorphism. Using only dependent sums, identity types,\nextensional dependent products, and a type of two elements with large\nelimination, we construct a natural number type from an integer type. As a\ncorollary, homotopy type theory with only $\\Sigma$, $\\mathsf{Id}$, $\\Pi$, and\nfinite colimits with descent (and no universes) admits a natural number type.\nThis improves and simplifies a result by Rose.",
        "subjects": [
            "cs.LO",
            "math.CT"
        ],
        "authors": [
            "Christian Sattler",
            "David Wärn"
        ],
        "published": "2024-05-28T17:28:20Z"
    },
    {
        "title": "A Review and Implementation of Object Detection Models and Optimizations\n  for Real-time Medical Mask Detection during the COVID-19 Pandemic",
        "link": "http://dx.doi.org/10.1109/INISTA55318.2022.9894232",
        "abstract": "Convolutional Neural Networks (CNN) are commonly used for the problem of\nobject detection thanks to their increased accuracy. Nevertheless, the\nperformance of CNN-based detection models is ambiguous when detection speed is\nconsidered. To the best of our knowledge, there has not been sufficient\nevaluation of the available methods in terms of the speed/accuracy trade-off in\nrelated literature. This work assesses the most fundamental object detection\nmodels on the Common Objects in Context (COCO) dataset with respect to this\ntrade-off, their memory consumption, and computational and storage cost. Next,\nwe select a highly efficient model called YOLOv5 to train on the topical and\nunexplored dataset of human faces with medical masks, the Properly-Wearing\nMasked Faces Dataset (PWMFD), and analyze the benefits of specific optimization\ntechniques for real-time medical mask detection: transfer learning, data\naugmentations, and a Squeeze-and-Excitation attention mechanism. Using our\nfindings in the context of the COVID-19 pandemic, we propose an optimized model\nbased on YOLOv5s using transfer learning for the detection of correctly and\nincorrectly worn medical masks that surpassed more than two times in speed (69\nframes per second) the state-of-the-art model SE-YOLOv3 on the PWMFD dataset\nwhile maintaining the same level of mean Average Precision (67%).",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Ioanna Gogou",
            "Dimitrios Koutsomitropoulos"
        ],
        "published": "2024-05-28T17:27:24Z"
    },
    {
        "title": "Instruct-MusicGen: Unlocking Text-to-Music Editing for Music Language\n  Models via Instruction Tuning",
        "link": "http://arxiv.org/abs/2405.18386v2",
        "abstract": "Recent advances in text-to-music editing, which employ text queries to modify\nmusic (e.g.\\ by changing its style or adjusting instrumental components),\npresent unique challenges and opportunities for AI-assisted music creation.\nPrevious approaches in this domain have been constrained by the necessity to\ntrain specific editing models from scratch, which is both resource-intensive\nand inefficient; other research uses large language models to predict edited\nmusic, resulting in imprecise audio reconstruction. To Combine the strengths\nand address these limitations, we introduce Instruct-MusicGen, a novel approach\nthat finetunes a pretrained MusicGen model to efficiently follow editing\ninstructions such as adding, removing, or separating stems. Our approach\ninvolves a modification of the original MusicGen architecture by incorporating\na text fusion module and an audio fusion module, which allow the model to\nprocess instruction texts and audio inputs concurrently and yield the desired\nedited music. Remarkably, Instruct-MusicGen only introduces 8% new parameters\nto the original MusicGen model and only trains for 5K steps, yet it achieves\nsuperior performance across all tasks compared to existing baselines, and\ndemonstrates performance comparable to the models trained for specific tasks.\nThis advancement not only enhances the efficiency of text-to-music editing but\nalso broadens the applicability of music language models in dynamic music\nproduction environments.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.LG",
            "cs.MM",
            "eess.AS"
        ],
        "authors": [
            "Yixiao Zhang",
            "Yukara Ikemiya",
            "Woosung Choi",
            "Naoki Murata",
            "Marco A. Martínez-Ramírez",
            "Liwei Lin",
            "Gus Xia",
            "Wei-Hsiang Liao",
            "Yuki Mitsufuji",
            "Simon Dixon"
        ],
        "published": "2024-05-28T17:27:20Z"
    },
    {
        "title": "Asymmetrical estimator for training grey-box deep photonic neural\n  networks",
        "link": "http://arxiv.org/abs/2405.18458v1",
        "abstract": "Physical neural networks (PNNs) are emerging paradigms for neural network\nacceleration due to their high-bandwidth, in-propagation analogue processing.\nDespite the advantages of PNN for inference, training remains a challenge. The\nimperfect information of the physical transformation means the failure of\nconventional gradient-based updates from backpropagation (BP). Here, we present\nthe asymmetrical training (AT) method, which treats the PNN structure as a grey\nbox. AT performs training while only knowing the last layer output and neuron\ntopological connectivity of a deep neural network structure, not requiring\ninformation about the physical control-transformation mapping. We\nexperimentally demonstrated the AT method on deep grey-box PNNs implemented by\nuncalibrated photonic integrated circuits (PICs), improving the classification\naccuracy of Iris flower and modified MNIST hand-written digits from random\nguessing to near theoretical maximum. We also showcased the consistently\nenhanced performance of AT over BP for different datasets, including MNIST,\nfashion-MNIST, and Kuzushiji-MNIST. The AT method demonstrated successful\ntraining with minimal hardware overhead and reduced computational overhead,\nserving as a robust light-weight training alternative to fully explore the\nadvantages of physical computation.",
        "subjects": [
            "cs.LG",
            "physics.optics",
            "78-05"
        ],
        "authors": [
            "Yizhi Wang",
            "Minjia Chen",
            "Chunhui Yao",
            "Jie Ma",
            "Ting Yan",
            "Richard Penty",
            "Qixiang Cheng"
        ],
        "published": "2024-05-28T17:27:20Z"
    },
    {
        "title": "Blocking Tracking JavaScript at the Function Granularity",
        "link": "http://arxiv.org/abs/2405.18385v1",
        "abstract": "Modern websites extensively rely on JavaScript to implement both\nfunctionality and tracking. Existing privacy enhancing content blocking tools\nstruggle against mixed scripts, which simultaneously implement both\nfunctionality and tracking, because blocking the script would break\nfunctionality and not blocking it would allow tracking. We propose Not.js, a\nfine grained JavaScript blocking tool that operates at the function level\ngranularity. Not.js's strengths lie in analyzing the dynamic execution context,\nincluding the call stack and calling context of each JavaScript function, and\nthen encoding this context to build a rich graph representation. Not.js trains\na supervised machine learning classifier on a webpage's graph representation to\nfirst detect tracking at the JavaScript function level and then automatically\ngenerate surrogate scripts that preserve functionality while removing tracking.\nOur evaluation of Not.js on the top 10K websites demonstrates that it achieves\nhigh precision (94%) and recall (98%) in detecting tracking JavaScript\nfunctions, outperforming the state of the art while being robust against off\nthe shelf JavaScript obfuscation. Fine grained detection of tracking functions\nallows Not.js to automatically generate surrogate scripts that remove tracking\nJavaScript functions without causing major breakage. Our deployment of Not.js\nshows that mixed scripts are present on 62.3% of the top 10K websites, with\n70.6% of the mixed scripts being third party that engage in tracking activities\nsuch as cookie ghostwriting. We share a sample of the tracking functions\ndetected by Not.js within mixed scripts not currently on filter lists with\nfilter list authors, who confirm that these scripts are not blocked due to\npotential functionality breakage, despite being known to implement tracking.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Abdul Haddi Amjad",
            "Shaoor Munir",
            "Zubair Shafiq",
            "Muhammad Ali Gulzar"
        ],
        "published": "2024-05-28T17:26:57Z"
    },
    {
        "title": "Brain Tumor Segmentation (BraTS) Challenge 2024: Meningioma Radiotherapy\n  Planning Automated Segmentation",
        "link": "http://arxiv.org/abs/2405.18383v1",
        "abstract": "The 2024 Brain Tumor Segmentation Meningioma Radiotherapy (BraTS-MEN-RT)\nchallenge aims to advance automated segmentation algorithms using the largest\nknown multi-institutional dataset of radiotherapy planning brain MRIs with\nexpert-annotated target labels for patients with intact or post-operative\nmeningioma that underwent either conventional external beam radiotherapy or\nstereotactic radiosurgery. Each case includes a defaced 3D post-contrast\nT1-weighted radiotherapy planning MRI in its native acquisition space,\naccompanied by a single-label \"target volume\" representing the gross tumor\nvolume (GTV) and any at-risk post-operative site. Target volume annotations\nadhere to established radiotherapy planning protocols, ensuring consistency\nacross cases and institutions. For pre-operative meningiomas, the target volume\nencompasses the entire GTV and associated nodular dural tail, while for\npost-operative cases, it includes at-risk resection cavity margins as\ndetermined by the treating institution. Case annotations were reviewed and\napproved by expert neuroradiologists and radiation oncologists. Participating\nteams will develop, containerize, and evaluate automated segmentation models\nusing this comprehensive dataset. Model performance will be assessed using the\nlesion-wise Dice Similarity Coefficient and the 95% Hausdorff distance. The\ntop-performing teams will be recognized at the Medical Image Computing and\nComputer Assisted Intervention Conference in October 2024. BraTS-MEN-RT is\nexpected to significantly advance automated radiotherapy planning by enabling\nprecise tumor segmentation and facilitating tailored treatment, ultimately\nimproving patient outcomes.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.HC",
            "cs.LG"
        ],
        "authors": [
            "Dominic LaBella",
            "Katherine Schumacher",
            "Michael Mix",
            "Kevin Leu",
            "Shan McBurney-Lin",
            "Pierre Nedelec",
            "Javier Villanueva-Meyer",
            "Jonathan Shapey",
            "Tom Vercauteren",
            "Kazumi Chia",
            "Omar Al-Salihi",
            "Justin Leu",
            "Lia Halasz",
            "Yury Velichko",
            "Chunhao Wang",
            "John Kirkpatrick",
            "Scott Floyd",
            "Zachary J. Reitman",
            "Trey Mullikin",
            "Ulas Bagci",
            "Sean Sachdev",
            "Jona A. Hattangadi-Gluth",
            "Tyler Seibert",
            "Nikdokht Farid",
            "Connor Puett",
            "Matthew W. Pease",
            "Kevin Shiue",
            "Syed Muhammad Anwar",
            "Shahriar Faghani",
            "Muhammad Ammar Haider",
            "Pranav Warman",
            "Jake Albrecht",
            "András Jakab",
            "Mana Moassefi",
            "Verena Chung",
            "Alejandro Aristizabal",
            "Alexandros Karargyris",
            "Hasan Kassem",
            "Sarthak Pati",
            "Micah Sheller",
            "Christina Huang",
            "Aaron Coley",
            "Siddharth Ghanta",
            "Alex Schneider",
            "Conrad Sharp",
            "Rachit Saluja",
            "Florian Kofler",
            "Philipp Lohmann",
            "Phillipp Vollmuth",
            "Louis Gagnon",
            "Maruf Adewole",
            "Hongwei Bran Li",
            "Anahita Fathi Kazerooni",
            "Nourel Hoda Tahon",
            "Udunna Anazodo",
            "Ahmed W. Moawad",
            "Bjoern Menze",
            "Marius George Linguraru",
            "Mariam Aboian",
            "Benedikt Wiestler",
            "Ujjwal Baid",
            "Gian-Marco Conte",
            "Andreas M. T. Rauschecker",
            "Ayman Nada",
            "Aly H. Abayazeed",
            "Raymond Huang",
            "Maria Correia de Verdier",
            "Jeffrey D. Rudie",
            "Spyridon Bakas",
            "Evan Calabrese"
        ],
        "published": "2024-05-28T17:25:43Z"
    },
    {
        "title": "OwLore: Outlier-weighed Layerwise Sampled Low-Rank Projection for\n  Memory-Efficient LLM Fine-tuning",
        "link": "http://arxiv.org/abs/2405.18380v1",
        "abstract": "The rapid advancements in Large Language Models (LLMs) have revolutionized\nvarious natural language processing tasks. However, the substantial size of\nLLMs presents significant challenges in training or fine-tuning. While\nparameter-efficient approaches such as low-rank adaptation (LoRA) have gained\npopularity, they often compromise performance compared to full-rank\nfine-tuning. In this paper, we propose Outlier-weighed Layerwise Sampled\nLow-Rank Projection (OwLore), a new memory-efficient fine-tuning approach,\ninspired by the layerwise outlier distribution of LLMs, which dynamically\nsamples pre-trained layers to fine-tune instead of adding additional adaptors.\nWe first interpret the outlier phenomenon through the lens of Heavy-Tailed\nSelf-Regularization theory (HT-SR), discovering that layers with more outliers\ntend to be more heavy-tailed and consequently better trained. Inspired by this\nfinding, OwLore strategically assigns higher sampling probabilities to layers\nwith more outliers to better leverage the knowledge stored in pre-trained LLMs.\nTo further mitigate the memory demands of fine-tuning, we integrate gradient\nlow-rank projection into our approach, which facilitates each layer to be\nefficiently trained in a low-rank manner. By incorporating the efficient\ncharacteristics of low-rank and optimal layerwise sampling, OwLore\nsignificantly improves the memory-performance trade-off in LLM pruning. Our\nextensive experiments across various architectures, including LLaMa2, LLaMa3,\nand Mistral, demonstrate that OwLore consistently outperforms baseline\napproaches, including full fine-tuning. Specifically, it achieves up to a 1.1%\naverage accuracy gain on the Commonsense Reasoning benchmark, a 3.0%\nimprovement on MMLU, and a notable 10% boost on MT-Bench, while being more\nmemory efficient. OwLore allows us to fine-tune LLaMa2-7B with only 21GB of\nmemory.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Pengxiang Li",
            "Lu Yin",
            "Xiaowei Gao",
            "Shiwei Liu"
        ],
        "published": "2024-05-28T17:22:22Z"
    },
    {
        "title": "A Canonization Perspective on Invariant and Equivariant Learning",
        "link": "http://arxiv.org/abs/2405.18378v2",
        "abstract": "In many applications, we desire neural networks to exhibit invariance or\nequivariance to certain groups due to symmetries inherent in the data.\nRecently, frame-averaging methods emerged to be a unified framework for\nattaining symmetries efficiently by averaging over input-dependent subsets of\nthe group, i.e., frames. What we currently lack is a principled understanding\nof the design of frames. In this work, we introduce a canonization perspective\nthat provides an essential and complete view of the design of frames.\nCanonization is a classic approach for attaining invariance by mapping inputs\nto their canonical forms. We show that there exists an inherent connection\nbetween frames and canonical forms. Leveraging this connection, we can\nefficiently compare the complexity of frames as well as determine the\noptimality of certain frames. Guided by this principle, we design novel frames\nfor eigenvectors that are strictly superior to existing methods -- some are\neven optimal -- both theoretically and empirically. The reduction to the\ncanonization perspective further uncovers equivalences between previous\nmethods. These observations suggest that canonization provides a fundamental\nunderstanding of existing frame-averaging methods and unifies existing\nequivariant and invariant learning methods.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "George Ma",
            "Yifei Wang",
            "Derek Lim",
            "Stefanie Jegelka",
            "Yisen Wang"
        ],
        "published": "2024-05-28T17:22:15Z"
    },
    {
        "title": "A Note on the Prediction-Powered Bootstrap",
        "link": "http://arxiv.org/abs/2405.18379v1",
        "abstract": "We introduce PPBoot: a bootstrap-based method for prediction-powered\ninference. PPBoot is applicable to arbitrary estimation problems and is very\nsimple to implement, essentially only requiring one application of the\nbootstrap. Through a series of examples, we demonstrate that PPBoot often\nperforms nearly identically to (and sometimes better than) the earlier PPI(++)\nmethod based on asymptotic normality$\\unicode{x2013}$when the latter is\napplicable$\\unicode{x2013}$without requiring any asymptotic characterizations.\nGiven its versatility, PPBoot could simplify and expand the scope of\napplication of prediction-powered inference to problems where central limit\ntheorems are hard to prove.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "authors": [
            "Tijana Zrnic"
        ],
        "published": "2024-05-28T17:22:15Z"
    },
    {
        "title": "LLaMA-NAS: Efficient Neural Architecture Search for Large Language\n  Models",
        "link": "http://arxiv.org/abs/2405.18377v1",
        "abstract": "The abilities of modern large language models (LLMs) in solving natural\nlanguage processing, complex reasoning, sentiment analysis and other tasks have\nbeen extraordinary which has prompted their extensive adoption. Unfortunately,\nthese abilities come with very high memory and computational costs which\nprecludes the use of LLMs on most hardware platforms. To mitigate this, we\npropose an effective method of finding Pareto-optimal network architectures\nbased on LLaMA2-7B using one-shot NAS. In particular, we fine-tune LLaMA2-7B\nonly once and then apply genetic algorithm-based search to find smaller, less\ncomputationally complex network architectures. We show that, for certain\nstandard benchmark tasks, the pre-trained LLaMA2-7B network is unnecessarily\nlarge and complex. More specifically, we demonstrate a 1.5x reduction in model\nsize and 1.3x speedup in throughput for certain tasks with negligible drop in\naccuracy. In addition to finding smaller, higher-performing network\narchitectures, our method does so more effectively and efficiently than certain\npruning or sparsification techniques. Finally, we demonstrate how quantization\nis complementary to our method and that the size and complexity of the networks\nwe find can be further decreased using quantization. We believe that our work\nprovides a way to automatically create LLMs which can be used on less expensive\nand more readily available hardware platforms.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Anthony Sarah",
            "Sharath Nittur Sridhar",
            "Maciej Szankin",
            "Sairam Sundaresan"
        ],
        "published": "2024-05-28T17:20:44Z"
    },
    {
        "title": "Empowering Source-Free Domain Adaptation with MLLM-driven Curriculum\n  Learning",
        "link": "http://arxiv.org/abs/2405.18376v1",
        "abstract": "Source-Free Domain Adaptation (SFDA) aims to adapt a pre-trained source model\nto a target domain using only unlabeled target data. Current SFDA methods face\nchallenges in effectively leveraging pre-trained knowledge and exploiting\ntarget domain data. Multimodal Large Language Models (MLLMs) offer remarkable\ncapabilities in understanding visual and textual information, but their\napplicability to SFDA poses challenges such as instruction-following failures,\nintensive computational demands, and difficulties in performance measurement\nprior to adaptation. To alleviate these issues, we propose Reliability-based\nCurriculum Learning (RCL), a novel framework that integrates multiple MLLMs for\nknowledge exploitation via pseudo-labeling in SFDA. Our framework incorporates\nproposed Reliable Knowledge Transfer, Self-correcting and MLLM-guided Knowledge\nExpansion, and Multi-hot Masking Refinement to progressively exploit unlabeled\ndata in the target domain. RCL achieves state-of-the-art (SOTA) performance on\nmultiple SFDA benchmarks, e.g., $\\textbf{+9.4%}$ on DomainNet, demonstrating\nits effectiveness in enhancing adaptability and robustness without requiring\naccess to source data. Code: https://github.com/Dong-Jie-Chen/RCL.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Dongjie Chen",
            "Kartik Patwari",
            "Zhengfeng Lai",
            "Sen-ching Cheung",
            "Chen-Nee Chuah"
        ],
        "published": "2024-05-28T17:18:17Z"
    },
    {
        "title": "Thai Winograd Schemas: A Benchmark for Thai Commonsense Reasoning",
        "link": "http://arxiv.org/abs/2405.18375v1",
        "abstract": "Commonsense reasoning is one of the important aspect of natural language\nunderstanding, with several benchmarks developed to evaluate it. However, only\na few of these benchmarks are available in languages other than English.\nDeveloping parallel benchmarks facilitates cross-lingual evaluation, enabling a\nbetter understanding of different languages. This research introduces a\ncollection of Winograd Schemas in Thai, a novel dataset designed to evaluate\ncommonsense reasoning capabilities in the context of the Thai language.\n  Through a methodology involving native speakers, professional translators,\nand thorough validation, the schemas aim to closely reflect Thai language\nnuances, idioms, and cultural references while maintaining ambiguity and\ncommonsense challenges. We evaluate the performance of popular large language\nmodels on this benchmark, revealing their strengths, limitations, and providing\ninsights into the current state-of-the-art. Results indicate that while models\nlike GPT-4 and Claude-3-Opus achieve high accuracy in English, their\nperformance significantly drops in Thai, highlighting the need for further\nadvancements in multilingual commonsense reasoning.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Phakphum Artkaew"
        ],
        "published": "2024-05-28T17:14:02Z"
    },
    {
        "title": "Hostile Counterspeech Drives Users From Hate Subreddits",
        "link": "http://arxiv.org/abs/2405.18374v1",
        "abstract": "Counterspeech -- speech that opposes hate speech -- has gained significant\nattention recently as a strategy to reduce hate on social media. While previous\nstudies suggest that counterspeech can somewhat reduce hate speech, little is\nknown about its effects on participation in online hate communities, nor which\ncounterspeech tactics reduce harmful behavior. We begin to address these gaps\nby identifying 25 large hate communities (\"subreddits\") within Reddit and\nanalyzing the effect of counterspeech on newcomers within these communities. We\nfirst construct a new public dataset of carefully annotated counterspeech and\nnon-counterspeech comments within these subreddits. We use this dataset to\ntrain a state-of-the-art counterspeech detection model. Next, we use matching\nto evaluate the causal effects of hostile and non-hostile counterspeech on the\nengagement of newcomers in hate subreddits. We find that, while non-hostile\ncounterspeech is ineffective at keeping users from fully disengaging from these\nhate subreddits, a single hostile counterspeech comment substantially reduces\nboth future likelihood of engagement. While offering nuance to the\nunderstanding of counterspeech efficacy, these results a) leave unanswered the\nquestion of whether hostile counterspeech dissuades newcomers from\nparticipation in online hate writ large, or merely drives them into\nless-moderated and more extreme hate communities, and b) raises ethical\nconsiderations about hostile counterspeech, which is both comparatively common\nand might exacerbate rather than mitigate the net level of antagonism in\nsociety. These findings underscore the importance of future work to improve\ncounterspeech tactics and minimize unintended harm.",
        "subjects": [
            "cs.CY",
            "cs.HC"
        ],
        "authors": [
            "Daniel Hickey",
            "Matheus Schmitz",
            "Daniel M. T. Fessler",
            "Paul E. Smaldino",
            "Kristina Lerman",
            "Goran Murić",
            "Keith Burghardt"
        ],
        "published": "2024-05-28T17:12:41Z"
    },
    {
        "title": "A Hessian-Aware Stochastic Differential Equation for Modelling SGD",
        "link": "http://arxiv.org/abs/2405.18373v1",
        "abstract": "Continuous-time approximation of Stochastic Gradient Descent (SGD) is a\ncrucial tool to study its escaping behaviors from stationary points. However,\nexisting stochastic differential equation (SDE) models fail to fully capture\nthese behaviors, even for simple quadratic objectives. Built on a novel\nstochastic backward error analysis framework, we derive the Hessian-Aware\nStochastic Modified Equation (HA-SME), an SDE that incorporates Hessian\ninformation of the objective function into both its drift and diffusion terms.\nOur analysis shows that HA-SME matches the order-best approximation error\nguarantee among existing SDE models in the literature, while achieving a\nsignificantly reduced dependence on the smoothness parameter of the objective.\nFurther, for quadratic objectives, under mild conditions, HA-SME is proved to\nbe the first SDE model that recovers exactly the SGD dynamics in the\ndistributional sense. Consequently, when the local landscape near a stationary\npoint can be approximated by quadratics, HA-SME is expected to accurately\npredict the local escaping behaviors of SGD.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Xiang Li",
            "Zebang Shen",
            "Liang Zhang",
            "Niao He"
        ],
        "published": "2024-05-28T17:11:34Z"
    },
    {
        "title": "ML-QLS: Multilevel Quantum Layout Synthesis",
        "link": "http://arxiv.org/abs/2405.18371v1",
        "abstract": "Quantum Layout Synthesis (QLS) plays a crucial role in optimizing quantum\ncircuit execution on physical quantum devices. As we enter the era where\nquantum computers have hundreds of qubits, we are faced with scalability issues\nusing optimal approaches and degrading heuristic methods' performance due to\nthe lack of global optimization. To this end, we introduce a hybrid design that\nobtains the much improved solution for the heuristic method utilizing the\nmultilevel framework, which is an effective methodology to solve large-scale\nproblems in VLSI design. In this paper, we present ML-QLS, the first multilevel\nquantum layout tool with a scalable refinement operation integrated with novel\ncost functions and clustering strategies. Our clustering provides valuable\ninsights into generating a proper problem approximation for quantum circuits\nand devices. Our experimental results demonstrate that ML-QLS can scale up to\nproblems involving hundreds of qubits and achieve a remarkable 52% performance\nimprovement over leading heuristic QLS tools for large circuits, which\nunderscores the effectiveness of multilevel frameworks in quantum applications.",
        "subjects": [
            "quant-ph",
            "cs.AR",
            "cs.DC"
        ],
        "authors": [
            "Wan-Hsuan Lin",
            "Jason Cong"
        ],
        "published": "2024-05-28T17:10:20Z"
    },
    {
        "title": "PromptWizard: Task-Aware Agent-driven Prompt Optimization Framework",
        "link": "http://arxiv.org/abs/2405.18369v1",
        "abstract": "Large language models (LLMs) have revolutionized AI across diverse domains,\nshowcasing remarkable capabilities. Central to their success is the concept of\nprompting, which guides model output generation. However, manual prompt\nengineering is labor-intensive and domain-specific, necessitating automated\nsolutions. This paper introduces PromptWizard, a novel framework leveraging\nLLMs to iteratively synthesize and refine prompts tailored to specific tasks.\nUnlike existing approaches, PromptWizard optimizes both prompt instructions and\nin-context examples, maximizing model performance. The framework iteratively\nrefines prompts by mutating instructions and incorporating negative examples to\ndeepen understanding and ensure diversity. It further enhances both\ninstructions and examples with the aid of a critic, synthesizing new\ninstructions and examples enriched with detailed reasoning steps for optimal\nperformance. PromptWizard offers several key features and capabilities,\nincluding computational efficiency compared to state-of-the-art approaches,\nadaptability to scenarios with varying amounts of training data, and\neffectiveness with smaller LLMs. Rigorous evaluation across 35 tasks on 8\ndatasets demonstrates PromptWizard's superiority over existing prompt\nstrategies, showcasing its efficacy and scalability in prompt optimization.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Eshaan Agarwal",
            "Vivek Dani",
            "Tanuja Ganu",
            "Akshay Nambi"
        ],
        "published": "2024-05-28T17:08:31Z"
    },
    {
        "title": "The 2024 Brain Tumor Segmentation (BraTS) Challenge: Glioma Segmentation\n  on Post-treatment MRI",
        "link": "http://arxiv.org/abs/2405.18368v1",
        "abstract": "Gliomas are the most common malignant primary brain tumors in adults and one\nof the deadliest types of cancer. There are many challenges in treatment and\nmonitoring due to the genetic diversity and high intrinsic heterogeneity in\nappearance, shape, histology, and treatment response. Treatments include\nsurgery, radiation, and systemic therapies, with magnetic resonance imaging\n(MRI) playing a key role in treatment planning and post-treatment longitudinal\nassessment. The 2024 Brain Tumor Segmentation (BraTS) challenge on\npost-treatment glioma MRI will provide a community standard and benchmark for\nstate-of-the-art automated segmentation models based on the largest\nexpert-annotated post-treatment glioma MRI dataset. Challenge competitors will\ndevelop automated segmentation models to predict four distinct tumor\nsub-regions consisting of enhancing tissue (ET), surrounding non-enhancing\nT2/fluid-attenuated inversion recovery (FLAIR) hyperintensity (SNFH),\nnon-enhancing tumor core (NETC), and resection cavity (RC). Models will be\nevaluated on separate validation and test datasets using standardized\nperformance metrics utilized across the BraTS 2024 cluster of challenges,\nincluding lesion-wise Dice Similarity Coefficient and Hausdorff Distance.\nModels developed during this challenge will advance the field of automated MRI\nsegmentation and contribute to their integration into clinical practice,\nultimately enhancing patient care.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Maria Correia de Verdier",
            "Rachit Saluja",
            "Louis Gagnon",
            "Dominic LaBella",
            "Ujjwall Baid",
            "Nourel Hoda Tahon",
            "Martha Foltyn-Dumitru",
            "Jikai Zhang",
            "Maram Alafif",
            "Saif Baig",
            "Ken Chang",
            "Gennaro D'Anna",
            "Lisa Deptula",
            "Diviya Gupta",
            "Muhammad Ammar Haider",
            "Ali Hussain",
            "Michael Iv",
            "Marinos Kontzialis",
            "Paul Manning",
            "Farzan Moodi",
            "Teresa Nunes",
            "Aaron Simon",
            "Nico Sollmann",
            "David Vu",
            "Maruf Adewole",
            "Jake Albrecht",
            "Udunna Anazodo",
            "Rongrong Chai",
            "Verena Chung",
            "Shahriar Faghani",
            "Keyvan Farahani",
            "Anahita Fathi Kazerooni",
            "Eugenio Iglesias",
            "Florian Kofler",
            "Hongwei Li",
            "Marius George Linguraru",
            "Bjoern Menze",
            "Ahmed W. Moawad",
            "Yury Velichko",
            "Benedikt Wiestler",
            "Talissa Altes",
            "Patil Basavasagar",
            "Martin Bendszus",
            "Gianluca Brugnara",
            "Jaeyoung Cho",
            "Yaseen Dhemesh",
            "Brandon K. K. Fields",
            "Filip Garrett",
            "Jaime Gass",
            "Lubomir Hadjiiski",
            "Jona Hattangadi-Gluth",
            "Christopher Hess",
            "Jessica L. Houk",
            "Edvin Isufi",
            "Lester J. Layfield",
            "George Mastorakos",
            "John Mongan",
            "Pierre Nedelec",
            "Uyen Nguyen",
            "Sebastian Oliva",
            "Matthew W. Pease",
            "Aditya Rastogi",
            "Jason Sinclair",
            "Robert X. Smith",
            "Leo P. Sugrue",
            "Jonathan Thacker",
            "Igor Vidic",
            "Javier Villanueva-Meyer",
            "Nathan S. White",
            "Mariam Aboian",
            "Gian Marco Conte",
            "Anders Dale",
            "Mert R. Sabuncu",
            "Tyler M. Seibert",
            "Brent Weinberg",
            "Aly Abayazeed",
            "Raymond Huang",
            "Sevcan Turk",
            "Andreas M. Rauschecker",
            "Nikdokht Farid",
            "Philipp Vollmuth",
            "Ayman Nada",
            "Spyridon Bakas",
            "Evan Calabrese",
            "Jeffrey D. Rudie"
        ],
        "published": "2024-05-28T17:07:55Z"
    },
    {
        "title": "Black Hole Search in Dynamic Graphs",
        "link": "http://arxiv.org/abs/2405.18367v1",
        "abstract": "A black hole in a graph is a dangerous site that disposes any incoming agent\ninto that node without leaving any trace of its existence. In the Black Hole\nSearch (BHS) problem, the goal is for at least one agent to survive, locate the\nposition of the black hole, and then terminate. This problem has been\nextensively studied for static graphs, where the edges do not disappear with\ntime. In dynamic graphs, where the edges may disappear and reappear with time,\nthe problem has only been studied for specific graphs such as rings and\ncactuses. In this work, we investigate the problem of BHS for general graphs\nwith a much weaker model with respect to the one used for the cases of rings\nand cactus graphs\\cite{bhattacharya_2023, Paola_2024}. We consider two cases:\n(a) where the adversary can remove at most one edge in each round, and (b)\nwhere the adversary can remove at most $f$ edges in each round. In both\nscenarios, we consider rooted configuration.\n  In the case when the adversary can remove at most one edge from the graph, we\nprovide an algorithm that uses 9 agents to solve the BHS problem in $O(m^2)$\ntime given that each node $v$ is equipped with $O(\\log \\delta_v)$ storage in\nthe form of a whiteboard, where $m$ is the number of edges in $G$ and\n$\\delta_v$ is the degree of node $v$. We also prove that it is impossible for\n$2\\delta_{BH}$ many agents with $O(\\log n)$ memory to locate the black hole\nwhere $\\delta_{BH}$ is the degree of the black hole even if the nodes are\nequipped with whiteboards of $O(\\log \\delta_v)$ storage.\n  In a scenario where the adversary can remove at most $f$ edges and the\ninitial configuration is rooted, we present an algorithm that uses $6f$ agents\nto solve the BHS problem. We also prove that solving BHS using $2f+1$ agents\nstarting from a rooted configuration on a general graph is impossible, even\nwith unlimited node storage and infinite agent memory.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Tanvir Kaur",
            "Ashish Saxena",
            "Partha Sarathi Mandal",
            "Kaushik Mondal"
        ],
        "published": "2024-05-28T17:05:29Z"
    },
    {
        "title": "A comparison of mixed precision iterative refinement approaches for\n  least-squares problems",
        "link": "http://arxiv.org/abs/2405.18363v1",
        "abstract": "Various approaches to iterative refinement (IR) for least-squares problems\nhave been proposed in the literature and it may not be clear which approach is\nsuitable for a given problem. We consider three approaches to IR for\nleast-squares problems when two precisions are used and review their\ntheoretical guarantees, known shortcomings and when the method can be expected\nto recognize that the correct solution has been found, and extend uniform\nprecision analysis for an IR approach based on the semi-normal equations to the\ntwo-precision case. We focus on the situation where it is desired to refine the\nsolution to the working precision level. It is shown that the IR methods\nexhibit different sensitivities to the conditioning of the problem and the size\nof the least-squares residual, which should be taken into account when choosing\nthe IR approach. We also discuss a new approach that is based on solving\nmultiple least-squares problems.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Erin Carson",
            "Ieva Daužickaitė"
        ],
        "published": "2024-05-28T16:59:20Z"
    },
    {
        "title": "Improving Linear System Solvers for Hyperparameter Optimisation in\n  Iterative Gaussian Processes",
        "link": "http://arxiv.org/abs/2405.18457v1",
        "abstract": "Scaling hyperparameter optimisation to very large datasets remains an open\nproblem in the Gaussian process community. This paper focuses on iterative\nmethods, which use linear system solvers, like conjugate gradients, alternating\nprojections or stochastic gradient descent, to construct an estimate of the\nmarginal likelihood gradient. We discuss three key improvements which are\napplicable across solvers: (i) a pathwise gradient estimator, which reduces the\nrequired number of solver iterations and amortises the computational cost of\nmaking predictions, (ii) warm starting linear system solvers with the solution\nfrom the previous step, which leads to faster solver convergence at the cost of\nnegligible bias, (iii) early stopping linear system solvers after a limited\ncomputational budget, which synergises with warm starting, allowing solver\nprogress to accumulate over multiple marginal likelihood steps. These\ntechniques provide speed-ups of up to $72\\times$ when solving to tolerance, and\ndecrease the average residual norm by up to $7\\times$ when stopping early.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Jihao Andreas Lin",
            "Shreyas Padhy",
            "Bruno Mlodozeniec",
            "Javier Antorán",
            "José Miguel Hernández-Lobato"
        ],
        "published": "2024-05-28T16:58:37Z"
    },
    {
        "title": "Is a 3D-Tokenized LLM the Key to Reliable Autonomous Driving?",
        "link": "http://arxiv.org/abs/2405.18361v1",
        "abstract": "Rapid advancements in Autonomous Driving (AD) tasks turned a significant\nshift toward end-to-end fashion, particularly in the utilization of\nvision-language models (VLMs) that integrate robust logical reasoning and\ncognitive abilities to enable comprehensive end-to-end planning. However, these\nVLM-based approaches tend to integrate 2D vision tokenizers and a large\nlanguage model (LLM) for ego-car planning, which lack 3D geometric priors as a\ncornerstone of reliable planning. Naturally, this observation raises a critical\nconcern: Can a 2D-tokenized LLM accurately perceive the 3D environment? Our\nevaluation of current VLM-based methods across 3D object detection, vectorized\nmap construction, and environmental caption suggests that the answer is,\nunfortunately, NO. In other words, 2D-tokenized LLM fails to provide reliable\nautonomous driving. In response, we introduce DETR-style 3D perceptrons as 3D\ntokenizers, which connect LLM with a one-layer linear projector. This simple\nyet elegant strategy, termed Atlas, harnesses the inherent priors of the 3D\nphysical world, enabling it to simultaneously process high-resolution\nmulti-view images and employ spatiotemporal modeling. Despite its simplicity,\nAtlas demonstrates superior performance in both 3D detection and ego planning\ntasks on nuScenes dataset, proving that 3D-tokenized LLM is the key to reliable\nautonomous driving. The code and datasets will be released.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yifan Bai",
            "Dongming Wu",
            "Yingfei Liu",
            "Fan Jia",
            "Weixin Mao",
            "Ziheng Zhang",
            "Yucheng Zhao",
            "Jianbing Shen",
            "Xing Wei",
            "Tiancai Wang",
            "Xiangyu Zhang"
        ],
        "published": "2024-05-28T16:57:44Z"
    },
    {
        "title": "Bridging the Gap: Dynamic Learning Strategies for Improving Multilingual\n  Performance in LLMs",
        "link": "http://arxiv.org/abs/2405.18359v1",
        "abstract": "Large language models (LLMs) are at the forefront of transforming numerous\ndomains globally. However, their inclusivity and effectiveness remain limited\nfor non-Latin scripts and low-resource languages. This paper tackles the\nimperative challenge of enhancing the multilingual performance of LLMs without\nextensive training or fine-tuning. Through systematic investigation and\nevaluation of diverse languages using popular question-answering (QA) datasets,\nwe present novel techniques that unlock the true potential of LLMs in a\npolyglot landscape. Our approach encompasses three key strategies that yield\nsignificant improvements in multilingual proficiency. First, by meticulously\noptimizing prompts tailored for polyglot LLMs, we unlock their latent\ncapabilities, resulting in substantial performance boosts across languages.\nSecond, we introduce a new hybrid approach that synergizes LLM Retrieval\nAugmented Generation (RAG) with multilingual embeddings and achieves improved\nmultilingual task performance. Finally, we introduce a novel learning approach\nthat dynamically selects the optimal prompt strategy, LLM model, and embedding\nmodel per query at run-time. This dynamic adaptation maximizes the efficacy of\nLLMs across languages, outperforming best static and random strategies.\nAdditionally, our approach adapts configurations in both offline and online\nsettings, and can seamlessly adapt to new languages and datasets, leading to\nsubstantial advancements in multilingual understanding and generation across\ndiverse languages.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Somnath Kumar",
            "Vaibhav Balloli",
            "Mercy Ranjit",
            "Kabir Ahuja",
            "Tanuja Ganu",
            "Sunayana Sitaram",
            "Kalika Bali",
            "Akshay Nambi"
        ],
        "published": "2024-05-28T16:56:42Z"
    },
    {
        "title": "MMCTAgent: Multi-modal Critical Thinking Agent Framework for Complex\n  Visual Reasoning",
        "link": "http://arxiv.org/abs/2405.18358v1",
        "abstract": "Recent advancements in Multi-modal Large Language Models (MLLMs) have\nsignificantly improved their performance in tasks combining vision and\nlanguage. However, challenges persist in detailed multi-modal understanding,\ncomprehension of complex tasks, and reasoning over multi-modal information.\nThis paper introduces MMCTAgent, a novel multi-modal critical thinking agent\nframework designed to address the inherent limitations of current MLLMs in\ncomplex visual reasoning tasks. Inspired by human cognitive processes and\ncritical thinking, MMCTAgent iteratively analyzes multi-modal information,\ndecomposes queries, plans strategies, and dynamically evolves its reasoning.\nAdditionally, MMCTAgent incorporates critical thinking elements such as\nverification of final answers and self-reflection through a novel approach that\ndefines a vision-based critic and identifies task-specific evaluation criteria,\nthereby enhancing its decision-making abilities. Through rigorous evaluations\nacross various image and video understanding benchmarks, we demonstrate that\nMMCTAgent (with and without the critic) outperforms both foundational MLLMs and\nother tool-augmented pipelines.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Somnath Kumar",
            "Yash Gadhia",
            "Tanuja Ganu",
            "Akshay Nambi"
        ],
        "published": "2024-05-28T16:55:41Z"
    },
    {
        "title": "Faithful Logical Reasoning via Symbolic Chain-of-Thought",
        "link": "http://arxiv.org/abs/2405.18357v1",
        "abstract": "While the recent Chain-of-Thought (CoT) technique enhances the reasoning\nability of large language models (LLMs) with the theory of mind, it might still\nstruggle in handling logical reasoning that relies much on symbolic expressions\nand rigid deducing rules. To strengthen the logical reasoning capability of\nLLMs, we propose a novel Symbolic Chain-of-Thought, namely SymbCoT, a fully\nLLM-based framework that integrates symbolic expressions and logic rules with\nCoT prompting. Technically, building upon an LLM, SymbCoT 1) first translates\nthe natural language context into the symbolic format, and then 2) derives a\nstep-by-step plan to solve the problem with symbolic logical rules, 3) followed\nby a verifier to check the translation and reasoning chain. Via thorough\nevaluations on 5 standard datasets with both First-Order Logic and Constraint\nOptimization symbolic expressions, SymbCoT shows striking improvements over the\nCoT method consistently, meanwhile refreshing the current state-of-the-art\nperformances. We further demonstrate that our system advances in more faithful,\nflexible, and explainable logical reasoning. To our knowledge, this is the\nfirst to combine symbolic expressions and rules into CoT for logical reasoning\nwith LLMs. Code is open at https://github.com/Aiden0526/SymbCoT.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Jundong Xu",
            "Hao Fei",
            "Liangming Pan",
            "Qian Liu",
            "Mong-Li Lee",
            "Wynne Hsu"
        ],
        "published": "2024-05-28T16:55:33Z"
    },
    {
        "title": "Universal and Extensible Language-Vision Models for Organ Segmentation\n  and Tumor Detection from Abdominal Computed Tomography",
        "link": "http://arxiv.org/abs/2405.18356v1",
        "abstract": "The advancement of artificial intelligence (AI) for organ segmentation and\ntumor detection is propelled by the growing availability of computed tomography\n(CT) datasets with detailed, per-voxel annotations. However, these AI models\noften struggle with flexibility for partially annotated datasets and\nextensibility for new classes due to limitations in the one-hot encoding,\narchitectural design, and learning scheme. To overcome these limitations, we\npropose a universal, extensible framework enabling a single model, termed\nUniversal Model, to deal with multiple public datasets and adapt to new classes\n(e.g., organs/tumors). Firstly, we introduce a novel language-driven parameter\ngenerator that leverages language embeddings from large language models,\nenriching semantic encoding compared with one-hot encoding. Secondly, the\nconventional output layers are replaced with lightweight, class-specific heads,\nallowing Universal Model to simultaneously segment 25 organs and six types of\ntumors and ease the addition of new classes. We train our Universal Model on\n3,410 CT volumes assembled from 14 publicly available datasets and then test it\non 6,173 CT volumes from four external datasets. Universal Model achieves first\nplace on six CT tasks in the Medical Segmentation Decathlon (MSD) public\nleaderboard and leading performance on the Beyond The Cranial Vault (BTCV)\ndataset. In summary, Universal Model exhibits remarkable computational\nefficiency (6x faster than other dataset-specific models), demonstrates strong\ngeneralization across different hospitals, transfers well to numerous\ndownstream tasks, and more importantly, facilitates the extensibility to new\nclasses while alleviating the catastrophic forgetting of previously learned\nclasses. Codes, models, and datasets are available at\nhttps://github.com/ljwztc/CLIP-Driven-Universal-Model",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Jie Liu",
            "Yixiao Zhang",
            "Kang Wang",
            "Mehmet Can Yavuz",
            "Xiaoxi Chen",
            "Yixuan Yuan",
            "Haoliang Li",
            "Yang Yang",
            "Alan Yuille",
            "Yucheng Tang",
            "Zongwei Zhou"
        ],
        "published": "2024-05-28T16:55:15Z"
    },
    {
        "title": "Simulating infinite-dimensional nonlinear diffusion bridges",
        "link": "http://arxiv.org/abs/2405.18353v1",
        "abstract": "The diffusion bridge is a type of diffusion process that conditions on\nhitting a specific state within a finite time period. It has broad applications\nin fields such as Bayesian inference, financial mathematics, control theory,\nand shape analysis. However, simulating the diffusion bridge for natural data\ncan be challenging due to both the intractability of the drift term and\ncontinuous representations of the data. Although several methods are available\nto simulate finite-dimensional diffusion bridges, infinite-dimensional cases\nremain unresolved. In the paper, we present a solution to this problem by\nmerging score-matching techniques with operator learning, enabling a direct\napproach to score-matching for the infinite-dimensional bridge. We construct\nthe score to be discretization invariant, which is natural given the underlying\nspatially continuous process. We conduct a series of experiments, ranging from\nsynthetic examples with closed-form solutions to the stochastic nonlinear\nevolution of real-world biological shape data, and our method demonstrates high\nefficacy, particularly due to its ability to adapt to any resolution without\nextra training.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Gefan Yang",
            "Elizabeth Louise Baker",
            "Michael L. Severinsen",
            "Christy Anna Hipsley",
            "Stefan Sommer"
        ],
        "published": "2024-05-28T16:52:52Z"
    },
    {
        "title": "Evolutionary Algorithms for Optimizing Emergency Exit Placement in\n  Indoor Environments",
        "link": "http://dx.doi.org/10.1007/978-3-031-56852-7_13",
        "abstract": "The problem of finding the optimal placement of emergency exits in an indoor\nenvironment to facilitate the rapid and orderly evacuation of crowds is\naddressed in this work. A cellular-automaton model is used to simulate the\nbehavior of pedestrians in such scenarios, taking into account factors such as\nthe environment, the pedestrians themselves, and the interactions among them. A\nmetric is proposed to determine how successful or satisfactory an evacuation\nwas. Subsequently, two metaheuristic algorithms, namely an iterated greedy\nheuristic and an evolutionary algorithm (EA) are proposed to solve the\noptimization problem. A comparative analysis shows that the proposed EA is able\nto find effective solutions for different scenarios, and that an island-based\nversion of it outperforms the other two algorithms in terms of solution\nquality.",
        "subjects": [
            "cs.NE"
        ],
        "authors": [
            "Carlos Cotta",
            "José E. Gallardo"
        ],
        "published": "2024-05-28T16:50:42Z"
    },
    {
        "title": "Evaluating Bayesian deep learning for radio galaxy classification",
        "link": "http://arxiv.org/abs/2405.18351v1",
        "abstract": "The radio astronomy community is rapidly adopting deep learning techniques to\ndeal with the huge data volumes expected from the next generation of radio\nobservatories. Bayesian neural networks (BNNs) provide a principled way to\nmodel uncertainty in the predictions made by such deep learning models and will\nplay an important role in extracting well-calibrated uncertainty estimates on\ntheir outputs. In this work, we evaluate the performance of different BNNs\nagainst the following criteria: predictive performance, uncertainty calibration\nand distribution-shift detection for the radio galaxy classification problem.",
        "subjects": [
            "cs.LG",
            "astro-ph.IM"
        ],
        "authors": [
            "Devina Mohan",
            "Anna M. M. Scaife"
        ],
        "published": "2024-05-28T16:49:28Z"
    },
    {
        "title": "A System for Automatic English Text Expansion",
        "link": "http://dx.doi.org/10.1109/ACCESS.2019.2937505",
        "abstract": "We present an automatic text expansion system to generate English sentences,\nwhich performs automatic Natural Language Generation (NLG) by combining\nlinguistic rules with statistical approaches. Here, \"automatic\" means that the\nsystem can generate coherent and correct sentences from a minimum set of words.\nFrom its inception, the design is modular and adaptable to other languages.\nThis adaptability is one of its greatest advantages. For English, we have\ncreated the highly precise aLexiE lexicon with wide coverage, which represents\na contribution on its own. We have evaluated the resulting NLG library in an\nAugmentative and Alternative Communication (AAC) proof of concept, both\ndirectly (by regenerating corpus sentences) and manually (from annotations)\nusing a popular corpus in the NLG field. We performed a second analysis by\ncomparing the quality of text expansion in English to Spanish, using an ad-hoc\nSpanish-English parallel corpus. The system might also be applied to other\ndomains such as report and news generation.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Silvia García Méndez",
            "Milagros Fernández Gavilanes",
            "Enrique Costa Montenegro",
            "Jonathan Juncal Martínez",
            "Francisco Javier González Castaño",
            "Ehud Reiter"
        ],
        "published": "2024-05-28T16:48:05Z"
    },
    {
        "title": "Can Automatic Metrics Assess High-Quality Translations?",
        "link": "http://arxiv.org/abs/2405.18348v1",
        "abstract": "Automatic metrics for evaluating translation quality are typically validated\nby measuring how well they correlate with human assessments. However,\ncorrelation methods tend to capture only the ability of metrics to\ndifferentiate between good and bad source-translation pairs, overlooking their\nreliability in distinguishing alternative translations for the same source. In\nthis paper, we confirm that this is indeed the case by showing that current\nmetrics are insensitive to nuanced differences in translation quality. This\neffect is most pronounced when the quality is high and the variance among\nalternatives is low. Given this finding, we shift towards detecting\nhigh-quality correct translations, an important problem in practical\ndecision-making scenarios where a binary check of correctness is prioritized\nover a nuanced evaluation of quality. Using the MQM framework as the gold\nstandard, we systematically stress-test the ability of current metrics to\nidentify translations with no errors as marked by humans. Our findings reveal\nthat current metrics often over or underestimate translation quality,\nindicating significant room for improvement in automatic evaluation methods.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Sweta Agrawal",
            "António Farinhas",
            "Ricardo Rei",
            "André F. T. Martins"
        ],
        "published": "2024-05-28T16:44:02Z"
    },
    {
        "title": "Dataset Growth",
        "link": "http://arxiv.org/abs/2405.18347v1",
        "abstract": "Deep learning benefits from the growing abundance of available data.\nMeanwhile, efficiently dealing with the growing data scale has become a\nchallenge. Data publicly available are from different sources with various\nqualities, and it is impractical to do manual cleaning against noise and\nredundancy given today's data scale. There are existing techniques for\ncleaning/selecting the collected data. However, these methods are mainly\nproposed for offline settings that target one of the cleanness and redundancy\nproblems. In practice, data are growing exponentially with both problems. This\nleads to repeated data curation with sub-optimal efficiency. To tackle this\nchallenge, we propose InfoGrowth, an efficient online algorithm for data\ncleaning and selection, resulting in a growing dataset that keeps up to date\nwith awareness of cleanliness and diversity. InfoGrowth can improve data\nquality/efficiency on both single-modal and multi-modal tasks, with an\nefficient and scalable design. Its framework makes it practical for real-world\ndata engines.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ziheng Qin",
            "Zhaopan Xu",
            "Yukun Zhou",
            "Zangwei Zheng",
            "Zebang Cheng",
            "Hao Tang",
            "Lei Shang",
            "Baigui Sun",
            "Xiaojiang Peng",
            "Radu Timofte",
            "Hongxun Yao",
            "Kai Wang",
            "Yang You"
        ],
        "published": "2024-05-28T16:43:57Z"
    },
    {
        "title": "Intelligent Clinical Documentation: Harnessing Generative AI for\n  Patient-Centric Clinical Note Generation",
        "link": "http://dx.doi.org/10.38124/ijisrt/IJISRT24MAY1483",
        "abstract": "Comprehensive clinical documentation is crucial for effective healthcare\ndelivery, yet it poses a significant burden on healthcare professionals,\nleading to burnout, increased medical errors, and compromised patient safety.\nThis paper explores the potential of generative AI (Artificial Intelligence) to\nstreamline the clinical documentation process, specifically focusing on\ngenerating SOAP (Subjective, Objective, Assessment, Plan) and BIRP (Behavior,\nIntervention, Response, Plan) notes. We present a case study demonstrating the\napplication of natural language processing (NLP) and automatic speech\nrecognition (ASR) technologies to transcribe patient-clinician interactions,\ncoupled with advanced prompting techniques to generate draft clinical notes\nusing large language models (LLMs). The study highlights the benefits of this\napproach, including time savings, improved documentation quality, and enhanced\npatient-centered care. Additionally, we discuss ethical considerations, such as\nmaintaining patient confidentiality and addressing model biases, underscoring\nthe need for responsible deployment of generative AI in healthcare settings.\nThe findings suggest that generative AI has the potential to revolutionize\nclinical documentation practices, alleviating administrative burdens and\nenabling healthcare professionals to focus more on direct patient care.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Anjanava Biswas",
            "Wrick Talukdar"
        ],
        "published": "2024-05-28T16:43:41Z"
    },
    {
        "title": "The Battle of LLMs: A Comparative Study in Conversational QA Tasks",
        "link": "http://arxiv.org/abs/2405.18344v1",
        "abstract": "Large language models have gained considerable interest for their impressive\nperformance on various tasks. Within this domain, ChatGPT and GPT-4, developed\nby OpenAI, and the Gemini, developed by Google, have emerged as particularly\npopular among early adopters. Additionally, Mixtral by Mistral AI and Claude by\nAnthropic are newly released, further expanding the landscape of advanced\nlanguage models. These models are viewed as disruptive technologies with\napplications spanning customer service, education, healthcare, and finance.\nMore recently, Mistral has entered the scene, captivating users with its unique\nability to generate creative content. Understanding the perspectives of these\nusers is crucial, as they can offer valuable insights into the potential\nstrengths, weaknesses, and overall success or failure of these technologies in\nvarious domains. This research delves into the responses generated by ChatGPT,\nGPT-4, Gemini, Mixtral and Claude across different Conversational QA corpora.\nEvaluation scores were meticulously computed and subsequently compared to\nascertain the overall performance of these models. Our study pinpointed\ninstances where these models provided inaccurate answers to questions, offering\ninsights into potential areas where they might be susceptible to errors. In\nessence, this research provides a comprehensive comparison and evaluation of\nthese state of-the-art language models, shedding light on their capabilities\nwhile also highlighting potential areas for improvement",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "I.7, I.m"
        ],
        "authors": [
            "Aryan Rangapur",
            "Aman Rangapur"
        ],
        "published": "2024-05-28T16:42:43Z"
    },
    {
        "title": "What characteristics define disinformation and fake news?: review of\n  taxonomies and definitions",
        "link": "http://arxiv.org/abs/2405.18339v1",
        "abstract": "What characteristics define disinformation and fake news? To address this\nresearch question, this Technical Note provides a comprehensive analysis of\ndisinformation and fake news, synthesizing 46 definitions and highlighting four\nkey points addressing their fundamental characteristics. Adopting the Prisma\n2020 method, five search sets with the Boolean operator AND were selected in\nboth Portuguese and English, which were applied across four databases,\nresulting in 237 reviewed articles. Following a meticulous analysis, relevant\narticles were identified and included, while duplicates and inaccessible\ndocuments were excluded. It points to disinformation as information that is\ntotally or partially false, crafted by a sender with the aim of misleading,\nwith opportunistic content designed to manipulate reality, being amplified by\nindividual characteristics of the receiver in their interpretation and by\ncontextual factors in which they are embedded. This Technical Note seeks to\ncontribute to an understanding of the phenomenon of disinformation that\nincludes the contextual dimension, obtaining as fundamental elements of\nanalysis: I.) Sender; II.) Content; III.) Receiver; and IV.) Environment.",
        "subjects": [
            "cs.CY",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Ergon Cugler de Moraes Silva",
            "Jose Carlos Vaz"
        ],
        "published": "2024-05-28T16:32:24Z"
    },
    {
        "title": "Approximating Densest Subgraph in Geometric Intersection Graphs",
        "link": "http://arxiv.org/abs/2405.18337v1",
        "abstract": "$ \\newcommand{\\cardin}[1]{\\left| {#1} \\right|}%\n\\newcommand{\\Graph}{\\Mh{\\mathsf{G}}}% \\providecommand{\\G}{\\Graph}%\n\\renewcommand{\\G}{\\Graph}% \\providecommand{\\GA}{\\Mh{H}}%\n\\renewcommand{\\GA}{\\Mh{H}}% \\newcommand{\\VV}{\\Mh{\\mathsf{V}}}%\n\\newcommand{\\VX}[1]{\\VV\\pth{#1}}% \\providecommand{\\EE}{\\Mh{\\mathsf{E}}}%\n\\renewcommand{\\EE}{\\Mh{\\mathsf{E}}}% \\newcommand{\\Re}{\\mathbb{R}}\n\\newcommand{\\reals}{\\mathbb{R}} \\newcommand{\\SetX}{\\mathsf{X}}\n\\newcommand{\\rad}{r} \\newcommand{\\Mh}[1]{#1} \\newcommand{\\query}{q}\n\\newcommand{\\eps}{\\varepsilon} \\newcommand{\\VorX}[1]{\\mathcal{V} \\pth{#1}}\n\\newcommand{\\Polygon}{\\mathsf{P}} \\newcommand{\\IntRange}[1]{[ #1 ]}\n\\newcommand{\\Space}{\\overline{\\mathsf{m}}}\n\\newcommand{\\pth}[2][\\!]{#1\\left({#2}\\right)}\n\\newcommand{\\polylog}{\\mathrm{polylog}} \\newcommand{\\N}{\\mathbb N}\n\\newcommand{\\Z}{\\mathbb Z} \\newcommand{\\pt}{p} \\newcommand{\\distY}[2]{\\left\\|\n{#1} - {#2} \\right\\|} \\newcommand{\\ptq}{q} \\newcommand{\\pts}{s}$ For an\nundirected graph $\\mathsf{G}=(\\mathsf{V}, \\mathsf{E})$, with $n$ vertices and\n$m$ edges, the \\emph{densest subgraph} problem, is to compute a subset $S\n\\subseteq \\mathsf{V}$ which maximizes the ratio $|\\mathsf{E}_S| / |S|$, where\n$\\mathsf{E}_S \\subseteq \\mathsf{E}$ is the set of all edges of $\\mathsf{G}$\nwith endpoints in $S$. The densest subgraph problem is a well studied problem\nin computer science. Existing exact and approximation algorithms for computing\nthe densest subgraph require $\\Omega(m)$ time. We present near-linear time (in\n$n$) approximation algorithms for the densest subgraph problem on\n\\emph{implicit} geometric intersection graphs, where the vertices are\nexplicitly given but not the edges. As a concrete example, we consider $n$\ndisks in the plane with arbitrary radii and present two different approximation\nalgorithms.",
        "subjects": [
            "cs.CG"
        ],
        "authors": [
            "Sariel Har-Peled",
            "Rahul Saladi"
        ],
        "published": "2024-05-28T16:30:36Z"
    },
    {
        "title": "Interpretable classification of wiki-review streams",
        "link": "http://dx.doi.org/10.1109/ACCESS.2023.3342472",
        "abstract": "Wiki articles are created and maintained by a crowd of editors, producing a\ncontinuous stream of reviews. Reviews can take the form of additions, reverts,\nor both. This crowdsourcing model is exposed to manipulation since neither\nreviews nor editors are automatically screened and purged. To protect articles\nagainst vandalism or damage, the stream of reviews can be mined to classify\nreviews and profile editors in real-time. The goal of this work is to\nanticipate and explain which reviews to revert. This way, editors are informed\nwhy their edits will be reverted. The proposed method employs stream-based\nprocessing, updating the profiling and classification models on each incoming\nevent. The profiling uses side and content-based features employing Natural\nLanguage Processing, and editor profiles are incrementally updated based on\ntheir reviews. Since the proposed method relies on self-explainable\nclassification algorithms, it is possible to understand why a review has been\nclassified as a revert or a non-revert. In addition, this work contributes an\nalgorithm for generating synthetic data for class balancing, making the final\nclassification fairer. The proposed online method was tested with a real data\nset from Wikivoyage, which was balanced through the aforementioned synthetic\ndata generation. The results attained near-90 % values for all evaluation\nmetrics (accuracy, precision, recall, and F-measure).",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Silvia García Méndez",
            "Fátima Leal",
            "Benedita Malheiro",
            "Juan Carlos Burguillo Rial"
        ],
        "published": "2024-05-28T16:28:58Z"
    },
    {
        "title": "SketchQL Demonstration: Zero-shot Video Moment Querying with Sketches",
        "link": "http://arxiv.org/abs/2405.18334v1",
        "abstract": "In this paper, we will present SketchQL, a video database management system\n(VDBMS) for retrieving video moments with a sketch-based query interface. This\nnovel interface allows users to specify object trajectory events with simple\nmouse drag-and-drop operations. Users can use trajectories of single objects as\nbuilding blocks to compose complex events. Using a pre-trained model that\nencodes trajectory similarity, SketchQL achieves zero-shot video moments\nretrieval by performing similarity searches over the video to identify clips\nthat are the most similar to the visual query. In this demonstration, we\nintroduce the graphic user interface of SketchQL and detail its functionalities\nand interaction mechanisms. We also demonstrate the end-to-end usage of\nSketchQL from query composition to video moments retrieval using real-world\nscenarios.",
        "subjects": [
            "cs.DB",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Renzhi Wu",
            "Pramod Chunduri",
            "Dristi J Shah",
            "Ashmitha Julius Aravind",
            "Ali Payani",
            "Xu Chu",
            "Joy Arulraj",
            "Kexin Rong"
        ],
        "published": "2024-05-28T16:28:51Z"
    },
    {
        "title": "On the analysis of a higher-order Lotka-Volterra model: an application\n  of S-tensors and the polynomial complementarity problem",
        "link": "http://arxiv.org/abs/2405.18333v1",
        "abstract": "It is known that the effect of species' density on species' growth is\nnon-additive in real ecological systems. This challenges the conventional\nLotka-Volterra model, where the interactions are always pairwise and their\neffects are additive. To address this challenge, we introduce HOIs\n(Higher-Order Interactions) which are able to capture, for example, the\nindirect effect of one species on a second one correlating to a third species.\nTowards this end, we propose a general higher-order Lotka-Volterra model. We\nprovide an existence result of a positive equilibrium for a non-homogeneous\npolynomial equation system with the help of S-tensors. Afterward, by utilizing\nthe latter result, as well as the theory of monotone systems and results from\nthe polynomial complementarity problem, we provide comprehensive results\nregarding the existence, uniqueness, and stability of the corresponding\nequilibrium. These results can be regarded as natural extensions of many\nanalogous ones for the classical Lotka-Volterra model, especially in the case\nof full cooperation, competition among two factions, and pure competition.\nFinally, illustrative numerical examples are provided to highlight our\ncontributions.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Shaoxuan Cui",
            "Qi Zhao",
            "Guofeng Zhang",
            "Hildeberto Jardón-Kojakhmetov",
            "Ming Cao"
        ],
        "published": "2024-05-28T16:28:28Z"
    },
    {
        "title": "Frustratingly Easy Test-Time Adaptation of Vision-Language Models",
        "link": "http://arxiv.org/abs/2405.18330v1",
        "abstract": "Vision-Language Models seamlessly discriminate among arbitrary semantic\ncategories, yet they still suffer from poor generalization when presented with\nchallenging examples. For this reason, Episodic Test-Time Adaptation (TTA)\nstrategies have recently emerged as powerful techniques to adapt VLMs in the\npresence of a single unlabeled image. The recent literature on TTA is dominated\nby the paradigm of prompt tuning by Marginal Entropy Minimization, which,\nrelying on online backpropagation, inevitably slows down inference while\nincreasing memory. In this work, we theoretically investigate the properties of\nthis approach and unveil that a surprisingly strong TTA method lies dormant and\nhidden within it. We term this approach ZERO (TTA with \"zero\" temperature),\nwhose design is both incredibly effective and frustratingly simple: augment N\ntimes, predict, retain the most confident predictions, and marginalize after\nsetting the Softmax temperature to zero. Remarkably, ZERO requires a single\nbatched forward pass through the vision encoder only and no backward passes. We\nthoroughly evaluate our approach following the experimental protocol\nestablished in the literature and show that ZERO largely surpasses or compares\nfavorably w.r.t. the state-of-the-art while being almost 10x faster and 13x\nmore memory-friendly than standard Test-Time Prompt Tuning. Thanks to its\nsimplicity and comparatively negligible computation, ZERO can serve as a strong\nbaseline for future work in this field. The code is available at\nhttps://github.com/FarinaMatteo/zero.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Matteo Farina",
            "Gianni Franchi",
            "Giovanni Iacca",
            "Massimiliano Mancini",
            "Elisa Ricci"
        ],
        "published": "2024-05-28T16:24:47Z"
    },
    {
        "title": "Warm Start Marginal Likelihood Optimisation for Iterative Gaussian\n  Processes",
        "link": "http://arxiv.org/abs/2405.18328v1",
        "abstract": "Gaussian processes are a versatile probabilistic machine learning model whose\neffectiveness often depends on good hyperparameters, which are typically\nlearned by maximising the marginal likelihood. In this work, we consider\niterative methods, which use iterative linear system solvers to approximate\nmarginal likelihood gradients up to a specified numerical precision, allowing a\ntrade-off between compute time and accuracy of a solution. We introduce a\nthree-level hierarchy of marginal likelihood optimisation for iterative\nGaussian processes, and identify that the computational costs are dominated by\nsolving sequential batches of large positive-definite systems of linear\nequations. We then propose to amortise computations by reusing solutions of\nlinear system solvers as initialisations in the next step, providing a\n$\\textit{warm start}$. Finally, we discuss the necessary conditions and\nquantify the consequences of warm starts and demonstrate their effectiveness on\nregression tasks, where warm starts achieve the same results as the\nconventional procedure while providing up to a $16 \\times$ average speed-up\namong datasets.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Jihao Andreas Lin",
            "Shreyas Padhy",
            "Bruno Mlodozeniec",
            "José Miguel Hernández-Lobato"
        ],
        "published": "2024-05-28T16:22:18Z"
    },
    {
        "title": "Histopathology Based AI Model Predicts Anti-Angiogenic Therapy Response\n  in Renal Cancer Clinical Trial",
        "link": "http://arxiv.org/abs/2405.18327v1",
        "abstract": "Predictive biomarkers of treatment response are lacking for metastatic clear\ncell renal cell carcinoma (ccRCC), a tumor type that is treated with\nangiogenesis inhibitors, immune checkpoint inhibitors, mTOR inhibitors and a\nHIF2 inhibitor. The Angioscore, an RNA-based quantification of angiogenesis, is\narguably the best candidate to predict anti-angiogenic (AA) response. However,\nthe clinical adoption of transcriptomic assays faces several challenges\nincluding standardization, time delay, and high cost. Further, ccRCC tumors are\nhighly heterogenous, and sampling multiple areas for sequencing is impractical.\nHere we present a novel deep learning (DL) approach to predict the Angioscore\nfrom ubiquitous histopathology slides. To overcome the lack of\ninterpretability, one of the biggest limitations of typical DL models, our\nmodel produces a visual vascular network which is the basis of the model's\nprediction. To test its reliability, we applied this model to multiple cohorts\nincluding a clinical trial dataset. Our model accurately predicts the RNA-based\nAngioscore on multiple independent cohorts (spearman correlations of 0.77 and\n0.73). Further, the predictions help unravel meaningful biology such as\nassociation of angiogenesis with grade, stage, and driver mutation status.\nFinally, we find our model can predict response to AA therapy, in both a\nreal-world cohort and the IMmotion150 clinical trial. The predictive power of\nour model vastly exceeds that of CD31, a marker of vasculature, and nearly\nrivals the performance (c-index 0.66 vs 0.67) of the ground truth RNA-based\nAngioscore at a fraction of the cost. By providing a robust yet interpretable\nprediction of the Angioscore from histopathology slides alone, our approach\noffers insights into angiogenesis biology and AA treatment response.",
        "subjects": [
            "q-bio.QM",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Jay Jasti",
            "Hua Zhong",
            "Vandana Panwar",
            "Vipul Jarmale",
            "Jeffrey Miyata",
            "Deyssy Carrillo",
            "Alana Christie",
            "Dinesh Rakheja",
            "Zora Modrusan",
            "Edward Ernest Kadel III",
            "Niha Beig",
            "Mahrukh Huseni",
            "James Brugarolas",
            "Payal Kapur",
            "Satwik Rajaram"
        ],
        "published": "2024-05-28T16:21:20Z"
    },
    {
        "title": "VITON-DiT: Learning In-the-Wild Video Try-On from Human Dance Videos via\n  Diffusion Transformers",
        "link": "http://arxiv.org/abs/2405.18326v1",
        "abstract": "Video try-on stands as a promising area for its tremendous real-world\npotential. Prior works are limited to transferring product clothing images onto\nperson videos with simple poses and backgrounds, while underperforming on\ncasually captured videos. Recently, Sora revealed the scalability of Diffusion\nTransformer (DiT) in generating lifelike videos featuring real-world scenarios.\nInspired by this, we explore and propose the first DiT-based video try-on\nframework for practical in-the-wild applications, named VITON-DiT.\nSpecifically, VITON-DiT consists of a garment extractor, a Spatial-Temporal\ndenoising DiT, and an identity preservation ControlNet. To faithfully recover\nthe clothing details, the extracted garment features are fused with the\nself-attention outputs of the denoising DiT and the ControlNet. We also\nintroduce novel random selection strategies during training and an Interpolated\nAuto-Regressive (IAR) technique at inference to facilitate long video\ngeneration. Unlike existing attempts that require the laborious and restrictive\nconstruction of a paired training dataset, severely limiting their scalability,\nVITON-DiT alleviates this by relying solely on unpaired human dance videos and\na carefully designed multi-stage training strategy. Furthermore, we curate a\nchallenging benchmark dataset to evaluate the performance of casual video\ntry-on. Extensive experiments demonstrate the superiority of VITON-DiT in\ngenerating spatio-temporal consistent try-on results for in-the-wild videos\nwith complicated human poses.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jun Zheng",
            "Fuwei Zhao",
            "Youjiang Xu",
            "Xin Dong",
            "Xiaodan Liang"
        ],
        "published": "2024-05-28T16:21:03Z"
    },
    {
        "title": "Value Alignment and Trust in Human-Robot Interaction: Insights from\n  Simulation and User Study",
        "link": "http://arxiv.org/abs/2405.18324v1",
        "abstract": "With the advent of AI technologies, humans and robots are increasingly\nteaming up to perform collaborative tasks. To enable smooth and effective\ncollaboration, the topic of value alignment (operationalized herein as the\ndegree of dynamic goal alignment within a task) between the robot and the human\nis gaining increasing research attention. Prior literature on value alignment\nmakes an inherent assumption that aligning the values of the robot with that of\nthe human benefits the team. This assumption, however, has not been empirically\nverified. Moreover, prior literature does not account for human's trust in the\nrobot when analyzing human-robot value alignment. Thus, a research gap needs to\nbe bridged by answering two questions: How does alignment of values affect\ntrust? Is it always beneficial to align the robot's values with that of the\nhuman? We present a simulation study and a human-subject study to answer these\nquestions. Results from the simulation study show that alignment of values is\nimportant for trust when the overall risk level of the task is high. We also\npresent an adaptive strategy for the robot that uses Inverse Reinforcement\nLearning (IRL) to match the values of the robot with those of the human during\ninteraction. Our simulations suggest that such an adaptive strategy is able to\nmaintain trust across the full spectrum of human values. We also present\nresults from an empirical study that validate these findings from simulation.\nResults indicate that real-time personalized value alignment is beneficial to\ntrust and perceived performance by the human when the robot does not have a\ngood prior on the human's values.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Shreyas Bhat",
            "Joseph B. Lyons",
            "Cong Shi",
            "X. Jessie Yang"
        ],
        "published": "2024-05-28T16:20:33Z"
    },
    {
        "title": "SCE-MAE: Selective Correspondence Enhancement with Masked Autoencoder\n  for Self-Supervised Landmark Estimation",
        "link": "http://arxiv.org/abs/2405.18322v1",
        "abstract": "Self-supervised landmark estimation is a challenging task that demands the\nformation of locally distinct feature representations to identify sparse facial\nlandmarks in the absence of annotated data. To tackle this task, existing\nstate-of-the-art (SOTA) methods (1) extract coarse features from backbones that\nare trained with instance-level self-supervised learning (SSL) paradigms, which\nneglect the dense prediction nature of the task, (2) aggregate them into\nmemory-intensive hypercolumn formations, and (3) supervise lightweight\nprojector networks to naively establish full local correspondences among all\npairs of spatial features. In this paper, we introduce SCE-MAE, a framework\nthat (1) leverages the MAE, a region-level SSL method that naturally better\nsuits the landmark prediction task, (2) operates on the vanilla feature map\ninstead of on expensive hypercolumns, and (3) employs a Correspondence\nApproximation and Refinement Block (CARB) that utilizes a simple density peak\nclustering algorithm and our proposed Locality-Constrained Repellence Loss to\ndirectly hone only select local correspondences. We demonstrate through\nextensive experiments that SCE-MAE is highly effective and robust,\noutperforming existing SOTA methods by large margins of approximately 20%-44%\non the landmark matching and approximately 9%-15% on the landmark detection\ntasks.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Kejia Yin",
            "Varshanth R. Rao",
            "Ruowei Jiang",
            "Xudong Liu",
            "Parham Aarabi",
            "David B. Lindell"
        ],
        "published": "2024-05-28T16:14:10Z"
    },
    {
        "title": "Self-Supervised Learning Based Handwriting Verification",
        "link": "http://arxiv.org/abs/2405.18320v1",
        "abstract": "We present SSL-HV: Self-Supervised Learning approaches applied to the task of\nHandwriting Verification. This task involves determining whether a given pair\nof handwritten images originate from the same or different writer distribution.\nWe have compared the performance of multiple generative, contrastive SSL\napproaches against handcrafted feature extractors and supervised learning on\nCEDAR AND dataset. We show that ResNet based Variational Auto-Encoder (VAE)\noutperforms other generative approaches achieving 76.3% accuracy, while\nResNet-18 fine-tuned using Variance-Invariance-Covariance Regularization\n(VICReg) outperforms other contrastive approaches achieving 78% accuracy. Using\na pre-trained VAE and VICReg for the downstream task of writer verification we\nobserved a relative improvement in accuracy of 6.7% and 9% over ResNet-18\nsupervised baseline with 10% writer labels.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Mihir Chauhan",
            "Mohammad Abuzar Shaikh",
            "Bina Ramamurthy",
            "Mingchen Gao",
            "Siwei Lyu",
            "Sargur Srihari"
        ],
        "published": "2024-05-28T16:11:11Z"
    },
    {
        "title": "DSDL: Data Set Description Language for Bridging Modalities and Tasks in\n  AI Data",
        "link": "http://arxiv.org/abs/2405.18315v1",
        "abstract": "In the era of artificial intelligence, the diversity of data modalities and\nannotation formats often renders data unusable directly, requiring\nunderstanding and format conversion before it can be used by researchers or\ndevelopers with different needs. To tackle this problem, this article\nintroduces a framework called Dataset Description Language (DSDL) that aims to\nsimplify dataset processing by providing a unified standard for AI datasets.\nDSDL adheres to the three basic practical principles of generic, portable, and\nextensible, using a unified standard to express data of different modalities\nand structures, facilitating the dissemination of AI data, and easily extending\nto new modalities and tasks. The standardized specifications of DSDL reduce the\nworkload for users in data dissemination, processing, and usage. To further\nimprove user convenience, we provide predefined DSDL templates for various\ntasks, convert mainstream datasets to comply with DSDL specifications, and\nprovide comprehensive documentation and DSDL tools. These efforts aim to\nsimplify the use of AI data, thereby improving the efficiency of AI\ndevelopment.",
        "subjects": [
            "cs.AI",
            "cs.PL"
        ],
        "authors": [
            "Bin Wang",
            "Linke Ouyang",
            "Fan Wu",
            "Wenchang Ning",
            "Xiao Han",
            "Zhiyuan Zhao",
            "Jiahui Peng",
            "Yiying Jiang",
            "Dahua Lin",
            "Conghui He"
        ],
        "published": "2024-05-28T16:07:45Z"
    },
    {
        "title": "Deriving Causal Order from Single-Variable Interventions: Guarantees &\n  Algorithm",
        "link": "http://arxiv.org/abs/2405.18314v1",
        "abstract": "Targeted and uniform interventions to a system are crucial for unveiling\ncausal relationships. While several methods have been developed to leverage\ninterventional data for causal structure learning, their practical application\nin real-world scenarios often remains challenging. Recent benchmark studies\nhave highlighted these difficulties, even when large numbers of single-variable\nintervention samples are available. In this work, we demonstrate, both\ntheoretically and empirically, that such datasets contain a wealth of causal\ninformation that can be effectively extracted under realistic assumptions about\nthe data distribution. More specifically, we introduce the notion of\ninterventional faithfulness, which relies on comparisons between the marginal\ndistributions of each variable across observational and interventional\nsettings, and we introduce a score on causal orders. Under this assumption, we\nare able to prove strong theoretical guarantees on the optimum of our score\nthat also hold for large-scale settings. To empirically verify our theory, we\nintroduce Intersort, an algorithm designed to infer the causal order from\ndatasets containing large numbers of single-variable interventions by\napproximately optimizing our score. Intersort outperforms baselines (GIES, PC\nand EASE) on almost all simulated data settings replicating common benchmarks\nin the field. Our proposed novel approach to modeling interventional datasets\nthus offers a promising avenue for advancing causal inference, highlighting\nsignificant potential for further enhancements under realistic assumptions.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Mathieu Chevalley",
            "Patrick Schwab",
            "Arash Mehrjou"
        ],
        "published": "2024-05-28T16:07:17Z"
    },
    {
        "title": "Deterministic and statistical calibration of constitutive models from\n  full-field data with parametric physics-informed neural networks",
        "link": "http://arxiv.org/abs/2405.18311v1",
        "abstract": "The calibration of constitutive models from full-field data has recently\ngained increasing interest due to improvements in full-field measurement\ncapabilities. In addition to the experimental characterization of novel\nmaterials, continuous structural health monitoring is another application that\nis of great interest. However, monitoring is usually associated with severe\ntime constraints, difficult to meet with standard numerical approaches.\nTherefore, parametric physics-informed neural networks (PINNs) for constitutive\nmodel calibration from full-field displacement data are investigated. In an\noffline stage, a parametric PINN can be trained to learn a parameterized\nsolution of the underlying partial differential equation. In the subsequent\nonline stage, the parametric PINN then acts as a surrogate for the\nparameters-to-state map in calibration. We test the proposed approach for the\ndeterministic least-squares calibration of a linear elastic as well as a\nhyperelastic constitutive model from noisy synthetic displacement data. We\nfurther carry out Markov chain Monte Carlo-based Bayesian inference to quantify\nthe uncertainty. A proper statistical evaluation of the results underlines the\nhigh accuracy of the deterministic calibration and that the estimated\nuncertainty is valid. Finally, we consider experimental data and show that the\nresults are in good agreement with a Finite Element Method-based calibration.\nDue to the fast evaluation of PINNs, calibration can be performed in near\nreal-time. This advantage is particularly evident in many-query applications\nsuch as Markov chain Monte Carlo-based Bayesian inference.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "David Anton",
            "Jendrik-Alexander Tröger",
            "Henning Wessels",
            "Ulrich Römer",
            "Alexander Henkes",
            "Stefan Hartmann"
        ],
        "published": "2024-05-28T16:02:11Z"
    },
    {
        "title": "Joint Lemmatization and Morphological Tagging with LEMMING",
        "link": "http://arxiv.org/abs/2405.18308v1",
        "abstract": "We present LEMMING, a modular log-linear model that jointly models\nlemmatization and tagging and supports the integration of arbitrary global\nfeatures. It is trainable on corpora annotated with gold standard tags and\nlemmata and does not rely on morphological dictionaries or analyzers. LEMMING\nsets the new state of the art in token-based statistical lemmatization on six\nlanguages; e.g., for Czech lemmatization, we reduce the error by 60%, from 4.05\nto 1.58. We also give empirical evidence that jointly modeling morphological\ntags and lemmata is mutually beneficial.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Thomas Muller",
            "Ryan Cotterell",
            "Alexander Fraser",
            "Hinrich Schütze"
        ],
        "published": "2024-05-28T16:01:19Z"
    },
    {
        "title": "Learning Staged Trees from Incomplete Data",
        "link": "http://arxiv.org/abs/2405.18306v1",
        "abstract": "Staged trees are probabilistic graphical models capable of representing any\nclass of non-symmetric independence via a coloring of its vertices. Several\nstructural learning routines have been defined and implemented to learn staged\ntrees from data, under the frequentist or Bayesian paradigm. They assume a data\nset has been observed fully and, in practice, observations with missing entries\nare either dropped or imputed before learning the model. Here, we introduce the\nfirst algorithms for staged trees that handle missingness within the learning\nof the model. To this end, we characterize the likelihood of staged tree models\nin the presence of missing data and discuss pseudo-likelihoods that approximate\nit. A structural expectation-maximization algorithm estimating the model\ndirectly from the full likelihood is also implemented and evaluated. A\ncomputational experiment showcases the performance of the novel learning\nalgorithms, demonstrating that it is feasible to account for different\nmissingness patterns when learning staged trees.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Jack Storror Carter",
            "Manuele Leonelli",
            "Eva Riccomagno",
            "Gherardo Varando"
        ],
        "published": "2024-05-28T16:00:23Z"
    },
    {
        "title": "Volt-PF Control Mode for Distribution Feeder Voltage Management Under\n  High Penetration of Distributed Energy Resources",
        "link": "http://arxiv.org/abs/2405.18305v1",
        "abstract": "Volt-VAr control is a popular method for mitigating overvoltage violations\ncaused by high penetration of distributed energy resources (DERs) in\ndistribution feeders. An inherent limitation of volt-VAr control is that the\nreactive power (Q) absorbed/injected by the DER is determined based only on the\nterminal voltage, without considering the active power (P) generated by the\nDER. This leads to an inequitable burden of Q support, in the sense that those\nDERs generating lower P, and hence contributing less to overvoltage issues, may\nbe required to provide more than their share of $Q$ support. The resulting PF\nof these DERs is required to vary over a wide range, which many current DERs do\nnot support. A new control scheme, namely volt-PF control, is proposed here\nwhere the Q support is inherently a function of both the voltage and $P$ from\nDERs, which alleviates the above concerns while limiting the PF variation\nwithin a narrow range of 0.9 to 1. The proposed scheme is validated through\nextensive static and dynamic simulations on a real, large (8000+ nodes) feeder\nwith very high penetration (>200%) of DERs.The implementation of the new scheme\nin new and existing commercial hardware inverters is described.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Madhura Sondharangalla",
            "Dan Moldovan",
            "Raja Ayyanar"
        ],
        "published": "2024-05-28T15:59:28Z"
    },
    {
        "title": "Multi-modal Generation via Cross-Modal In-Context Learning",
        "link": "http://arxiv.org/abs/2405.18304v1",
        "abstract": "In this work, we study the problem of generating novel images from complex\nmultimodal prompt sequences. While existing methods achieve promising results\nfor text-to-image generation, they often struggle to capture fine-grained\ndetails from lengthy prompts and maintain contextual coherence within prompt\nsequences. Moreover, they often result in misaligned image generation for\nprompt sequences featuring multiple objects. To address this, we propose a\nMulti-modal Generation via Cross-Modal In-Context Learning (MGCC) method that\ngenerates novel images from complex multimodal prompt sequences by leveraging\nthe combined capabilities of large language models (LLMs) and diffusion models.\nOur MGCC comprises a novel Cross-Modal Refinement module to explicitly learn\ncross-modal dependencies between the text and image in the LLM embedding space,\nand a contextual object grounding module to generate object bounding boxes\nspecifically targeting scenes with multiple objects. Our MGCC demonstrates a\ndiverse range of multimodal capabilities, like novel image generation, the\nfacilitation of multimodal dialogue, and generation of texts. Experimental\nevaluations on two benchmark datasets, demonstrate the effectiveness of our\nmethod. On Visual Story Generation (VIST) dataset with multimodal inputs, our\nMGCC achieves a CLIP Similarity score of $0.652$ compared to SOTA GILL $0.641$.\nSimilarly, on Visual Dialogue Context (VisDial) having lengthy dialogue\nsequences, our MGCC achieves an impressive CLIP score of $0.660$, largely\noutperforming existing SOTA method scoring $0.645$. Code:\nhttps://github.com/VIROBO-15/MGCC",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Amandeep Kumar",
            "Muzammal Naseer",
            "Sanath Narayan",
            "Rao Muhammad Anwer",
            "Salman Khan",
            "Hisham Cholakkal"
        ],
        "published": "2024-05-28T15:58:31Z"
    },
    {
        "title": "Deep Network Pruning: A Comparative Study on CNNs in Face Recognition",
        "link": "http://arxiv.org/abs/2405.18302v1",
        "abstract": "The widespread use of mobile devices for all kind of transactions makes\nnecessary reliable and real-time identity authentication, leading to the\nadoption of face recognition (FR) via the cameras embedded in such devices.\nProgress of deep Convolutional Neural Networks (CNNs) has provided substantial\nadvances in FR. Nonetheless, the size of state-of-the-art architectures is\nunsuitable for mobile deployment, since they often encompass hundreds of\nmegabytes and millions of parameters. We address this by studying methods for\ndeep network compression applied to FR. In particular, we apply network pruning\nbased on Taylor scores, where less important filters are removed iteratively.\nThe method is tested on three networks based on the small SqueezeNet (1.24M\nparameters) and the popular MobileNetv2 (3.5M) and ResNet50 (23.5M)\narchitectures. These have been selected to showcase the method on CNNs with\ndifferent complexities and sizes. We observe that a substantial percentage of\nfilters can be removed with minimal performance loss. Also, filters with the\nhighest amount of output channels tend to be removed first, suggesting that\nhigh-dimensional spaces within popular CNNs are over-dimensionated.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Fernando Alonso-Fernandez",
            "Kevin Hernandez-Diaz",
            "Jose Maria Buades Rubio",
            "Prayag Tiwari",
            "Josef Bigun"
        ],
        "published": "2024-05-28T15:57:58Z"
    },
    {
        "title": "CompetEvo: Towards Morphological Evolution from Competition",
        "link": "http://arxiv.org/abs/2405.18300v1",
        "abstract": "Training an agent to adapt to specific tasks through co-optimization of\nmorphology and control has widely attracted attention. However, whether there\nexists an optimal configuration and tactics for agents in a multiagent\ncompetition scenario is still an issue that is challenging to definitively\nconclude. In this context, we propose competitive evolution (CompetEvo), which\nco-evolves agents' designs and tactics in confrontation. We build arenas\nconsisting of three animals and their evolved derivatives, placing agents with\ndifferent morphologies in direct competition with each other. The results\nreveal that our method enables agents to evolve a more suitable design and\nstrategy for fighting compared to fixed-morph agents, allowing them to obtain\nadvantages in combat scenarios. Moreover, we demonstrate the amazing and\nimpressive behaviors that emerge when confrontations are conducted under\nasymmetrical morphs.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Kangyao Huang",
            "Di Guo",
            "Xinyu Zhang",
            "Xiangyang Ji",
            "Huaping Liu"
        ],
        "published": "2024-05-28T15:53:02Z"
    },
    {
        "title": "Deep Learning Innovations for Underwater Waste Detection: An In-Depth\n  Analysis",
        "link": "http://arxiv.org/abs/2405.18299v1",
        "abstract": "Addressing the issue of submerged underwater trash is crucial for\nsafeguarding aquatic ecosystems and preserving marine life. While identifying\ndebris present on the surface of water bodies is straightforward, assessing the\nunderwater submerged waste is a challenge due to the image distortions caused\nby factors such as light refraction, absorption, suspended particles, color\nshifts, and occlusion. This paper conducts a comprehensive review of\nstate-of-the-art architectures and on the existing datasets to establish a\nbaseline for submerged waste and trash detection. The primary goal remains to\nestablish the benchmark of the object localization techniques to be leveraged\nby advanced underwater sensors and autonomous underwater vehicles. The ultimate\nobjective is to explore the underwater environment, to identify, and remove\nunderwater debris. The absence of benchmarks (dataset or algorithm) in many\nresearches emphasizes the need for a more robust algorithmic solution. Through\nthis research, we aim to give performance comparative analysis of various\nunderwater trash detection algorithms.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ],
        "authors": [
            "Jaskaran Singh Walia",
            "Pavithra L K"
        ],
        "published": "2024-05-28T15:51:18Z"
    },
    {
        "title": "Context-Specific Refinements of Bayesian Network Classifiers",
        "link": "http://arxiv.org/abs/2405.18298v1",
        "abstract": "Supervised classification is one of the most ubiquitous tasks in machine\nlearning. Generative classifiers based on Bayesian networks are often used\nbecause of their interpretability and competitive accuracy. The widely used\nnaive and TAN classifiers are specific instances of Bayesian network\nclassifiers with a constrained underlying graph. This paper introduces novel\nclasses of generative classifiers extending TAN and other famous types of\nBayesian network classifiers. Our approach is based on staged tree models,\nwhich extend Bayesian networks by allowing for complex, context-specific\npatterns of dependence. We formally study the relationship between our novel\nclasses of classifiers and Bayesian networks. We introduce and implement\ndata-driven learning routines for our models and investigate their accuracy in\nan extensive computational study. The study demonstrates that models embedding\nasymmetric information can enhance classification accuracy.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Manuele Leonelli",
            "Gherardo Varando"
        ],
        "published": "2024-05-28T15:50:50Z"
    },
    {
        "title": "Bias in Motion: Theoretical Insights into the Dynamics of Bias in SGD\n  Training",
        "link": "http://arxiv.org/abs/2405.18296v1",
        "abstract": "Machine learning systems often acquire biases by leveraging undesired\nfeatures in the data, impacting accuracy variably across different\nsub-populations. Current understanding of bias formation mostly focuses on the\ninitial and final stages of learning, leaving a gap in knowledge regarding the\ntransient dynamics. To address this gap, this paper explores the evolution of\nbias in a teacher-student setup modeling different data sub-populations with a\nGaussian-mixture model. We provide an analytical description of the stochastic\ngradient descent dynamics of a linear classifier in this setting, which we\nprove to be exact in high dimension. Notably, our analysis reveals how\ndifferent properties of sub-populations influence bias at different timescales,\nshowing a shifting preference of the classifier during training. Applying our\nfindings to fairness and robustness, we delineate how and when heterogeneous\ndata and spurious features can generate and amplify bias. We empirically\nvalidate our results in more complex scenarios by training deeper networks on\nsynthetic and real datasets, including CIFAR10, MNIST, and CelebA.",
        "subjects": [
            "cs.LG",
            "cond-mat.dis-nn",
            "stat.ML"
        ],
        "authors": [
            "Anchit Jain",
            "Rozhin Nobahari",
            "Aristide Baratin",
            "Stefano Sarao Mannelli"
        ],
        "published": "2024-05-28T15:50:10Z"
    },
    {
        "title": "Intent3D: 3D Object Detection in RGB-D Scans Based on Human Intention",
        "link": "http://arxiv.org/abs/2405.18295v1",
        "abstract": "In real-life scenarios, humans seek out objects in the 3D world to fulfill\ntheir daily needs or intentions. This inspires us to introduce 3D intention\ngrounding, a new task in 3D object detection employing RGB-D, based on human\nintention, such as \"I want something to support my back\". Closely related, 3D\nvisual grounding focuses on understanding human reference. To achieve detection\nbased on human intention, it relies on humans to observe the scene, reason out\nthe target that aligns with their intention (\"pillow\" in this case), and\nfinally provide a reference to the AI system, such as \"A pillow on the couch\".\nInstead, 3D intention grounding challenges AI agents to automatically observe,\nreason and detect the desired target solely based on human intention. To tackle\nthis challenge, we introduce the new Intent3D dataset, consisting of 44,990\nintention texts associated with 209 fine-grained classes from 1,042 scenes of\nthe ScanNet dataset. We also establish several baselines based on different\nlanguage-based 3D object detection models on our benchmark. Finally, we propose\nIntentNet, our unique approach, designed to tackle this intention-based\ndetection problem. It focuses on three key aspects: intention understanding,\nreasoning to identify object candidates, and cascaded adaptive learning that\nleverages the intrinsic priority logic of different losses for multiple\nobjective optimization.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Weitai Kang",
            "Mengxue Qu",
            "Jyoti Kini",
            "Yunchao Wei",
            "Mubarak Shah",
            "Yan Yan"
        ],
        "published": "2024-05-28T15:48:39Z"
    },
    {
        "title": "CF-OPT: Counterfactual Explanations for Structured Prediction",
        "link": "http://arxiv.org/abs/2405.18293v1",
        "abstract": "Optimization layers in deep neural networks have enjoyed a growing popularity\nin structured learning, improving the state of the art on a variety of\napplications. Yet, these pipelines lack interpretability since they are made of\ntwo opaque layers: a highly non-linear prediction model, such as a deep neural\nnetwork, and an optimization layer, which is typically a complex black-box\nsolver. Our goal is to improve the transparency of such methods by providing\ncounterfactual explanations. We build upon variational autoencoders a\nprincipled way of obtaining counterfactuals: working in the latent space leads\nto a natural notion of plausibility of explanations. We finally introduce a\nvariant of the classic loss for VAE training that improves their performance in\nour specific structured context. These provide the foundations of CF-OPT, a\nfirst-order optimization algorithm that can find counterfactual explanations\nfor a broad class of structured learning architectures. Our numerical results\nshow that both close and plausible explanations can be obtained for problems\nfrom the recent literature.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Germain Vivier--Ardisson",
            "Alexandre Forel",
            "Axel Parmentier",
            "Thibaut Vidal"
        ],
        "published": "2024-05-28T15:48:27Z"
    },
    {
        "title": "Semantic are Beacons: A Semantic Perspective for Unveiling\n  Parameter-Efficient Fine-Tuning in Knowledge Learning",
        "link": "http://arxiv.org/abs/2405.18292v1",
        "abstract": "Parameter-Efficient Fine-Tuning (PEFT) methods enable efficient adaptation of\nLarge Language Models (LLMs) to various downstream applications. However, the\neffectiveness of the PEFT diminishes notably when downstream tasks require\naccurate learning of factual knowledge. In this paper, we adopt a semantic\nperspective to investigate this phenomenon, uncovering the reasons behind\nPEFT's limitations in knowledge learning task. Our findings reveal that: (1)\nPEFT presents a notable risk of pushing the model away from the intended\nknowledge target; (2) multiple knowledge interfere with each other, and such\ninterference suppresses the learning and expression of knowledge features.\nBased on these insights, we introduce a data filtering strategy to exclude data\nthat is detrimental to knowledge learning and a re-weighted learning strategy\nto make the model attentive to semantic distance during knowledge learning.\nExperimental results demonstrate the effectiveness of the proposed method on\nopen-source large language model, further validate the semantic challenge in\nPEFT, thus paving the way for future research.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Renzhi Wang",
            "Piji Li"
        ],
        "published": "2024-05-28T15:47:11Z"
    },
    {
        "title": "FedSAC: Dynamic Submodel Allocation for Collaborative Fairness in\n  Federated Learning",
        "link": "http://arxiv.org/abs/2405.18291v1",
        "abstract": "Collaborative fairness stands as an essential element in federated learning\nto encourage client participation by equitably distributing rewards based on\nindividual contributions. Existing methods primarily focus on adjusting\ngradient allocations among clients to achieve collaborative fairness. However,\nthey frequently overlook crucial factors such as maintaining consistency across\nlocal models and catering to the diverse requirements of high-contributing\nclients. This oversight inevitably decreases both fairness and model accuracy\nin practice. To address these issues, we propose FedSAC, a novel Federated\nlearning framework with dynamic Submodel Allocation for Collaborative fairness,\nbacked by a theoretical convergence guarantee. First, we present the concept of\n\"bounded collaborative fairness (BCF)\", which ensures fairness by tailoring\nrewards to individual clients based on their contributions. Second, to\nimplement the BCF, we design a submodel allocation module with a theoretical\nguarantee of fairness. This module incentivizes high-contributing clients with\nhigh-performance submodels containing a diverse range of crucial neurons,\nthereby preserving consistency across local models. Third, we further develop a\ndynamic aggregation module to adaptively aggregate submodels, ensuring the\nequitable treatment of low-frequency neurons and consequently enhancing overall\nmodel accuracy. Extensive experiments conducted on three public benchmarks\ndemonstrate that FedSAC outperforms all baseline methods in both fairness and\nmodel accuracy. We see this work as a significant step towards incentivizing\nbroader client participation in federated learning. The source code is\navailable at https://github.com/wangzihuixmu/FedSAC.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC"
        ],
        "authors": [
            "Zihui Wang",
            "Zheng Wang",
            "Lingjuan Lyu",
            "Zhaopeng Peng",
            "Zhicheng Yang",
            "Chenglu Wen",
            "Rongshan Yu",
            "Cheng Wang",
            "Xiaoliang Fan"
        ],
        "published": "2024-05-28T15:43:29Z"
    },
    {
        "title": "Highway Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.18289v1",
        "abstract": "Learning from multi-step off-policy data collected by a set of policies is a\ncore problem of reinforcement learning (RL). Approaches based on importance\nsampling (IS) often suffer from large variances due to products of IS ratios.\nTypical IS-free methods, such as $n$-step Q-learning, look ahead for $n$ time\nsteps along the trajectory of actions (where $n$ is called the lookahead depth)\nand utilize off-policy data directly without any additional adjustment. They\nwork well for proper choices of $n$. We show, however, that such IS-free\nmethods underestimate the optimal value function (VF), especially for large\n$n$, restricting their capacity to efficiently utilize information from distant\nfuture time steps. To overcome this problem, we introduce a novel, IS-free,\nmulti-step off-policy method that avoids the underestimation issue and\nconverges to the optimal VF. At its core lies a simple but non-trivial\n\\emph{highway gate}, which controls the information flow from the distant\nfuture by comparing it to a threshold. The highway gate guarantees convergence\nto the optimal VF for arbitrary $n$ and arbitrary behavioral policies. It gives\nrise to a novel family of off-policy RL algorithms that safely learn even when\n$n$ is very large, facilitating rapid credit assignment from the far future to\nthe past. On tasks with greatly delayed rewards, including video games where\nthe reward is given only at the end of the game, our new methods outperform\nmany existing multi-step off-policy algorithms.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Yuhui Wang",
            "Miroslav Strupl",
            "Francesco Faccio",
            "Qingyuan Wu",
            "Haozhe Liu",
            "Michał Grudzień",
            "Xiaoyang Tan",
            "Jürgen Schmidhuber"
        ],
        "published": "2024-05-28T15:42:45Z"
    },
    {
        "title": "Adaptive debiased SGD in high-dimensional GLMs with steaming data",
        "link": "http://arxiv.org/abs/2405.18284v1",
        "abstract": "Online statistical inference facilitates real-time analysis of sequentially\ncollected data, making it different from traditional methods that rely on\nstatic datasets. This paper introduces a novel approach to online inference in\nhigh-dimensional generalized linear models, where we update regression\ncoefficient estimates and their standard errors upon each new data arrival. In\ncontrast to existing methods that either require full dataset access or\nlarge-dimensional summary statistics storage, our method operates in a\nsingle-pass mode, significantly reducing both time and space complexity. The\ncore of our methodological innovation lies in an adaptive stochastic gradient\ndescent algorithm tailored for dynamic objective functions, coupled with a\nnovel online debiasing procedure. This allows us to maintain low-dimensional\nsummary statistics while effectively controlling optimization errors introduced\nby the dynamically changing loss functions. We demonstrate that our method,\ntermed the Approximated Debiased Lasso (ADL), not only mitigates the need for\nthe bounded individual probability condition but also significantly improves\nnumerical performance. Numerical experiments demonstrate that the proposed ADL\nmethod consistently exhibits robust performance across various covariance\nmatrix structures.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Ruijian Han",
            "Lan Luo",
            "Yuanhang Luo",
            "Yuanyuan Lin",
            "Jian Huang"
        ],
        "published": "2024-05-28T15:36:48Z"
    },
    {
        "title": "MODL: Multilearner Online Deep Learning",
        "link": "http://arxiv.org/abs/2405.18281v1",
        "abstract": "Online deep learning solves the problem of learning from streams of data,\nreconciling two opposing objectives: learn fast and learn deep. Existing work\nfocuses almost exclusively on exploring pure deep learning solutions, which are\nmuch better suited to handle the \"deep\" than the \"fast\" part of the online\nlearning equation. In our work, we propose a different paradigm, based on a\nhybrid multilearner approach. First, we develop a fast online logistic\nregression learner. This learner does not rely on backpropagation. Instead, it\nuses closed form recursive updates of model parameters, handling the fast\nlearning part of the online learning problem. We then analyze the existing\nonline deep learning theory and show that the widespread ODL approach,\ncurrently operating at complexity $O(L^2)$ in terms of the number of layers\n$L$, can be equivalently implemented in $O(L)$ complexity. This further leads\nus to the cascaded multilearner design, in which multiple shallow and deep\nlearners are co-trained to solve the online learning problem in a cooperative,\nsynergistic fashion. We show that this approach achieves state-of-the-art\nresults on common online learning datasets, while also being able to handle\nmissing features gracefully. Our code is publicly available at\nhttps://github.com/AntonValk/MODL.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Antonios Valkanas",
            "Boris N. Oreshkin",
            "Mark Coates"
        ],
        "published": "2024-05-28T15:34:33Z"
    },
    {
        "title": "NotPlaNET: Removing False Positives from Planet Hunters TESS with\n  Machine Learning",
        "link": "http://arxiv.org/abs/2405.18278v1",
        "abstract": "Differentiating between real transit events and false positive signals in\nphotometric time series data is a bottleneck in the identification of\ntransiting exoplanets, particularly long-period planets. This differentiation\ntypically requires visual inspection of a large number of transit-like signals\nto rule out instrumental and astrophysical false positives that mimic planetary\ntransit signals. We build a one-dimensional convolutional neural network (CNN)\nto separate eclipsing binaries and other false positives from potential planet\ncandidates, reducing the number of light curves that require human vetting. Our\nCNN is trained using the TESS light curves that were identified by Planet\nHunters citizen scientists as likely containing a transit. We also include the\nbackground flux and centroid information. The light curves are visually\ninspected and labeled by project scientists and are minimally pre-processed,\nwith only normalization and data augmentation taking place before training. The\nmedian percentage of contaminants flagged across the test sectors is 18% with a\nmaximum of 37% and a minimum of 10%. Our model keeps 100% of the planets for 16\nof the 18 test sectors, while incorrectly flagging one planet candidate (0.3%)\nfor one sector and two (0.6%) for the remaining sector. Our method shows\npotential to reduce the number of light curves requiring manual vetting by up\nto a third with minimal misclassification of planet candidates.",
        "subjects": [
            "astro-ph.EP",
            "astro-ph.IM",
            "cs.LG"
        ],
        "authors": [
            "Valentina Tardugno Poleo",
            "Nora Eisner",
            "David W. Hogg"
        ],
        "published": "2024-05-28T15:29:40Z"
    },
    {
        "title": "Can We Trust Recommender System Fairness Evaluation? The Role of\n  Fairness and Relevance",
        "link": "http://dx.doi.org/10.1145/3626772.3657832",
        "abstract": "Relevance and fairness are two major objectives of recommender systems (RSs).\nRecent work proposes measures of RS fairness that are either independent from\nrelevance (fairness-only) or conditioned on relevance (joint measures). While\nfairness-only measures have been studied extensively, we look into whether\njoint measures can be trusted. We collect all joint evaluation measures of RS\nrelevance and fairness, and ask: How much do they agree with each other? To\nwhat extent do they agree with relevance/fairness measures? How sensitive are\nthey to changes in rank position, or to increasingly fair and relevant\nrecommendations? We empirically study for the first time the behaviour of these\nmeasures across 4 real-world datasets and 4 recommenders. We find that most of\nthese measures: i) correlate weakly with one another and even contradict each\nother at times; ii) are less sensitive to rank position changes than relevance-\nand fairness-only measures, meaning that they are less granular than\ntraditional RS measures; and iii) tend to compress scores at the low end of\ntheir range, meaning that they are not very expressive. We counter the above\nlimitations with a set of guidelines on the appropriate usage of such measures,\ni.e., they should be used with caution due to their tendency to contradict each\nother and of having a very small empirical range.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Theresia Veronika Rampisela",
            "Tuukka Ruotsalo",
            "Maria Maistro",
            "Christina Lioma"
        ],
        "published": "2024-05-28T15:25:04Z"
    },
    {
        "title": "The Round Complexity of Proofs in the Bounded Quantum Storage Model",
        "link": "http://arxiv.org/abs/2405.18275v1",
        "abstract": "The round complexity of interactive proof systems is a key question of\npractical and theoretical relevance in complexity theory and cryptography.\nMoreover, results such as QIP = QIP(3) (STOC'00) show that quantum resources\nsignificantly help in such a task.\n  In this work, we initiate the study of round compression of protocols in the\nbounded quantum storage model (BQSM). In this model, the malicious parties have\na bounded quantum memory and they cannot store the all the qubits that are\ntransmitted in the protocol.\n  Our main results in this setting are the following:\n  1. There is a non-interactive (statistical) witness indistinguishable proof\nfor any language in NP (and even QMA) in BQSM in the plain model. We notice\nthat in this protocol, only the memory of the verifier is bounded.\n  2. Any classical proof system can be compressed in a two-message quantum\nproof system in BQSM. Moreover, if the original proof system is zero-knowledge,\nthe quantum protocol is zero-knowledge too. In this result, we assume that the\nprover has bounded memory.\n  Finally, we give evidence towards the \"tightness\" of our results. First, we\nshow that NIZK in the plain model against BQS adversaries is unlikely with\nstandard techniques. Second, we prove that without the BQS model there is no\n2-message zero-knowledge quantum interactive proof, even under computational\nassumptions.",
        "subjects": [
            "quant-ph",
            "cs.CC",
            "cs.CR"
        ],
        "authors": [
            "Alex B. Grilo",
            "Philippe Lamontagne"
        ],
        "published": "2024-05-28T15:24:48Z"
    },
    {
        "title": "Signal-Plus-Noise Decomposition of Nonlinear Spiked Random Matrix Models",
        "link": "http://arxiv.org/abs/2405.18274v1",
        "abstract": "In this paper, we study a nonlinear spiked random matrix model where a\nnonlinear function is applied element-wise to a noise matrix perturbed by a\nrank-one signal. We establish a signal-plus-noise decomposition for this model\nand identify precise phase transitions in the structure of the signal\ncomponents at critical thresholds of signal strength. To demonstrate the\napplicability of this decomposition, we then utilize it to study new phenomena\nin the problems of signed signal recovery in nonlinear models and community\ndetection in transformed stochastic block models. Finally, we validate our\nresults through a series of numerical simulations.",
        "subjects": [
            "math.ST",
            "cs.LG",
            "eess.SP",
            "stat.ML",
            "stat.TH"
        ],
        "authors": [
            "Behrad Moniri",
            "Hamed Hassani"
        ],
        "published": "2024-05-28T15:24:35Z"
    },
    {
        "title": "Synchronization on circles and spheres with nonlinear interactions",
        "link": "http://arxiv.org/abs/2405.18273v1",
        "abstract": "We consider the dynamics of $n$ points on a sphere in $\\mathbb{R}^d$ ($d \\geq\n2$) which attract each other according to a function $\\varphi$ of their inner\nproducts. When $\\varphi$ is linear ($\\varphi(t) = t$), the points converge to a\ncommon value (i.e., synchronize) in various connectivity scenarios: this is\npart of classical work on Kuramoto oscillator networks. When $\\varphi$ is\nexponential ($\\varphi(t) = e^{\\beta t}$), these dynamics correspond to a limit\nof how idealized transformers process data, as described by Geshkovski et al.\n(2024). Accordingly, they ask whether synchronization occurs for exponential\n$\\varphi$.\n  In the context of consensus for multi-agent control, Markdahl et al. (2018)\nshow that for $d \\geq 3$ (spheres), if the interaction graph is connected and\n$\\varphi$ is increasing and convex, then the system synchronizes. What is the\nsituation on circles ($d=2$)? First, we show that $\\varphi$ being increasing\nand convex is no longer sufficient. Then we identify a new condition (that the\nTaylor coefficients of $\\varphi'$ are decreasing) under which we do have\nsynchronization on the circle. In so doing, we provide some answers to the open\nproblems posed by Geshkovski et al. (2024).",
        "subjects": [
            "math.OC",
            "cs.LG",
            "math.DS"
        ],
        "authors": [
            "Christopher Criscitiello",
            "Quentin Rebjock",
            "Andrew D. McRae",
            "Nicolas Boumal"
        ],
        "published": "2024-05-28T15:24:30Z"
    },
    {
        "title": "Metaheuristics and Large Language Models Join Forces: Towards an\n  Integrated Optimization Approach",
        "link": "http://arxiv.org/abs/2405.18272v1",
        "abstract": "Since the rise of Large Language Models (LLMs) a couple of years ago,\nresearchers in metaheuristics (MHs) have wondered how to use their power in a\nbeneficial way within their algorithms. This paper introduces a novel approach\nthat leverages LLMs as pattern recognition tools to improve MHs. The resulting\nhybrid method, tested in the context of a social network-based combinatorial\noptimization problem, outperforms existing state-of-the-art approaches that\ncombine machine learning with MHs regarding the obtained solution quality. By\ncarefully designing prompts, we demonstrate that the output obtained from LLMs\ncan be used as problem knowledge, leading to improved results. Lastly, we\nacknowledge LLMs' potential drawbacks and limitations and consider it essential\nto examine them to advance this type of research further.",
        "subjects": [
            "cs.AI",
            "68T20"
        ],
        "authors": [
            "Camilo Chacón Sartori",
            "Christian Blum",
            "Filippo Bistaffa",
            "Guillem Rodríguez Corominas"
        ],
        "published": "2024-05-28T15:23:46Z"
    },
    {
        "title": "CT-based brain ventricle segmentation via diffusion Schrödinger Bridge\n  without target domain ground truths",
        "link": "http://arxiv.org/abs/2405.18267v1",
        "abstract": "Efficient and accurate brain ventricle segmentation from clinical CT scans is\ncritical for emergency surgeries like ventriculostomy. With the challenges in\npoor soft tissue contrast and a scarcity of well-annotated databases for\nclinical brain CTs, we introduce a novel uncertainty-aware ventricle\nsegmentation technique without the need of CT segmentation ground truths by\nleveraging diffusion-model-based domain adaptation. Specifically, our method\nemploys the diffusion Schr\\\"odinger Bridge and an attention recurrent residual\nU-Net to capitalize on unpaired CT and MRI scans to derive automatic CT\nsegmentation from those of the MRIs, which are more accessible. Importantly, we\npropose an end-to-end, joint training framework of image translation and\nsegmentation tasks, and demonstrate its benefit over training individual tasks\nseparately. By comparing the proposed method against similar setups using two\ndifferent GAN models for domain adaptation (CycleGAN and CUT), we also reveal\nthe advantage of diffusion models towards improved segmentation and image\ntranslation quality. With a Dice score of 0.78$\\pm$0.27, our proposed method\noutperformed the compared methods, including SynSeg-Net, while providing\nintuitive uncertainty measures to further facilitate quality control of the\nautomatic segmentation outcomes.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Reihaneh Teimouri",
            "Marta Kersten-Oertel",
            "Yiming Xiao"
        ],
        "published": "2024-05-28T15:17:58Z"
    },
    {
        "title": "Error-Free and Current-Driven Synthetic Antiferromagnetic Domain Wall\n  Memory Enabled by Channel Meandering",
        "link": "http://arxiv.org/abs/2405.18261v1",
        "abstract": "We propose a new type of multi-bit and energy-efficient magnetic memory based\non current-driven, field-free, and highly controlled domain wall motion. A\nmeandering domain wall channel with precisely interspersed pinning regions\nprovides the multi-bit capability of a magnetic tunnel junction. The magnetic\nfree layer of the memory device has perpendicular magnetic anisotropy and\ninterfacial Dzyaloshinskii-Moriya interaction, so that spin-orbit torques\ninduce efficient domain wall motion. Using micromagnetic simulations, we find\ntwo pinning mechanisms that lead to different cell designs: two-way switching\nand four-way switching. The memory cell design choices and the physics behind\nthese pinning mechanisms are discussed in detail. Furthermore, we show that\nswitching reliability and speed may be significantly improved by replacing the\nferromagnetic free layer with a synthetic antiferromagnetic layer. Switching\nbehavior and material choices will be discussed for the two implementations.",
        "subjects": [
            "cs.ET",
            "cond-mat.mes-hall",
            "cond-mat.mtrl-sci",
            "physics.app-ph"
        ],
        "authors": [
            "Pengxiang Zhang",
            "Wilfried Haensch",
            "Charudatta M. Phatak",
            "Supratik Guha"
        ],
        "published": "2024-05-28T15:16:21Z"
    },
    {
        "title": "A Vlogger-augmented Graph Neural Network Model for Micro-video\n  Recommendation",
        "link": "http://dx.doi.org/10.1007/978-3-031-43427-3_41",
        "abstract": "Existing micro-video recommendation models exploit the interactions between\nusers and micro-videos and/or multi-modal information of micro-videos to\npredict the next micro-video a user will watch, ignoring the information\nrelated to vloggers, i.e., the producers of micro-videos. However, in\nmicro-video scenarios, vloggers play a significant role in user-video\ninteractions, since vloggers generally focus on specific topics and users tend\nto follow the vloggers they are interested in. Therefore, in the paper, we\npropose a vlogger-augmented graph neural network model VA-GNN, which takes the\neffect of vloggers into consideration. Specifically, we construct a tripartite\ngraph with users, micro-videos, and vloggers as nodes, capturing user\npreferences from different views, i.e., the video-view and the vlogger-view.\nMoreover, we conduct cross-view contrastive learning to keep the consistency\nbetween node embeddings from the two different views. Besides, when predicting\nthe next user-video interaction, we adaptively combine the user preferences for\na video itself and its vlogger. We conduct extensive experiments on two\nreal-world datasets. The experimental results show that VA-GNN outperforms\nmultiple existing GNN-based recommendation models.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Weijiang Lai",
            "Beihong Jin",
            "Beibei Li",
            "Yiyuan Zheng",
            "Rui Zhao"
        ],
        "published": "2024-05-28T15:13:29Z"
    },
    {
        "title": "Ranking with Ties based on Noisy Performance Data",
        "link": "http://arxiv.org/abs/2405.18259v1",
        "abstract": "We consider the problem of ranking a set of objects based on their\nperformance when the measurement of said performance is subject to noise. In\nthis scenario, the performance is measured repeatedly, resulting in a range of\nmeasurements for each object. If the ranges of two objects do not overlap, then\nwe consider one object as 'better' than the other, and we expect it to receive\na higher rank; if, however, the ranges overlap, then the objects are\nincomparable, and we wish them to be assigned the same rank. Unfortunately, the\nincomparability relation of ranges is in general not transitive; as a\nconsequence, in general the two requirements cannot be satisfied\nsimultaneously, i.e., it is not possible to guarantee both distinct ranks for\nobjects with separated ranges, and same rank for objects with overlapping\nranges. This conflict leads to more than one reasonable way to rank a set of\nobjects. In this paper, we explore the ambiguities that arise when ranking with\nties, and define a set of reasonable rankings, which we call partial rankings.\nWe develop and analyse three different methodologies to compute a partial\nranking. Finally, we show how performance differences among objects can be\ninvestigated with the help of partial ranking.",
        "subjects": [
            "cs.PF",
            "cs.IR"
        ],
        "authors": [
            "Aravind Sankaran",
            "Lars Karlsson",
            "Paolo Bientinesi"
        ],
        "published": "2024-05-28T15:13:19Z"
    },
    {
        "title": "Text-only Synthesis for Image Captioning",
        "link": "http://arxiv.org/abs/2405.18258v1",
        "abstract": "From paired image-text training to text-only training for image captioning,\nthe pursuit of relaxing the requirements for high-cost and large-scale\nannotation of good quality data remains consistent. In this paper, we propose\nText-only Synthesis for Image Captioning (ToCa), which further advances this\nrelaxation with fewer human labor and less computing time. Specifically, we\ndeconstruct caption text into structures and lexical words, which serve as the\nfundamental components of the caption. By combining different structures and\nlexical words as inputs to the large language model, massive captions that\ncontain various patterns of lexical words are generated. This method not only\napproaches the target domain but also surpasses it by generating new captions,\nthereby enhancing the zero-shot generalization ability of the model.\nConsidering the different levels of data access in the real world, we define\nthree synthesis scenarios: cross-domain synthesis, in-domain synthesis, and\ndata-efficient synthesis. Experiments in these scenarios demonstrate the\ngeneralizability, transferability and practicability of ToCa with a nearly 5\nCIDEr improvement for zero-shot cross-domain captioning and a maximum increase\nof over 20 CIDEr for data-efficient captioning.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Qing Zhou",
            "Junlin Huang",
            "Qiang Li",
            "Junyu Gao",
            "Qi Wang"
        ],
        "published": "2024-05-28T15:11:17Z"
    },
    {
        "title": "Channel Reciprocity Based Attack Detection for Securing UWB Ranging by\n  Autoencoder",
        "link": "http://arxiv.org/abs/2405.18255v1",
        "abstract": "A variety of ranging threats represented by Ghost Peak attack have raised\nconcerns regarding the security performance of Ultra-Wide Band (UWB) systems\nwith the finalization of the IEEE 802.15.4z standard. Based on channel\nreciprocity, this paper proposes a low complexity attack detection scheme that\ncompares Channel Impulse Response (CIR) features of both ranging sides\nutilizing an autoencoder with the capability of data compression and feature\nextraction. Taking Ghost Peak attack as an example, this paper demonstrates the\neffectiveness, feasibility and generalizability of the proposed attack\ndetection scheme through simulation and experimental validation. The proposed\nscheme achieves an attack detection success rate of over 99% and can be\nimplemented in current systems at low cost.",
        "subjects": [
            "cs.CR",
            "cs.SI",
            "eess.SP",
            "H.1.1"
        ],
        "authors": [
            "Wenlong Gou",
            "Chuanhang Yu",
            "Juntao Ma",
            "Gang Wu",
            "Vladimir Mordachev"
        ],
        "published": "2024-05-28T15:07:50Z"
    },
    {
        "title": "Truthful Dataset Valuation by Pointwise Mutual Information",
        "link": "http://arxiv.org/abs/2405.18253v1",
        "abstract": "A common way to evaluate a dataset in ML involves training a model on this\ndataset and assessing the model's performance on a test set. However, this\napproach has two issues: (1) it may incentivize undesirable data manipulation\nin data marketplaces, as the self-interested data providers seek to modify the\ndataset to maximize their evaluation scores; (2) it may select datasets that\noverfit to potentially small test sets. We propose a new data valuation method\nthat provably guarantees the following: data providers always maximize their\nexpected score by truthfully reporting their observed data. Any manipulation of\nthe data, including but not limited to data duplication, adding random data,\ndata removal, or re-weighting data from different groups, cannot increase their\nexpected score. Our method, following the paradigm of proper scoring rules,\nmeasures the pointwise mutual information (PMI) of the test dataset and the\nevaluated dataset. However, computing the PMI of two datasets is challenging.\nWe introduce a novel PMI measuring method that greatly improves tractability\nwithin Bayesian machine learning contexts. This is accomplished through a new\ncharacterization of PMI that relies solely on the posterior probabilities of\nthe model parameter at an arbitrarily selected value. Finally, we support our\ntheoretical results with simulations and further test the effectiveness of our\ndata valuation method in identifying the top datasets among multiple data\nproviders. Interestingly, our method outperforms the standard approach of\nselecting datasets based on the trained model's test performance, suggesting\nthat our truthful valuation score can also be more robust to overfitting.",
        "subjects": [
            "cs.LG",
            "cs.GT"
        ],
        "authors": [
            "Shuran Zheng",
            "Yongchan Kwon",
            "Xuan Qi",
            "James Zou"
        ],
        "published": "2024-05-28T15:04:17Z"
    },
    {
        "title": "Sensor-Based Distributionally Robust Control for Safe Robot Navigation\n  in Dynamic Environments",
        "link": "http://arxiv.org/abs/2405.18251v1",
        "abstract": "We introduce a novel method for safe mobile robot navigation in dynamic,\nunknown environments, utilizing onboard sensing to impose safety constraints\nwithout the need for accurate map reconstruction. Traditional methods typically\nrely on detailed map information to synthesize safe stabilizing controls for\nmobile robots, which can be computationally demanding and less effective,\nparticularly in dynamic operational conditions. By leveraging recent advances\nin distributionally robust optimization, we develop a distributionally robust\ncontrol barrier function (DR-CBF) constraint that directly processes range\nsensor data to impose safety constraints. Coupling this with a control Lyapunov\nfunction (CLF) for path tracking, we demonstrate that our CLF-DR-CBF control\nsynthesis method achieves safe, efficient, and robust navigation in uncertain\ndynamic environments. We demonstrate the effectiveness of our approach in\nsimulated and real autonomous robot navigation experiments, marking a\nsubstantial advancement in real-time safety guarantees for mobile robots.",
        "subjects": [
            "cs.RO",
            "cs.SY",
            "eess.SY",
            "math.OC"
        ],
        "authors": [
            "Kehan Long",
            "Yinzhuang Yi",
            "Zhirui Dai",
            "Sylvia Herbert",
            "Jorge Cortés",
            "Nikolay Atanasov"
        ],
        "published": "2024-05-28T15:02:09Z"
    },
    {
        "title": "Extreme Value Monte Carlo Tree Search",
        "link": "http://arxiv.org/abs/2405.18248v1",
        "abstract": "Despite being successful in board games and reinforcement learning (RL), UCT,\na Monte-Carlo Tree Search (MCTS) combined with UCB1 Multi-Armed Bandit (MAB),\nhas had limited success in domain-independent planning until recently. Previous\nwork showed that UCB1, designed for $[0,1]$-bounded rewards, is not appropriate\nfor estimating the distance-to-go which are potentially unbounded in\n$\\mathbb{R}$, such as heuristic functions used in classical planning, then\nproposed combining MCTS with MABs designed for Gaussian reward distributions\nand successfully improved the performance. In this paper, we further sharpen\nour understanding of ideal bandits for planning tasks. Existing work has two\nissues: First, while Gaussian MABs no longer over-specify the distances as\n$h\\in [0,1]$, they under-specify them as $h\\in [-\\infty,\\infty]$ while they are\nnon-negative and can be further bounded in some cases. Second, there is no\ntheoretical justifications for Full-Bellman backup (Schulte & Keller, 2014)\nthat backpropagates minimum/maximum of samples. We identified \\emph{extreme\nvalue} statistics as a theoretical framework that resolves both issues at once\nand propose two bandits, UCB1-Uniform/Power, and apply them to MCTS for\nclassical planning. We formally prove their regret bounds and empirically\ndemonstrate their performance in classical planning.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Masataro Asai",
            "Stephen Wissow"
        ],
        "published": "2024-05-28T14:58:43Z"
    },
    {
        "title": "Utilitarian Algorithm Configuration for Infinite Parameter Spaces",
        "link": "http://arxiv.org/abs/2405.18246v1",
        "abstract": "Utilitarian algorithm configuration is a general-purpose technique for\nautomatically searching the parameter space of a given algorithm to optimize\nits performance, as measured by a given utility function, on a given set of\ninputs. Recently introduced utilitarian configuration procedures offer\noptimality guarantees about the returned parameterization while provably\nadapting to the hardness of the underlying problem. However, the applicability\nof these approaches is severely limited by the fact that they only search a\nfinite, relatively small set of parameters. They cannot effectively search the\nconfiguration space of algorithms with continuous or uncountable parameters. In\nthis paper we introduce a new procedure, which we dub COUP (Continuous,\nOptimistic Utilitarian Procrastination). COUP is designed to search infinite\nparameter spaces efficiently to find good configurations quickly. Furthermore,\nCOUP maintains the theoretical benefits of previous utilitarian configuration\nprocedures when applied to finite parameter spaces but is significantly faster,\nboth provably and experimentally.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Devon Graham",
            "Kevin Leyton-Brown"
        ],
        "published": "2024-05-28T14:58:07Z"
    },
    {
        "title": "Compiling with Arrays",
        "link": "http://arxiv.org/abs/2405.18242v1",
        "abstract": "Linear algebra computations are foundational for neural networks and machine\nlearning, often handled through arrays. While many functional programming\nlanguages feature lists and recursion, arrays in linear algebra demand\nconstant-time access and bulk operations. To bridge this gap, some languages\nrepresent arrays as (eager) functions instead of lists. In this paper, we\nconnect this idea to a formal logical foundation by interpreting functions as\nthe usual negative types from polarized type theory, and arrays as the\ncorresponding dual positive version of the function type. Positive types are\ndefined to have a single elimination form whose computational interpretation is\npattern matching. Just like (positive) product types bind two variables during\npattern matching, (positive) array types bind variables with multiplicity\nduring pattern matching. We follow a similar approach for Booleans by\nintroducing conditionally-defined variables.\n  The positive formulation for the array type enables us to combine typed\npartial evaluation and common subexpression elimination into an elegant\nalgorithm whose result enjoys a property we call maximal fission, which we\nargue can be beneficial for further optimizations. For this purpose, we present\nthe novel intermediate representation indexed administrative normal form\n(AiNF), which relies on the formal logical foundation of the positive\nformulation for the array type to facilitate maximal loop fission and\nsubsequent optimizations. AiNF is normal with regard to commuting conversion\nfor both let-bindings and for-loops, leading to flat and maximally fissioned\nterms. We mechanize the translation and normalization from a simple surface\nlanguage to AiNF, establishing that the process terminates, preserves types,\nand produces maximally fissioned terms.",
        "subjects": [
            "cs.PL"
        ],
        "authors": [
            "David Richter",
            "Timon Böhler",
            "Pascal Weisenburger",
            "Mira Mezini"
        ],
        "published": "2024-05-28T14:51:32Z"
    },
    {
        "title": "Active Use of Latent Constituency Representation in both Humans and\n  Large Language Models",
        "link": "http://arxiv.org/abs/2405.18241v1",
        "abstract": "Understanding how sentences are internally represented in the human brain, as\nwell as in large language models (LLMs) such as ChatGPT, is a major challenge\nfor cognitive science. Classic linguistic theories propose that the brain\nrepresents a sentence by parsing it into hierarchically organized constituents.\nIn contrast, LLMs do not explicitly parse linguistic constituents and their\nlatent representations remains poorly explained. Here, we demonstrate that\nhumans and LLMs construct similar latent representations of hierarchical\nlinguistic constituents by analyzing their behaviors during a novel one-shot\nlearning task, in which they infer which words should be deleted from a\nsentence. Both humans and LLMs tend to delete a constituent, instead of a\nnonconstituent word string. In contrast, a naive sequence processing model that\nhas access to word properties and ordinal positions does not show this\nproperty. Based on the word deletion behaviors, we can reconstruct the latent\nconstituency tree representation of a sentence for both humans and LLMs. These\nresults demonstrate that a latent tree-structured constituency representation\ncan emerge in both the human brain and LLMs.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Wei Liu",
            "Ming Xiang",
            "Nai Ding"
        ],
        "published": "2024-05-28T14:50:22Z"
    },
    {
        "title": "MSPE: Multi-Scale Patch Embedding Prompts Vision Transformers to Any\n  Resolution",
        "link": "http://arxiv.org/abs/2405.18240v1",
        "abstract": "Although Vision Transformers (ViTs) have recently advanced computer vision\ntasks significantly, an important real-world problem was overlooked: adapting\nto variable input resolutions. Typically, images are resized to a fixed\nresolution, such as 224x224, for efficiency during training and inference.\nHowever, uniform input size conflicts with real-world scenarios where images\nnaturally vary in resolution. Modifying the preset resolution of a model may\nseverely degrade the performance. In this work, we propose to enhance the model\nadaptability to resolution variation by optimizing the patch embedding. The\nproposed method, called Multi-Scale Patch Embedding (MSPE), substitutes the\nstandard patch embedding with multiple variable-sized patch kernels and selects\nthe best parameters for different resolutions, eliminating the need to resize\nthe original image. Our method does not require high-cost training or\nmodifications to other parts, making it easy to apply to most ViT models.\nExperiments in image classification, segmentation, and detection tasks\ndemonstrate the effectiveness of MSPE, yielding superior performance on\nlow-resolution inputs and performing comparably on high-resolution inputs with\nexisting methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Wenzhuo Liu",
            "Fei Zhu",
            "Shijie Ma",
            "Cheng-Lin Liu"
        ],
        "published": "2024-05-28T14:50:12Z"
    },
    {
        "title": "The CoExplorer Technology Probe: A Generative AI-Powered Adaptive\n  Interface to Support Intentionality in Planning and Running Video Meetings",
        "link": "http://dx.doi.org/10.1145/3643834.3661507",
        "abstract": "Effective meetings are effortful, but traditional videoconferencing systems\noffer little support for reducing this effort across the meeting lifecycle.\nGenerative AI (GenAI) has the potential to radically redefine meetings by\naugmenting intentional meeting behaviors. CoExplorer, our novel adaptive\nmeeting prototype, preemptively generates likely phases that meetings would\nundergo, tools that allow capturing attendees' thoughts before the meeting, and\nfor each phase, window layouts, and appropriate applications and files. Using\nCoExplorer as a technology probe in a guided walkthrough, we studied its\npotential in a sample of participants from a global technology company. Our\nfindings suggest that GenAI has the potential to help meetings stay on track\nand reduce workload, although concerns were raised about users' agency, trust,\nand possible disruption to traditional meeting norms. We discuss these concerns\nand their design implications for the development of GenAI meeting technology.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Gun Woo Warren Park",
            "Payod Panda",
            "Lev Tankelevitch",
            "Sean Rintel"
        ],
        "published": "2024-05-28T14:48:19Z"
    },
    {
        "title": "Unveiling the Cycloid Trajectory of EM Iterations in Mixed Linear\n  Regression",
        "link": "http://arxiv.org/abs/2405.18237v1",
        "abstract": "We study the trajectory of iterations and the convergence rates of the\nExpectation-Maximization (EM) algorithm for two-component Mixed Linear\nRegression (2MLR). The fundamental goal of MLR is to learn the regression\nmodels from unlabeled observations. The EM algorithm finds extensive\napplications in solving the mixture of linear regressions. Recent results have\nestablished the super-linear convergence of EM for 2MLR in the noiseless and\nhigh SNR settings under some assumptions and its global convergence rate with\nrandom initialization has been affirmed. However, the exponent of convergence\nhas not been theoretically estimated and the geometric properties of the\ntrajectory of EM iterations are not well-understood. In this paper, first,\nusing Bessel functions we provide explicit closed-form expressions for the EM\nupdates under all SNR regimes. Then, in the noiseless setting, we completely\ncharacterize the behavior of EM iterations by deriving a recurrence relation at\nthe population level and notably show that all the iterations lie on a certain\ncycloid. Based on this new trajectory-based analysis, we exhibit the\ntheoretical estimate for the exponent of super-linear convergence and further\nimprove the statistical error bound at the finite-sample level. Our analysis\nprovides a new framework for studying the behavior of EM for Mixed Linear\nRegression.",
        "subjects": [
            "cs.LG",
            "math.ST",
            "stat.ML",
            "stat.TH"
        ],
        "authors": [
            "Zhankun Luo",
            "Abolfazl Hashemi"
        ],
        "published": "2024-05-28T14:46:20Z"
    },
    {
        "title": "Position Paper: Think Globally, React Locally -- Bringing Real-time\n  Reference-based Website Phishing Detection on macOS",
        "link": "http://arxiv.org/abs/2405.18236v1",
        "abstract": "Background. The recent surge in phishing attacks keeps undermining the\neffectiveness of the traditional anti-phishing blacklist approaches. On-device\nanti-phishing solutions are gaining popularity as they offer faster phishing\ndetection locally. Aim. We aim to eliminate the delay in recognizing and\nrecording phishing campaigns in databases via on-device solutions that identify\nphishing sites immediately when encountered by the user rather than waiting for\na web crawler's scan to finish. Additionally, utilizing operating\nsystem-specific resources and frameworks, we aim to minimize the impact on\nsystem performance and depend on local processing to protect user privacy.\nMethod. We propose a phishing detection solution that uses a combination of\ncomputer vision and on-device machine learning models to analyze websites in\nreal time. Our reference-based approach analyzes the visual content of\nwebpages, identifying phishing attempts through layout analysis, credential\ninput areas detection, and brand impersonation criteria combination. Results.\nOur case study shows it's feasible to perform background processing on-device\ncontinuously, for the case of the web browser requiring the resource use of 16%\nof a single CPU core and less than 84MB of RAM on Apple M1 while maintaining\nthe accuracy of brand logo detection at 46.6% (comparable with baselines), and\nof Credential Requiring Page detection at 98.1% (improving the baseline by\n3.1%), within the test dataset. Conclusions. Our results demonstrate the\npotential of on-device, real-time phishing detection systems to enhance\ncybersecurity defensive technologies and extend the scope of phishing detection\nto more similar regions of interest, e.g., email clients and messenger windows.",
        "subjects": [
            "cs.CR",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Ivan Petrukha",
            "Nataliia Stulova",
            "Sergii Kryvoblotskyi"
        ],
        "published": "2024-05-28T14:46:03Z"
    },
    {
        "title": "Cooperative Relative Localization in MAV Swarms with Ultra-wideband\n  Ranging",
        "link": "http://arxiv.org/abs/2405.18234v1",
        "abstract": "Relative localization (RL) is essential for the successful operation of micro\nair vehicle (MAV) swarms. Achieving accurate 3-D RL in infrastructure-free and\nGPS-denied environments with only distance information is a challenging problem\nthat has not been satisfactorily solved. In this work, based on the range-based\npeer-to-peer RL using the ultra-wideband (UWB) ranging technique, we develop a\nnovel UWB-based cooperative relative localization (CRL) solution that\nintegrates the relative motion dynamics of each host-neighbor pair to build a\nunified dynamic model and takes the distances between the neighbors as\n\\textit{bonus information}. Observability analysis using differential geometry\nshows that the proposed CRL scheme can expand the observable subspace compared\nto other alternatives using only direct distances between the host agent and\nits neighbors. In addition, we apply the kernel-induced extended Kalman filter\n(EKF) to the CRL state estimation problem with the novel-designed\nLogarithmic-Versoria (LV) kernel to tackle heavy-tailed UWB noise. Sufficient\nconditions for the convergence of the fixed-point iteration involved in the\nestimation algorithm are also derived. Comparative Monte Carlo simulations\ndemonstrate that the proposed CRL scheme combined with the LV-kernel EKF\nsignificantly improves the estimation accuracy owing to its robustness against\nboth measurement outliers and incorrect measurement covariance matrix\ninitialization. Moreover, with the LV kernel, the estimation is still\nsatisfactory when performing the fixed-point iteration only once for reduced\ncomputational complexity.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Changrui Liu",
            "Sven U. Pfeiffer",
            "Guido C. H. E. de Croon"
        ],
        "published": "2024-05-28T14:45:00Z"
    },
    {
        "title": "SSLChange: A Self-supervised Change Detection Framework Based on Domain\n  Adaptation",
        "link": "http://arxiv.org/abs/2405.18224v1",
        "abstract": "In conventional remote sensing change detection (RS CD) procedures, extensive\nmanual labeling for bi-temporal images is first required to maintain the\nperformance of subsequent fully supervised training. However, pixel-level\nlabeling for CD tasks is very complex and time-consuming. In this paper, we\nexplore a novel self-supervised contrastive framework applicable to the RS CD\ntask, which promotes the model to accurately capture spatial, structural, and\nsemantic information through domain adapter and hierarchical contrastive head.\nThe proposed SSLChange framework accomplishes self-learning only by taking a\nsingle-temporal sample and can be flexibly transferred to main-stream CD\nbaselines. With self-supervised contrastive learning, feature representation\npre-training can be performed directly based on the original data even without\nlabeling. After a certain amount of labels are subsequently obtained, the\npre-trained features will be aligned with the labels for fully supervised\nfine-tuning. Without introducing any additional data or labels, the performance\nof downstream baselines will experience a significant enhancement. Experimental\nresults on 2 entire datasets and 6 diluted datasets show that our proposed\nSSLChange improves the performance and stability of CD baseline in data-limited\nsituations. The code of SSLChange will be released at\n\\url{https://github.com/MarsZhaoYT/SSLChange}",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yitao Zhao",
            "Turgay Celik",
            "Nanqing Liu",
            "Feng Gao",
            "Heng-Chao Li"
        ],
        "published": "2024-05-28T14:34:51Z"
    },
    {
        "title": "Multi-modal Mood Reader: Pre-trained Model Empowers Cross-Subject\n  Emotion Recognition",
        "link": "http://arxiv.org/abs/2405.19373v1",
        "abstract": "Emotion recognition based on Electroencephalography (EEG) has gained\nsignificant attention and diversified development in fields such as neural\nsignal processing and affective computing. However, the unique brain anatomy of\nindividuals leads to non-negligible natural differences in EEG signals across\nsubjects, posing challenges for cross-subject emotion recognition. While recent\nstudies have attempted to address these issues, they still face limitations in\npractical effectiveness and model framework unity. Current methods often\nstruggle to capture the complex spatial-temporal dynamics of EEG signals and\nfail to effectively integrate multimodal information, resulting in suboptimal\nperformance and limited generalizability across subjects. To overcome these\nlimitations, we develop a Pre-trained model based Multimodal Mood Reader for\ncross-subject emotion recognition that utilizes masked brain signal modeling\nand interlinked spatial-temporal attention mechanism. The model learns\nuniversal latent representations of EEG signals through pre-training on large\nscale dataset, and employs Interlinked spatial-temporal attention mechanism to\nprocess Differential Entropy(DE) features extracted from EEG data.\nSubsequently, a multi-level fusion layer is proposed to integrate the\ndiscriminative features, maximizing the advantages of features across different\ndimensions and modalities. Extensive experiments on public datasets demonstrate\nMood Reader's superior performance in cross-subject emotion recognition tasks,\noutperforming state-of-the-art methods. Additionally, the model is dissected\nfrom attention perspective, providing qualitative analysis of emotion-related\nbrain areas, offering valuable insights for affective research in neural signal\nprocessing.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "authors": [
            "Yihang Dong",
            "Xuhang Chen",
            "Yanyan Shen",
            "Michael Kwok-Po Ng",
            "Tao Qian",
            "Shuqiang Wang"
        ],
        "published": "2024-05-28T14:31:11Z"
    },
    {
        "title": "From Learning to Optimize to Learning Optimization Algorithms",
        "link": "http://arxiv.org/abs/2405.18222v1",
        "abstract": "Towards designing learned optimization algorithms that are usable beyond\ntheir training setting, we identify key principles that classical algorithms\nobey, but have up to now, not been used for Learning to Optimize (L2O).\nFollowing these principles, we provide a general design pipeline, taking into\naccount data, architecture and learning strategy, and thereby enabling a\nsynergy between classical optimization and L2O, resulting in a philosophy of\nLearning Optimization Algorithms. As a consequence our learned algorithms\nperform well far beyond problems from the training distribution. We demonstrate\nthe success of these novel principles by designing a new learning-enhanced BFGS\nalgorithm and provide numerical experiments evidencing its adaptation to many\nsettings at test time.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Camille Castera",
            "Peter Ochs"
        ],
        "published": "2024-05-28T14:30:07Z"
    },
    {
        "title": "Recurrent Natural Policy Gradient for POMDPs",
        "link": "http://arxiv.org/abs/2405.18221v1",
        "abstract": "In this paper, we study a natural policy gradient method based on recurrent\nneural networks (RNNs) for partially-observable Markov decision processes,\nwhereby RNNs are used for policy parameterization and policy evaluation to\naddress curse of dimensionality in non-Markovian reinforcement learning. We\npresent finite-time and finite-width analyses for both the critic (recurrent\ntemporal difference learning), and correspondingly-operated recurrent natural\npolicy gradient method in the near-initialization regime. Our analysis\ndemonstrates the efficiency of RNNs for problems with short-term memory with\nexplicit bounds on the required network widths and sample complexity, and\npoints out the challenges in the case of long-term dependencies.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Semih Cayci",
            "Atilla Eryilmaz"
        ],
        "published": "2024-05-28T14:29:31Z"
    },
    {
        "title": "Non-negative Tensor Mixture Learning for Discrete Density Estimation",
        "link": "http://arxiv.org/abs/2405.18220v1",
        "abstract": "We present an expectation-maximization (EM) based unified framework for\nnon-negative tensor decomposition that optimizes the Kullback-Leibler\ndivergence. To avoid iterations in each M-step and learning rate tuning, we\nestablish a general relationship between low-rank decomposition and many-body\napproximation. Using this connection, we exploit that the closed-form solution\nof the many-body approximation can be used to update all parameters\nsimultaneously in the M-step. Our framework not only offers a unified\nmethodology for a variety of low-rank structures, including CP, Tucker, and\nTrain decompositions, but also their combinations forming mixtures of tensors\nas well as robust adaptive noise modeling. Empirically, we demonstrate that our\nframework provides superior generalization for discrete density estimation\ncompared to conventional tensor-based approaches.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "68T01",
            "I.2.6"
        ],
        "authors": [
            "Kazu Ghalamkari",
            "Jesper Løve Hinrich",
            "Morten Mørup"
        ],
        "published": "2024-05-28T14:28:28Z"
    },
    {
        "title": "FinerCut: Finer-grained Interpretable Layer Pruning for Large Language\n  Models",
        "link": "http://arxiv.org/abs/2405.18218v1",
        "abstract": "Overparametrized transformer networks are the state-of-the-art architecture\nfor Large Language Models (LLMs). However, such models contain billions of\nparameters making large compute a necessity, while raising environmental\nconcerns. To address these issues, we propose FinerCut, a new form of\nfine-grained layer pruning, which in contrast to prior work at the transformer\nblock level, considers all self-attention and feed-forward network (FFN) layers\nwithin blocks as individual pruning candidates. FinerCut prunes layers whose\nremoval causes minimal alternation to the model's output -- contributing to a\nnew, lean, interpretable, and task-agnostic pruning method. Tested across 9\nbenchmarks, our approach retains 90% performance of Llama3-8B with 25% layers\nremoved, and 95% performance of Llama3-70B with 30% layers removed, all without\nfine-tuning or post-pruning reconstruction. Strikingly, we observe intriguing\nresults with FinerCut: 42% (34 out of 80) of the self-attention layers in\nLlama3-70B can be removed while preserving 99% of its performance -- without\nadditional fine-tuning after removal. Moreover, FinerCut provides a tool to\ninspect the types and locations of pruned layers, allowing to observe\ninteresting pruning behaviors. For instance, we observe a preference for\npruning self-attention layers, often at deeper consecutive decoder layers. We\nhope our insights inspire future efficient LLM architecture designs.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Yang Zhang",
            "Yawei Li",
            "Xinpeng Wang",
            "Qianli Shen",
            "Barbara Plank",
            "Bernd Bischl",
            "Mina Rezaei",
            "Kenji Kawaguchi"
        ],
        "published": "2024-05-28T14:21:15Z"
    },
    {
        "title": "Understanding Inter-Concept Relationships in Concept-Based Models",
        "link": "http://arxiv.org/abs/2405.18217v1",
        "abstract": "Concept-based explainability methods provide insight into deep learning\nsystems by constructing explanations using human-understandable concepts. While\nthe literature on human reasoning demonstrates that we exploit relationships\nbetween concepts when solving tasks, it is unclear whether concept-based\nmethods incorporate the rich structure of inter-concept relationships. We\nanalyse the concept representations learnt by concept-based models to\nunderstand whether these models correctly capture inter-concept relationships.\nFirst, we empirically demonstrate that state-of-the-art concept-based models\nproduce representations that lack stability and robustness, and such methods\nfail to capture inter-concept relationships. Then, we develop a novel algorithm\nwhich leverages inter-concept relationships to improve concept intervention\naccuracy, demonstrating how correctly capturing inter-concept relationships can\nimprove downstream tasks.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Naveen Raman",
            "Mateo Espinosa Zarlenga",
            "Mateja Jamnik"
        ],
        "published": "2024-05-28T14:20:49Z"
    },
    {
        "title": "A Survey on Modern Code Review: Progresses, Challenges and Opportunities",
        "link": "http://arxiv.org/abs/2405.18216v1",
        "abstract": "Over the past decade, modern code review (MCR) has been deemed as a crucial\npractice of software quality assurance, which is applied to improve software\nquality and transfer development knowledge within a software team. Despite its\nimportance, MCR is often a complicated and time-consuming activity for\npractitioners. In recent years, many studies that are dedicated to the\ncomprehension and the improvement of MCR have been explored so that the MCR\nactivity can be carried out more conveniently and efficiently. To provide\nresearchers and practitioners a clear understanding of the current research\nstatus on MCR, this paper conducts a systematic literature review of the past\nyears. Given the collected 231 surveyed papers, this paper makes the following\nfive contributions: First, we analyze the research trends of related MCR\nstudies. Second, we provide a taxonomy for the current MCR, encompassing both\nImprovement Techniques and Understanding Studies. Third, we present the\nconcrete research progress of each novel MCR methodology and prototype tool.\nFourth, we exploit the main empirical insights from empirical study and user\nstudy that are helpful to improve MCR. Finally, we sum up unsolved challenges\nand outline several possible research opportunities in the future.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Zezhou Yang",
            "Cuiyun Gao",
            "Zhaoqiang Guo",
            "Zhenhao Li",
            "Kui Liu",
            "Xin Xia",
            "Yuming Zhou"
        ],
        "published": "2024-05-28T14:20:38Z"
    },
    {
        "title": "Tactile-Driven Non-Prehensile Object Manipulation via Extrinsic Contact\n  Mode Control",
        "link": "http://arxiv.org/abs/2405.18214v1",
        "abstract": "In this paper, we consider the problem of non-prehensile manipulation using\ngrasped objects. This problem is a superset of many common manipulation skills\nincluding instances of tool-use (e.g., grasped spatula flipping a burger) and\nassembly (e.g., screwdriver tightening a screw). Here, we present an\nalgorithmic approach for non-prehensile manipulation leveraging a gripper with\nhighly compliant and high-resolution tactile sensors. Our approach solves for\nrobot actions that drive object poses and forces to desired values while\nobeying the complex dynamics induced by the sensors as well as the constraints\nimposed by static equilibrium, object kinematics, and frictional contact. Our\nmethod is able to produce a variety of manipulation skills and is amenable to\ngradient-based optimization by exploiting differentiability within contact\nmodes (e.g., specifications of sticking or sliding contacts). We evaluate 4\nvariants of controllers that attempt to realize these plans and demonstrate a\nnumber of complex skills including non-prehensile planar sliding and pivoting\non a variety of object geometries. The perception and controls capabilities\nthat drive these skills are the building blocks towards dexterous and reactive\nautonomy in unstructured environments.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Miquel Oller",
            "Dmitry Berenson",
            "Nima Fazeli"
        ],
        "published": "2024-05-28T14:18:22Z"
    },
    {
        "title": "NeRAF: 3D Scene Infused Neural Radiance and Acoustic Fields",
        "link": "http://arxiv.org/abs/2405.18213v1",
        "abstract": "Sound plays a major role in human perception, providing essential scene\ninformation alongside vision for understanding our environment. Despite\nprogress in neural implicit representations, learning acoustics that match a\nvisual scene is still challenging. We propose NeRAF, a method that jointly\nlearns acoustic and radiance fields. NeRAF is designed as a Nerfstudio module\nfor convenient access to realistic audio-visual generation. It synthesizes both\nnovel views and spatialized audio at new positions, leveraging radiance field\ncapabilities to condition the acoustic field with 3D scene information. At\ninference, each modality can be rendered independently and at spatially\nseparated positions, providing greater versatility. We demonstrate the\nadvantages of our method on the SoundSpaces dataset. NeRAF achieves substantial\nperformance improvements over previous works while being more data-efficient.\nFurthermore, NeRAF enhances novel view synthesis of complex scenes trained with\nsparse data through cross-modal learning.",
        "subjects": [
            "cs.SD",
            "cs.CV",
            "eess.AS"
        ],
        "authors": [
            "Amandine Brunetto",
            "Sascha Hornauer",
            "Fabien Moutarde"
        ],
        "published": "2024-05-28T14:17:41Z"
    },
    {
        "title": "Safe Multi-Agent Reinforcement Learning with Bilevel Optimization in\n  Autonomous Driving",
        "link": "http://arxiv.org/abs/2405.18209v1",
        "abstract": "Ensuring safety in MARL, particularly when deploying it in real-world\napplications such as autonomous driving, emerges as a critical challenge. To\naddress this challenge, traditional safe MARL methods extend MARL approaches to\nincorporate safety considerations, aiming to minimize safety risk values.\nHowever, these safe MARL algorithms often fail to model other agents and lack\nconvergence guarantees, particularly in dynamically complex environments. In\nthis study, we propose a safe MARL method grounded in a Stackelberg model with\nbi-level optimization, for which convergence analysis is provided. Derived from\nour theoretical analysis, we develop two practical algorithms, namely\nConstrained Stackelberg Q-learning (CSQ) and Constrained Stackelberg\nMulti-Agent Deep Deterministic Policy Gradient (CS-MADDPG), designed to\nfacilitate MARL decision-making in autonomous driving applications. To evaluate\nthe effectiveness of our algorithms, we developed a safe MARL autonomous\ndriving benchmark and conducted experiments on challenging autonomous driving\nscenarios, such as merges, roundabouts, intersections, and racetracks. The\nexperimental results indicate that our algorithms, CSQ and CS-MADDPG,\noutperform several strong MARL baselines, such as Bi-AC, MACPO, and MAPPO-L,\nregarding reward and safety performance. The demos and source code are\navailable at\n{https://github.com/SafeRL-Lab/Safe-MARL-in-Autonomous-Driving.git}.",
        "subjects": [
            "cs.RO",
            "cs.LG"
        ],
        "authors": [
            "Zhi Zheng",
            "Shangding Gu"
        ],
        "published": "2024-05-28T14:15:18Z"
    },
    {
        "title": "A Human-Like Reasoning Framework for Multi-Phases Planning Task with\n  Large Language Models",
        "link": "http://arxiv.org/abs/2405.18208v1",
        "abstract": "Recent studies have highlighted their proficiency in some simple tasks like\nwriting and coding through various reasoning strategies. However, LLM agents\nstill struggle with tasks that require comprehensive planning, a process that\nchallenges current models and remains a critical research issue. In this study,\nwe concentrate on travel planning, a Multi-Phases planning problem, that\ninvolves multiple interconnected stages, such as outlining, information\ngathering, and planning, often characterized by the need to manage various\nconstraints and uncertainties. Existing reasoning approaches have struggled to\neffectively address this complex task. Our research aims to address this\nchallenge by developing a human-like planning framework for LLM agents, i.e.,\nguiding the LLM agent to simulate various steps that humans take when solving\nMulti-Phases problems. Specifically, we implement several strategies to enable\nLLM agents to generate a coherent outline for each travel query, mirroring\nhuman planning patterns. Additionally, we integrate Strategy Block and\nKnowledge Block into our framework: Strategy Block facilitates information\ncollection, while Knowledge Block provides essential information for detailed\nplanning. Through our extensive experiments, we demonstrate that our framework\nsignificantly improves the planning capabilities of LLM agents, enabling them\nto tackle the travel planning task with improved efficiency and effectiveness.\nOur experimental results showcase the exceptional performance of the proposed\nframework; when combined with GPT-4-Turbo, it attains $10\\times$ the\nperformance gains in comparison to the baseline framework deployed on\nGPT-4-Turbo.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Chengxing Xie",
            "Difan Zou"
        ],
        "published": "2024-05-28T14:13:32Z"
    },
    {
        "title": "Space-Filling Input Design for Nonlinear State-Space Identification",
        "link": "http://arxiv.org/abs/2405.18207v1",
        "abstract": "The quality of a model resulting from (black-box) system identification is\nhighly dependent on the quality of the data that is used during the\nidentification procedure. Designing experiments for linear time-invariant\nsystems is well understood and mainly focuses on the power spectrum of the\ninput signal. Performing experiment design for nonlinear system identification\non the other hand remains an open challenge as informativity of the data\ndepends both on the frequency-domain content and on the time-domain evolution\nof the input signal. Furthermore, as nonlinear system identification is much\nmore sensitive to modeling and extrapolation errors, having experiments that\nexplore the considered operation range of interest is of high importance.\nHence, this paper focuses on designing space-filling experiments i.e.,\nexperiments that cover the full operation range of interest, for nonlinear\ndynamical systems that can be represented in a state-space form using a broad\nset of input signals. The presented experiment design approach can\nstraightforwardly be extended to a wider range of system classes (e.g.,\nNARMAX). The effectiveness of the proposed approach is illustrated on the\nexperiment design for a nonlinear mass-spring-damper system, using a multisine\ninput signal.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Máté Kiss",
            "Roland Tóth",
            "Maarten Schoukens"
        ],
        "published": "2024-05-28T14:12:54Z"
    },
    {
        "title": "Multi-CATE: Multi-Accurate Conditional Average Treatment Effect\n  Estimation Robust to Unknown Covariate Shifts",
        "link": "http://arxiv.org/abs/2405.18206v1",
        "abstract": "Estimating heterogeneous treatment effects is important to tailor treatments\nto those individuals who would most likely benefit. However, conditional\naverage treatment effect predictors may often be trained on one population but\npossibly deployed on different, possibly unknown populations. We use\nmethodology for learning multi-accurate predictors to post-process CATE\nT-learners (differenced regressions) to become robust to unknown covariate\nshifts at the time of deployment. The method works in general for\npseudo-outcome regression, such as the DR-learner. We show how this approach\ncan combine (large) confounded observational and (smaller) randomized datasets\nby learning a confounded predictor from the observational dataset, and auditing\nfor multi-accuracy on the randomized controlled trial. We show improvements in\nbias and mean squared error in simulations with increasingly larger covariate\nshift, and on a semi-synthetic case study of a parallel large observational\nstudy and smaller randomized controlled experiment. Overall, we establish a\nconnection between methods developed for multi-distribution learning and\nachieve appealing desiderata (e.g. external validity) in causal inference and\nmachine learning.",
        "subjects": [
            "cs.LG",
            "stat.ME",
            "stat.ML"
        ],
        "authors": [
            "Christoph Kern",
            "Michael Kim",
            "Angela Zhou"
        ],
        "published": "2024-05-28T14:12:25Z"
    },
    {
        "title": "Joint Radar Sensing, Location, and Communication Resources Optimization\n  in 6G Network",
        "link": "http://arxiv.org/abs/2405.18205v1",
        "abstract": "The possibility of jointly optimizing location sensing and communication\nresources, facilitated by the existence of communication and sensing spectrum\nsharing, is what promotes the system performance to a higher level. However,\nthe rapid mobility of user equipment (UE) can result in inaccurate location\nestimation, which can severely degrade system performance. Therefore, the\nprecise UE location sensing and resource allocation issues are investigated in\na spectrum sharing sixth generation network. An approach is proposed for joint\nsubcarrier and power optimization based on UE location sensing, aiming to\nminimize system energy consumption. The joint allocation process is separated\ninto two key phases of operation. In the radar location sensing phase, the\nmultipath interference and Doppler effects are considered simultaneously, and\nthe issues of UE's location and channel state estimation are transformed into a\nconvex optimization problem, which is then solved through gradient descent. In\nthe communication phase, a subcarrier allocation method based on subcarrier\nweights is proposed. To further minimize system energy consumption, a joint\nsubcarrier and power allocation method is introduced, resolved via the Lagrange\nmultiplier method for the non-convex resource allocation problem. Simulation\nanalysis results indicate that the location sensing algorithm exhibits a\nprominent improvement in accuracy compared to benchmark algorithms.\nSimultaneously, the proposed resource allocation scheme also demonstrates a\nsubstantial enhancement in performance relative to baseline schemes.",
        "subjects": [
            "eess.SY",
            "cs.SY",
            "eess.SP"
        ],
        "authors": [
            "Haijun Zhang",
            "Bowen Chen",
            "Xiangnan Liu",
            "Chao Ren"
        ],
        "published": "2024-05-28T14:11:42Z"
    },
    {
        "title": "IAPT: Instruction-Aware Prompt Tuning for Large Language Models",
        "link": "http://arxiv.org/abs/2405.18203v1",
        "abstract": "Soft prompt tuning is a widely studied parameter-efficient fine-tuning\nmethod. However, it has a clear drawback: many soft tokens must be inserted\ninto the input sequences to guarantee downstream performance. As a result, soft\nprompt tuning is less considered than Low-rank adaptation (LoRA) in the large\nlanguage modeling (LLM) era. In this work, we propose a novel prompt tuning\nmethod, Instruction-Aware Prompt Tuning (IAPT), that requires only four soft\ntokens. First, we install a parameter-efficient soft prompt generator at each\nTransformer layer to generate idiosyncratic soft prompts for each input\ninstruction. The generated soft prompts can be seen as a semantic summary of\nthe input instructions and can effectively guide the output generation. Second,\nthe soft prompt generators are modules with a bottleneck architecture\nconsisting of a self-attention pooling operation, two linear projections, and\nan activation function. Pilot experiments show that prompt generators at\ndifferent Transformer layers require different activation functions. Thus, we\npropose to learn the idiosyncratic activation functions for prompt generators\nautomatically with the help of rational functions. We have conducted\nexperiments on various tasks, and the experimental results demonstrate that (a)\nour IAPT method can outperform the recent baselines with comparable tunable\nparameters. (b) Our IAPT method is more efficient than LoRA under the\nsingle-backbone multi-tenant setting.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Wei Zhu",
            "Aaron Xuxiang Tian",
            "Congrui Yin",
            "Yuan Ni",
            "Xiaoling Wang",
            "Guotong Xie"
        ],
        "published": "2024-05-28T14:11:01Z"
    },
    {
        "title": "IM-Context: In-Context Learning for Imbalanced Regression Tasks",
        "link": "http://arxiv.org/abs/2405.18202v1",
        "abstract": "Regression models often fail to generalize effectively in regions\ncharacterized by highly imbalanced label distributions. Previous methods for\ndeep imbalanced regression rely on gradient-based weight updates, which tend to\noverfit in underrepresented regions. This paper proposes a paradigm shift\ntowards in-context learning as an effective alternative to conventional\nin-weight learning methods, particularly for addressing imbalanced regression.\nIn-context learning refers to the ability of a model to condition itself, given\na prompt sequence composed of in-context samples (input-label pairs) alongside\na new query input to generate predictions, without requiring any parameter\nupdates. In this paper, we study the impact of the prompt sequence on the model\nperformance from both theoretical and empirical perspectives. We emphasize the\nimportance of localized context in reducing bias within regions of high\nimbalance. Empirical evaluations across a variety of real-world datasets\ndemonstrate that in-context learning substantially outperforms existing\nin-weight learning methods in scenarios with high levels of imbalance.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ismail Nejjar",
            "Faez Ahmed",
            "Olga Fink"
        ],
        "published": "2024-05-28T14:10:51Z"
    },
    {
        "title": "Adam with model exponential moving average is effective for nonconvex\n  optimization",
        "link": "http://arxiv.org/abs/2405.18199v1",
        "abstract": "In this work, we offer a theoretical analysis of two modern optimization\ntechniques for training large and complex models: (i) adaptive optimization\nalgorithms, such as Adam, and (ii) the model exponential moving average (EMA).\nSpecifically, we demonstrate that a clipped version of Adam with model EMA\nachieves the optimal convergence rates in various nonconvex optimization\nsettings, both smooth and nonsmooth. Moreover, when the scale varies\nsignificantly across different coordinates, we demonstrate that the\ncoordinate-wise adaptivity of Adam is provably advantageous. Notably, unlike\nprevious analyses of Adam, our analysis crucially relies on its core elements\n-- momentum and discounting factors -- as well as model EMA, motivating their\nwide applications in practice.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Kwangjun Ahn",
            "Ashok Cutkosky"
        ],
        "published": "2024-05-28T14:08:04Z"
    },
    {
        "title": "OREO: O-RAN intElligence Orchestration of xApp-based network services",
        "link": "http://arxiv.org/abs/2405.18198v2",
        "abstract": "The Open Radio Access Network (O-RAN) architecture aims to support a plethora\nof network services, such as beam management and network slicing, through the\nuse of third-party applications called xApps. To efficiently provide network\nservices at the radio interface, it is thus essential that the deployment of\nthe xApps is carefully orchestrated. In this paper, we introduce OREO, an O-RAN\nxApp orchestrator, designed to maximize the offered services. OREO's key idea\nis that services can share xApps whenever they correspond to semantically\nequivalent functions, and the xApp output is of sufficient quality to fulfill\nthe service requirements. By leveraging a multi-layer graph model that captures\nall the system components, from services to xApps, OREO implements an\nalgorithmic solution that selects the best service configuration, maximizes the\nnumber of shared xApps, and efficiently and dynamically allocates resources to\nthem. Numerical results as well as experimental tests performed using our\nproof-of-concept implementation, demonstrate that OREO closely matches the\noptimum, obtained by solving an NP-hard problem. Further, it outperforms the\nstate of the art, deploying up to 35% more services with an average of 30%\nfewer xApps and a similar reduction in the resource consumption.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Federico Mungari",
            "Corrado Puligheddu",
            "Andres Garcia-Saavedra",
            "Carla Fabiana Chiasserini"
        ],
        "published": "2024-05-28T14:07:15Z"
    },
    {
        "title": "Render and Diffuse: Aligning Image and Action Spaces for Diffusion-based\n  Behaviour Cloning",
        "link": "http://arxiv.org/abs/2405.18196v1",
        "abstract": "In the field of Robot Learning, the complex mapping between high-dimensional\nobservations such as RGB images and low-level robotic actions, two inherently\nvery different spaces, constitutes a complex learning problem, especially with\nlimited amounts of data. In this work, we introduce Render and Diffuse (R&D) a\nmethod that unifies low-level robot actions and RGB observations within the\nimage space using virtual renders of the 3D model of the robot. Using this\njoint observation-action representation it computes low-level robot actions\nusing a learnt diffusion process that iteratively updates the virtual renders\nof the robot. This space unification simplifies the learning problem and\nintroduces inductive biases that are crucial for sample efficiency and spatial\ngeneralisation. We thoroughly evaluate several variants of R&D in simulation\nand showcase their applicability on six everyday tasks in the real world. Our\nresults show that R&D exhibits strong spatial generalisation capabilities and\nis more sample efficient than more common image-to-action methods.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Vitalis Vosylius",
            "Younggyo Seo",
            "Jafar Uruç",
            "Stephen James"
        ],
        "published": "2024-05-28T14:06:10Z"
    },
    {
        "title": "Delving into Differentially Private Transformer",
        "link": "http://arxiv.org/abs/2405.18194v2",
        "abstract": "Deep learning with differential privacy (DP) has garnered significant\nattention over the past years, leading to the development of numerous methods\naimed at enhancing model accuracy and training efficiency. This paper delves\ninto the problem of training Transformer models with differential privacy. Our\ntreatment is modular: the logic is to `reduce' the problem of training DP\nTransformer to the more basic problem of training DP vanilla neural nets. The\nlatter is better understood and amenable to many model-agnostic methods. Such\n`reduction' is done by first identifying the hardness unique to DP Transformer\ntraining: the attention distraction phenomenon and a lack of compatibility with\nexisting techniques for efficient gradient clipping. To deal with these two\nissues, we propose the Re-Attention Mechanism and Phantom Clipping,\nrespectively. We believe that our work not only casts new light on training DP\nTransformers but also promotes a modular treatment to advance research in the\nfield of differentially private deep learning.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "authors": [
            "Youlong Ding",
            "Xueyang Wu",
            "Yining Meng",
            "Yonggang Luo",
            "Hao Wang",
            "Weike Pan"
        ],
        "published": "2024-05-28T14:04:09Z"
    },
    {
        "title": "In-Context Symmetries: Self-Supervised Learning through Contextual World\n  Models",
        "link": "http://arxiv.org/abs/2405.18193v1",
        "abstract": "At the core of self-supervised learning for vision is the idea of learning\ninvariant or equivariant representations with respect to a set of data\ntransformations. This approach, however, introduces strong inductive biases,\nwhich can render the representations fragile in downstream tasks that do not\nconform to these symmetries. In this work, drawing insights from world models,\nwe propose to instead learn a general representation that can adapt to be\ninvariant or equivariant to different transformations by paying attention to\ncontext -- a memory module that tracks task-specific states, actions, and\nfuture states. Here, the action is the transformation, while the current and\nfuture states respectively represent the input's representation before and\nafter the transformation. Our proposed algorithm, Contextual Self-Supervised\nLearning (ContextSSL), learns equivariance to all transformations (as opposed\nto invariance). In this way, the model can learn to encode all relevant\nfeatures as general representations while having the versatility to tail down\nto task-wise symmetries when given a few examples as the context. Empirically,\nwe demonstrate significant performance gains over existing methods on\nequivariance-related tasks, supported by both qualitative and quantitative\nevaluations.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Sharut Gupta",
            "Chenyu Wang",
            "Yifei Wang",
            "Tommi Jaakkola",
            "Stefanie Jegelka"
        ],
        "published": "2024-05-28T14:03:52Z"
    },
    {
        "title": "Mutation-Bias Learning in Games",
        "link": "http://arxiv.org/abs/2405.18190v1",
        "abstract": "We present two variants of a multi-agent reinforcement learning algorithm\nbased on evolutionary game theoretic considerations. The intentional simplicity\nof one variant enables us to prove results on its relationship to a system of\nordinary differential equations of replicator-mutator dynamics type, allowing\nus to present proofs on the algorithm's convergence conditions in various\nsettings via its ODE counterpart. The more complicated variant enables\ncomparisons to Q-learning based algorithms. We compare both variants\nexperimentally to WoLF-PHC and frequency-adjusted Q-learning on a range of\nsettings, illustrating cases of increasing dimensionality where our variants\npreserve convergence in contrast to more complicated algorithms. The\navailability of analytic results provides a degree of transferability of\nresults as compared to purely empirical case studies, illustrating the general\nutility of a dynamical systems perspective on multi-agent reinforcement\nlearning when addressing questions of convergence and reliable generalisation.",
        "subjects": [
            "cs.LG",
            "cs.MA",
            "math.DS",
            "math.OC",
            "q-bio.PE",
            "37N40 (Primary) 91A26 (Secondary)"
        ],
        "authors": [
            "Johann Bauer",
            "Sheldon West",
            "Eduardo Alonso",
            "Mark Broom"
        ],
        "published": "2024-05-28T14:02:44Z"
    },
    {
        "title": "AlignIQL: Policy Alignment in Implicit Q-Learning through Constrained\n  Optimization",
        "link": "http://arxiv.org/abs/2405.18187v1",
        "abstract": "Implicit Q-learning (IQL) serves as a strong baseline for offline RL, which\nlearns the value function using only dataset actions through quantile\nregression. However, it is unclear how to recover the implicit policy from the\nlearned implicit Q-function and why IQL can utilize weighted regression for\npolicy extraction. IDQL reinterprets IQL as an actor-critic method and gets\nweights of implicit policy, however, this weight only holds for the optimal\nvalue function. In this work, we introduce a different way to solve the\nimplicit policy-finding problem (IPF) by formulating this problem as an\noptimization problem. Based on this optimization problem, we further propose\ntwo practical algorithms AlignIQL and AlignIQL-hard, which inherit the\nadvantages of decoupling actor from critic in IQL and provide insights into why\nIQL can use weighted regression for policy extraction. Compared with IQL and\nIDQL, we find our method keeps the simplicity of IQL and solves the implicit\npolicy-finding problem. Experimental results on D4RL datasets show that our\nmethod achieves competitive or superior results compared with other SOTA\noffline RL methods. Especially in complex sparse reward tasks like Antmaze and\nAdroit, our method outperforms IQL and IDQL by a significant margin.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Longxiang He",
            "Li Shen",
            "Junbo Tan",
            "Xueqian Wang"
        ],
        "published": "2024-05-28T14:01:03Z"
    },
    {
        "title": "A blended physics-based and black-box identification approach for\n  spacecraft inertia estimation -- EXTENDED VERSION",
        "link": "http://arxiv.org/abs/2405.18186v1",
        "abstract": "In this paper, the problem of identifying inertial characteristics of a\ngeneric space vehicle relying on the physical and structural insights of the\ndynamical system is presented. To this aim, we exploit a recently introduced\nframework for the identification of physical parameters directly feeding the\nmeasurements into a backpropagation-like learning algorithm. In particular,\nthis paper extends this approach by introducing a recursive algorithm that\ncombines physics-based and black-box techniques to enhance accuracy and\nreliability in estimating spacecraft inertia. We demonstrate through numerical\nresults that, relying on the derived algorithm to identify the inertia tensor\nof a nanosatellite, we can achieve improved estimation accuracy and robustness,\nby integrating physical constraints and leveraging partial knowledge of the\nsystem dynamics. In particular, we show how it is possible to enhance the\nconvergence of the physics-based algorithm to the true values by either\noverparametrization or introducing a black-box term that captures the\nunmodelled dynamics related to the off-diagonal components.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Martina Mammarella",
            "Cesare Donati",
            "Fabrizio Dabbene",
            "Carlo Novara",
            "Constantino Lagoa"
        ],
        "published": "2024-05-28T13:54:48Z"
    },
    {
        "title": "Drawing with Distance",
        "link": "http://arxiv.org/abs/2405.18182v1",
        "abstract": "Drawing (a multiset of) coloured balls from an urn is one of the most basic\nmodels in discrete probability theory. Three modes of drawing are commonly\ndistinguished: multinomial (draw-replace), hypergeometric (draw-delete), and\nP\\'olya (draw-add). These drawing operations are represented as maps from urns\nto distributions over multisets of draws. The set of urns is a metric space via\nthe Wasserstein distance. The set of distributions over draws is also a metric\nspace, using Wasserstein-over-Wasserstein. It is shown that these three draw\noperations are all isometries, that is, they exactly preserve the Wasserstein\ndistances. Further, drawing is studied in the limit, both for large urns and\nfor large draws. First it is shown that, as the urn size increases, the\nWasserstein distances go to zero between hypergeometric and multinomial draws,\nand also between P\\'olya and multinomial draws. Second, it is shown that, as\nthe draw size increases, the Wasserstein distance goes to zero (in probability)\nbetween an urn and (normalised) multinomial draws from the urn. These results\nare known, but here, they are formulated in a novel manner as limits of\nWasserstein distances. We call these two limit results the law of large urns\nand the law of large draws.",
        "subjects": [
            "cs.LO",
            "math.PR",
            "03B70, 68Q87, 18C50",
            "F.3.2; G.3"
        ],
        "authors": [
            "Bart Jacobs"
        ],
        "published": "2024-05-28T13:50:07Z"
    },
    {
        "title": "Feature-Based Online Bilateral Trade",
        "link": "http://arxiv.org/abs/2405.18183v1",
        "abstract": "Bilateral trade models the problem of facilitating trades between a seller\nand a buyer having private valuations for the item being sold. In the online\nversion of the problem, the learner faces a new seller and buyer at each time\nstep, and has to post a price for each of the two parties without any knowledge\nof their valuations. We consider a scenario where, at each time step, before\nposting prices the learner observes a context vector containing information\nabout the features of the item for sale. The valuations of both the seller and\nthe buyer follow an unknown linear function of the context. In this setting,\nthe learner could leverage previous transactions in an attempt to estimate\nprivate valuations. We characterize the regret regimes of different settings,\ntaking as a baseline the best context-dependent prices in hindsight. First, in\nthe setting in which the learner has two-bit feedback and strong budget balance\nconstraints, we propose an algorithm with $O(\\log T)$ regret. Then, we study\nthe same set-up with noisy valuations, providing a tight $\\widetilde\nO(T^{\\frac23})$ regret upper bound. Finally, we show that loosening budget\nbalance constraints allows the learner to operate under more restrictive\nfeedback. Specifically, we show how to address the one-bit, global budget\nbalance setting through a reduction from the two-bit, strong budget balance\nsetup. This established a fundamental trade-off between the quality of the\nfeedback and the strictness of the budget constraints.",
        "subjects": [
            "cs.GT"
        ],
        "authors": [
            "Solenne Gaucher",
            "Martino Bernasconi",
            "Matteo Castiglioni",
            "Andrea Celli",
            "Vianney Perchet"
        ],
        "published": "2024-05-28T13:50:07Z"
    },
    {
        "title": "Towards Practicable Algorithms for Rewriting Graph Queries beyond\n  DL-Lite",
        "link": "http://arxiv.org/abs/2405.18181v1",
        "abstract": "Despite the many advantages that ontology-based data access (OBDA) has\nbrought to a range of application domains, state-of-the-art OBDA systems still\ndo not support popular graph database management systems such as Neo4j.\nAlgorithms for query rewriting focus on languages like conjunctive queries and\ntheir unions, which are fragments of first-order logic and were developed for\nrelational data. Such query languages are poorly suited for querying graph\ndata. Moreover, they also limit the expressiveness of the ontology languages\nthat admit rewritings, restricting them to those where the data complexity of\nreasoning is not higher than it is in first-order logic. In this paper, we\npropose a technique for rewriting a family of navigational queries for a\nsuitably restricted fragment of ELHI that extends DL-Lite and that is\nNL-complete in data complexity. We implemented a proof-of-concept prototype\nthat rewrites into Cypher queries, and tested it on a real-world cognitive\nneuroscience use case with promising results.",
        "subjects": [
            "cs.DB",
            "cs.LO"
        ],
        "authors": [
            "Bianca Löhnert",
            "Nikolaus Augsten",
            "Cem Okulmus",
            "Magdalena Ortiz"
        ],
        "published": "2024-05-28T13:48:36Z"
    },
    {
        "title": "Safe Reinforcement Learning in Black-Box Environments via Adaptive\n  Shielding",
        "link": "http://arxiv.org/abs/2405.18180v1",
        "abstract": "Empowering safe exploration of reinforcement learning (RL) agents during\ntraining is a critical impediment towards deploying RL agents in many\nreal-world scenarios. Training RL agents in unknown, black-box environments\nposes an even greater safety risk when prior knowledge of the domain/task is\nunavailable. We introduce ADVICE (Adaptive Shielding with a Contrastive\nAutoencoder), a novel post-shielding technique that distinguishes safe and\nunsafe features of state-action pairs during training, thus protecting the RL\nagent from executing actions that yield potentially hazardous outcomes. Our\ncomprehensive experimental evaluation against state-of-the-art safe RL\nexploration techniques demonstrates how ADVICE can significantly reduce safety\nviolations during training while maintaining a competitive outcome reward.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Daniel Bethell",
            "Simos Gerasimou",
            "Radu Calinescu",
            "Calum Imrie"
        ],
        "published": "2024-05-28T13:47:21Z"
    },
    {
        "title": "Rethinking the A in STEAM: Insights from and for AI Literacy Education",
        "link": "http://arxiv.org/abs/2405.18179v1",
        "abstract": "This article rethinks the role of arts in STEAM education, emphasizing its\nimportance in AI literacy within K-12 contexts. Arguing against the\nmarginalization of arts, the paper is structured around four key domains:\nlanguage studies, philosophy, social studies, and visual arts. Each section\naddresses critical AI-related phenomena and provides pedagogical strate-gies\nfor effective integration into STEAM education. Language studies focus on media\nrepresentations and the probabilistic nature of AI language models. The\nphilosophy section examines anthropomorphism, ethics, and the misconstrued\nhuman-like capabilities of AI. Social studies discuss AI's societal impacts,\nbiases, and ethical considerations in data prac-tices. Visual arts explore the\nimplications of generative AI on artistic processes and intellec-tual property.\nThe article concludes by advocating for a robust inclusion of arts in STEAM to\nfoster a holistic, equitable, and sustainable understanding of AI, ultimately\ninspiring technologies that promote fairness and creativity.",
        "subjects": [
            "cs.CY"
        ],
        "authors": [
            "Pekka Mertala",
            "JAnne Fagerlund",
            "Tomi Slotte Dufva"
        ],
        "published": "2024-05-28T13:46:22Z"
    },
    {
        "title": "SEMF: Supervised Expectation-Maximization Framework for Predicting\n  Intervals",
        "link": "http://arxiv.org/abs/2405.18176v2",
        "abstract": "This work introduces the Supervised Expectation-Maximization Framework\n(SEMF), a versatile and model-agnostic framework that generates prediction\nintervals for datasets with complete or missing data. SEMF extends the\nExpectation-Maximization (EM) algorithm, traditionally used in unsupervised\nlearning, to a supervised context, enabling it to extract latent\nrepresentations for uncertainty estimation. The framework demonstrates\nrobustness through extensive empirical evaluation across 11 tabular datasets,\nachieving$\\unicode{x2013}$in some cases$\\unicode{x2013}$narrower normalized\nprediction intervals and higher coverage than traditional quantile regression\nmethods. Furthermore, SEMF integrates seamlessly with existing machine learning\nalgorithms, such as gradient-boosted trees and neural networks, exemplifying\nits usefulness for real-world applications. The experimental results highlight\nSEMF's potential to advance state-of-the-art techniques in uncertainty\nquantification.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Ilia Azizi",
            "Marc-Olivier Boldi",
            "Valérie Chavez-Demoulin"
        ],
        "published": "2024-05-28T13:43:34Z"
    },
    {
        "title": "Crash Report Accumulation During Continuous Fuzzing",
        "link": "http://arxiv.org/abs/2405.18174v1",
        "abstract": "Crash report accumulation is a necessary step during continuous fuzzing.\nDynamic software analysis techniques like fuzzing and dynamic symbolic\nexecution generate a large number of crashes for analysis. However, the time\nand resource constraints often lead to the postponement of fixing some less\ncritical issues, potentially introducing new errors in future releases. Thus,\nthere is a need to distinguish new errors from old ones. We propose a crash\naccumulation method and implemented it as part of the CASR toolset. We\nevaluated our approach on crash reports collected from fuzzing results.",
        "subjects": [
            "cs.CR",
            "cs.SE"
        ],
        "authors": [
            "Ilya Yegorov",
            "Georgy Savidov"
        ],
        "published": "2024-05-28T13:36:31Z"
    },
    {
        "title": "AnyFit: Controllable Virtual Try-on for Any Combination of Attire Across\n  Any Scenario",
        "link": "http://arxiv.org/abs/2405.18172v1",
        "abstract": "While image-based virtual try-on has made significant strides, emerging\napproaches still fall short of delivering high-fidelity and robust fitting\nimages across various scenarios, as their models suffer from issues of\nill-fitted garment styles and quality degrading during the training process,\nnot to mention the lack of support for various combinations of attire.\nTherefore, we first propose a lightweight, scalable, operator known as Hydra\nBlock for attire combinations. This is achieved through a parallel attention\nmechanism that facilitates the feature injection of multiple garments from\nconditionally encoded branches into the main network. Secondly, to\nsignificantly enhance the model's robustness and expressiveness in real-world\nscenarios, we evolve its potential across diverse settings by synthesizing the\nresiduals of multiple models, as well as implementing a mask region boost\nstrategy to overcome the instability caused by information leakage in existing\nmodels. Equipped with the above design, AnyFit surpasses all baselines on\nhigh-resolution benchmarks and real-world data by a large gap, excelling in\nproducing well-fitting garments replete with photorealistic and rich details.\nFurthermore, AnyFit's impressive performance on high-fidelity virtual try-ons\nin any scenario from any image, paves a new path for future research within the\nfashion community.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Yuhan Li",
            "Hao Zhou",
            "Wenxiang Shang",
            "Ran Lin",
            "Xuanhong Chen",
            "Bingbing Ni"
        ],
        "published": "2024-05-28T13:33:08Z"
    },
    {
        "title": "An Open-Source Reproducible Chess Robot for Human-Robot Interaction\n  Research",
        "link": "http://arxiv.org/abs/2405.18170v1",
        "abstract": "Recent advancements in AI have sped up the evolution of versatile robot\ndesigns. Chess provides a standardized environment that allows for the\nevaluation of the influence of robot behaviors on human behavior. This article\npresents an open-source chess robot for human-robot interaction (HRI) research,\nspecifically focusing on verbal and non-verbal interactions. OpenChessRobot\nrecognizes chess pieces using computer vision, executes moves, and interacts\nwith the human player using voice and robotic gestures. We detail the software\ndesign, provide quantitative evaluations of the robot's efficacy and offer a\nguide for its reproducibility. The code and are accessible on GitHub:\nhttps://github.com/renchizhhhh/OpenChessRobot",
        "subjects": [
            "cs.RO",
            "cs.HC"
        ],
        "authors": [
            "Renchi Zhang",
            "Joost de Winter",
            "Dimitra Dodou",
            "Harleigh Seyffert",
            "Yke Bauke Eisma"
        ],
        "published": "2024-05-28T13:30:53Z"
    },
    {
        "title": "Efficient Adaptable Streaming Aggregation Engine",
        "link": "http://arxiv.org/abs/2405.18168v1",
        "abstract": "Aggregation queries are a series of computationally-demanding analytics\noperations on grouped and/or time series (streaming) data. They include tasks\nsuch as summation or finding the mean among the items of a group (sharing a\ngroup ID) or within the last N observed tuples. They have a wide range of\napplications including in database analytics, operating systems, bank security\nand medical sensors. Existing challenges include the increased hardware\nutilisation and random memory access patterns that result from hash-based\napproaches or multi-tasking as a way to introduce parallelism. There are also\nchallenges relating to the degree of which the function can be calculated\nincrementally for sliding windows, such as with overlapping windows. This paper\npresents a pipelined and reconfigurable approach for calculating a wide range\nof aggregation queries with minimal hardware overhead.",
        "subjects": [
            "cs.AR",
            "cs.DB"
        ],
        "authors": [
            "Philippos Papaphilippou",
            "Wayne Luk"
        ],
        "published": "2024-05-28T13:29:31Z"
    },
    {
        "title": "Confidence-aware multi-modality learning for eye disease screening",
        "link": "http://arxiv.org/abs/2405.18167v1",
        "abstract": "Multi-modal ophthalmic image classification plays a key role in diagnosing\neye diseases, as it integrates information from different sources to complement\ntheir respective performances. However, recent improvements have mainly focused\non accuracy, often neglecting the importance of confidence and robustness in\npredictions for diverse modalities. In this study, we propose a novel\nmulti-modality evidential fusion pipeline for eye disease screening. It\nprovides a measure of confidence for each modality and elegantly integrates the\nmulti-modality information using a multi-distribution fusion perspective.\nSpecifically, our method first utilizes normal inverse gamma prior\ndistributions over pre-trained models to learn both aleatoric and epistemic\nuncertainty for uni-modality. Then, the normal inverse gamma distribution is\nanalyzed as the Student's t distribution. Furthermore, within a\nconfidence-aware fusion framework, we propose a mixture of Student's t\ndistributions to effectively integrate different modalities, imparting the\nmodel with heavy-tailed properties and enhancing its robustness and\nreliability. More importantly, the confidence-aware multi-modality ranking\nregularization term induces the model to more reasonably rank the noisy\nsingle-modal and fused-modal confidence, leading to improved reliability and\naccuracy. Experimental results on both public and internal datasets demonstrate\nthat our model excels in robustness, particularly in challenging scenarios\ninvolving Gaussian noise and modality missing conditions. Moreover, our model\nexhibits strong generalization capabilities to out-of-distribution data,\nunderscoring its potential as a promising solution for multimodal eye disease\nscreening.",
        "subjects": [
            "eess.IV",
            "cs.CV"
        ],
        "authors": [
            "Ke Zou",
            "Tian Lin",
            "Zongbo Han",
            "Meng Wang",
            "Xuedong Yuan",
            "Haoyu Chen",
            "Changqing Zhang",
            "Xiaojing Shen",
            "Huazhu Fu"
        ],
        "published": "2024-05-28T13:27:30Z"
    },
    {
        "title": "Defending Large Language Models Against Jailbreak Attacks via\n  Layer-specific Editing",
        "link": "http://arxiv.org/abs/2405.18166v1",
        "abstract": "Large language models (LLMs) are increasingly being adopted in a wide range\nof real-world applications. Despite their impressive performance, recent\nstudies have shown that LLMs are vulnerable to deliberately crafted adversarial\nprompts even when aligned via Reinforcement Learning from Human Feedback or\nsupervised fine-tuning. While existing defense methods focus on either\ndetecting harmful prompts or reducing the likelihood of harmful responses\nthrough various means, defending LLMs against jailbreak attacks based on the\ninner mechanisms of LLMs remains largely unexplored. In this work, we\ninvestigate how LLMs response to harmful prompts and propose a novel defense\nmethod termed \\textbf{L}ayer-specific \\textbf{Ed}iting (LED) to enhance the\nresilience of LLMs against jailbreak attacks. Through LED, we reveal that\nseveral critical \\textit{safety layers} exist among the early layers of LLMs.\nWe then show that realigning these safety layers (and some selected additional\nlayers) with the decoded safe response from selected target layers can\nsignificantly improve the alignment of LLMs against jailbreak attacks.\nExtensive experiments across various LLMs (e.g., Llama2, Mistral) show the\neffectiveness of LED, which effectively defends against jailbreak attacks while\nmaintaining performance on benign prompts. Our code is available at\n\\url{https://github.com/ledllm/ledllm}.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Wei Zhao",
            "Zhe Li",
            "Yige Li",
            "Ye Zhang",
            "Jun Sun"
        ],
        "published": "2024-05-28T13:26:12Z"
    },
    {
        "title": "Time Series Representation Models",
        "link": "http://arxiv.org/abs/2405.18165v1",
        "abstract": "Time series analysis remains a major challenge due to its sparse\ncharacteristics, high dimensionality, and inconsistent data quality. Recent\nadvancements in transformer-based techniques have enhanced capabilities in\nforecasting and imputation; however, these methods are still resource-heavy,\nlack adaptability, and face difficulties in integrating both local and global\nattributes of time series. To tackle these challenges, we propose a new\narchitectural concept for time series analysis based on introspection. Central\nto this concept is the self-supervised pretraining of Time Series\nRepresentation Models (TSRMs), which once learned can be easily tailored and\nfine-tuned for specific tasks, such as forecasting and imputation, in an\nautomated and resource-efficient manner. Our architecture is equipped with a\nflexible and hierarchical representation learning process, which is robust\nagainst missing data and outliers. It can capture and learn both local and\nglobal features of the structure, semantics, and crucial patterns of a given\ntime series category, such as heart rate data. Our learned time series\nrepresentation models can be efficiently adapted to a specific task, such as\nforecasting or imputation, without manual intervention. Furthermore, our\narchitecture's design supports explainability by highlighting the significance\nof each input value for the task at hand. Our empirical study using four\nbenchmark datasets shows that, compared to investigated state-of-the-art\nbaseline methods, our architecture improves imputation and forecasting errors\nby up to 90.34% and 71.54%, respectively, while reducing the required trainable\nparameters by up to 92.43%. The source code is available at\nhttps://github.com/RobertLeppich/TSRM.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Robert Leppich",
            "Vanessa Borst",
            "Veronika Lesch",
            "Samuel Kounev"
        ],
        "published": "2024-05-28T13:25:31Z"
    },
    {
        "title": "NegGS: Negative Gaussian Splatting",
        "link": "http://arxiv.org/abs/2405.18163v2",
        "abstract": "One of the key advantages of 3D rendering is its ability to simulate\nintricate scenes accurately. One of the most widely used methods for this\npurpose is Gaussian Splatting, a novel approach that is known for its rapid\ntraining and inference capabilities. In essence, Gaussian Splatting involves\nincorporating data about the 3D objects of interest into a series of Gaussian\ndistributions, each of which can then be depicted in 3D in a manner analogous\nto traditional meshes. It is regrettable that the use of Gaussians in Gaussian\nSplatting is currently somewhat restrictive due to their perceived linear\nnature. In practice, 3D objects are often composed of complex curves and highly\nnonlinear structures. This issue can to some extent be alleviated by employing\na multitude of Gaussian components to reflect the complex, nonlinear structures\naccurately. However, this approach results in a considerable increase in time\ncomplexity. This paper introduces the concept of negative Gaussians, which are\ninterpreted as items with negative colors. The rationale behind this approach\nis based on the density distribution created by dividing the probability\ndensity functions (PDFs) of two Gaussians, which we refer to as Diff-Gaussian.\nSuch a distribution can be used to approximate structures such as donut and\nmoon-shaped datasets. Experimental findings indicate that the application of\nthese techniques enhances the modeling of high-frequency elements with rapid\ncolor transitions. Additionally, it improves the representation of shadows. To\nthe best of our knowledge, this is the first paper to extend the simple\nelipsoid shapes of Gaussian Splatting to more complex nonlinear structures.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Artur Kasymov",
            "Bartosz Czekaj",
            "Marcin Mazur",
            "Jacek Tabor",
            "Przemysław Spurek"
        ],
        "published": "2024-05-28T13:24:25Z"
    },
    {
        "title": "Back to the Drawing Board for Fair Representation Learning",
        "link": "http://arxiv.org/abs/2405.18161v1",
        "abstract": "The goal of Fair Representation Learning (FRL) is to mitigate biases in\nmachine learning models by learning data representations that enable high\naccuracy on downstream tasks while minimizing discrimination based on sensitive\nattributes. The evaluation of FRL methods in many recent works primarily\nfocuses on the tradeoff between downstream fairness and accuracy with respect\nto a single task that was used to approximate the utility of representations\nduring training (proxy task). This incentivizes retaining only features\nrelevant to the proxy task while discarding all other information. In extreme\ncases, this can cause the learned representations to collapse to a trivial,\nbinary value, rendering them unusable in transfer settings. In this work, we\nargue that this approach is fundamentally mismatched with the original\nmotivation of FRL, which arises from settings with many downstream tasks\nunknown at training time (transfer tasks). To remedy this, we propose to\nrefocus the evaluation protocol of FRL methods primarily around the performance\non transfer tasks. A key challenge when conducting such an evaluation is the\nlack of adequate benchmarks. We address this by formulating four criteria that\na suitable evaluation procedure should fulfill. Based on these, we propose\nTransFair, a benchmark that satisfies these criteria, consisting of novel\nvariations of popular FRL datasets with carefully calibrated transfer tasks. In\nthis setting, we reevaluate state-of-the-art FRL methods, observing that they\noften overfit to the proxy task, which causes them to underperform on certain\ntransfer tasks. We further highlight the importance of task-agnostic learning\nsignals for FRL methods, as they can lead to more transferrable\nrepresentations.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Angéline Pouget",
            "Nikola Jovanović",
            "Mark Vero",
            "Robin Staab",
            "Martin Vechev"
        ],
        "published": "2024-05-28T13:23:04Z"
    },
    {
        "title": "VividPose: Advancing Stable Video Diffusion for Realistic Human Image\n  Animation",
        "link": "http://arxiv.org/abs/2405.18156v1",
        "abstract": "Human image animation involves generating a video from a static image by\nfollowing a specified pose sequence. Current approaches typically adopt a\nmulti-stage pipeline that separately learns appearance and motion, which often\nleads to appearance degradation and temporal inconsistencies. To address these\nissues, we propose VividPose, an innovative end-to-end pipeline based on Stable\nVideo Diffusion (SVD) that ensures superior temporal stability. To enhance the\nretention of human identity, we propose an identity-aware appearance controller\nthat integrates additional facial information without compromising other\nappearance details such as clothing texture and background. This approach\nensures that the generated videos maintain high fidelity to the identity of\nhuman subject, preserving key facial features across various poses. To\naccommodate diverse human body shapes and hand movements, we introduce a\ngeometry-aware pose controller that utilizes both dense rendering maps from\nSMPL-X and sparse skeleton maps. This enables accurate alignment of pose and\nshape in the generated videos, providing a robust framework capable of handling\na wide range of body shapes and dynamic hand movements. Extensive qualitative\nand quantitative experiments on the UBCFashion and TikTok benchmarks\ndemonstrate that our method achieves state-of-the-art performance. Furthermore,\nVividPose exhibits superior generalization capabilities on our proposed\nin-the-wild dataset. Codes and models will be available.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Qilin Wang",
            "Zhengkai Jiang",
            "Chengming Xu",
            "Jiangning Zhang",
            "Yabiao Wang",
            "Xinyi Zhang",
            "Yun Cao",
            "Weijian Cao",
            "Chengjie Wang",
            "Yanwei Fu"
        ],
        "published": "2024-05-28T13:18:32Z"
    },
    {
        "title": "On Bounded Advice Classes",
        "link": "http://arxiv.org/abs/2405.18155v1",
        "abstract": "Advice classes in computational complexity have frequently been used to model\nreal-world scenarios encountered in cryptography, quantum computing and machine\nlearning, where some computational task may be broken down into a preprocessing\nand deployment phase, each associated with a different complexity. However, in\nthese scenarios, the advice given by the preprocessing phase must still be\ngenerated by some (albeit more powerful) bounded machine, which is not the case\nin conventional advice classes. To better model these cases we develop `bounded\nadvice classes', where a more powerful Turing machine generates advice for\nanother, less powerful, Turing machine. We then focus on the question of when\nvarious classes generate useful advice, to answer this we connect bounded\nadvice to unary languages. This connection allows us to state various\nconditional and unconditional results on the utility of advice generated by\n$\\mathsf{EXP}$, $\\mathsf{NP}$, $\\mathsf{BQP}$, $\\mathsf{PSPACE}$, and more. We\nstudy the relations between bounded advice classes, quantum bounded advice\nclasses, and randomised bounded advice. We also examine how each of these\nconcepts interact with recently introduced classes, like $\\mathsf{BPP/samp}$.\nOur results also improve the state of the art in existing research on the\ncomplexity of advice functions.",
        "subjects": [
            "cs.CC",
            "quant-ph"
        ],
        "authors": [
            "Simon Marshall",
            "Casper Gyurik",
            "Vedran Dunjko"
        ],
        "published": "2024-05-28T13:16:10Z"
    },
    {
        "title": "Practical aspects for the creation of an audio dataset from field\n  recordings with optimized labeling budget with AI-assisted strategy",
        "link": "http://arxiv.org/abs/2405.18153v1",
        "abstract": "Machine Listening focuses on developing technologies to extract relevant\ninformation from audio signals. A critical aspect of these projects is the\nacquisition and labeling of contextualized data, which is inherently complex\nand requires specific resources and strategies. Despite the availability of\nsome audio datasets, many are unsuitable for commercial applications. The paper\nemphasizes the importance of Active Learning (AL) using expert labelers over\ncrowdsourcing, which often lacks detailed insights into dataset structures. AL\nis an iterative process combining human labelers and AI models to optimize the\nlabeling budget by intelligently selecting samples for human review. This\napproach addresses the challenge of handling large, constantly growing datasets\nthat exceed available computational resources and memory. The paper presents a\ncomprehensive data-centric framework for Machine Listening projects, detailing\nthe configuration of recording nodes, database structure, and labeling budget\noptimization in resource-constrained scenarios. Applied to an industrial port\nin Valencia, Spain, the framework successfully labeled 6540 ten-second audio\nsamples over five months with a small team, demonstrating its effectiveness and\nadaptability to various resource availability situations.",
        "subjects": [
            "cs.SD",
            "cs.LG",
            "eess.AS"
        ],
        "authors": [
            "Javier Naranjo-Alcazar",
            "Jordi Grau-Haro",
            "Ruben Ribes-Serrano",
            "Pedro Zuccarello"
        ],
        "published": "2024-05-28T13:14:26Z"
    },
    {
        "title": "Tree Coloring: Random Order and Predictions",
        "link": "http://arxiv.org/abs/2405.18151v1",
        "abstract": "Coloring is a notoriously hard problem, and even more so in the online\nsetting, where each arriving vertex has to be colored immediately and\nirrevocably. Already on trees, which are trivially two-colorable, it is\nimpossible to achieve anything better than a logarithmic competitive ratio.\n  We show how to undercut this bound by a double-logarithmic factor in the\nslightly relaxed online model where the vertices arrive in random order. We\nthen also analyze algorithms with predictions, showing how well we can color\ntrees with machine-learned advice of varying reliability. We further extend our\nanalysis to all two-colorable graphs and provide matching lower bounds in both\ncases. Finally, we demonstrate how the two mentioned approaches, both of which\ndiminish the often unjustified pessimism of the classical online model, can be\ncombined to yield even better results.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Fabian Frei",
            "Matthias Gehnen",
            "Dennis Komm",
            "Rastislav Královič",
            "Richard Královič",
            "Peter Rossmanith",
            "Moritz Stocker"
        ],
        "published": "2024-05-28T13:12:54Z"
    },
    {
        "title": "Learning to Detour: Shortcut Mitigating Augmentation for Weakly\n  Supervised Semantic Segmentation",
        "link": "http://arxiv.org/abs/2405.18148v1",
        "abstract": "Weakly supervised semantic segmentation (WSSS) employing weak forms of labels\nhas been actively studied to alleviate the annotation cost of acquiring\npixel-level labels. However, classifiers trained on biased datasets tend to\nexploit shortcut features and make predictions based on spurious correlations\nbetween certain backgrounds and objects, leading to a poor generalization\nperformance. In this paper, we propose shortcut mitigating augmentation (SMA)\nfor WSSS, which generates synthetic representations of object-background\ncombinations not seen in the training data to reduce the use of shortcut\nfeatures. Our approach disentangles the object-relevant and background\nfeatures. We then shuffle and combine the disentangled representations to\ncreate synthetic features of diverse object-background combinations.\nSMA-trained classifier depends less on contexts and focuses more on the target\nobject when making predictions. In addition, we analyzed the behavior of the\nclassifier on shortcut usage after applying our augmentation using an\nattribution method-based metric. The proposed method achieved the improved\nperformance of semantic segmentation result on PASCAL VOC 2012 and MS COCO 2014\ndatasets.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "JuneHyoung Kwon",
            "Eunju Lee",
            "Yunsung Cho",
            "YoungBin Kim"
        ],
        "published": "2024-05-28T13:07:35Z"
    },
    {
        "title": "Unified Low-rank Compression Framework for Click-through Rate Prediction",
        "link": "http://arxiv.org/abs/2405.18146v1",
        "abstract": "Deep Click-Through Rate (CTR) prediction models play an important role in\nmodern industrial recommendation scenarios. However, high memory overhead and\ncomputational costs limit their deployment in resource-constrained\nenvironments. Low-rank approximation is an effective method for computer vision\nand natural language processing models, but its application in compressing CTR\nprediction models has been less explored. Due to the limited memory and\ncomputing resources, compression of CTR prediction models often confronts three\nfundamental challenges, i.e., (1). How to reduce the model sizes to adapt to\nedge devices? (2). How to speed up CTR prediction model inference? (3). How to\nretain the capabilities of original models after compression? Previous low-rank\ncompression research mostly uses tensor decomposition, which can achieve a high\nparameter compression ratio, but brings in AUC degradation and additional\ncomputing overhead. To address these challenges, we propose a unified low-rank\ndecomposition framework for compressing CTR prediction models. We find that\neven with the most classic matrix decomposition SVD method, our framework can\nachieve better performance than the original model. To further improve the\neffectiveness of our framework, we locally compress the output features instead\nof compressing the model weights. Our unified low-rank compression framework\ncan be applied to embedding tables and MLP layers in various CTR prediction\nmodels. Extensive experiments on two academic datasets and one real industrial\nbenchmark demonstrate that, with 3-5x model size reduction, our compressed\nmodels can achieve both faster inference and higher AUC than the uncompressed\noriginal models. Our code is at\nhttps://github.com/yuhao318/Atomic_Feature_Mimicking.",
        "subjects": [
            "cs.IR",
            "cs.LG"
        ],
        "authors": [
            "Hao Yu",
            "Minghao Fu",
            "Jiandong Ding",
            "Yusheng Zhou",
            "Jianxin Wu"
        ],
        "published": "2024-05-28T13:06:32Z"
    },
    {
        "title": "4-bit Shampoo for Memory-Efficient Network Training",
        "link": "http://arxiv.org/abs/2405.18144v1",
        "abstract": "Second-order optimizers, maintaining a matrix termed a preconditioner, are\nsuperior to first-order optimizers in both theory and practice. The states\nforming the preconditioner and its inverse root restrict the maximum size of\nmodels trained by second-order optimizers. To address this, compressing 32-bit\noptimizer states to lower bitwidths has shown promise in reducing memory usage.\nHowever, current approaches only pertain to first-order optimizers. In this\npaper, we propose the first 4-bit second-order optimizers, exemplified by 4-bit\nShampoo, maintaining performance similar to that of 32-bit ones. We show that\nquantizing the eigenvector matrix of the preconditioner in 4-bit Shampoo is\nremarkably better than quantizing the preconditioner itself both theoretically\nand experimentally. By rectifying the orthogonality of the quantized\neigenvector matrix, we enhance the approximation of the preconditioner's\neigenvector matrix, which also benefits the computation of its inverse 4-th\nroot. Besides, we find that linear square quantization slightly outperforms\ndynamic tree quantization when quantizing second-order optimizer states.\nEvaluation on various networks for image classification demonstrates that our\n4-bit Shampoo achieves comparable test accuracy to its 32-bit counterpart while\nbeing more memory-efficient. The source code will be made available.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Sike Wang",
            "Jia Li",
            "Pan Zhou",
            "Hua Huang"
        ],
        "published": "2024-05-28T13:02:56Z"
    },
    {
        "title": "Data-Driven Distributionally Robust System Level Synthesis",
        "link": "http://arxiv.org/abs/2405.18142v1",
        "abstract": "We present a novel approach for the control of uncertain, linear\ntime-invariant systems, which are perturbed by potentially unbounded, additive\ndisturbances. We propose a \\emph{doubly robust} data-driven state-feedback\ncontroller to ensure reliable performance against both model mismatch and\ndisturbance distribution uncertainty. Our controller, which leverages the\nSystem Level Synthesis parameterization, is designed as the solution to a\ndistributionally robust finite-horizon optimal control problem. The goal is to\nminimize a cost function while satisfying constraints against the worst-case\nrealization of the uncertainty, which is quantified using distributional\nambiguity sets. The latter are defined as balls in the Wasserstein metric\ncentered on the predictive empirical distribution computed from a set of\ncollected trajectory data. By harnessing techniques from robust control and\ndistributionally robust optimization, we characterize the distributional shift\nbetween the predictive and the actual closed-loop distributions, and highlight\nits dependency on the model mismatch and the uncertainty about the disturbance\ndistribution. We also provide bounds on the number of samples required to\nachieve a desired confidence level and propose a tractable approximate\nformulation for the doubly robust data-driven controller. To demonstrate the\neffectiveness of our approach, we present a numerical example showcasing the\nperformance of the proposed algorithm.",
        "subjects": [
            "math.OC",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Francesco Micheli",
            "Anastasios Tsiamis",
            "John Lygeros"
        ],
        "published": "2024-05-28T13:01:53Z"
    },
    {
        "title": "Unlocking Futures: A Natural Language Driven Career Prediction System\n  for Computer Science and Software Engineering Students",
        "link": "http://arxiv.org/abs/2405.18139v1",
        "abstract": "A career is a crucial aspect for any person to fulfill their desires through\nhard work. During their studies, students cannot find the best career\nsuggestions unless they receive meaningful guidance tailored to their skills.\nTherefore, we developed an AI-assisted model for early prediction to provide\nbetter career suggestions. Although the task is difficult, proper guidance can\nmake it easier. Effective career guidance requires understanding a student's\nacademic skills, interests, and skill-related activities. In this research, we\ncollected essential information from Computer Science (CS) and Software\nEngineering (SWE) students to train a machine learning (ML) model that predicts\ncareer paths based on students' career-related information. To adequately train\nthe models, we applied Natural Language Processing (NLP) techniques and\ncompleted dataset pre-processing. For comparative analysis, we utilized\nmultiple classification ML algorithms and deep learning (DL) algorithms. This\nstudy contributes valuable insights to educational advising by providing\nspecific career suggestions based on the unique features of CS and SWE\nstudents. Additionally, the research helps individual CS and SWE students find\nsuitable jobs that match their skills, interests, and skill-related activities.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Sakir Hossain Faruque",
            "Sharun Akter Khushbu",
            "Sharmin Akter"
        ],
        "published": "2024-05-28T12:56:57Z"
    },
    {
        "title": "Exploiting LLM Quantization",
        "link": "http://arxiv.org/abs/2405.18137v1",
        "abstract": "Quantization leverages lower-precision weights to reduce the memory usage of\nlarge language models (LLMs) and is a key technique for enabling their\ndeployment on commodity hardware. While LLM quantization's impact on utility\nhas been extensively explored, this work for the first time studies its adverse\neffects from a security perspective. We reveal that widely used quantization\nmethods can be exploited to produce a harmful quantized LLM, even though the\nfull-precision counterpart appears benign, potentially tricking users into\ndeploying the malicious quantized model. We demonstrate this threat using a\nthree-staged attack framework: (i) first, we obtain a malicious LLM through\nfine-tuning on an adversarial task; (ii) next, we quantize the malicious model\nand calculate constraints that characterize all full-precision models that map\nto the same quantized model; (iii) finally, using projected gradient descent,\nwe tune out the poisoned behavior from the full-precision model while ensuring\nthat its weights satisfy the constraints computed in step (ii). This procedure\nresults in an LLM that exhibits benign behavior in full precision but when\nquantized, it follows the adversarial behavior injected in step (i). We\nexperimentally demonstrate the feasibility and severity of such an attack\nacross three diverse scenarios: vulnerable code generation, content injection,\nand over-refusal attack. In practice, the adversary could host the resulting\nfull-precision model on an LLM community hub such as Hugging Face, exposing\nmillions of users to the threat of deploying its malicious quantized version on\ntheir devices.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "authors": [
            "Kazuki Egashira",
            "Mark Vero",
            "Robin Staab",
            "Jingxuan He",
            "Martin Vechev"
        ],
        "published": "2024-05-28T12:51:01Z"
    },
    {
        "title": "Bringing Rust to Safety-Critical Systems in Space",
        "link": "http://arxiv.org/abs/2405.18135v1",
        "abstract": "The development of safety-critical aerospace systems is traditionally\ndominated by the C language. Its language characteristics make it trivial to\naccidentally introduce memory safety issues resulting in undefined behavior or\nsecurity vulnerabilities. The Rust language aims to drastically reduce the\nchance of introducing bugs and consequently produces overall more secure and\nsafer code. However, due to its relatively short lifespan, industry adaption in\nsafety-critical environments is still lacking. This work provides a set of\nrecommendations for the development of safety-critical space systems in Rust.\nOur recommendations are based on insights from our multi-fold contributions\ntowards safer and more secure aerospace systems: We provide a comprehensive\noverview of ongoing efforts to adapt Rust for safety-critical system\nprogramming, highlighting its potential to enhance system robustness. Next, we\nintroduce a procedure for partially rewriting C-based systems in Rust, offering\na pragmatic pathway to improving safety without necessitating a full system\noverhaul. During the execution of our rewriting case study, we identify and fix\nthree previously undiscovered vulnerabilities in a popular open-source\nsatellite communication protocol. Finally, we introduce a new Rust compiler\ntarget configuration for bare metal PowerPC. With this, we aim to broaden\nRust's applicability in space-oriented projects, as the architecture is\ncommonly encountered in the domain, e.g., in the James Webb Space Telescope.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Lukas Seidel",
            "Julian Beier"
        ],
        "published": "2024-05-28T12:48:47Z"
    },
    {
        "title": "Metric and Geometric Spanners that are Resilient to Degree-Bounded Edge\n  Faults",
        "link": "http://arxiv.org/abs/2405.18134v1",
        "abstract": "Let $H$ be an edge-weighted graph, and let $G$ be a subgraph of $H$. We say\nthat $G$ is an $f$-fault-tolerant $t$-spanner for $H$, if the following is true\nfor any subset $F$ of at most $f$ edges of $G$: For any two vertices $p$ and\n$q$, the shortest-path distance between $p$ and $q$ in the graph $G \\setminus\nF$ is at most $t$ times the shortest-path distance between $p$ and $q$ in the\ngraph $H \\setminus F$.\n  Recently, Bodwin, Haeupler, and Parter generalized this notion to the case\nwhen $F$ can be any set of edges in $G$, as long as the maximum degree of $F$\nis at most $f$. They gave constructions for general graphs $H$.\n  We first consider the case when $H$ is a complete graph whose vertex set is\nan arbitrary metric space. We show that if this metric space contains a\n$t$-spanner with $m$ edges, then it also contains a graph $G$ with $O(fm)$\nedges, that is resilient to edge faults of maximum degree $f$ and has stretch\nfactor $O(ft)$.\n  Next, we consider the case when $H$ is a complete graph whose vertex set is a\nmetric space that admits a well-separated pair decomposition. We show that, if\nthe metric space has such a decomposition of size $m$, then it contains a graph\nwith at most $(2f+1)^2 m$ edges, that is resilient to edge faults of maximum\ndegree $f$ and has stretch factor at most $1+\\varepsilon$, for any given\n$\\varepsilon > 0$. For example, if the vertex set is a set of $n$ points in\n$\\mathbb{R}^d$ ($d$ being a constant) or a set of $n$ points in a metric space\nof bounded doubling dimension, then the spanner has $O(f^2 n)$ edges.\n  Finally, for the case when $H$ is a complete graph on $n$ points in\n$\\mathbb{R}^d$, we show how natural variants of the Yao- and $\\Theta$-graphs\nlead to graphs with $O(fn)$ edges, that are resilient to edge faults of maximum\ndegree $f$ and have stretch factor at most $1+\\varepsilon$, for any given\n$\\varepsilon > 0$.",
        "subjects": [
            "cs.CG"
        ],
        "authors": [
            "Ahmad Biniaz",
            "Jean-Lou De Carufel",
            "Anil Maheshwari",
            "Michiel Smid"
        ],
        "published": "2024-05-28T12:48:26Z"
    },
    {
        "title": "A Grid-Free Fluid Solver based on Gaussian Spatial Representation",
        "link": "http://arxiv.org/abs/2405.18133v1",
        "abstract": "We present a grid-free fluid solver featuring a novel Gaussian\nrepresentation. Drawing inspiration from the expressive capabilities of 3D\nGaussian Splatting in multi-view image reconstruction, we model the continuous\nflow velocity as a weighted sum of multiple Gaussian functions. Leveraging this\nrepresentation, we derive differential operators for the field and implement a\ntime-dependent PDE solver using the traditional operator splitting method.\nCompared to implicit neural representations as another continuous spatial\nrepresentation with increasing attention, our method with flexible 3D Gaussians\npresents enhanced accuracy on vorticity preservation. Moreover, we apply\nphysics-driven strategies to accelerate the optimization-based time integration\nof Gaussian functions. This temporal evolution surpasses previous work based on\nimplicit neural representation with reduced computational time and memory.\nAlthough not surpassing the quality of state-of-the-art Eulerian methods in\nfluid simulation, experiments and ablation studies indicate the potential of\nour memory-efficient representation. With enriched spatial information, our\nmethod exhibits a distinctive perspective combining the advantages of Eulerian\nand Lagrangian approaches.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Jingrui Xing",
            "Bin Wang",
            "Mengyu Chu",
            "Baoquan Chen"
        ],
        "published": "2024-05-28T12:47:49Z"
    },
    {
        "title": "EG4D: Explicit Generation of 4D Object without Score Distillation",
        "link": "http://arxiv.org/abs/2405.18132v1",
        "abstract": "In recent years, the increasing demand for dynamic 3D assets in design and\ngaming applications has given rise to powerful generative pipelines capable of\nsynthesizing high-quality 4D objects. Previous methods generally rely on score\ndistillation sampling (SDS) algorithm to infer the unseen views and motion of\n4D objects, thus leading to unsatisfactory results with defects like\nover-saturation and Janus problem. Therefore, inspired by recent progress of\nvideo diffusion models, we propose to optimize a 4D representation by\nexplicitly generating multi-view videos from one input image. However, it is\nfar from trivial to handle practical challenges faced by such a pipeline,\nincluding dramatic temporal inconsistency, inter-frame geometry and texture\ndiversity, and semantic defects brought by video generation results. To address\nthese issues, we propose DG4D, a novel multi-stage framework that generates\nhigh-quality and consistent 4D assets without score distillation. Specifically,\ncollaborative techniques and solutions are developed, including an attention\ninjection strategy to synthesize temporal-consistent multi-view videos, a\nrobust and efficient dynamic reconstruction method based on Gaussian Splatting,\nand a refinement stage with diffusion prior for semantic restoration. The\nqualitative results and user preference study demonstrate that our framework\noutperforms the baselines in generation quality by a considerable margin. Code\nwill be released at \\url{https://github.com/jasongzy/EG4D}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Qi Sun",
            "Zhiyang Guo",
            "Ziyu Wan",
            "Jing Nathan Yan",
            "Shengming Yin",
            "Wengang Zhou",
            "Jing Liao",
            "Houqiang Li"
        ],
        "published": "2024-05-28T12:47:22Z"
    },
    {
        "title": "Self-Supervised Dual Contouring",
        "link": "http://arxiv.org/abs/2405.18131v1",
        "abstract": "Learning-based isosurface extraction methods have recently emerged as a\nrobust and efficient alternative to axiomatic techniques. However, the vast\nmajority of such approaches rely on supervised training with axiomatically\ncomputed ground truths, thus potentially inheriting biases and data artifacts\nof the corresponding axiomatic methods. Steering away from such dependencies,\nwe propose a self-supervised training scheme for the Neural Dual Contouring\nmeshing framework, resulting in our method: Self-Supervised Dual Contouring\n(SDC). Instead of optimizing predicted mesh vertices with supervised training,\nwe use two novel self-supervised loss functions that encourage the consistency\nbetween distances to the generated mesh up to the first order. Meshes\nreconstructed by SDC surpass existing data-driven methods in capturing\nintricate details while being more robust to possible irregularities in the\ninput. Furthermore, we use the same self-supervised training objective linking\ninferred mesh and input SDF, to regularize the training process of Deep\nImplicit Networks (DINs). We demonstrate that the resulting DINs produce\nhigher-quality implicit functions, ultimately leading to more accurate and\ndetail-preserving surfaces compared to prior baselines for different input\nmodalities. Finally, we demonstrate that our self-supervised losses improve\nmeshing performance in the single-view reconstruction task by enabling joint\ntraining of predicted SDF and resulting output mesh. We open-source our code at\nhttps://github.com/Sentient07/SDC",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ramana Sundararaman",
            "Roman Klokov",
            "Maks Ovsjanikov"
        ],
        "published": "2024-05-28T12:44:28Z"
    },
    {
        "title": "Graph Coarsening with Message-Passing Guarantees",
        "link": "http://arxiv.org/abs/2405.18127v1",
        "abstract": "Graph coarsening aims to reduce the size of a large graph while preserving\nsome of its key properties, which has been used in many applications to reduce\ncomputational load and memory footprint. For instance, in graph machine\nlearning, training Graph Neural Networks (GNNs) on coarsened graphs leads to\ndrastic savings in time and memory. However, GNNs rely on the Message-Passing\n(MP) paradigm, and classical spectral preservation guarantees for graph\ncoarsening do not directly lead to theoretical guarantees when performing naive\nmessage-passing on the coarsened graph. In this work, we propose a new\nmessage-passing operation specific to coarsened graphs, which exhibit\ntheoretical guarantees on the preservation of the propagated signal.\nInterestingly, and in a sharp departure from previous proposals, this operation\non coarsened graphs is oriented, even when the original graph is undirected. We\nconduct node classification tasks on synthetic and real data and observe\nimproved results compared to performing naive message-passing on the coarsened\ngraph.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Antonin Joly",
            "Nicolas Keriven"
        ],
        "published": "2024-05-28T12:39:24Z"
    },
    {
        "title": "Dual-Path Multi-Scale Transformer for High-Quality Image Deraining",
        "link": "http://arxiv.org/abs/2405.18124v1",
        "abstract": "Despite the superiority of convolutional neural networks (CNNs) and\nTransformers in single-image rain removal, current multi-scale models still\nface significant challenges due to their reliance on single-scale feature\npyramid patterns. In this paper, we propose an effective rain removal method,\nthe dual-path multi-scale Transformer (DPMformer) for high-quality image\nreconstruction by leveraging rich multi-scale information. This method consists\nof a backbone path and two branch paths from two different multi-scale\napproaches. Specifically, one path adopts the coarse-to-fine strategy,\nprogressively downsampling the image to 1/2 and 1/4 scales, which helps capture\nfine-scale potential rain information fusion. Simultaneously, we employ the\nmulti-patch stacked model (non-overlapping blocks of size 2 and 4) to enrich\nthe feature information of the deep network in the other path. To learn a\nricher blend of features, the backbone path fully utilizes the multi-scale\ninformation to achieve high-quality rain removal image reconstruction.\nExtensive experiments on benchmark datasets demonstrate that our method\nachieves promising performance compared to other state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Huiling Zhou",
            "Xianhao Wu",
            "Hongming Chen"
        ],
        "published": "2024-05-28T12:31:23Z"
    },
    {
        "title": "PyTAG: Tabletop Games for Multi-Agent Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.18123v1",
        "abstract": "Modern Tabletop Games present various interesting challenges for Multi-agent\nReinforcement Learning. In this paper, we introduce PyTAG, a new framework that\nsupports interacting with a large collection of games implemented in the\nTabletop Games framework. In this work we highlight the challenges tabletop\ngames provide, from a game-playing agent perspective, along with the\nopportunities they provide for future research. Additionally, we highlight the\ntechnical challenges that involve training Reinforcement Learning agents on\nthese games. To explore the Multi-agent setting provided by PyTAG we train the\npopular Proximal Policy Optimisation Reinforcement Learning algorithm using\nself-play on a subset of games and evaluate the trained policies against some\nsimple agents and Monte-Carlo Tree Search implemented in the Tabletop Games\nframework.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Martin Balla",
            "George E. M. Long",
            "James Goodman",
            "Raluca D. Gaina",
            "Diego Perez-Liebana"
        ],
        "published": "2024-05-28T12:30:28Z"
    },
    {
        "title": "Low-Resource Crop Classification from Multi-Spectral Time Series Using\n  Lossless Compressors",
        "link": "http://arxiv.org/abs/2405.18119v1",
        "abstract": "Deep learning has significantly improved the accuracy of crop classification\nusing multispectral temporal data. However, these models have complex\nstructures with numerous parameters, requiring large amounts of data and costly\ntraining. In low-resource situations with fewer labeled samples, deep learning\nmodels perform poorly due to insufficient data. Conversely, compressors are\ndata-type agnostic, and non-parametric methods do not bring underlying\nassumptions. Inspired by this insight, we propose a non-training alternative to\ndeep learning models, aiming to address these situations. Specifically, the\nSymbolic Representation Module is proposed to convert the reflectivity into\nsymbolic representations. The symbolic representations are then\ncross-transformed in both the channel and time dimensions to generate symbolic\nembeddings. Next, the Multi-scale Normalised Compression Distance (MNCD) is\ndesigned to measure the correlation between any two symbolic embeddings.\nFinally, based on the MNCDs, high quality crop classification can be achieved\nusing only a k-nearest-neighbor classifier kNN. The entire framework is\nready-to-use and lightweight. Without any training, it outperformed, on\naverage, 7 advanced deep learning models trained at scale on three benchmark\ndatasets. It also outperforms more than half of these models in the few-shot\nsetting with sparse crop labels. Therefore, the high performance and robustness\nof our non-training framework makes it truly applicable to real-world crop\nmapping. Codes are available at:\nhttps://github.com/qinfengsama/Compressor-Based-Crop-Mapping.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Wei Cheng",
            "Hongrui Ye",
            "Xiao Wen",
            "Jiachen Zhang",
            "Jiping Xu",
            "Feifan Zhang"
        ],
        "published": "2024-05-28T12:28:12Z"
    },
    {
        "title": "An approach to improve agent learning via guaranteeing goal reaching in\n  all episodes",
        "link": "http://arxiv.org/abs/2405.18118v2",
        "abstract": "Reinforcement learning is commonly concerned with problems of maximizing\naccumulated rewards in Markov decision processes. Oftentimes, a certain goal\nstate or a subset of the state space attain maximal reward. In such a case, the\nenvironment may be considered solved when the goal is reached. Whereas numerous\ntechniques, learning or non-learning based, exist for solving environments,\ndoing so optimally is the biggest challenge. Say, one may choose a reward rate\nwhich penalizes the action effort. Reinforcement learning is currently among\nthe most actively developed frameworks for solving environments optimally by\nvirtue of maximizing accumulated reward, in other words, returns. Yet, tuning\nagents is a notoriously hard task as reported in a series of works. Our aim\nhere is to help the agent learn a near-optimal policy efficiently while\nensuring a goal reaching property of some basis policy that merely solves the\nenvironment. We suggest an algorithm, which is fairly flexible, and can be used\nto augment practically any agent as long as it comprises of a critic. A formal\nproof of a goal reaching property is provided. Simulation experiments on six\nproblems under five agents, including the benchmarked one, provided an\nempirical evidence that the learning can indeed be boosted while ensuring goal\nreaching property.",
        "subjects": [
            "cs.AI",
            "cs.SY",
            "eess.SY",
            "math.DS"
        ],
        "authors": [
            "Pavel Osinenko",
            "Grigory Yaremenko",
            "Georgiy Malaniya",
            "Anton Bolychev"
        ],
        "published": "2024-05-28T12:27:36Z"
    },
    {
        "title": "The Knesset Corpus: An Annotated Corpus of Hebrew Parliamentary\n  Proceedings",
        "link": "http://arxiv.org/abs/2405.18115v1",
        "abstract": "We present the Knesset Corpus, a corpus of Hebrew parliamentary proceedings\ncontaining over 30 million sentences (over 384 million tokens) from all the\n(plenary and committee) protocols held in the Israeli parliament between 1998\nand 2022. Sentences are annotated with morpho-syntactic information and are\nassociated with detailed meta-information reflecting demographic and political\nproperties of the speakers, based on a large database of parliament members and\nfactions that we compiled. We discuss the structure and composition of the\ncorpus and the various processing steps we applied to it. To demonstrate the\nutility of this novel dataset we present two use cases. We show that the corpus\ncan be used to examine historical developments in the style of political\ndiscussions by showing a reduction in lexical richness in the proceedings over\ntime. We also investigate some differences between the styles of men and women\nspeakers. These use cases exemplify the potential of the corpus to shed light\non important trends in the Israeli society, supporting research in linguistics,\npolitical science, communication, law, etc.",
        "subjects": [
            "cs.CL",
            "68T50",
            "I.2.7"
        ],
        "authors": [
            "Gili Goldin",
            "Nick Howell",
            "Noam Ordan",
            "Ella Rabinovich",
            "Shuly Wintner"
        ],
        "published": "2024-05-28T12:23:39Z"
    },
    {
        "title": "Fatigue and mental underload further pronounced in L3 conditionally\n  automated driving: Results from an EEG experiment on a test track",
        "link": "http://dx.doi.org/10.1145/3581754.3584133",
        "abstract": "Drivers' role changes with increasing automation from the primary driver to a\nsystem supervisor. This study investigates how supervising an SAE L2 and L3\nautomated vehicle (AV) affects drivers' mental workload and sleepiness compared\nto manual driving. Using an AV prototype on a test track, the oscillatory brain\nactivity of 23 adult participants was recorded during L2, L3, and manual\ndriving. Results showed decreased mental workload and increased sleepiness in\nL3 drives compared to L2 and manual drives, indicated by self-report scales and\nchanges in the frontal alpha and theta power spectral density. These findings\nsuggest that fatigue and mental underload are significant issues in L3 driving\nand should be considered when designing future AV interfaces.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Nikol Figalová",
            "Hans Joachim Bieg",
            "Michael Schulz",
            "Jürgen Pichen",
            "Martin Baumann",
            "Lewis Chuang",
            "Olga Pollatos"
        ],
        "published": "2024-05-28T12:23:24Z"
    },
    {
        "title": "Facilitating Multi-Role and Multi-Behavior Collaboration of Large\n  Language Models for Online Job Seeking and Recruiting",
        "link": "http://arxiv.org/abs/2405.18113v1",
        "abstract": "The emergence of online recruitment services has revolutionized the\ntraditional landscape of job seeking and recruitment, necessitating the\ndevelopment of high-quality industrial applications to improve person-job\nfitting. Existing methods generally rely on modeling the latent semantics of\nresumes and job descriptions and learning a matching function between them.\nInspired by the powerful role-playing capabilities of Large Language Models\n(LLMs), we propose to introduce a mock interview process between LLM-played\ninterviewers and candidates. The mock interview conversations can provide\nadditional evidence for candidate evaluation, thereby augmenting traditional\nperson-job fitting based solely on resumes and job descriptions. However,\ncharacterizing these two roles in online recruitment still presents several\nchallenges, such as developing the skills to raise interview questions,\nformulating appropriate answers, and evaluating two-sided fitness. To this end,\nwe propose MockLLM, a novel applicable framework that divides the person-job\nmatching process into two modules: mock interview generation and two-sided\nevaluation in handshake protocol, jointly enhancing their performance through\ncollaborative behaviors between interviewers and candidates. We design a\nrole-playing framework as a multi-role and multi-behavior paradigm to enable a\nsingle LLM agent to effectively behave with multiple functions for both\nparties. Moreover, we propose reflection memory generation and dynamic prompt\nmodification techniques to refine the behaviors of both sides, enabling\ncontinuous optimization of the augmented additional evidence. Extensive\nexperimental results show that MockLLM can achieve the best performance on\nperson-job matching accompanied by high mock interview quality, envisioning its\nemerging application in real online recruitment in the future.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Hongda Sun",
            "Hongzhan Lin",
            "Haiyu Yan",
            "Chen Zhu",
            "Yang Song",
            "Xin Gao",
            "Shuo Shang",
            "Rui Yan"
        ],
        "published": "2024-05-28T12:23:16Z"
    },
    {
        "title": "ATM: Adversarial Tuning Multi-agent System Makes a Robust\n  Retrieval-Augmented Generator",
        "link": "http://arxiv.org/abs/2405.18111v1",
        "abstract": "Large language model (LLM) has proven to benefit a lot from retrieval\naugmentation in alleviating hallucinations confronted with knowledge-intensive\nquestions. Retrieval-augmented generation (RAG) adopts IR-based techniques\nutilizing semantic-relevant documents as the generator's input context and\nrealizes external knowledge injection. However, on today's Internet which is\nflooded with content generated by LLMs, there are too many \"related yet\nuseless\" documents or even fake knowledge fabricated by LLMs, which will\nintroduce extra noise to the generator and distract it from giving correct\nresults. To this end, we regard the training of the RAG generator model as a\nmulti-agent adversarial-defensive system, guiding the generator to have a\nbetter taste of whether a specific document helps answer the question through\nthe Adversarial Tuning in a Multi-agent (ATM) system to strengthen the\ngenerator's robustness in an RAG pipeline. After rounds of multi-agent\niterative tuning, we find that the ATM Generator can eventually discriminate\nuseful documents amongst LLM fabrications and achieve better performance than\nstrong baselines.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Junda Zhu",
            "Lingyong Yan",
            "Haibo Shi",
            "Dawei Yin",
            "Lei Sha"
        ],
        "published": "2024-05-28T12:18:50Z"
    },
    {
        "title": "Individual Contributions as Intrinsic Exploration Scaffolds for\n  Multi-agent Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.18110v1",
        "abstract": "In multi-agent reinforcement learning (MARL), effective exploration is\ncritical, especially in sparse reward environments. Although introducing global\nintrinsic rewards can foster exploration in such settings, it often complicates\ncredit assignment among agents. To address this difficulty, we propose\nIndividual Contributions as intrinsic Exploration Scaffolds (ICES), a novel\napproach to motivate exploration by assessing each agent's contribution from a\nglobal view. In particular, ICES constructs exploration scaffolds with Bayesian\nsurprise, leveraging global transition information during centralized training.\nThese scaffolds, used only in training, help to guide individual agents towards\nactions that significantly impact the global latent state transitions.\nAdditionally, ICES separates exploration policies from exploitation policies,\nenabling the former to utilize privileged global information during training.\nExtensive experiments on cooperative benchmark tasks with sparse rewards,\nincluding Google Research Football (GRF) and StarCraft Multi-agent Challenge\n(SMAC), demonstrate that ICES exhibits superior exploration capabilities\ncompared with baselines. The code is publicly available at\nhttps://github.com/LXXXXR/ICES.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.MA",
            "I.2.6; I.2.11"
        ],
        "authors": [
            "Xinran Li",
            "Zifan Liu",
            "Shibo Chen",
            "Jun Zhang"
        ],
        "published": "2024-05-28T12:18:19Z"
    },
    {
        "title": "A Unified Temporal Knowledge Graph Reasoning Model Towards Interpolation\n  and Extrapolation",
        "link": "http://arxiv.org/abs/2405.18106v1",
        "abstract": "Temporal knowledge graph (TKG) reasoning has two settings: interpolation\nreasoning and extrapolation reasoning. Both of them draw plenty of research\ninterest and have great significance. Methods of the former de-emphasize the\ntemporal correlations among facts sequences, while methods of the latter\nrequire strict chronological order of knowledge and ignore inferring clues\nprovided by missing facts of the past. These limit the practicability of TKG\napplications as almost all of the existing TKG reasoning methods are designed\nspecifically to address either one setting. To this end, this paper proposes an\noriginal Temporal PAth-based Reasoning (TPAR) model for both the interpolation\nand extrapolation reasoning. TPAR performs a neural-driven symbolic reasoning\nfashion that is robust to ambiguous and noisy temporal data and with fine\ninterpretability as well. Comprehensive experiments show that TPAR outperforms\nSOTA methods on the link prediction task for both the interpolation and the\nextrapolation settings. A novel pipeline experimental setting is designed to\nevaluate the performances of SOTA combinations and the proposed TPAR towards\ninterpolation and extrapolation reasoning. More diverse experiments are\nconducted to show the robustness and interpretability of TPAR.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Kai Chen",
            "Ye Wang",
            "Yitong Li",
            "Aiping Li",
            "Han Yu",
            "Xin Song"
        ],
        "published": "2024-05-28T12:13:07Z"
    },
    {
        "title": "Apportionment with Weighted Seats",
        "link": "http://arxiv.org/abs/2405.18102v1",
        "abstract": "Apportionment is the task of assigning resources to entities with different\nentitlements in a fair manner, and specifically a manner that is as\nproportional as possible. The best-known application concerns the assignment of\nparliamentary seats to political parties based on their share in the popular\nvote. Here we enrich the standard model of apportionment by associating each\nseat with a weight that reflects the value of that seat, for example because\nseats come with different roles, such as chair or treasurer, that have\ndifferent (objective) values. We define several apportionment methods and\nnatural fairness requirements for this new setting, and study the extent to\nwhich our methods satisfy our requirements. Our findings show that full\nfairness is harder to achieve than in the standard apportionment setting. At\nthe same time, for relaxations of those requirements we can achieve stronger\nresults than in the more general model of weighted fair division, where the\nvalues of objects are subjective.",
        "subjects": [
            "cs.GT"
        ],
        "authors": [
            "Julian Chingoma",
            "Ulle Endriss",
            "Ronald de Haan",
            "Adrian Haret",
            "Jan Maly"
        ],
        "published": "2024-05-28T12:08:54Z"
    },
    {
        "title": "A Pontryagin Perspective on Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.18100v1",
        "abstract": "Reinforcement learning has traditionally focused on learning state-dependent\npolicies to solve optimal control problems in a closed-loop fashion. In this\nwork, we introduce the paradigm of open-loop reinforcement learning where a\nfixed action sequence is learned instead. We present three new algorithms: one\nrobust model-based method and two sample-efficient model-free methods. Rather\nthan basing our algorithms on Bellman's equation from dynamic programming, our\nwork builds on Pontryagin's principle from the theory of open-loop optimal\ncontrol. We provide convergence guarantees and evaluate all methods empirically\non a pendulum swing-up task, as well as on two high-dimensional MuJoCo tasks,\ndemonstrating remarkable performance compared to existing baselines.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Onno Eberhard",
            "Claire Vernade",
            "Michael Muehlebach"
        ],
        "published": "2024-05-28T12:05:20Z"
    },
    {
        "title": "Manipulating Drivers' Mental Workload: Neuroergonomic Evaluation of the\n  Speed Regulation N-Back Task Using NASA-TLX and Auditory P3a",
        "link": "http://dx.doi.org/10.1145/3581961.3609887",
        "abstract": "Manipulating MW in driving simulator studies without the need to introduce a\nnon-driving-related task remains challenging. This study aims to empirically\nevaluate the modified speed regulation n-back task, a tool to manipulate\ndrivers' MW. Our experiment involved 23 participants who experienced a 0-back\nand 2-back driving condition, with task-irrelevant novel environmental sounds\nused to elicit P3a event-related potentials. Results indicate that the 2-back\ncondition was perceived as more demanding, evidenced by higher NASA-TLX scores\n(overall score, mental and temporal demand, effort, frustration). The mean P3a\namplitude was diminished during the 2-back condition compared to the 0-back\ncondition, suggesting that drivers experienced higher MW and had fewer\nresources available to process the novel environmental sounds. This study\nprovides empirical evidence indicating that the speed regulation n-back task\ncould be a valid, effective, and reproducible method to manipulate MW in\ndriving research.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Nikol Figalová",
            "Jürgen Pichen",
            "Vanchha Chandrayan",
            "Olga Pollatos",
            "Lewis Chuang",
            "Martin Baumann"
        ],
        "published": "2024-05-28T12:03:33Z"
    },
    {
        "title": "Is machine learning good or bad for the natural sciences?",
        "link": "http://arxiv.org/abs/2405.18095v1",
        "abstract": "Machine learning (ML) methods are having a huge impact across all of the\nsciences. However, ML has a strong ontology - in which only the data exist -\nand a strong epistemology - in which a model is considered good if it performs\nwell on held-out training data. These philosophies are in strong conflict with\nboth standard practices and key philosophies in the natural sciences. Here, we\nidentify some locations for ML in the natural sciences at which the ontology\nand epistemology are valuable. For example, when an expressive machine learning\nmodel is used in a causal inference to represent the effects of confounders,\nsuch as foregrounds, backgrounds, or instrument calibration parameters, the\nmodel capacity and loose philosophy of ML can make the results more\ntrustworthy. We also show that there are contexts in which the introduction of\nML introduces strong, unwanted statistical biases. For one, when ML models are\nused to emulate physical (or first-principles) simulations, they introduce\nstrong confirmation biases. For another, when expressive regressions are used\nto label datasets, those labels cannot be used in downstream joint or ensemble\nanalyses without taking on uncontrolled biases. The question in the title is\nbeing asked of all of the natural sciences; that is, we are calling on the\nscientific communities to take a step back and consider the role and value of\nML in their fields; the (partial) answers we give here come from the particular\nperspective of physics.",
        "subjects": [
            "stat.ML",
            "astro-ph.IM",
            "cs.LG",
            "physics.data-an"
        ],
        "authors": [
            "David W. Hogg",
            "Soledad Villar"
        ],
        "published": "2024-05-28T12:01:52Z"
    },
    {
        "title": "A space-time variational formulation for the many-body electronic\n  Schr{ö}dinger evolution equation",
        "link": "http://arxiv.org/abs/2405.18094v1",
        "abstract": "We prove in this paper that the solution of the time-dependent\nSchr{\\\"o}dinger equation can be expressed as the solution of a global\nspace-time quadratic minimization problem that is amenable to Galerkin\ntime-space discretization schemes, using an appropriate least-square\nformulation. The present analysis can be applied to the electronic many-body\ntime-dependent Schr{\\\"o}dinger equation with an arbitrary number of electrons\nand interaction potentials with Coulomb singularities. We motivate the interest\nof the present approach with two goals: first, the design of Galerkin\nspace-time discretization methods; second, the definition of dynamical low-rank\napproximations following a variational principle different from the classical\nDirac-Frenkel principle, and for which it is possible to prove the\nglobal-in-time existence of solutions.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Mi-Song Dupuy",
            "Virginie Ehrlacher",
            "Clément Guillot"
        ],
        "published": "2024-05-28T12:00:16Z"
    },
    {
        "title": "Pipette: Automatic Fine-grained Large Language Model Training\n  Configurator for Real-World Clusters",
        "link": "http://arxiv.org/abs/2405.18093v1",
        "abstract": "Training large language models (LLMs) is known to be challenging because of\nthe huge computational and memory capacity requirements. To address these\nissues, it is common to use a cluster of GPUs with 3D parallelism, which splits\na model along the data batch, pipeline stage, and intra-layer tensor\ndimensions. However, the use of 3D parallelism produces the additional\nchallenge of finding the optimal number of ways on each dimension and mapping\nthe split models onto the GPUs. Several previous studies have attempted to\nautomatically find the optimal configuration, but many of these lacked several\nimportant aspects. For instance, the heterogeneous nature of the interconnect\nspeeds is often ignored. While the peak bandwidths for the interconnects are\nusually made equal, the actual attained bandwidth varies per link in real-world\nclusters. Combined with the critical path modeling that does not properly\nconsider the communication, they easily fall into sub-optimal configurations.\nIn addition, they often fail to consider the memory requirement per GPU, often\nrecommending solutions that could not be executed. To address these challenges,\nwe propose Pipette, which is an automatic fine-grained LLM training\nconfigurator for real-world clusters. By devising better performance models\nalong with the memory estimator and fine-grained individual GPU assignment,\nPipette achieves faster configurations that satisfy the memory constraints. We\nevaluated Pipette on large clusters to show that it provides a significant\nspeedup over the prior art. The implementation of Pipette is available at\nhttps://github.com/yimjinkyu1/date2024_pipette.",
        "subjects": [
            "cs.DC",
            "cs.LG"
        ],
        "authors": [
            "Jinkyu Yim",
            "Jaeyong Song",
            "Yerim Choi",
            "Jaebeen Lee",
            "Jaewon Jung",
            "Hongsun Jang",
            "Jinho Lee"
        ],
        "published": "2024-05-28T11:59:44Z"
    },
    {
        "title": "LLM experiments with simulation: Large Language Model Multi-Agent System\n  for Process Simulation Parametrization in Digital Twins",
        "link": "http://arxiv.org/abs/2405.18092v1",
        "abstract": "This paper presents a novel design of a multi-agent system framework that\napplies a large language model (LLM) to automate the parametrization of process\nsimulations in digital twins. We propose a multi-agent framework that includes\nfour types of agents: observation, reasoning, decision and summarization. By\nenabling dynamic interaction between LLM agents and simulation model, the\ndeveloped system can automatically explore the parametrization of the\nsimulation and use heuristic reasoning to determine a set of parameters to\ncontrol the simulation to achieve an objective. The proposed approach enhances\nthe simulation model by infusing it with heuristics from LLM and enables\nautonomous search for feasible parametrization to solve a user task.\nFurthermore, the system has the potential to increase user-friendliness and\nreduce the cognitive load on human users by assisting in complex\ndecision-making processes. The effectiveness and functionality of the system\nare demonstrated through a case study, and the visualized demos are available\nat a GitHub Repository: https://github.com/YuchenXia/LLMDrivenSimulation",
        "subjects": [
            "cs.AI",
            "cs.ET",
            "cs.MA",
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Yuchen Xia",
            "Daniel Dittler",
            "Nasser Jazdi",
            "Haonan Chen",
            "Michael Weyrich"
        ],
        "published": "2024-05-28T11:59:40Z"
    },
    {
        "title": "An adaptive transfer learning perspective on classification in\n  non-stationary environments",
        "link": "http://arxiv.org/abs/2405.18091v1",
        "abstract": "We consider a semi-supervised classification problem with non-stationary\nlabel-shift in which we observe a labelled data set followed by a sequence of\nunlabelled covariate vectors in which the marginal probabilities of the class\nlabels may change over time. Our objective is to predict the corresponding\nclass-label for each covariate vector, without ever observing the ground-truth\nlabels, beyond the initial labelled data set. Previous work has demonstrated\nthe potential of sophisticated variants of online gradient descent to perform\ncompetitively with the optimal dynamic strategy (Bai et al. 2022). In this work\nwe explore an alternative approach grounded in statistical methods for adaptive\ntransfer learning. We demonstrate the merits of this alternative methodology by\nestablishing a high-probability regret bound on the test error at any given\nindividual test-time, which adapt automatically to the unknown dynamics of the\nmarginal label probabilities. Further more, we give bounds on the average\ndynamic regret which match the average guarantees of the online learning\nperspective for any given time interval.",
        "subjects": [
            "math.ST",
            "cs.LG",
            "stat.TH"
        ],
        "authors": [
            "Henry W J Reeve"
        ],
        "published": "2024-05-28T11:57:29Z"
    },
    {
        "title": "FlowSDF: Flow Matching for Medical Image Segmentation Using Distance\n  Transforms",
        "link": "http://arxiv.org/abs/2405.18087v1",
        "abstract": "Medical image segmentation is a crucial task that relies on the ability to\naccurately identify and isolate regions of interest in medical images. Thereby,\ngenerative approaches allow to capture the statistical properties of\nsegmentation masks that are dependent on the respective structures. In this\nwork we propose FlowSDF, an image-guided conditional flow matching framework to\nrepresent the signed distance function (SDF) leading to an implicit\ndistribution of segmentation masks. The advantage of leveraging the SDF is a\nmore natural distortion when compared to that of binary masks. By learning a\nvector field that is directly related to the probability path of a conditional\ndistribution of SDFs, we can accurately sample from the distribution of\nsegmentation masks, allowing for the evaluation of statistical quantities.\nThus, this probabilistic representation allows for the generation of\nuncertainty maps represented by the variance, which can aid in further analysis\nand enhance the predictive robustness. We qualitatively and quantitatively\nillustrate competitive performance of the proposed method on a public nuclei\nand gland segmentation data set, highlighting its utility in medical image\nsegmentation applications.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Lea Bogensperger",
            "Dominik Narnhofer",
            "Alexander Falk",
            "Konrad Schindler",
            "Thomas Pock"
        ],
        "published": "2024-05-28T11:47:12Z"
    },
    {
        "title": "Network Diffusion -- Framework to Simulate Spreading Processes in\n  Complex Networks",
        "link": "http://dx.doi.org/10.26599/BDMA.2024.9020010",
        "abstract": "With the advancement of computational network science, its research scope has\nsignificantly expanded beyond static graphs to encompass more complex\nstructures. The introduction of streaming, temporal, multilayer, and\nhypernetwork approaches has brought new possibilities and imposed additional\nrequirements. For instance, by utilising these advancements, one can model\nstructures such as social networks in a much more refined manner, which is\nparticularly relevant in simulations of the spreading processes. Unfortunately,\nthe pace of advancement is often too rapid for existing computational packages\nto keep up with the functionality updates. This results in a significant\nproliferation of tools used by researchers and, consequently, a lack of a\nuniversally accepted technological stack that would standardise experimental\nmethods (as seen, e.g. in machine learning). This article addresses that issue\nby presenting an extended version of the Network Diffusion library. First, a\nsurvey of the existing approaches and toolkits for simulating spreading\nphenomena is shown and then, an overview of the framework functionalities.\nFinally, we report four case studies conducted with the package to demonstrate\nits usefulness: the impact of sanitary measures on the spread of COVID-19, the\ncomparison of information diffusion on two temporal network models, and the\neffectiveness of seed selection methods in the task of influence maximisation\nin multilayer networks. We conclude the paper with a critical assessment of the\nlibrary and the outline of still awaiting challenges to standardise research\nenvironments in computational network science.",
        "subjects": [
            "cs.SI",
            "cs.MA",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Michał Czuba",
            "Mateusz Nurek",
            "Damian Serwata",
            "Yu-Xuan Qiu",
            "Mingshan Jia",
            "Katarzyna Musial",
            "Radosław Michalski",
            "Piotr Bródka"
        ],
        "published": "2024-05-28T11:46:18Z"
    },
    {
        "title": "Guidance and Control Networks with Periodic Activation Functions",
        "link": "http://arxiv.org/abs/2405.18084v1",
        "abstract": "Inspired by the versatility of sinusoidal representation networks (SIRENs),\nwe present a modified Guidance & Control Networks (G&CNETs) variant using\nperiodic activation functions in the hidden layers. We demonstrate that the\nresulting G&CNETs train faster and achieve a lower overall training error on\nthree different control scenarios on which G&CNETs have been tested previously.\nA preliminary analysis is presented in an attempt to explain the superior\nperformance of the SIREN architecture for the particular types of tasks that\nG&CNETs excel on.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Sebastien Origer",
            "Dario Izzo"
        ],
        "published": "2024-05-28T11:45:30Z"
    },
    {
        "title": "Full Field Inversion of the Attenuated Wave Equation: Theory and\n  Numerical Inversion",
        "link": "http://arxiv.org/abs/2405.18082v1",
        "abstract": "Standard photoacoustic tomography (PAT) provides data that consist of\ntime-dependent signals governed by the wave equation, which are measured on an\nobservation surface. In contrast, the measured data from the recently invented\nfull-field PAT is the Radon transform of the solution of the wave equation on a\nspatial domain at a single instant in time. While reconstruction using\nclassical PAT data has been extensively studied, not much is known about the\nfull-field PAT problem. In this paper, we study full-field photoacoustic\ntomography with spatially variable sound speed and spatially variable damping.\nIn particular, we prove the uniqueness and stability of the associated\nsingle-time full-field wave inversion problem and develop algorithms for its\nnumerical inversion using iterative and variational regularization methods.\nNumerical simulations are presented for both full-angle and limited-angle data\ncases",
        "subjects": [
            "math.NA",
            "cs.NA",
            "math.AP"
        ],
        "authors": [
            "Ngoc Do",
            "Markus Haltmeier",
            "Richard Kowar",
            "Linh V. Nguyen",
            "Robert Nuster"
        ],
        "published": "2024-05-28T11:42:56Z"
    },
    {
        "title": "Optimality of Approximate Message Passing Algorithms for Spiked Matrix\n  Models with Rotationally Invariant Noise",
        "link": "http://arxiv.org/abs/2405.18081v1",
        "abstract": "We study the problem of estimating a rank one signal matrix from an observed\nmatrix generated by corrupting the signal with additive rotationally invariant\nnoise. We develop a new class of approximate message-passing algorithms for\nthis problem and provide a simple and concise characterization of their\ndynamics in the high-dimensional limit. At each iteration, these algorithms\nexploit prior knowledge about the noise structure by applying a non-linear\nmatrix denoiser to the eigenvalues of the observed matrix and prior information\nregarding the signal structure by applying a non-linear iterate denoiser to the\nprevious iterates generated by the algorithm. We exploit our result on the\ndynamics of these algorithms to derive the optimal choices for the matrix and\niterate denoisers. We show that the resulting algorithm achieves the smallest\npossible asymptotic estimation error among a broad class of iterative\nalgorithms under a fixed iteration budget.",
        "subjects": [
            "math.ST",
            "cs.IT",
            "math.IT",
            "math.PR",
            "stat.ML",
            "stat.TH"
        ],
        "authors": [
            "Rishabh Dudeja",
            "Songbin Liu",
            "Junjie Ma"
        ],
        "published": "2024-05-28T11:42:51Z"
    },
    {
        "title": "HarmoDT: Harmony Multi-Task Decision Transformer for Offline\n  Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.18080v1",
        "abstract": "The purpose of offline multi-task reinforcement learning (MTRL) is to develop\na unified policy applicable to diverse tasks without the need for online\nenvironmental interaction. Recent advancements approach this through sequence\nmodeling, leveraging the Transformer architecture's scalability and the\nbenefits of parameter sharing to exploit task similarities. However, variations\nin task content and complexity pose significant challenges in policy\nformulation, necessitating judicious parameter sharing and management of\nconflicting gradients for optimal policy performance. In this work, we\nintroduce the Harmony Multi-Task Decision Transformer (HarmoDT), a novel\nsolution designed to identify an optimal harmony subspace of parameters for\neach task. We approach this as a bi-level optimization problem, employing a\nmeta-learning framework that leverages gradient-based techniques. The upper\nlevel of this framework is dedicated to learning a task-specific mask that\ndelineates the harmony subspace, while the inner level focuses on updating\nparameters to enhance the overall performance of the unified policy. Empirical\nevaluations on a series of benchmarks demonstrate the superiority of HarmoDT,\nverifying the effectiveness of our approach.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Shengchao Hu",
            "Ziqing Fan",
            "Li Shen",
            "Ya Zhang",
            "Yanfeng Wang",
            "Dacheng Tao"
        ],
        "published": "2024-05-28T11:41:41Z"
    },
    {
        "title": "Edge-guided and Class-balanced Active Learning for Semantic Segmentation\n  of Aerial Images",
        "link": "http://arxiv.org/abs/2405.18078v1",
        "abstract": "Semantic segmentation requires pixel-level annotation, which is\ntime-consuming. Active Learning (AL) is a promising method for reducing data\nannotation costs. Due to the gap between aerial and natural images, the\nprevious AL methods are not ideal, mainly caused by unreasonable labeling units\nand the neglect of class imbalance. Previous labeling units are based on images\nor regions, which does not consider the characteristics of segmentation tasks\nand aerial images, i.e., the segmentation network often makes mistakes in the\nedge region, and the edge of aerial images is often interlaced and irregular.\nTherefore, an edge-guided labeling unit is proposed and supplemented as the new\nunit. On the other hand, the class imbalance is severe, manifested in two\naspects: the aerial image is seriously imbalanced, and the AL strategy does not\nfully consider the class balance. Both seriously affect the performance of AL\nin aerial images. We comprehensively ensure class balance from all steps that\nmay occur imbalance, including initial labeled data, subsequent labeled data,\nand pseudo-labels. Through the two improvements, our method achieves more than\n11.2\\% gains compared to state-of-the-art methods on three benchmark datasets,\nDeepglobe, Potsdam, and Vaihingen, and more than 18.6\\% gains compared to the\nbaseline. Sufficient ablation studies show that every module is indispensable.\nFurthermore, we establish a fair and strong benchmark for future research on AL\nfor aerial image segmentation.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Lianlei Shan",
            "Weiqiang Wang",
            "Ke Lv",
            "Bin Luo"
        ],
        "published": "2024-05-28T11:39:36Z"
    },
    {
        "title": "Design Principles for Falsifiable, Replicable and Reproducible Empirical\n  ML Research",
        "link": "http://arxiv.org/abs/2405.18077v1",
        "abstract": "Empirical research plays a fundamental role in the machine learning domain.\nAt the heart of impactful empirical research lies the development of clear\nresearch hypotheses, which then shape the design of experiments. The execution\nof experiments must be carried out with precision to ensure reliable results,\nfollowed by statistical analysis to interpret these outcomes. This process is\nkey to either supporting or refuting initial hypotheses. Despite its\nimportance, there is a high variability in research practices across the\nmachine learning community and no uniform understanding of quality criteria for\nempirical research. To address this gap, we propose a model for the empirical\nresearch process, accompanied by guidelines to uphold the validity of empirical\nresearch. By embracing these recommendations, greater consistency, enhanced\nreliability and increased impact can be achieved.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Daniel Vranješ",
            "Oliver Niggemann"
        ],
        "published": "2024-05-28T11:37:59Z"
    },
    {
        "title": "Implicitly Guided Design with PropEn: Match your Data to Follow the\n  Gradient",
        "link": "http://arxiv.org/abs/2405.18075v1",
        "abstract": "Across scientific domains, generating new models or optimizing existing ones\nwhile meeting specific criteria is crucial. Traditional machine learning\nframeworks for guided design use a generative model and a surrogate model\n(discriminator), requiring large datasets. However, real-world scientific\napplications often have limited data and complex landscapes, making data-hungry\nmodels inefficient or impractical. We propose a new framework, PropEn, inspired\nby ``matching'', which enables implicit guidance without training a\ndiscriminator. By matching each sample with a similar one that has a better\nproperty value, we create a larger training dataset that inherently indicates\nthe direction of improvement. Matching, combined with an encoder-decoder\narchitecture, forms a domain-agnostic generative framework for property\nenhancement. We show that training with a matched dataset approximates the\ngradient of the property of interest while remaining within the data\ndistribution, allowing efficient design optimization. Extensive evaluations in\ntoy problems and scientific applications, such as therapeutic protein design\nand airfoil optimization, demonstrate PropEn's advantages over common\nbaselines. Notably, the protein design results are validated with wet lab\nexperiments, confirming the competitiveness and effectiveness of our approach.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Nataša Tagasovska",
            "Vladimir Gligorijević",
            "Kyunghyun Cho",
            "Andreas Loukas"
        ],
        "published": "2024-05-28T11:30:19Z"
    },
    {
        "title": "A Regularization for Time-Fractional Backward Heat Conduction Problem\n  with Inhomogeneous Source Function",
        "link": "http://arxiv.org/abs/2405.18074v1",
        "abstract": "Recently, Nair and Danumjaya (2023) introduced a new regularization method\nfor the homogeneous time-fractional backward heat conduction problem (TFBHCP)\nin a one-dimensional space variable, for determining the initial value\nfunction. In this paper, the authors extend the analysis done in the above\nreferred paper to a more general setting of an inhomogeneous time-fractional\nheat equation involving the higher dimensional state variables and a general\nelliptic operator. We carry out the analysis for the newly introduced\nregularization method for the TFBHCP providing optimal order error estimates\nunder a source condition by choosing the regularization parameter\nappropriately, and also carry out numerical experiments illustrating the\ntheoretical results.",
        "subjects": [
            "math.AP",
            "cs.NA",
            "math.NA",
            "35K57, 35R25, 35R30, 65J20"
        ],
        "authors": [
            "Vighnesh V. Alavani",
            "P. Danumjaya",
            "M. Thamban Nair"
        ],
        "published": "2024-05-28T11:29:59Z"
    },
    {
        "title": "Towards Dialogues for Joint Human-AI Reasoning and Value Alignment",
        "link": "http://arxiv.org/abs/2405.18073v1",
        "abstract": "We argue that enabling human-AI dialogue, purposed to support joint reasoning\n(i.e., 'inquiry'), is important for ensuring that AI decision making is aligned\nwith human values and preferences. In particular, we point to logic-based\nmodels of argumentation and dialogue, and suggest that the traditional focus on\npersuasion dialogues be replaced by a focus on inquiry dialogues, and the\ndistinct challenges that joint inquiry raises. Given recent dramatic advances\nin the performance of large language models (LLMs), and the anticipated\nincrease in their use for decision making, we provide a roadmap for research\ninto inquiry dialogues for supporting joint human-LLM reasoning tasks that are\nethically salient, and that thereby require that decisions are value aligned.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Elfia Bezou-Vrakatseli",
            "Oana Cocarascu",
            "Sanjay Modgil"
        ],
        "published": "2024-05-28T11:29:57Z"
    },
    {
        "title": "Asynchronous BFT Asset Transfer: Quasi-Anonymous, Light, and\n  Consensus-Free",
        "link": "http://arxiv.org/abs/2405.18072v1",
        "abstract": "This article introduces a new asynchronous Byzantine-tolerant asset transfer\nsystem (cryptocurrency) with three noteworthy properties: quasi-anonymity,\nlightness, and consensus-freedom. Quasi-anonymity means no information is\nleaked regarding the receivers and amounts of the asset transfers. Lightness\nmeans that the underlying cryptographic schemes are \\textit{succinct}, and each\nprocess only stores data polylogarithmic in the number of its own\ntransfers.Consensus-freedom means the system does not rely on a total order of\nasset transfers. The proposed algorithm is the first asset transfer system that\nsimultaneously fulfills all these properties in the presence of asynchrony and\nByzantine processes. To obtain them, the paper adopts a modular approach\ncombining a new distributed object called agreement proofs and well-known\ntechniques such as vector commitments, universal accumulators, and\nzero-knowledge proofs. The paper also presents a new non-trivial universal\naccumulator implementation that does not need knowledge of the underlying\naccumulated set to generate (non-)membership proofs, which could benefit other\ncrypto-based applications.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Timothé Albouy",
            "Emmanuelle Anceaume",
            "Davide Frey",
            "Mathieu Gestin",
            "Arthur Rauch",
            "Michel Raynal",
            "François Taïani"
        ],
        "published": "2024-05-28T11:29:32Z"
    },
    {
        "title": "Text Modality Oriented Image Feature Extraction for Detecting\n  Diffusion-based DeepFake",
        "link": "http://arxiv.org/abs/2405.18071v1",
        "abstract": "The widespread use of diffusion methods enables the creation of highly\nrealistic images on demand, thereby posing significant risks to the integrity\nand safety of online information and highlighting the necessity of DeepFake\ndetection. Our analysis of features extracted by traditional image encoders\nreveals that both low-level and high-level features offer distinct advantages\nin identifying DeepFake images produced by various diffusion methods. Inspired\nby this finding, we aim to develop an effective representation that captures\nboth low-level and high-level features to detect diffusion-based DeepFakes. To\naddress the problem, we propose a text modality-oriented feature extraction\nmethod, termed TOFE. Specifically, for a given target image, the representation\nwe discovered is a corresponding text embedding that can guide the generation\nof the target image with a specific text-to-image model. Experiments conducted\nacross ten diffusion types demonstrate the efficacy of our proposed method.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Di Yang",
            "Yihao Huang",
            "Qing Guo",
            "Felix Juefei-Xu",
            "Xiaojun Jia",
            "Run Wang",
            "Geguang Pu",
            "Yang Liu"
        ],
        "published": "2024-05-28T11:29:30Z"
    },
    {
        "title": "Carbon-Aware Computing in a Network of Data Centers: A Hierarchical\n  Game-Theoretic Approach",
        "link": "http://arxiv.org/abs/2405.18070v1",
        "abstract": "Over the past decade, the continuous surge in cloud computing demand has\nintensified data center workloads, leading to significant carbon emissions and\ndriving the need for improving their efficiency and sustainability. This paper\nfocuses on the optimal allocation problem of batch compute loads with temporal\nand spatial flexibility across a global network of data centers. We propose a\nbilevel game-theoretic solution approach that captures the inherent\nhierarchical relationship between supervisory control objectives, such as\ncarbon reduction and peak shaving, and operational objectives, such as\npriority-aware scheduling. Numerical simulations with real carbon intensity\ndata demonstrate that the proposed approach successfully reduces carbon\nemissions while simultaneously ensuring operational reliability and\npriority-aware scheduling.",
        "subjects": [
            "cs.GT",
            "cs.NI"
        ],
        "authors": [
            "Enno Breukelman",
            "Sophie Hall",
            "Giuseppe Belgioioso",
            "Florian Dörfler"
        ],
        "published": "2024-05-28T11:29:29Z"
    },
    {
        "title": "An Empirical Analysis of Forgetting in Pre-trained Models with\n  Incremental Low-Rank Updates",
        "link": "http://arxiv.org/abs/2405.18069v1",
        "abstract": "Broad, open source availability of large pretrained foundation models on the\ninternet through platforms such as HuggingFace has taken the world of practical\ndeep learning by storm. A classical pipeline for neural network training now\ntypically consists of finetuning these pretrained network on a small target\ndataset instead of training from scratch. In the case of large models this can\nbe done even on modest hardware using a low rank training technique known as\nLow-Rank Adaptation (LoRA). While Low Rank training has already been studied in\nthe continual learning setting, existing works often consider storing the\nlearned adapter along with the existing model but rarely attempt to modify the\nweights of the pretrained model by merging the LoRA with the existing weights\nafter finishing the training of each task. In this article we investigate this\nsetting and study the impact of LoRA rank on the forgetting of the pretraining\nfoundation task and on the plasticity and forgetting of subsequent ones. We\nobserve that this rank has an important impact on forgetting of both the\npretraining and downstream tasks. We also observe that vision transformers\nfinetuned in that way exhibit a sort of ``contextual'' forgetting, a behaviour\nthat we do not observe for residual networks and that we believe has not been\nobserved yet in previous continual learning works.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Albin Soutif--Cormerais",
            "Simone Magistri",
            "Joost van de Weijer",
            "Andew D. Bagdanov"
        ],
        "published": "2024-05-28T11:29:25Z"
    },
    {
        "title": "A Survey of Latent Factor Models in Recommender Systems",
        "link": "http://arxiv.org/abs/2405.18068v1",
        "abstract": "Recommender systems are essential tools in the digital era, providing\npersonalized content to users in areas like e-commerce, entertainment, and\nsocial media. Among the many approaches developed to create these systems,\nlatent factor models have proven particularly effective. This survey\nsystematically reviews latent factor models in recommender systems, focusing on\ntheir core principles, methodologies, and recent advancements. The literature\nis examined through a structured framework covering learning data, model\narchitecture, learning strategies, and optimization techniques. The analysis\nincludes a taxonomy of contributions and detailed discussions on the types of\nlearning data used, such as implicit feedback, trust, and content data, various\nmodels such as probabilistic, nonlinear, and neural models, and an exploration\nof diverse learning strategies like online learning, transfer learning, and\nactive learning. Furthermore, the survey addresses the optimization strategies\nused to train latent factor models, improving their performance and\nscalability. By identifying trends, gaps, and potential research directions,\nthis survey aims to provide valuable insights for researchers and practitioners\nlooking to advance the field of recommender systems.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Hind I. Alshbanat",
            "Hafida Benhidour",
            "Said Kerrache"
        ],
        "published": "2024-05-28T11:28:59Z"
    },
    {
        "title": "An on-demand resource allocation algorithm for a quantum network hub and\n  its performance analysis",
        "link": "http://arxiv.org/abs/2405.18066v1",
        "abstract": "To effectively support the execution of quantum network applications for\nmultiple sets of user-controlled quantum nodes, a quantum network must\nefficiently allocate shared resources. We study traffic models for a type of\nquantum network hub called an Entanglement Generation Switch (EGS), a device\nthat allocates resources to enable entanglement generation between nodes in\nresponse to user-generated demand. We propose an on-demand resource allocation\nalgorithm, where a demand is either blocked if no resources are available or\nelse results in immediate resource allocation. We model the EGS as an Erlang\nloss system, with demands corresponding to sessions whose arrival is modelled\nas a Poisson process. To reflect the operation of a practical quantum switch,\nour model captures scenarios where a resource is allocated for batches of\nentanglement generation attempts, possibly interleaved with calibration periods\nfor the quantum network nodes. Calibration periods are necessary to correct\nagainst drifts or jumps in the physical parameters of a quantum node that occur\non a timescale that is long compared to the duration of an attempt. We then\nderive a formula for the demand blocking probability under three different\ntraffic scenarios using analytical methods from applied probability and\nqueueing theory. We prove an insensitivity theorem which guarantees that the\nprobability a demand is blocked only depends upon the mean duration of each\nentanglement generation attempt and calibration period, and is not sensitive to\nthe underlying distributions of attempt and calibration period duration. We\nprovide numerical results to support our analysis. Our work is the first\nanalysis of traffic characteristics at an EGS system and provides a valuable\nanalytic tool for devising performance driven resource allocation algorithms.",
        "subjects": [
            "quant-ph",
            "cs.NI",
            "cs.PF"
        ],
        "authors": [
            "Scarlett Gauthier",
            "Thirupathaiah Vasantam",
            "Gayane Vardoyan"
        ],
        "published": "2024-05-28T11:25:32Z"
    },
    {
        "title": "EffoVPR: Effective Foundation Model Utilization for Visual Place\n  Recognition",
        "link": "http://arxiv.org/abs/2405.18065v1",
        "abstract": "The task of Visual Place Recognition (VPR) is to predict the location of a\nquery image from a database of geo-tagged images. Recent studies in VPR have\nhighlighted the significant advantage of employing pre-trained foundation\nmodels like DINOv2 for the VPR task. However, these models are often deemed\ninadequate for VPR without further fine-tuning on task-specific data. In this\npaper, we propose a simple yet powerful approach to better exploit the\npotential of a foundation model for VPR. We first demonstrate that features\nextracted from self-attention layers can serve as a powerful re-ranker for VPR.\nUtilizing these features in a zero-shot manner, our method surpasses previous\nzero-shot methods and achieves competitive results compared to supervised\nmethods across multiple datasets. Subsequently, we demonstrate that a\nsingle-stage method leveraging internal ViT layers for pooling can generate\nglobal features that achieve state-of-the-art results, even when reduced to a\ndimensionality as low as 128D. Nevertheless, incorporating our local foundation\nfeatures for re-ranking, expands this gap. Our approach further demonstrates\nremarkable robustness and generalization, achieving state-of-the-art results,\nwith a significant gap, in challenging scenarios, involving occlusion,\nday-night variations, and seasonal changes.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Issar Tzachor",
            "Boaz Lerner",
            "Matan Levy",
            "Michael Green",
            "Tal Berkovitz Shalev",
            "Gavriel Habib",
            "Dvir Samuel",
            "Noam Korngut Zailer",
            "Or Shimshi",
            "Nir Darshan",
            "Rami Ben-Ari"
        ],
        "published": "2024-05-28T11:24:41Z"
    },
    {
        "title": "Automated Real-World Sustainability Data Generation from Images of\n  Buildings",
        "link": "http://arxiv.org/abs/2405.18064v1",
        "abstract": "When data on building features is unavailable, the task of determining how to\nimprove that building in terms of carbon emissions becomes infeasible. We show\nthat from only a set of images, a Large Language Model with appropriate prompt\nengineering and domain knowledge can successfully estimate a range of building\nfeatures relevant for sustainability calculations. We compare our novel\nimage-to-data method with a ground truth comprising real building data for 47\napartments and achieve accuracy better than a human performing the same task.\nWe also demonstrate that the method can generate tailored recommendations to\nthe owner on how best to improve their properties and discuss methods to scale\nthe approach.",
        "subjects": [
            "cs.AI",
            "cs.CV",
            "68T07, 94A08"
        ],
        "authors": [
            "Peter J Bentley",
            "Soo Ling Lim",
            "Rajat Mathur",
            "Sid Narang"
        ],
        "published": "2024-05-28T11:24:20Z"
    },
    {
        "title": "Towards Integrating Emerging AI Applications in SE Education",
        "link": "http://arxiv.org/abs/2405.18062v1",
        "abstract": "Artificial Intelligence (AI) approaches have been incorporated into modern\nlearning environments and software engineering (SE) courses and curricula for\nseveral years. However, with the significant rise in popularity of large\nlanguage models (LLMs) in general, and OpenAI's LLM-powered chatbot ChatGPT in\nparticular in the last year, educators are faced with rapidly changing\nclassroom environments and disrupted teaching principles. Examples range from\nprogramming assignment solutions that are fully generated via ChatGPT, to\nvarious forms of cheating during exams. However, despite these negative aspects\nand emerging challenges, AI tools in general, and LLM applications in\nparticular, can also provide significant opportunities in a wide variety of SE\ncourses, supporting both students and educators in meaningful ways. In this\nearly research paper, we present preliminary results of a systematic analysis\nof current trends in the area of AI, and how they can be integrated into\nuniversity-level SE curricula, guidelines, and approaches to support both\ninstructors and learners. We collected both teaching and research papers and\nanalyzed their potential usage in SE education, using the ACM Computer Science\nCurriculum Guidelines CS2023. As an initial outcome, we discuss a series of\nopportunities for AI applications and further research areas.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Michael Vierhauser",
            "Iris Groher",
            "Tobias Antensteiner",
            "Clemens Sauerwein"
        ],
        "published": "2024-05-28T11:21:45Z"
    },
    {
        "title": "Context is Important in Depressive Language: A Study of the Interaction\n  Between the Sentiments and Linguistic Markers in Reddit Discussions",
        "link": "http://arxiv.org/abs/2405.18061v1",
        "abstract": "Research exploring linguistic markers in individuals with depression has\ndemonstrated that language usage can serve as an indicator of mental health.\nThis study investigates the impact of discussion topic as context on linguistic\nmarkers and emotional expression in depression, using a Reddit dataset to\nexplore interaction effects. Contrary to common findings, our sentiment\nanalysis revealed a broader range of emotional intensity in depressed\nindividuals, with both higher negative and positive sentiments than controls.\nThis pattern was driven by posts containing no emotion words, revealing the\nlimitations of the lexicon based approaches in capturing the full emotional\ncontext. We observed several interesting results demonstrating the importance\nof contextual analyses. For instance, the use of 1st person singular pronouns\nand words related to anger and sadness correlated with increased positive\nsentiments, whereas a higher rate of present-focused words was associated with\nmore negative sentiments. Our findings highlight the importance of discussion\ncontexts while interpreting the language used in depression, revealing that the\nemotional intensity and meaning of linguistic markers can vary based on the\ntopic of discussion.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Neha Sharma",
            "Kairit Sirts"
        ],
        "published": "2024-05-28T11:19:39Z"
    },
    {
        "title": "PRFashion24: A Dataset for Sentiment Analysis of Fashion Products\n  Reviews in Persian",
        "link": "http://arxiv.org/abs/2405.18060v1",
        "abstract": "The PRFashion24 dataset is a comprehensive Persian dataset collected from\nvarious online fashion stores, spanning from April 2020 to March 2024. With\n767,272 reviews, it is the first dataset in its kind that encompasses diverse\ncategories within the fashion industry in the Persian language. The goal of\nthis study is to harness deep learning techniques, specifically Long Short-Term\nMemory (LSTM) networks and a combination of Bidirectional LSTM and\nConvolutional Neural Network (BiLSTM-CNN), to analyze and reveal sentiments\ntowards online fashion shopping. The LSTM model yielded an accuracy of 81.23%,\nwhile the BiLSTM-CNN model reached 82.89%. This research aims not only to\nintroduce a diverse dataset in the field of fashion but also to enhance the\npublic's understanding of opinions on online fashion shopping, which\npredominantly reflect a positive sentiment. Upon publication, both the\noptimized models and the PRFashion24 dataset will be available on GitHub.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Mehrimah Amirpour",
            "Reza Azmi"
        ],
        "published": "2024-05-28T11:19:13Z"
    },
    {
        "title": "Rank-Refining Seed Selection Methods for Budget Constrained Influence\n  Maximisation in Multilayer Networks under Linear Threshold Model",
        "link": "http://arxiv.org/abs/2405.18059v1",
        "abstract": "The problem of selecting an optimal seed set to maximise influence in\nnetworks has been a subject of intense research in recent years. However,\ndespite numerous works addressing this area, it remains a topic that requires\nfurther elaboration. Most often, it is considered within the scope of\nclassically defined graphs with a spreading model in the form of Independent\nCascades. In this work, we focus on the problem of budget-constrained influence\nmaximisation in multilayer networks using a Linear Threshold Model. Both the\ngraph model and the spreading process we employ are less prevalent in the\nliterature, even though their application allows for a more precise\nrepresentation of the opinion dynamics in social networks. This paper aims to\nanswer which of the sixteen evaluated seed selection methods is the most\neffective and how similar they are. Additionally, we focus our analysis on the\nimpact of spreading model parameters, network characteristics, a budget, and\nthe seed selection methods on the diffusion effectiveness in multilayer\nnetworks. Our contribution also includes extending several centrality measures\nand heuristics to the case of such graphs. The results indicate that all the\nfactors mentioned above collectively contribute to the effectiveness of\ninfluence maximisation. Moreover, there is no seed selection method which\nalways provides the best results. However, the seeds chosen with VoteRank-based\nmethods (especially with the $v-rnk-m$ variant we propose) usually provide the\nmost extensive diffusion.",
        "subjects": [
            "cs.SI"
        ],
        "authors": [
            "Michał Czuba",
            "Piotr Bródka"
        ],
        "published": "2024-05-28T11:15:54Z"
    },
    {
        "title": "ReChorus2.0: A Modular and Task-Flexible Recommendation Library",
        "link": "http://arxiv.org/abs/2405.18058v1",
        "abstract": "With the applications of recommendation systems rapidly expanding, an\nincreasing number of studies have focused on every aspect of recommender\nsystems with different data inputs, models, and task settings. Therefore, a\nflexible library is needed to help researchers implement the experimental\nstrategies they require. Existing open libraries for recommendation scenarios\nhave enabled reproducing various recommendation methods and provided standard\nimplementations. However, these libraries often impose certain restrictions on\ndata and seldom support the same model to perform different tasks and input\nformats, limiting users from customized explorations. To fill the gap, we\npropose ReChorus2.0, a modular and task-flexible library for recommendation\nresearchers. Based on ReChorus, we upgrade the supported input formats, models,\nand training&evaluation strategies to help realize more recommendation tasks\nwith more data types. The main contributions of ReChorus2.0 include: (1)\nRealization of complex and practical tasks, including reranking and CTR\nprediction tasks; (2) Inclusion of various context-aware and rerank\nrecommenders; (3) Extension of existing and new models to support different\ntasks with the same models; (4) Support of highly-customized input with\nimpression logs, negative items, or click labels, as well as user, item, and\nsituation contexts. To summarize, ReChorus2.0 serves as a comprehensive and\nflexible library better aligning with the practical problems in the\nrecommendation scenario and catering to more diverse research needs. The\nimplementation and detailed tutorials of ReChorus2.0 can be found at\nhttps://github.com/THUwangcy/ReChorus.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Jiayu Li",
            "Hanyu Li",
            "Zhiyu He",
            "Weizhi Ma",
            "Peijie Sun",
            "Min Zhang",
            "Shaoping Ma"
        ],
        "published": "2024-05-28T11:14:15Z"
    },
    {
        "title": "Algebraic Geometry Codes for Cross-Subspace Alignment in Private\n  Information Retrieval",
        "link": "http://arxiv.org/abs/2405.18052v1",
        "abstract": "A new framework for interference alignment in secure and private information\nretrieval (PIR) from colluding servers is proposed, generalizing the original\ncross-subspace alignment (CSA) codes proposed by Jia, Sun, and Jafar. The\ngeneral scheme is built on algebraic geometry codes and explicit constructions\nwith replicated storage are given over curves of genus zero and one. It is\nshown that the proposed scheme offers interesting tradeoffs between the field\nsize, file size, number of colluding servers, and the total number of servers.\nWhen the field size is fixed, this translates in some cases to higher retrieval\nrates than those of the original scheme. In addition, the new schemes exist\nalso in cases where the original ones do not.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Okko Makkonen",
            "David Karpuk",
            "Camilla Hollanti"
        ],
        "published": "2024-05-28T11:06:15Z"
    },
    {
        "title": "Learning-Based Link Anomaly Detection in Continuous-Time Dynamic Graphs",
        "link": "http://arxiv.org/abs/2405.18050v1",
        "abstract": "Anomaly detection in continuous-time dynamic graphs is an emerging field yet\nunder-explored in the context of learning-based approaches. In this paper, we\npioneer structured analyses of link-level anomalies and graph representation\nlearning for identifying anomalous links in these graphs. First, we introduce a\nfine-grain taxonomy for edge-level anomalies leveraging structural, temporal,\nand contextual graph properties. We present a method for generating and\ninjecting such typed anomalies into graphs. Next, we introduce a novel method\nto generate continuous-time dynamic graphs with consistent patterns across\ntime, structure, and context. To allow temporal graph methods to learn the link\nanomaly detection task, we extend the generic link prediction setting by: (1)\nconditioning link existence on contextual edge attributes; and (2) refining the\ntraining regime to accommodate diverse perturbations in the negative edge\nsampler. Building on this, we benchmark methods for anomaly detection.\nComprehensive experiments on synthetic and real-world datasets -- featuring\nsynthetic and labeled organic anomalies and employing six state-of-the-art\nlearning methods -- validate our taxonomy and generation processes for\nanomalies and benign graphs, as well as our approach to adapting link\nprediction methods for anomaly detection. Our results further reveal that\ndifferent learning methods excel in capturing different aspects of graph\nnormality and detecting different types of anomalies. We conclude with a\ncomprehensive list of findings highlighting opportunities for future research.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "authors": [
            "Tim Poštuvan",
            "Claas Grohnfeldt",
            "Michele Russo",
            "Giulio Lovisotto"
        ],
        "published": "2024-05-28T11:05:41Z"
    },
    {
        "title": "Expectation in Stochastic Window Mean-Payoff Games",
        "link": "http://arxiv.org/abs/2405.18048v1",
        "abstract": "Stochastic two-player games model systems with an environment that is both\nadversarial and stochastic. In this paper, we study the expected value of the\nwindow mean-payoff measure in stochastic games. The window mean-payoff measure\nstrengthens the classical mean-payoff measure by measuring the mean-payoff over\na window of bounded length that slides along an infinite path. Two variants\nhave been considered: in one variant, the maximum window length is fixed and\ngiven, while in the other, it is not fixed but is required to be bounded. For\nboth variants, we show that the decision problem to check if the expected value\nis at least a given threshold is in NP $\\cap$ coNP. The result follows from\nguessing the expected values of the vertices, partitioning them into so-called\nvalue classes, and proving that a short certificate for the expected values\nexists. Finally, we also show that the memory required by the players to play\noptimally is no more than that in non-stochastic two-player games with the\ncorresponding window objectives.",
        "subjects": [
            "cs.GT"
        ],
        "authors": [
            "Laurent Doyen",
            "Pranshu Gaba",
            "Shibashis Guha"
        ],
        "published": "2024-05-28T11:02:22Z"
    },
    {
        "title": "2BP: 2-Stage Backpropagation",
        "link": "http://arxiv.org/abs/2405.18047v1",
        "abstract": "As Deep Neural Networks (DNNs) grow in size and complexity, they often exceed\nthe memory capacity of a single accelerator, necessitating the sharding of\nmodel parameters across multiple accelerators. Pipeline parallelism is a\ncommonly used sharding strategy for training large DNNs. However, current\nimplementations of pipeline parallelism are being unintentionally bottlenecked\nby the automatic differentiation tools provided by ML frameworks. This paper\nintroduces 2-stage backpropagation (2BP). By splitting the backward propagation\nstep into two separate stages, we can reduce idle compute time. We tested 2BP\non various model architectures and pipelining schedules, achieving increases in\nthroughput in all cases. Using 2BP, we were able to achieve a 1.70x increase in\nthroughput compared to traditional methods when training a LLaMa-like\ntransformer with 7 billion parameters across 4 GPUs.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC"
        ],
        "authors": [
            "Christopher Rae",
            "Joseph K. L. Lee",
            "James Richings"
        ],
        "published": "2024-05-28T11:02:01Z"
    },
    {
        "title": "Bridging Mini-Batch and Asymptotic Analysis in Contrastive Learning:\n  From InfoNCE to Kernel-Based Losses",
        "link": "http://arxiv.org/abs/2405.18045v1",
        "abstract": "What do different contrastive learning (CL) losses actually optimize for?\nAlthough multiple CL methods have demonstrated remarkable representation\nlearning capabilities, the differences in their inner workings remain largely\nopaque. In this work, we analyse several CL families and prove that, under\ncertain conditions, they admit the same minimisers when optimizing either their\nbatch-level objectives or their expectations asymptotically. In both cases, an\nintimate connection with the hyperspherical energy minimisation (HEM) problem\nresurfaces. Drawing inspiration from this, we introduce a novel CL objective,\ncoined Decoupled Hyperspherical Energy Loss (DHEL). DHEL simplifies the problem\nby decoupling the target hyperspherical energy from the alignment of positive\nexamples while preserving the same theoretical guarantees. Going one step\nfurther, we show the same results hold for another relevant CL family, namely\nkernel contrastive learning (KCL), with the additional advantage of the\nexpected loss being independent of batch size, thus identifying the minimisers\nin the non-asymptotic regime. Empirical results demonstrate improved downstream\nperformance and robustness across combinations of different batch sizes and\nhyperparameters and reduced dimensionality collapse, on several computer vision\ndatasets.",
        "subjects": [
            "cs.LG",
            "cs.CV"
        ],
        "authors": [
            "Panagiotis Koromilas",
            "Giorgos Bouritsas",
            "Theodoros Giannakopoulos",
            "Mihalis Nicolaou",
            "Yannis Panagakis"
        ],
        "published": "2024-05-28T11:00:41Z"
    },
    {
        "title": "Cognitive Insights and Stable Coalition Matching for Fostering\n  Multi-Agent Cooperation",
        "link": "http://arxiv.org/abs/2405.18044v1",
        "abstract": "Cognitive abilities, such as Theory of Mind (ToM), play a vital role in\nfacilitating cooperation in human social interactions. However, our study\nreveals that agents with higher ToM abilities may not necessarily exhibit\nbetter cooperative behavior compared to those with lower ToM abilities. To\naddress this challenge, we propose a novel matching coalition mechanism that\nleverages the strengths of agents with different ToM levels by explicitly\nconsidering belief alignment and specialized abilities when forming coalitions.\nOur proposed matching algorithm seeks to find stable coalitions that maximize\nthe potential for cooperative behavior and ensure long-term viability. By\nincorporating cognitive insights into the design of multi-agent systems, our\nwork demonstrates the potential of leveraging ToM to create more sophisticated\nand human-like coordination strategies that foster cooperation and improve\noverall system performance.",
        "subjects": [
            "cs.MA",
            "cs.AI"
        ],
        "authors": [
            "Jiaqi Shao",
            "Tianjun Yuan",
            "Tao Lin",
            "Xuanyu Cao",
            "Bing Luo"
        ],
        "published": "2024-05-28T10:59:33Z"
    },
    {
        "title": "Visualizing the loss landscape of Self-supervised Vision Transformer",
        "link": "http://arxiv.org/abs/2405.18042v1",
        "abstract": "The Masked autoencoder (MAE) has drawn attention as a representative\nself-supervised approach for masked image modeling with vision transformers.\nHowever, even though MAE shows better generalization capability than fully\nsupervised training from scratch, the reason why has not been explored. In\nanother line of work, the Reconstruction Consistent Masked Auto Encoder\n(RC-MAE), has been proposed which adopts a self-distillation scheme in the form\nof an exponential moving average (EMA) teacher into MAE, and it has been shown\nthat the EMA-teacher performs a conditional gradient correction during\noptimization. To further investigate the reason for better generalization of\nthe self-supervised ViT when trained by MAE (MAE-ViT) and the effect of the\ngradient correction of RC-MAE from the perspective of optimization, we\nvisualize the loss landscapes of the self-supervised vision transformer by both\nMAE and RC-MAE and compare them with the supervised ViT (Sup-ViT). Unlike\nprevious loss landscape visualizations of neural networks based on\nclassification task loss, we visualize the loss landscape of ViT by computing\npre-training task loss. Through the lens of loss landscapes, we find two\ninteresting observations: (1) MAE-ViT has a smoother and wider overall loss\ncurvature than Sup-ViT. (2) The EMA-teacher allows MAE to widen the region of\nconvexity in both pretraining and linear probing, leading to quicker\nconvergence. To the best of our knowledge, this work is the first to\ninvestigate the self-supervised ViT through the lens of the loss landscape.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Youngwan Lee",
            "Jeffrey Ryan Willette",
            "Jonghee Kim",
            "Sung Ju Hwang"
        ],
        "published": "2024-05-28T10:54:26Z"
    },
    {
        "title": "Fast-FedUL: A Training-Free Federated Unlearning with Provable Skew\n  Resilience",
        "link": "http://arxiv.org/abs/2405.18040v1",
        "abstract": "Federated learning (FL) has recently emerged as a compelling machine learning\nparadigm, prioritizing the protection of privacy for training data. The\nincreasing demand to address issues such as ``the right to be forgotten'' and\ncombat data poisoning attacks highlights the importance of techniques, known as\n\\textit{unlearning}, which facilitate the removal of specific training data\nfrom trained FL models. Despite numerous unlearning methods proposed for\ncentralized learning, they often prove inapplicable to FL due to fundamental\ndifferences in the operation of the two learning paradigms. Consequently,\nunlearning in FL remains in its early stages, presenting several challenges.\nMany existing unlearning solutions in FL require a costly retraining process,\nwhich can be burdensome for clients. Moreover, these methods are primarily\nvalidated through experiments, lacking theoretical assurances. In this study,\nwe introduce Fast-FedUL, a tailored unlearning method for FL, which eliminates\nthe need for retraining entirely. Through meticulous analysis of the target\nclient's influence on the global model in each round, we develop an algorithm\nto systematically remove the impact of the target client from the trained\nmodel. In addition to presenting empirical findings, we offer a theoretical\nanalysis delineating the upper bound of our unlearned model and the exact\nretrained model (the one obtained through retraining using untargeted clients).\nExperimental results with backdoor attack scenarios indicate that Fast-FedUL\neffectively removes almost all traces of the target client, while retaining the\nknowledge of untargeted clients (obtaining a high accuracy of up to 98\\% on the\nmain task). Significantly, Fast-FedUL attains the lowest time complexity,\nproviding a speed that is 1000 times faster than retraining. Our source code is\npublicly available at \\url{https://github.com/thanhtrunghuynh93/fastFedUL}.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.DC",
            "cs.ET"
        ],
        "authors": [
            "Thanh Trung Huynh",
            "Trong Bang Nguyen",
            "Phi Le Nguyen",
            "Thanh Tam Nguyen",
            "Matthias Weidlich",
            "Quoc Viet Hung Nguyen",
            "Karl Aberer"
        ],
        "published": "2024-05-28T10:51:38Z"
    },
    {
        "title": "Large Language Model-Driven Curriculum Design for Mobile Networks",
        "link": "http://arxiv.org/abs/2405.18039v1",
        "abstract": "This paper proposes a novel framework that leverages large language models\n(LLMs) to automate curriculum design, thereby enhancing the application of\nreinforcement learning (RL) in mobile networks. As mobile networks evolve\ntowards the 6G era, managing their increasing complexity and dynamic nature\nposes significant challenges. Conventional RL approaches often suffer from slow\nconvergence and poor generalization due to conflicting objectives and the large\nstate and action spaces associated with mobile networks. To address these\nshortcomings, we introduce curriculum learning, a method that systematically\nexposes the RL agent to progressively challenging tasks, improving convergence\nand generalization. However, curriculum design typically requires extensive\ndomain knowledge and manual human effort. Our framework mitigates this by\nutilizing the generative capabilities of LLMs to automate the curriculum design\nprocess, significantly reducing human effort while improving the RL agent's\nconvergence and performance. We deploy our approach within a simulated mobile\nnetwork environment and demonstrate improved RL convergence rates,\ngeneralization to unseen scenarios, and overall performance enhancements. As a\ncase study, we consider autonomous coordination and user association in mobile\nnetworks. Our obtained results highlight the potential of combining LLM-based\ncurriculum generation with RL for managing next-generation wireless networks,\nmarking a significant step towards fully autonomous network operations.",
        "subjects": [
            "cs.LG",
            "cs.NI"
        ],
        "authors": [
            "Omar Erak",
            "Omar Alhussein",
            "Shimaa Naser",
            "Nouf Alabbasi",
            "De Mi",
            "Sami Muhaidat"
        ],
        "published": "2024-05-28T10:50:35Z"
    },
    {
        "title": "ForecastGrapher: Redefining Multivariate Time Series Forecasting with\n  Graph Neural Networks",
        "link": "http://arxiv.org/abs/2405.18036v1",
        "abstract": "The challenge of effectively learning inter-series correlations for\nmultivariate time series forecasting remains a substantial and unresolved\nproblem. Traditional deep learning models, which are largely dependent on the\nTransformer paradigm for modeling long sequences, often fail to integrate\ninformation from multiple time series into a coherent and universally\napplicable model. To bridge this gap, our paper presents ForecastGrapher, a\nframework reconceptualizes multivariate time series forecasting as a node\nregression task, providing a unique avenue for capturing the intricate temporal\ndynamics and inter-series correlations. Our approach is underpinned by three\npivotal steps: firstly, generating custom node embeddings to reflect the\ntemporal variations within each series; secondly, constructing an adaptive\nadjacency matrix to encode the inter-series correlations; and thirdly,\naugmenting the GNNs' expressive power by diversifying the node feature\ndistribution. To enhance this expressive power, we introduce the Group Feature\nConvolution GNN (GFC-GNN). This model employs a learnable scaler to segment\nnode features into multiple groups and applies one-dimensional convolutions\nwith different kernel lengths to each group prior to the aggregation phase.\nConsequently, the GFC-GNN method enriches the diversity of node feature\ndistribution in a fully end-to-end fashion. Through extensive experiments and\nablation studies, we show that ForecastGrapher surpasses strong baselines and\nleading published techniques in the domain of multivariate time series\nforecasting.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Wanlin Cai",
            "Kun Wang",
            "Hao Wu",
            "Xiaoxu Chen",
            "Yuankai Wu"
        ],
        "published": "2024-05-28T10:40:20Z"
    },
    {
        "title": "Instruction Tuning with Retrieval-based Examples Ranking for\n  Aspect-based Sentiment Analysis",
        "link": "http://arxiv.org/abs/2405.18035v2",
        "abstract": "Aspect-based sentiment analysis (ABSA) identifies sentiment information\nrelated to specific aspects and provides deeper market insights to businesses\nand organizations. With the emergence of large language models (LMs), recent\nstudies have proposed using fixed examples for instruction tuning to\nreformulate ABSA as a generation task. However, the performance is sensitive to\nthe selection of in-context examples; several retrieval methods are based on\nsurface similarity and are independent of the LM generative objective. This\nstudy proposes an instruction learning method with retrieval-based example\nranking for ABSA tasks. For each target sample, an LM was applied as a scorer\nto estimate the likelihood of the output given the input and a candidate\nexample as the prompt, and training examples were labeled as positive or\nnegative by ranking the scores. An alternating training schema is proposed to\ntrain both the retriever and LM. Instructional prompts can be constructed using\nhigh-quality examples. The LM is used for both scoring and inference, improving\nthe generation efficiency without incurring additional computational costs or\ntraining difficulties. Extensive experiments on three ABSA subtasks verified\nthe effectiveness of the proposed method, demonstrating its superiority over\nvarious strong baseline models. Code and data are released at\nhttps://github.com/zgMin/IT-RER-ABSA.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Guangmin Zheng",
            "Jin Wang",
            "Liang-Chih Yu",
            "Xuejie Zhang"
        ],
        "published": "2024-05-28T10:39:10Z"
    },
    {
        "title": "Convergence rates of particle approximation of forward-backward\n  splitting algorithm for granular medium equations",
        "link": "http://arxiv.org/abs/2405.18034v1",
        "abstract": "We study the spatially homogeneous granular medium equation\n\\[\\partial_t\\mu=\\rm{div}(\\mu\\nabla V)+\\rm{div}(\\mu(\\nabla W \\ast\n\\mu))+\\Delta\\mu\\,,\\] within a large and natural class of the confinement\npotentials $V$ and interaction potentials $W$. The considered problem do not\nneed to assume that $\\nabla V$ or $\\nabla W$ are globally Lipschitz. With the\naim of providing particle approximation of solutions, we design efficient\nforward-backward splitting algorithms. Sharp convergence rates in terms of the\nWasserstein distance are provided.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "stat.CO"
        ],
        "authors": [
            "Matej Benko",
            "Iwona Chlebicka",
            "Jørgen Endal",
            "Błażej Miasojedow"
        ],
        "published": "2024-05-28T10:38:27Z"
    },
    {
        "title": "RT-GS2: Real-Time Generalizable Semantic Segmentation for 3D Gaussian\n  Representations of Radiance Fields",
        "link": "http://arxiv.org/abs/2405.18033v1",
        "abstract": "Gaussian Splatting has revolutionized the world of novel view synthesis by\nachieving high rendering performance in real-time. Recently, studies have\nfocused on enriching these 3D representations with semantic information for\ndownstream tasks. In this paper, we introduce RT-GS2, the first generalizable\nsemantic segmentation method employing Gaussian Splatting. While existing\nGaussian Splatting-based approaches rely on scene-specific training, RT-GS2\ndemonstrates the ability to generalize to unseen scenes. Our method adopts a\nnew approach by first extracting view-independent 3D Gaussian features in a\nself-supervised manner, followed by a novel View-Dependent / View-Independent\n(VDVI) feature fusion to enhance semantic consistency over different views.\nExtensive experimentation on three different datasets showcases RT-GS2's\nsuperiority over the state-of-the-art methods in semantic segmentation quality,\nexemplified by a 8.01% increase in mIoU on the Replica dataset. Moreover, our\nmethod achieves real-time performance of 27.03 FPS, marking an astonishing 901\ntimes speedup compared to existing approaches. This work represents a\nsignificant advancement in the field by introducing, to the best of our\nknowledge, the first real-time generalizable semantic segmentation method for\n3D Gaussian representations of radiance fields.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Mihnea-Bogdan Jurca",
            "Remco Royen",
            "Ion Giosan",
            "Adrian Munteanu"
        ],
        "published": "2024-05-28T10:34:28Z"
    },
    {
        "title": "Automatic Abelian Complexities of Parikh-Collinear Fixed Points",
        "link": "http://arxiv.org/abs/2405.18032v1",
        "abstract": "Parikh-collinear morphisms have the property that all the Parikh vectors of\nthe images of letters are collinear, i.e., the associated adjacency matrix has\nrank 1. In the conference DLT-WORDS 2023 we showed that fixed points of\nParikh-collinear morphisms are automatic. We also showed that the abelian\ncomplexity function of a binary fixed point of such a morphism is automatic\nunder some assumptions. In this note, we fully generalize the latter result.\nNamely, we show that the abelian complexity function of a fixed point of an\narbitrary, possibly erasing, Parikh-collinear morphism is automatic.\nFurthermore, a deterministic finite automaton with output generating this\nabelian complexity function is provided by an effective procedure. To that end,\nwe discuss the constant of recognizability of a morphism and the related\ncutting set.",
        "subjects": [
            "cs.DM",
            "cs.FL",
            "math.CO"
        ],
        "authors": [
            "Michel Rigo",
            "Manon Stipulanti",
            "Markus A. Whiteland"
        ],
        "published": "2024-05-28T10:31:15Z"
    },
    {
        "title": "Lower Bounds and Optimal Algorithms for Non-Smooth Convex Decentralized\n  Optimization over Time-Varying Networks",
        "link": "http://arxiv.org/abs/2405.18031v1",
        "abstract": "We consider the task of minimizing the sum of convex functions stored in a\ndecentralized manner across the nodes of a communication network. This problem\nis relatively well-studied in the scenario when the objective functions are\nsmooth, or the links of the network are fixed in time, or both. In particular,\nlower bounds on the number of decentralized communications and (sub)gradient\ncomputations required to solve the problem have been established, along with\nmatching optimal algorithms. However, the remaining and most challenging\nsetting of non-smooth decentralized optimization over time-varying networks is\nlargely underexplored, as neither lower bounds nor optimal algorithms are known\nin the literature. We resolve this fundamental gap with the following\ncontributions: (i) we establish the first lower bounds on the communication and\nsubgradient computation complexities of solving non-smooth convex decentralized\noptimization problems over time-varying networks; (ii) we develop the first\noptimal algorithm that matches these lower bounds and offers substantially\nimproved theoretical performance compared to the existing state of the art.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "authors": [
            "Dmitry Kovalev",
            "Ekaterina Borodich",
            "Alexander Gasnikov",
            "Dmitrii Feoktistov"
        ],
        "published": "2024-05-28T10:28:45Z"
    },
    {
        "title": "Modeling and Controlling Many-Core HPC Processors: an Alternative to PID\n  and Moving Average Algorithms",
        "link": "http://arxiv.org/abs/2405.18030v1",
        "abstract": "The race towards performance increase and computing power has led to chips\nwith heterogeneous and complex designs, integrating an ever-growing number of\ncores on the same monolithic chip or chiplet silicon die. Higher integration\ndensity, compounded with the slowdown of technology-driven power reduction,\nimplies that power and thermal management become increasingly relevant.\nUnfortunately, existing research lacks a detailed analysis and modeling of\nthermal, power, and electrical coupling effects and how they have to be jointly\nconsidered to perform dynamic control of complex and heterogeneous\nMulti-Processor System on Chips (MPSoCs). To close the gap, in this work, we\nfirst provide a detailed thermal and power model targeting a modern High\nPerformance Computing (HPC) MPSoC. We consider real-world coupling effects such\nas actuators' non-idealities and the exponential relation between the\ndissipated power, the temperature state, and the voltage level in a single\nprocessing element. We analyze how these factors affect the control algorithm\nbehavior and the type of challenges that they pose. Based on the analysis, we\npropose a thermal capping strategy inspired by Fuzzy control theory to replace\nthe state-of-the-art PID controller, as well as a root-finding iterative method\nto optimally choose the shared voltage value among cores grouped in the same\nvoltage domain. We evaluate the proposed controller with model-in-the-loop and\nhardware-in-the-loop co-simulations. We show an improvement over\nstate-of-the-art methods of up to 5x the maximum exceeded temperature while\nproviding an average of 3.56% faster application execution runtime across all\nthe evaluation scenarios.",
        "subjects": [
            "eess.SY",
            "cs.PF",
            "cs.SY"
        ],
        "authors": [
            "Giovanni Bambini",
            "Alessandro Ottaviano",
            "Christian Conficoni",
            "Andrea Tilli",
            "Luca Benini",
            "Andrea Bartolini"
        ],
        "published": "2024-05-28T10:26:37Z"
    },
    {
        "title": "Are Image Distributions Indistinguishable to Humans Indistinguishable to\n  Classifiers?",
        "link": "http://arxiv.org/abs/2405.18029v1",
        "abstract": "The ultimate goal of generative models is to characterize the data\ndistribution perfectly. For image generation, common metrics of visual quality\n(e.g., FID), and the truthlikeness of generated images to the human eyes seem\nto suggest that we are close to achieving it. However, through distribution\nclassification tasks, we find that, in the eyes of classifiers parameterized by\nneural networks, the strongest diffusion models are still far from this goal.\nSpecifically, classifiers consistently and effortlessly distinguish between\nreal and generated images in various settings. Further, we observe an\nintriguing discrepancy: classifiers can identify differences between diffusion\nmodels with similar performance (e.g., U-ViT-H vs. DiT-XL), but struggle to\ndifferentiate between the smallest and largest models in the same family (e.g.,\nEDM2-XS vs. EDM2-XXL), whereas humans exhibit the opposite tendency. As an\nexplanation, our comprehensive empirical study suggests that, unlike humans,\nclassifiers tend to classify images through edge and high-frequency components.\nWe believe that our methodology can serve as a probe to understand how\ngenerative models work and inspire further thought on how existing models can\nbe improved and how the abuse of such models can be prevented.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Zebin You",
            "Xinyu Zhang",
            "Hanzhong Guo",
            "Jingdong Wang",
            "Chongxuan Li"
        ],
        "published": "2024-05-28T10:25:06Z"
    },
    {
        "title": "Edinburgh Clinical NLP at MEDIQA-CORR 2024: Guiding Large Language\n  Models with Hints",
        "link": "http://arxiv.org/abs/2405.18028v1",
        "abstract": "The MEDIQA-CORR 2024 shared task aims to assess the ability of Large Language\nModels (LLMs) to identify and correct medical errors in clinical notes. In this\nstudy, we evaluate the capability of general LLMs, specifically GPT-3.5 and\nGPT-4, to identify and correct medical errors with multiple prompting\nstrategies. Recognising the limitation of LLMs in generating accurate\ncorrections only via prompting strategies, we propose incorporating error-span\npredictions from a smaller, fine-tuned model in two ways: 1) by presenting it\nas a hint in the prompt and 2) by framing it as multiple-choice questions from\nwhich the LLM can choose the best correction. We found that our proposed\nprompting strategies significantly improve the LLM's ability to generate\ncorrections. Our best-performing solution with 8-shot + CoT + hints ranked\nsixth in the shared task leaderboard. Additionally, our comprehensive analyses\nshow the impact of the location of the error sentence, the prompted role, and\nthe position of the multiple-choice option on the accuracy of the LLM. This\nprompts further questions about the readiness of LLM to be implemented in\nreal-world clinical settings.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Aryo Pradipta Gema",
            "Chaeeun Lee",
            "Pasquale Minervini",
            "Luke Daines",
            "T. Ian Simpson",
            "Beatrice Alex"
        ],
        "published": "2024-05-28T10:20:29Z"
    },
    {
        "title": "TimeChara: Evaluating Point-in-Time Character Hallucination of\n  Role-Playing Large Language Models",
        "link": "http://arxiv.org/abs/2405.18027v1",
        "abstract": "While Large Language Models (LLMs) can serve as agents to simulate human\nbehaviors (i.e., role-playing agents), we emphasize the importance of\npoint-in-time role-playing. This situates characters at specific moments in the\nnarrative progression for three main reasons: (i) enhancing users' narrative\nimmersion, (ii) avoiding spoilers, and (iii) fostering engagement in fandom\nrole-playing. To accurately represent characters at specific time points,\nagents must avoid character hallucination, where they display knowledge that\ncontradicts their characters' identities and historical timelines. We introduce\nTimeChara, a new benchmark designed to evaluate point-in-time character\nhallucination in role-playing LLMs. Comprising 10,895 instances generated\nthrough an automated pipeline, this benchmark reveals significant hallucination\nissues in current state-of-the-art LLMs (e.g., GPT-4o). To counter this\nchallenge, we propose Narrative-Experts, a method that decomposes the reasoning\nsteps and utilizes narrative experts to reduce point-in-time character\nhallucinations effectively. Still, our findings with TimeChara highlight the\nongoing challenges of point-in-time character hallucination, calling for\nfurther study.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Jaewoo Ahn",
            "Taehyun Lee",
            "Junyoung Lim",
            "Jin-Hwa Kim",
            "Sangdoo Yun",
            "Hwaran Lee",
            "Gunhee Kim"
        ],
        "published": "2024-05-28T10:19:18Z"
    },
    {
        "title": "Unveiling the Power of Diffusion Features For Personalized Segmentation\n  and Retrieval",
        "link": "http://arxiv.org/abs/2405.18025v1",
        "abstract": "Personalized retrieval and segmentation aim to locate specific instances\nwithin a dataset based on an input image and a short description of the\nreference instance. While supervised methods are effective, they require\nextensive labeled data for training. Recently, self-supervised foundation\nmodels have been introduced to these tasks showing comparable results to\nsupervised methods. However, a significant flaw in these models is evident:\nthey struggle to locate a desired instance when other instances within the same\nclass are presented. In this paper, we explore text-to-image diffusion models\nfor these tasks. Specifically, we propose a novel approach called PDM for\nPersonalized Features Diffusion Matching, that leverages intermediate features\nof pre-trained text-to-image models for personalization tasks without any\nadditional training. PDM demonstrates superior performance on popular retrieval\nand segmentation benchmarks, outperforming even supervised methods. We also\nhighlight notable shortcomings in current instance and segmentation datasets\nand propose new benchmarks for these tasks.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Dvir Samuel",
            "Rami Ben-Ari",
            "Matan Levy",
            "Nir Darshan",
            "Gal Chechik"
        ],
        "published": "2024-05-28T10:13:18Z"
    },
    {
        "title": "Generator polynomials of cyclic expurgated or extended Goppa codes",
        "link": "http://arxiv.org/abs/2405.18023v1",
        "abstract": "Classical Goppa codes are a well-known class of codes with applications in\ncode-based cryptography, which are a special case of alternant codes. Many\npapers are devoted to the search for Goppa codes with a cyclic extension or\nwith a cyclic parity-check subcode. Let $\\Bbb F_q$ be a finite field with\n$q=2^l$ elements, where $l$ is a positive integer. In this paper, we determine\nall the generator polynomials of cyclic expurgated or extended Goppa codes\nunder some prescribed permutations induced by the projective general linear\nautomorphism $A \\in PGL_2(\\Bbb F_q)$. Moreover, we provide some examples to\nsupport our findings.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Xue Jia",
            "Fengwei Li",
            "Huan Sun",
            "Qin Yue"
        ],
        "published": "2024-05-28T10:11:38Z"
    },
    {
        "title": "MULi-Ev: Maintaining Unperturbed LiDAR-Event Calibration",
        "link": "http://arxiv.org/abs/2405.18021v1",
        "abstract": "Despite the increasing interest in enhancing perception systems for\nautonomous vehicles, the online calibration between event cameras and LiDAR -\ntwo sensors pivotal in capturing comprehensive environmental information -\nremains unexplored. We introduce MULi-Ev, the first online, deep learning-based\nframework tailored for the extrinsic calibration of event cameras with LiDAR.\nThis advancement is instrumental for the seamless integration of LiDAR and\nevent cameras, enabling dynamic, real-time calibration adjustments that are\nessential for maintaining optimal sensor alignment amidst varying operational\nconditions. Rigorously evaluated against the real-world scenarios presented in\nthe DSEC dataset, MULi-Ev not only achieves substantial improvements in\ncalibration accuracy but also sets a new standard for integrating LiDAR with\nevent cameras in mobile platforms. Our findings reveal the potential of MULi-Ev\nto bolster the safety, reliability, and overall performance of event-based\nperception systems in autonomous driving, marking a significant step forward in\ntheir real-world deployment and effectiveness.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Mathieu Cocheteux",
            "Julien Moreau",
            "Franck Davoine"
        ],
        "published": "2024-05-28T10:09:49Z"
    },
    {
        "title": "A Calibration Tool for Refractive Underwater Vision",
        "link": "http://arxiv.org/abs/2405.18018v1",
        "abstract": "Many underwater robotic applications relying on vision sensors require proper\ncamera calibration, i.e. knowing the incoming light ray for each pixel in the\nimage. While for the ideal pinhole camera model all viewing rays intersect in a\nsingle 3D point, underwater cameras suffer from - possibly multiple -\nrefractions of light rays at the interfaces of water, glass and air. These\nchanges of direction depend on the position and orientation of the camera\ninside the water-proof housing, as well as on the shape and properties of the\noptical window, the port, itself. In recent years explicit models for\nunderwater vision behind common ports such as flat or dome port have been\nproposed, but the underwater community is still lacking a calibration tool\nwhich can determine port parameters through refractive calibration. With this\nwork we provide the first open source implementation of an underwater\nrefractive camera calibration toolbox. It allows end-to-end calibration of\nunderwater vision systems, including camera, stereo and housing calibration for\nsystems with dome or flat ports. The implementation is verified using rendered\ndatasets and real-world experiments.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Felix Seegräber",
            "Mengkun She",
            "Felix Woelk",
            "Kevin Köser"
        ],
        "published": "2024-05-28T10:05:10Z"
    },
    {
        "title": "On Creativity and Open-Endedness",
        "link": "http://arxiv.org/abs/2405.18016v1",
        "abstract": "Artificial Life (ALife) as an interdisciplinary field draws inspiration and\ninfluence from a variety of perspectives. Scientific progress crucially\ndepends, then, on concerted efforts to invite cross-disciplinary dialogue. The\ngoal of this paper is to revitalize discussions of potential connections\nbetween the fields of Computational Creativity (CC) and ALife, focusing\nspecifically on the concept of Open-Endedness (OE); the primary goal of CC is\nto endow artificial systems with creativity, and ALife has dedicated much\nresearch effort into studying and synthesizing OE and artificial innovation.\nHowever, despite the close proximity of these concepts, their use so far\nremains confined to their respective communities, and their relationship is\nlargely unclear. We provide historical context for research in both domains,\nand review the limited work connecting research on creativity and OE\nexplicitly. We then highlight specific questions to be considered, with the\neventual goals of (i) decreasing conceptual ambiguity by highlighting\nsimilarities and differences between the concepts of OE, (ii) identifying\nsynergy effects of a research agenda that encompasses both OE and creativity,\nand (iii) establishing a dialogue between ALife and CC research.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Lisa Soros",
            "Alyssa Adams",
            "Stefano Kalonaris",
            "Olaf Witkowski",
            "Christian Guckelsberger"
        ],
        "published": "2024-05-28T09:57:37Z"
    },
    {
        "title": "MultiADE: A Multi-domain Benchmark for Adverse Drug Event Extraction",
        "link": "http://arxiv.org/abs/2405.18015v1",
        "abstract": "Objective. Active adverse event surveillance monitors Adverse Drug Events\n(ADE) from different data sources, such as electronic health records, medical\nliterature, social media and search engine logs. Over years, many datasets are\ncreated, and shared tasks are organised to facilitate active adverse event\nsurveillance. However, most-if not all-datasets or shared tasks focus on\nextracting ADEs from a particular type of text. Domain generalisation-the\nability of a machine learning model to perform well on new, unseen domains\n(text types)-is under-explored. Given the rapid advancements in natural\nlanguage processing, one unanswered question is how far we are from having a\nsingle ADE extraction model that are effective on various types of text, such\nas scientific literature and social media posts}. Methods. We contribute to\nanswering this question by building a multi-domain benchmark for adverse drug\nevent extraction, which we named MultiADE. The new benchmark comprises several\nexisting datasets sampled from different text types and our newly created\ndataset-CADECv2, which is an extension of CADEC (Karimi, et al., 2015),\ncovering online posts regarding more diverse drugs than CADEC. Our new dataset\nis carefully annotated by human annotators following detailed annotation\nguidelines. Conclusion. Our benchmark results show that the generalisation of\nthe trained models is far from perfect, making it infeasible to be deployed to\nprocess different types of text. In addition, although intermediate transfer\nlearning is a promising approach to utilising existing resources, further\ninvestigation is needed on methods of domain adaptation, particularly\ncost-effective methods to select useful training instances.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Xiang Dai",
            "Sarvnaz Karimi",
            "Abeed Sarker",
            "Ben Hachey",
            "Cecile Paris"
        ],
        "published": "2024-05-28T09:57:28Z"
    },
    {
        "title": "Coupled Mamba: Enhanced Multi-modal Fusion with Coupled State Space\n  Model",
        "link": "http://arxiv.org/abs/2405.18014v2",
        "abstract": "The essence of multi-modal fusion lies in exploiting the complementary\ninformation inherent in diverse modalities. However, prevalent fusion methods\nrely on traditional neural architectures and are inadequately equipped to\ncapture the dynamics of interactions across modalities, particularly in\npresence of complex intra- and inter-modality correlations. Recent advancements\nin State Space Models (SSMs), notably exemplified by the Mamba model, have\nemerged as promising contenders. Particularly, its state evolving process\nimplies stronger modality fusion paradigm, making multi-modal fusion on SSMs an\nappealing direction. However, fusing multiple modalities is challenging for\nSSMs due to its hardware-aware parallelism designs. To this end, this paper\nproposes the Coupled SSM model, for coupling state chains of multiple\nmodalities while maintaining independence of intra-modality state processes.\nSpecifically, in our coupled scheme, we devise an inter-modal hidden states\ntransition scheme, in which the current state is dependent on the states of its\nown chain and that of the neighbouring chains at the previous time-step. To\nfully comply with the hardware-aware parallelism, we devise an expedite coupled\nstate transition scheme and derive its corresponding global convolution kernel\nfor parallelism. Extensive experiments on CMU-MOSEI, CH-SIMS, CH-SIMSV2 through\nmulti-domain input verify the effectiveness of our model compared to current\nstate-of-the-art methods, improved F1-Score by 0.4\\%, 0.9\\%, and 2.3\\% on the\nthree datasets respectively, 49\\% faster inference and 83.7\\% GPU memory save.\nThe results demonstrate that Coupled Mamba model is capable of enhanced\nmulti-modal fusion.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Wenbing Li",
            "Hang Zhou",
            "Junqing Yu",
            "Zikai Song",
            "Wei Yang"
        ],
        "published": "2024-05-28T09:57:03Z"
    },
    {
        "title": "Flow-Assisted Motion Learning Network for Weakly-Supervised Group\n  Activity Recognition",
        "link": "http://arxiv.org/abs/2405.18012v1",
        "abstract": "Weakly-Supervised Group Activity Recognition (WSGAR) aims to understand the\nactivity performed together by a group of individuals with the video-level\nlabel and without actor-level labels. We propose Flow-Assisted Motion Learning\nNetwork (Flaming-Net) for WSGAR, which consists of the motion-aware actor\nencoder to extract actor features and the two-pathways relation module to infer\nthe interaction among actors and their activity. Flaming-Net leverages an\nadditional optical flow modality in the training stage to enhance its motion\nawareness when finding locally active actors. The first pathway of the relation\nmodule, the actor-centric path, initially captures the temporal dynamics of\nindividual actors and then constructs inter-actor relationships. In parallel,\nthe group-centric path starts by building spatial connections between actors\nwithin the same timeframe and then captures simultaneous spatio-temporal\ndynamics among them. We demonstrate that Flaming-Net achieves new\nstate-of-the-art WSGAR results on two benchmarks, including a 2.8%p higher MPCA\nscore on the NBA dataset. Importantly, we use the optical flow modality only\nfor training and not for inference.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Muhammad Adi Nugroho",
            "Sangmin Woo",
            "Sumin Lee",
            "Jinyoung Park",
            "Yooseung Wang",
            "Donguk Kim",
            "Changick Kim"
        ],
        "published": "2024-05-28T09:53:47Z"
    },
    {
        "title": "Rethinking Recommender Systems: Cluster-based Algorithm Selection",
        "link": "http://arxiv.org/abs/2405.18011v1",
        "abstract": "Cluster-based algorithm selection deals with selecting recommendation\nalgorithms on clusters of users to obtain performance gains. No studies have\nbeen attempted for many combinations of clustering approaches and\nrecommendation algorithms. We want to show that clustering users prior to\nalgorithm selection increases the performance of recommendation algorithms. Our\nstudy covers eight datasets, four clustering approaches, and eight\nrecommendation algorithms. We select the best performing recommendation\nalgorithm for each cluster. Our work shows that cluster-based algorithm\nselection is an effective technique for optimizing recommendation algorithm\nperformance. For five out of eight datasets, we report an increase in nDCG@10\nbetween 19.28% (0.032) and 360.38% (0.191) compared to algorithm selection\nwithout prior clustering.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Andreas Lizenberger",
            "Ferdinand Pfeifer",
            "Bastian Polewka"
        ],
        "published": "2024-05-28T09:53:11Z"
    },
    {
        "title": "Exploring Context Window of Large Language Models via Decomposed\n  Positional Vectors",
        "link": "http://arxiv.org/abs/2405.18009v1",
        "abstract": "Transformer-based large language models (LLMs) typically have a limited\ncontext window, resulting in significant performance degradation when\nprocessing text beyond the length of the context window. Extensive studies have\nbeen proposed to extend the context window and achieve length extrapolation of\nLLMs, but there is still a lack of in-depth interpretation of these approaches.\nIn this study, we explore the positional information within and beyond the\ncontext window for deciphering the underlying mechanism of LLMs. By using a\nmean-based decomposition method, we disentangle positional vectors from hidden\nstates of LLMs and analyze their formation and effect on attention.\nFurthermore, when texts exceed the context window, we analyze the change of\npositional vectors in two settings, i.e., direct extrapolation and context\nwindow extension. Based on our findings, we design two training-free context\nwindow extension methods, positional vector replacement and attention window\nextension. Experimental results show that our methods can effectively extend\nthe context window length.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Zican Dong",
            "Junyi Li",
            "Xin Men",
            "Wayne Xin Zhao",
            "Bingbing Wang",
            "Zhen Tian",
            "Weipeng Chen",
            "Ji-Rong Wen"
        ],
        "published": "2024-05-28T09:50:46Z"
    },
    {
        "title": "SkinCAP: A Multi-modal Dermatology Dataset Annotated with Rich Medical\n  Captions",
        "link": "http://arxiv.org/abs/2405.18004v1",
        "abstract": "With the widespread application of artificial intelligence (AI), particularly\ndeep learning (DL) and vision-based large language models (VLLMs), in skin\ndisease diagnosis, the need for interpretability becomes crucial. However,\nexisting dermatology datasets are limited in their inclusion of concept-level\nmeta-labels, and none offer rich medical descriptions in natural language. This\ndeficiency impedes the advancement of LLM-based methods in dermatological\ndiagnosis. To address this gap and provide a meticulously annotated dermatology\ndataset with comprehensive natural language descriptions, we introduce SkinCAP:\na multi-modal dermatology dataset annotated with rich medical captions. SkinCAP\ncomprises 4,000 images sourced from the Fitzpatrick 17k skin disease dataset\nand the Diverse Dermatology Images dataset, annotated by board-certified\ndermatologists to provide extensive medical descriptions and captions. Notably,\nSkinCAP represents the world's first such dataset and is publicly available at\nhttps://huggingface.co/datasets/joshuachou/SkinCAP.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Juexiao Zhou",
            "Liyuan Sun",
            "Yan Xu",
            "Wenbin Liu",
            "Shawn Afvari",
            "Zhongyi Han",
            "Jiaoyan Song",
            "Yongzhi Ji",
            "Xiaonan He",
            "Xin Gao"
        ],
        "published": "2024-05-28T09:48:23Z"
    },
    {
        "title": "MAVIN: Multi-Action Video Generation with Diffusion Models via\n  Transition Video Infilling",
        "link": "http://arxiv.org/abs/2405.18003v1",
        "abstract": "Diffusion-based video generation has achieved significant progress, yet\ngenerating multiple actions that occur sequentially remains a formidable task.\nDirectly generating a video with sequential actions can be extremely\nchallenging due to the scarcity of fine-grained action annotations and the\ndifficulty in establishing temporal semantic correspondences and maintaining\nlong-term consistency. To tackle this, we propose an intuitive and\nstraightforward solution: splicing multiple single-action video segments\nsequentially. The core challenge lies in generating smooth and natural\ntransitions between these segments given the inherent complexity and\nvariability of action transitions. We introduce MAVIN (Multi-Action Video\nINfilling model), designed to generate transition videos that seamlessly\nconnect two given videos, forming a cohesive integrated sequence. MAVIN\nincorporates several innovative techniques to address challenges in the\ntransition video infilling task. Firstly, a consecutive noising strategy\ncoupled with variable-length sampling is employed to handle large infilling\ngaps and varied generation lengths. Secondly, boundary frame guidance (BFG) is\nproposed to address the lack of semantic guidance during transition generation.\nLastly, a Gaussian filter mixer (GFM) dynamically manages noise initialization\nduring inference, mitigating train-test discrepancy while preserving generation\nflexibility. Additionally, we introduce a new metric, CLIP-RS (CLIP Relative\nSmoothness), to evaluate temporal coherence and smoothness, complementing\ntraditional quality-based metrics. Experimental results on horse and tiger\nscenarios demonstrate MAVIN's superior performance in generating smooth and\ncoherent video transitions compared to existing methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Bowen Zhang",
            "Xiaofei Xie",
            "Haotian Lu",
            "Na Ma",
            "Tianlin Li",
            "Qing Guo"
        ],
        "published": "2024-05-28T09:46:09Z"
    },
    {
        "title": "Network-Aware Reliability Modeling and Optimization for Microservice\n  Placement",
        "link": "http://arxiv.org/abs/2405.18001v1",
        "abstract": "Optimizing microservice placement to enhance the reliability of services is\ncrucial for improving the service level of microservice architecture-based\nmobile networks and Internet of Things (IoT) networks. Despite extensive\nresearch on service reliability, the impact of network load and routing on\nservice reliability remains understudied, leading to suboptimal models and\nunsatisfactory performance. To address this issue, we propose a novel\nnetwork-aware service reliability model that effectively captures the\ncorrelation between network state changes and reliability. Based on this model,\nwe formulate the microservice placement problem as an integer nonlinear\nprogramming problem, aiming to maximize service reliability. Subsequently, a\nservice reliability-aware placement (SRP) algorithm is proposed to solve the\nproblem efficiently. To reduce bandwidth consumption, we further discuss the\nmicroservice placement problem with the shared backup path mechanism and\npropose a placement algorithm based on the SRP algorithm using shared path\nreliability calculation, known as the SRP-S algorithm. Extensive simulations\ndemonstrate that the SRP algorithm reduces service failures by up to 29%\ncompared to the benchmark algorithms. By introducing the shared backup path\nmechanism, the SRP-S algorithm reduces bandwidth consumption by up to 62%\ncompared to the SRP algorithm with the fully protected path mechanism. It also\nreduces service failures by up to 21% compared to the SRP algorithm with the\nshared backup mechanism.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Fangyu Zhang",
            "Yuang Chen",
            "Hancheng Lu",
            "Yongsheng Huang"
        ],
        "published": "2024-05-28T09:39:29Z"
    },
    {
        "title": "A Passive and Asynchronous Wake-up Receiver for Acoustic Underwater\n  Communication",
        "link": "http://arxiv.org/abs/2405.18000v1",
        "abstract": "Establishing reliable data exchange in an underwater domain using energy and\npower-efficient communication methods is crucial and challenging. Radio\nfrequencies are absorbed by the salty and mineral-rich water and optical\nsignals are obstructed and scattered after short distances. In contrast,\nacoustic communication benefits from low absorption and enables communication\nover long distances. Underwater communication must match low power and energy\nrequirements as underwater sensor systems must have a long battery lifetime and\nneed to work reliably due to their deployment and maintenance cost. For\nlong-term deployments, the sensors' overall power consumption is determined by\nthe power consumption during idle state. It can be reduced by integrating\nasynchronous always-on wake-up circuits with nano-watt power consumption.\nHowever, this approach does reduce but not eliminate idle power consumption,\nleaving a margin for improvement. This paper presents a passive and\nasynchronous wake-up receiver for acoustic underwater communication enabling\nzero-power always-on listening. Zero-power listening is achieved by combining\nenergy and information transmission using a low-power wake-up receiver that\nextracts energy out of the acoustic signal and eliminates radio frontend idle\nconsumption. In-field evaluations demonstrate that the wake-up circuit requires\nonly 63 uW to detect and compare an 8-bit UUID at a data rate of 200 bps up to\na distance of 5 m and that the needed energy can directly be extracted from the\nacoustic signal.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Lukas Schulthess",
            "Philipp Mayer",
            "Luca Benini",
            "Michele Magno"
        ],
        "published": "2024-05-28T09:36:22Z"
    },
    {
        "title": "Source Echo Chamber: Exploring the Escalation of Source Bias in User,\n  Data, and Recommender System Feedback Loop",
        "link": "http://arxiv.org/abs/2405.17998v1",
        "abstract": "Recently, researchers have uncovered that neural retrieval models prefer\nAI-generated content (AIGC), called source bias. Compared to active search\nbehavior, recommendation represents another important means of information\nacquisition, where users are more prone to source bias. Furthermore, delving\ninto the recommendation scenario, as AIGC becomes integrated within the\nfeedback loop involving users, data, and the recommender system, it\nprogressively contaminates the candidate items, the user interaction history,\nand ultimately, the data used to train the recommendation models. How and to\nwhat extent the source bias affects the neural recommendation models within\nfeedback loop remains unknown. In this study, we extend the investigation of\nsource bias into the realm of recommender systems, specifically examining its\nimpact across different phases of the feedback loop. We conceptualize the\nprogression of AIGC integration into the recommendation content ecosystem in\nthree distinct phases-HGC dominate, HGC-AIGC coexist, and AIGC dominance-each\nrepresenting past, present, and future states, respectively. Through extensive\nexperiments across three datasets from diverse domains, we demonstrate the\nprevalence of source bias and reveal a potential digital echo chamber with\nsource bias amplification throughout the feedback loop. This trend risks\ncreating a recommender ecosystem with limited information source, such as AIGC,\nbeing disproportionately recommended. To counteract this bias and prevent its\nescalation in the feedback loop, we introduce a black-box debiasing method that\nmaintains model impartiality towards both HGC and AIGC. Our experimental\nresults validate the effectiveness of the proposed debiasing method, confirming\nits potential to disrupt the feedback loop.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Yuqi Zhou",
            "Sunhao Dai",
            "Liang Pang",
            "Gang Wang",
            "Zhenhua Dong",
            "Jun Xu",
            "Ji-Rong Wen"
        ],
        "published": "2024-05-28T09:34:50Z"
    },
    {
        "title": "DMT-JEPA: Discriminative Masked Targets for Joint-Embedding Predictive\n  Architecture",
        "link": "http://arxiv.org/abs/2405.17995v1",
        "abstract": "The joint-embedding predictive architecture (JEPA) recently has shown\nimpressive results in extracting visual representations from unlabeled imagery\nunder a masking strategy. However, we reveal its disadvantages, notably its\ninsufficient understanding of local semantics. This deficiency originates from\nmasked modeling in the embedding space, resulting in a reduction of\ndiscriminative power and can even lead to the neglect of critical local\nsemantics. To bridge this gap, we introduce DMT-JEPA, a novel masked modeling\nobjective rooted in JEPA, specifically designed to generate discriminative\nlatent targets from neighboring information. Our key idea is simple: we\nconsider a set of semantically similar neighboring patches as a target of a\nmasked patch. To be specific, the proposed DMT-JEPA (a) computes feature\nsimilarities between each masked patch and its corresponding neighboring\npatches to select patches having semantically meaningful relations, and (b)\nemploys lightweight cross-attention heads to aggregate features of neighboring\npatches as the masked targets. Consequently, DMT-JEPA demonstrates strong\ndiscriminative power, offering benefits across a diverse spectrum of downstream\ntasks. Through extensive experiments, we demonstrate our effectiveness across\nvarious visual benchmarks, including ImageNet-1K image classification, ADE20K\nsemantic segmentation, and COCO object detection tasks. Code is available at:\n\\url{https://github.com/DMTJEPA/DMTJEPA}.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "eess.IV"
        ],
        "authors": [
            "Shentong Mo",
            "Sukmin Yun"
        ],
        "published": "2024-05-28T09:28:52Z"
    },
    {
        "title": "fMRI predictors based on language models of increasing complexity\n  recover brain left lateralization",
        "link": "http://arxiv.org/abs/2405.17992v1",
        "abstract": "Over the past decade, studies of naturalistic language processing where\nparticipants are scanned while listening to continuous text have flourished.\nUsing word embeddings at first, then large language models, researchers have\ncreated encoding models to analyze the brain signals. Presenting these models\nwith the same text as the participants allows to identify brain areas where\nthere is a significant correlation between the functional magnetic resonance\nimaging (fMRI) time series and the ones predicted by the models' artificial\nneurons. One intriguing finding from these studies is that they have revealed\nhighly symmetric bilateral activation patterns, somewhat at odds with the\nwell-known left lateralization of language processing. Here, we report analyses\nof an fMRI dataset where we manipulate the complexity of large language models,\ntesting 28 pretrained models from 8 different families, ranging from 124M to\n14.2B parameters. First, we observe that the performance of models in\npredicting brain responses follows a scaling law, where the fit with brain\nactivity increases linearly with the logarithm of the number of parameters of\nthe model (and its performance on natural language processing tasks). Second,\nwe show that a left-right asymmetry gradually appears as model size increases,\nand that the difference in left-right brain correlations also follows a scaling\nlaw. Whereas the smallest models show no asymmetry, larger models fit better\nand better left hemispheric activations than right hemispheric ones. This\nfinding reconciles computational analyses of brain activity using large\nlanguage models with the classic observation from aphasic patients showing left\nhemisphere dominance for language.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "q-bio.NC"
        ],
        "authors": [
            "Laurent Bonnasse-Gahot",
            "Christophe Pallier"
        ],
        "published": "2024-05-28T09:24:52Z"
    },
    {
        "title": "VeLoRA: Memory Efficient Training using Rank-1 Sub-Token Projections",
        "link": "http://arxiv.org/abs/2405.17991v1",
        "abstract": "Large language models (LLMs) have recently emerged as powerful tools for\ntackling many language-processing tasks. Despite their success, training and\nfine-tuning these models is still far too computationally and memory intensive.\nIn this paper, we identify and characterise the important components needed for\neffective model convergence using gradient descent. In doing so we find that\nthe intermediate activations used to implement backpropagation can be\nexcessively compressed without incurring any degradation in performance. This\nresult leads us to a cheap and memory-efficient algorithm for both fine-tuning\nand pre-training LLMs. The proposed algorithm simply divides the tokens up into\nsmaller sub-tokens before projecting them onto a fixed 1-dimensional subspace\nduring the forward pass. These features are then coarsely reconstructed during\nthe backward pass to implement the update rules. We confirm the effectiveness\nof our algorithm as being complimentary to many state-of-the-art PEFT methods\non the VTAB-1k fine-tuning benchmark. Furthermore, we outperform QLoRA for\nfine-tuning LLaMA and show competitive performance against other\nmemory-efficient pre-training methods on the large-scale C4 dataset.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Roy Miles",
            "Pradyumna Reddy",
            "Ismail Elezi",
            "Jiankang Deng"
        ],
        "published": "2024-05-28T09:23:14Z"
    },
    {
        "title": "BlueSWAT: A Lightweight State-Aware Security Framework for Bluetooth Low\n  Energy",
        "link": "http://arxiv.org/abs/2405.17987v1",
        "abstract": "Bluetooth Low Energy (BLE) is a short-range wireless communication technology\nfor resource-constrained IoT devices. Unfortunately, BLE is vulnerable to\nsession-based attacks, where previous packets construct exploitable conditions\nfor subsequent packets to compromise connections. Defending against\nsession-based attacks is challenging because each step in the attack sequence\nis legitimate when inspected individually. In this paper, we present BlueSWAT,\na lightweight state-aware security framework for protecting BLE devices. To\nperform inspection on the session level rather than individual packets,\nBlueSWAT leverages a finite state machine (FSM) to monitor sequential actions\nof connections at runtime. Patterns of session-based attacks are modeled as\nmalicious transition paths in the FSM. To overcome the heterogeneous IoT\nenvironment, we develop a lightweight eBPF framework to facilitate universal\npatch distribution across different BLE architectures and stacks, without\nrequiring device reboot. We implement BlueSWAT on 5 real-world devices with\ndifferent chips and stacks to demonstrate its cross-device adaptability. On our\ndataset with 101 real-world BLE vulnerabilities, BlueSWAT can mitigate 76.1% of\nsession-based attacks, outperforming other defense frameworks. In our\nend-to-end application evaluation, BlueSWAT patches introduce an average of\n0.073% memory overhead and negligible latency.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Xijia Che",
            "Yi He",
            "Xuewei Feng",
            "Kun Sun",
            "Ke Xu",
            "Qi Li"
        ],
        "published": "2024-05-28T09:19:52Z"
    },
    {
        "title": "Cross-Context Backdoor Attacks against Graph Prompt Learning",
        "link": "http://arxiv.org/abs/2405.17984v1",
        "abstract": "Graph Prompt Learning (GPL) bridges significant disparities between\npretraining and downstream applications to alleviate the knowledge transfer\nbottleneck in real-world graph learning. While GPL offers superior\neffectiveness in graph knowledge transfer and computational efficiency, the\nsecurity risks posed by backdoor poisoning effects embedded in pretrained\nmodels remain largely unexplored. Our study provides a comprehensive analysis\nof GPL's vulnerability to backdoor attacks. We introduce \\textit{CrossBA}, the\nfirst cross-context backdoor attack against GPL, which manipulates only the\npretraining phase without requiring knowledge of downstream applications. Our\ninvestigation reveals both theoretically and empirically that tuning trigger\ngraphs, combined with prompt transformations, can seamlessly transfer the\nbackdoor threat from pretrained encoders to downstream applications. Through\nextensive experiments involving 3 representative GPL methods across 5 distinct\ncross-context scenarios and 5 benchmark datasets of node and graph\nclassification tasks, we demonstrate that \\textit{CrossBA} consistently\nachieves high attack success rates while preserving the functionality of\ndownstream applications over clean input. We also explore potential\ncountermeasures against \\textit{CrossBA} and conclude that current defenses are\ninsufficient to mitigate \\textit{CrossBA}. Our study highlights the persistent\nbackdoor threats to GPL systems, raising trustworthiness concerns in the\npractices of GPL techniques.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Xiaoting Lyu",
            "Yufei Han",
            "Wei Wang",
            "Hangwei Qian",
            "Ivor Tsang",
            "Xiangliang Zhang"
        ],
        "published": "2024-05-28T09:17:58Z"
    },
    {
        "title": "Reinforced Model Predictive Control via Trust-Region Quasi-Newton Policy\n  Optimization",
        "link": "http://arxiv.org/abs/2405.17983v1",
        "abstract": "Model predictive control can optimally deal with nonlinear systems under\nconsideration of constraints. The control performance depends on the model\naccuracy and the prediction horizon. Recent advances propose to use\nreinforcement learning applied to a parameterized model predictive controller\nto recover the optimal control performance even if an imperfect model or short\nprediction horizons are used. However, common reinforcement learning algorithms\nrely on first order updates, which only have a linear convergence rate and\nhence need an excessive amount of dynamic data. Higher order updates are\ntypically intractable if the policy is approximated with neural networks due to\nthe large number of parameters.\n  In this work, we use a parameterized model predictive controller as policy,\nand leverage the small amount of necessary parameters to propose a trust-region\nconstrained Quasi-Newton training algorithm for policy optimization with a\nsuperlinear convergence rate. We show that the required second order derivative\ninformation can be calculated by the solution of a linear system of equations.\nA simulation study illustrates that the proposed training algorithm outperforms\nother algorithms in terms of data efficiency and accuracy.",
        "subjects": [
            "cs.LG",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Dean Brandner",
            "Sergio Lucia"
        ],
        "published": "2024-05-28T09:16:08Z"
    },
    {
        "title": "Peering into the Mind of Language Models: An Approach for Attribution in\n  Contextual Question Answering",
        "link": "http://arxiv.org/abs/2405.17980v1",
        "abstract": "With the enhancement in the field of generative artificial intelligence (AI),\ncontextual question answering has become extremely relevant. Attributing model\ngenerations to the input source document is essential to ensure trustworthiness\nand reliability. We observe that when large language models (LLMs) are used for\ncontextual question answering, the output answer often consists of text copied\nverbatim from the input prompt which is linked together with \"glue text\"\ngenerated by the LLM. Motivated by this, we propose that LLMs have an inherent\nawareness from where the text was copied, likely captured in the hidden states\nof the LLM. We introduce a novel method for attribution in contextual question\nanswering, leveraging the hidden state representations of LLMs. Our approach\nbypasses the need for extensive model retraining and retrieval model overhead,\noffering granular attributions and preserving the quality of generated answers.\nOur experimental results demonstrate that our method performs on par or better\nthan GPT-4 at identifying verbatim copied segments in LLM generations and in\nattributing these segments to their source. Importantly, our method shows\nrobust performance across various LLM architectures, highlighting its broad\napplicability. Additionally, we present Verifiability-granular, an attribution\ndataset which has token level annotations for LLM generations in the contextual\nquestion answering setup.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Anirudh Phukan",
            "Shwetha Somasundaram",
            "Apoorv Saxena",
            "Koustava Goswami",
            "Balaji Vasan Srinivasan"
        ],
        "published": "2024-05-28T09:12:44Z"
    },
    {
        "title": "Performance of Slotted ALOHA in User-Centric Cell-Free Massive MIMO",
        "link": "http://arxiv.org/abs/2405.17979v1",
        "abstract": "To efficiently utilize the scarce wireless resource, the random access scheme\nhas been attaining renewed interest primarily in supporting the sporadic\ntraffic of a large number of devices encountered in the Internet of Things\n(IoT). In this paper we investigate the performance of slotted ALOHA -- a\nsimple and practical random access scheme -- in connection with the grant-free\nrandom access protocol applied for user-centric cell-free massive MIMO. More\nspecifically, we provide the expression of the sum-throughput under the\nassumptions of the capture capability owned by the centralized detector in the\nuplink. Further, a comparative study of user-centric cell-free massive MIMO\nwith other types of networks is provided, which allows us to identify its\npotential and possible limitation. Our numerical simulations show that the\nuser-centric cell-free massive MIMO has a good trade-off between performance\nand fronthaul load, especially at low activation probability regime.",
        "subjects": [
            "cs.IT",
            "cs.NI",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Dick Maryopi",
            "Daud Al Adumy",
            "Osman Musa",
            "Peter Jung",
            "Agus Virgono"
        ],
        "published": "2024-05-28T09:08:56Z"
    },
    {
        "title": "FASTopic: A Fast, Adaptive, Stable, and Transferable Topic Modeling\n  Paradigm",
        "link": "http://arxiv.org/abs/2405.17978v1",
        "abstract": "Topic models have been evolving rapidly over the years, from conventional to\nrecent neural models. However, existing topic models generally struggle with\neither effectiveness, efficiency, or stability, highly impeding their practical\napplications. In this paper, we propose FASTopic, a fast, adaptive, stable, and\ntransferable topic model. FASTopic follows a new paradigm: Dual\nSemantic-relation Reconstruction (DSR). Instead of previous conventional,\nneural VAE-based or clustering-based methods, DSR discovers latent topics by\nreconstruction through modeling the semantic relations among document, topic,\nand word embeddings. This brings about a neat and efficient topic modeling\nframework. We further propose a novel Embedding Transport Plan (ETP) method.\nRather than early straightforward approaches, ETP explicitly regularizes the\nsemantic relations as optimal transport plans. This addresses the relation bias\nissue and thus leads to effective topic modeling. Extensive experiments on\nbenchmark datasets demonstrate that our FASTopic shows superior effectiveness,\nefficiency, adaptivity, stability, and transferability, compared to\nstate-of-the-art baselines across various scenarios. Our code is available at\nhttps://github.com/bobxwu/FASTopic .",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Xiaobao Wu",
            "Thong Nguyen",
            "Delvin Ce Zhang",
            "William Yang Wang",
            "Anh Tuan Luu"
        ],
        "published": "2024-05-28T09:06:38Z"
    },
    {
        "title": "Aligning to Thousands of Preferences via System Message Generalization",
        "link": "http://arxiv.org/abs/2405.17977v1",
        "abstract": "Although humans inherently have diverse values, current large language model\n(LLM) alignment methods often assume that aligning LLMs with the general\npublic's preferences is optimal. A major challenge in adopting a more\nindividualized approach to LLM alignment is its lack of scalability, as it\ninvolves repeatedly acquiring preference data and training new reward models\nand LLMs for each individual's preferences. To address these challenges, we\npropose a new paradigm where users specify what they value most within the\nsystem message, steering the LLM's generation behavior to better align with the\nuser's intentions. However, a naive application of such an approach is\nnon-trivial since LLMs are typically trained on a uniform system message (e.g.,\n\"You are a helpful assistant\") which limits their ability to generalize to\ndiverse, unseen system messages. To improve this generalization, we create the\nMultifaceted Collection, a preference dataset with 192k combinations of values\nbeyond generic helpfulness and harmlessness, spanning 65k user instructions.\nUsing this dataset, we train a 7B LLM called Janus and test it on 921 prompts\nfrom 5 benchmarks (AlpacaEval 2.0, FLASK, Koala, MT-Bench, and Self-Instruct)\nby adding various unseen system messages that reflect user preferences. Janus\nachieves tie+win rate of 75.2%, 72.4%, and 66.4% against Mistral 7B Instruct\nv0.2, GPT-3.5 Turbo, and GPT-4, respectively. Unexpectedly, on three benchmarks\nfocused on response helpfulness (AlpacaEval 2.0, MT-Bench, Arena Hard Auto\nv0.1), Janus also outperforms LLaMA 3 8B Instruct by a +4.0%, +0.1%, +3.0%\nmargin, underscoring that training with a vast array of system messages could\nalso enhance alignment to the general public's preference as well. Our code,\ndataset, benchmark, and models are available at\nhttps://github.com/kaistAI/Janus.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Seongyun Lee",
            "Sue Hyun Park",
            "Seungone Kim",
            "Minjoon Seo"
        ],
        "published": "2024-05-28T09:06:18Z"
    },
    {
        "title": "Yuan 2.0-M32: Mixture of Experts with Attention Router",
        "link": "http://arxiv.org/abs/2405.17976v2",
        "abstract": "Yuan 2.0-M32, with a similar base architecture as Yuan-2.0 2B, uses a\nmixture-of-experts architecture with 32 experts of which 2 experts are active.\nA new router network, Attention Router, is proposed and adopted for a more\nefficient selection of experts, which improves the accuracy compared to the\nmodel with classical router network. Yuan 2.0-M32 is trained with 2000B tokens\nfrom scratch, and the training computation consumption is only 9.25% of a dense\nmodel at the same parameter scale. Yuan 2.0-M32 demonstrates competitive\ncapability on coding, math, and various domains of expertise, with only 3.7B\nactive parameters of 40B in total, and 7.4 GFlops forward computation per\ntoken, both of which are only 1/19 of Llama3-70B. Yuan 2.0-M32 surpass\nLlama3-70B on MATH and ARC-Challenge benchmark, with accuracy of 55.89 and 95.8\nrespectively. The models and source codes of Yuan 2.0-M32 are released at\nGithub1.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Shaohua Wu",
            "Jiangang Luo",
            "Xi Chen",
            "Lingjun Li",
            "Xudong Zhao",
            "Tong Yu",
            "Chao Wang",
            "Yue Wang",
            "Fei Wang",
            "Weixu Qiao",
            "Houbo He",
            "Zeru Zhang",
            "Zeyu Sun",
            "Junxiong Mao",
            "Chong Shen"
        ],
        "published": "2024-05-28T09:05:08Z"
    },
    {
        "title": "Recent Trends in Personalized Dialogue Generation: A Review of Datasets,\n  Methodologies, and Evaluations",
        "link": "http://arxiv.org/abs/2405.17974v1",
        "abstract": "Enhancing user engagement through personalization in conversational agents\nhas gained significance, especially with the advent of large language models\nthat generate fluent responses. Personalized dialogue generation, however, is\nmultifaceted and varies in its definition -- ranging from instilling a persona\nin the agent to capturing users' explicit and implicit cues. This paper seeks\nto systemically survey the recent landscape of personalized dialogue\ngeneration, including the datasets employed, methodologies developed, and\nevaluation metrics applied. Covering 22 datasets, we highlight benchmark\ndatasets and newer ones enriched with additional features. We further analyze\n17 seminal works from top conferences between 2021-2023 and identify five\ndistinct types of problems. We also shed light on recent progress by LLMs in\npersonalized dialogue generation. Our evaluation section offers a comprehensive\nsummary of assessment facets and metrics utilized in these works. In\nconclusion, we discuss prevailing challenges and envision prospect directions\nfor future research in personalized dialogue generation.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Yi-Pei Chen",
            "Noriki Nishida",
            "Hideki Nakayama",
            "Yuji Matsumoto"
        ],
        "published": "2024-05-28T09:04:13Z"
    },
    {
        "title": "A Qualitative Analysis Framework for mHealth Privacy Practices",
        "link": "http://arxiv.org/abs/2405.17971v1",
        "abstract": "Mobile Health (mHealth) applications have become a crucial part of health\nmonitoring and management. However, the proliferation of these applications has\nalso raised concerns over the privacy and security of Personally Identifiable\nInformation and Protected Health Information. Addressing these concerns, this\npaper introduces a novel framework for the qualitative evaluation of privacy\npractices in mHealth apps, particularly focusing on the handling and\ntransmission of sensitive user data. Our investigation encompasses an analysis\nof 152 leading mHealth apps on the Android platform, leveraging the proposed\nframework to provide a multifaceted view of their data processing activities.\nDespite stringent regulations like the General Data Protection Regulation in\nthe European Union and the Health Insurance Portability and Accountability Act\nin the United States, our findings indicate persistent issues with negligence\nand misuse of sensitive user information. We uncover significant instances of\nhealth information leakage to third-party trackers and a widespread neglect of\nprivacy-by-design and transparency principles. Our research underscores the\ncritical need for stricter enforcement of data protection laws and sets a\nfoundation for future efforts aimed at enhancing user privacy within the\nmHealth ecosystem.",
        "subjects": [
            "cs.CY"
        ],
        "authors": [
            "Thomas Cory",
            "Wolf Rieder",
            "Thu-My Huynh"
        ],
        "published": "2024-05-28T08:57:52Z"
    },
    {
        "title": "Knowledge Circuits in Pretrained Transformers",
        "link": "http://arxiv.org/abs/2405.17969v1",
        "abstract": "The remarkable capabilities of modern large language models are rooted in\ntheir vast repositories of knowledge encoded within their parameters, enabling\nthem to perceive the world and engage in reasoning. The inner workings of how\nthese models store knowledge have long been a subject of intense interest and\ninvestigation among researchers. To date, most studies have concentrated on\nisolated components within these models, such as the Multilayer Perceptrons and\nattention head. In this paper, we delve into the computation graph of the\nlanguage model to uncover the knowledge circuits that are instrumental in\narticulating specific knowledge. The experiments, conducted with GPT2 and\nTinyLLAMA, has allowed us to observe how certain information heads, relation\nheads, and Multilayer Perceptrons collaboratively encode knowledge within the\nmodel. Moreover, we evaluate the impact of current knowledge editing techniques\non these knowledge circuits, providing deeper insights into the functioning and\nconstraints of these editing methodologies. Finally, we utilize knowledge\ncircuits to analyze and interpret language model behaviors such as\nhallucinations and in-context learning. We believe the knowledge circuit holds\npotential for advancing our understanding of Transformers and guiding the\nimproved design of knowledge editing. Code and data are available in\nhttps://github.com/zjunlp/KnowledgeCircuits.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV",
            "cs.IR",
            "cs.LG"
        ],
        "authors": [
            "Yunzhi Yao",
            "Ningyu Zhang",
            "Zekun Xi",
            "Mengru Wang",
            "Ziwen Xu",
            "Shumin Deng",
            "Huajun Chen"
        ],
        "published": "2024-05-28T08:56:33Z"
    },
    {
        "title": "Matroid Semi-Bandits in Sublinear Time",
        "link": "http://arxiv.org/abs/2405.17968v1",
        "abstract": "We study the matroid semi-bandits problem, where at each round the learner\nplays a subset of $K$ arms from a feasible set, and the goal is to maximize the\nexpected cumulative linear rewards. Existing algorithms have per-round time\ncomplexity at least $\\Omega(K)$, which becomes expensive when $K$ is large. To\naddress this computational issue, we propose FasterCUCB whose sampling rule\ntakes time sublinear in $K$ for common classes of matroids: $O(D\\text{\npolylog}(K)\\text{ polylog}(T))$ for uniform matroids, partition matroids, and\ngraphical matroids, and $O(D\\sqrt{K}\\text{ polylog}(T))$ for transversal\nmatroids. Here, $D$ is the maximum number of elements in any feasible subset of\narms, and $T$ is the horizon. Our technique is based on dynamic maintenance of\nan approximate maximum-weight basis over inner-product weights. Although the\nintroduction of an approximate maximum-weight basis presents a challenge in\nregret analysis, we can still guarantee an upper bound on regret as tight as\nCUCB in the sense that it matches the gap-dependent lower bound by Kveton et\nal. (2014a) asymptotically.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Ruo-Chun Tzeng",
            "Naoto Ohsaka",
            "Kaito Ariu"
        ],
        "published": "2024-05-28T08:55:02Z"
    },
    {
        "title": "AttenCraft: Attention-guided Disentanglement of Multiple Concepts for\n  Text-to-Image Customization",
        "link": "http://arxiv.org/abs/2405.17965v1",
        "abstract": "With the unprecedented performance being achieved by text-to-image (T2I)\ndiffusion models, T2I customization further empowers users to tailor the\ndiffusion model to new concepts absent in the pre-training dataset, termed\nsubject-driven generation. Moreover, extracting several new concepts from a\nsingle image enables the model to learn multiple concepts, and simultaneously\ndecreases the difficulties of training data preparation, urging the\ndisentanglement of multiple concepts to be a new challenge. However, existing\nmodels for disentanglement commonly require pre-determined masks or retain\nbackground elements. To this end, we propose an attention-guided method,\nAttenCraft, for multiple concept disentanglement. In particular, our method\nleverages self-attention and cross-attention maps to create accurate masks for\neach concept within a single initialization step, omitting any required mask\npreparation by humans or other models. The created masks are then applied to\nguide the cross-attention activation of each target concept during training and\nachieve concept disentanglement. Additionally, we introduce Uniform sampling\nand Reweighted sampling schemes to alleviate the non-synchronicity of feature\nacquisition from different concepts, and improve generation quality. Our method\noutperforms baseline models in terms of image-alignment, and behaves comparably\non text-alignment. Finally, we showcase the applicability of AttenCraft to more\ncomplicated settings, such as an input image containing three concepts. The\nproject is available at https://github.com/junjie-shentu/AttenCraft.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Junjie Shentu",
            "Matthew Watson",
            "Noura Al Moubayed"
        ],
        "published": "2024-05-28T08:50:14Z"
    },
    {
        "title": "Transformer and Hybrid Deep Learning Based Models for Machine-Generated\n  Text Detection",
        "link": "http://arxiv.org/abs/2405.17964v1",
        "abstract": "This paper describes the approach of the UniBuc - NLP team in tackling the\nSemEval 2024 Task 8: Multigenerator, Multidomain, and Multilingual Black-Box\nMachine-Generated Text Detection. We explored transformer-based and hybrid deep\nlearning architectures. For subtask B, our transformer-based model achieved a\nstrong \\textbf{second-place} out of $77$ teams with an accuracy of\n\\textbf{86.95\\%}, demonstrating the architecture's suitability for this task.\nHowever, our models showed overfitting in subtask A which could potentially be\nfixed with less fine-tunning and increasing maximum sequence length. For\nsubtask C (token-level classification), our hybrid model overfit during\ntraining, hindering its ability to detect transitions between human and\nmachine-generated text.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Teodor-George Marchitan",
            "Claudiu Creanga",
            "Liviu P. Dinu"
        ],
        "published": "2024-05-28T08:48:08Z"
    },
    {
        "title": "Attention-based sequential recommendation system using multimodal data",
        "link": "http://arxiv.org/abs/2405.17959v1",
        "abstract": "Sequential recommendation systems that model dynamic preferences based on a\nuse's past behavior are crucial to e-commerce. Recent studies on these systems\nhave considered various types of information such as images and texts. However,\nmultimodal data have not yet been utilized directly to recommend products to\nusers. In this study, we propose an attention-based sequential recommendation\nmethod that employs multimodal data of items such as images, texts, and\ncategories. First, we extract image and text features from pre-trained VGG and\nBERT and convert categories into multi-labeled forms. Subsequently, attention\noperations are performed independent of the item sequence and multimodal\nrepresentations. Finally, the individual attention information is integrated\nthrough an attention fusion function. In addition, we apply multitask learning\nloss for each modality to improve the generalization performance. The\nexperimental results obtained from the Amazon datasets show that the proposed\nmethod outperforms those of conventional sequential recommendation systems.",
        "subjects": [
            "cs.IR",
            "cs.AI",
            "I.2.1; I.2.4; I.2.7"
        ],
        "authors": [
            "Hyungtaik Oh",
            "Wonkeun Jo",
            "Dongil Kim"
        ],
        "published": "2024-05-28T08:41:05Z"
    },
    {
        "title": "FreeSplat: Generalizable 3D Gaussian Splatting Towards Free-View\n  Synthesis of Indoor Scenes",
        "link": "http://arxiv.org/abs/2405.17958v1",
        "abstract": "Empowering 3D Gaussian Splatting with generalization ability is appealing.\nHowever, existing generalizable 3D Gaussian Splatting methods are largely\nconfined to narrow-range interpolation between stereo images due to their heavy\nbackbones, thus lacking the ability to accurately localize 3D Gaussian and\nsupport free-view synthesis across wide view range. In this paper, we present a\nnovel framework FreeSplat that is capable of reconstructing geometrically\nconsistent 3D scenes from long sequence input towards free-view\nsynthesis.Specifically, we firstly introduce Low-cost Cross-View Aggregation\nachieved by constructing adaptive cost volumes among nearby views and\naggregating features using a multi-scale structure. Subsequently, we present\nthe Pixel-wise Triplet Fusion to eliminate redundancy of 3D Gaussians in\noverlapping view regions and to aggregate features observed across multiple\nviews. Additionally, we propose a simple but effective free-view training\nstrategy that ensures robust view synthesis across broader view range\nregardless of the number of views. Our empirical results demonstrate\nstate-of-the-art novel view synthesis peformances in both novel view rendered\ncolor maps quality and depth maps accuracy across different numbers of input\nviews. We also show that FreeSplat performs inference more efficiently and can\neffectively reduce redundant Gaussians, offering the possibility of\nfeed-forward large scene reconstruction without depth priors.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yunsong Wang",
            "Tianxin Huang",
            "Hanlin Chen",
            "Gim Hee Lee"
        ],
        "published": "2024-05-28T08:40:14Z"
    },
    {
        "title": "Modeling Dynamic Topics in Chain-Free Fashion by Evolution-Tracking\n  Contrastive Learning and Unassociated Word Exclusion",
        "link": "http://arxiv.org/abs/2405.17957v1",
        "abstract": "Dynamic topic models track the evolution of topics in sequential documents,\nwhich have derived various applications like trend analysis and opinion mining.\nHowever, existing models suffer from repetitive topic and unassociated topic\nissues, failing to reveal the evolution and hindering further applications. To\naddress these issues, we break the tradition of simply chaining topics in\nexisting work and propose a novel neural \\modelfullname. We introduce a new\nevolution-tracking contrastive learning method that builds the similarity\nrelations among dynamic topics. This not only tracks topic evolution but also\nmaintains topic diversity, mitigating the repetitive topic issue. To avoid\nunassociated topics, we further present an unassociated word exclusion method\nthat consistently excludes unassociated words from discovered topics. Extensive\nexperiments demonstrate our model significantly outperforms state-of-the-art\nbaselines, tracking topic evolution with high-quality topics, showing better\nperformance on downstream tasks, and remaining robust to the hyperparameter for\nevolution intensities. Our code is available at https://github.com/bobxwu/CFDTM .",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Xiaobao Wu",
            "Xinshuai Dong",
            "Liangming Pan",
            "Thong Nguyen",
            "Anh Tuan Luu"
        ],
        "published": "2024-05-28T08:39:49Z"
    },
    {
        "title": "Hybrid Preference Optimization: Augmenting Direct Preference\n  Optimization with Auxiliary Objectives",
        "link": "http://arxiv.org/abs/2405.17956v2",
        "abstract": "For aligning large language models (LLMs), prior work has leveraged\nreinforcement learning via human feedback (RLHF) or variations of direct\npreference optimization (DPO). While DPO offers a simpler framework based on\nmaximum likelihood estimation, it compromises on the ability to tune language\nmodels to easily maximize non-differentiable and non-binary objectives\naccording to the LLM designer's preferences (e.g., using simpler language or\nminimizing specific kinds of harmful content). These may neither align with\nuser preferences nor even be able to be captured tractably by binary preference\ndata. To leverage the simplicity and performance of DPO with the\ngeneralizability of RL, we propose a hybrid approach between DPO and RLHF. With\na simple augmentation to the implicit reward decomposition of DPO, we allow for\ntuning LLMs to maximize a set of arbitrary auxiliary rewards using offline RL.\nThe proposed method, Hybrid Preference Optimization (HPO), shows the ability to\neffectively generalize to both user preferences and auxiliary designer\nobjectives, while preserving alignment performance across a range of\nchallenging benchmarks and model sizes.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Anirudhan Badrinath",
            "Prabhat Agarwal",
            "Jiajing Xu"
        ],
        "published": "2024-05-28T08:35:48Z"
    },
    {
        "title": "Efficient Prior Calibration From Indirect Data",
        "link": "http://arxiv.org/abs/2405.17955v1",
        "abstract": "Bayesian inversion is central to the quantification of uncertainty within\nproblems arising from numerous applications in science and engineering. To\nformulate the approach, four ingredients are required: a forward model mapping\nthe unknown parameter to an element of a solution space, often the solution\nspace for a differential equation; an observation operator mapping an element\nof the solution space to the data space; a noise model describing how noise\npollutes the observations; and a prior model describing knowledge about the\nunknown parameter before the data is acquired. This paper is concerned with\nlearning the prior model from data; in particular, learning the prior from\nmultiple realizations of indirect data obtained through the noisy observation\nprocess. The prior is represented, using a generative model, as the pushforward\nof a Gaussian in a latent space; the pushforward map is learned by minimizing\nan appropriate loss function. A metric that is well-defined under empirical\napproximation is used to define the loss function for the pushforward map to\nmake an implementable methodology. Furthermore, an efficient residual-based\nneural operator approximation of the forward model is proposed and it is shown\nthat this may be learned concurrently with the pushforward map, using a bilevel\noptimization formulation of the problem; this use of neural operator\napproximation has the potential to make prior learning from indirect data more\ncomputationally efficient, especially when the observation process is\nexpensive, non-smooth or not known. The ideas are illustrated with the Darcy\nflow inverse problem of finding permeability from piezometric head\nmeasurements.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.CO"
        ],
        "authors": [
            "O. Deniz Akyildiz",
            "Mark Girolami",
            "Andrew M. Stuart",
            "Arnaud Vadeboncoeur"
        ],
        "published": "2024-05-28T08:34:41Z"
    },
    {
        "title": "Graph Threading with Turn Costs",
        "link": "http://arxiv.org/abs/2405.17953v1",
        "abstract": "How should we thread a single string through a set of tubes so that pulling\nthe string taut self-assembles the tubes into a desired graph? While prior work\n[ITCS 2024] solves this problem with the goal of minimizing the length of\nstring, we study here the objective of minimizing the total turn cost. The\nfrictional force required to pull the string through the tubes grows\nexponentially with the total absolute turn angles (by the Capstan equation), so\nthis metric often dominates the friction in real-world applications such as\ndeployable structures. We show that minimum-turn threading is NP-hard, even for\ngraphs of maximum degree 4, and even when restricted to some special cases of\nthreading. On the other hand, we show that these special cases can in fact be\nsolved efficiently for graphs of maximum degree 4, thereby fully characterizing\ntheir dependence on maximum degree. We further provide polynomial-time exact\nand approximation algorithms for variants of turn-cost threading: restricting\nto threading each edge exactly twice, and on rectangular grid graphs.",
        "subjects": [
            "cs.DS",
            "cs.CC",
            "G.2.2; F.2.2"
        ],
        "authors": [
            "Erik D. Demaine",
            "Yael Kirkpatrick",
            "Rebecca Lin"
        ],
        "published": "2024-05-28T08:34:03Z"
    },
    {
        "title": "Upper Bounds on the Average Height of Random Binary Trees",
        "link": "http://arxiv.org/abs/2405.17952v1",
        "abstract": "We study the average height of random trees generated by leaf-centric binary\ntree sources as introduced by Zhang, Yang and Kieffer. A leaf-centric binary\ntree source induces for every $n \\geq 2$ a probability distribution on the set\nof binary trees with $n$ leaves. Our results generalize a result by Devroye,\naccording to which the average height of a random binary search tree of size\n$n$ is in $\\mathcal{O}(\\log n)$.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "authors": [
            "Louisa Seelbach Benkner"
        ],
        "published": "2024-05-28T08:32:01Z"
    },
    {
        "title": "Efficient Time Series Processing for Transformers and State-Space Models\n  through Token Merging",
        "link": "http://arxiv.org/abs/2405.17951v1",
        "abstract": "Transformer architectures have shown promising results in time series\nprocessing. However, despite recent advances in subquadratic attention\nmechanisms or state-space models, processing very long sequences still imposes\nsignificant computational requirements. Token merging, which involves replacing\nmultiple tokens with a single one calculated as their linear combination, has\nshown to considerably improve the throughput of vision transformer\narchitectures while maintaining accuracy. In this work, we go beyond computer\nvision and perform the first investigations of token merging in time series\nanalysis on both time series transformers and state-space models. To\neffectively scale token merging to long sequences, we introduce local merging,\na domain-specific token merging algorithm that selectively combines tokens\nwithin a local neighborhood, adjusting the computational complexity from linear\nto quadratic based on the neighborhood size. Our comprehensive empirical\nevaluation demonstrates that token merging offers substantial computational\nbenefits with minimal impact on accuracy across various models and datasets. On\nthe recently proposed Chronos foundation model, we achieve accelerations up to\n5400% with only minor accuracy degradations.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Leon Götz",
            "Marcel Kollovieh",
            "Stephan Günnemann",
            "Leo Schwinn"
        ],
        "published": "2024-05-28T08:28:18Z"
    },
    {
        "title": "Self-Guiding Exploration for Combinatorial Problems",
        "link": "http://arxiv.org/abs/2405.17950v1",
        "abstract": "Large Language Models (LLMs) have become pivotal in addressing reasoning\ntasks across diverse domains, including arithmetic, commonsense, and symbolic\nreasoning. They utilize prompting techniques such as Exploration-of-Thought,\nDecomposition, and Refinement to effectively navigate and solve intricate\ntasks. Despite these advancements, the application of LLMs to Combinatorial\nProblems (CPs), known for their NP-hardness and critical roles in logistics and\nresource management remains underexplored. To address this gap, we introduce a\nnovel prompting strategy: Self-Guiding Exploration (SGE), designed to enhance\nthe performance of solving CPs. SGE operates autonomously, generating multiple\nthought trajectories for each CP task. It then breaks these trajectories down\ninto actionable subtasks, executes them sequentially, and refines the results\nto ensure optimal outcomes. We present our research as the first to apply LLMs\nto a broad range of CPs and demonstrate that SGE outperforms existing prompting\nstrategies by over 27.84% in CP optimization performance. Additionally, SGE\nachieves a 2.46% higher accuracy over the best existing results in other\nreasoning tasks (arithmetic, commonsense, and symbolic).",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Zangir Iklassov",
            "Yali Du",
            "Farkhad Akimov",
            "Martin Takac"
        ],
        "published": "2024-05-28T08:26:54Z"
    },
    {
        "title": "Remeasuring the Arbitrage and Sandwich Attacks of Maximal Extractable\n  Value in Ethereum",
        "link": "http://arxiv.org/abs/2405.17944v1",
        "abstract": "Maximal Extractable Value (MEV) drives the prosperity of the blockchain\necosystem. By strategically including, excluding, or reordering transactions\nwithin blocks, block producers/validators can extract additional value, which\nin turn incentivizes them to keep the decentralization of the whole blockchain\nplatform. Before The Merge of Ethereum in Sep. 2022, around \\$675M was\nextracted in terms of MEV. Despite its importance, current measurement works on\nMEV suffer some limitations. First, current works only focus on transactions of\na very limited number of DApps. Second, current methods heavily rely on fixed\nheuristic rule-based patterns, leading to false negative/positive. Third, the\nobservations and conclusions are outdated to some extent due to the\ncontinuously introduced features, like The Merge in Ethereum. To address these\nchallenges, in this work, we first propose two robust methods to identify\narbitrage transactions and sandwich attacks, respectively. Then, we apply them\nto the largest-ever dataset to filter out related MEV transactions. Based on\nthe identified results, we have characterized the overall landscape of the\nEthereum MEV ecosystem, the impact the private transaction architectures bring,\nand the adoption of back-running mechanism. Our research will shed light on\nfuture MEV-related work.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Tianyang Chi",
            "Ningyu He",
            "Xiaohui Hu",
            "Haoyu Wang"
        ],
        "published": "2024-05-28T08:17:15Z"
    },
    {
        "title": "Self-supervised Pre-training for Transferable Multi-modal Perception",
        "link": "http://arxiv.org/abs/2405.17942v1",
        "abstract": "In autonomous driving, multi-modal perception models leveraging inputs from\nmultiple sensors exhibit strong robustness in degraded environments. However,\nthese models face challenges in efficiently and effectively transferring\nlearned representations across different modalities and tasks. This paper\npresents NeRF-Supervised Masked Auto Encoder (NS-MAE), a self-supervised\npre-training paradigm for transferable multi-modal representation learning.\nNS-MAE is designed to provide pre-trained model initializations for efficient\nand high-performance fine-tuning. Our approach uses masked multi-modal\nreconstruction in neural radiance fields (NeRF), training the model to\nreconstruct missing or corrupted input data across multiple modalities.\nSpecifically, multi-modal embeddings are extracted from corrupted LiDAR point\nclouds and images, conditioned on specific view directions and locations. These\nembeddings are then rendered into projected multi-modal feature maps using\nneural rendering techniques. The original multi-modal signals serve as\nreconstruction targets for the rendered feature maps, facilitating\nself-supervised representation learning. Extensive experiments demonstrate the\npromising transferability of NS-MAE representations across diverse multi-modal\nand single-modal perception models. This transferability is evaluated on\nvarious 3D perception downstream tasks, such as 3D object detection and BEV map\nsegmentation, using different amounts of fine-tuning labeled data. Our code\nwill be released to support the community.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "authors": [
            "Xiaohao Xu",
            "Tianyi Zhang",
            "Jinrong Yang",
            "Matthew Johnson-Roberson",
            "Xiaonan Huang"
        ],
        "published": "2024-05-28T08:13:49Z"
    },
    {
        "title": "World Models for General Surgical Grasping",
        "link": "http://arxiv.org/abs/2405.17940v1",
        "abstract": "Intelligent vision control systems for surgical robots should adapt to\nunknown and diverse objects while being robust to system disturbances. Previous\nmethods did not meet these requirements due to mainly relying on pose\nestimation and feature tracking. We propose a world-model-based deep\nreinforcement learning framework \"Grasp Anything for Surgery\" (GAS), that\nlearns a pixel-level visuomotor policy for surgical grasping, enhancing both\ngenerality and robustness. In particular, a novel method is proposed to\nestimate the values and uncertainties of depth pixels for a rigid-link object's\ninaccurate region based on the empirical prior of the object's size; both depth\nand mask images of task objects are encoded to a single compact 3-channel image\n(size: 64x64x3) by dynamically zooming in the mask regions, minimizing the\ninformation loss. The learned controller's effectiveness is extensively\nevaluated in simulation and in a real robot. Our learned visuomotor policy\nhandles: i) unseen objects, including 5 types of target grasping objects and a\nrobot gripper, in unstructured real-world surgery environments, and ii)\ndisturbances in perception and control. Note that we are the first work to\nachieve a unified surgical control system that grasps diverse surgical objects\nusing different robot grippers on real robots in complex surgery scenes\n(average success rate: 69%). Our system also demonstrates significant\nrobustness across 6 conditions including background variation, target\ndisturbance, camera pose variation, kinematic control error, image noise, and\nre-grasping after the gripped target object drops from the gripper. Videos and\ncodes can be found on our project page: https://linhongbin.github.io/gas/.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "authors": [
            "Hongbin Lin",
            "Bin Li",
            "Chun Wai Wong",
            "Juan Rojas",
            "Xiangyu Chu",
            "Kwok Wai Samuel Au"
        ],
        "published": "2024-05-28T08:11:12Z"
    },
    {
        "title": "An empirical study of bloated dependencies in CommonJS packages",
        "link": "http://arxiv.org/abs/2405.17939v1",
        "abstract": "JavaScript packages are notoriously prone to bloat, a factor that\nsignificantly impacts the performance and maintainability of web applications.\nWhile web bundlers and tree-shaking can mitigate this issue in client-side\napplications at the function level, they cannot effectively detect and remove\nbloat in server-side applications. In this paper, we conduct an empirical study\nto investigate the bloated dependencies that are entirely unused within\nserver-side applications. Our study focuses on applications built with the\nwidely used and highly dynamic CommonJS module system. We propose a trace-based\ndynamic analysis that monitors file access, to determine which dependencies are\nnot accessed during runtime. To conduct our study, we curate an original\ndataset of 92 CommonJS packages with a median test coverage of 96.9% and a\ntotal of 50,661 dependencies. Our dynamic analysis identifies and successfully\nremoves 50.7% of these dependencies while maintaining the correct build of all\npackages. Furthermore, we find that 14.9% of directly used dependencies and\n51.3% of indirect dependencies are bloated. A key insight is that focusing on\nremoving only the direct bloated dependencies by cleaning the package.json\nfile, also removes a significant share of unnecessary bloated indirect\ndependencies. Compared to the state-of-the-art dynamic debloating technique,\nour analysis based on file accesses has fewer false positives, and demonstrates\nhigher accuracy in detecting bloated dependencies. Our findings suggest that\nnative support for dependency debloating in package managers could\nsignificantly alleviate the burden of maintaining dependencies.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Yuxin Liu",
            "Deepika Tiwari",
            "Cristian Bogdan",
            "Benoit Baudry"
        ],
        "published": "2024-05-28T08:04:01Z"
    },
    {
        "title": "RC-Mixup: A Data Augmentation Strategy against Noisy Data for Regression\n  Tasks",
        "link": "http://arxiv.org/abs/2405.17938v1",
        "abstract": "We study the problem of robust data augmentation for regression tasks in the\npresence of noisy data. Data augmentation is essential for generalizing deep\nlearning models, but most of the techniques like the popular Mixup are\nprimarily designed for classification tasks on image data. Recently, there are\nalso Mixup techniques that are specialized to regression tasks like C-Mixup. In\ncomparison to Mixup, which takes linear interpolations of pairs of samples,\nC-Mixup is more selective in which samples to mix based on their label\ndistances for better regression performance. However, C-Mixup does not\ndistinguish noisy versus clean samples, which can be problematic when mixing\nand lead to suboptimal model performance. At the same time, robust training has\nbeen heavily studied where the goal is to train accurate models against noisy\ndata through multiple rounds of model training. We thus propose our data\naugmentation strategy RC-Mixup, which tightly integrates C-Mixup with\nmulti-round robust training methods for a synergistic effect. In particular,\nC-Mixup improves robust training in identifying clean data, while robust\ntraining provides cleaner data to C-Mixup for it to perform better. A key\nadvantage of RC-Mixup is that it is data-centric where the robust model\ntraining algorithm itself does not need to be modified, but can simply benefit\nfrom data mixing. We show in our experiments that RC-Mixup significantly\noutperforms C-Mixup and robust training baselines on noisy data benchmarks and\ncan be integrated with various robust training methods.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Seong-Hyeon Hwang",
            "Minsu Kim",
            "Steven Euijong Whang"
        ],
        "published": "2024-05-28T08:02:42Z"
    },
    {
        "title": "Tool Learning with Large Language Models: A Survey",
        "link": "http://arxiv.org/abs/2405.17935v2",
        "abstract": "Recently, tool learning with large language models (LLMs) has emerged as a\npromising paradigm for augmenting the capabilities of LLMs to tackle highly\ncomplex problems. Despite growing attention and rapid advancements in this\nfield, the existing literature remains fragmented and lacks systematic\norganization, posing barriers to entry for newcomers. This gap motivates us to\nconduct a comprehensive survey of existing works on tool learning with LLMs. In\nthis survey, we focus on reviewing existing literature from the two primary\naspects (1) why tool learning is beneficial and (2) how tool learning is\nimplemented, enabling a comprehensive understanding of tool learning with LLMs.\nWe first explore the \"why\" by reviewing both the benefits of tool integration\nand the inherent benefits of the tool learning paradigm from six specific\naspects. In terms of \"how\", we systematically review the literature according\nto a taxonomy of four key stages in the tool learning workflow: task planning,\ntool selection, tool calling, and response generation. Additionally, we provide\na detailed summary of existing benchmarks and evaluation methods, categorizing\nthem according to their relevance to different stages. Finally, we discuss\ncurrent challenges and outline potential future directions, aiming to inspire\nboth researchers and industrial developers to further explore this emerging and\npromising area. We also maintain a GitHub repository to continually keep track\nof the relevant papers and resources in this rising area at\n\\url{https://github.com/quchangle1/LLM-Tool-Survey}.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Changle Qu",
            "Sunhao Dai",
            "Xiaochi Wei",
            "Hengyi Cai",
            "Shuaiqiang Wang",
            "Dawei Yin",
            "Jun Xu",
            "Ji-Rong Wen"
        ],
        "published": "2024-05-28T08:01:26Z"
    },
    {
        "title": "Proof of Quality: A Costless Paradigm for Trustless Generative AI Model\n  Inference on Blockchains",
        "link": "http://arxiv.org/abs/2405.17934v2",
        "abstract": "Generative AI models, such as GPT-4 and Stable Diffusion, have demonstrated\npowerful and disruptive capabilities in natural language and image tasks.\nHowever, deploying these models in decentralized environments remains\nchallenging. Unlike traditional centralized deployment, systematically\nguaranteeing the integrity of AI model services in fully decentralized\nenvironments, particularly on trustless blockchains, is both crucial and\ndifficult. In this paper, we present a new inference paradigm called\n\\emph{proof of quality} (PoQ) to enable the deployment of arbitrarily large\ngenerative models on blockchain architecture. Unlike traditional approaches\nbased on validating inference procedures, such as ZKML or OPML, our PoQ\nparadigm focuses on the outcome quality of model inference. Using lightweight\nBERT-based cross-encoders as our underlying quality evaluation model, we design\nand implement PQML, the first practical protocol for real-world NLP generative\nmodel inference on blockchains, tailored for popular open-source models such as\nLlama 3 and Mixtral. Our analysis demonstrates that our protocol is robust\nagainst adversarial but rational participants in ecosystems, where lazy or\ndishonest behavior results in fewer benefits compared to well-behaving\nparticipants. The computational overhead of validating the quality evaluation\nis minimal, allowing quality validators to complete the quality check within a\nsecond, even using only a CPU. Preliminary simulation results show that PoQ\nconsensus is generated in milliseconds, 1,000 times faster than any existing\nscheme.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Zhenjie Zhang",
            "Yuyang Rao",
            "Hao Xiao",
            "Xiaokui Xiao",
            "Yin Yang"
        ],
        "published": "2024-05-28T08:00:54Z"
    },
    {
        "title": "ToonCrafter: Generative Cartoon Interpolation",
        "link": "http://arxiv.org/abs/2405.17933v1",
        "abstract": "We introduce ToonCrafter, a novel approach that transcends traditional\ncorrespondence-based cartoon video interpolation, paving the way for generative\ninterpolation. Traditional methods, that implicitly assume linear motion and\nthe absence of complicated phenomena like dis-occlusion, often struggle with\nthe exaggerated non-linear and large motions with occlusion commonly found in\ncartoons, resulting in implausible or even failed interpolation results. To\novercome these limitations, we explore the potential of adapting live-action\nvideo priors to better suit cartoon interpolation within a generative\nframework. ToonCrafter effectively addresses the challenges faced when applying\nlive-action video motion priors to generative cartoon interpolation. First, we\ndesign a toon rectification learning strategy that seamlessly adapts\nlive-action video priors to the cartoon domain, resolving the domain gap and\ncontent leakage issues. Next, we introduce a dual-reference-based 3D decoder to\ncompensate for lost details due to the highly compressed latent prior spaces,\nensuring the preservation of fine details in interpolation results. Finally, we\ndesign a flexible sketch encoder that empowers users with interactive control\nover the interpolation results. Experimental results demonstrate that our\nproposed method not only produces visually convincing and more natural\ndynamics, but also effectively handles dis-occlusion. The comparative\nevaluation demonstrates the notable superiority of our approach over existing\ncompetitors.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jinbo Xing",
            "Hanyuan Liu",
            "Menghan Xia",
            "Yong Zhang",
            "Xintao Wang",
            "Ying Shan",
            "Tien-Tsin Wong"
        ],
        "published": "2024-05-28T07:58:33Z"
    },
    {
        "title": "Towards Communication-efficient Federated Learning via Sparse and\n  Aligned Adaptive Optimization",
        "link": "http://arxiv.org/abs/2405.17932v1",
        "abstract": "Adaptive moment estimation (Adam), as a Stochastic Gradient Descent (SGD)\nvariant, has gained widespread popularity in federated learning (FL) due to its\nfast convergence. However, federated Adam (FedAdam) algorithms suffer from a\nthreefold increase in uplink communication overhead compared to federated SGD\n(FedSGD) algorithms, which arises from the necessity to transmit both local\nmodel updates and first and second moment estimates from distributed devices to\nthe centralized server for aggregation. Driven by this issue, we propose a\nnovel sparse FedAdam algorithm called FedAdam-SSM, wherein distributed devices\nsparsify the updates of local model parameters and moment estimates and\nsubsequently upload the sparse representations to the centralized server. To\nfurther reduce the communication overhead, the updates of local model\nparameters and moment estimates incorporate a shared sparse mask (SSM) into the\nsparsification process, eliminating the need for three separate sparse masks.\nTheoretically, we develop an upper bound on the divergence between the local\nmodel trained by FedAdam-SSM and the desired model trained by centralized Adam,\nwhich is related to sparsification error and imbalanced data distribution. By\nminimizing the divergence bound between the model trained by FedAdam-SSM and\ncentralized Adam, we optimize the SSM to mitigate the learning performance\ndegradation caused by sparsification error. Additionally, we provide\nconvergence bounds for FedAdam-SSM in both convex and non-convex objective\nfunction settings, and investigate the impact of local epoch, learning rate and\nsparsification ratio on the convergence rate of FedAdam-SSM. Experimental\nresults show that FedAdam-SSM outperforms baselines in terms of convergence\nrate (over 1.1$\\times$ faster than the sparse FedAdam baselines) and test\naccuracy (over 14.5\\% ahead of the quantized FedAdam baselines).",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "authors": [
            "Xiumei Deng",
            "Jun Li",
            "Kang Wei",
            "Long Shi",
            "Zeihui Xiong",
            "Ming Ding",
            "Wen Chen",
            "Shi Jin",
            "H. Vincent Poor"
        ],
        "published": "2024-05-28T07:56:49Z"
    },
    {
        "title": "Online Merging Optimizers for Boosting Rewards and Mitigating Tax in\n  Alignment",
        "link": "http://arxiv.org/abs/2405.17931v1",
        "abstract": "Effectively aligning Large Language Models (LLMs) with human-centric values\nwhile preventing the degradation of abilities acquired through Pre-training and\nSupervised Fine-tuning (SFT) poses a central challenge in Reinforcement\nLearning from Human Feedback (RLHF). In this paper, we first discover that\ninterpolating RLHF and SFT model parameters can adjust the trade-off between\nhuman preference and basic capabilities, thereby reducing the alignment tax at\nthe cost of alignment reward. Inspired by this, we propose integrating the RL\npolicy and SFT models at each optimization step in RLHF to continuously\nregulate the training direction, introducing the Online Merging Optimizer.\nSpecifically, we merge gradients with the parameter differences between SFT and\npretrained models, effectively steering the gradient towards maximizing rewards\nin the direction of SFT optimization. We demonstrate that our optimizer works\nwell with different LLM families, such as Qwen and LLaMA, across various model\nsizes ranging from 1.8B to 8B, various RLHF algorithms like DPO and KTO, and\nexisting model merging methods. It significantly enhances alignment reward\nwhile mitigating alignment tax, achieving higher overall performance across 14\nbenchmarks.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Keming Lu",
            "Bowen Yu",
            "Fei Huang",
            "Yang Fan",
            "Runji Lin",
            "Chang Zhou"
        ],
        "published": "2024-05-28T07:53:40Z"
    },
    {
        "title": "Towards Unified Robustness Against Both Backdoor and Adversarial Attacks",
        "link": "http://arxiv.org/abs/2405.17929v1",
        "abstract": "Deep Neural Networks (DNNs) are known to be vulnerable to both backdoor and\nadversarial attacks. In the literature, these two types of attacks are commonly\ntreated as distinct robustness problems and solved separately, since they\nbelong to training-time and inference-time attacks respectively. However, this\npaper revealed that there is an intriguing connection between them: (1)\nplanting a backdoor into a model will significantly affect the model's\nadversarial examples; (2) for an infected model, its adversarial examples have\nsimilar features as the triggered images. Based on these observations, a novel\nProgressive Unified Defense (PUD) algorithm is proposed to defend against\nbackdoor and adversarial attacks simultaneously. Specifically, our PUD has a\nprogressive model purification scheme to jointly erase backdoors and enhance\nthe model's adversarial robustness. At the early stage, the adversarial\nexamples of infected models are utilized to erase backdoors. With the backdoor\ngradually erased, our model purification can naturally turn into a stage to\nboost the model's robustness against adversarial attacks. Besides, our PUD\nalgorithm can effectively identify poisoned images, which allows the initial\nextra dataset not to be completely clean. Extensive experimental results show\nthat, our discovered connection between backdoor and adversarial attacks is\nubiquitous, no matter what type of backdoor attack. The proposed PUD\noutperforms the state-of-the-art backdoor defense, including the model\nrepairing-based and data filtering-based methods. Besides, it also has the\nability to compete with the most advanced adversarial defense methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhenxing Niu",
            "Yuyao Sun",
            "Qiguang Miao",
            "Rong Jin",
            "Gang Hua"
        ],
        "published": "2024-05-28T07:50:00Z"
    },
    {
        "title": "Relational Self-supervised Distillation with Compact Descriptors for\n  Image Copy Detection",
        "link": "http://arxiv.org/abs/2405.17928v2",
        "abstract": "This paper addresses image copy detection, a task in online sharing platforms\nfor copyright protection. While previous approaches have performed\nexceptionally well, the large size of their networks and descriptors remains a\nsignificant disadvantage, complicating their practical application. In this\npaper, we propose a novel method that achieves a competitive performance by\nusing a lightweight network and compact descriptors. By utilizing relational\nself-supervised distillation to transfer knowledge from a large network to a\nsmall network, we enable the training of lightweight networks with a small\ndescriptor size. Our approach, which we call Relational selfsupervised\nDistillation with Compact Descriptors (RDCD), introduces relational\nself-supervised distillation (RSD) for flexible representation in a smaller\nfeature space and applies contrastive learning with a hard negative (HN) loss\nto prevent dimensional collapse. We demonstrate the effectiveness of our method\nusing the DISC2021, Copydays, and NDEC benchmark datasets, with which our\nlightweight network with compact descriptors achieves a competitive\nperformance. For the DISC2021 benchmark, ResNet-50/EfficientNet- B0 are used as\na teacher and student respectively, the micro average precision improved by\n5.0%/4.9%/5.9% for 64/128/256 descriptor sizes compared to the baseline method.",
        "subjects": [
            "cs.CV",
            "I.4.0; I.4.10"
        ],
        "authors": [
            "Juntae Kim",
            "Sungwon Woo",
            "Jongho Nang"
        ],
        "published": "2024-05-28T07:49:52Z"
    },
    {
        "title": "The Evolution of Multimodal Model Architectures",
        "link": "http://arxiv.org/abs/2405.17927v1",
        "abstract": "This work uniquely identifies and characterizes four prevalent multimodal\nmodel architectural patterns in the contemporary multimodal landscape.\nSystematically categorizing models by architecture type facilitates monitoring\nof developments in the multimodal domain. Distinct from recent survey papers\nthat present general information on multimodal architectures, this research\nconducts a comprehensive exploration of architectural details and identifies\nfour specific architectural types. The types are distinguished by their\nrespective methodologies for integrating multimodal inputs into the deep neural\nnetwork model. The first two types (Type A and B) deeply fuses multimodal\ninputs within the internal layers of the model, whereas the following two types\n(Type C and D) facilitate early fusion at the input stage. Type-A employs\nstandard cross-attention, whereas Type-B utilizes custom-designed layers for\nmodality fusion within the internal layers. On the other hand, Type-C utilizes\nmodality-specific encoders, while Type-D leverages tokenizers to process the\nmodalities at the model's input stage. The identified architecture types aid\nthe monitoring of any-to-any multimodal model development. Notably, Type-C and\nType-D are currently favored in the construction of any-to-any multimodal\nmodels. Type-C, distinguished by its non-tokenizing multimodal model\narchitecture, is emerging as a viable alternative to Type-D, which utilizes\ninput-tokenizing techniques. To assist in model selection, this work highlights\nthe advantages and disadvantages of each architecture type based on data and\ncompute requirements, architecture complexity, scalability, simplification of\nadding modalities, training objectives, and any-to-any multimodal generation\ncapability.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "cs.LG",
            "eess.AS"
        ],
        "authors": [
            "Shakti N. Wadekar",
            "Abhishek Chaurasia",
            "Aman Chadha",
            "Eugenio Culurciello"
        ],
        "published": "2024-05-28T07:48:15Z"
    },
    {
        "title": "SarcNet: A Novel AI-based Framework to Automatically Analyze and Score\n  Sarcomere Organizations in Fluorescently Tagged hiPSC-CMs",
        "link": "http://arxiv.org/abs/2405.17926v1",
        "abstract": "Quantifying sarcomere structure organization in human-induced pluripotent\nstem cell-derived cardiomyocytes (hiPSC-CMs) is crucial for understanding\ncardiac disease pathology, improving drug screening, and advancing regenerative\nmedicine. Traditional methods, such as manual annotation and Fourier transform\nanalysis, are labor-intensive, error-prone, and lack high-throughput\ncapabilities. In this study, we present a novel deep learning-based framework\nthat leverages cell images and integrates cell features to automatically\nevaluate the sarcomere structure of hiPSC-CMs from the onset of\ndifferentiation. This framework overcomes the limitations of traditional\nmethods through automated, high-throughput analysis, providing consistent,\nreliable results while accurately detecting complex sarcomere patterns across\ndiverse samples. The proposed framework contains the SarcNet, a linear\nlayers-added ResNet-18 module, to output a continuous score ranging from one to\nfive that captures the level of sarcomere structure organization. It is trained\nand validated on an open-source dataset of hiPSC-CMs images with the\nendogenously GFP-tagged alpha-actinin-2 structure developed by the Allen\nInstitute for Cell Science (AICS). SarcNet achieves a Spearman correlation of\n0.831 with expert evaluations, demonstrating superior performance and an\nimprovement of 0.075 over the current state-of-the-art approach, which uses\nLinear Regression. Our results also show a consistent pattern of increasing\norganization from day 18 to day 32 of differentiation, aligning with expert\nevaluations. By integrating the quantitative features calculated directly from\nthe images with the visual features learned during the deep learning model, our\nframework offers a more comprehensive and accurate assessment, thereby\nenhancing the further utility of hiPSC-CMs in medical research and therapy\ndevelopment.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Huyen Le",
            "Khiet Dang",
            "Tien Lai",
            "Nhung Nguyen",
            "Mai Tran",
            "Hieu Pham"
        ],
        "published": "2024-05-28T07:48:10Z"
    },
    {
        "title": "A real/fast-time simulator for impact assessment of spoofing & jamming\n  attacks on GNSS receivers",
        "link": "http://arxiv.org/abs/2405.17925v1",
        "abstract": "In aviation, the impact of threats is becoming increasingly significant,\nparticularly for global navigation satellite system (GNSS). Two relevant GNSS\nthreats are represented by jamming and spoofing. In order to evaluate the\ntechnological solutions to counter GNSS attacks, such attacks should be\nassessed by means of a proper GNSS threat simulator. This work shows the\nimplementation and the testing results of a GNSS security impact simulator\nwhich injects the desired threat scenarios as a deviations on the GNSS actual\nmeasurements. The proposed simulator can be integrated in both real- and\nfast-time simulation environments. The provided results confirm the\neffectiveness of the simulator, and include in-flight demonstrations by means\nof a flight experimental vehicle.",
        "subjects": [
            "eess.SP",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Ivan Iudice",
            "Domenico Pascarella",
            "Gianluca Corraro",
            "Giovanni Cuciniello"
        ],
        "published": "2024-05-28T07:47:28Z"
    },
    {
        "title": "Generative AI Enhances Team Performance and Reduces Need for Traditional\n  Teams",
        "link": "http://arxiv.org/abs/2405.17924v1",
        "abstract": "Recent advancements in generative artificial intelligence (AI) have\ntransformed collaborative work processes, yet the impact on team performance\nremains underexplored. Here we examine the role of generative AI in enhancing\nor replacing traditional team dynamics using a randomized controlled experiment\nwith 435 participants across 122 teams. We show that teams augmented with\ngenerative AI significantly outperformed those relying solely on human\ncollaboration across various performance measures. Interestingly, teams with\nmultiple AIs did not exhibit further gains, indicating diminishing returns with\nincreased AI integration. Our analysis suggests that centralized AI usage by a\nfew team members is more effective than distributed engagement. Additionally,\nindividual-AI pairs matched the performance of conventional teams, suggesting a\nreduced need for traditional team structures in some contexts. However, despite\nthis capability, individual-AI pairs still fell short of the performance levels\nachieved by AI-assisted teams. These findings underscore that while generative\nAI can replace some traditional team functions, more comprehensively\nintegrating AI within team structures provides superior benefits, enhancing\noverall effectiveness beyond individual efforts.",
        "subjects": [
            "cs.HC",
            "cs.AI",
            "econ.GN",
            "q-fin.EC"
        ],
        "authors": [
            "Ning Li",
            "Huaikang Zhou",
            "Kris Mikel-Hong"
        ],
        "published": "2024-05-28T07:47:03Z"
    },
    {
        "title": "Towards Clinical AI Fairness: Filling Gaps in the Puzzle",
        "link": "http://arxiv.org/abs/2405.17921v1",
        "abstract": "The ethical integration of Artificial Intelligence (AI) in healthcare\nnecessitates addressing fairness-a concept that is highly context-specific\nacross medical fields. Extensive studies have been conducted to expand the\ntechnical components of AI fairness, while tremendous calls for AI fairness\nhave been raised from healthcare. Despite this, a significant disconnect\npersists between technical advancements and their practical clinical\napplications, resulting in a lack of contextualized discussion of AI fairness\nin clinical settings. Through a detailed evidence gap analysis, our review\nsystematically pinpoints several deficiencies concerning both healthcare data\nand the provided AI fairness solutions. We highlight the scarcity of research\non AI fairness in many medical domains where AI technology is increasingly\nutilized. Additionally, our analysis highlights a substantial reliance on group\nfairness, aiming to ensure equality among demographic groups from a macro\nhealthcare system perspective; in contrast, individual fairness, focusing on\nequity at a more granular level, is frequently overlooked. To bridge these\ngaps, our review advances actionable strategies for both the healthcare and AI\nresearch communities. Beyond applying existing AI fairness methods in\nhealthcare, we further emphasize the importance of involving healthcare\nprofessionals to refine AI fairness concepts and methods to ensure contextually\nrelevant and ethically sound AI applications in healthcare.",
        "subjects": [
            "cs.AI",
            "cs.CY"
        ],
        "authors": [
            "Mingxuan Liu",
            "Yilin Ning",
            "Salinelat Teixayavong",
            "Xiaoxuan Liu",
            "Mayli Mertens",
            "Yuqing Shang",
            "Xin Li",
            "Di Miao",
            "Jie Xu",
            "Daniel Shu Wei Ting",
            "Lionel Tim-Ee Cheng",
            "Jasmine Chiat Ling Ong",
            "Zhen Ling Teo",
            "Ting Fang Tan",
            "Narrendar RaviChandran",
            "Fei Wang",
            "Leo Anthony Celi",
            "Marcus Eng Hock Ong",
            "Nan Liu"
        ],
        "published": "2024-05-28T07:42:55Z"
    },
    {
        "title": "Banana Trees for the Persistence in Time Series Experimentally",
        "link": "http://arxiv.org/abs/2405.17920v1",
        "abstract": "In numerous fields, dynamic time series data require continuous updates,\nnecessitating efficient data processing techniques for accurate analysis. This\npaper examines the banana tree data structure, specifically designed to\nefficiently maintain persistent homology -- a multi-scale topological\ndescriptor -- for dynamically changing time series data. We implement this data\nstructure and conduct an experimental study to assess its properties and\nruntime for update operations. Our findings indicate that banana trees are\nhighly effective with unbiased random data, outperforming state-of-the-art\nstatic algorithms in these scenarios. Additionally, our results show that\nreal-world time series share structural properties with unbiased random walks,\nsuggesting potential practical utility for our implementation.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Lara Ost",
            "Sebastiano Cultrera di Montesano",
            "Herbert Edelsbrunner"
        ],
        "published": "2024-05-28T07:42:52Z"
    },
    {
        "title": "Cost-Sensitive Multi-Fidelity Bayesian Optimization with Transfer of\n  Learning Curve Extrapolation",
        "link": "http://arxiv.org/abs/2405.17918v1",
        "abstract": "In this paper, we address the problem of cost-sensitive multi-fidelity\nBayesian Optimization (BO) for efficient hyperparameter optimization (HPO).\nSpecifically, we assume a scenario where users want to early-stop the BO when\nthe performance improvement is not satisfactory with respect to the required\ncomputational cost. Motivated by this scenario, we introduce utility, which is\na function predefined by each user and describes the trade-off between cost and\nperformance of BO. This utility function, combined with our novel acquisition\nfunction and stopping criterion, allows us to dynamically choose for each BO\nstep the best configuration that we expect to maximally improve the utility in\nfuture, and also automatically stop the BO around the maximum utility. Further,\nwe improve the sample efficiency of existing learning curve (LC) extrapolation\nmethods with transfer learning, while successfully capturing the correlations\nbetween different configurations to develop a sensible surrogate function for\nmulti-fidelity BO. We validate our algorithm on various LC datasets and found\nit outperform all the previous multi-fidelity BO and transfer-BO baselines we\nconsider, achieving significantly better trade-off between cost and performance\nof BO.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Dong Bok Lee",
            "Aoxuan Silvia Zhang",
            "Byungjoo Kim",
            "Junhyeon Park",
            "Juho Lee",
            "Sung Ju Hwang",
            "Hae Beom Lee"
        ],
        "published": "2024-05-28T07:38:39Z"
    },
    {
        "title": "Cascaded Group Testing",
        "link": "http://arxiv.org/abs/2405.17917v1",
        "abstract": "In this paper, we introduce a variation of the group testing problem where\neach test is specified by an ordered subset of items, and returns the first\ndefective item in the specified order. We refer to this as \\textit{cascaded\ngroup testing} and the goal is to identify a small set of $K$ defective items\namongst a collection of size $N$, using as few tests as possible. For the\nadaptive testing regime, we show that a simple scheme is able to find all\ndefective items in at most $K$ tests, which is optimal. For the non-adaptive\nsetting, we first come up with a necessary and sufficient condition for any\ncollection of tests to be feasible for recovering all the defectives. Using\nthis, we are able to show that any feasible non-adaptive strategy requires at\nleast $\\Omega(K^2)$ tests. In terms of achievability, it is easy to show that a\ncollection of $O(K^2 \\log (N/K))$ randomly constructed tests is feasible. We\nshow via carefully constructed explicit designs that one can do significantly\nbetter. We provide two simple schemes for $K = 1, 2$ which only require one and\ntwo tests respectively irrespective of the number of items $N$. Note that this\nis in contrast to standard binary group testing, where at least $\\Omega(\\log\nN)$ tests are required. The case of $K \\ge 3$ is more challenging and here we\ncome up with an iterative design which requires only $\\text{poly}(\\log \\log N)$\ntests.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Waqar Mirza",
            "Nikhil Karamchandani",
            "Niranjan Balachandran"
        ],
        "published": "2024-05-28T07:38:01Z"
    },
    {
        "title": "Boosting General Trimap-free Matting in the Real-World Image",
        "link": "http://arxiv.org/abs/2405.17916v1",
        "abstract": "Image matting aims to obtain an alpha matte that separates foreground objects\nfrom the background accurately. Recently, trimap-free matting has been well\nstudied because it requires only the original image without any extra input.\nSuch methods usually extract a rough foreground by itself to take place trimap\nas further guidance. However, the definition of 'foreground' lacks a unified\nstandard and thus ambiguities arise. Besides, the extracted foreground is\nsometimes incomplete due to inadequate network design. Most importantly, there\nis not a large-scale real-world matting dataset, and current trimap-free\nmethods trained with synthetic images suffer from large domain shift problems\nin practice. In this paper, we define the salient object as foreground, which\nis consistent with human cognition and annotations of the current matting\ndataset. Meanwhile, data and technologies in salient object detection can be\ntransferred to matting in a breeze. To obtain a more accurate and complete\nalpha matte, we propose a network called \\textbf{M}ulti-\\textbf{F}eature\nfusion-based \\textbf{C}oarse-to-fine Network \\textbf{(MFC-Net)}, which fully\nintegrates multiple features for an accurate and complete alpha matte.\nFurthermore, we introduce image harmony in data composition to bridge the gap\nbetween synthetic and real images. More importantly, we establish the largest\ngeneral matting dataset \\textbf{(Real-19k)} in the real world to date.\nExperiments show that our method is significantly effective on both synthetic\nand real-world images, and the performance in the real-world dataset is far\nbetter than existing matting-free methods. Our code and data will be released\nsoon.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Leo Shan Wenzhang Zhou Grace Zhao"
        ],
        "published": "2024-05-28T07:37:44Z"
    },
    {
        "title": "Long Context is Not Long at All: A Prospector of Long-Dependency Data\n  for Large Language Models",
        "link": "http://arxiv.org/abs/2405.17915v1",
        "abstract": "Long-context modeling capabilities are important for large language models\n(LLMs) in various applications. However, directly training LLMs with long\ncontext windows is insufficient to enhance this capability since some training\nsamples do not exhibit strong semantic dependencies across long contexts. In\nthis study, we propose a data mining framework \\textbf{ProLong} that can assign\neach training sample with a long dependency score, which can be used to rank\nand filter samples that are more advantageous for enhancing long-context\nmodeling abilities in LLM training. Specifically, we first use delta perplexity\nscores to measure the \\textit{Dependency Strength} between text segments in a\ngiven document. Then we refine this metric based on the \\textit{Dependency\nDistance} of these segments to incorporate spatial relationships across\nlong-contexts. Final results are calibrated with a \\textit{Dependency\nSpecificity} metric to prevent trivial dependencies introduced by repetitive\npatterns. Moreover, a random sampling approach is proposed to optimize the\ncomputational efficiency of ProLong. Comprehensive experiments on multiple\nbenchmarks indicate that ProLong effectively identifies documents that carry\nlong dependencies and LLMs trained on these documents exhibit significantly\nenhanced long-context modeling capabilities.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Longze Chen",
            "Ziqiang Liu",
            "Wanwei He",
            "Yunshui Li",
            "Run Luo",
            "Min Yang"
        ],
        "published": "2024-05-28T07:36:56Z"
    },
    {
        "title": "Trustworthy DNN Partition for Blockchain-enabled Digital Twin in\n  Wireless IIoT Networks",
        "link": "http://arxiv.org/abs/2405.17914v1",
        "abstract": "Digital twin (DT) has emerged as a promising solution to enhance\nmanufacturing efficiency in industrial Internet of Things (IIoT) networks. To\npromote the efficiency and trustworthiness of DT for wireless IIoT networks, we\npropose a blockchain-enabled DT (B-DT) framework that employs deep neural\nnetwork (DNN) partitioning technique and reputation-based consensus mechanism,\nwherein the DTs maintained at the gateway side execute DNN inference tasks\nusing the data collected from their associated IIoT devices. First, we employ\nDNN partitioning technique to offload the top-layer DNN inference tasks to the\naccess point (AP) side, which alleviates the computation burden at the gateway\nside and thereby improves the efficiency of DNN inference. Second, we propose a\nreputation-based consensus mechanism that integrates Proof of Work (PoW) and\nProof of Stake (PoS). Specifically, the proposed consensus mechanism evaluates\nthe off-chain reputation of each AP according to its computation resource\ncontributions to the DNN inference tasks, and utilizes the off-chain reputation\nas a stake to adjust the block generation difficulty. Third, we formulate a\nstochastic optimization problem of communication resource (i.e., partition\npoint) and computation resource allocation (i.e., computation frequency of APs\nfor top-layer DNN inference and block generation) to minimize system latency\nunder the time-varying channel state and long-term constraints of off-chain\nreputation, and solve the problem using Lyapunov optimization method.\nExperimental results show that the proposed dynamic DNN partitioning and\nresource allocation (DPRA) algorithm outperforms the baselines in terms of\nreducing the overall latency while guaranteeing the trustworthiness of the B-DT\nsystem.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Xiumei Deng",
            "Jun Li",
            "Long Shi",
            "Kang Wei",
            "Ming Ding",
            "Yumeng Shao",
            "Wen Chen",
            "Shi Jin"
        ],
        "published": "2024-05-28T07:34:12Z"
    },
    {
        "title": "OV-DQUO: Open-Vocabulary DETR with Denoising Text Query Training and\n  Open-World Unknown Objects Supervision",
        "link": "http://arxiv.org/abs/2405.17913v1",
        "abstract": "Open-Vocabulary Detection (OVD) aims to detect objects from novel categories\nbeyond the base categories on which the detector is trained. However, existing\nopen-vocabulary detectors trained on known category data tend to assign higher\nconfidence to trained categories and confuse novel categories with background.\nTo resolve this, we propose OV-DQUO, an \\textbf{O}pen-\\textbf{V}ocabulary DETR\nwith \\textbf{D}enoising text \\textbf{Q}uery training and open-world\n\\textbf{U}nknown \\textbf{O}bjects supervision. Specifically, we introduce a\nwildcard matching method that enables the detector to learn from pairs of\nunknown objects recognized by the open-world detector and text embeddings with\ngeneral semantics, mitigating the confidence bias between base and novel\ncategories. Additionally, we propose a denoising text query training strategy\nthat synthesizes additional noisy query-box pairs from open-world unknown\nobjects to trains the detector through contrastive learning, enhancing its\nability to distinguish novel objects from the background. We conducted\nextensive experiments on the challenging OV-COCO and OV-LVIS benchmarks,\nachieving new state-of-the-art results of 45.6 AP50 and 39.3 mAP on novel\ncategories respectively, without the need for additional training data. Models\nand code are released at https://github.com/xiaomoguhz/OV-DQUO",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Junjie Wang",
            "Bin Chen",
            "Bin Kang",
            "Yulin Li",
            "YiChi Chen",
            "Weizhi Xian",
            "Huifeng Chang"
        ],
        "published": "2024-05-28T07:33:27Z"
    },
    {
        "title": "Human-Cobot collaboration's impact on success, time completion, errors,\n  workload, gestures and acceptability during an assembly task",
        "link": "http://dx.doi.org/10.1016/j.apergo.2024.104306",
        "abstract": "The 5.0 industry promotes collaborative robots (cobots). This research\nstudies the impacts of cobot collaboration using an experimental setup. 120\nparticipants realized a simple and a complex assembly task. 50% collaborated\nwith another human (H/H) and 50% with a cobot (H/C). The workload and the\nacceptability of the cobotic collaboration were measured. Working with a cobot\ndecreases the effect of the task complexity on the human workload and on the\noutput quality. However, it increases the time completion and the number of\ngestures (while decreasing their frequency). The H/C couples have a higher\nchance of success but they take more time and more gestures to realize the\ntask. The results of this research could help developers and stakeholders to\nunderstand the impacts of implementing a cobot in production chains.",
        "subjects": [
            "cs.AI",
            "cs.HC",
            "cs.RO"
        ],
        "authors": [
            "Étienne Fournier",
            "Christine Jeoffrion",
            "Belal Hmedan",
            "Damien Pellier",
            "Humbert Fiorino",
            "Aurélie Landry"
        ],
        "published": "2024-05-28T07:30:28Z"
    },
    {
        "title": "Cycle-YOLO: A Efficient and Robust Framework for Pavement Damage\n  Detection",
        "link": "http://arxiv.org/abs/2405.17905v1",
        "abstract": "With the development of modern society, traffic volume continues to increase\nin most countries worldwide, leading to an increase in the rate of pavement\ndamage Therefore, the real-time and highly accurate pavement damage detection\nand maintenance have become the current need. In this paper, an enhanced\npavement damage detection method with CycleGAN and improved YOLOv5 algorithm is\npresented. We selected 7644 self-collected images of pavement damage samples as\nthe initial dataset and augmented it by CycleGAN. Due to a substantial\ndifference between the images generated by CycleGAN and real road images, we\nproposed a data enhancement method based on an improved Scharr filter,\nCycleGAN, and Laplacian pyramid. To improve the target recognition effect on a\ncomplex background and solve the problem that the spatial pyramid pooling-fast\nmodule in the YOLOv5 network cannot handle multiscale targets, we introduced\nthe convolutional block attention module attention mechanism and proposed the\natrous spatial pyramid pooling with squeeze-and-excitation structure. In\naddition, we optimized the loss function of YOLOv5 by replacing the CIoU with\nEIoU. The experimental results showed that our algorithm achieved a precision\nof 0.872, recall of 0.854, and mean average precision@0.5 of 0.882 in detecting\nthree main types of pavement damage: cracks, potholes, and patching. On the\nGPU, its frames per second reached 68, meeting the requirements for real-time\ndetection. Its overall performance even exceeded the current more advanced\nYOLOv7 and achieved good results in practical applications, providing a basis\nfor decision-making in pavement damage detection and prevention.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CY",
            "cs.LG"
        ],
        "authors": [
            "Zhengji Li",
            "Xi Xiao",
            "Jiacheng Xie",
            "Yuxiao Fan",
            "Wentao Wang",
            "Gang Chen",
            "Liqiang Zhang",
            "Tianyang Wang"
        ],
        "published": "2024-05-28T07:27:42Z"
    },
    {
        "title": "Reliable Object Tracking by Multimodal Hybrid Feature Extraction and\n  Transformer-Based Fusion",
        "link": "http://arxiv.org/abs/2405.17903v1",
        "abstract": "Visual object tracking, which is primarily based on visible light image\nsequences, encounters numerous challenges in complicated scenarios, such as low\nlight conditions, high dynamic ranges, and background clutter. To address these\nchallenges, incorporating the advantages of multiple visual modalities is a\npromising solution for achieving reliable object tracking. However, the\nexisting approaches usually integrate multimodal inputs through adaptive local\nfeature interactions, which cannot leverage the full potential of visual cues,\nthus resulting in insufficient feature modeling. In this study, we propose a\nnovel multimodal hybrid tracker (MMHT) that utilizes frame-event-based data for\nreliable single object tracking. The MMHT model employs a hybrid backbone\nconsisting of an artificial neural network (ANN) and a spiking neural network\n(SNN) to extract dominant features from different visual modalities and then\nuses a unified encoder to align the features across different domains.\nMoreover, we propose an enhanced transformer-based module to fuse multimodal\nfeatures using attention mechanisms. With these methods, the MMHT model can\neffectively construct a multiscale and multidimensional visual feature space\nand achieve discriminative feature modeling. Extensive experiments demonstrate\nthat the MMHT model exhibits competitive performance in comparison with that of\nother state-of-the-art methods. Overall, our results highlight the\neffectiveness of the MMHT model in terms of addressing the challenges faced in\nvisual object tracking tasks.",
        "subjects": [
            "cs.CV",
            "q-bio.NC"
        ],
        "authors": [
            "Hongze Sun",
            "Rui Liu",
            "Wuque Cai",
            "Jun Wang",
            "Yue Wang",
            "Huajin Tang",
            "Yan Cui",
            "Dezhong Yao",
            "Daqing Guo"
        ],
        "published": "2024-05-28T07:24:56Z"
    },
    {
        "title": "Boosting Protein Language Models with Negative Sample Mining",
        "link": "http://arxiv.org/abs/2405.17902v1",
        "abstract": "We introduce a pioneering methodology for boosting large language models in\nthe domain of protein representation learning. Our primary contribution lies in\nthe refinement process for correlating the over-reliance on co-evolution\nknowledge, in a way that networks are trained to distill invaluable insights\nfrom negative samples, constituted by protein pairs sourced from disparate\ncategories. By capitalizing on this novel approach, our technique steers the\ntraining of transformer-based models within the attention score space. This\nadvanced strategy not only amplifies performance but also reflects the nuanced\nbiological behaviors exhibited by proteins, offering aligned evidence with\ntraditional biological mechanisms such as protein-protein interaction. We\nexperimentally observed improved performance on various tasks over datasets, on\ntop of several well-established large protein models. This innovative paradigm\nopens up promising horizons for further progress in the realms of protein\nresearch and computational biology.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Yaoyao Xu",
            "Xinjian Zhao",
            "Xiaozhuang Song",
            "Benyou Wang",
            "Tianshu Yu"
        ],
        "published": "2024-05-28T07:24:20Z"
    },
    {
        "title": "Near-Infrared and Low-Rank Adaptation of Vision Transformers in Remote\n  Sensing",
        "link": "http://arxiv.org/abs/2405.17901v1",
        "abstract": "Plant health can be monitored dynamically using multispectral sensors that\nmeasure Near-Infrared reflectance (NIR). Despite this potential, obtaining and\nannotating high-resolution NIR images poses a significant challenge for\ntraining deep neural networks. Typically, large networks pre-trained on the RGB\ndomain are utilized to fine-tune infrared images. This practice introduces a\ndomain shift issue because of the differing visual traits between RGB and NIR\nimages.As an alternative to fine-tuning, a method called low-rank adaptation\n(LoRA) enables more efficient training by optimizing rank-decomposition\nmatrices while keeping the original network weights frozen. However, existing\nparameter-efficient adaptation strategies for remote sensing images focus on\nRGB images and overlook domain shift issues in the NIR domain. Therefore, this\nstudy investigates the potential benefits of using vision transformer (ViT)\nbackbones pre-trained in the RGB domain, with low-rank adaptation for\ndownstream tasks in the NIR domain. Extensive experiments demonstrate that\nemploying LoRA with pre-trained ViT backbones yields the best performance for\ndownstream tasks applied to NIR images.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Irem Ulku",
            "O. Ozgur Tanriover",
            "Erdem Akagündüz"
        ],
        "published": "2024-05-28T07:24:07Z"
    },
    {
        "title": "Enhancing Emotion Recognition in Conversation through Emotional\n  Cross-Modal Fusion and Inter-class Contrastive Learning",
        "link": "http://arxiv.org/abs/2405.17900v1",
        "abstract": "The purpose of emotion recognition in conversation (ERC) is to identify the\nemotion category of an utterance based on contextual information. Previous ERC\nmethods relied on simple connections for cross-modal fusion and ignored the\ninformation differences between modalities, resulting in the model being unable\nto focus on modality-specific emotional information. At the same time, the\nshared information between modalities was not processed to generate emotions.\nInformation redundancy problem. To overcome these limitations, we propose a\ncross-modal fusion emotion prediction network based on vector connections. The\nnetwork mainly includes two stages: the multi-modal feature fusion stage based\non connection vectors and the emotion classification stage based on fused\nfeatures. Furthermore, we design a supervised inter-class contrastive learning\nmodule based on emotion labels. Experimental results confirm the effectiveness\nof the proposed method, demonstrating excellent performance on the IEMOCAP and\nMELD datasets.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Haoxiang Shi",
            "Xulong Zhang",
            "Ning Cheng",
            "Yong Zhang",
            "Jun Yu",
            "Jing Xiao",
            "Jianzong Wang"
        ],
        "published": "2024-05-28T07:22:30Z"
    },
    {
        "title": "FlashST: A Simple and Universal Prompt-Tuning Framework for Traffic\n  Prediction",
        "link": "http://arxiv.org/abs/2405.17898v1",
        "abstract": "The objective of traffic prediction is to accurately forecast and analyze the\ndynamics of transportation patterns, considering both space and time. However,\nthe presence of distribution shift poses a significant challenge in this field,\nas existing models struggle to generalize well when faced with test data that\nsignificantly differs from the training distribution. To tackle this issue,\nthis paper introduces a simple and universal spatio-temporal prompt-tuning\nframework-FlashST, which adapts pre-trained models to the specific\ncharacteristics of diverse downstream datasets, improving generalization in\ndiverse traffic prediction scenarios. Specifically, the FlashST framework\nemploys a lightweight spatio-temporal prompt network for in-context learning,\ncapturing spatio-temporal invariant knowledge and facilitating effective\nadaptation to diverse scenarios. Additionally, we incorporate a distribution\nmapping mechanism to align the data distributions of pre-training and\ndownstream data, facilitating effective knowledge transfer in spatio-temporal\nforecasting. Empirical evaluations demonstrate the effectiveness of our FlashST\nacross different spatio-temporal prediction tasks using diverse urban datasets.\nCode is available at https://github.com/HKUDS/FlashST.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CY"
        ],
        "authors": [
            "Zhonghang Li",
            "Lianghao Xia",
            "Yong Xu",
            "Chao Huang"
        ],
        "published": "2024-05-28T07:18:52Z"
    },
    {
        "title": "$C^2M^3$: Cycle-Consistent Multi-Model Merging",
        "link": "http://arxiv.org/abs/2405.17897v1",
        "abstract": "In this paper, we present a novel data-free method for merging neural\nnetworks in weight space. Differently from most existing works, our method\noptimizes for the permutations of network neurons globally across all layers.\nThis allows us to enforce cycle consistency of the permutations when merging $N\n\\geq 3$ models, allowing circular compositions of permutations to be computed\nwithout accumulating error along the path. We qualitatively and quantitatively\nmotivate the need for such a constraint, showing its benefits when merging sets\nof models in scenarios spanning varying architectures and datasets. We finally\nshow that, when coupled with activation renormalization, our approach yields\nthe best results in the task.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Donato Crisostomi",
            "Marco Fumero",
            "Daniele Baieri",
            "Florian Bernard",
            "Emanuele Rodolà"
        ],
        "published": "2024-05-28T07:18:45Z"
    },
    {
        "title": "White-box Multimodal Jailbreaks Against Large Vision-Language Models",
        "link": "http://arxiv.org/abs/2405.17894v1",
        "abstract": "Recent advancements in Large Vision-Language Models (VLMs) have underscored\ntheir superiority in various multimodal tasks. However, the adversarial\nrobustness of VLMs has not been fully explored. Existing methods mainly assess\nrobustness through unimodal adversarial attacks that perturb images, while\nassuming inherent resilience against text-based attacks. Different from\nexisting attacks, in this work we propose a more comprehensive strategy that\njointly attacks both text and image modalities to exploit a broader spectrum of\nvulnerability within VLMs. Specifically, we propose a dual optimization\nobjective aimed at guiding the model to generate affirmative responses with\nhigh toxicity. Our attack method begins by optimizing an adversarial image\nprefix from random noise to generate diverse harmful responses in the absence\nof text input, thus imbuing the image with toxic semantics. Subsequently, an\nadversarial text suffix is integrated and co-optimized with the adversarial\nimage prefix to maximize the probability of eliciting affirmative responses to\nvarious harmful instructions. The discovered adversarial image prefix and text\nsuffix are collectively denoted as a Universal Master Key (UMK). When\nintegrated into various malicious queries, UMK can circumvent the alignment\ndefenses of VLMs and lead to the generation of objectionable content, known as\njailbreaks. The experimental results demonstrate that our universal attack\nstrategy can effectively jailbreak MiniGPT-4 with a 96% success rate,\nhighlighting the vulnerability of VLMs and the urgent need for new alignment\nstrategies.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Ruofan Wang",
            "Xingjun Ma",
            "Hanxu Zhou",
            "Chuanjun Ji",
            "Guangnan Ye",
            "Yu-Gang Jiang"
        ],
        "published": "2024-05-28T07:13:30Z"
    },
    {
        "title": "Arithmetic Reasoning with LLM: Prolog Generation & Permutation",
        "link": "http://arxiv.org/abs/2405.17893v1",
        "abstract": "Instructing large language models (LLMs) to solve elementary school math\nproblems has shown great success using Chain of Thought (CoT). However, the CoT\napproach relies on an LLM to generate a sequence of arithmetic calculations\nwhich can be prone to cascaded calculation errors. We hypothesize that an LLM\nshould focus on extracting predicates and generating symbolic formulas from the\nmath problem description so that the underlying calculation can be done via an\nexternal code interpreter. We investigate using LLM to generate Prolog programs\nto solve mathematical questions. Experimental results show that our\nProlog-based arithmetic problem-solving outperforms CoT generation in the GSM8K\nbenchmark across three distinct LLMs. In addition, given the insensitive\nordering of predicates and symbolic formulas in Prolog, we propose to permute\nthe ground truth predicates for more robust LLM training via data augmentation.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Xiaocheng Yang",
            "Bingsen Chen",
            "Yik-Cheung Tam"
        ],
        "published": "2024-05-28T07:13:25Z"
    },
    {
        "title": "A Refined 3D Gaussian Representation for High-Quality Dynamic Scene\n  Reconstruction",
        "link": "http://arxiv.org/abs/2405.17891v1",
        "abstract": "In recent years, Neural Radiance Fields (NeRF) has revolutionized\nthree-dimensional (3D) reconstruction with its implicit representation.\nBuilding upon NeRF, 3D Gaussian Splatting (3D-GS) has departed from the\nimplicit representation of neural networks and instead directly represents\nscenes as point clouds with Gaussian-shaped distributions. While this shift has\nnotably elevated the rendering quality and speed of radiance fields but\ninevitably led to a significant increase in memory usage. Additionally,\neffectively rendering dynamic scenes in 3D-GS has emerged as a pressing\nchallenge. To address these concerns, this paper purposes a refined 3D Gaussian\nrepresentation for high-quality dynamic scene reconstruction. Firstly, we use a\ndeformable multi-layer perceptron (MLP) network to capture the dynamic offset\nof Gaussian points and express the color features of points through hash\nencoding and a tiny MLP to reduce storage requirements. Subsequently, we\nintroduce a learnable denoising mask coupled with denoising loss to eliminate\nnoise points from the scene, thereby further compressing 3D Gaussian model.\nFinally, motion noise of points is mitigated through static constraints and\nmotion consistency constraints. Experimental results demonstrate that our\nmethod surpasses existing approaches in rendering quality and speed, while\nsignificantly reducing the memory usage associated with 3D-GS, making it highly\nsuitable for various tasks such as novel view synthesis, and dynamic mapping.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Bin Zhang",
            "Bi Zeng",
            "Zexin Peng"
        ],
        "published": "2024-05-28T07:12:22Z"
    },
    {
        "title": "SLMRec: Empowering Small Language Models for Sequential Recommendation",
        "link": "http://arxiv.org/abs/2405.17890v1",
        "abstract": "The sequential Recommendation (SR) task involves predicting the next item a\nuser is likely to interact with, given their past interactions. The SR models\nexamine the sequence of a user's actions to discern more complex behavioral\npatterns and temporal dynamics. Recent research demonstrates the great impact\nof LLMs on sequential recommendation systems, either viewing sequential\nrecommendation as language modeling or serving as the backbone for user\nrepresentation. Although these methods deliver outstanding performance, there\nis scant evidence of the necessity of a large language model and how large the\nlanguage model is needed, especially in the sequential recommendation scene.\nMeanwhile, due to the huge size of LLMs, it is inefficient and impractical to\napply a LLM-based model in real-world platforms that often need to process\nbillions of traffic logs daily. In this paper, we explore the influence of\nLLMs' depth by conducting extensive experiments on large-scale industry\ndatasets. Surprisingly, we discover that most intermediate layers of LLMs are\nredundant. Motivated by this insight, we empower small language models for SR,\nnamely SLMRec, which adopt a simple yet effective knowledge distillation\nmethod. Moreover, SLMRec is orthogonal to other post-training efficiency\ntechniques, such as quantization and pruning, so that they can be leveraged in\ncombination. Comprehensive experimental results illustrate that the proposed\nSLMRec model attains the best performance using only 13% of the parameters\nfound in LLM-based recommendation models, while simultaneously achieving up to\n6.6x and 8.0x speedups in training and inference time costs, respectively.",
        "subjects": [
            "cs.IR",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Wujiang Xu",
            "Zujie Liang",
            "Jiaojiao Han",
            "Xuying Ning",
            "Wenfang Lin",
            "Linxun Chen",
            "Feng Wei",
            "Yongfeng Zhang"
        ],
        "published": "2024-05-28T07:12:06Z"
    },
    {
        "title": "Improving Discrete Diffusion Models via Structured Preferential\n  Generation",
        "link": "http://arxiv.org/abs/2405.17889v1",
        "abstract": "In the domains of image and audio, diffusion models have shown impressive\nperformance. However, their application to discrete data types, such as\nlanguage, has often been suboptimal compared to autoregressive generative\nmodels. This paper tackles the challenge of improving discrete diffusion models\nby introducing a structured forward process that leverages the inherent\ninformation hierarchy in discrete categories, such as words in text. Our\napproach biases the generative process to produce certain categories before\nothers, resulting in a notable improvement in log-likelihood scores on the\ntext8 dataset. This work paves the way for more advances in discrete diffusion\nmodels with potentially significant enhancements in performance.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Severi Rissanen",
            "Markus Heinonen",
            "Arno Solin"
        ],
        "published": "2024-05-28T07:11:30Z"
    },
    {
        "title": "Getting More Juice Out of the SFT Data: Reward Learning from Human\n  Demonstration Improves SFT for LLM Alignment",
        "link": "http://arxiv.org/abs/2405.17888v2",
        "abstract": "Aligning human preference and value is an important requirement for\ncontemporary foundation models. State-of-the-art techniques such as\nReinforcement Learning from Human Feedback (RLHF) often consist of two stages:\n1) supervised fine-tuning (SFT), where the model is fine-tuned by learning from\nhuman demonstration data; 2) Preference learning, where preference data is used\nto learn a reward model, which is in turn used by a reinforcement learning (RL)\nstep to fine-tune the model. Such reward model serves as a proxy to human\npreference, and it is critical to guide the RL step towards improving the model\nquality. In this work, we argue that the SFT stage significantly benefits from\nlearning a reward model as well. Instead of using the human demonstration data\ndirectly via supervised learning, we propose to leverage an Inverse\nReinforcement Learning (IRL) technique to (explicitly or implicitly) build an\nreward model, while learning the policy model. This approach leads to new SFT\nalgorithms that are not only efficient to implement, but also promote the\nability to distinguish between the preferred and non-preferred continuations.\nMoreover, we identify a connection between the proposed IRL based approach, and\ncertain self-play approach proposed recently, and showed that self-play is a\nspecial case of modeling a reward-learning agent. Theoretically, we show that\nthe proposed algorithms converge to the stationary solutions of the IRL\nproblem. Empirically, we align 1B and 7B models using proposed methods and\nevaluate them on a reward benchmark model and the HuggingFace Open LLM\nLeaderboard. The proposed methods show significant performance improvement over\nexisting SFT approaches. Our results indicate that it is beneficial to\nexplicitly or implicitly leverage reward learning throughout the entire\nalignment process.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Jiaxiang Li",
            "Siliang Zeng",
            "Hoi-To Wai",
            "Chenliang Li",
            "Alfredo Garcia",
            "Mingyi Hong"
        ],
        "published": "2024-05-28T07:11:05Z"
    },
    {
        "title": "Graphomotor and Handwriting Disabilities Rating Scale (GHDRS):towards\n  complex and objective assessment",
        "link": "http://dx.doi.org/10.1080/19404158.2024.2326686",
        "abstract": "Graphomotor and handwriting disabilities (GD and HD, respectively) could\nsignificantly reduce children's quality of life. Effective remediation depends\non proper diagnosis; however, current approaches to diagnosis and assessment of\nGD and HD have several limitations and knowledge gaps, e.g. they are\nsubjective, they do not facilitate identification of specific manifestations,\netc. The aim of this work is to introduce a new scale (GHDRS Graphomotor and\nHandwriting Disabilities Rating Scale) that will enable experts to perform\nobjective and complex computeraided diagnosis and assessment of GD and HD. The\nscale supports quantification of 17 manifestations associated with the\nprocess/product of drawing/ handwriting. The whole methodology of GHDRS design\nis made maximally transparent so that it could be adapted for other languages.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jiri Mekyska",
            "Katarina Safarova",
            "Tomas Urbanek",
            "Jirina Bednarova",
            "Vojtech Zvoncak",
            "Jana Marie Havigerova",
            "Lukas Cunek",
            "Zoltan Galaz",
            "Jan Mucha",
            "Christine Klauszova",
            "Marcos Faundez-Zanuy",
            "Miguel A. Ferrer",
            "Moises Diaz"
        ],
        "published": "2024-05-28T07:09:42Z"
    },
    {
        "title": "When is exponential asymptotic optimality achievable in average-reward\n  restless bandits?",
        "link": "http://arxiv.org/abs/2405.17882v1",
        "abstract": "We consider the discrete-time infinite-horizon average-reward restless bandit\nproblem. We propose a novel policy that maintains two dynamic subsets of arms:\none subset of arms has a nearly optimal state distribution and takes actions\naccording to an Optimal Local Control routine; the other subset of arms is\ndriven towards the optimal state distribution and gradually merged into the\nfirst subset. We show that our policy is asymptotically optimal with an\n$O(\\exp(-C N))$ optimality gap for an $N$-armed problem, under the mild\nassumptions of aperiodic-unichain, non-degeneracy, and local stability. Our\npolicy is the first to achieve exponential asymptotic optimality under the\nabove set of easy-to-verify assumptions, whereas prior work either requires a\nstrong Global Attractor assumption or only achieves an $O(1/\\sqrt{N})$\noptimality gap. We further discuss the fundamental obstacles in significantly\nweakening our assumptions. In particular, we prove a lower bound showing that\nlocal stability is fundamental for exponential asymptotic optimality.",
        "subjects": [
            "cs.LG",
            "math.OC",
            "math.PR",
            "90C40",
            "G.3; I.6"
        ],
        "authors": [
            "Yige Hong",
            "Qiaomin Xie",
            "Yudong Chen",
            "Weina Wang"
        ],
        "published": "2024-05-28T07:08:29Z"
    },
    {
        "title": "Crystal-LSBO: Automated Design of De Novo Crystals with Latent Space\n  Bayesian Optimization",
        "link": "http://arxiv.org/abs/2405.17881v1",
        "abstract": "Generative modeling of crystal structures is significantly challenged by the\ncomplexity of input data, which constrains the ability of these models to\nexplore and discover novel crystals. This complexity often confines de novo\ndesign methodologies to merely small perturbations of known crystals and\nhampers the effective application of advanced optimization techniques. One such\noptimization technique, Latent Space Bayesian Optimization (LSBO) has\ndemonstrated promising results in uncovering novel objects across various\ndomains, especially when combined with Variational Autoencoders (VAEs).\nRecognizing LSBO's potential and the critical need for innovative crystal\ndiscovery, we introduce Crystal-LSBO, a de novo design framework for crystals\nspecifically tailored to enhance explorability within LSBO frameworks.\nCrystal-LSBO employs multiple VAEs, each dedicated to a distinct aspect of\ncrystal structure: lattice, coordinates, and chemical elements, orchestrated by\nan integrative model that synthesizes these components into a cohesive output.\nThis setup not only streamlines the learning process but also produces\nexplorable latent spaces thanks to the decreased complexity of the learning\ntask for each model, enabling LSBO approaches to operate. Our study pioneers\nthe use of LSBO for de novo crystal design, demonstrating its efficacy through\noptimization tasks focused mainly on formation energy values. Our results\nhighlight the effectiveness of our methodology, offering a new perspective for\nde novo crystal discovery.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Onur Boyar",
            "Yanheng Gu",
            "Yuji Tanaka",
            "Shunsuke Tonogai",
            "Tomoya Itakura",
            "Ichiro Takeuchi"
        ],
        "published": "2024-05-28T07:03:49Z"
    },
    {
        "title": "Diffusion Rejection Sampling",
        "link": "http://arxiv.org/abs/2405.17880v1",
        "abstract": "Recent advances in powerful pre-trained diffusion models encourage the\ndevelopment of methods to improve the sampling performance under well-trained\ndiffusion models. This paper introduces Diffusion Rejection Sampling (DiffRS),\nwhich uses a rejection sampling scheme that aligns the sampling transition\nkernels with the true ones at each timestep. The proposed method can be viewed\nas a mechanism that evaluates the quality of samples at each intermediate\ntimestep and refines them with varying effort depending on the sample.\nTheoretical analysis shows that DiffRS can achieve a tighter bound on sampling\nerror compared to pre-trained models. Empirical results demonstrate the\nstate-of-the-art performance of DiffRS on the benchmark datasets and the\neffectiveness of DiffRS for fast diffusion samplers and large-scale\ntext-to-image diffusion models. Our code is available at\nhttps://github.com/aailabkaist/DiffRS.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Byeonghu Na",
            "Yeongmin Kim",
            "Minsang Park",
            "Donghyeok Shin",
            "Wanmo Kang",
            "Il-Chul Moon"
        ],
        "published": "2024-05-28T07:00:28Z"
    },
    {
        "title": "Resisting Stochastic Risks in Diffusion Planners with the Trajectory\n  Aggregation Tree",
        "link": "http://arxiv.org/abs/2405.17879v1",
        "abstract": "Diffusion planners have shown promise in handling long-horizon and\nsparse-reward tasks due to the non-autoregressive plan generation. However,\ntheir inherent stochastic risk of generating infeasible trajectories presents\nsignificant challenges to their reliability and stability. We introduce a novel\napproach, the Trajectory Aggregation Tree (TAT), to address this issue in\ndiffusion planners. Compared to prior methods that rely solely on raw\ntrajectory predictions, TAT aggregates information from both historical and\ncurrent trajectories, forming a dynamic tree-like structure. Each trajectory is\nconceptualized as a branch and individual states as nodes. As the structure\nevolves with the integration of new trajectories, unreliable states are\nmarginalized, and the most impactful nodes are prioritized for decision-making.\nTAT can be deployed without modifying the original training and sampling\npipelines of diffusion planners, making it a training-free, ready-to-deploy\nsolution. We provide both theoretical analysis and empirical evidence to\nsupport TAT's effectiveness. Our results highlight its remarkable ability to\nresist the risk from unreliable trajectories, guarantee the performance\nboosting of diffusion planners in $100\\%$ of tasks, and exhibit an appreciable\ntolerance margin for sample quality, thereby enabling planning with a more than\n$3\\times$ acceleration.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Lang Feng",
            "Pengjie Gu",
            "Bo An",
            "Gang Pan"
        ],
        "published": "2024-05-28T06:57:22Z"
    },
    {
        "title": "An Information Theoretic Metric for Evaluating Unlearning Models",
        "link": "http://arxiv.org/abs/2405.17878v1",
        "abstract": "Machine unlearning (MU) addresses privacy concerns by removing information of\n`forgetting data' samples from trained models. Typically, evaluating MU methods\ninvolves comparing unlearned models to those retrained from scratch without\nforgetting data, using metrics such as membership inference attacks (MIA) and\naccuracy measurements. These evaluations implicitly assume that if the output\nlogits of the unlearned and retrained models are similar, the unlearned model\nhas successfully forgotten the data. Here, we challenge if this assumption is\nvalid. In particular, we conduct a simple experiment of training only the last\nlayer of a given original model using a novel masked-distillation technique\nwhile keeping the rest fixed. Surprisingly, simply altering the last layer\nyields favorable outcomes in the existing evaluation metrics, while the model\ndoes not successfully unlearn the samples or classes. For better evaluating the\nMU methods, we propose a metric that quantifies the residual information about\nforgetting data samples in intermediate features using mutual information,\ncalled information difference index or IDI for short. The IDI provides a\ncomprehensive evaluation of MU methods by efficiently analyzing the internal\nstructure of DNNs. Our metric is scalable to large datasets and adaptable to\nvarious model architectures. Additionally, we present COLapse-and-Align (COLA),\na simple contrastive-based method that effectively unlearns intermediate\nfeatures.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Dongjae Jeon",
            "Wonje Jeung",
            "Taeheon Kim",
            "Albert No",
            "Jonghyun Choi"
        ],
        "published": "2024-05-28T06:57:01Z"
    },
    {
        "title": "Sparsity- and Hybridity-Inspired Visual Parameter-Efficient Fine-Tuning\n  for Medical Diagnosis",
        "link": "http://arxiv.org/abs/2405.17877v1",
        "abstract": "The success of Large Vision Models (LVMs) is accompanied by vast data\nvolumes, which are prohibitively expensive in medical diagnosis.To address\nthis, recent efforts exploit Parameter-Efficient Fine-Tuning (PEFT), which\ntrains a small number of weights while freezing the rest.However, they\ntypically assign trainable weights to the same positions in LVMs in a heuristic\nmanner, regardless of task differences, making them suboptimal for professional\napplications like medical diagnosis.To address this, we statistically reveal\nthe nature of sparsity and hybridity during diagnostic-targeted fine-tuning,\ni.e., a small portion of key weights significantly impacts performance, and\nthese key weights are hybrid, including both task-specific and task-agnostic\nparts.Based on this, we propose a novel Sparsity- and Hybridity-inspired\nParameter Efficient Fine-Tuning (SH-PEFT).It selects and trains a small portion\nof weights based on their importance, which is innovatively estimated by\nhybridizing both task-specific and task-agnostic strategies.Validated on six\nmedical datasets of different modalities, we demonstrate that SH-PEFT achieves\nstate-of-the-art performance in transferring LVMs to medical diagnosis in terms\nof accuracy. By tuning around 0.01% number of weights, it outperforms full\nmodel fine-tuning.Moreover, SH-PEFT also achieves comparable performance to\nother models deliberately optimized for specific medical tasks.Extensive\nexperiments demonstrate the effectiveness of each design and reveal that large\nmodel transfer holds great potential in medical diagnosis.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Mingyuan Liu",
            "Lu Xu",
            "Shengnan Liu",
            "Jicong Zhang"
        ],
        "published": "2024-05-28T06:56:39Z"
    },
    {
        "title": "Decentralized Directed Collaboration for Personalized Federated Learning",
        "link": "http://arxiv.org/abs/2405.17876v1",
        "abstract": "Personalized Federated Learning (PFL) is proposed to find the greatest\npersonalized models for each client. To avoid the central failure and\ncommunication bottleneck in the server-based FL, we concentrate on the\nDecentralized Personalized Federated Learning (DPFL) that performs distributed\nmodel training in a Peer-to-Peer (P2P) manner. Most personalized works in DPFL\nare based on undirected and symmetric topologies, however, the data,\ncomputation and communication resources heterogeneity result in large variances\nin the personalized models, which lead the undirected aggregation to suboptimal\npersonalized performance and unguaranteed convergence. To address these issues,\nwe propose a directed collaboration DPFL framework by incorporating stochastic\ngradient push and partial model personalized, called \\textbf{D}ecentralized\n\\textbf{Fed}erated \\textbf{P}artial \\textbf{G}radient \\textbf{P}ush\n(\\textbf{DFedPGP}). It personalizes the linear classifier in the modern deep\nmodel to customize the local solution and learns a consensus representation in\na fully decentralized manner. Clients only share gradients with a subset of\nneighbors based on the directed and asymmetric topologies, which guarantees\nflexible choices for resource efficiency and better convergence. Theoretically,\nwe show that the proposed DFedPGP achieves a superior convergence rate of\n$\\mathcal{O}(\\frac{1}{\\sqrt{T}})$ in the general non-convex setting, and prove\nthe tighter connectivity among clients will speed up the convergence. The\nproposed method achieves state-of-the-art (SOTA) accuracy in both data and\ncomputation heterogeneity scenarios, demonstrating the efficiency of the\ndirected collaboration and partial gradient push.",
        "subjects": [
            "cs.LG",
            "cs.DC",
            "math.OC"
        ],
        "authors": [
            "Yingqi Liu",
            "Yifan Shi",
            "Qinglun Li",
            "Baoyuan Wu",
            "Xueqian Wang",
            "Li Shen"
        ],
        "published": "2024-05-28T06:52:19Z"
    },
    {
        "title": "BO4IO: A Bayesian optimization approach to inverse optimization with\n  uncertainty quantification",
        "link": "http://arxiv.org/abs/2405.17875v1",
        "abstract": "This work addresses data-driven inverse optimization (IO), where the goal is\nto estimate unknown parameters in an optimization model from observed decisions\nthat can be assumed to be optimal or near-optimal solutions to the optimization\nproblem. The IO problem is commonly formulated as a large-scale bilevel program\nthat is notoriously difficult to solve. Deviating from traditional exact\nsolution methods, we propose a derivative-free optimization approach based on\nBayesian optimization, which we call BO4IO, to solve general IO problems. We\ntreat the IO loss function as a black box and approximate it with a Gaussian\nprocess model. Using the predicted posterior function, an acquisition function\nis minimized at each iteration to query new candidate solutions and\nsequentially converge to the optimal parameter estimates. The main advantages\nof using Bayesian optimization for IO are two-fold: (i) it circumvents the need\nof complex reformulations of the bilevel program or specialized algorithms and\ncan hence enable computational tractability even when the underlying\noptimization problem is nonconvex or involves discrete variables, and (ii) it\nallows approximations of the profile likelihood, which provide uncertainty\nquantification on the IO parameter estimates. We apply the proposed method to\nthree computational case studies, covering different classes of forward\noptimization problems ranging from convex nonlinear to nonconvex mixed-integer\nnonlinear programs. Our extensive computational results demonstrate the\nefficacy and robustness of BO4IO to accurately estimate unknown model\nparameters from small and noisy datasets. In addition, the proposed profile\nlikelihood analysis has proven to be effective in providing good approximations\nof the confidence intervals on the parameter estimates and assessing the\nidentifiability of the unknown parameters.",
        "subjects": [
            "math.OC",
            "cs.LG"
        ],
        "authors": [
            "Yen-An Lu",
            "Wei-Shou Hu",
            "Joel A. Paulson",
            "Qi Zhang"
        ],
        "published": "2024-05-28T06:52:17Z"
    },
    {
        "title": "NUTS, NARS, and Speech",
        "link": "http://dx.doi.org/10.1007/978-3-031-33469-6_31",
        "abstract": "To investigate whether \"Intelligence is the capacity of an\ninformation-processing system to adapt to its environment while operating with\ninsufficient knowledge and resources\", we look at utilising the non axiomatic\nreasoning system (NARS) for speech recognition. This article presents NUTS:\nraNdom dimensionality redUction non axiomaTic reasoning few Shot learner for\nperception. NUTS consists of naive dimensionality reduction, some\npre-processing, and then non axiomatic reasoning (NARS). With only 2 training\nexamples NUTS performs similarly to the Whisper Tiny model for discrete word\nidentification.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "D. van der Sluis"
        ],
        "published": "2024-05-28T06:51:42Z"
    },
    {
        "title": "MixDQ: Memory-Efficient Few-Step Text-to-Image Diffusion Models with\n  Metric-Decoupled Mixed Precision Quantization",
        "link": "http://arxiv.org/abs/2405.17873v2",
        "abstract": "Diffusion models have achieved significant visual generation quality.\nHowever, their significant computational and memory costs pose challenge for\ntheir application on resource-constrained mobile devices or even desktop GPUs.\nRecent few-step diffusion models reduces the inference time by reducing the\ndenoising steps. However, their memory consumptions are still excessive. The\nPost Training Quantization (PTQ) replaces high bit-width FP representation with\nlow-bit integer values (INT4/8) , which is an effective and efficient technique\nto reduce the memory cost. However, when applying to few-step diffusion models,\nexisting quantization methods face challenges in preserving both the image\nquality and text alignment. To address this issue, we propose an\nmixed-precision quantization framework - MixDQ. Firstly, We design specialized\nBOS-aware quantization method for highly sensitive text embedding quantization.\nThen, we conduct metric-decoupled sensitivity analysis to measure the\nsensitivity of each layer. Finally, we develop an integer-programming-based\nmethod to conduct bit-width allocation. While existing quantization methods\nfall short at W8A8, MixDQ could achieve W8A8 without performance loss, and W4A8\nwith negligible visual degradation. Compared with FP16, we achieve 3-4x\nreduction in model size and memory cost, and 1.45x latency speedup.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Tianchen Zhao",
            "Xuefei Ning",
            "Tongcheng Fang",
            "Enshu Liu",
            "Guyue Huang",
            "Zinan Lin",
            "Shengen Yan",
            "Guohao Dai",
            "Yu Wang"
        ],
        "published": "2024-05-28T06:50:58Z"
    },
    {
        "title": "HFGS: 4D Gaussian Splatting with Emphasis on Spatial and Temporal\n  High-Frequency Components for Endoscopic Scene Reconstruction",
        "link": "http://arxiv.org/abs/2405.17872v2",
        "abstract": "Robot-assisted minimally invasive surgery benefits from enhancing dynamic\nscene reconstruction, as it improves surgical outcomes. While Neural Radiance\nFields (NeRF) have been effective in scene reconstruction, their slow inference\nspeeds and lengthy training durations limit their applicability. To overcome\nthese limitations, 3D Gaussian Splatting (3D-GS) based methods have emerged as\na recent trend, offering rapid inference capabilities and superior 3D quality.\nHowever, these methods still struggle with under-reconstruction in both static\nand dynamic scenes. In this paper, we propose HFGS, a novel approach for\ndeformable endoscopic reconstruction that addresses these challenges from\nspatial and temporal frequency perspectives. Our approach incorporates\ndeformation fields to better handle dynamic scenes and introduces Spatial\nHigh-Frequency Emphasis Reconstruction (SHF) to minimize discrepancies in\nspatial frequency spectra between the rendered image and its ground truth.\nAdditionally, we introduce Temporal High-Frequency Emphasis Reconstruction\n(THF) to enhance dynamic awareness in neural rendering by leveraging flow\npriors, focusing optimization on motion-intensive parts. Extensive experiments\non two widely used benchmarks demonstrate that HFGS achieves superior rendering\nquality. Our code will be available.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Haoyu Zhao",
            "Xingyue Zhao",
            "Lingting Zhu",
            "Weixi Zheng",
            "Yongchao Xu"
        ],
        "published": "2024-05-28T06:48:02Z"
    },
    {
        "title": "Seeing the Image: Prioritizing Visual Correlation by Contrastive\n  Alignment",
        "link": "http://arxiv.org/abs/2405.17871v1",
        "abstract": "Existing image-text modality alignment in Vision Language Models (VLMs)\ntreats each text token equally in an autoregressive manner. Despite being\nsimple and effective, this method results in sub-optimal cross-modal alignment\nby over-emphasizing the text tokens that are less correlated with or even\ncontradictory with the input images. In this paper, we advocate for assigning\ndistinct contributions for each text token based on its visual correlation.\nSpecifically, we present by contrasting image inputs, the difference in\nprediction logits on each text token provides strong guidance of visual\ncorrelation. We therefore introduce Contrastive ALignment (CAL), a simple yet\neffective re-weighting strategy that prioritizes training visually correlated\ntokens. Our experimental results demonstrate that CAL consistently improves\ndifferent types of VLMs across different resolutions and model sizes on various\nbenchmark datasets. Importantly, our method incurs minimal additional\ncomputational overhead, rendering it highly efficient compared to alternative\ndata scaling strategies. Codes are available at\nhttps://github.com/foundation-multimodal-models/CAL.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Xin Xiao",
            "Bohong Wu",
            "Jiacong Wang",
            "Chunyuan Li",
            "Xun Zhou",
            "Haoyuan Guo"
        ],
        "published": "2024-05-28T06:44:13Z"
    },
    {
        "title": "Full-Stack Allreduce on Multi-Rail Networks",
        "link": "http://arxiv.org/abs/2405.17870v1",
        "abstract": "The high communication costs impede scalability in distributed systems.\nMultimodal models like Sora exacerbate this issue by requiring more resources\nthan current networks can support. However, existing network architectures fail\nto address this gap. In this paper, we provide full-stack support for allreduce\non multi-rail networks, aiming to overcome the scalability limitations of\nlarge-scale networks by facilitating collaborative data transfer across various\nnetworks. To achieve this, we propose the Nezha system, which integrates TCP,\nin-network computing protocol SHARP, and RDMA-based protocol GLEX. To maximize\ndata transfer rates, Nezha incorporates a load balancing data allocation scheme\nbased on cost feedback and combines exception handling to achieve reliable data\ntransmission. Our experiments on a six-node cluster demonstrate that Nezha\nsignificantly enhances allreduce performance by 58\\% to 87\\% in homogeneous\ndual-rail configurations and offers considerable acceleration in heterogeneous\nsettings, contingent on the performance variance among networks.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Enda Yu",
            "Dezun Dong",
            "Xiangke Liao"
        ],
        "published": "2024-05-28T06:44:09Z"
    },
    {
        "title": "Distance based prefetching algorithms for mining of the sporadic\n  requests associations",
        "link": "http://arxiv.org/abs/2405.18450v1",
        "abstract": "Modern storage systems intensively utilize data prefetching algorithms while\nprocessing sequences of the read requests. Performance of the prefetching\nalgorithm (for instance increase of the cache hit ratio of the cache system -\nCHR) directly affects overall performance characteristics of the storage system\n(read latency, IOPS, etc.). There are widely known prefetching algorithms that\nare focused on the discovery of the sequential patterns in the stream of\nrequests. This study examines a family of prefetching algorithms that is\nfocused on mining of the pseudo random (sporadic) patterns between read\nrequests - sporadic prefetching algorithms. The key contribution of this paper\nis that it discovers a new, lightweight family of distance-based sporadic\nprefetching algorithms (DBSP) that outperforms the best previously known\nresults on MSR traces collection.Another important contribution of this paper\nis a thorough description of the procedure for comparing the performance of\nsporadic prefetchers.",
        "subjects": [
            "cs.DB"
        ],
        "authors": [
            "Vadim Voevodkin",
            "Andrey Sokolov"
        ],
        "published": "2024-05-28T06:37:25Z"
    },
    {
        "title": "An algorithm applied the Turing pattern model to control active swarm\n  robots using only information from neighboring modules",
        "link": "http://arxiv.org/abs/2405.17868v1",
        "abstract": "Swarm robots, inspired by the emergence of animal herds, are robots that\nassemble a large number of modules and self-organize themselves to form\nspecific morphologies and exhibit specific functions. These modular robots\nperform relatively simple actions and controls, and create macroscopic\nmorphologies and functions through the interaction of a large number of modular\nrobots. This research focuses on such self-organizing robots or swarm robots.\nThe proposed algorithm is a model that applies the Turing pattern, one of the\nself-organization models, to make a group of modules accumulate and stay within\na certain region. The proposed method utilizes the area within the spots of the\nTuring pattern as the aggregation region of the modules. Furthermore, it\nconsiders the value corresponding to the concentration distribution within the\nspotted pattern of the Turing pattern model (referred to as the potential value\nin this research), identifies the center of the region (spotted pattern), and\nmakes it the center of the module group. By controlling the modules in the\ndirection of the higher potential value, it succeeds in maintaining the shape\nof the module group as a whole while moving. The algorithm was validated using\na two-dimensional simulation model. The unit module robot was assumed to have\nthe following properties: 1) limited self-drive, 2) no module identifier, 3)\ninformation exchange only with adjacent modules, 4) no coordinate system, and\n5) only simple arithmetic and memory functions. Using these modules, the\ndevised algorithm was able to achieve not only the creation of static forms but\nalso the realization of the following movements: 1) modules accumulate and\ngrow, 2) modules move to the light source, 3) exit the gap while maintaining\nits shape, and 4) self-replication.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Takeshi Ishida"
        ],
        "published": "2024-05-28T06:33:21Z"
    },
    {
        "title": "Towards robust prediction of material properties for nuclear reactor\n  design under scarce data -- a study in creep rupture property",
        "link": "http://arxiv.org/abs/2405.17862v1",
        "abstract": "Advances in Deep Learning bring further investigation into credibility and\nrobustness, especially for safety-critical engineering applications such as the\nnuclear industry. The key challenges include the availability of data set\n(often scarce and sparse) and insufficient consideration of the uncertainty in\nthe data, model, and prediction. This paper therefore presents a meta-learning\nbased approach that is both uncertainty- and prior knowledge-informed, aiming\nat trustful predictions of material properties for the nuclear reactor design.\nIt is suited for robust learning under limited data. Uncertainty has been\naccounted for where a distribution of predictor functions are produced for\nextrapolation. Results suggest it achieves superior performance than existing\nempirical methods in rupture life prediction, a case which is typically under a\nsmall data regime. While demonstrated herein with rupture properties, this\nlearning approach is transferable to solve similar problems of data scarcity\nacross the nuclear industry. It is of great importance to boosting the AI\nanalytics in the nuclear industry by proving the applicability and robustness\nwhile providing tools that can be trusted.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Yu Chen",
            "Edoardo Patelli",
            "Zhen Yang",
            "Adolphus Lye"
        ],
        "published": "2024-05-28T06:20:14Z"
    },
    {
        "title": "Adapting Pre-Trained Vision Models for Novel Instance Detection and\n  Segmentation",
        "link": "http://arxiv.org/abs/2405.17859v1",
        "abstract": "Novel Instance Detection and Segmentation (NIDS) aims at detecting and\nsegmenting novel object instances given a few examples of each instance. We\npropose a unified framework (NIDS-Net) comprising object proposal generation,\nembedding creation for both instance templates and proposal regions, and\nembedding matching for instance label assignment. Leveraging recent\nadvancements in large vision methods, we utilize the Grounding DINO and Segment\nAnything Model (SAM) to obtain object proposals with accurate bounding boxes\nand masks. Central to our approach is the generation of high-quality instance\nembeddings. We utilize foreground feature averages of patch embeddings from the\nDINOv2 ViT backbone, followed by refinement through a weight adapter mechanism\nthat we introduce. We show experimentally that our weight adapter can adjust\nthe embeddings locally within their feature space and effectively limit\noverfitting. This methodology enables a straightforward matching strategy,\nresulting in significant performance gains. Our framework surpasses current\nstate-of-the-art methods, demonstrating notable improvements of 22.3, 46.2,\n10.3, and 24.0 in average precision (AP) across four detection datasets. In\ninstance segmentation tasks on seven core datasets of the BOP challenge, our\nmethod outperforms the top RGB methods by 3.6 AP and remains competitive with\nthe best RGB-D method. Code is available at:\nhttps://github.com/YoungSean/NIDS-Net",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Yangxiao Lu",
            "Jishnu Jaykumar P",
            "Yunhui Guo",
            "Nicholas Ruozzi",
            "Yu Xiang"
        ],
        "published": "2024-05-28T06:16:57Z"
    },
    {
        "title": "A Deep Neural Network Approach to Fare Evasion",
        "link": "http://arxiv.org/abs/2405.17855v1",
        "abstract": "Fare evasion is a problem for public transport companies, with LSTM models\nthis issue can help companies get an analytical insight into where this issue\noccurs the most, to prevent capital loss. In addition to the financial burden\nthis problem causes, having more inspectors is not enough to alleviate the\nproblem. The purpose of this study is to find a different way to predict fare\nevasion in the public transport sector. Through the use of keypoint extractions\nof passengers in video footage, an LSTM model is trained on those keypoints to\nhelp predict the actions of passengers between payments and evasions. The\nresults were promising when it came to predicting the actions of passengers on\nreal-time footage. Thus a sophisticated approach can help to decrease the fare\nevasion problem. A ReID model can be used alongside the LSTM model for better\naccuracy, as there is always the chance that a person might only pay for the\nfare at a later stage. With both models, it is possible for public transport\ncompanies to start narrowing down where the root of their fare evasion problems\nemerges.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Johannes van der Vyver"
        ],
        "published": "2024-05-28T06:14:38Z"
    },
    {
        "title": "I-LLM: Efficient Integer-Only Inference for Fully-Quantized Low-Bit\n  Large Language Models",
        "link": "http://arxiv.org/abs/2405.17849v1",
        "abstract": "Post-training quantization (PTQ) serves as a potent technique to accelerate\nthe inference of large language models (LLMs). Nonetheless, existing works\nstill necessitate a considerable number of floating-point (FP) operations\nduring inference, including additional quantization and de-quantization, as\nwell as non-linear operators such as RMSNorm and Softmax. This limitation\nhinders the deployment of LLMs on the edge and cloud devices. In this paper, we\nidentify the primary obstacle to integer-only quantization for LLMs lies in the\nlarge fluctuation of activations across channels and tokens in both linear and\nnon-linear operations. To address this issue, we propose I-LLM, a novel\ninteger-only fully-quantized PTQ framework tailored for LLMs. Specifically, (1)\nwe develop Fully-Smooth Block-Reconstruction (FSBR) to aggressively smooth\ninter-channel variations of all activations and weights. (2) to alleviate\ndegradation caused by inter-token variations, we introduce a novel approach\ncalled Dynamic Integer-only MatMul (DI-MatMul). This method enables dynamic\nquantization in full-integer matrix multiplication by dynamically quantizing\nthe input and outputs with integer-only operations. (3) we design\nDI-ClippedSoftmax, DI-Exp, and DI-Normalization, which utilize bit shift to\nexecute non-linear operators efficiently while maintaining accuracy. The\nexperiment shows that our I-LLM achieves comparable accuracy to the FP baseline\nand outperforms non-integer quantization methods. For example, I-LLM can\noperate at W4A4 with negligible loss of accuracy. To our knowledge, we are the\nfirst to bridge the gap between integer-only quantization and LLMs. We've\npublished our code on anonymous.4open.science, aiming to contribute to the\nadvancement of this field.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Xing Hu",
            "Yuan Chen",
            "Dawei Yang",
            "Sifan Zhou",
            "Zhihang Yuan",
            "Jiangyong Yu",
            "Chen Xu"
        ],
        "published": "2024-05-28T05:56:11Z"
    },
    {
        "title": "Sparsification of Phylogenetic Covariance Matrices of $k$-Regular Trees",
        "link": "http://arxiv.org/abs/2405.17847v1",
        "abstract": "Consider a tree $T=(V,E)$ with root $\\circ$ and edge length function\n$\\ell:E\\to\\mathbb{R}_+$. The phylogenetic covariance matrix of $T$ is the\nmatrix $C$ with rows and columns indexed by $L$, the leaf set of $T$, with\nentries $C(i,j):=\\sum_{e\\in[i\\wedge j,o]}\\ell(e)$, for each $i,j\\in L$. Recent\nwork [15] has shown that the phylogenetic covariance matrix of a large, random\nbinary tree $T$ is significantly sparsified with overwhelmingly high\nprobability under a change-of-basis with respect to the so-called Haar-like\nwavelets of $T$. This finding notably enables manipulating the spectrum of\ncovariance matrices of large binary trees without the necessity to store them\nin computer memory but instead performing two post-order traversals of the\ntree. Building on the methods of [15], this manuscript further advances their\nsparsification result to encompass the broader class of $k$-regular trees, for\nany given $k\\ge2$. This extension is achieved by refining existing asymptotic\nformulas for the mean and variance of the internal path length of random\n$k$-regular trees, utilizing hypergeometric function properties and identities.",
        "subjects": [
            "q-bio.PE",
            "cs.DM",
            "math.CO",
            "math.PR",
            "60C05, 68R05, 65F05, 65F15, 65F55, 92-08, 92C70",
            "G.2.1; G.2.2; G.3; J.2; J.3"
        ],
        "authors": [
            "Sean S. Svihla",
            "Manuel E. Lladser"
        ],
        "published": "2024-05-28T05:52:19Z"
    },
    {
        "title": "Safety Control of Service Robots with LLMs and Embodied Knowledge Graphs",
        "link": "http://arxiv.org/abs/2405.17846v1",
        "abstract": "Safety limitations in service robotics across various industries have raised\nsignificant concerns about the need for robust mechanisms ensuring that robots\nadhere to safe practices, thereby preventing actions that might harm humans or\ncause property damage. Despite advances, including the integration of Knowledge\nGraphs (KGs) with Large Language Models (LLMs), challenges in ensuring\nconsistent safety in autonomous robot actions persist. In this paper, we\npropose a novel integration of Large Language Models with Embodied Robotic\nControl Prompts (ERCPs) and Embodied Knowledge Graphs (EKGs) to enhance the\nsafety framework for service robots. ERCPs are designed as predefined\ninstructions that ensure LLMs generate safe and precise responses. These\nresponses are subsequently validated by EKGs, which provide a comprehensive\nknowledge base ensuring that the actions of the robot are continuously aligned\nwith safety protocols, thereby promoting safer operational practices in varied\ncontexts. Our experimental setup involved diverse real-world tasks, where\nrobots equipped with our framework demonstrated significantly higher compliance\nwith safety standards compared to traditional methods. This integration fosters\nsecure human-robot interactions and positions our methodology at the forefront\nof AI-driven safety innovations in service robotics.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "authors": [
            "Yong Qi",
            "Gabriel Kyebambo",
            "Siyuan Xie",
            "Wei Shen",
            "Shenghui Wang",
            "Bitao Xie",
            "Bin He",
            "Zhipeng Wang",
            "Shuo Jiang"
        ],
        "published": "2024-05-28T05:50:25Z"
    },
    {
        "title": "A System for Quantifying Data Science Workflows with Fine-Grained\n  Procedural Logging and a Pilot Study",
        "link": "http://arxiv.org/abs/2405.17845v1",
        "abstract": "It is important for researchers to understand precisely how data scientists\nturn raw data into insights, including typical programming patterns, workflow,\nand methodology. This paper contributes a novel system, called DataInquirer,\nthat tracks incremental code executions in Jupyter notebooks (a type of\ncomputational notebook). The system allows us to quantitatively measure timing,\nworkflow, and operation frequency in data science tasks without resorting to\nhuman annotation or interview. In a series of pilot studies, we collect 97\ntraces, logging data scientist activities across four studies. While this paper\npresents a general system and data analysis approach, we focus on a\nfoundational sub-question in our pilot studies: How consistent are different\ndata scientists in analyzing the same data? We taxonomize variation between\ndata scientists on the same dataset according to three categories: semantic,\nsyntactic, and methodological. Our results suggest that there are statistically\nsignificant differences in the conclusions reached by different data scientists\non the same task and present quantitative evidence for this phenomenon.\nFurthermore, our results suggest that AI-powered code tools subtly influence\nthese results, allowing student participants to generate workflows that more\nresemble expert data practitioners.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Jinjin Zhao",
            "Avidgor Gal",
            "Sanjay Krishnan"
        ],
        "published": "2024-05-28T05:50:10Z"
    },
    {
        "title": "Multi-Wheeled Passive Sliding with Fully-Actuated Aerial Robots:\n  Tip-Over Recovery and Avoidance",
        "link": "http://arxiv.org/abs/2405.17844v2",
        "abstract": "Push-and-slide tasks carried out by fully-actuated aerial robots can be used\nfor inspection and simple maintenance tasks at height, such as non-destructive\ntesting and painting. Often, an end-effector based on multiple non-actuated\ncontact wheels is used to contact the surface. This approach entails challenges\nin ensuring consistent wheel contact with a surface whose exact orientation and\nlocation might be uncertain due to sensor aliasing and drift. Using a standard\nfull-pose controller dependent on the inaccurate surface position and\norientation may cause wheels to lose contact during sliding, and subsequently\nlead to robot tip-over. To address the tip-over issue, we present two\napproaches: (1) tip-over avoidance guidelines for hardware design, and (2)\ncontrol for tip-over recovery and avoidance. Physical experiments with a\nfully-actuated aerial vehicle were executed for a push-and-slide task on a flat\nsurface. The resulting data is used in deriving tip-over avoidance guidelines\nand designing a simulator that closely captures real-world conditions. We then\nuse the simulator to test the effectiveness and robustness of the proposed\napproaches in risky scenarios against uncertainties.",
        "subjects": [
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Tong Hui",
            "Eugenio Cuniato",
            "Michael Pantic",
            "Jefferson Ghielmini",
            "Christian Lanegger",
            "Dimitrios Papageorgiou",
            "Marco Tognon",
            "Roland Siegwart",
            "Matteo Fumagalli"
        ],
        "published": "2024-05-28T05:49:32Z"
    },
    {
        "title": "Ai.llude: Encouraging Rewriting AI-Generated Text to Support Creative\n  Expression",
        "link": "http://dx.doi.org/10.1145/3635636.3656187",
        "abstract": "In each step of the creative writing process, writers must grapple with their\ncreative goals and individual perspectives. This process affects the writer's\nsense of authenticity and their engagement with the written output. Fluent text\ngeneration by AIs risks undermining the reflective loop of rewriting. We\nhypothesize that deliberately generating imperfect intermediate text can\nencourage rewriting and prompt higher level decision making. Using logs from 27\nwriting sessions using a text generation AI, we characterize how writers adapt\nand rewrite AI suggestions, and show that intermediate suggestions\nsignificantly motivate and increase rewriting. We discuss the implications of\nthis finding, and future steps for investigating how to leverage intermediate\ntext in AI writing support tools to support ownership over creative expression.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "David Zhou",
            "Sarah Sterman"
        ],
        "published": "2024-05-28T05:45:30Z"
    },
    {
        "title": "Discriminator-Guided Cooperative Diffusion for Joint Audio and Video\n  Generation",
        "link": "http://arxiv.org/abs/2405.17842v1",
        "abstract": "In this study, we aim to construct an audio-video generative model with\nminimal computational cost by leveraging pre-trained single-modal generative\nmodels for audio and video. To achieve this, we propose a novel method that\nguides each single-modal model to cooperatively generate well-aligned samples\nacross modalities. Specifically, given two pre-trained base diffusion models,\nwe train a lightweight joint guidance module to adjust scores separately\nestimated by the base models to match the score of joint distribution over\naudio and video. We theoretically show that this guidance can be computed\nthrough the gradient of the optimal discriminator distinguishing real\naudio-video pairs from fake ones independently generated by the base models. On\nthe basis of this analysis, we construct the joint guidance module by training\nthis discriminator. Additionally, we adopt a loss function to make the gradient\nof the discriminator work as a noise estimator, as in standard diffusion\nmodels, stabilizing the gradient of the discriminator. Empirical evaluations on\nseveral benchmark datasets demonstrate that our method improves both\nsingle-modal fidelity and multi-modal alignment with a relatively small number\nof parameters.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "cs.MM",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Akio Hayakawa",
            "Masato Ishii",
            "Takashi Shibuya",
            "Yuki Mitsufuji"
        ],
        "published": "2024-05-28T05:43:03Z"
    },
    {
        "title": "Benchmark Underestimates the Readiness of Multi-lingual Dialogue Agents",
        "link": "http://arxiv.org/abs/2405.17840v1",
        "abstract": "Creating multilingual task-oriented dialogue (TOD) agents is challenging due\nto the high cost of training data acquisition. Following the research trend of\nimproving training data efficiency, we show for the first time, that in-context\nlearning is sufficient to tackle multilingual TOD.\n  To handle the challenging dialogue state tracking (DST) subtask, we break it\ndown to simpler steps that are more compatible with in-context learning where\nonly a handful of few-shot examples are used. We test our approach on the\nmultilingual TOD dataset X-RiSAWOZ, which has 12 domains in Chinese, English,\nFrench, Korean, Hindi, and code-mixed Hindi-English. Our turn-by-turn DST\naccuracy on the 6 languages range from 55.6% to 80.3%, seemingly worse than the\nSOTA results from fine-tuned models that achieve from 60.7% to 82.8%; our BLEU\nscores in the response generation (RG) subtask are also significantly lower\nthan SOTA.\n  However, after manual evaluation of the validation set, we find that by\ncorrecting gold label errors and improving dataset annotation schema, GPT-4\nwith our prompts can achieve (1) 89.6%-96.8% accuracy in DST, and (2) more than\n99% correct response generation across different languages. This leads us to\nconclude that current automatic metrics heavily underestimate the effectiveness\nof in-context learning.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Andrew H. Lee",
            "Sina J. Semnani",
            "Galo Castillo-López",
            "Gäel de Chalendar",
            "Monojit Choudhury",
            "Ashna Dua",
            "Kapil Rajesh Kavitha",
            "Sungkyun Kim",
            "Prashant Kodali",
            "Ponnurangam Kumaraguru",
            "Alexis Lombard",
            "Mehrad Moradshahi",
            "Gihyun Park",
            "Nasredine Semmar",
            "Jiwon Seo",
            "Tianhao Shen",
            "Manish Shrivastava",
            "Deyi Xiong",
            "Monica S. Lam"
        ],
        "published": "2024-05-28T05:33:13Z"
    },
    {
        "title": "PeerFL: A Simulator for Peer-to-Peer Federated Learning at Scale",
        "link": "http://arxiv.org/abs/2405.17839v1",
        "abstract": "This work integrates peer-to-peer federated learning tools with NS3, a widely\nused network simulator, to create a novel simulator designed to allow\nheterogeneous device experiments in federated learning. This cross-platform\nadaptability addresses a critical gap in existing simulation tools, enhancing\nthe overall utility and user experience. NS3 is leveraged to simulate WiFi\ndynamics to facilitate federated learning experiments with participants that\nmove around physically during training, leading to dynamic network\ncharacteristics. Our experiments showcase the simulator's efficiency in\ncomputational resource utilization at scale, with a maximum of 450\nheterogeneous devices modelled as participants in federated learning. This\npositions it as a valuable tool for simulation-based investigations in\npeer-to-peer federated learning. The framework is open source and available for\nuse and extension to the community.",
        "subjects": [
            "cs.DC",
            "cs.AI"
        ],
        "authors": [
            "Alka Luqman",
            "Shivanshu Shekhar",
            "Anupam Chattopadhyay"
        ],
        "published": "2024-05-28T05:30:18Z"
    },
    {
        "title": "Trust and Terror: Hazards in Text Reveal Negatively Biased Credulity and\n  Partisan Negativity Bias",
        "link": "http://arxiv.org/abs/2405.17838v1",
        "abstract": "Socio-linguistic indicators of text, such as emotion or sentiment, are often\nextracted using neural networks in order to better understand features of\nsocial media. One indicator that is often overlooked, however, is the presence\nof hazards within text. Recent psychological research suggests that statements\nabout hazards are more believable than statements about benefits (a property\nknown as negatively biased credulity), and that political liberals and\nconservatives differ in how often they share hazards. Here, we develop a new\nmodel to detect information concerning hazards, trained on a new collection of\nannotated X posts, as well as urban legends annotated in previous work. We show\nthat not only does this model perform well (outperforming, e.g., zero-shot\nhuman annotator proxies, such as GPT-4) but that the hazard information it\nextracts is not strongly correlated with other indicators, namely moral\noutrage, sentiment, emotions, and threat words. (That said, consonant with\nexpectations, hazard information does correlate positively with such emotions\nas fear, and negatively with emotions like joy.) We then apply this model to\nthree datasets: X posts about COVID-19, X posts about the 2023 Hamas-Israel\nwar, and a new expanded collection of urban legends. From these data, we\nuncover words associated with hazards unique to each dataset as well as\ndifferences in this language between groups of users, such as conservatives and\nliberals, which informs what these groups perceive as hazards. We further show\nthat information about hazards peaks in frequency after major hazard events,\nand therefore acts as an automated indicator of such events. Finally, we find\nthat information about hazards is especially prevalent in urban legends, which\nis consistent with previous work that finds that reports of hazards are more\nlikely to be both believed and transmitted.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Keith Burghardt",
            "Daniel M. T. Fessler",
            "Chyna Tang",
            "Anne Pisor",
            "Kristina Lerman"
        ],
        "published": "2024-05-28T05:28:49Z"
    },
    {
        "title": "Enabling Generative Design Tools with LLM Agents for Building Novel\n  Devices: A Case Study on Fluidic Computation Interfaces",
        "link": "http://arxiv.org/abs/2405.17837v1",
        "abstract": "In the field of Human-Computer Interaction (HCI), the development of\ninteractive devices represents a significant area of focus. The advent of novel\nhardware and advanced fabrication techniques has underscored the demand for\nspecialized design tools that democratize the prototyping process for such\ncutting-edge devices. While these tools simplify the process through parametric\ndesign and simulation, they typically require a certain learning curve and\noften fall short in facilitating creative ideation. In this study, we employ\nfluidic computation interface as a case study to investigate the potential of\naugmenting design tools of physical devices with Large Language Model (LLM)\nagents. Enhanced by LLM agents, the Generative Design Tool (GDT) can comprehend\nthe capabilities and limitations of newly developed devices; it can propose\nvaried, insightful, and practical application scenarios, and recommend device\ndesigns that are technically and contextually appropriate. Furthermore, it\ngenerates the necessary design parameters for the traditional part of the\ndesign tool to visualize results and produce support files for fabrication.\nThis paper outlines the GDT's framework, implementation, and performance, while\nalso contemplating its prospects and the obstacles encountered.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Qiuyu Lu",
            "Jiawei Fang",
            "Zhihao Yao",
            "Yue Yang",
            "Shiqing Lyu",
            "Haipeng Mi",
            "Lining Yao"
        ],
        "published": "2024-05-28T05:21:09Z"
    },
    {
        "title": "An Innovative Networks in Federated Learning",
        "link": "http://arxiv.org/abs/2405.17836v1",
        "abstract": "This paper presents the development and application of Wavelet\nKolmogorov-Arnold Networks (Wav-KAN) in federated learning. We implemented\nWav-KAN \\cite{wav-kan} in the clients. Indeed, we have considered both\ncontinuous wavelet transform (CWT) and also discrete wavelet transform (DWT) to\nenable multiresolution capabaility which helps in heteregeneous data\ndistribution across clients. Extensive experiments were conducted on different\ndatasets, demonstrating Wav-KAN's superior performance in terms of\ninterpretability, computational speed, training and test accuracy. Our\nfederated learning algorithm integrates wavelet-based activation functions,\nparameterized by weight, scale, and translation, to enhance local and global\nmodel performance. Results show significant improvements in computational\nefficiency, robustness, and accuracy, highlighting the effectiveness of wavelet\nselection in scalable neural network design.",
        "subjects": [
            "eess.SP",
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Zavareh Bozorgasl",
            "Hao Chen"
        ],
        "published": "2024-05-28T05:20:01Z"
    },
    {
        "title": "Deform3DGS: Flexible Deformation for Fast Surgical Scene Reconstruction\n  with Gaussian Splatting",
        "link": "http://arxiv.org/abs/2405.17835v3",
        "abstract": "Tissue deformation poses a key challenge for accurate surgical scene\nreconstruction. Despite yielding high reconstruction quality, existing methods\nsuffer from slow rendering speeds and long training times, limiting their\nintraoperative applicability. Motivated by recent progress in 3D Gaussian\nSplatting, an emerging technology in real-time 3D rendering, this work presents\na novel fast reconstruction framework, termed Deform3DGS, for deformable\ntissues during endoscopic surgery. Specifically, we introduce 3D GS into\nsurgical scenes by integrating a point cloud initialization to improve\nreconstruction. Furthermore, we propose a novel flexible deformation modeling\nscheme (FDM) to learn tissue deformation dynamics at the level of individual\nGaussians. Our FDM can model the surface deformation with efficient\nrepresentations, allowing for real-time rendering performance. More\nimportantly, FDM significantly accelerates surgical scene reconstruction,\ndemonstrating considerable clinical values, particularly in intraoperative\nsettings where time efficiency is crucial. Experiments on DaVinci robotic\nsurgery videos indicate the efficacy of our approach, showcasing superior\nreconstruction fidelity PSNR: (37.90) and rendering speed (338.8 FPS) while\nsubstantially reducing training time to only 1 minute/scene. Our code is\navailable at https://github.com/jinlab-imvr/Deform3DGS.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Shuojue Yang",
            "Qian Li",
            "Daiyun Shen",
            "Bingchen Gong",
            "Qi Dou",
            "Yueming Jin"
        ],
        "published": "2024-05-28T05:14:57Z"
    },
    {
        "title": "Mollification Effects of Policy Gradient Methods",
        "link": "http://arxiv.org/abs/2405.17832v1",
        "abstract": "Policy gradient methods have enabled deep reinforcement learning (RL) to\napproach challenging continuous control problems, even when the underlying\nsystems involve highly nonlinear dynamics that generate complex non-smooth\noptimization landscapes. We develop a rigorous framework for understanding how\npolicy gradient methods mollify non-smooth optimization landscapes to enable\neffective policy search, as well as the downside of it: while making the\nobjective function smoother and easier to optimize, the stochastic objective\ndeviates further from the original problem. We demonstrate the equivalence\nbetween policy gradient methods and solving backward heat equations. Following\nthe ill-posedness of backward heat equations from PDE theory, we present a\nfundamental challenge to the use of policy gradient under stochasticity.\nMoreover, we make the connection between this limitation and the uncertainty\nprinciple in harmonic analysis to understand the effects of exploration with\nstochastic policies in RL. We also provide experimental results to illustrate\nboth the positive and negative aspects of mollification effects in practice.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.RO"
        ],
        "authors": [
            "Tao Wang",
            "Sylvia Herbert",
            "Sicun Gao"
        ],
        "published": "2024-05-28T05:05:33Z"
    },
    {
        "title": "More Than Catastrophic Forgetting: Integrating General Capabilities For\n  Domain-Specific LLMs",
        "link": "http://arxiv.org/abs/2405.17830v1",
        "abstract": "The performance on general tasks decreases after Large Language Models (LLMs)\nare fine-tuned on domain-specific tasks, the phenomenon is known as\nCatastrophic Forgetting (CF). However, this paper presents a further challenge\nfor real application of domain-specific LLMs beyond CF, called General\nCapabilities Integration (GCI), which necessitates the integration of both the\ngeneral capabilities and domain knowledge within a single instance. The\nobjective of GCI is not merely to retain previously acquired general\ncapabilities alongside new domain knowledge, but to harmonize and utilize both\nsets of skills in a cohesive manner to enhance performance on domain-specific\ntasks. Taking legal domain as an example, we carefully design three groups of\ntraining and testing tasks without lacking practicability, and construct the\ncorresponding datasets. To better incorporate general capabilities across\ndomain-specific scenarios, we introduce ALoRA, which utilizes a multi-head\nattention module upon LoRA, facilitating direct information transfer from\npreceding tokens to the current one. This enhancement permits the\nrepresentation to dynamically switch between domain-specific knowledge and\ngeneral competencies according to the attention. Extensive experiments are\nconducted on the proposed tasks. The results exhibit the significance of our\nsetting, and the effectiveness of our method.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Chengyuan Liu",
            "Shihang Wang",
            "Yangyang Kang",
            "Lizhi Qing",
            "Fubang Zhao",
            "Changlong Sun",
            "Kun Kuang",
            "Fei Wu"
        ],
        "published": "2024-05-28T05:00:12Z"
    },
    {
        "title": "LDMol: Text-Conditioned Molecule Diffusion Model Leveraging Chemically\n  Informative Latent Space",
        "link": "http://arxiv.org/abs/2405.17829v1",
        "abstract": "With the emergence of diffusion models as the frontline of generative models,\nmany researchers have proposed molecule generation techniques using conditional\ndiffusion models. However, due to the fundamental nature of a molecule, which\ncarries highly entangled correlations within a small number of atoms and bonds,\nit becomes difficult for a model to connect raw data with the conditions when\nthe conditions become more complex as natural language. To address this, here\nwe present a novel latent diffusion model dubbed LDMol, which enables a natural\ntext-conditioned molecule generation. Specifically, LDMol is composed of three\nbuilding blocks: a molecule encoder that produces a chemically informative\nfeature space, a natural language-conditioned latent diffusion model using a\nDiffusion Transformer (DiT), and an autoregressive decoder for molecule re. In\nparticular, recognizing that multiple SMILES notations can represent the same\nmolecule, we employ a contrastive learning strategy to extract the chemical\ninformative feature space. LDMol not only beats the existing baselines on the\ntext-to-molecule generation benchmark but is also capable of zero-shot\ninference with unseen scenarios. Furthermore, we show that LDMol can be applied\nto downstream tasks such as molecule-to-text retrieval and text-driven molecule\nediting, demonstrating its versatility as a diffusion model.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Jinho Chang",
            "Jong Chul Ye"
        ],
        "published": "2024-05-28T04:59:13Z"
    },
    {
        "title": "DanceGen: Supporting Choreography Ideation and Prototyping with\n  Generative AI",
        "link": "http://dx.doi.org/10.1145/3643834.3661594",
        "abstract": "Choreography creation requires high proficiency in artistic and technical\nskills. Choreographers typically go through four stages to create a dance\npiece: preparation, studio, performance, and reflection. This process is often\nindividualized, complicated, and challenging due to multiple constraints at\neach stage. To assist choreographers, most prior work has focused on designing\ndigital tools to support the last three stages of the choreography process,\nwith the preparation stage being the least explored. To address this research\ngap, we introduce an AI-based approach to assist the preparation stage by\nsupporting ideation, creating choreographic prototypes, and documenting\ncreative attempts and outcomes. We address the limitations of existing AI-based\nmotion generation methods for ideation by allowing generated sequences to be\nedited and modified in an interactive web interface. This capability is\nmotivated by insights from a formative study we conducted with seven\nchoreographers. We evaluated our system's functionality, benefits, and\nlimitations with six expert choreographers. Results highlight the usability of\nour system, with users reporting increased efficiency, expanded creative\npossibilities, and an enhanced iterative process. We also identified areas for\nimprovement, such as the relationship between user intent and AI outcome,\nintuitive and flexible user interaction design, and integration with existing\nphysical choreography prototyping workflows. By reflecting on the evaluation\nresults, we present three insights that aim to inform the development of future\nAI systems that can empower choreographers.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Yimeng Liu",
            "Misha Sra"
        ],
        "published": "2024-05-28T04:50:55Z"
    },
    {
        "title": "Diffusion Model Patching via Mixture-of-Prompts",
        "link": "http://arxiv.org/abs/2405.17825v2",
        "abstract": "We present Diffusion Model Patching (DMP), a simple method to boost the\nperformance of pre-trained diffusion models that have already reached\nconvergence, with a negligible increase in parameters. DMP inserts a small,\nlearnable set of prompts into the model's input space while keeping the\noriginal model frozen. The effectiveness of DMP is not merely due to the\naddition of parameters but stems from its dynamic gating mechanism, which\nselects and combines a subset of learnable prompts at every step of the\ngenerative process (e.g., reverse denoising steps). This strategy, which we\nterm \"mixture-of-prompts\", enables the model to draw on the distinct expertise\nof each prompt, essentially \"patching\" the model's functionality at every step\nwith minimal yet specialized parameters. Uniquely, DMP enhances the model by\nfurther training on the same dataset on which it was originally trained, even\nin a scenario where significant improvements are typically not expected due to\nmodel convergence. Experiments show that DMP significantly enhances the\nconverged FID of DiT-L/2 on FFHQ 256x256 by 10.38%, achieved with only a 1.43%\nparameter increase and 50K additional training iterations.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Seokil Ham",
            "Sangmin Woo",
            "Jin-Young Kim",
            "Hyojun Go",
            "Byeongjun Park",
            "Changick Kim"
        ],
        "published": "2024-05-28T04:47:54Z"
    },
    {
        "title": "mTREE: Multi-Level Text-Guided Representation End-to-End Learning for\n  Whole Slide Image Analysis",
        "link": "http://arxiv.org/abs/2405.17824v1",
        "abstract": "Multi-modal learning adeptly integrates visual and textual data, but its\napplication to histopathology image and text analysis remains challenging,\nparticularly with large, high-resolution images like gigapixel Whole Slide\nImages (WSIs). Current methods typically rely on manual region labeling or\nmulti-stage learning to assemble local representations (e.g., patch-level) into\nglobal features (e.g., slide-level). However, there is no effective way to\nintegrate multi-scale image representations with text data in a seamless\nend-to-end process. In this study, we introduce Multi-Level Text-Guided\nRepresentation End-to-End Learning (mTREE). This novel text-guided approach\neffectively captures multi-scale WSI representations by utilizing information\nfrom accompanying textual pathology information. mTREE innovatively combines -\nthe localization of key areas (global-to-local) and the development of a\nWSI-level image-text representation (local-to-global) - into a unified,\nend-to-end learning framework. In this model, textual information serves a dual\npurpose: firstly, functioning as an attention map to accurately identify key\nareas, and secondly, acting as a conduit for integrating textual features into\nthe comprehensive representation of the image. Our study demonstrates the\neffectiveness of mTREE through quantitative analyses in two image-related\ntasks: classification and survival prediction, showcasing its remarkable\nsuperiority over baselines.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Quan Liu",
            "Ruining Deng",
            "Can Cui",
            "Tianyuan Yao",
            "Vishwesh Nath",
            "Yucheng Tang",
            "Yuankai Huo"
        ],
        "published": "2024-05-28T04:47:44Z"
    },
    {
        "title": "Spectral Truncation Kernels: Noncommutativity in $C^*$-algebraic Kernel\n  Machines",
        "link": "http://arxiv.org/abs/2405.17823v2",
        "abstract": "In this paper, we propose a new class of positive definite kernels based on\nthe spectral truncation, which has been discussed in the fields of\nnoncommutative geometry and $C^*$-algebra. We focus on kernels whose inputs and\noutputs are functions and generalize existing kernels, such as polynomial,\nproduct, and separable kernels, by introducing a truncation parameter $n$ that\ndescribes the noncommutativity of the products appearing in the kernels. When\n$n$ goes to infinity, the proposed kernels tend to the existing commutative\nkernels. If $n$ is finite, they exhibit different behavior, and the\nnoncommutativity induces interactions along the data function domain. We show\nthat the truncation parameter $n$ is a governing factor leading to performance\nenhancement: by setting an appropriate $n$, we can balance the representation\npower and the complexity of the representation space. The flexibility of the\nproposed class of kernels allows us to go beyond previous commutative kernels.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.OA"
        ],
        "authors": [
            "Yuka Hashimoto",
            "Ayoub Hafid",
            "Masahiro Ikeda",
            "Hachem Kadri"
        ],
        "published": "2024-05-28T04:47:12Z"
    },
    {
        "title": "Conv-CoA: Improving Open-domain Question Answering in Large Language\n  Models via Conversational Chain-of-Action",
        "link": "http://arxiv.org/abs/2405.17822v1",
        "abstract": "We present a Conversational Chain-of-Action (Conv-CoA) framework for\nOpen-domain Conversational Question Answering (OCQA). Compared with literature,\nConv-CoA addresses three major challenges: (i) unfaithful hallucination that is\ninconsistent with real-time or domain facts, (ii) weak reasoning performance in\nconversational scenarios, and (iii) unsatisfying performance in conversational\ninformation retrieval. Our key contribution is a dynamic reasoning-retrieval\nmechanism that extracts the intent of the question and decomposes it into a\nreasoning chain to be solved via systematic prompting, pre-designed actions,\nupdating the Contextual Knowledge Set (CKS), and a novel Hopfield-based\nretriever. Methodologically, we propose a resource-efficiency Hopfield\nretriever to enhance the efficiency and accuracy of conversational information\nretrieval within our actions. Additionally, we propose a\nconversational-multi-reference faith score (Conv-MRFS) to verify and resolve\nconflicts between retrieved knowledge and answers in conversations.\nEmpirically, we conduct comparisons between our framework and 23\nstate-of-the-art methods across five different research directions and two\npublic benchmarks. These comparisons demonstrate that our Conv-CoA outperforms\nother methods in both the accuracy and efficiency dimensions.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Zhenyu Pan",
            "Haozheng Luo",
            "Manling Li",
            "Han Liu"
        ],
        "published": "2024-05-28T04:46:52Z"
    },
    {
        "title": "RITUAL: Random Image Transformations as a Universal Anti-hallucination\n  Lever in LVLMs",
        "link": "http://arxiv.org/abs/2405.17821v1",
        "abstract": "Recent advancements in Large Vision Language Models (LVLMs) have\nrevolutionized how machines understand and generate textual responses based on\nvisual inputs. Despite their impressive capabilities, they often produce\n\"hallucinatory\" outputs that do not accurately reflect the visual information,\nposing challenges in reliability and trustworthiness. Current methods such as\ncontrastive decoding have made strides in addressing these issues by\ncontrasting the original probability distribution of generated tokens with\ndistorted counterparts; yet, generating visually-faithful outputs remains a\nchallenge. In this work, we shift our focus to the opposite: What could serve\nas a complementary enhancement to the original probability distribution? We\npropose a simple, training-free method termed RITUAL to enhance robustness\nagainst hallucinations in LVLMs. Our approach employs random image\ntransformations as complements to the original probability distribution, aiming\nto mitigate the likelihood of hallucinatory visual explanations by enriching\nthe model's exposure to varied visual scenarios. Our empirical results show\nthat while the isolated use of transformed images initially degrades\nperformance, strategic implementation of these transformations can indeed serve\nas effective complements. Notably, our method is compatible with current\ncontrastive decoding methods and does not require external models or costly\nself-feedback mechanisms, making it a practical addition. In experiments,\nRITUAL significantly outperforms existing contrastive decoding methods across\nseveral object hallucination benchmarks, including POPE, CHAIR, and MME.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Sangmin Woo",
            "Jaehyuk Jang",
            "Donguk Kim",
            "Yubin Choi",
            "Changick Kim"
        ],
        "published": "2024-05-28T04:41:02Z"
    },
    {
        "title": "Don't Miss the Forest for the Trees: Attentional Vision Calibration for\n  Large Vision Language Models",
        "link": "http://arxiv.org/abs/2405.17820v1",
        "abstract": "This study addresses the issue observed in Large Vision Language Models\n(LVLMs), where excessive attention on a few image tokens, referred to as blind\ntokens, leads to hallucinatory responses in tasks requiring fine-grained\nunderstanding of visual objects. We found that tokens receiving lower attention\nweights often hold essential information for identifying nuanced object details\n-- ranging from merely recognizing object existence to identifying their\nattributes (color, position, etc.) and understanding their relationships. To\ncounteract the over-emphasis on blind tokens and to accurately respond to user\nqueries, we introduce a technique called Attentional Vision Calibration (AVC).\nDuring the decoding phase, AVC identifies blind tokens by analyzing the\nimage-related attention distribution. It then dynamically adjusts the logits\nfor the next token prediction by contrasting the logits conditioned on the\noriginal visual tokens with those conditioned on the blind tokens. This\neffectively lowers the dependency on blind tokens and promotes a more balanced\nconsideration of all tokens. We validate AVC on benchmarks such as POPE, MME,\nand AMBER, where it consistently outperforms existing decoding techniques in\nmitigating object hallucinations in LVLMs.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Sangmin Woo",
            "Donguk Kim",
            "Jaehyuk Jang",
            "Yubin Choi",
            "Changick Kim"
        ],
        "published": "2024-05-28T04:40:57Z"
    },
    {
        "title": "An optimal chromatic bound for ($P_2+P_3$, gem)-free graphs",
        "link": "http://arxiv.org/abs/2405.17819v1",
        "abstract": "Given a graph $G$, the parameters $\\chi(G)$ and $\\omega(G)$ respectively\ndenote the chromatic number and the clique number of $G$. A function $f :\n\\mathbb{N} \\rightarrow \\mathbb{N}$ such that $f(1) = 1$ and $f(x) \\geq x$, for\nall $x \\in \\mathbb{N}$ is called a $\\chi$-binding function for the given class\nof graphs $\\cal{G}$ if every $G \\in \\cal{G}$ satisfies $\\chi(G) \\leq\nf(\\omega(G))$, and the \\emph{smallest $\\chi$-binding function} $f^*$ for\n$\\cal{G}$ is defined as $f^*(x) := \\max\\{\\chi(G)\\mid G\\in {\\cal G} \\mbox{ and }\n\\omega(G)=x\\}$. In general, the problem of obtaining the smallest\n$\\chi$-binding function for the given class of graphs seems to be extremely\nhard, and only a few classes of graphs are studied in this direction. In this\npaper, we study the class of ($P_2+ P_3$, gem)-free graphs, and prove that the\nfunction $\\phi:\\mathbb{N}\\rightarrow \\mathbb{N}$ defined by $\\phi(1)=1$,\n$\\phi(2)=4$, $\\phi(3)=6$ and\n$\\phi(x)=\\left\\lceil\\frac{1}{4}(5x-1)\\right\\rceil$, for $x\\geq 4$ is the\nsmallest $\\chi$-binding function for the class of ($P_2+ P_3$, gem)-free\ngraphs.",
        "subjects": [
            "math.CO",
            "cs.DM"
        ],
        "authors": [
            "Arnab Char",
            "T. Karthick"
        ],
        "published": "2024-05-28T04:38:40Z"
    },
    {
        "title": "Hyperspectral and multispectral image fusion with arbitrary resolution\n  through self-supervised representations",
        "link": "http://arxiv.org/abs/2405.17818v1",
        "abstract": "The fusion of a low-resolution hyperspectral image (LR-HSI) with a\nhigh-resolution multispectral image (HR-MSI) has emerged as an effective\ntechnique for achieving HSI super-resolution (SR). Previous studies have mainly\nconcentrated on estimating the posterior distribution of the latent\nhigh-resolution hyperspectral image (HR-HSI), leveraging an appropriate image\nprior and likelihood computed from the discrepancy between the latent HSI and\nobserved images. Low rankness stands out for preserving latent HSI\ncharacteristics through matrix factorization among the various priors. However,\nthis method only enhances resolution within the dimensions of the two\nmodalities. To overcome this limitation, we propose a novel continuous low-rank\nfactorization (CLoRF) by integrating two neural representations into the matrix\nfactorization, capturing spatial and spectral information, respectively. This\napproach enables us to harness both the low rankness from the matrix\nfactorization and the continuity from neural representation in a\nself-supervised manner. Theoretically, we prove the low-rank property and\nLipschitz continuity in the proposed continuous low-rank factorization.\nExperimentally, our method significantly surpasses existing techniques and\nachieves user-desired resolutions without the need for neural network\nretraining.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Ting Wang",
            "Zipei Yan",
            "Jizhou Li",
            "Xile Zhao",
            "Chao Wang",
            "Michael Ng"
        ],
        "published": "2024-05-28T04:29:23Z"
    },
    {
        "title": "Benchmarking Skeleton-based Motion Encoder Models for Clinical\n  Applications: Estimating Parkinson's Disease Severity in Walking Sequences",
        "link": "http://arxiv.org/abs/2405.17817v2",
        "abstract": "This study investigates the application of general human motion encoders\ntrained on large-scale human motion datasets for analyzing gait patterns in PD\npatients. Although these models have learned a wealth of human biomechanical\nknowledge, their effectiveness in analyzing pathological movements, such as\nparkinsonian gait, has yet to be fully validated. We propose a comparative\nframework and evaluate six pre-trained state-of-the-art human motion encoder\nmodels on their ability to predict the Movement Disorder Society - Unified\nParkinson's Disease Rating Scale (MDS-UPDRS-III) gait scores from motion\ncapture data. We compare these against a traditional gait feature-based\npredictive model in a recently released large public PD dataset, including PD\npatients on and off medication. The feature-based model currently shows higher\nweighted average accuracy, precision, recall, and F1-score. Motion encoder\nmodels with closely comparable results demonstrate promise for scalability and\nefficiency in clinical settings. This potential is underscored by the enhanced\nperformance of the encoder model upon fine-tuning on PD training set. Four of\nthe six human motion models examined provided prediction scores that were\nsignificantly different between on- and off-medication states. This finding\nreveals the sensitivity of motion encoder models to nuanced clinical changes.\nIt also underscores the necessity for continued customization of these models\nto better capture disease-specific features, thereby reducing the reliance on\nlabor-intensive feature engineering. Lastly, we establish a benchmark for the\nanalysis of skeleton-based motion encoder models in clinical settings. To the\nbest of our knowledge, this is the first study to provide a benchmark that\nenables state-of-the-art models to be tested and compete in a clinical context.\nCodes and benchmark leaderboard are available at code.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Vida Adeli",
            "Soroush Mehraban",
            "Irene Ballester",
            "Yasamin Zarghami",
            "Andrea Sabo",
            "Andrea Iaboni",
            "Babak Taati"
        ],
        "published": "2024-05-28T04:29:10Z"
    },
    {
        "title": "Pursuing Feature Separation based on Neural Collapse for\n  Out-of-Distribution Detection",
        "link": "http://arxiv.org/abs/2405.17816v1",
        "abstract": "In the open world, detecting out-of-distribution (OOD) data, whose labels are\ndisjoint with those of in-distribution (ID) samples, is important for reliable\ndeep neural networks (DNNs). To achieve better detection performance, one type\nof approach proposes to fine-tune the model with auxiliary OOD datasets to\namplify the difference between ID and OOD data through a separation loss\ndefined on model outputs. However, none of these studies consider enlarging the\nfeature disparity, which should be more effective compared to outputs. The main\ndifficulty lies in the diversity of OOD samples, which makes it hard to\ndescribe their feature distribution, let alone design losses to separate them\nfrom ID features. In this paper, we neatly fence off the problem based on an\naggregation property of ID features named Neural Collapse (NC). NC means that\nthe penultimate features of ID samples within a class are nearly identical to\nthe last layer weight of the corresponding class. Based on this property, we\npropose a simple but effective loss called OrthLoss, which binds the features\nof OOD data in a subspace orthogonal to the principal subspace of ID features\nformed by NC. In this way, the features of ID and OOD samples are separated by\ndifferent dimensions. By optimizing the feature separation loss rather than\npurely enlarging output differences, our detection achieves SOTA performance on\nCIFAR benchmarks without any additional data augmentation or sampling,\ndemonstrating the importance of feature separation in OOD detection. The code\nwill be published.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Yingwen Wu",
            "Ruiji Yu",
            "Xinwen Cheng",
            "Zhengbao He",
            "Xiaolin Huang"
        ],
        "published": "2024-05-28T04:24:38Z"
    },
    {
        "title": "Visual Anchors Are Strong Information Aggregators For Multimodal Large\n  Language Model",
        "link": "http://arxiv.org/abs/2405.17815v1",
        "abstract": "In the realm of Multimodal Large Language Models (MLLMs), vision-language\nconnector plays a crucial role to link the pre-trained vision encoders with\nLarge Language Models (LLMs). Despite its importance, the vision-language\nconnector has been relatively less explored. In this study, we aim to propose a\nstrong vision-language connector that enables MLLMs to achieve high accuracy\nwhile maintain low computation cost. We first reveal the existence of the\nvisual anchors in Vision Transformer and propose a cost-effective search\nalgorithm to extract them. Building on these findings, we introduce the Anchor\nFormer (AcFormer), a novel vision-language connector designed to leverage the\nrich prior knowledge obtained from these visual anchors during pretraining,\nguiding the aggregation of information. Through extensive experimentation, we\ndemonstrate that the proposed method significantly reduces computational costs\nby nearly two-thirds compared with baseline, while simultaneously outperforming\nbaseline methods. This highlights the effectiveness and efficiency of AcFormer.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Haogeng Liu",
            "Quanzeng You",
            "Xiaotian Han",
            "Yongfei Liu",
            "Huaibo Huang",
            "Ran He",
            "Hongxia Yang"
        ],
        "published": "2024-05-28T04:23:00Z"
    },
    {
        "title": "FAIntbench: A Holistic and Precise Benchmark for Bias Evaluation in\n  Text-to-Image Models",
        "link": "http://arxiv.org/abs/2405.17814v1",
        "abstract": "The rapid development and reduced barriers to entry for Text-to-Image (T2I)\nmodels have raised concerns about the biases in their outputs, but existing\nresearch lacks a holistic definition and evaluation framework of biases,\nlimiting the enhancement of debiasing techniques. To address this issue, we\nintroduce FAIntbench, a holistic and precise benchmark for biases in T2I\nmodels. In contrast to existing benchmarks that evaluate bias in limited\naspects, FAIntbench evaluate biases from four dimensions: manifestation of\nbias, visibility of bias, acquired attributes, and protected attributes. We\napplied FAIntbench to evaluate seven recent large-scale T2I models and\nconducted human evaluation, whose results demonstrated the effectiveness of\nFAIntbench in identifying various biases. Our study also revealed new research\nquestions about biases, including the side-effect of distillation. The findings\npresented here are preliminary, highlighting the potential of FAIntbench to\nadvance future research aimed at mitigating the biases in T2I models. Our\nbenchmark is publicly available to ensure the reproducibility.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Hanjun Luo",
            "Ziye Deng",
            "Ruizhe Chen",
            "Zuozhu Liu"
        ],
        "published": "2024-05-28T04:18:00Z"
    },
    {
        "title": "The Impacts of Data, Ordering, and Intrinsic Dimensionality on Recall in\n  Hierarchical Navigable Small Worlds",
        "link": "http://arxiv.org/abs/2405.17813v1",
        "abstract": "Vector search systems, pivotal in AI applications, often rely on the\nHierarchical Navigable Small Worlds (HNSW) algorithm. However, the behaviour of\nHNSW under real-world scenarios using vectors generated with deep learning\nmodels remains under-explored. Existing Approximate Nearest Neighbours (ANN)\nbenchmarks and research typically has an over-reliance on simplistic datasets\nlike MNIST or SIFT1M and fail to reflect the complexity of current use-cases.\nOur investigation focuses on HNSW's efficacy across a spectrum of datasets,\nincluding synthetic vectors tailored to mimic specific intrinsic\ndimensionalities, widely-used retrieval benchmarks with popular embedding\nmodels, and proprietary e-commerce image data with CLIP models. We survey the\nmost popular HNSW vector databases and collate their default parameters to\nprovide a realistic fixed parameterisation for the duration of the paper.\n  We discover that the recall of approximate HNSW search, in comparison to\nexact K Nearest Neighbours (KNN) search, is linked to the vector space's\nintrinsic dimensionality and significantly influenced by the data insertion\nsequence. Our methodology highlights how insertion order, informed by\nmeasurable properties such as the pointwise Local Intrinsic Dimensionality\n(LID) or known categories, can shift recall by up to 12 percentage points. We\nalso observe that running popular benchmark datasets with HNSW instead of KNN\ncan shift rankings by up to three positions for some models. This work\nunderscores the need for more nuanced benchmarks and design considerations in\ndeveloping robust vector search systems using approximate vector search\nalgorithms. This study presents a number of scenarios with varying real world\napplicability which aim to better increase understanding and future development\nof ANN algorithms and embedding",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Owen Pendrigh Elliott",
            "Jesse Clark"
        ],
        "published": "2024-05-28T04:16:43Z"
    },
    {
        "title": "Lyndon pairs and the lexicographically greatest perfect necklace",
        "link": "http://arxiv.org/abs/2405.17812v1",
        "abstract": "Fix a finite alphabet. A necklace is a circular word. For positive integers\n$n$ and~$k$, a necklace is $(n,k)$-perfect if all words of length $n$ occur $k$\ntimes but at positions with different congruence modulo $k$, for any convention\nof the starting position. We define the notion of a Lyndon pair and we use it\nto construct the lexicographically greatest $(n,k)$-perfect necklace, for any\n$n$ and $k$ such that $n$ divides~$k$ or $k$ divides~$n$. Our construction\ngeneralizes Fredricksen and Maiorana's construction of the lexicographically\ngreatest de Bruijn sequence of order $n$, based on the concatenation of the\nLyndon words whose length divide $n$.",
        "subjects": [
            "math.CO",
            "cs.DM",
            "Primary 68R15, 05A05, Secondary 11K16",
            "G.2.1"
        ],
        "authors": [
            "Verónica Becher",
            "Tomás Tropea"
        ],
        "published": "2024-05-28T04:15:39Z"
    },
    {
        "title": "Mani-GS: Gaussian Splatting Manipulation with Triangular Mesh",
        "link": "http://arxiv.org/abs/2405.17811v1",
        "abstract": "Neural 3D representations such as Neural Radiance Fields (NeRF), excel at\nproducing photo-realistic rendering results but lack the flexibility for\nmanipulation and editing which is crucial for content creation. Previous works\nhave attempted to address this issue by deforming a NeRF in canonical space or\nmanipulating the radiance field based on an explicit mesh. However,\nmanipulating NeRF is not highly controllable and requires a long training and\ninference time. With the emergence of 3D Gaussian Splatting (3DGS), extremely\nhigh-fidelity novel view synthesis can be achieved using an explicit\npoint-based 3D representation with much faster training and rendering speed.\nHowever, there is still a lack of effective means to manipulate 3DGS freely\nwhile maintaining rendering quality. In this work, we aim to tackle the\nchallenge of achieving manipulable photo-realistic rendering. We propose to\nutilize a triangular mesh to manipulate 3DGS directly with self-adaptation.\nThis approach reduces the need to design various algorithms for different types\nof Gaussian manipulation. By utilizing a triangle shape-aware Gaussian binding\nand adapting method, we can achieve 3DGS manipulation and preserve\nhigh-fidelity rendering after manipulation. Our approach is capable of handling\nlarge deformations, local manipulations, and soft body simulations while\nkeeping high-quality rendering. Furthermore, we demonstrate that our method is\nalso effective with inaccurate meshes extracted from 3DGS. Experiments\nconducted demonstrate the effectiveness of our method and its superiority over\nbaseline approaches.",
        "subjects": [
            "cs.GR",
            "cs.CV"
        ],
        "authors": [
            "Xiangjun Gao",
            "Xiaoyu Li",
            "Yiyu Zhuang",
            "Qi Zhang",
            "Wenbo Hu",
            "Chaopeng Zhang",
            "Yao Yao",
            "Ying Shan",
            "Long Quan"
        ],
        "published": "2024-05-28T04:13:21Z"
    },
    {
        "title": "TransVIP: Speech to Speech Translation System with Voice and Isochrony\n  Preservation",
        "link": "http://arxiv.org/abs/2405.17809v1",
        "abstract": "There is a rising interest and trend in research towards directly translating\nspeech from one language to another, known as end-to-end speech-to-speech\ntranslation. However, most end-to-end models struggle to outperform cascade\nmodels, i.e., a pipeline framework by concatenating speech recognition, machine\ntranslation and text-to-speech models. The primary challenges stem from the\ninherent complexities involved in direct translation tasks and the scarcity of\ndata. In this study, we introduce a novel model framework TransVIP that\nleverages diverse datasets in a cascade fashion yet facilitates end-to-end\ninference through joint probability. Furthermore, we propose two separated\nencoders to preserve the speaker's voice characteristics and isochrony from the\nsource speech during the translation process, making it highly suitable for\nscenarios such as video dubbing. Our experiments on the French-English language\npair demonstrate that our model outperforms the current state-of-the-art\nspeech-to-speech translation model.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Chenyang Le",
            "Yao Qian",
            "Dongmei Wang",
            "Long Zhou",
            "Shujie Liu",
            "Xiaofei Wang",
            "Midia Yousefi",
            "Yanmin Qian",
            "Jinyu Li",
            "Sheng Zhao",
            "Michael Zeng"
        ],
        "published": "2024-05-28T04:11:37Z"
    },
    {
        "title": "Detection-Correction Structure via General Language Model for\n  Grammatical Error Correction",
        "link": "http://arxiv.org/abs/2405.17804v1",
        "abstract": "Grammatical error correction (GEC) is a task dedicated to rectifying texts\nwith minimal edits, which can be decoupled into two components: detection and\ncorrection. However, previous works have predominantly focused on direct\ncorrection, with no prior efforts to integrate both into a single model.\nMoreover, the exploration of the detection-correction paradigm by large\nlanguage models (LLMs) remains underdeveloped. This paper introduces an\nintegrated detection-correction structure, named DeCoGLM, based on the General\nLanguage Model (GLM). The detection phase employs a fault-tolerant detection\ntemplate, while the correction phase leverages autoregressive mask infilling\nfor localized error correction. Through the strategic organization of input\ntokens and modification of attention masks, we facilitate multi-task learning\nwithin a single model. Our model demonstrates competitive performance against\nthe state-of-the-art models on English and Chinese GEC datasets. Further\nexperiments present the effectiveness of the detection-correction structure in\nLLMs, suggesting a promising direction for GEC.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Wei Li",
            "Houfeng Wang"
        ],
        "published": "2024-05-28T04:04:40Z"
    },
    {
        "title": "Multi-level Interaction Modeling for Protein Mutational Effect\n  Prediction",
        "link": "http://arxiv.org/abs/2405.17802v1",
        "abstract": "Protein-protein interactions are central mediators in many biological\nprocesses. Accurately predicting the effects of mutations on interactions is\ncrucial for guiding the modulation of these interactions, thereby playing a\nsignificant role in therapeutic development and drug discovery. Mutations\ngenerally affect interactions hierarchically across three levels: mutated\nresidues exhibit different sidechain conformations, which lead to changes in\nthe backbone conformation, eventually affecting the binding affinity between\nproteins. However, existing methods typically focus only on sidechain-level\ninteraction modeling, resulting in suboptimal predictions. In this work, we\npropose a self-supervised multi-level pre-training framework, ProMIM, to fully\ncapture all three levels of interactions with well-designed pretraining\nobjectives. Experiments show ProMIM outperforms all the baselines on the\nstandard benchmark, especially on mutations where significant changes in\nbackbone conformations may occur. In addition, leading results from zero-shot\nevaluations for SARS-CoV-2 mutational effect prediction and antibody\noptimization underscore the potential of ProMIM as a powerful next-generation\ntool for developing novel therapeutic approaches and new drugs.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "q-bio.BM"
        ],
        "authors": [
            "Yuanle Mo",
            "Xin Hong",
            "Bowen Gao",
            "Yinjun Jia",
            "Yanyan Lan"
        ],
        "published": "2024-05-28T03:53:26Z"
    },
    {
        "title": "Bandwidth Efficient Cache Selection and Content Advertisement",
        "link": "http://arxiv.org/abs/2405.17801v2",
        "abstract": "Caching is extensively used in various networking environments to optimize\nperformance by reducing latency, bandwidth, and energy consumption. To optimize\nperformance, caches often advertise their content using indicators, which are\ndata structures that trade space efficiency for accuracy. However, this\ntradeoff introduces the risk of false indications. Existing solutions for cache\ncontent advertisement and cache selection often lead to inefficiencies, failing\nto adapt to dynamic network conditions. This paper introduces SALSA2, a\nScalable Adaptive and Learning-based Selection and Advertisement Algorithm,\nwhich addresses these limitations through a dynamic and adaptive approach.\nSALSA2 accurately estimates mis-indication probabilities by considering\ninter-cache dependencies and dynamically adjusts the size and frequency of\nindicator advertisements to minimize transmission overhead while maintaining\nhigh accuracy. Our extensive simulation study, conducted using a variety of\nreal-world cache traces, demonstrates that SALSA2 achieves up to 84\\% bandwidth\nsavings compared to the state-of-the-art solution and close-to-optimal service\ncost in most scenarios. These results highlight SALSA2's effectiveness in\nenhancing cache management, making it a robust and versatile solution for\nmodern networking challenges.",
        "subjects": [
            "cs.NI"
        ],
        "authors": [
            "Itamar Cohen"
        ],
        "published": "2024-05-28T03:53:10Z"
    },
    {
        "title": "Exploring Activation Patterns of Parameters in Language Models",
        "link": "http://arxiv.org/abs/2405.17799v1",
        "abstract": "Most work treats large language models as black boxes without in-depth\nunderstanding of their internal working mechanism. In order to explain the\ninternal representations of LLMs, we propose a gradient-based metric to assess\nthe activation level of model parameters. Based on this metric, we obtain three\npreliminary findings. (1) When the inputs are in the same domain, parameters in\nthe shallow layers will be activated densely, which means a larger portion of\nparameters will have great impacts on the outputs. In contrast, parameters in\nthe deep layers are activated sparsely. (2) When the inputs are across\ndifferent domains, parameters in shallow layers exhibit higher similarity in\nthe activation behavior than deep layers. (3) In deep layers, the similarity of\nthe distributions of activated parameters is positively correlated to the\nempirical data relevance. Further, we develop three validation experiments to\nsolidify these findings. (1) Firstly, starting from the first finding, we\nattempt to configure different prune ratios for different layers, and find this\nmethod can benefit model pruning. (2) Secondly, we find that a pruned model\nbased on one calibration set can better handle tasks related to the calibration\ntask than those not related, which validate the second finding. (3) Thirdly,\nBased on the STS-B and SICK benchmark, we find that two sentences with\nconsistent semantics tend to share similar parameter activation patterns in\ndeep layers, which aligns with our third finding. Our work sheds light on the\nbehavior of parameter activation in LLMs, and we hope these findings will have\nthe potential to inspire more practical applications.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "authors": [
            "Yudong Wang",
            "Damai Dai",
            "Zhifang Sui"
        ],
        "published": "2024-05-28T03:49:54Z"
    },
    {
        "title": "Learn to be Fair without Labels: a Distribution-based Learning Framework\n  for Fair Ranking",
        "link": "http://dx.doi.org/10.1145/3578337.3605132",
        "abstract": "Ranking algorithms as an essential component of retrieval systems have been\nconstantly improved in previous studies, especially regarding relevance-based\nutilities. In recent years, more and more research attempts have been proposed\nregarding fairness in rankings due to increasing concerns about potential\ndiscrimination and the issue of echo chamber. These attempts include\ntraditional score-based methods that allocate exposure resources to different\ngroups using pre-defined scoring functions or selection strategies and\nlearning-based methods that learn the scoring functions based on data samples.\nLearning-based models are more flexible and achieve better performance than\ntraditional methods. However, most of the learning-based models were trained\nand tested on outdated datasets where fairness labels are barely available.\nState-of-art models utilize relevance-based utility scores as a substitute for\nthe fairness labels to train their fairness-aware loss, where plugging in the\nsubstitution does not guarantee the minimum loss. This inconsistency challenges\nthe model's accuracy and performance, especially when learning is achieved by\ngradient descent. Hence, we propose a distribution-based fair learning\nframework (DLF) that does not require labels by replacing the unavailable\nfairness labels with target fairness exposure distributions. Experimental\nstudies on TREC fair ranking track dataset confirm that our proposed framework\nachieves better fairness performance while maintaining better control over the\nfairness-relevance trade-off than state-of-art fair ranking frameworks.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Fumian Chen",
            "Hui Fang"
        ],
        "published": "2024-05-28T03:49:04Z"
    },
    {
        "title": "Offline Oracle-Efficient Learning for Contextual MDPs via Layerwise\n  Exploration-Exploitation Tradeoff",
        "link": "http://arxiv.org/abs/2405.17796v1",
        "abstract": "Motivated by the recent discovery of a statistical and computational\nreduction from contextual bandits to offline regression (Simchi-Levi and Xu,\n2021), we address the general (stochastic) Contextual Markov Decision Process\n(CMDP) problem with horizon H (as known as CMDP with H layers). In this paper,\nwe introduce a reduction from CMDPs to offline density estimation under the\nrealizability assumption, i.e., a model class M containing the true underlying\nCMDP is provided in advance. We develop an efficient, statistically\nnear-optimal algorithm requiring only O(HlogT) calls to an offline density\nestimation algorithm (or oracle) across all T rounds of interaction. This\nnumber can be further reduced to O(HloglogT) if T is known in advance. Our\nresults mark the first efficient and near-optimal reduction from CMDPs to\noffline density estimation without imposing any structural assumptions on the\nmodel class. A notable feature of our algorithm is the design of a layerwise\nexploration-exploitation tradeoff tailored to address the layerwise structure\nof CMDPs. Additionally, our algorithm is versatile and applicable to pure\nexploration tasks in reward-free reinforcement learning.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Jian Qian",
            "Haichen Hu",
            "David Simchi-Levi"
        ],
        "published": "2024-05-28T03:47:41Z"
    },
    {
        "title": "Dataset Regeneration for Sequential Recommendation",
        "link": "http://arxiv.org/abs/2405.17795v1",
        "abstract": "The sequential recommender (SR) system is a crucial component of modern\nrecommender systems, as it aims to capture the evolving preferences of users.\nSignificant efforts have been made to enhance the capabilities of SR systems.\nThese methods typically follow the \\textbf{model-centric} paradigm, which\ninvolves developing effective models based on fixed datasets. However, this\napproach often overlooks potential quality issues and flaws inherent in the\ndata. Driven by the potential of \\textbf{data-centric} AI, we propose a novel\ndata-centric paradigm for developing an ideal training dataset using a\nmodel-agnostic dataset regeneration framework called DR4SR. This framework\nenables the regeneration of a dataset with exceptional cross-architecture\ngeneralizability. Additionally, we introduce the DR4SR+ framework, which\nincorporates a model-aware dataset personalizer to tailor the regenerated\ndataset specifically for a target model. To demonstrate the effectiveness of\nthe data-centric paradigm, we integrate our framework with various\nmodel-centric methods and observe significant performance improvements across\nfour widely adopted datasets. Furthermore, we conduct in-depth analyses to\nexplore the potential of the data-centric paradigm and provide valuable\ninsights. The code can be found at\n\\textcolor{blue}{\\url{https://anonymous.4open.science/r/KDD2024-86EA/}}",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Mingjia Yin",
            "Hao Wang",
            "Wei Guo",
            "Yong Liu",
            "Suojuan Zhang",
            "Sirui Zhao",
            "Defu Lian",
            "Enhong Chen"
        ],
        "published": "2024-05-28T03:45:34Z"
    },
    {
        "title": "LNS2+RL: Combining Multi-agent Reinforcement Learning with Large\n  Neighborhood Search in Multi-agent Path Finding",
        "link": "http://arxiv.org/abs/2405.17794v1",
        "abstract": "Multi-Agent Path Finding (MAPF) is a critical component of logistics and\nwarehouse management, which focuses on planning collision-free paths for a team\nof robots in a known environment. Recent work introduced a novel MAPF approach,\nLNS2, which proposed to repair a quickly-obtainable set of infeasible paths via\niterative re-planning, by relying on a fast, yet lower-quality, priority-based\nplanner. At the same time, there has been a recent push for Multi-Agent\nReinforcement Learning (MARL) based MAPF algorithms, which let agents learn\ndecentralized policies that exhibit improved cooperation over such priority\nplanning, although inevitably remaining slower. In this paper, we introduce a\nnew MAPF algorithm, LNS2+RL, which combines the distinct yet complementary\ncharacteristics of LNS2 and MARL to effectively balance their individual\nlimitations and get the best from both worlds. During early iterations, LNS2+RL\nrelies on MARL for low-level re-planning, which we show eliminates collisions\nmuch more than a priority-based planner. There, our MARL-based planner allows\nagents to reason about past and future/predicted information to gradually learn\ncooperative decision-making through a finely designed curriculum learning. At\nlater stages of planning, LNS2+RL adaptively switches to priority-based\nplanning to quickly resolve the remaining collisions, naturally trading-off\nsolution quality and computational efficiency. Our comprehensive experiments on\nchallenging tasks across various team sizes, world sizes, and map structures\nconsistently demonstrate the superior performance of LNS2+RL compared to many\nMAPF algorithms, including LNS2, LaCAM, and EECBS, where LNS2+RL shows\nsignificantly better performance in complex scenarios. We finally\nexperimentally validate our algorithm in a hybrid simulation of a warehouse\nmockup involving a team of 100 (real-world and simulated) robots.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Yutong Wang",
            "Tanishq Duhan",
            "Jiaoyang Li",
            "Guillaume Sartoretti"
        ],
        "published": "2024-05-28T03:45:32Z"
    },
    {
        "title": "SafeguardGS: 3D Gaussian Primitive Pruning While Avoiding Catastrophic\n  Scene Destruction",
        "link": "http://arxiv.org/abs/2405.17793v1",
        "abstract": "3D Gaussian Splatting (3DGS) has made a significant stride in novel view\nsynthesis, demonstrating top-notch rendering quality while achieving real-time\nrendering speed. However, the excessively large number of Gaussian primitives\nresulting from 3DGS' suboptimal densification process poses a major challenge,\nslowing down frame-per-second (FPS) and demanding considerable memory cost,\nmaking it unfavorable for low-end devices. To cope with this issue, many\nfollow-up studies have suggested various pruning techniques, often in\ncombination with different score functions, to optimize rendering performance.\nNonetheless, a comprehensive discussion regarding their effectiveness and\nimplications across all techniques is missing. In this paper, we first\ncategorize 3DGS pruning techniques into two types: Cross-view pruning and\npixel-wise pruning, which differ in their approaches to rank primitives. Our\nsubsequent experiments reveal that while cross-view pruning leads to disastrous\nquality drops under extreme Gaussian primitives decimation, the pixel-wise\npruning technique not only sustains relatively high rendering quality with\nminuscule performance degradation but also provides a reasonable minimum\nboundary for pruning. Building on this observation, we further propose multiple\nvariations of score functions and empirically discover that the color-weighted\nscore function outperforms others for discriminating insignificant primitives\nfor rendering. We believe our research provides valuable insights for\noptimizing 3DGS pruning strategies for future works.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yongjae Lee",
            "Zhaoliang Zhang",
            "Deliang Fan"
        ],
        "published": "2024-05-28T03:41:36Z"
    },
    {
        "title": "Instruct-ReID++: Towards Universal Purpose Instruction-Guided Person\n  Re-identification",
        "link": "http://arxiv.org/abs/2405.17790v1",
        "abstract": "Human intelligence can retrieve any person according to both visual and\nlanguage descriptions. However, the current computer vision community studies\nspecific person re-identification (ReID) tasks in different scenarios\nseparately, which limits the applications in the real world. This paper strives\nto resolve this problem by proposing a novel instruct-ReID task that requires\nthe model to retrieve images according to the given image or language\ninstructions. Instruct-ReID is the first exploration of a general ReID setting,\nwhere existing 6 ReID tasks can be viewed as special cases by assigning\ndifferent instructions. To facilitate research in this new instruct-ReID task,\nwe propose a large-scale OmniReID++ benchmark equipped with diverse data and\ncomprehensive evaluation methods e.g., task specific and task-free evaluation\nsettings. In the task-specific evaluation setting, gallery sets are categorized\naccording to specific ReID tasks. We propose a novel baseline model, IRM, with\nan adaptive triplet loss to handle various retrieval tasks within a unified\nframework. For task-free evaluation setting, where target person images are\nretrieved from task-agnostic gallery sets, we further propose a new method\ncalled IRM++ with novel memory bank-assisted learning. Extensive evaluations of\nIRM and IRM++ on OmniReID++ benchmark demonstrate the superiority of our\nproposed methods, achieving state-of-the-art performance on 10 test sets. The\ndatasets, the model, and the code will be available at\nhttps://github.com/hwz-zju/Instruct-ReID",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Weizhen He",
            "Yiheng Deng",
            "Yunfeng Yan",
            "Feng Zhu",
            "Yizhou Wang",
            "Lei Bai",
            "Qingsong Xie",
            "Donglian Qi",
            "Wanli Ouyang",
            "Shixiang Tang"
        ],
        "published": "2024-05-28T03:35:46Z"
    },
    {
        "title": "On the Downlink Average Energy Efficiency of Non-Stationary XL-MIMO",
        "link": "http://arxiv.org/abs/2405.17789v2",
        "abstract": "Extra large-scale multiple-input multiple-output (XL-MIMO) is a key\ntechnology for future wireless communication systems. This paper considers the\neffects of visibility region (VR) at the base station (BS) in a non-stationary\nmulti-user XL-MIMO scenario, where only partial antennas can receive users'\nsignal. In time division duplexing (TDD) mode, we first estimate the VR at the\nBS by detecting the energy of the received signal during uplink training phase.\nThe probabilities of two detection errors are derived and the uplink channel on\nthe detected VR is estimated. In downlink data transmission, to avoid\ncumbersome Monte-Carlo trials, we derive a deterministic approximate expression\nfor ergodic {average energy efficiency (EE)} with the regularized zero-forcing\n(RZF) precoding. In frequency division duplexing (FDD) mode, the VR is\nestimated in uplink training and then the channel information of detected VR is\nacquired from the feedback channel. In downlink data transmission, the\napproximation of ergodic average {EE} is also derived with the RZF precoding.\nInvoking approximate results, we propose an alternate optimization algorithm to\ndesign the detection threshold and the pilot length in both TDD and FDD modes.\nThe numerical results reveal the impacts of VR estimation error on ergodic\naverage {EE} and demonstrate the effectiveness of our proposed algorithm.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Jun Zhang",
            "Jiacheng Lu",
            "Jingjing Zhang",
            "Yu Han",
            "Jue Wang",
            "Shi Jin"
        ],
        "published": "2024-05-28T03:35:41Z"
    },
    {
        "title": "Enhancing Road Safety: Real-Time Detection of Driver Distraction through\n  Convolutional Neural Networks",
        "link": "http://arxiv.org/abs/2405.17788v1",
        "abstract": "As we navigate our daily commutes, the threat posed by a distracted driver is\nat a large, resulting in a troubling rise in traffic accidents. Addressing this\nsafety concern, our project harnesses the analytical power of Convolutional\nNeural Networks (CNNs), with a particular emphasis on the well-established\nmodels VGG16 and VGG19. These models are acclaimed for their precision in image\nrecognition and are meticulously tested for their ability to detect nuances in\ndriver behavior under varying environmental conditions. Through a comparative\nanalysis against an array of CNN architectures, this study seeks to identify\nthe most efficient model for real-time detection of driver distractions. The\nultimate aim is to incorporate the findings into vehicle safety systems,\nsignificantly boosting their capability to prevent accidents triggered by\ninattention. This research not only enhances our understanding of automotive\nsafety technologies but also marks a pivotal step towards creating vehicles\nthat are intuitively aligned with driver behaviors, ensuring safer roads for\nall.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Amaan Aijaz Sheikh",
            "Imaad Zaffar Khan"
        ],
        "published": "2024-05-28T03:34:55Z"
    },
    {
        "title": "Adaptive Horizon Actor-Critic for Policy Learning in Contact-Rich\n  Differentiable Simulation",
        "link": "http://arxiv.org/abs/2405.17784v1",
        "abstract": "Model-Free Reinforcement Learning~(MFRL), leveraging the policy gradient\ntheorem, has demonstrated considerable success in continuous control tasks.\nHowever, these approaches are plagued by high gradient variance due to\nzeroth-order gradient estimation, resulting in suboptimal policies. Conversely,\nFirst-Order Model-Based Reinforcement Learning~(FO-MBRL) methods, employing\ndifferentiable simulation, provide gradients with reduced variance but are\nsusceptible to sampling error in scenarios involving stiff dynamics, such as\nphysical contact. This paper investigates the source of this error and\nintroduces Adaptive Horizon Actor-Critic (AHAC), an FO-MBRL algorithm that\nreduces gradient error by adapting the model-based horizon to avoid stiff\ndynamics. Empirical findings reveal that AHAC outperforms MFRL baselines,\nattaining 40\\% more reward across a set of locomotion tasks, and efficiently\nscaling to high-dimensional control environments with improved wall-clock-time\nefficiency.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Ignat Georgiev",
            "Krishnan Srinivasan",
            "Jie Xu",
            "Eric Heiden",
            "Animesh Garg"
        ],
        "published": "2024-05-28T03:28:00Z"
    },
    {
        "title": "Post-Fair Federated Learning: Achieving Group and Community Fairness in\n  Federated Learning via Post-processing",
        "link": "http://arxiv.org/abs/2405.17782v1",
        "abstract": "Federated Learning (FL) is a distributed machine learning framework in which\na set of local communities collaboratively learn a shared global model while\nretaining all training data locally within each community. Two notions of\nfairness have recently emerged as important issues for federated learning:\ngroup fairness and community fairness. Group fairness requires that a model's\ndecisions do not favor any particular group based on a set of legally protected\nattributes such as race or gender. Community fairness requires that global\nmodels exhibit similar levels of performance (accuracy) across all\ncollaborating communities. Both fairness concepts can coexist within an FL\nframework, but the existing literature has focused on either one concept or the\nother. This paper proposes and analyzes a post-processing fair federated\nlearning (FFL) framework called post-FFL. Post-FFL uses a linear program to\nsimultaneously enforce group and community fairness while maximizing the\nutility of the global model. Because Post-FFL is a post-processing approach, it\ncan be used with existing FL training pipelines whose convergence properties\nare well understood. This paper uses post-FFL on real-world datasets to mimic\nhow hospital networks, for example, use federated learning to deliver community\nhealth care. Theoretical results bound the accuracy lost when post-FFL enforces\nboth notion of fairness. Experimental results illustrate that post-FFL\nsimultaneously improves both group and community fairness in FL. Moreover,\npost-FFL outperforms the existing in-processing fair federated learning in\nterms of improving both notions of fairness, communication efficiency and\ncomputation cost.",
        "subjects": [
            "cs.LG",
            "cs.CY"
        ],
        "authors": [
            "Yuying Duan",
            "Yijun Tian",
            "Nitesh Chawla",
            "Michael Lemmon"
        ],
        "published": "2024-05-28T03:26:00Z"
    },
    {
        "title": "Unmasking Vulnerabilities: Cardinality Sketches under Adaptive Inputs",
        "link": "http://arxiv.org/abs/2405.17780v1",
        "abstract": "Cardinality sketches are popular data structures that enhance the efficiency\nof working with large data sets. The sketches are randomized representations of\nsets that are only of logarithmic size but can support set merges and\napproximate cardinality (i.e., distinct count) queries. When queries are not\nadaptive, that is, they do not depend on preceding query responses, the design\nprovides strong guarantees of correctly answering a number of queries\nexponential in the sketch size $k$.\n  In this work, we investigate the performance of cardinality sketches in\nadaptive settings and unveil inherent vulnerabilities. We design an attack\nagainst the ``standard'' estimators that constructs an adversarial input by\npost-processing responses to a set of simple non-adaptive queries of size\nlinear in the sketch size $k$. Empirically, our attack used only $4k$ queries\nwith the widely used HyperLogLog\n(HLL++)~\\citep{hyperloglog:2007,hyperloglogpractice:EDBT2013} sketch. The\nsimple attack technique suggests it can be effective with post-processed\nnatural workloads. Finally and importantly, we demonstrate that the\nvulnerability is inherent as \\emph{any} estimator applied to known sketch\nstructures can be attacked using a number of queries that is quadratic in $k$,\nmatching a generic upper bound.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Sara Ahmadian",
            "Edith Cohen"
        ],
        "published": "2024-05-28T03:20:05Z"
    },
    {
        "title": "Online Analytic Exemplar-Free Continual Learning with Large Models for\n  Imbalanced Autonomous Driving Task",
        "link": "http://arxiv.org/abs/2405.17779v1",
        "abstract": "In the field of autonomous driving, even a meticulously trained model can\nencounter failures when faced with unfamiliar sceanrios. One of these scenarios\ncan be formulated as an online continual learning (OCL) problem. That is, data\ncome in an online fashion, and models are updated according to these streaming\ndata. Two major OCL challenges are catastrophic forgetting and data imbalance.\nTo address these challenges, in this paper, we propose an Analytic\nExemplar-Free Online Continual Learning (AEF-OCL). The AEF-OCL leverages\nanalytic continual learning principles and employs ridge regression as a\nclassifier for features extracted by a large backbone network. It solves the\nOCL problem by recursively calculating the analytical solution, ensuring an\nequalization between the continual learning and its joint-learning counterpart,\nand works without the need to save any used samples (i.e., exemplar-free).\nAdditionally, we introduce a Pseudo-Features Generator (PFG) module that\nrecursively estimates the deviation of real features. The PFG generates offset\npseudo-features following a normal distribution, thereby addressing the data\nimbalance issue. Experimental results demonstrate that despite being an\nexemplar-free strategy, our method outperforms various methods on the\nautonomous driving SODA10M dataset. Source code is available at\nhttps://github.com/ZHUANGHP/Analytic-continual-learning.",
        "subjects": [
            "cs.LG",
            "cs.RO"
        ],
        "authors": [
            "Huiping Zhuang",
            "Di Fang",
            "Kai Tong",
            "Yuchen Liu",
            "Ziqian Zeng",
            "Xu Zhou",
            "Cen Chen"
        ],
        "published": "2024-05-28T03:19:15Z"
    },
    {
        "title": "RREH: Reconstruction Relations Embedded Hashing for Semi-Paired\n  Cross-Modal Retrieval",
        "link": "http://arxiv.org/abs/2405.17777v1",
        "abstract": "Known for efficient computation and easy storage, hashing has been\nextensively explored in cross-modal retrieval. The majority of current hashing\nmodels are predicated on the premise of a direct one-to-one mapping between\ndata points. However, in real practice, data correspondence across modalities\nmay be partially provided. In this research, we introduce an innovative\nunsupervised hashing technique designed for semi-paired cross-modal retrieval\ntasks, named Reconstruction Relations Embedded Hashing (RREH). RREH assumes\nthat multi-modal data share a common subspace. For paired data, RREH explores\nthe latent consistent information of heterogeneous modalities by seeking a\nshared representation. For unpaired data, to effectively capture the latent\ndiscriminative features, the high-order relationships between unpaired data and\nanchors are embedded into the latent subspace, which are computed by efficient\nlinear reconstruction. The anchors are sampled from paired data, which improves\nthe efficiency of hash learning. The RREH trains the underlying features and\nthe binary encodings in a unified framework with high-order reconstruction\nrelations preserved. With the well devised objective function and discrete\noptimization algorithm, RREH is designed to be scalable, making it suitable for\nlarge-scale datasets and facilitating efficient cross-modal retrieval. In the\nevaluation process, the proposed is tested with partially paired data to\nestablish its superiority over several existing methods.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Jianzong Wang",
            "Haoxiang Shi",
            "Kaiyi Luo",
            "Xulong Zhang",
            "Ning Cheng",
            "Jing Xiao"
        ],
        "published": "2024-05-28T03:12:54Z"
    },
    {
        "title": "The Binary Quantized Neural Network for Dense Prediction via Specially\n  Designed Upsampling and Attention",
        "link": "http://arxiv.org/abs/2405.17776v1",
        "abstract": "Deep learning-based information processing consumes long time and requires\nhuge computing resources, especially for dense prediction tasks which require\nan output for each pixel, like semantic segmentation and salient object\ndetection. There are mainly two challenges for quantization of dense prediction\ntasks. Firstly, directly applying the upsampling operation that dense\nprediction tasks require is extremely crude and causes unacceptable accuracy\nreduction. Secondly, the complex structure of dense prediction networks means\nit is difficult to maintain a fast speed as well as a high accuracy when\nperforming quantization. In this paper, we propose an effective upsampling\nmethod and an efficient attention computation strategy to transfer the success\nof the binary neural networks (BNN) from single prediction tasks to dense\nprediction tasks. Firstly, we design a simple and robust multi-branch parallel\nupsampling structure to achieve the high accuracy. Then we further optimize the\nattention method which plays an important role in segmentation but has huge\ncomputation complexity. Our attention method can reduce the computational\ncomplexity by a factor of one hundred times but retain the original effect.\nExperiments on Cityscapes, KITTI road, and ECSSD fully show the effectiveness\nof our work.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Xingyu Ding",
            "Lianlei Shan",
            "Guiqin Zhao",
            "Meiqi Wu",
            "Wenzhang Zhou",
            "Wei Li"
        ],
        "published": "2024-05-28T03:12:33Z"
    },
    {
        "title": "Adaptive Multiscale Retinal Diagnosis: A Hybrid Trio-Model Approach for\n  Comprehensive Fundus Multi-Disease Detection Leveraging Transfer Learning and\n  Siamese Networks",
        "link": "http://arxiv.org/abs/2405.18449v1",
        "abstract": "WHO has declared that more than 2.2 billion people worldwide are suffering\nfrom visual disorders, such as media haze, glaucoma, and drusen. At least 1\nbillion of these cases could have been either prevented or successfully\ntreated, yet they remain unaddressed due to poverty, a lack of specialists,\ninaccurate ocular fundus diagnoses by ophthalmologists, or the presence of a\nrare disease. To address this, the research has developed the Hybrid\nTrio-Network Model Algorithm for accurately diagnosing 12 distinct common and\nrare eye diseases. This algorithm utilized the RFMiD dataset of 3,200 fundus\nimages and the Binary Relevance Method to detect diseases separately, ensuring\nexpandability and avoiding incorrect correlations. Each detector, incorporating\nfinely tuned hyperparameters to optimize performance, consisted of three\nfeature components: A classical transfer learning CNN model, a two-stage CNN\nmodel, and a Siamese Network. The diagnosis was made using features extracted\nthrough this Trio-Model with Ensembled Machine Learning algorithms. The\nproposed model achieved an average accuracy of 97% and an AUC score of 0.96.\nCompared to past benchmark studies, an increase of over 10% in the F1-score was\nobserved for most diseases. Furthermore, using the Siamese Network, the model\nsuccessfully made predictions in diseases like optic disc pallor, which past\nstudies failed to predict due to low confidence. This diagnostic tool presents\na stable, adaptive, cost-effective, efficient, accessible, and fast solution\nfor globalizing early detection of both common and rare diseases.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Yavuz Selim Inan"
        ],
        "published": "2024-05-28T03:06:10Z"
    },
    {
        "title": "Gradually Vanishing Gap in Prototypical Network for Unsupervised Domain\n  Adaptation",
        "link": "http://arxiv.org/abs/2405.17774v1",
        "abstract": "Unsupervised domain adaptation (UDA) is a critical problem for transfer\nlearning, which aims to transfer the semantic information from labeled source\ndomain to unlabeled target domain. Recent advancements in UDA models have\ndemonstrated significant generalization capabilities on the target domain.\nHowever, the generalization boundary of UDA models remains unclear. When the\ndomain discrepancy is too large, the model can not preserve the distribution\nstructure, leading to distribution collapse during the alignment. To address\nthis challenge, we propose an efficient UDA framework named Gradually Vanishing\nGap in Prototypical Network (GVG-PN), which achieves transfer learning from\nboth global and local perspectives. From the global alignment standpoint, our\nmodel generates a domain-biased intermediate domain that helps preserve the\ndistribution structures. By entangling cross-domain features, our model\nprogressively reduces the risk of distribution collapse. However, only relying\non global alignment is insufficient to preserve the distribution structure. To\nfurther enhance the inner relationships of features, we introduce the local\nperspective. We utilize the graph convolutional network (GCN) as an intuitive\nmethod to explore the internal relationships between features, ensuring the\npreservation of manifold structures and generating domain-biased prototypes.\nAdditionally, we consider the discriminability of the inner relationships\nbetween features. We propose a pro-contrastive loss to enhance the\ndiscriminability at the prototype level by separating hard negative pairs. By\nincorporating both GCN and the pro-contrastive loss, our model fully explores\nfine-grained semantic relationships. Experiments on several UDA benchmarks\nvalidated that the proposed GVG-PN can clearly outperform the SOTA models.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Shanshan Wang",
            "Hao Zhou",
            "Xun Yang",
            "Zhenwei He",
            "Mengzhu Wang",
            "Xingyi Zhang",
            "Meng Wang"
        ],
        "published": "2024-05-28T03:03:32Z"
    },
    {
        "title": "Towards a Generalist and Blind RGB-X Tracker",
        "link": "http://arxiv.org/abs/2405.17773v1",
        "abstract": "With the emergence of a single large model capable of successfully solving a\nmultitude of tasks in NLP, there has been growing research interest in\nachieving similar goals in computer vision. On the one hand, most of these\ngeneric models, referred to as generalist vision models, aim at producing\nunified outputs serving different tasks. On the other hand, some existing\nmodels aim to combine different input types (aka data modalities), which are\nthen processed by a single large model. Yet, this step of combination remains\nspecialized, which falls short of serving the initial ambition. In this paper,\nwe showcase that such specialization (during unification) is unnecessary, in\nthe context of RGB-X video object tracking. Our single model tracker, termed\nXTrack, can remain blind to any modality X during inference time. Our tracker\nemploys a mixture of modal experts comprising those dedicated to shared\ncommonality and others capable of flexibly performing reasoning conditioned on\ninput modality. Such a design ensures the unification of input modalities\ntowards a common latent space, without weakening the modality-specific\ninformation representation. With this idea, our training process is extremely\nsimple, integrating multi-label classification loss with a routing function,\nthereby effectively aligning and unifying all modalities together, even from\nonly paired data. Thus, during inference, we can adopt any modality without\nrelying on the inductive bias of the modal prior and achieve generalist\nperformance. Without any bells and whistles, our generalist and blind tracker\ncan achieve competitive performance compared to well-established modal-specific\nmodels on 5 benchmarks across 3 auxiliary modalities, covering commonly used\ndepth, thermal, and event data.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yuedong Tan",
            "Zongwei Wu",
            "Yuqian Fu",
            "Zhuyun Zhou",
            "Guolei Sun",
            "Chao Ma",
            "Danda Pani Paudel",
            "Luc Van Gool",
            "Radu Timofte"
        ],
        "published": "2024-05-28T03:00:58Z"
    },
    {
        "title": "Microsaccade-inspired Event Camera for Robotics",
        "link": "http://arxiv.org/abs/2405.17769v1",
        "abstract": "Neuromorphic vision sensors or event cameras have made the visual perception\nof extremely low reaction time possible, opening new avenues for high-dynamic\nrobotics applications. These event cameras' output is dependent on both motion\nand texture. However, the event camera fails to capture object edges that are\nparallel to the camera motion. This is a problem intrinsic to the sensor and\ntherefore challenging to solve algorithmically. Human vision deals with\nperceptual fading using the active mechanism of small involuntary eye\nmovements, the most prominent ones called microsaccades. By moving the eyes\nconstantly and slightly during fixation, microsaccades can substantially\nmaintain texture stability and persistence. Inspired by microsaccades, we\ndesigned an event-based perception system capable of simultaneously maintaining\nlow reaction time and stable texture. In this design, a rotating wedge prism\nwas mounted in front of the aperture of an event camera to redirect light and\ntrigger events. The geometrical optics of the rotating wedge prism allows for\nalgorithmic compensation of the additional rotational motion, resulting in a\nstable texture appearance and high informational output independent of external\nmotion. The hardware device and software solution are integrated into a system,\nwhich we call Artificial MIcrosaccade-enhanced EVent camera (AMI-EV). Benchmark\ncomparisons validate the superior data quality of AMI-EV recordings in\nscenarios where both standard cameras and event cameras fail to deliver.\nVarious real-world experiments demonstrate the potential of the system to\nfacilitate robotics perception both for low-level and high-level vision tasks.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "authors": [
            "Botao He",
            "Ze Wang",
            "Yuan Zhou",
            "Jingxi Chen",
            "Chahat Deep Singh",
            "Haojia Li",
            "Yuman Gao",
            "Shaojie Shen",
            "Kaiwei Wang",
            "Yanjun Cao",
            "Chao Xu",
            "Yiannis Aloimonos",
            "Fei Gao",
            "Cornelia Fermuller"
        ],
        "published": "2024-05-28T02:49:46Z"
    },
    {
        "title": "Revisiting the Message Passing in Heterophilous Graph Neural Networks",
        "link": "http://arxiv.org/abs/2405.17768v1",
        "abstract": "Graph Neural Networks (GNNs) have demonstrated strong performance in graph\nmining tasks due to their message-passing mechanism, which is aligned with the\nhomophily assumption that adjacent nodes exhibit similar behaviors. However, in\nmany real-world graphs, connected nodes may display contrasting behaviors,\ntermed as heterophilous patterns, which has attracted increased interest in\nheterophilous GNNs (HTGNNs). Although the message-passing mechanism seems\nunsuitable for heterophilous graphs due to the propagation of class-irrelevant\ninformation, it is still widely used in many existing HTGNNs and consistently\nachieves notable success. This raises the question: why does message passing\nremain effective on heterophilous graphs? To answer this question, in this\npaper, we revisit the message-passing mechanisms in heterophilous graph neural\nnetworks and reformulate them into a unified heterophilious message-passing\n(HTMP) mechanism. Based on HTMP and empirical analysis, we reveal that the\nsuccess of message passing in existing HTGNNs is attributed to implicitly\nenhancing the compatibility matrix among classes. Moreover, we argue that the\nfull potential of the compatibility matrix is not completely achieved due to\nthe existence of incomplete and noisy semantic neighborhoods in real-world\nheterophilous graphs. To bridge this gap, we introduce a new approach named\nCMGNN, which operates within the HTMP mechanism to explicitly leverage and\nimprove the compatibility matrix. A thorough evaluation involving 10 benchmark\ndatasets and comparative analysis against 13 well-established baselines\nhighlights the superior performance of the HTMP mechanism and CMGNN method.",
        "subjects": [
            "cs.LG",
            "cs.SI"
        ],
        "authors": [
            "Zhuonan Zheng",
            "Yuanchen Bei",
            "Sheng Zhou",
            "Yao Ma",
            "Ming Gu",
            "HongJia XU",
            "Chengyu Lai",
            "Jiawei Chen",
            "Jiajun Bu"
        ],
        "published": "2024-05-28T02:47:53Z"
    },
    {
        "title": "Linguistic Collapse: Neural Collapse in (Large) Language Models",
        "link": "http://arxiv.org/abs/2405.17767v1",
        "abstract": "Neural collapse ($\\mathcal{NC}$) is a phenomenon observed in classification\ntasks where top-layer representations collapse into their class means, which\nbecome equinorm, equiangular and aligned with the classifiers. These behaviors\n-- associated with generalization and robustness -- would manifest under\nspecific conditions: models are trained towards zero loss, with noise-free\nlabels belonging to balanced classes, which do not outnumber the model's hidden\ndimension. Recent studies have explored $\\mathcal{NC}$ in the absence of one or\nmore of these conditions to extend and capitalize on the associated benefits of\nideal geometries. Language modeling presents a curious frontier, as\n\\textit{training by token prediction} constitutes a classification task where\nnone of the conditions exist: the vocabulary is imbalanced and exceeds the\nembedding dimension; different tokens might correspond to similar contextual\nembeddings; and large language models (LLMs) in particular are typically only\ntrained for a few epochs. This paper empirically investigates the impact of\nscaling the architectures and training of causal language models (CLMs) on\ntheir progression towards $\\mathcal{NC}$. We find that $\\mathcal{NC}$\nproperties that develop with scaling are linked to generalization. Moreover,\nthere is evidence of some relationship between $\\mathcal{NC}$ and\ngeneralization independent of scale. Our work therefore underscores the\ngenerality of $\\mathcal{NC}$ as it extends to the novel and more challenging\nsetting of language modeling. Downstream, we seek to inspire further research\non the phenomenon to deepen our understanding of LLMs -- and neural networks at\nlarge -- and improve existing architectures based on $\\mathcal{NC}$-related\nproperties.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "stat.ML",
            "68T07 (Primary) 68T50 (Secondary)",
            "I.2.6; I.2.7"
        ],
        "authors": [
            "Robert Wu",
            "Vardan Papyan"
        ],
        "published": "2024-05-28T02:46:11Z"
    },
    {
        "title": "SleepFM: Multi-modal Representation Learning for Sleep Across Brain\n  Activity, ECG and Respiratory Signals",
        "link": "http://arxiv.org/abs/2405.17766v1",
        "abstract": "Sleep is a complex physiological process evaluated through various modalities\nrecording electrical brain, cardiac, and respiratory activities. We curate a\nlarge polysomnography dataset from over 14,000 participants comprising over\n100,000 hours of multi-modal sleep recordings. Leveraging this extensive\ndataset, we developed SleepFM, the first multi-modal foundation model for sleep\nanalysis. We show that a novel leave-one-out approach for contrastive learning\nsignificantly improves downstream task performance compared to representations\nfrom standard pairwise contrastive learning. A logistic regression model\ntrained on SleepFM's learned embeddings outperforms an end-to-end trained\nconvolutional neural network (CNN) on sleep stage classification (macro AUROC\n0.88 vs 0.72 and macro AUPRC 0.72 vs 0.48) and sleep disordered breathing\ndetection (AUROC 0.85 vs 0.69 and AUPRC 0.77 vs 0.61). Notably, the learned\nembeddings achieve 48% top-1 average accuracy in retrieving the corresponding\nrecording clips of other modalities from 90,000 candidates. This work\ndemonstrates the value of holistic multi-modal sleep modeling to fully capture\nthe richness of sleep recordings. SleepFM is open source and available at\nhttps://github.com/rthapa84/sleepfm-codebase.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "eess.SP"
        ],
        "authors": [
            "Rahul Thapa",
            "Bryan He",
            "Magnus Ruud Kjaer",
            "Hyatt Moore",
            "Gauri Ganjoo",
            "Emmanuel Mignot",
            "James Zou"
        ],
        "published": "2024-05-28T02:43:53Z"
    },
    {
        "title": "PTM-VQA: Efficient Video Quality Assessment Leveraging Diverse\n  PreTrained Models from the Wild",
        "link": "http://arxiv.org/abs/2405.17765v1",
        "abstract": "Video quality assessment (VQA) is a challenging problem due to the numerous\nfactors that can affect the perceptual quality of a video, \\eg, content\nattractiveness, distortion type, motion pattern, and level. However, annotating\nthe Mean opinion score (MOS) for videos is expensive and time-consuming, which\nlimits the scale of VQA datasets, and poses a significant obstacle for deep\nlearning-based methods. In this paper, we propose a VQA method named PTM-VQA,\nwhich leverages PreTrained Models to transfer knowledge from models pretrained\non various pre-tasks, enabling benefits for VQA from different aspects.\n  Specifically, we extract features of videos from different pretrained models\nwith frozen weights and integrate them to generate representation. Since these\nmodels possess various fields of knowledge and are often trained with labels\nirrelevant to quality, we propose an Intra-Consistency and Inter-Divisibility\n(ICID) loss to impose constraints on features extracted by multiple pretrained\nmodels. The intra-consistency constraint ensures that features extracted by\ndifferent pretrained models are in the same unified quality-aware latent space,\nwhile the inter-divisibility introduces pseudo clusters based on the annotation\nof samples and tries to separate features of samples from different clusters.\nFurthermore, with a constantly growing number of pretrained models, it is\ncrucial to determine which models to use and how to use them. To address this\nproblem, we propose an efficient scheme to select suitable candidates. Models\nwith better clustering performance on VQA datasets are chosen to be our\ncandidates. Extensive experiments demonstrate the effectiveness of the proposed\nmethod.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Kun Yuan",
            "Hongbo Liu",
            "Mading Li",
            "Muyi Sun",
            "Ming Sun",
            "Jiachao Gong",
            "Jinhua Hao",
            "Chao Zhou",
            "Yansong Tang"
        ],
        "published": "2024-05-28T02:37:29Z"
    },
    {
        "title": "On the Sequence Evaluation based on Stochastic Processes",
        "link": "http://arxiv.org/abs/2405.17764v1",
        "abstract": "Modeling and analyzing long sequences of text is an essential task for\nNatural Language Processing. Success in capturing long text dynamics using\nneural language models will facilitate many downstream tasks such as coherence\nevaluation, text generation, machine translation and so on. This paper presents\na novel approach to model sequences through a stochastic process. We introduce\na likelihood-based training objective for the text encoder and design a more\nthorough measurement (score) for long text evaluation compared to the previous\napproach. The proposed training objective effectively preserves the sequence\ncoherence, while the new score comprehensively captures both temporal and\nspatial dependencies. Theoretical properties of our new score show its\nadvantages in sequence evaluation. Experimental results show superior\nperformance in various sequence evaluation tasks, including global and local\ndiscrimination within and between documents of different lengths. We also\ndemonstrate the encoder achieves competitive results on discriminating human\nand AI written text.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "math.ST",
            "stat.TH"
        ],
        "authors": [
            "Tianhao Zhang",
            "Zhexiao Lin",
            "Zhecheng Sheng",
            "Chen Jiang",
            "Dongyeop Kang"
        ],
        "published": "2024-05-28T02:33:38Z"
    },
    {
        "title": "Double Variance Reduction: A Smoothing Trick for Composite Optimization\n  Problems without First-Order Gradient",
        "link": "http://arxiv.org/abs/2405.17761v1",
        "abstract": "Variance reduction techniques are designed to decrease the sampling variance,\nthereby accelerating convergence rates of first-order (FO) and zeroth-order\n(ZO) optimization methods. However, in composite optimization problems, ZO\nmethods encounter an additional variance called the coordinate-wise variance,\nwhich stems from the random gradient estimation. To reduce this variance, prior\nworks require estimating all partial derivatives, essentially approximating FO\ninformation. This approach demands O(d) function evaluations (d is the\ndimension size), which incurs substantial computational costs and is\nprohibitive in high-dimensional scenarios. This paper proposes the Zeroth-order\nProximal Double Variance Reduction (ZPDVR) method, which utilizes the averaging\ntrick to reduce both sampling and coordinate-wise variances. Compared to prior\nmethods, ZPDVR relies solely on random gradient estimates, calls the stochastic\nzeroth-order oracle (SZO) in expectation $\\mathcal{O}(1)$ times per iteration,\nand achieves the optimal $\\mathcal{O}(d(n + \\kappa)\\log (\\frac{1}{\\epsilon}))$\nSZO query complexity in the strongly convex and smooth setting, where $\\kappa$\nrepresents the condition number and $\\epsilon$ is the desired accuracy.\nEmpirical results validate ZPDVR's linear convergence and demonstrate its\nsuperior performance over other related methods.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Hao Di",
            "Haishan Ye",
            "Yueling Zhang",
            "Xiangyu Chang",
            "Guang Dai",
            "Ivor W. Tsang"
        ],
        "published": "2024-05-28T02:27:53Z"
    },
    {
        "title": "Wireless Federated Learning over Resource-Constrained Networks: Digital\n  versus Analog Transmissions",
        "link": "http://arxiv.org/abs/2405.17759v1",
        "abstract": "To enable wireless federated learning (FL) in communication\nresource-constrained networks, two communication schemes, i.e., digital and\nanalog ones, are effective solutions. In this paper, we quantitatively compare\nthese two techniques, highlighting their essential differences as well as\nrespectively suitable scenarios. We first examine both digital and analog\ntransmission schemes, together with a unified and fair comparison framework\nunder imbalanced device sampling, strict latency targets, and transmit power\nconstraints. A universal convergence analysis under various imperfections is\nestablished for evaluating the performance of FL over wireless networks. These\nanalytical results reveal that the fundamental difference between the digital\nand analog communications lies in whether communication and computation are\njointly designed or not. The digital scheme decouples the communication design\nfrom FL computing tasks, making it difficult to support uplink transmission\nfrom massive devices with limited bandwidth and hence the performance is mainly\ncommunication-limited. In contrast, the analog communication allows\nover-the-air computation (AirComp) and achieves better spectrum utilization.\nHowever, the computation-oriented analog transmission reduces power efficiency,\nand its performance is sensitive to computation errors from imperfect channel\nstate information (CSI). Furthermore, device sampling for both schemes are\noptimized and differences in sampling optimization are analyzed. Numerical\nresults verify the theoretical analysis and affirm the superior performance of\nthe sampling optimization.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Jiacheng Yao",
            "Wei Xu",
            "Zhaohui Yang",
            "Xiaohu You",
            "Mehdi Bennis",
            "H. Vincent Poor"
        ],
        "published": "2024-05-28T02:23:48Z"
    },
    {
        "title": "NASPrecision: Neural Architecture Search-Driven Multi-Stage Learning for\n  Surface Roughness Prediction in Ultra-Precision Machining",
        "link": "http://arxiv.org/abs/2405.17757v1",
        "abstract": "Accurate surface roughness prediction is critical for ensuring high product\nquality, especially in areas like manufacturing and aerospace, where the\nsmallest imperfections can compromise performance or safety. However, this is\nchallenging due to complex, non-linear interactions among variables, which is\nfurther exacerbated with limited and imbalanced datasets. Existing methods\nusing traditional machine learning algorithms require extensive domain\nknowledge for feature engineering and substantial human intervention for model\nselection. To address these issues, we propose NASPrecision, a Neural\nArchitecture Search (NAS)-Driven Multi-Stage Learning Framework. This\ninnovative approach autonomously identifies the most suitable features and\nmodels for various surface roughness prediction tasks and significantly\nenhances the performance by multi-stage learning. Our framework operates in\nthree stages: 1) architecture search stage, employing NAS to automatically\nidentify the most effective model architecture; 2) initial training stage,\nwhere we train the neural network for initial predictions; 3) refinement stage,\nwhere a subsequent model is appended to refine and capture subtle variations\noverlooked by the initial training stage. In light of limited and imbalanced\ndatasets, we adopt a generative data augmentation technique to balance and\ngenerate new data by learning the underlying data distribution. We conducted\nexperiments on three distinct real-world datasets linked to different machining\ntechniques. Results show improvements in Mean Absolute Percentage Error (MAPE),\nRoot Mean Square Error (RMSE), and Standard Deviation (STD) by 18%, 31%, and\n22%, respectively. This establishes it as a robust and general solution for\nprecise surface roughness prediction, potentially boosting production\nefficiency and product quality in key industries while minimizing domain\nexpertise and human intervention.",
        "subjects": [
            "cs.CE"
        ],
        "authors": [
            "Penghui Ruan",
            "Divya Saxena",
            "Jiannong Cao",
            "Xiaoyun Liu",
            "Ruoxin Wang",
            "Chi Fai Cheung"
        ],
        "published": "2024-05-28T02:18:56Z"
    },
    {
        "title": "Motion-Informed Deep Learning for Brain MR Image Reconstruction\n  Framework",
        "link": "http://arxiv.org/abs/2405.17756v1",
        "abstract": "Motion artifacts in Magnetic Resonance Imaging (MRI) are one of the\nfrequently occurring artifacts due to patient movements during scanning. Motion\nis estimated to be present in approximately 30% of clinical MRI scans; however,\nmotion has not been explicitly modeled within deep learning image\nreconstruction models. Deep learning (DL) algorithms have been demonstrated to\nbe effective for both the image reconstruction task and the motion correction\ntask, but the two tasks are considered separately. The image reconstruction\ntask involves removing undersampling artifacts such as noise and aliasing\nartifacts, whereas motion correction involves removing artifacts including\nblurring, ghosting, and ringing. In this work, we propose a novel method to\nsimultaneously accelerate imaging and correct motion. This is achieved by\nintegrating a motion module into the deep learning-based MRI reconstruction\nprocess, enabling real-time detection and correction of motion. We model motion\nas a tightly integrated auxiliary layer in the deep learning model during\ntraining, making the deep learning model 'motion-informed'. During inference,\nimage reconstruction is performed from undersampled raw k-space data using a\ntrained motion-informed DL model. Experimental results demonstrate that the\nproposed motion-informed deep learning image reconstruction network\noutperformed the conventional image reconstruction network for motion-degraded\nMRI datasets.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG",
            "physics.med-ph"
        ],
        "authors": [
            "Zhifeng Chen",
            "Kamlesh Pawar",
            "Kh Tohidul Islam",
            "Himashi Peiris",
            "Gary Egan",
            "Zhaolin Chen"
        ],
        "published": "2024-05-28T02:16:35Z"
    },
    {
        "title": "XL3M: A Training-free Framework for LLM Length Extension Based on\n  Segment-wise Inference",
        "link": "http://arxiv.org/abs/2405.17755v1",
        "abstract": "Length generalization failure problem, namely the large language model (LLM)\nfails to generalize to texts longer than its maximum training length, greatly\nrestricts the application of LLM in the scenarios with streaming long inputs.\nTo address this problem, the existing methods either require substantial costs\nor introduce precision loss. In this paper, we empirically find that the\naccuracy of the LLM's prediction is highly correlated to its certainty. Based\non this, we propose an efficient training free framework, named XL3M (it means\nextra-long large language model), which enables the LLMs trained on short\nsequences to reason extremely long sequence without any further training or\nfine-tuning. Under the XL3M framework, the input context will be firstly\ndecomposed into multiple short sub-contexts, where each sub-context contains an\nindependent segment and a common ``question'' which is a few tokens from the\nend of the original context. Then XL3M gives a method to measure the relevance\nbetween each segment and the ``question'', and constructs a concise key context\nby splicing all the relevant segments in chronological order. The key context\nis further used instead of the original context to complete the inference task.\nEvaluations on comprehensive benchmarks show the superiority of XL3M. Using our\nframework, a Llama2-7B model is able to reason 20M long sequences on an 8-card\nHuawei Ascend 910B NPU machine with 64GB memory per card.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Shengnan Wang",
            "Youhui Bai",
            "Lin Zhang",
            "Pingyi Zhou",
            "Shixiong Zhao",
            "Gong Zhang",
            "Sen Wang",
            "Renhai Chen",
            "Hua Xu",
            "Hongwei Sun"
        ],
        "published": "2024-05-28T02:12:35Z"
    },
    {
        "title": "Differential Voltage Analysis and Patterns in Parallel-Connected Pairs\n  of Imbalanced Cells",
        "link": "http://arxiv.org/abs/2405.17754v1",
        "abstract": "Diagnosing imbalances in capacity and resistance within parallel-connected\ncells in battery packs is critical for battery management and fault detection,\nbut it is challenging given that individual currents flowing into each cell are\noften unmeasured. This work introduces a novel method useful for identifying\nimbalances in capacity and resistance within a pair of parallel-connected cells\nusing only voltage and current measurements from the pair. Our method utilizes\ndifferential voltage analysis (DVA) when the pair is under constant current\ndischarge and demonstrates that features of the pair's differential voltage\ncurve (dV/dQ), namely its mid-to-high SOC dV/dQ peak's height and skewness, are\nsensitive to imbalances in capacity and resistance. We analyze and explain how\nand why these dV/dQ peak shape features change in response to these imbalances,\nhighlighting that the underlying current imbalance dynamics resulting from\nthese imbalances contribute to these changes. Ultimately, we demonstrate that\ndV/dQ peak shape features can identify the product of capacity imbalance and\nresistance imbalance, but cannot uniquely identify the imbalances. This work\nlays the groundwork for identifying imbalances in capacity and resistance in\nparallel-connected cell groups in battery packs, where commonly only a single\ncurrent sensor is placed for each parallel cell group.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Clement Wong",
            "Andrew Weng",
            "Sravan Pannala",
            "Jeesoon Choi",
            "Jason B. Siegel",
            "Anna Stefanopoulou"
        ],
        "published": "2024-05-28T02:12:16Z"
    },
    {
        "title": "Regression Equilibrium in Electricity Markets",
        "link": "http://arxiv.org/abs/2405.17753v1",
        "abstract": "Renewable power producers participating in electricity markets build\nforecasting models independently, relying on their own data, model and feature\npreferences. In this paper, we argue that in renewable-dominated markets, such\nan uncoordinated approach to forecasting results in substantial opportunity\ncosts for stochastic producers and additional operating costs for the power\nsystem. As a solution, we introduce Regression Equilibrium--a welfare-optimal\nstate of electricity markets under uncertainty, where profit-seeking stochastic\nproducers do not benefit by unilaterally deviating from their equilibrium\nforecast models. While the regression equilibrium maximizes the private\nwelfare, i.e., the average profit of stochastic producers across the day-ahead\nand real-time markets, it also aligns with the socially optimal, least-cost\ndispatch solution for the system. We base the equilibrium analysis on the\ntheory of variational inequalities, providing results on the existence and\nuniqueness of regression equilibrium in energy-only markets. We also devise two\nmethods for computing the regression equilibrium: centralized optimization and\na decentralized ADMM-based algorithm that preserves the privacy of regression\ndatasets.",
        "subjects": [
            "eess.SY",
            "cs.SY",
            "econ.GN",
            "math.OC",
            "q-fin.EC"
        ],
        "authors": [
            "Vladimir Dvorkin"
        ],
        "published": "2024-05-28T02:11:21Z"
    },
    {
        "title": "Magnitude-based Neuron Pruning for Backdoor Defens",
        "link": "http://arxiv.org/abs/2405.17750v1",
        "abstract": "Deep Neural Networks (DNNs) are known to be vulnerable to backdoor attacks,\nposing concerning threats to their reliable deployment. Recent research reveals\nthat backdoors can be erased from infected DNNs by pruning a specific group of\nneurons, while how to effectively identify and remove these backdoor-associated\nneurons remains an open challenge. In this paper, we investigate the\ncorrelation between backdoor behavior and neuron magnitude, and find that\nbackdoor neurons deviate from the magnitude-saliency correlation of the model.\nThe deviation inspires us to propose a Magnitude-based Neuron Pruning (MNP)\nmethod to detect and prune backdoor neurons. Specifically, MNP uses three\nmagnitude-guided objective functions to manipulate the magnitude-saliency\ncorrelation of backdoor neurons, thus achieving the purpose of exposing\nbackdoor behavior, eliminating backdoor neurons and preserving clean neurons,\nrespectively. Experiments show our pruning strategy achieves state-of-the-art\nbackdoor defense performance against a variety of backdoor attacks with a\nlimited amount of clean data, demonstrating the crucial role of magnitude for\nguiding backdoor defenses.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "authors": [
            "Nan Li",
            "Haoyu Jiang",
            "Ping Yi"
        ],
        "published": "2024-05-28T02:05:39Z"
    },
    {
        "title": "Rethinking Pruning for Backdoor Mitigation: An Optimization Perspective",
        "link": "http://arxiv.org/abs/2405.17746v1",
        "abstract": "Deep Neural Networks (DNNs) are known to be vulnerable to backdoor attacks,\nposing concerning threats to their reliable deployment. Recent research reveals\nthat backdoors can be erased from infected DNNs by pruning a specific group of\nneurons, while how to effectively identify and remove these backdoor-associated\nneurons remains an open challenge. Most of the existing defense methods rely on\ndefined rules and focus on neuron's local properties, ignoring the exploration\nand optimization of pruning policies. To address this gap, we propose an\nOptimized Neuron Pruning (ONP) method combined with Graph Neural Network (GNN)\nand Reinforcement Learning (RL) to repair backdoor models. Specifically, ONP\nfirst models the target DNN as graphs based on neuron connectivity, and then\nuses GNN-based RL agents to learn graph embeddings and find a suitable pruning\npolicy. To the best of our knowledge, this is the first attempt to employ GNN\nand RL for optimizing pruning policies in the field of backdoor defense.\nExperiments show, with a small amount of clean data, ONP can effectively prune\nthe backdoor neurons implanted by a set of backdoor attacks at the cost of\nnegligible performance degradation, achieving a new state-of-the-art\nperformance for backdoor mitigation.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CR"
        ],
        "authors": [
            "Nan Li",
            "Haiyang Yu",
            "Ping Yi"
        ],
        "published": "2024-05-28T01:59:06Z"
    },
    {
        "title": "ORLM: Training Large Language Models for Optimization Modeling",
        "link": "http://arxiv.org/abs/2405.17743v2",
        "abstract": "Large Language Models (LLMs) have emerged as powerful tools for tackling\ncomplex Operations Research (OR) problem by providing the capacity in\nautomating optimization modeling. However, current methodologies heavily rely\non prompt engineering (e.g., multi-agent cooperation) with proprietary LLMs,\nraising data privacy concerns that could be prohibitive in industry\napplications. To tackle this issue, we propose training open-source LLMs for\noptimization modeling. We identify four critical requirements for the training\ndataset of OR LLMs, design and implement OR-Instruct, a semi-automated process\nfor creating synthetic data tailored to specific requirements. We also\nintroduce the IndustryOR benchmark, the first industrial benchmark for testing\nLLMs on solving real-world OR problems. We apply the data from OR-Instruct to\nvarious open-source LLMs of 7b size (termed as ORLMs), resulting in a\nsignificantly improved capability for optimization modeling. Our\nbest-performing ORLM achieves state-of-the-art performance on the NL4OPT, MAMO,\nand IndustryOR benchmarks. Our code and data are available at\n\\url{https://github.com/Cardinal-Operations/ORLM}.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CE",
            "cs.LG"
        ],
        "authors": [
            "Zhengyang Tang",
            "Chenyu Huang",
            "Xin Zheng",
            "Shixi Hu",
            "Zizhuo Wang",
            "Dongdong Ge",
            "Benyou Wang"
        ],
        "published": "2024-05-28T01:55:35Z"
    },
    {
        "title": "LoRA-Switch: Boosting the Efficiency of Dynamic LLM Adapters via\n  System-Algorithm Co-design",
        "link": "http://arxiv.org/abs/2405.17741v1",
        "abstract": "Recent literature has found that an effective method to customize or further\nimprove large language models (LLMs) is to add dynamic adapters, such as\nlow-rank adapters (LoRA) with Mixture-of-Experts (MoE) structures. Though such\ndynamic adapters incur modest computational complexity, they surprisingly lead\nto huge inference latency overhead, slowing down the decoding speed by 2.5+\ntimes. In this paper, we analyze the fine-grained costs of the dynamic adapters\nand find that the fragmented CUDA kernel calls are the root cause. Therefore,\nwe propose LoRA-Switch, a system-algorithm co-designed architecture for\nefficient dynamic adapters. Unlike most existing dynamic structures that adopt\nlayer-wise or block-wise dynamic routing, LoRA-Switch introduces a token-wise\nrouting mechanism. It switches the LoRA adapters and weights for each token and\nmerges them into the backbone for inference. For efficiency, this switching is\nimplemented with an optimized CUDA kernel, which fuses the merging operations\nfor all LoRA adapters at once. Based on experiments with popular open-source\nLLMs on common benchmarks, our approach has demonstrated similar accuracy\nimprovement as existing dynamic adapters, while reducing the decoding latency\nby more than 2.4 times.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Rui Kong",
            "Qiyang Li",
            "Xinyu Fang",
            "Qingtian Feng",
            "Qingfeng He",
            "Yazhu Dong",
            "Weijun Wang",
            "Yuanchun Li",
            "Linghe Kong",
            "Yunxin Liu"
        ],
        "published": "2024-05-28T01:53:26Z"
    },
    {
        "title": "MobileConvRec: A Conversational Dataset for Mobile Apps Recommendations",
        "link": "http://arxiv.org/abs/2405.17740v1",
        "abstract": "Existing recommendation systems have focused on two paradigms: 1- historical\nuser-item interaction-based recommendations and 2- conversational\nrecommendations. Conversational recommendation systems facilitate natural\nlanguage dialogues between users and the system, allowing the system to solicit\nusers' explicit needs while enabling users to inquire about recommendations and\nprovide feedback. Due to substantial advancements in natural language\nprocessing, conversational recommendation systems have gained prominence.\nExisting conversational recommendation datasets have greatly facilitated\nresearch in their respective domains. Despite the exponential growth in mobile\nusers and apps in recent years, research in conversational mobile app\nrecommender systems has faced substantial constraints. This limitation can\nprimarily be attributed to the lack of high-quality benchmark datasets\nspecifically tailored for mobile apps. To facilitate research for\nconversational mobile app recommendations, we introduce MobileConvRec.\nMobileConvRec simulates conversations by leveraging real user interactions with\nmobile apps on the Google Play store, originally captured in large-scale mobile\napp recommendation dataset MobileRec. The proposed conversational\nrecommendation dataset synergizes sequential user-item interactions, which\nreflect implicit user preferences, with comprehensive multi-turn conversations\nto effectively grasp explicit user needs. MobileConvRec consists of over 12K\nmulti-turn recommendation-related conversations spanning 45 app categories.\nMoreover, MobileConvRec presents rich metadata for each app such as permissions\ndata, security and privacy-related information, and binary executables of apps,\namong others. We demonstrate that MobileConvRec can serve as an excellent\ntestbed for conversational mobile app recommendation through a comparative\nstudy of several pre-trained large language models.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Srijata Maji",
            "Moghis Fereidouni",
            "Vinaik Chhetri",
            "Umar Farooq",
            "A. B. Siddique"
        ],
        "published": "2024-05-28T01:53:16Z"
    },
    {
        "title": "The Widening Gap: The Benefits and Harms of Generative AI for Novice\n  Programmers",
        "link": "http://arxiv.org/abs/2405.17739v1",
        "abstract": "Novice programmers often struggle through programming problem solving due to\na lack of metacognitive awareness and strategies. Previous research has shown\nthat novices can encounter multiple metacognitive difficulties while\nprogramming. Novices are typically unaware of how these difficulties are\nhindering their progress. Meanwhile, many novices are now programming with\ngenerative AI (GenAI), which can provide complete solutions to most\nintroductory programming problems, code suggestions, hints for next steps when\nstuck, and explain cryptic error messages. Its impact on novice metacognition\nhas only started to be explored. Here we replicate a previous study that\nexamined novice programming problem solving behavior and extend it by\nincorporating GenAI tools. Through 21 lab sessions consisting of participant\nobservation, interview, and eye tracking, we explore how novices are coding\nwith GenAI tools. Although 20 of 21 students completed the assigned programming\nproblem, our findings show an unfortunate divide in the use of GenAI tools\nbetween students who accelerated and students who struggled. Students who\naccelerated were able to use GenAI to create code they already intended to make\nand were able to ignore unhelpful or incorrect inline code suggestions. But for\nstudents who struggled, our findings indicate that previously known\nmetacognitive difficulties persist, and that GenAI unfortunately can compound\nthem and even introduce new metacognitive difficulties. Furthermore, struggling\nstudents often expressed cognitive dissonance about their problem solving\nability, thought they performed better than they did, and finished with an\nillusion of competence. Based on our observations from both groups, we propose\nways to scaffold the novice GenAI experience and make suggestions for future\nwork.",
        "subjects": [
            "cs.AI",
            "cs.HC"
        ],
        "authors": [
            "James Prather",
            "Brent Reeves",
            "Juho Leinonen",
            "Stephen MacNeil",
            "Arisoa S. Randrianasolo",
            "Brett Becker",
            "Bailey Kimmel",
            "Jared Wright",
            "Ben Briggs"
        ],
        "published": "2024-05-28T01:48:28Z"
    },
    {
        "title": "The HTTP Garden: Discovering Parsing Vulnerabilities in HTTP/1.1\n  Implementations by Differential Fuzzing of Request Streams",
        "link": "http://arxiv.org/abs/2405.17737v1",
        "abstract": "HTTP/1.1 parsing discrepancies have been the basis for numerous classes of\nattacks against web servers. Previous techniques for discovering HTTP parsing\ndiscrepancies have focused on blackbox differential testing of HTTP gateway\nservers, despite evidence that the most significant parsing anomalies occur\nwithin origin servers. While these techniques can detect some vulnerabilities,\nnot all parsing discrepancy-related vulnerabilities are detectable by examining\na gateway server's output alone. Our system, the HTTP Garden, examines both\norigin servers' interpretations and gateway servers' transformations of HTTP\nrequests. It also includes a coverage-guided differential fuzzer for HTTP/1.1\norigin servers that is capable of mutating all components of a request stream,\npaired with an interactive REPL that facilitates the automatic discovery of\nmeaningful HTTP parsing discrepancies and the rapid development of those\ndiscrepancies into attack payloads. Using our tool, we have discovered and\nreported over 100 HTTP parsing bugs in popular web servers, of which 68 have\nbeen fixed following our reports. We designate 39 of these to be exploitable.\nWe release the HTTP Garden to the public on GitHub under a free software\nlicense to allow researchers to further explore new parser discrepancy-based\nattacks against HTTP/1.1 servers.",
        "subjects": [
            "cs.CR",
            "cs.NI"
        ],
        "authors": [
            "Ben Kallus",
            "Prashant Anantharaman",
            "Michael Locasto",
            "Sean W. Smith"
        ],
        "published": "2024-05-28T01:48:05Z"
    },
    {
        "title": "State Feedback as a Strategy for Control and Analysis of COVID-19",
        "link": "http://arxiv.org/abs/2405.17735v1",
        "abstract": "This paper presents a study on a compartmental epidemic model for COVID-19,\nexamining the stability of its equilibrium points upon the introduction of\nvaccination as a strategy to mitigate the spread of the disease. Initially, the\nSIQR (Susceptible-Infectious-Quarantine-Recovered) mathematical model and its\ntechnical aspects are introduced. Subsequently, vaccination is incorporated as\na control measure within the model scope. Equilibrium points and the basic\nreproductive number are determined, followed by an analysis of their stability.\nFurthermore, controllability characteristics and Optimal Control strategies for\nthe system are investigated, supplemented by numerical simulations.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "physics.soc-ph"
        ],
        "authors": [
            "Leonardo R. S. Rodrigues",
            "Felipe Gabrielli"
        ],
        "published": "2024-05-28T01:36:38Z"
    },
    {
        "title": "Towards Efficient Disaster Response via Cost-effective Unbiased Class\n  Rate Estimation through Neyman Allocation Stratified Sampling Active Learning",
        "link": "http://arxiv.org/abs/2405.17734v1",
        "abstract": "With the rapid development of earth observation technology, we have entered\nan era of massively available satellite remote-sensing data. However, a large\namount of satellite remote sensing data lacks a label or the label cost is too\nhigh to hinder the potential of AI technology mining satellite data. Especially\nin such an emergency response scenario that uses satellite data to evaluate the\ndegree of disaster damage. Disaster damage assessment encountered bottlenecks\ndue to excessive focus on the damage of a certain building in a specific\ngeographical space or a certain area on a larger scale. In fact, in the early\ndays of disaster emergency response, government departments were more concerned\nabout the overall damage rate of the disaster area instead of single-building\ndamage, because this helps the government decide the level of emergency\nresponse. We present an innovative algorithm that constructs Neyman stratified\nrandom sampling trees for binary classification and extends this approach to\nmulticlass problems. Through extensive experimentation on various datasets and\nmodel structures, our findings demonstrate that our method surpasses both\npassive and conventional active learning techniques in terms of class rate\nestimation and model enhancement with only 30\\%-60\\% of the annotation cost of\nsimple sampling. It effectively addresses the 'sampling bias' challenge in\ntraditional active learning strategies and mitigates the 'cold start' dilemma.\nThe efficacy of our approach is further substantiated through application to\ndisaster evaluation tasks using Xview2 Satellite imagery, showcasing its\npractical utility in real-world contexts.",
        "subjects": [
            "cs.LG",
            "stat.AP"
        ],
        "authors": [
            "Yanbing Bai",
            "Xinyi Wu",
            "Lai Xu",
            "Jihan Pei",
            "Erick Mas",
            "Shunichi Koshimura"
        ],
        "published": "2024-05-28T01:34:35Z"
    },
    {
        "title": "C$^{3}$Bench: A Comprehensive Classical Chinese Understanding Benchmark\n  for Large Language Models",
        "link": "http://arxiv.org/abs/2405.17732v2",
        "abstract": "Classical Chinese Understanding (CCU) holds significant value in preserving\nand exploration of the outstanding traditional Chinese culture. Recently,\nresearchers have attempted to leverage the potential of Large Language Models\n(LLMs) for CCU by capitalizing on their remarkable comprehension and semantic\ncapabilities. However, no comprehensive benchmark is available to assess the\nCCU capabilities of LLMs. To fill this gap, this paper introduces C$^{3}$bench,\na Comprehensive Classical Chinese understanding benchmark, which comprises\n50,000 text pairs for five primary CCU tasks, including classification,\nretrieval, named entity recognition, punctuation, and translation. Furthermore,\nthe data in C$^{3}$bench originates from ten different domains, covering most\nof the categories in classical Chinese. Leveraging the proposed C$^{3}$bench,\nwe extensively evaluate the quantitative performance of 15 representative LLMs\non all five CCU tasks. Our results not only establish a public leaderboard of\nLLMs' CCU capabilities but also gain some findings. Specifically, existing LLMs\nare struggle with CCU tasks and still inferior to supervised models.\nAdditionally, the results indicate that CCU is a task that requires special\nattention. We believe this study could provide a standard benchmark,\ncomprehensive baselines, and valuable insights for the future advancement of\nLLM-based CCU research. The evaluation pipeline and dataset are available at\n\\url{https://github.com/SCUT-DLVCLab/C3bench}.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Jiahuan Cao",
            "Yongxin Shi",
            "Dezhi Peng",
            "Yang Liu",
            "Lianwen Jin"
        ],
        "published": "2024-05-28T01:23:58Z"
    },
    {
        "title": "Evaluating NoSQL Databases for OLAP Workloads: A Benchmarking Study of\n  MongoDB, Redis, Kudu and ArangoDB",
        "link": "http://arxiv.org/abs/2405.17731v1",
        "abstract": "In the era of big data, conventional RDBMS models have become impractical for\nhandling colossal workloads. Consequently, NoSQL databases have emerged as the\npreferred storage solutions for executing processing-intensive Online\nAnalytical Processing (OLAP) tasks. Within the realm of NoSQL databases,\nvarious classifications exist based on their data storage mechanisms, making it\nchallenging to select the most suitable one for a given OLAP workload. While\neach NoSQL database boasts distinct advantages, inherent scalability,\nadaptability to diverse data formats, and high data availability are\nuniversally recognized benefits crucial for managing OLAP workloads\neffectively. Existing research predominantly evaluates individual databases\nwithin custom data pipeline setups, lacking a standardized approach for\ncomparative analysis across different databases to identify the optimal data\npipeline for OLAP workloads. In this paper, we present our experimental\ninsights into how various NoSQL databases handle OLAP workloads within a\nstandardized data processing pipeline. Our experimental pipeline comprises\nApache Spark for large-scale transformations, data cleansing, and schema\nnormalization, diverse NoSQL databases as data stores, and a Business\nIntelligence tool for data analysis and visualization.",
        "subjects": [
            "cs.DB"
        ],
        "authors": [
            "Rishi Kesav Mohan",
            "Risheek Rakshit Sukumar Kanmani",
            "Krishna Anandan Ganesan",
            "Nisha Ramasubramanian"
        ],
        "published": "2024-05-28T01:19:18Z"
    },
    {
        "title": "MMPareto: Boosting Multimodal Learning with Innocent Unimodal Assistance",
        "link": "http://arxiv.org/abs/2405.17730v1",
        "abstract": "Multimodal learning methods with targeted unimodal learning objectives have\nexhibited their superior efficacy in alleviating the imbalanced multimodal\nlearning problem. However, in this paper, we identify the previously ignored\ngradient conflict between multimodal and unimodal learning objectives,\npotentially misleading the unimodal encoder optimization. To well diminish\nthese conflicts, we observe the discrepancy between multimodal loss and\nunimodal loss, where both gradient magnitude and covariance of the\neasier-to-learn multimodal loss are smaller than the unimodal one. With this\nproperty, we analyze Pareto integration under our multimodal scenario and\npropose MMPareto algorithm, which could ensure a final gradient with direction\nthat is common to all learning objectives and enhanced magnitude to improve\ngeneralization, providing innocent unimodal assistance. Finally, experiments\nacross multiple types of modalities and frameworks with dense cross-modal\ninteraction indicate our superior and extendable method performance. Our method\nis also expected to facilitate multi-task cases with a clear discrepancy in\ntask difficulty, demonstrating its ideal scalability. The source code and\ndataset are available at https://github.com/GeWu-Lab/MMPareto_ICML2024.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.MM"
        ],
        "authors": [
            "Yake Wei",
            "Di Hu"
        ],
        "published": "2024-05-28T01:19:13Z"
    },
    {
        "title": "Hierarchical Action Recognition: A Contrastive Video-Language Approach\n  with Hierarchical Interactions",
        "link": "http://arxiv.org/abs/2405.17729v1",
        "abstract": "Video recognition remains an open challenge, requiring the identification of\ndiverse content categories within videos. Mainstream approaches often perform\nflat classification, overlooking the intrinsic hierarchical structure relating\ncategories. To address this, we formalize the novel task of hierarchical video\nrecognition, and propose a video-language learning framework tailored for\nhierarchical recognition. Specifically, our framework encodes dependencies\nbetween hierarchical category levels, and applies a top-down constraint to\nfilter recognition predictions. We further construct a new fine-grained dataset\nbased on medical assessments for rehabilitation of stroke patients, serving as\na challenging benchmark for hierarchical recognition. Through extensive\nexperiments, we demonstrate the efficacy of our approach for hierarchical\nrecognition, significantly outperforming conventional methods, especially for\nfine-grained subcategories. The proposed framework paves the way for\nhierarchical modeling in video understanding tasks, moving beyond flat\ncategorization.",
        "subjects": [
            "cs.CV",
            "cs.MM"
        ],
        "authors": [
            "Rui Zhang",
            "Shuailong Li",
            "Junxiao Xue",
            "Feng Lin",
            "Qing Zhang",
            "Xiao Ma",
            "Xiaoran Yan"
        ],
        "published": "2024-05-28T01:17:22Z"
    },
    {
        "title": "Multi-objective Representation for Numbers in Clinical Narratives Using\n  CamemBERT-bio",
        "link": "http://arxiv.org/abs/2405.18448v1",
        "abstract": "This research aims to classify numerical values extracted from medical\ndocuments across seven distinct physiological categories, employing\nCamemBERT-bio. Previous studies suggested that transformer-based models might\nnot perform as well as traditional NLP models in such tasks. To enhance\nCamemBERT-bio's performances, we introduce two main innovations: integrating\nkeyword embeddings into the model and adopting a number-agnostic strategy by\nexcluding all numerical data from the text. The implementation of label\nembedding techniques refines the attention mechanisms, while the technique of\nusing a `numerical-blind' dataset aims to bolster context-centric learning.\nAnother key component of our research is determining the criticality of\nextracted numerical data. To achieve this, we utilized a simple approach that\ninvolves verifying if the value falls within the established standard ranges.\nOur findings are encouraging, showing substantial improvements in the\neffectiveness of CamemBERT-bio, surpassing conventional methods with an F1\nscore of 0.89. This represents an over 20\\% increase over the 0.73 $F_1$ score\nof traditional approaches and an over 9\\% increase over the 0.82 $F_1$ score of\nstate-of-the-art approaches. All this was achieved despite using small and\nimbalanced training datasets.",
        "subjects": [
            "cs.CL",
            "eess.SP"
        ],
        "authors": [
            "Boammani Aser Lompo",
            "Thanh-Dung Le"
        ],
        "published": "2024-05-28T01:15:21Z"
    },
    {
        "title": "Facilitating Holistic Evaluations with LLMs: Insights from\n  Scenario-Based Experiments",
        "link": "http://arxiv.org/abs/2405.17728v1",
        "abstract": "Workshop courses designed to foster creativity are gaining popularity.\nHowever, achieving a holistic evaluation that accommodates diverse perspectives\nis challenging, even for experienced faculty teams. Adequate discussion is\nessential to integrate varied assessments, but faculty often lack the time for\nsuch deliberations. Deriving an average score without discussion undermines the\npurpose of a holistic evaluation. This paper explores the use of a Large\nLanguage Model (LLM) as a facilitator to integrate diverse faculty assessments.\nScenario-based experiments were conducted to determine if the LLM could\nsynthesize diverse evaluations and explain the underlying theories to faculty.\nThe results were noteworthy, showing that the LLM effectively facilitated\nfaculty discussions. Additionally, the LLM demonstrated the capability to\ngeneralize and create evaluation criteria from a single scenario based on its\nlearned domain knowledge.",
        "subjects": [
            "cs.CY",
            "cs.AI",
            "cs.HC"
        ],
        "authors": [
            "Toru Ishida"
        ],
        "published": "2024-05-28T01:07:06Z"
    },
    {
        "title": "Color Shift Estimation-and-Correction for Image Enhancement",
        "link": "http://arxiv.org/abs/2405.17725v2",
        "abstract": "Images captured under sub-optimal illumination conditions may contain both\nover- and under-exposures. Current approaches mainly focus on adjusting image\nbrightness, which may exacerbate the color tone distortion in under-exposed\nareas and fail to restore accurate colors in over-exposed regions. We observe\nthat over- and under-exposed regions display opposite color tone distribution\nshifts with respect to each other, which may not be easily normalized in joint\nmodeling as they usually do not have ``normal-exposed'' regions/pixels as\nreference. In this paper, we propose a novel method to enhance images with both\nover- and under-exposures by learning to estimate and correct such color\nshifts. Specifically, we first derive the color feature maps of the brightened\nand darkened versions of the input image via a UNet-based network, followed by\na pseudo-normal feature generator to produce pseudo-normal color feature maps.\nWe then propose a novel COlor Shift Estimation (COSE) module to estimate the\ncolor shifts between the derived brightened (or darkened) color feature maps\nand the pseudo-normal color feature maps. The COSE module corrects the\nestimated color shifts of the over- and under-exposed regions separately. We\nfurther propose a novel COlor MOdulation (COMO) module to modulate the\nseparately corrected colors in the over- and under-exposed regions to produce\nthe enhanced image. Comprehensive experiments show that our method outperforms\nexisting approaches. Project webpage: https://github.com/yiyulics/CSEC.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yiyu Li",
            "Ke Xu",
            "Gerhard Petrus Hancke",
            "Rynson W. H. Lau"
        ],
        "published": "2024-05-28T00:45:35Z"
    },
    {
        "title": "ClavaDDPM: Multi-relational Data Synthesis with Cluster-guided Diffusion\n  Models",
        "link": "http://arxiv.org/abs/2405.17724v1",
        "abstract": "Recent research in tabular data synthesis has focused on single tables,\nwhereas real-world applications often involve complex data with tens or\nhundreds of interconnected tables. Previous approaches to synthesizing\nmulti-relational (multi-table) data fall short in two key aspects: scalability\nfor larger datasets and capturing long-range dependencies, such as correlations\nbetween attributes spread across different tables. Inspired by the success of\ndiffusion models in tabular data modeling, we introduce\n  $\\textbf{C}luster$ $\\textbf{La}tent$ $\\textbf{Va}riable$ $guided$\n$\\textbf{D}enoising$ $\\textbf{D}iffusion$ $\\textbf{P}robabilistic$\n$\\textbf{M}odels$ (ClavaDDPM). This novel approach leverages clustering labels\nas intermediaries to model relationships between tables, specifically focusing\non foreign key constraints. ClavaDDPM leverages the robust generation\ncapabilities of diffusion models while incorporating efficient algorithms to\npropagate the learned latent variables across tables. This enables ClavaDDPM to\ncapture long-range dependencies effectively.\n  Extensive evaluations on multi-table datasets of varying sizes show that\nClavaDDPM significantly outperforms existing methods for these long-range\ndependencies while remaining competitive on utility metrics for single-table\ndata.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Wei Pang",
            "Masoumeh Shafieinejad",
            "Lucy Liu",
            "Xi He"
        ],
        "published": "2024-05-28T00:42:18Z"
    },
    {
        "title": "TableDC: Deep Clustering for Tabular Data",
        "link": "http://arxiv.org/abs/2405.17723v1",
        "abstract": "Deep clustering (DC), a fusion of deep representation learning and\nclustering, has recently demonstrated positive results in data science,\nparticularly text processing and computer vision. However, joint optimization\nof feature learning and data distribution in the multi-dimensional space is\ndomain-specific, so existing DC methods struggle to generalize to other\napplication domains (such as data integration and cleaning). In data management\ntasks, where high-density embeddings and overlapping clusters dominate, a data\nmanagement-specific DC algorithm should be able to interact better with the\ndata properties for supporting data cleaning and integration tasks. This paper\npresents a deep clustering algorithm for tabular data (TableDC) that reflects\nthe properties of data management applications, particularly schema inference,\nentity resolution, and domain discovery. To address overlapping clusters,\nTableDC integrates Mahalanobis distance, which considers variance and\ncorrelation within the data, offering a similarity method suitable for tables,\nrows, or columns in high-dimensional latent spaces. TableDC provides\nflexibility for the final clustering assignment and shows higher tolerance to\noutliers through its heavy-tailed Cauchy distribution as the similarity kernel.\nThe proposed similarity measure is particularly beneficial where the embeddings\nof raw data are densely packed and exhibit high degrees of overlap. Data\ncleaning tasks may involve a large number of clusters, which affects the\nscalability of existing DC methods. TableDC's self-supervised module\nefficiently learns data embeddings with a large number of clusters compared to\nexisting benchmarks, which scale in quadratic time. We evaluated TableDC with\nseveral existing DC, Standard Clustering (SC), and state-of-the-art bespoke\nmethods over benchmark datasets. TableDC consistently outperforms existing DC,\nSC, and bespoke methods.",
        "subjects": [
            "cs.DB"
        ],
        "authors": [
            "Hafiz Tayyab Rauf",
            "Andre Freitas",
            "Norman W. Paton"
        ],
        "published": "2024-05-28T00:40:43Z"
    },
    {
        "title": "MindFormer: A Transformer Architecture for Multi-Subject Brain Decoding\n  via fMRI",
        "link": "http://arxiv.org/abs/2405.17720v1",
        "abstract": "Research efforts to understand neural signals have been ongoing for many\nyears, with visual decoding from fMRI signals attracting considerable\nattention. Particularly, the advent of image diffusion models has advanced the\nreconstruction of images from fMRI data significantly. However, existing\napproaches often introduce inter- and intra- subject variations in the\nreconstructed images, which can compromise accuracy. To address current\nlimitations in multi-subject brain decoding, we introduce a new Transformer\narchitecture called MindFormer. This model is specifically designed to generate\nfMRI-conditioned feature vectors that can be used for conditioning Stable\nDiffusion model. More specifically, MindFormer incorporates two key\ninnovations: 1) a novel training strategy based on the IP-Adapter to extract\nsemantically meaningful features from fMRI signals, and 2) a subject specific\ntoken and linear layer that effectively capture individual differences in fMRI\nsignals while synergistically combines multi subject fMRI data for training.\nOur experimental results demonstrate that Stable Diffusion, when integrated\nwith MindFormer, produces semantically consistent images across different\nsubjects. This capability significantly surpasses existing models in\nmulti-subject brain decoding. Such advancements not only improve the accuracy\nof our reconstructions but also deepen our understanding of neural processing\nvariations among individuals.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Inhwa Han",
            "Jaayeon Lee",
            "Jong Chul Ye"
        ],
        "published": "2024-05-28T00:36:25Z"
    },
    {
        "title": "EgoNCE++: Do Egocentric Video-Language Models Really Understand\n  Hand-Object Interactions?",
        "link": "http://arxiv.org/abs/2405.17719v1",
        "abstract": "Egocentric video-language pretraining is a crucial paradigm to advance the\nlearning of egocentric hand-object interactions (EgoHOI). Despite the great\nsuccess on existing testbeds, these benchmarks focus more on closed-set visual\nconcepts or limited scenarios. Due to the occurrence of diverse EgoHOIs in the\nreal world, we propose an open-vocabulary benchmark named EgoHOIBench to reveal\nthe diminished performance of current egocentric video-language models (EgoVLM)\non fined-grained concepts, indicating that these models still lack a full\nspectrum of egocentric understanding. We attribute this performance gap to\ninsufficient fine-grained supervision and strong bias towards understanding\nobjects rather than temporal dynamics in current methods. To tackle these\nissues, we introduce a novel asymmetric contrastive objective for EgoHOI named\nEgoNCE++. For video-to-text loss, we enhance text supervision through the\ngeneration of negative captions by leveraging the in-context learning of large\nlanguage models to perform HOI-related word substitution. For text-to-video\nloss, we propose an object-centric positive video sampling strategy that\naggregates video representations by the same nouns. Our extensive experiments\ndemonstrate that EgoNCE++ significantly boosts open-vocabulary HOI recognition,\nmulti-instance retrieval, and action recognition tasks across various\negocentric models, with improvements of up to +26.55%. Our code is available at\nhttps://github.com/xuboshen/EgoNCEpp.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Boshen Xu",
            "Ziheng Wang",
            "Yang Du",
            "Sipeng Zheng",
            "Zhinan Song",
            "Qin Jin"
        ],
        "published": "2024-05-28T00:27:29Z"
    },
    {
        "title": "AdapNet: Adaptive Noise-Based Network for Low-Quality Image Retrieval",
        "link": "http://arxiv.org/abs/2405.17718v1",
        "abstract": "Image retrieval aims to identify visually similar images within a database\nusing a given query image. Traditional methods typically employ both global and\nlocal features extracted from images for matching, and may also apply\nre-ranking techniques to enhance accuracy. However, these methods often fail to\naccount for the noise present in query images, which can stem from natural or\nhuman-induced factors, thereby negatively impacting retrieval performance. To\nmitigate this issue, we introduce a novel setting for low-quality image\nretrieval, and propose an Adaptive Noise-Based Network (AdapNet) to learn\nrobust abstract representations. Specifically, we devise a quality compensation\nblock trained to compensate for various low-quality factors in input images.\nBesides, we introduce an innovative adaptive noise-based loss function, which\ndynamically adjusts its focus on the gradient in accordance with image quality,\nthereby augmenting the learning of unknown noisy samples during training and\nenhancing intra-class compactness. To assess the performance, we construct two\ndatasets with low-quality queries, which is built by applying various types of\nnoise on clean query images on the standard Revisited Oxford and Revisited\nParis datasets. Comprehensive experimental results illustrate that AdapNet\nsurpasses state-of-the-art methods on the Noise Revisited Oxford and Noise\nRevisited Paris benchmarks, while maintaining competitive performance on\nhigh-quality datasets. The code and constructed datasets will be made\navailable.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Sihe Zhang",
            "Qingdong He",
            "Jinlong Peng",
            "Yuxi Li",
            "Zhengkai Jiang",
            "Jiafu Wu",
            "Mingmin Chi",
            "Yabiao Wang",
            "Chengjie Wang"
        ],
        "published": "2024-05-28T00:25:41Z"
    },
    {
        "title": "AI Alignment with Changing and Influenceable Reward Functions",
        "link": "http://arxiv.org/abs/2405.17713v1",
        "abstract": "Existing AI alignment approaches assume that preferences are static, which is\nunrealistic: our preferences change, and may even be influenced by our\ninteractions with AI systems themselves. To clarify the consequences of\nincorrectly assuming static preferences, we introduce Dynamic Reward Markov\nDecision Processes (DR-MDPs), which explicitly model preference changes and the\nAI's influence on them. We show that despite its convenience, the\nstatic-preference assumption may undermine the soundness of existing alignment\ntechniques, leading them to implicitly reward AI systems for influencing user\npreferences in ways users may not truly want. We then explore potential\nsolutions. First, we offer a unifying perspective on how an agent's\noptimization horizon may partially help reduce undesirable AI influence. Then,\nwe formalize different notions of AI alignment that account for preference\nchange from the outset. Comparing the strengths and limitations of 8 such\nnotions of alignment, we find that they all either err towards causing\nundesirable AI influence, or are overly risk-averse, suggesting that a\nstraightforward solution to the problems of changing preferences may not exist.\nAs there is no avoiding grappling with changing preferences in real-world\nsettings, this makes it all the more important to handle these issues with\ncare, balancing risks and capabilities. We hope our work can provide conceptual\nclarity and constitute a first step towards AI alignment practices which\nexplicitly account for (and contend with) the changing and influenceable nature\nof human preferences.",
        "subjects": [
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Micah Carroll",
            "Davis Foote",
            "Anand Siththaranjan",
            "Stuart Russell",
            "Anca Dragan"
        ],
        "published": "2024-05-28T00:08:46Z"
    },
    {
        "title": "CLAIM Your Data: Enhancing Imputation Accuracy with Contextual Large\n  Language Models",
        "link": "http://arxiv.org/abs/2405.17712v1",
        "abstract": "This paper introduces the Contextual Language model for Accurate Imputation\nMethod (CLAIM), a novel strategy that capitalizes on the expansive knowledge\nand reasoning capabilities of pre-trained large language models (LLMs) to\naddress missing data challenges in tabular datasets. Unlike traditional\nimputation methods, which predominantly rely on numerical estimations, CLAIM\nutilizes contextually relevant natural language descriptors to fill missing\nvalues. This approach transforms datasets into natural language contextualized\nformats that are inherently more aligned with LLMs' capabilities, thereby\nfacilitating the dual use of LLMs: first, to generate missing value\ndescriptors, and then, to fine-tune the LLM on the enriched dataset for\nimproved performance in downstream tasks. Our evaluations across diverse\ndatasets and missingness patterns reveal CLAIM's superior performance over\nexisting imputation techniques. Furthermore, our investigation into the\neffectiveness of context-specific versus generic descriptors for missing data\nhighlights the importance of contextual accuracy in enhancing LLM performance\nfor data imputation. The results underscore CLAIM's potential to markedly\nimprove the reliability and quality of data analysis and machine learning\nmodels, offering a more nuanced and effective solution for handling missing\ndata.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Ahatsham Hayat",
            "Mohammad Rashedul Hasan"
        ],
        "published": "2024-05-28T00:08:29Z"
    },
    {
        "title": "RealityEffects: Augmenting 3D Volumetric Videos with Object-Centric\n  Annotation and Dynamic Visual Effects",
        "link": "http://dx.doi.org/10.1145/3643834.3661631",
        "abstract": "This paper introduces RealityEffects, a desktop authoring interface designed\nfor editing and augmenting 3D volumetric videos with object-centric annotations\nand visual effects. RealityEffects enhances volumetric capture by introducing a\nnovel method for augmenting captured physical motion with embedded, responsive\nvisual effects, referred to as object-centric augmentation. In RealityEffects,\nusers can interactively attach various visual effects to physical objects\nwithin the captured 3D scene, enabling these effects to dynamically move and\nanimate in sync with the corresponding physical motion and body movements. The\nprimary contribution of this paper is the development of a taxonomy for such\nobject-centric augmentations, which includes annotated labels, highlighted\nobjects, ghost effects, and trajectory visualization. This taxonomy is informed\nby an analysis of 120 edited videos featuring object-centric visual effects.\nThe findings from our user study confirm that our direct manipulation\ntechniques lower the barriers to editing and annotating volumetric captures,\nthereby enhancing interactive and engaging viewing experiences of 3D volumetric\nvideos.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Jian Liao",
            "Kevin Van",
            "Zhijie Xia",
            "Ryo Suzuki"
        ],
        "published": "2024-05-28T00:03:41Z"
    },
    {
        "title": "Does Geo-co-location Matter? A Case Study of Public Health Conversations\n  during COVID-19",
        "link": "http://arxiv.org/abs/2405.17710v1",
        "abstract": "Social media platforms like Twitter (now X) have been pivotal in information\ndissemination and public engagement, especially during COVID-19. A key goal for\npublic health experts was to encourage prosocial behavior that could impact\nlocal outcomes such as masking and social distancing. Given the importance of\nlocal news and guidance during COVID-19, the objective of our research is to\nanalyze the effect of localized engagement, on social media conversations. This\nstudy examines the impact of geographic co-location, as a proxy for localized\nengagement between public health experts (PHEs) and the public, on social\nmedia. We analyze a Twitter conversation dataset from January 2020 to November\n2021, comprising over 19 K tweets from nearly five hundred PHEs, along with\napproximately 800 K replies from 350 K participants. Our findings reveal that\ngeo-co-location is associated with higher engagement rates, especially in\nconversations on topics including masking, lockdowns, and education, and in\nconversations with academic and medical professionals. Lexical features\nassociated with emotion and personal experiences were more common in\ngeo-co-located contexts. This research provides insights into how geographic\nco-location influences social media engagement and can inform strategies to\nimprove public health messaging.",
        "subjects": [
            "cs.SI",
            "cs.CL"
        ],
        "authors": [
            "Paiheng Xu",
            "Louiqa Raschid",
            "Vanessa Frias-Martinez"
        ],
        "published": "2024-05-28T00:00:04Z"
    }
]