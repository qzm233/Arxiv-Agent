[
    {
        "title": "Unique3D: High-Quality and Efficient 3D Mesh Generation from a Single\n  Image",
        "link": "http://arxiv.org/abs/2405.20343v1",
        "abstract": "In this work, we introduce Unique3D, a novel image-to-3D framework for\nefficiently generating high-quality 3D meshes from single-view images,\nfeaturing state-of-the-art generation fidelity and strong generalizability.\nPrevious methods based on Score Distillation Sampling (SDS) can produce\ndiversified 3D results by distilling 3D knowledge from large 2D diffusion\nmodels, but they usually suffer from long per-case optimization time with\ninconsistent issues. Recent works address the problem and generate better 3D\nresults either by finetuning a multi-view diffusion model or training a fast\nfeed-forward model. However, they still lack intricate textures and complex\ngeometries due to inconsistency and limited generated resolution. To\nsimultaneously achieve high fidelity, consistency, and efficiency in single\nimage-to-3D, we propose a novel framework Unique3D that includes a multi-view\ndiffusion model with a corresponding normal diffusion model to generate\nmulti-view images with their normal maps, a multi-level upscale process to\nprogressively improve the resolution of generated orthographic multi-views, as\nwell as an instant and consistent mesh reconstruction algorithm called ISOMER,\nwhich fully integrates the color and geometric priors into mesh results.\nExtensive experiments demonstrate that our Unique3D significantly outperforms\nother image-to-3D baselines in terms of geometric and textural details.",
        "subjects": [
            "cs.CV",
            "cs.GR",
            "cs.LG",
            "I.2.10"
        ],
        "authors": [
            "Kailu Wu",
            "Fangfu Liu",
            "Zhihan Cai",
            "Runjie Yan",
            "Hanyang Wang",
            "Yating Hu",
            "Yueqi Duan",
            "Kaisheng Ma"
        ],
        "published": "2024-05-30T17:59:54Z"
    },
    {
        "title": "From Zero to Hero: Cold-Start Anomaly Detection",
        "link": "http://arxiv.org/abs/2405.20341v1",
        "abstract": "When first deploying an anomaly detection system, e.g., to detect\nout-of-scope queries in chatbots, there are no observed data, making\ndata-driven approaches ineffective. Zero-shot anomaly detection methods offer a\nsolution to such \"cold-start\" cases, but unfortunately they are often not\naccurate enough. This paper studies the realistic but underexplored cold-start\nsetting where an anomaly detection model is initialized using zero-shot\nguidance, but subsequently receives a small number of contaminated observations\n(namely, that may include anomalies). The goal is to make efficient use of both\nthe zero-shot guidance and the observations. We propose ColdFusion, a method\nthat effectively adapts the zero-shot anomaly detector to contaminated\nobservations. To support future development of this new setting, we propose an\nevaluation suite consisting of evaluation protocols and metrics.",
        "subjects": [
            "cs.LG",
            "cs.CL"
        ],
        "authors": [
            "Tal Reiss",
            "George Kour",
            "Naama Zwerdling",
            "Ateret Anaby-Tavor",
            "Yedid Hoshen"
        ],
        "published": "2024-05-30T17:59:51Z"
    },
    {
        "title": "MotionLLM: Understanding Human Behaviors from Human Motions and Videos",
        "link": "http://arxiv.org/abs/2405.20340v1",
        "abstract": "This study delves into the realm of multi-modality (i.e., video and motion\nmodalities) human behavior understanding by leveraging the powerful\ncapabilities of Large Language Models (LLMs). Diverging from recent LLMs\ndesigned for video-only or motion-only understanding, we argue that\nunderstanding human behavior necessitates joint modeling from both videos and\nmotion sequences (e.g., SMPL sequences) to capture nuanced body part dynamics\nand semantics effectively. In light of this, we present MotionLLM, a\nstraightforward yet effective framework for human motion understanding,\ncaptioning, and reasoning. Specifically, MotionLLM adopts a unified\nvideo-motion training strategy that leverages the complementary advantages of\nexisting coarse video-text data and fine-grained motion-text data to glean rich\nspatial-temporal insights. Furthermore, we collect a substantial dataset,\nMoVid, comprising diverse videos, motions, captions, and instructions.\nAdditionally, we propose the MoVid-Bench, with carefully manual annotations,\nfor better evaluation of human behavior understanding on video and motion.\nExtensive experiments show the superiority of MotionLLM in the caption,\nspatial-temporal comprehension, and reasoning ability.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ling-Hao Chen",
            "Shunlin Lu",
            "Ailing Zeng",
            "Hao Zhang",
            "Benyou Wang",
            "Ruimao Zhang",
            "Lei Zhang"
        ],
        "published": "2024-05-30T17:59:50Z"
    },
    {
        "title": "Visual Perception by Large Language Model's Weights",
        "link": "http://arxiv.org/abs/2405.20339v1",
        "abstract": "Existing Multimodal Large Language Models (MLLMs) follow the paradigm that\nperceives visual information by aligning visual features with the input space\nof Large Language Models (LLMs), and concatenating visual tokens with text\ntokens to form a unified sequence input for LLMs. These methods demonstrate\npromising results on various vision-language tasks but are limited by the high\ncomputational effort due to the extended input sequence resulting from the\ninvolvement of visual tokens. In this paper, instead of input space alignment,\nwe propose a novel parameter space alignment paradigm that represents visual\ninformation as model weights. For each input image, we use a vision encoder to\nextract visual features, convert features into perceptual weights, and merge\nthe perceptual weights with LLM's weights. In this way, the input of LLM does\nnot require visual tokens, which reduces the length of the input sequence and\ngreatly improves efficiency. Following this paradigm, we propose VLoRA with the\nperceptual weights generator. The perceptual weights generator is designed to\nconvert visual features to perceptual weights with low-rank property,\nexhibiting a form similar to LoRA. The experimental results show that our VLoRA\nachieves comparable performance on various benchmarks for MLLMs, while\nsignificantly reducing the computational costs for both training and inference.\nThe code and models will be made open-source.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Feipeng Ma",
            "Hongwei Xue",
            "Guangting Wang",
            "Yizhou Zhou",
            "Fengyun Rao",
            "Shilin Yan",
            "Yueyi Zhang",
            "Siying Wu",
            "Mike Zheng Shou",
            "Xiaoyan Sun"
        ],
        "published": "2024-05-30T17:59:47Z"
    },
    {
        "title": "Mixed finite element methods for fourth order obstacle problems in\n  linearised elasticity",
        "link": "http://arxiv.org/abs/2405.20338v1",
        "abstract": "This paper is devoted to the study of a novel mixed Finite Element Method for\napproximating the solutions of fourth order variational problems subjected to a\nconstraint.\n  The first problem we consider consists in establishing the convergence of the\nerror of the numerical approximation of the solution of a biharmonic obstacle\nproblem. The contents of this section are meant to generalise the approach\noriginally proposed by Ciarlet \\& Raviart, and then complemented by Ciarlet \\&\nGlowinski.\n  The second problem we consider amounts to studying a two-dimensional\nvariational problem for linearly elastic shallow shells subjected to remaining\nconfined in a prescribed half-space. We first study the case where the\nparametrisation of the middle surface for the linearly elastic shallow shell\nunder consideration has non-zero curvature, and we observe that the numerical\napproximation of this model via a mixed Finite Element Method based on\nconforming elements requires the implementation of the additional constraint\naccording to which the gradient matrix of the dual variable has to be\nsymmetric. However, differently from the biharmonic obstacle problem previously\nstudied, we show that the numerical implementation of this result cannot be\nimplemented by solely resorting to Courant triangles.\n  Finally, we show that if the middle surface of the linearly elastic shallow\nshell under consideration is flat, the symmetry constraint required for\nformulating the constrained mixed variational problem announced in the second\npart of the paper is not required, and the solution can thus be approximated by\nsolely resorting to Courant triangles.\n  The theoretical results we derived are complemented by a series of numerical\nexperiments.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Paolo Piersanti",
            "Tianyu Sun"
        ],
        "published": "2024-05-30T17:59:45Z"
    },
    {
        "title": "OccSora: 4D Occupancy Generation Models as World Simulators for\n  Autonomous Driving",
        "link": "http://arxiv.org/abs/2405.20337v1",
        "abstract": "Understanding the evolution of 3D scenes is important for effective\nautonomous driving. While conventional methods mode scene development with the\nmotion of individual instances, world models emerge as a generative framework\nto describe the general scene dynamics. However, most existing methods adopt an\nautoregressive framework to perform next-token prediction, which suffer from\ninefficiency in modeling long-term temporal evolutions. To address this, we\npropose a diffusion-based 4D occupancy generation model, OccSora, to simulate\nthe development of the 3D world for autonomous driving. We employ a 4D scene\ntokenizer to obtain compact discrete spatial-temporal representations for 4D\noccupancy input and achieve high-quality reconstruction for long-sequence\noccupancy videos. We then learn a diffusion transformer on the spatial-temporal\nrepresentations and generate 4D occupancy conditioned on a trajectory prompt.\nWe conduct extensive experiments on the widely used nuScenes dataset with Occ3D\noccupancy annotations. OccSora can generate 16s-videos with authentic 3D layout\nand temporal consistency, demonstrating its ability to understand the spatial\nand temporal distributions of driving scenes. With trajectory-aware 4D\ngeneration, OccSora has the potential to serve as a world simulator for the\ndecision-making of autonomous driving. Code is available at:\nhttps://github.com/wzzheng/OccSora.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Lening Wang",
            "Wenzhao Zheng",
            "Yilong Ren",
            "Han Jiang",
            "Zhiyong Cui",
            "Haiyang Yu",
            "Jiwen Lu"
        ],
        "published": "2024-05-30T17:59:42Z"
    },
    {
        "title": "RapVerse: Coherent Vocals and Whole-Body Motions Generations from Text",
        "link": "http://arxiv.org/abs/2405.20336v1",
        "abstract": "In this work, we introduce a challenging task for simultaneously generating\n3D holistic body motions and singing vocals directly from textual lyrics\ninputs, advancing beyond existing works that typically address these two\nmodalities in isolation. To facilitate this, we first collect the RapVerse\ndataset, a large dataset containing synchronous rapping vocals, lyrics, and\nhigh-quality 3D holistic body meshes. With the RapVerse dataset, we investigate\nthe extent to which scaling autoregressive multimodal transformers across\nlanguage, audio, and motion can enhance the coherent and realistic generation\nof vocals and whole-body human motions. For modality unification, a\nvector-quantized variational autoencoder is employed to encode whole-body\nmotion sequences into discrete motion tokens, while a vocal-to-unit model is\nleveraged to obtain quantized audio tokens preserving content, prosodic\ninformation, and singer identity. By jointly performing transformer modeling on\nthese three modalities in a unified way, our framework ensures a seamless and\nrealistic blend of vocals and human motions. Extensive experiments demonstrate\nthat our unified generation framework not only produces coherent and realistic\nsinging vocals alongside human motions directly from textual inputs but also\nrivals the performance of specialized single-modality generation systems,\nestablishing new benchmarks for joint vocal-motion generation. The project page\nis available for research purposes at https://vis-www.cs.umass.edu/RapVerse.",
        "subjects": [
            "cs.CV",
            "cs.SD",
            "eess.AS"
        ],
        "authors": [
            "Jiaben Chen",
            "Xin Yan",
            "Yihang Chen",
            "Siyuan Cen",
            "Qinwei Ma",
            "Haoyu Zhen",
            "Kaizhi Qian",
            "Lie Lu",
            "Chuang Gan"
        ],
        "published": "2024-05-30T17:59:39Z"
    },
    {
        "title": "Xwin-LM: Strong and Scalable Alignment Practice for LLMs",
        "link": "http://arxiv.org/abs/2405.20335v1",
        "abstract": "In this work, we present Xwin-LM, a comprehensive suite of alignment\nmethodologies for large language models (LLMs). This suite encompasses several\nkey techniques, including supervised finetuning (SFT), reward modeling (RM),\nrejection sampling finetuning (RS), and direct preference optimization (DPO).\nThe key components are as follows: (1) Xwin-LM-SFT, models initially finetuned\nwith high-quality instruction data; (2) Xwin-Pair, a large-scale, multi-turn\npreference dataset meticulously annotated using GPT-4; (3) Xwin-RM, reward\nmodels trained on Xwin-Pair, developed at scales of 7B, 13B, and 70B\nparameters; (4) Xwin-Set, a multiwise preference dataset in which each prompt\nis linked to 64 unique responses generated by Xwin-LM-SFT and scored by\nXwin-RM; (5) Xwin-LM-RS, models finetuned with the highest-scoring responses\nfrom Xwin-Set; (6) Xwin-LM-DPO, models further optimized on Xwin-Set using the\nDPO algorithm. Our evaluations on AlpacaEval and MT-bench demonstrate\nconsistent and significant improvements across the pipeline, demonstrating the\nstrength and scalability of Xwin-LM. The repository\nhttps://github.com/Xwin-LM/Xwin-LM will be continually updated to foster\ncommunity research.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Bolin Ni",
            "JingCheng Hu",
            "Yixuan Wei",
            "Houwen Peng",
            "Zheng Zhang",
            "Gaofeng Meng",
            "Han Hu"
        ],
        "published": "2024-05-30T17:59:31Z"
    },
    {
        "title": "VividDream: Generating 3D Scene with Ambient Dynamics",
        "link": "http://arxiv.org/abs/2405.20334v1",
        "abstract": "We introduce VividDream, a method for generating explorable 4D scenes with\nambient dynamics from a single input image or text prompt. VividDream first\nexpands an input image into a static 3D point cloud through iterative\ninpainting and geometry merging. An ensemble of animated videos is then\ngenerated using video diffusion models with quality refinement techniques and\nconditioned on renderings of the static 3D scene from the sampled camera\ntrajectories. We then optimize a canonical 4D scene representation using an\nanimated video ensemble, with per-video motion embeddings and visibility masks\nto mitigate inconsistencies. The resulting 4D scene enables free-view\nexploration of a 3D scene with plausible ambient scene dynamics. Experiments\ndemonstrate that VividDream can provide human viewers with compelling 4D\nexperiences generated based on diverse real images and text prompts.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "authors": [
            "Yao-Chih Lee",
            "Yi-Ting Chen",
            "Andrew Wang",
            "Ting-Hsuan Liao",
            "Brandon Y. Feng",
            "Jia-Bin Huang"
        ],
        "published": "2024-05-30T17:59:24Z"
    },
    {
        "title": "SurgiTrack: Fine-Grained Multi-Class Multi-Tool Tracking in Surgical\n  Videos",
        "link": "http://arxiv.org/abs/2405.20333v1",
        "abstract": "Accurate tool tracking is essential for the success of computer-assisted\nintervention. Previous efforts often modeled tool trajectories rigidly,\noverlooking the dynamic nature of surgical procedures, especially tracking\nscenarios like out-of-body and out-of-camera views. Addressing this limitation,\nthe new CholecTrack20 dataset provides detailed labels that account for\nmultiple tool trajectories in three perspectives: (1) intraoperative, (2)\nintracorporeal, and (3) visibility, representing the different types of\ntemporal duration of tool tracks. These fine-grained labels enhance tracking\nflexibility but also increase the task complexity. Re-identifying tools after\nocclusion or re-insertion into the body remains challenging due to high visual\nsimilarity, especially among tools of the same category. This work recognizes\nthe critical role of the tool operators in distinguishing tool track instances,\nespecially those belonging to the same tool category. The operators'\ninformation are however not explicitly captured in surgical videos. We\ntherefore propose SurgiTrack, a novel deep learning method that leverages\nYOLOv7 for precise tool detection and employs an attention mechanism to model\nthe originating direction of the tools, as a proxy to their operators, for tool\nre-identification. To handle diverse tool trajectory perspectives, SurgiTrack\nemploys a harmonizing bipartite matching graph, minimizing conflicts and\nensuring accurate tool identity association. Experimental results on\nCholecTrack20 demonstrate SurgiTrack's effectiveness, outperforming baselines\nand state-of-the-art methods with real-time inference capability. This work\nsets a new standard in surgical tool tracking, providing dynamic trajectories\nfor more adaptable and precise assistance in minimally invasive surgeries.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Chinedu Innocent Nwoye",
            "Nicolas Padoy"
        ],
        "published": "2024-05-30T17:59:10Z"
    },
    {
        "title": "CoSy: Evaluating Textual Explanations of Neurons",
        "link": "http://arxiv.org/abs/2405.20331v1",
        "abstract": "A crucial aspect of understanding the complex nature of Deep Neural Networks\n(DNNs) is the ability to explain learned concepts within their latent\nrepresentations. While various methods exist to connect neurons to textual\ndescriptions of human-understandable concepts, evaluating the quality of these\nexplanation methods presents a major challenge in the field due to a lack of\nunified, general-purpose quantitative evaluation. In this work, we introduce\nCoSy (Concept Synthesis) -- a novel, architecture-agnostic framework to\nevaluate the quality of textual explanations for latent neurons. Given textual\nexplanations, our proposed framework leverages a generative model conditioned\non textual input to create data points representing the textual explanation.\nThen, the neuron's response to these explanation data points is compared with\nthe response to control data points, providing a quality estimate of the given\nexplanation. We ensure the reliability of our proposed framework in a series of\nmeta-evaluation experiments and demonstrate practical value through insights\nfrom benchmarking various concept-based textual explanation methods for\nComputer Vision tasks, showing that tested explanation methods significantly\ndiffer in quality.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Laura Kopf",
            "Philine Lou Bommer",
            "Anna Hedström",
            "Sebastian Lapuschkin",
            "Marina M. -C. Höhne",
            "Kirill Bykov"
        ],
        "published": "2024-05-30T17:59:04Z"
    },
    {
        "title": "4DHands: Reconstructing Interactive Hands in 4D with Transformers",
        "link": "http://arxiv.org/abs/2405.20330v1",
        "abstract": "In this paper, we introduce 4DHands, a robust approach to recovering\ninteractive hand meshes and their relative movement from monocular inputs. Our\napproach addresses two major limitations of previous methods: lacking a unified\nsolution for handling various hand image inputs and neglecting the positional\nrelationship of two hands within images. To overcome these challenges, we\ndevelop a transformer-based architecture with novel tokenization and feature\nfusion strategies. Specifically, we propose a Relation-aware Two-Hand\nTokenization (RAT) method to embed positional relation information into the\nhand tokens. In this way, our network can handle both single-hand and two-hand\ninputs and explicitly leverage relative hand positions, facilitating the\nreconstruction of intricate hand interactions in real-world scenarios. As such\ntokenization indicates the relative relationship of two hands, it also supports\nmore effective feature fusion. To this end, we further develop a\nSpatio-temporal Interaction Reasoning (SIR) module to fuse hand tokens in 4D\nwith attention and decode them into 3D hand meshes and relative temporal\nmovements. The efficacy of our approach is validated on several benchmark\ndatasets. The results on in-the-wild videos and real-world scenarios\ndemonstrate the superior performances of our approach for interactive hand\nreconstruction. More video results can be found on the project page:\nhttps://4dhands.github.io.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR"
        ],
        "authors": [
            "Dixuan Lin",
            "Yuxiang Zhang",
            "Mengcheng Li",
            "Yebin Liu",
            "Wei Jing",
            "Qi Yan",
            "Qianying Wang",
            "Hongwen Zhang"
        ],
        "published": "2024-05-30T17:59:02Z"
    },
    {
        "title": "GECO: Generative Image-to-3D within a SECOnd",
        "link": "http://arxiv.org/abs/2405.20327v1",
        "abstract": "3D generation has seen remarkable progress in recent years. Existing\ntechniques, such as score distillation methods, produce notable results but\nrequire extensive per-scene optimization, impacting time efficiency.\nAlternatively, reconstruction-based approaches prioritize efficiency but\ncompromise quality due to their limited handling of uncertainty. We introduce\nGECO, a novel method for high-quality 3D generative modeling that operates\nwithin a second. Our approach addresses the prevalent issues of uncertainty and\ninefficiency in current methods through a two-stage approach. In the initial\nstage, we train a single-step multi-view generative model with score\ndistillation. Then, a second-stage distillation is applied to address the\nchallenge of view inconsistency from the multi-view prediction. This two-stage\nprocess ensures a balanced approach to 3D generation, optimizing both quality\nand efficiency. Our comprehensive experiments demonstrate that GECO achieves\nhigh-quality image-to-3D generation with an unprecedented level of efficiency.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Chen Wang",
            "Jiatao Gu",
            "Xiaoxiao Long",
            "Yuan Liu",
            "Lingjie Liu"
        ],
        "published": "2024-05-30T17:58:00Z"
    },
    {
        "title": "MotionFollower: Editing Video Motion via Lightweight Score-Guided\n  Diffusion",
        "link": "http://arxiv.org/abs/2405.20325v1",
        "abstract": "Despite impressive advancements in diffusion-based video editing models in\naltering video attributes, there has been limited exploration into modifying\nmotion information while preserving the original protagonist's appearance and\nbackground. In this paper, we propose MotionFollower, a lightweight\nscore-guided diffusion model for video motion editing. To introduce conditional\ncontrols to the denoising process, MotionFollower leverages two of our proposed\nlightweight signal controllers, one for poses and the other for appearances,\nboth of which consist of convolution blocks without involving heavy attention\ncalculations. Further, we design a score guidance principle based on a\ntwo-branch architecture, including the reconstruction and editing branches,\nwhich significantly enhance the modeling capability of texture details and\ncomplicated backgrounds. Concretely, we enforce several consistency\nregularizers and losses during the score estimation. The resulting gradients\nthus inject appropriate guidance to the intermediate latents, forcing the model\nto preserve the original background details and protagonists' appearances\nwithout interfering with the motion modification. Experiments demonstrate the\ncompetitive motion editing ability of MotionFollower qualitatively and\nquantitatively. Compared with MotionEditor, the most advanced motion editing\nmodel, MotionFollower achieves an approximately 80% reduction in GPU memory\nwhile delivering superior motion editing performance and exclusively supporting\nlarge camera movements and actions.",
        "subjects": [
            "cs.CV",
            "68T45, 68T10"
        ],
        "authors": [
            "Shuyuan Tu",
            "Qi Dai",
            "Zihao Zhang",
            "Sicheng Xie",
            "Zhi-Qi Cheng",
            "Chong Luo",
            "Xintong Han",
            "Zuxuan Wu",
            "Yu-Gang Jiang"
        ],
        "published": "2024-05-30T17:57:30Z"
    },
    {
        "title": "Don't drop your samples! Coherence-aware training benefits Conditional\n  diffusion",
        "link": "http://arxiv.org/abs/2405.20324v1",
        "abstract": "Conditional diffusion models are powerful generative models that can leverage\nvarious types of conditional information, such as class labels, segmentation\nmasks, or text captions. However, in many real-world scenarios, conditional\ninformation may be noisy or unreliable due to human annotation errors or weak\nalignment. In this paper, we propose the Coherence-Aware Diffusion (CAD), a\nnovel method that integrates coherence in conditional information into\ndiffusion models, allowing them to learn from noisy annotations without\ndiscarding data. We assume that each data point has an associated coherence\nscore that reflects the quality of the conditional information. We then\ncondition the diffusion model on both the conditional information and the\ncoherence score. In this way, the model learns to ignore or discount the\nconditioning when the coherence is low. We show that CAD is theoretically sound\nand empirically effective on various conditional generation tasks. Moreover, we\nshow that leveraging coherence generates realistic and diverse samples that\nrespect conditional information better than models trained on cleaned datasets\nwhere samples with low coherence have been discarded.",
        "subjects": [
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Nicolas Dufour",
            "Victor Besnier",
            "Vicky Kalogeiton",
            "David Picard"
        ],
        "published": "2024-05-30T17:57:26Z"
    },
    {
        "title": "$\\textit{S}^3$Gaussian: Self-Supervised Street Gaussians for Autonomous\n  Driving",
        "link": "http://arxiv.org/abs/2405.20323v1",
        "abstract": "Photorealistic 3D reconstruction of street scenes is a critical technique for\ndeveloping real-world simulators for autonomous driving. Despite the efficacy\nof Neural Radiance Fields (NeRF) for driving scenes, 3D Gaussian Splatting\n(3DGS) emerges as a promising direction due to its faster speed and more\nexplicit representation. However, most existing street 3DGS methods require\ntracked 3D vehicle bounding boxes to decompose the static and dynamic elements\nfor effective reconstruction, limiting their applications for in-the-wild\nscenarios. To facilitate efficient 3D scene reconstruction without costly\nannotations, we propose a self-supervised street Gaussian\n($\\textit{S}^3$Gaussian) method to decompose dynamic and static elements from\n4D consistency. We represent each scene with 3D Gaussians to preserve the\nexplicitness and further accompany them with a spatial-temporal field network\nto compactly model the 4D dynamics. We conduct extensive experiments on the\nchallenging Waymo-Open dataset to evaluate the effectiveness of our method. Our\n$\\textit{S}^3$Gaussian demonstrates the ability to decompose static and dynamic\nscenes and achieves the best performance without using 3D annotations. Code is\navailable at: https://github.com/nnanhuang/S3Gaussian/.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Nan Huang",
            "Xiaobao Wei",
            "Wenzhao Zheng",
            "Pengju An",
            "Ming Lu",
            "Wei Zhan",
            "Masayoshi Tomizuka",
            "Kurt Keutzer",
            "Shanghang Zhang"
        ],
        "published": "2024-05-30T17:57:08Z"
    },
    {
        "title": "Quantum generalizations of Glauber and Metropolis dynamics",
        "link": "http://arxiv.org/abs/2405.20322v1",
        "abstract": "Classical Markov Chain Monte Carlo methods have been essential for simulating\nstatistical physical systems and have proven well applicable to other systems\nwith complex degrees of freedom. Motivated by the statistical physics origins,\nChen, Kastoryano, and Gily\\'en [CKG23] proposed a continuous-time quantum\nthermodynamic analog to Glauber dynamic that is (i) exactly detailed balanced,\n(ii) efficiently implementable, and (iii) quasi-local for geometrically local\nsystems. Physically, their construction gives a smooth variant of the Davies'\ngenerator derived from weak system-bath interaction. In this work, we give an\nefficiently implementable discrete-time quantum counterpart to Metropolis\nsampling that also enjoys the desirable features (i)-(iii). Also, we give an\nalternative highly coherent quantum generalization of detailed balanced\ndynamics that resembles another physically derived master equation, and propose\na smooth interpolation between this and earlier constructions. We study generic\nproperties of all constructions, including the uniqueness of the fixed-point\nand the locality of the resulting operators. We hope our results provide a\nsystematic approach to the possible quantum generalizations of classical\nGlauber and Metropolis dynamics.",
        "subjects": [
            "quant-ph",
            "cs.DS"
        ],
        "authors": [
            "András Gilyén",
            "Chi-Fang Chen",
            "Joao F. Doriguello",
            "Michael J. Kastoryano"
        ],
        "published": "2024-05-30T17:57:04Z"
    },
    {
        "title": "Vision-based Manipulation from Single Human Video with Open-World Object\n  Graphs",
        "link": "http://arxiv.org/abs/2405.20321v1",
        "abstract": "We present an object-centric approach to empower robots to learn vision-based\nmanipulation skills from human videos. We investigate the problem of imitating\nrobot manipulation from a single human video in the open-world setting, where a\nrobot must learn to manipulate novel objects from one video demonstration. We\nintroduce ORION, an algorithm that tackles the problem by extracting an\nobject-centric manipulation plan from a single RGB-D video and deriving a\npolicy that conditions on the extracted plan. Our method enables the robot to\nlearn from videos captured by daily mobile devices such as an iPad and\ngeneralize the policies to deployment environments with varying visual\nbackgrounds, camera angles, spatial layouts, and novel object instances. We\nsystematically evaluate our method on both short-horizon and long-horizon\ntasks, demonstrating the efficacy of ORION in learning from a single human\nvideo in the open world. Videos can be found in the project website\nhttps://ut-austin-rpl.github.io/ORION-release.",
        "subjects": [
            "cs.RO",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Yifeng Zhu",
            "Arisrei Lim",
            "Peter Stone",
            "Yuke Zhu"
        ],
        "published": "2024-05-30T17:56:54Z"
    },
    {
        "title": "Improving the Training of Rectified Flows",
        "link": "http://arxiv.org/abs/2405.20320v1",
        "abstract": "Diffusion models have shown great promise for image and video generation, but\nsampling from state-of-the-art models requires expensive numerical integration\nof a generative ODE. One approach for tackling this problem is rectified flows,\nwhich iteratively learn smooth ODE paths that are less susceptible to\ntruncation error. However, rectified flows still require a relatively large\nnumber of function evaluations (NFEs). In this work, we propose improved\ntechniques for training rectified flows, allowing them to compete with\nknowledge distillation methods even in the low NFE setting. Our main insight is\nthat under realistic settings, a single iteration of the Reflow algorithm for\ntraining rectified flows is sufficient to learn nearly straight trajectories;\nhence, the current practice of using multiple Reflow iterations is unnecessary.\nWe thus propose techniques to improve one-round training of rectified flows,\nincluding a U-shaped timestep distribution and LPIPS-Huber premetric. With\nthese techniques, we improve the FID of the previous 2-rectified flow by up to\n72% in the 1 NFE setting on CIFAR-10. On ImageNet 64$\\times$64, our improved\nrectified flow outperforms the state-of-the-art distillation methods such as\nconsistency distillation and progressive distillation in both one-step and\ntwo-step settings and rivals the performance of improved consistency training\n(iCT) in FID. Code is available at https://github.com/sangyun884/rfpp.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Sangyun Lee",
            "Zinan Lin",
            "Giulia Fanti"
        ],
        "published": "2024-05-30T17:56:04Z"
    },
    {
        "title": "ParSEL: Parameterized Shape Editing with Language",
        "link": "http://arxiv.org/abs/2405.20319v1",
        "abstract": "The ability to edit 3D assets from natural language presents a compelling\nparadigm to aid in the democratization of 3D content creation. However, while\nnatural language is often effective at communicating general intent, it is\npoorly suited for specifying precise manipulation. To address this gap, we\nintroduce ParSEL, a system that enables controllable editing of high-quality 3D\nassets from natural language. Given a segmented 3D mesh and an editing request,\nParSEL produces a parameterized editing program. Adjusting the program\nparameters allows users to explore shape variations with a precise control over\nthe magnitudes of edits. To infer editing programs which align with an input\nedit request, we leverage the abilities of large-language models (LLMs).\nHowever, while we find that LLMs excel at identifying initial edit operations,\nthey often fail to infer complete editing programs, and produce outputs that\nviolate shape semantics. To overcome this issue, we introduce Analytical Edit\nPropagation (AEP), an algorithm which extends a seed edit with additional\noperations until a complete editing program has been formed. Unlike prior\nmethods, AEP searches for analytical editing operations compatible with a range\nof possible user edits through the integration of computer algebra systems for\ngeometric analysis. Experimentally we demonstrate ParSEL's effectiveness in\nenabling controllable editing of 3D objects through natural language requests\nover alternative system designs.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.GR",
            "cs.HC",
            "cs.SC"
        ],
        "authors": [
            "Aditya Ganeshan",
            "Ryan Y. Huang",
            "Xianghao Xu",
            "R. Kenny Jones",
            "Daniel Ritchie"
        ],
        "published": "2024-05-30T17:55:46Z"
    },
    {
        "title": "CausalQuest: Collecting Natural Causal Questions for AI Agents",
        "link": "http://arxiv.org/abs/2405.20318v1",
        "abstract": "Humans have an innate drive to seek out causality. Whether fuelled by\ncuriosity or specific goals, we constantly question why things happen, how they\nare interconnected, and many other related phenomena. To develop AI agents\ncapable of addressing this natural human quest for causality, we urgently need\na comprehensive dataset of natural causal questions. Unfortunately, existing\ndatasets either contain only artificially-crafted questions that do not reflect\nreal AI usage scenarios or have limited coverage of questions from specific\nsources. To address this gap, we present CausalQuest, a dataset of 13,500\nnaturally occurring questions sourced from social networks, search engines, and\nAI assistants. We formalize the definition of causal questions and establish a\ntaxonomy for finer-grained classification. Through a combined effort of human\nannotators and large language models (LLMs), we carefully label the dataset. We\nfind that 42% of the questions humans ask are indeed causal, with the majority\nseeking to understand the causes behind given effects. Using this dataset, we\ntrain efficient classifiers (up to 2.85B parameters) for the binary task of\nidentifying causal questions, achieving high performance with F1 scores of up\nto 0.877. We conclude with a rich set of future research directions that can\nbuild upon our data and models.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Roberto Ceraolo",
            "Dmitrii Kharlapenko",
            "Amélie Reymond",
            "Rada Mihalcea",
            "Mrinmaya Sachan",
            "Bernhard Schölkopf",
            "Zhijing Jin"
        ],
        "published": "2024-05-30T17:55:28Z"
    },
    {
        "title": "ANAH: Analytical Annotation of Hallucinations in Large Language Models",
        "link": "http://arxiv.org/abs/2405.20315v1",
        "abstract": "Reducing the `$\\textit{hallucination}$' problem of Large Language Models\n(LLMs) is crucial for their wide applications. A comprehensive and fine-grained\nmeasurement of the hallucination is the first key step for the governance of\nthis issue but is under-explored in the community. Thus, we present\n$\\textbf{ANAH}$, a bilingual dataset that offers $\\textbf{AN}$alytical\n$\\textbf{A}$nnotation of $\\textbf{H}$allucinations in LLMs within Generative\nQuestion Answering. Each answer sentence in our dataset undergoes rigorous\nannotation, involving the retrieval of a reference fragment, the judgment of\nthe hallucination type, and the correction of hallucinated content. ANAH\nconsists of ~12k sentence-level annotations for ~4.3k LLM responses covering\nover 700 topics, constructed by a human-in-the-loop pipeline. Thanks to the\nfine granularity of the hallucination annotations, we can quantitatively\nconfirm that the hallucinations of LLMs progressively accumulate in the answer\nand use ANAH to train and evaluate hallucination annotators. We conduct\nextensive experiments on studying generative and discriminative annotators and\nshow that, although current open-source LLMs have difficulties in fine-grained\nhallucination annotation, the generative annotator trained with ANAH can\nsurpass all open-source LLMs and GPT-3.5, obtain performance competitive with\nGPT-4, and exhibits better generalization ability on unseen questions.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Ziwei Ji",
            "Yuzhe Gu",
            "Wenwei Zhang",
            "Chengqi Lyu",
            "Dahua Lin",
            "Kai Chen"
        ],
        "published": "2024-05-30T17:54:40Z"
    },
    {
        "title": "S3D: A Simple and Cost-Effective Self-Speculative Decoding Scheme for\n  Low-Memory GPUs",
        "link": "http://arxiv.org/abs/2405.20314v1",
        "abstract": "Speculative decoding (SD) has attracted a significant amount of research\nattention due to the substantial speedup it can achieve for LLM inference.\nHowever, despite the high speedups they offer, speculative decoding methods\noften achieve optimal performance on high-end devices or with a substantial GPU\nmemory overhead. Given limited memory and the necessity of quantization, a\nhigh-performing model on a high-end GPU can slow down by up to 7 times. To this\nend, we propose Skippy Simultaneous Speculative Decoding (or S3D), a\ncost-effective self-speculative SD method based on simultaneous multi-token\ndecoding and mid-layer skipping. When compared against recent effective\nopen-source SD systems, our method has achieved one of the top\nperformance-memory ratios while requiring minimal architecture changes and\ntraining data. Leveraging our memory efficiency, we created a smaller yet more\neffective SD model based on Phi-3. It is 1.4 to 2 times faster than the\nquantized EAGLE model and operates in half-precision while using less VRAM.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Wei Zhong",
            "Manasa Bharadwaj"
        ],
        "published": "2024-05-30T17:54:35Z"
    },
    {
        "title": "Sequence-Augmented SE(3)-Flow Matching For Conditional Protein Backbone\n  Generation",
        "link": "http://arxiv.org/abs/2405.20313v1",
        "abstract": "Proteins are essential for almost all biological processes and derive their\ndiverse functions from complex 3D structures, which are in turn determined by\ntheir amino acid sequences. In this paper, we exploit the rich biological\ninductive bias of amino acid sequences and introduce FoldFlow-2, a novel\nsequence-conditioned SE(3)-equivariant flow matching model for protein\nstructure generation. FoldFlow-2 presents substantial new architectural\nfeatures over the previous FoldFlow family of models including a protein large\nlanguage model to encode sequence, a new multi-modal fusion trunk that combines\nstructure and sequence representations, and a geometric transformer based\ndecoder. To increase diversity and novelty of generated samples -- crucial for\nde-novo drug design -- we train FoldFlow-2 at scale on a new dataset that is an\norder of magnitude larger than PDB datasets of prior works, containing both\nknown proteins in PDB and high-quality synthetic structures achieved through\nfiltering. We further demonstrate the ability to align FoldFlow-2 to arbitrary\nrewards, e.g. increasing secondary structures diversity, by introducing a\nReinforced Finetuning (ReFT) objective. We empirically observe that FoldFlow-2\noutperforms previous state-of-the-art protein structure-based generative\nmodels, improving over RFDiffusion in terms of unconditional generation across\nall metrics including designability, diversity, and novelty across all protein\nlengths, as well as exhibiting generalization on the task of equilibrium\nconformation sampling. Finally, we demonstrate that a fine-tuned FoldFlow-2\nmakes progress on challenging conditional design tasks such as designing\nscaffolds for the VHH nanobody.",
        "subjects": [
            "cs.LG",
            "q-bio.BM"
        ],
        "authors": [
            "Guillaume Huguet",
            "James Vuckovic",
            "Kilian Fatras",
            "Eric Thibodeau-Laufer",
            "Pablo Lemos",
            "Riashat Islam",
            "Cheng-Hao Liu",
            "Jarrid Rector-Brooks",
            "Tara Akhound-Sadegh",
            "Michael Bronstein",
            "Alexander Tong",
            "Avishek Joey Bose"
        ],
        "published": "2024-05-30T17:53:50Z"
    },
    {
        "title": "A Pixel Is Worth More Than One 3D Gaussians in Single-View 3D\n  Reconstruction",
        "link": "http://arxiv.org/abs/2405.20310v1",
        "abstract": "Learning 3D scene representation from a single-view image is a long-standing\nfundamental problem in computer vision, with the inherent ambiguity in\npredicting contents unseen from the input view. Built on the recently proposed\n3D Gaussian Splatting (3DGS), the Splatter Image method has made promising\nprogress on fast single-image novel view synthesis via learning a single 3D\nGaussian for each pixel based on the U-Net feature map of an input image.\nHowever, it has limited expressive power to represent occluded components that\nare not observable in the input view. To address this problem, this paper\npresents a Hierarchical Splatter Image method in which a pixel is worth more\nthan one 3D Gaussians. Specifically,\n  each pixel is represented by a parent 3D Gaussian and a small number of child\n3D Gaussians. Parent 3D Gaussians are learned as done in the vanilla Splatter\nImage. Child 3D Gaussians are learned via a lightweight Multi-Layer Perceptron\n(MLP) which takes as input the projected image features of a parent 3D Gaussian\nand the embedding of a target camera view. Both parent and child 3D Gaussians\nare learned end-to-end in a stage-wise way. The joint condition of input image\nfeatures from eyes of the parent Gaussians and the target camera position\nfacilitates learning to allocate child Gaussians to ``see the unseen'',\nrecovering the occluded details that are often missed by parent Gaussians.\n  In experiments, the proposed method is tested on the ShapeNet-SRN and CO3D\ndatasets with state-of-the-art performance obtained, especially showing\npromising capabilities of reconstructing occluded contents in the input view.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jianghao Shen",
            "Tianfu Wu"
        ],
        "published": "2024-05-30T17:52:52Z"
    },
    {
        "title": "Large Language Models Can Self-Improve At Web Agent Tasks",
        "link": "http://arxiv.org/abs/2405.20309v1",
        "abstract": "Training models to act as agents that can effectively navigate and perform\nactions in a complex environment, such as a web browser, has typically been\nchallenging due to lack of training data. Large language models (LLMs) have\nrecently demonstrated some capability to navigate novel environments as agents\nin a zero-shot or few-shot fashion, purely guided by natural language\ninstructions as prompts. Recent research has also demonstrated LLMs have the\ncapability to exceed their base performance through self-improvement, i.e.\nfine-tuning on data generated by the model itself. In this work, we explore the\nextent to which LLMs can self-improve their performance as agents in\nlong-horizon tasks in a complex environment using the WebArena benchmark. In\nWebArena, an agent must autonomously navigate and perform actions on web pages\nto achieve a specified objective. We explore fine-tuning on three distinct\nsynthetic training data mixtures and achieve a 31\\% improvement in task\ncompletion rate over the base model on the WebArena benchmark through a\nself-improvement procedure. We additionally contribute novel evaluation metrics\nfor assessing the performance, robustness, capabilities, and quality of\ntrajectories of our fine-tuned agent models to a greater degree than simple,\naggregate-level benchmark scores currently used to measure self-improvement.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Ajay Patel",
            "Markus Hofmarcher",
            "Claudiu Leoveanu-Condrei",
            "Marius-Constantin Dinu",
            "Chris Callison-Burch",
            "Sepp Hochreiter"
        ],
        "published": "2024-05-30T17:52:36Z"
    },
    {
        "title": "Can't make an Omelette without Breaking some Eggs: Plausible Action\n  Anticipation using Large Video-Language Models",
        "link": "http://arxiv.org/abs/2405.20305v1",
        "abstract": "We introduce PlausiVL, a large video-language model for anticipating action\nsequences that are plausible in the real-world. While significant efforts have\nbeen made towards anticipating future actions, prior approaches do not take\ninto account the aspect of plausibility in an action sequence. To address this\nlimitation, we explore the generative capability of a large video-language\nmodel in our work and further, develop the understanding of plausibility in an\naction sequence by introducing two objective functions, a counterfactual-based\nplausible action sequence learning loss and a long-horizon action repetition\nloss. We utilize temporal logical constraints as well as verb-noun action pair\nlogical constraints to create implausible/counterfactual action sequences and\nuse them to train the model with plausible action sequence learning loss. This\nloss helps the model to differentiate between plausible and not plausible\naction sequences and also helps the model to learn implicit temporal cues\ncrucial for the task of action anticipation. The long-horizon action repetition\nloss puts a higher penalty on the actions that are more prone to repetition\nover a longer temporal window. With this penalization, the model is able to\ngenerate diverse, plausible action sequences. We evaluate our approach on two\nlarge-scale datasets, Ego4D and EPIC-Kitchens-100, and show improvements on the\ntask of action anticipation.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Himangi Mittal",
            "Nakul Agarwal",
            "Shao-Yuan Lo",
            "Kwonjoon Lee"
        ],
        "published": "2024-05-30T17:50:08Z"
    },
    {
        "title": "Group Robust Preference Optimization in Reward-free RLHF",
        "link": "http://arxiv.org/abs/2405.20304v1",
        "abstract": "Adapting large language models (LLMs) for specific tasks usually involves\nfine-tuning through reinforcement learning with human feedback (RLHF) on\npreference data. While these data often come from diverse labelers' groups\n(e.g., different demographics, ethnicities, company teams, etc.), traditional\nRLHF approaches adopt a \"one-size-fits-all\" approach, i.e., they\nindiscriminately assume and optimize a single preference model, thus not being\nrobust to unique characteristics and needs of the various groups. To address\nthis limitation, we propose a novel Group Robust Preference Optimization (GRPO)\nmethod to align LLMs to individual groups' preferences robustly. Our approach\nbuilds upon reward-free direct preference optimization methods, but unlike\nprevious approaches, it seeks a robust policy which maximizes the worst-case\ngroup performance. To achieve this, GRPO adaptively and sequentially weights\nthe importance of different groups, prioritizing groups with worse cumulative\nloss. We theoretically study the feasibility of GRPO and analyze its\nconvergence for the log-linear policy class. By fine-tuning LLMs with GRPO\nusing diverse group-based global opinion data, we significantly improved\nperformance for the worst-performing groups, reduced loss imbalances across\ngroups, and improved probability accuracies compared to non-robust baselines.",
        "subjects": [
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Shyam Sundhar Ramesh",
            "Yifan Hu",
            "Iason Chaimalas",
            "Viraj Mehta",
            "Pier Giuseppe Sessa",
            "Haitham Bou Ammar",
            "Ilija Bogunovic"
        ],
        "published": "2024-05-30T17:50:04Z"
    },
    {
        "title": "Truthful Budget Aggregation: Beyond Moving-Phantom Mechanisms",
        "link": "http://arxiv.org/abs/2405.20303v1",
        "abstract": "We study a budget-aggregation setting in which a number of voters report\ntheir ideal distribution of a budget over a set of alternatives, and a\nmechanism aggregates these reports into an allocation. Ideally, such mechanisms\nare truthful, i.e., voters should not be incentivized to misreport their\npreferences. For the case of two alternatives, the set of mechanisms that are\ntruthful and additionally meet a range of basic desiderata (anonymity,\nneutrality, and continuity) exactly coincides with the so-called moving-phantom\nmechanisms, but whether this space is richer for more alternatives was\nrepeatedly stated as an open question. We answer this question in the\naffirmative by presenting a new mechanism that is not a moving-phantom\nmechanism but satisfies the four properties. Since moving-phantom mechanisms\ncan only provide limited fairness guarantees (measured as the worst-case\ndistance to a fair share solution), one motivation for broadening the class of\ntruthful mechanisms is the hope for improved fairness guarantees. We dispel\nthis hope by showing that lower bounds holding for the class of moving-phantom\nmechanisms extend to all truthful, anonymous, neutral, and continuous\nmechanisms.",
        "subjects": [
            "cs.GT"
        ],
        "authors": [
            "Mark de Berg",
            "Rupert Freeman",
            "Ulrike Schmidt-Kraepelin",
            "Markus Utke"
        ],
        "published": "2024-05-30T17:49:23Z"
    },
    {
        "title": "Scaling White-Box Transformers for Vision",
        "link": "http://arxiv.org/abs/2405.20299v1",
        "abstract": "CRATE, a white-box transformer architecture designed to learn compressed and\nsparse representations, offers an intriguing alternative to standard vision\ntransformers (ViTs) due to its inherent mathematical interpretability. Despite\nextensive investigations into the scaling behaviors of language and vision\ntransformers, the scalability of CRATE remains an open question which this\npaper aims to address. Specifically, we propose CRATE-$\\alpha$, featuring\nstrategic yet minimal modifications to the sparse coding block in the CRATE\narchitecture design, and a light training recipe designed to improve the\nscalability of CRATE. Through extensive experiments, we demonstrate that\nCRATE-$\\alpha$ can effectively scale with larger model sizes and datasets. For\nexample, our CRATE-$\\alpha$-B substantially outperforms the prior best CRATE-B\nmodel accuracy on ImageNet classification by 3.7%, achieving an accuracy of\n83.2%. Meanwhile, when scaling further, our CRATE-$\\alpha$-L obtains an\nImageNet classification accuracy of 85.1%. More notably, these model\nperformance improvements are achieved while preserving, and potentially even\nenhancing the interpretability of learned CRATE models, as we demonstrate\nthrough showing that the learned token representations of increasingly larger\ntrained CRATE-$\\alpha$ models yield increasingly higher-quality unsupervised\nobject segmentation of images. The project page is\nhttps://rayjryang.github.io/CRATE-alpha/.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jinrui Yang",
            "Xianhang Li",
            "Druv Pai",
            "Yuyin Zhou",
            "Yi Ma",
            "Yaodong Yu",
            "Cihang Xie"
        ],
        "published": "2024-05-30T17:46:23Z"
    },
    {
        "title": "How (not) to Build Quantum PKE in Minicrypt",
        "link": "http://arxiv.org/abs/2405.20295v1",
        "abstract": "The seminal work by Impagliazzo and Rudich (STOC'89) demonstrated the\nimpossibility of constructing classical public key encryption (PKE) from\none-way functions (OWF) in a black-box manner. However, the question remains:\ncan quantum PKE (QPKE) be constructed from quantumly secure OWF? A recent line\nof work has shown that it is indeed possible to build QPKE from OWF, but with\none caveat -- they rely on quantum public keys, which cannot be authenticated\nand reused. In this work, we re-examine the possibility of perfect complete\nQPKE in the quantum random oracle model (QROM), where OWF exists. Our first\nmain result: QPKE with classical public keys, secret keys and ciphertext, does\nnot exist in the QROM, if the key generation only makes classical queries.\nTherefore, a necessary condition for constructing such QPKE from OWF is to have\nthe key generation classically ``un-simulatable''. Previous discussions\n(Austrin et al. CRYPTO'22) on the impossibility of QPKE from OWF rely on a\nseemingly strong conjecture. Our work makes a significant step towards a\ncomplete and unconditional quantization of Impagliazzo and Rudich's results.\nOur second main result extends to QPKE with quantum public keys. The second\nmain result: QPKE with quantum public keys, classical secret keys and\nciphertext, does not exist in the QROM, if the key generation only makes\nclassical queries and the quantum public key is either pure or ``efficiently\nclonable''. The result is tight due to all existing QPKEs constructions. Our\nresult further gives evidence on why existing QPKEs lose reusability. To\nachieve these results, we use a novel argument based on conditional mutual\ninformation and quantum Markov chain by Fawzi and Renner (Communications in\nMathematical Physics). We believe the techniques used in the work will find\nother usefulness in separations in quantum cryptography/complexity.",
        "subjects": [
            "quant-ph",
            "cs.CR"
        ],
        "authors": [
            "Longcheng Li",
            "Qian Li",
            "Xingjian Li",
            "Qipeng Liu"
        ],
        "published": "2024-05-30T17:44:03Z"
    },
    {
        "title": "Unveiling and Mitigating Backdoor Vulnerabilities based on Unlearning\n  Weight Changes and Backdoor Activeness",
        "link": "http://arxiv.org/abs/2405.20291v1",
        "abstract": "The security threat of backdoor attacks is a central concern for deep neural\nnetworks (DNNs). Recently, without poisoned data, unlearning models with clean\ndata and then learning a pruning mask have contributed to backdoor defense.\nAdditionally, vanilla fine-tuning with those clean data can help recover the\nlost clean accuracy. However, the behavior of clean unlearning is still\nunder-explored, and vanilla fine-tuning unintentionally induces back the\nbackdoor effect. In this work, we first investigate model unlearning from the\nperspective of weight changes and gradient norms, and find two interesting\nobservations in the backdoored model: 1) the weight changes between poison and\nclean unlearning are positively correlated, making it possible for us to\nidentify the backdoored-related neurons without using poisoned data; 2) the\nneurons of the backdoored model are more active (i.e., larger changes in\ngradient norm) than those in the clean model, suggesting the need to suppress\nthe gradient norm during fine-tuning. Then, we propose an effective two-stage\ndefense method. In the first stage, an efficient Neuron Weight Change\n(NWC)-based Backdoor Reinitialization is proposed based on observation 1). In\nthe second stage, based on observation 2), we design an Activeness-Aware\nFine-Tuning to replace the vanilla fine-tuning. Extensive experiments,\ninvolving eight backdoor attacks on three benchmark datasets, demonstrate the\nsuperior performance of our proposed method compared to recent state-of-the-art\nbackdoor defense approaches.",
        "subjects": [
            "cs.CR",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Weilin Lin",
            "Li Liu",
            "Shaokui Wei",
            "Jianze Li",
            "Hui Xiong"
        ],
        "published": "2024-05-30T17:41:32Z"
    },
    {
        "title": "DITTO-2: Distilled Diffusion Inference-Time T-Optimization for Music\n  Generation",
        "link": "http://arxiv.org/abs/2405.20289v1",
        "abstract": "Controllable music generation methods are critical for human-centered\nAI-based music creation, but are currently limited by speed, quality, and\ncontrol design trade-offs. Diffusion Inference-Time T-optimization (DITTO), in\nparticular, offers state-of-the-art results, but is over 10x slower than\nreal-time, limiting practical use. We propose Distilled Diffusion\nInference-Time T -Optimization (or DITTO-2), a new method to speed up\ninference-time optimization-based control and unlock faster-than-real-time\ngeneration for a wide-variety of applications such as music inpainting,\noutpainting, intensity, melody, and musical structure control. Our method works\nby (1) distilling a pre-trained diffusion model for fast sampling via an\nefficient, modified consistency or consistency trajectory distillation process\n(2) performing inference-time optimization using our distilled model with\none-step sampling as an efficient surrogate optimization task and (3) running a\nfinal multi-step sampling generation (decoding) using our estimated noise\nlatents for best-quality, fast, controllable generation. Through thorough\nevaluation, we find our method not only speeds up generation over 10-20x, but\nsimultaneously improves control adherence and generation quality all at once.\nFurthermore, we apply our approach to a new application of maximizing text\nadherence (CLAP score) and show we can convert an unconditional diffusion model\nwithout text inputs into a model that yields state-of-the-art text control.\nSound examples can be found at https://ditto-music.github.io/ditto2/.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Zachary Novack",
            "Julian McAuley",
            "Taylor Berg-Kirkpatrick",
            "Nicholas Bryan"
        ],
        "published": "2024-05-30T17:40:11Z"
    },
    {
        "title": "Flexible SE(2) graph neural networks with applications to PDE surrogates",
        "link": "http://arxiv.org/abs/2405.20287v1",
        "abstract": "This paper presents a novel approach for constructing graph neural networks\nequivariant to 2D rotations and translations and leveraging them as PDE\nsurrogates on non-gridded domains. We show that aligning the representations\nwith the principal axis allows us to sidestep many constraints while preserving\nSE(2) equivariance. By applying our model as a surrogate for fluid flow\nsimulations and conducting thorough benchmarks against non-equivariant models,\nwe demonstrate significant gains in terms of both data efficiency and accuracy.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.NA",
            "math.NA",
            "physics.flu-dyn"
        ],
        "authors": [
            "Maria Bånkestad",
            "Olof Mogren",
            "Aleksis Pirinen"
        ],
        "published": "2024-05-30T17:39:15Z"
    },
    {
        "title": "Who Writes the Review, Human or AI?",
        "link": "http://arxiv.org/abs/2405.20285v1",
        "abstract": "With the increasing use of Artificial Intelligence in Natural Language\nProcessing, concerns have been raised regarding the detection of AI-generated\ntext in various domains. This study aims to investigate this issue by proposing\na methodology to accurately distinguish AI-generated and human-written book\nreviews. Our approach utilizes transfer learning, enabling the model to\nidentify generated text across different topics while improving its ability to\ndetect variations in writing style and vocabulary. To evaluate the\neffectiveness of the proposed methodology, we developed a dataset consisting of\nreal book reviews and AI-generated reviews using the recently proposed Vicuna\nopen-source language model. The experimental results demonstrate that it is\nfeasible to detect the original source of text, achieving an accuracy rate of\n96.86%. Our efforts are oriented toward the exploration of the capabilities and\nlimitations of Large Language Models in the context of text identification.\nExpanding our knowledge in these aspects will be valuable for effectively\nnavigating similar models in the future and ensuring the integrity and\nauthenticity of human-generated content.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Panagiotis C. Theocharopoulos",
            "Spiros V. Georgakopoulos",
            "Sotiris K. Tasoulis",
            "Vassilis P. Plagianakos"
        ],
        "published": "2024-05-30T17:38:44Z"
    },
    {
        "title": "TetSphere Splatting: Representing High-Quality Geometry with Lagrangian\n  Volumetric Meshes",
        "link": "http://arxiv.org/abs/2405.20283v1",
        "abstract": "We present TetSphere splatting, an explicit, Lagrangian representation for\nreconstructing 3D shapes with high-quality geometry. In contrast to\nconventional object reconstruction methods which predominantly use Eulerian\nrepresentations, including both neural implicit (e.g., NeRF, NeuS) and explicit\nrepresentations (e.g., DMTet), and often struggle with high computational\ndemands and suboptimal mesh quality, TetSphere splatting utilizes an underused\nbut highly effective geometric primitive -- tetrahedral meshes. This approach\ndirectly yields superior mesh quality without relying on neural networks or\npost-processing. It deforms multiple initial tetrahedral spheres to accurately\nreconstruct the 3D shape through a combination of differentiable rendering and\ngeometric energy optimization, resulting in significant computational\nefficiency. Serving as a robust and versatile geometry representation,\nTet-Sphere splatting seamlessly integrates into diverse applications, including\nsingle-view 3D reconstruction, image-/text-to-3D content generation.\nExperimental results demonstrate that TetSphere splatting outperforms existing\nrepresentations, delivering faster optimization speed, enhanced mesh quality,\nand reliable preservation of thin structures.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "authors": [
            "Minghao Guo",
            "Bohan Wang",
            "Kaiming He",
            "Wojciech Matusik"
        ],
        "published": "2024-05-30T17:35:49Z"
    },
    {
        "title": "SemFlow: Binding Semantic Segmentation and Image Synthesis via Rectified\n  Flow",
        "link": "http://arxiv.org/abs/2405.20282v1",
        "abstract": "Semantic segmentation and semantic image synthesis are two representative\ntasks in visual perception and generation. While existing methods consider them\nas two distinct tasks, we propose a unified diffusion-based framework (SemFlow)\nand model them as a pair of reverse problems. Specifically, motivated by\nrectified flow theory, we train an ordinary differential equation (ODE) model\nto transport between the distributions of real images and semantic masks. As\nthe training object is symmetric, samples belonging to the two distributions,\nimages and semantic masks, can be effortlessly transferred reversibly. For\nsemantic segmentation, our approach solves the contradiction between the\nrandomness of diffusion outputs and the uniqueness of segmentation results. For\nimage synthesis, we propose a finite perturbation approach to enhance the\ndiversity of generated results without changing the semantic categories.\nExperiments show that our SemFlow achieves competitive results on semantic\nsegmentation and semantic image synthesis tasks. We hope this simple framework\nwill motivate people to rethink the unification of low-level and high-level\nvision. Project page: https://github.com/wang-chaoyang/SemFlow.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Chaoyang Wang",
            "Xiangtai Li",
            "Lu Qi",
            "Henghui Ding",
            "Yunhai Tong",
            "Ming-Hsuan Yang"
        ],
        "published": "2024-05-30T17:34:40Z"
    },
    {
        "title": "Tight Characterizations for Preprocessing against Cryptographic Salting",
        "link": "http://arxiv.org/abs/2405.20281v1",
        "abstract": "Cryptography often considers the strongest yet plausible attacks in the real\nworld. Preprocessing (a.k.a. non-uniform attack) plays an important role in\nboth theory and practice: an efficient online attacker can take advantage of\nadvice prepared by a time-consuming preprocessing stage.\n  Salting is a heuristic strategy to counter preprocessing attacks by feeding a\nsmall amount of randomness to the cryptographic primitive. We present general\nand tight characterizations of preprocessing against cryptographic salting,\nwith upper bounds matching the advantages of the most intuitive attack. Our\nresult quantitatively strengthens the previous work by Coretti, Dodis, Guo, and\nSteinberger (EUROCRYPT'18). Our proof exploits a novel connection between the\nnon-uniform security of salted games and direct product theorems for memoryless\nalgorithms.\n  For quantum adversaries, we give similar characterizations for property\nfinding games, resolving an open problem of the quantum non-uniform security of\nsalted collision resistant hash by Chung, Guo, Liu, and Qian (FOCS'20). Our\nproof extends the compressed oracle framework of Zhandry (CRYPTO'19) to prove\nquantum strong direct product theorems for property finding games in the\naverage-case hardness.",
        "subjects": [
            "cs.CR",
            "quant-ph"
        ],
        "authors": [
            "Fangqi Dong",
            "Qipeng Liu",
            "Kewen Wu"
        ],
        "published": "2024-05-30T17:34:25Z"
    },
    {
        "title": "CV-VAE: A Compatible Video VAE for Latent Generative Video Models",
        "link": "http://arxiv.org/abs/2405.20279v1",
        "abstract": "Spatio-temporal compression of videos, utilizing networks such as Variational\nAutoencoders (VAE), plays a crucial role in OpenAI's SORA and numerous other\nvideo generative models. For instance, many LLM-like video models learn the\ndistribution of discrete tokens derived from 3D VAEs within the VQVAE\nframework, while most diffusion-based video models capture the distribution of\ncontinuous latent extracted by 2D VAEs without quantization. The temporal\ncompression is simply realized by uniform frame sampling which results in\nunsmooth motion between consecutive frames. Currently, there lacks of a\ncommonly used continuous video (3D) VAE for latent diffusion-based video models\nin the research community. Moreover, since current diffusion-based approaches\nare often implemented using pre-trained text-to-image (T2I) models, directly\ntraining a video VAE without considering the compatibility with existing T2I\nmodels will result in a latent space gap between them, which will take huge\ncomputational resources for training to bridge the gap even with the T2I models\nas initialization. To address this issue, we propose a method for training a\nvideo VAE of latent video models, namely CV-VAE, whose latent space is\ncompatible with that of a given image VAE, e.g., image VAE of Stable Diffusion\n(SD). The compatibility is achieved by the proposed novel latent space\nregularization, which involves formulating a regularization loss using the\nimage VAE. Benefiting from the latent space compatibility, video models can be\ntrained seamlessly from pre-trained T2I or video models in a truly\nspatio-temporally compressed latent space, rather than simply sampling video\nframes at equal intervals. With our CV-VAE, existing video models can generate\nfour times more frames with minimal finetuning. Extensive experiments are\nconducted to demonstrate the effectiveness of the proposed video VAE.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "eess.IV"
        ],
        "authors": [
            "Sijie Zhao",
            "Yong Zhang",
            "Xiaodong Cun",
            "Shaoshu Yang",
            "Muyao Niu",
            "Xiaoyu Li",
            "Wenbo Hu",
            "Ying Shan"
        ],
        "published": "2024-05-30T17:33:10Z"
    },
    {
        "title": "Length independent generalization bounds for deep SSM architectures with\n  stability constraints",
        "link": "http://arxiv.org/abs/2405.20278v1",
        "abstract": "Many state-of-the-art models trained on long-range sequences, for example S4,\nS5 or LRU, are made of sequential blocks combining State-Space Models (SSMs)\nwith neural networks. In this paper we provide a PAC bound that holds for these\nkind of architectures with stable SSM blocks and does not depend on the length\nof the input sequence. Imposing stability of the SSM blocks is a standard\npractice in the literature, and it is known to help performance. Our results\nprovide a theoretical justification for the use of stable SSM blocks as the\nproposed PAC bound decreases as the degree of stability of the SSM blocks\nincreases.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML",
            "68",
            "I.2.6"
        ],
        "authors": [
            "Dániel Rácz",
            "Mihály Petreczky",
            "Bálint Daróczy"
        ],
        "published": "2024-05-30T17:32:46Z"
    },
    {
        "title": "Pre-train and Refine: Towards Higher Efficiency in K-Agnostic Community\n  Detection without Quality Degradation",
        "link": "http://arxiv.org/abs/2405.20277v1",
        "abstract": "Community detection (CD) is a classic graph inference task that partitions\nnodes of a graph into densely connected groups. While many CD methods have been\nproposed with either impressive quality or efficiency, balancing the two\naspects remains a challenge. This study explores the potential of deep graph\nlearning to achieve a better trade-off between the quality and efficiency of\nK-agnostic CD, where the number of communities K is unknown. We propose PRoCD\n(Pre-training & Refinement fOr Community Detection), a simple yet effective\nmethod that reformulates K-agnostic CD as the binary node pair classification.\nPRoCD follows a pre-training & refinement paradigm inspired by recent advances\nin pre-training techniques. We first conduct the offline pre-training of PRoCD\non small synthetic graphs covering various topology properties. Based on the\ninductive inference across graphs, we then generalize the pre-trained model\n(with frozen parameters) to large real graphs and use the derived CD results as\nthe initialization of an existing efficient CD method (e.g., InfoMap) to\nfurther refine the quality of CD results. In addition to benefiting from the\ntransfer ability regarding quality, the online generalization and refinement\ncan also help achieve high inference efficiency, since there is no\ntime-consuming model optimization. Experiments on public datasets with various\nscales demonstrate that PRoCD can ensure higher efficiency in K-agnostic CD\nwithout significant quality degradation.",
        "subjects": [
            "cs.SI"
        ],
        "authors": [
            "Meng Qin",
            "Chaorui Zhang",
            "Yu Gao",
            "Weixi Zhang",
            "Dit-Yan Yeung"
        ],
        "published": "2024-05-30T17:30:04Z"
    },
    {
        "title": "ROAST: Review-level Opinion Aspect Sentiment Target Joint Detection",
        "link": "http://arxiv.org/abs/2405.20274v1",
        "abstract": "Aspect-Based Sentiment Analysis (ABSA) has experienced tremendous expansion\nand diversity due to various shared tasks spanning several languages and fields\nand organized via SemEval workshops and Germeval. Nonetheless, a few\nshortcomings still need to be addressed, such as the lack of low-resource\nlanguage evaluations and the emphasis on sentence-level analysis. To thoroughly\nassess ABSA techniques in the context of complete reviews, this research\npresents a novel task, Review-Level Opinion Aspect Sentiment Target (ROAST).\nROAST seeks to close the gap between sentence-level and text-level ABSA by\nidentifying every ABSA constituent at the review level. We extend the available\ndatasets to enable ROAST, addressing the drawbacks noted in previous research\nby incorporating low-resource languages, numerous languages, and a variety of\ntopics. Through this effort, ABSA research will be able to cover more ground\nand get a deeper comprehension of the task and its practical application in a\nvariety of languages and domains (https://github.com/RiTUAL-UH/ROAST-ABSA).",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Siva Uday Sampreeth Chebolu",
            "Franck Dernoncourt",
            "Nedim Lipka",
            "Thamar Solorio"
        ],
        "published": "2024-05-30T17:29:15Z"
    },
    {
        "title": "Reconstruction Attacks on Machine Unlearning: Simple Models are\n  Vulnerable",
        "link": "http://arxiv.org/abs/2405.20272v1",
        "abstract": "Machine unlearning is motivated by desire for data autonomy: a person can\nrequest to have their data's influence removed from deployed models, and those\nmodels should be updated as if they were retrained without the person's data.\nWe show that, counter-intuitively, these updates expose individuals to\nhigh-accuracy reconstruction attacks which allow the attacker to recover their\ndata in its entirety, even when the original models are so simple that privacy\nrisk might not otherwise have been a concern. We show how to mount a\nnear-perfect attack on the deleted data point from linear regression models. We\nthen generalize our attack to other loss functions and architectures, and\nempirically demonstrate the effectiveness of our attacks across a wide range of\ndatasets (capturing both tabular and image data). Our work highlights that\nprivacy risk is significant even for extremely simple model classes when\nindividuals can request deletion of their data from the model.",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "authors": [
            "Martin Bertran",
            "Shuai Tang",
            "Michael Kearns",
            "Jamie Morgenstern",
            "Aaron Roth",
            "Zhiwei Steven Wu"
        ],
        "published": "2024-05-30T17:27:44Z"
    },
    {
        "title": "ETHER: Efficient Finetuning of Large-Scale Models with Hyperplane\n  Reflections",
        "link": "http://arxiv.org/abs/2405.20271v1",
        "abstract": "Parameter-efficient finetuning (PEFT) has become ubiquitous to adapt\nfoundation models to downstream task requirements while retaining their\ngeneralization ability. However, the amount of additionally introduced\nparameters and compute for successful adaptation and hyperparameter searches\ncan explode quickly, especially when deployed at scale to serve numerous\nindividual requests. To ensure effective, parameter-efficient, and\nhyperparameter-robust adaptation, we propose the ETHER transformation family,\nwhich performs Efficient fineTuning via HypErplane Reflections. By design,\nETHER transformations require a minimal number of parameters, are less likely\nto deteriorate model performance, and exhibit robustness to hyperparameter and\nlearning rate choices. In particular, we introduce ETHER and its relaxation\nETHER+, which match or outperform existing PEFT methods with significantly\nfewer parameters ($\\sim$$10$-$100$ times lower than LoRA or OFT) across\nmultiple image synthesis and natural language tasks without exhaustive\nhyperparameter tuning. Finally, we investigate the recent emphasis on\nHyperspherical Energy retention for adaptation and raise questions on its\npractical utility. The code is available at https://github.com/mwbini/ether.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.CV"
        ],
        "authors": [
            "Massimo Bini",
            "Karsten Roth",
            "Zeynep Akata",
            "Anna Khoreva"
        ],
        "published": "2024-05-30T17:26:02Z"
    },
    {
        "title": "IsraParlTweet: The Israeli Parliamentary and Twitter Resource",
        "link": "http://arxiv.org/abs/2405.20269v1",
        "abstract": "We introduce IsraParlTweet, a new linked corpus of Hebrew-language\nparliamentary discussions from the Knesset (Israeli Parliament) between the\nyears 1992-2023 and Twitter posts made by Members of the Knesset between the\nyears 2008-2023, containing a total of 294.5 million Hebrew tokens. In addition\nto raw text, the corpus contains comprehensive metadata on speakers and Knesset\nsessions as well as several linguistic annotations. As a result, IsraParlTweet\ncan be used to conduct a wide variety of quantitative and qualitative analyses\nand provide valuable insights into political discourse in Israel.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Guy Mor-Lan",
            "Effi Levi",
            "Tamir Sheafer",
            "Shaul R. Shenhav"
        ],
        "published": "2024-05-30T17:21:15Z"
    },
    {
        "title": "Auto Arena of LLMs: Automating LLM Evaluations with Agent Peer-battles\n  and Committee Discussions",
        "link": "http://arxiv.org/abs/2405.20267v1",
        "abstract": "As LLMs evolve on a daily basis, there is an urgent need for a trustworthy\nevaluation method that can provide robust evaluation results in a timely\nfashion. Currently, as static benchmarks are prone to contamination concerns,\nusers tend to trust human voting platforms, such as Chatbot Arena. However,\nhuman annotations require extensive manual efforts. To provide an automatic,\nrobust, and trustworthy evaluation framework, we innovatively propose the\nAuto-Arena of LLMs, which automates the entire evaluation process with LLM\nagents. Firstly, an examiner LLM devises queries. Then, a pair of candidate\nLLMs engage in a multi-round peer-battle around the query, during which the\nLLM's true performance gaps become visible. Finally, a committee of LLM judges\ncollectively discuss and determine the winner, which alleviates bias and\npromotes fairness. In our extensive experiment on the 17 newest LLMs,\nAuto-Arena shows the highest correlation with human preferences, providing a\npromising alternative to human evaluation platforms.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Ruochen Zhao",
            "Wenxuan Zhang",
            "Yew Ken Chia",
            "Deli Zhao",
            "Lidong Bing"
        ],
        "published": "2024-05-30T17:19:19Z"
    },
    {
        "title": "An algebraic proof of the graph orientation problem dichotomy for\n  forbidden tournaments",
        "link": "http://arxiv.org/abs/2405.20263v1",
        "abstract": "Using the theory of smooth approximations, we give a new and algebraic proof\nthat for any set F of finite tournaments, the problem of orienting a finite\ngraph whilst avoiding all members of F is either in P or NP-complete. We\ncharacterize both cases by algebraic conditions.",
        "subjects": [
            "math.CO",
            "cs.CC",
            "cs.LO",
            "math.RA"
        ],
        "authors": [
            "Roman Feller",
            "Michael Pinsker"
        ],
        "published": "2024-05-30T17:16:29Z"
    },
    {
        "title": "Speed Profile Definition for GLOSA Implementation on Buses Based on\n  Statistical Analysis of Experimental Data",
        "link": "http://arxiv.org/abs/2405.20261v1",
        "abstract": "Intelligent Transportation Systems (ITS) are pushing an increasing interest\nand development when dealing with eco-driving systems. In this framework, this\npaper presents a method to define speed profiles specifically designed for\nGreen Light Optimal Speed Advisory (GLOSA) systems on buses. GLOSA aims to\noptimize traffic flow by providing vehicles with real-time speed\nrecommendations synchronized with traffic signal timings. Leveraging\nstatistical analysis of experimental data collected from an urban bus, the\nstudy develops a methodology to extract meaningful insights into bus behaviour\nand traffic dynamics. The proposed approach considers road topology, scheduled\nbus stops, and signal timings to define simple although suitable speed profiles\nconsidering the peculiarities of the motion of a bus in an urban scenario.\nThrough extensive data collection robust statistical data are defined, allowing\nthe definition of vehicle motion profile for effectively develop and implement\nGLOSA systems. This research contributes to the advancement of Intelligent\nTransportation Systems by providing realistic data and practical insights for\noptimizing bus operations in urban environments.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Daniele Vignarca",
            "Stefano Arrigoni",
            "Edoardo Sabbioni",
            "Federico Cheli"
        ],
        "published": "2024-05-30T17:15:59Z"
    },
    {
        "title": "Ancillary Services Provision by Cross-Voltage-Level Power Flow Control\n  using Flexibility Regions",
        "link": "http://arxiv.org/abs/2405.20260v1",
        "abstract": "The large-scale integration of distributed renewable energy sources into the\nelectricity grid requires the investigation of new methods to ensure stability.\nFor example, Active Distribution Networks (ADNs) can be used at (sub-)\ntransmission levels for emergency operation, provided robust and efficient\ncontrol is available. This paper investigates the use of Feasible Operating\nRegions (FORs) and Flexibility Regions (FRs) for Cross-Voltage-Level Power Flow\nControl (CPFC). The enhancement of network stability due to the provision of\nancillary services is illustrated, as is the need for strengthened cooperation\nbetween Transmission (TSOs) and Distribution System Operators (DSOs). Optimal\npower flow methods are considered, focusing on computational advances through\nPieceWise Linearization (PWL) and convex relaxation techniques aiming to speed\nup runtime while keeping high accuracy. To illustrate the algorithms' benefits\nand drawbacks, they are analyzed using exemplary medium voltage grids.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Christian Holger Nerowski",
            "Zongjun Li",
            "Christian Rehtanz"
        ],
        "published": "2024-05-30T17:14:46Z"
    },
    {
        "title": "FaceMixup: Enhancing Facial Expression Recognition through Mixed Face\n  Regularization",
        "link": "http://arxiv.org/abs/2405.20259v1",
        "abstract": "The proliferation of deep learning solutions and the scarcity of large\nannotated datasets pose significant challenges in real-world applications.\nVarious strategies have been explored to overcome this challenge, with data\naugmentation (DA) approaches emerging as prominent solutions. DA approaches\ninvolve generating additional examples by transforming existing labeled data,\nthereby enriching the dataset and helping deep learning models achieve improved\ngeneralization without succumbing to overfitting. In real applications, where\nsolutions based on deep learning are widely used, there is facial expression\nrecognition (FER), which plays an essential role in human communication,\nimproving a range of knowledge areas (e.g., medicine, security, and marketing).\nIn this paper, we propose a simple and comprehensive face data augmentation\napproach based on mixed face component regularization that outperforms the\nclassical DA approaches from the literature, including the MixAugment which is\na specific approach for the target task in two well-known FER datasets existing\nin the literature.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Fabio A. Faria",
            "Mateus M. Souza",
            "Raoni F. da S. Teixeira",
            "Mauricio P. Segundo"
        ],
        "published": "2024-05-30T17:09:05Z"
    },
    {
        "title": "Conversational Agents to Facilitate Deliberation on Harmful Content in\n  WhatsApp Groups",
        "link": "http://arxiv.org/abs/2405.20254v1",
        "abstract": "WhatsApp groups have become a hotbed for the propagation of harmful content\nincluding misinformation, hate speech, polarizing content, and rumors,\nespecially in Global South countries. Given the platform's end-to-end\nencryption, moderation responsibilities lie on group admins and members, who\nrarely contest such content. Another approach is fact-checking, which is\nunscalable, and can only contest factual content (e.g., misinformation) but not\nsubjective content (e.g., hate speech). Drawing on recent literature, we\nexplore deliberation -- open and inclusive discussion -- as an alternative. We\ninvestigate the role of a conversational agent in facilitating deliberation on\nharmful content in WhatsApp groups. We conducted semi-structured interviews\nwith 21 Indian WhatsApp users, employing a design probe to showcase an example\nagent. Participants expressed the need for anonymity and recommended AI\nassistance to reduce the effort required in deliberation. They appreciated the\nagent's neutrality but pointed out the futility of deliberation in echo chamber\ngroups. Our findings highlight design tensions for such an agent, including\nprivacy versus group dynamics and freedom of speech in private spaces. We\ndiscuss the efficacy of deliberation using deliberative theory as a lens,\ncompare deliberation with moderation and fact-checking, and provide design\nrecommendations for future such systems. Ultimately, this work advances CSCW by\noffering insights into designing deliberative systems for combating harmful\ncontent in private group chats on social media.",
        "subjects": [
            "cs.HC",
            "cs.CY"
        ],
        "authors": [
            "Dhruv Agarwal",
            "Farhana Shahid",
            "Aditya Vashistha"
        ],
        "published": "2024-05-30T17:07:07Z"
    },
    {
        "title": "Evaluating Large Language Model Biases in Persona-Steered Generation",
        "link": "http://arxiv.org/abs/2405.20253v1",
        "abstract": "The task of persona-steered text generation requires large language models\n(LLMs) to generate text that reflects the distribution of views that an\nindividual fitting a persona could have. People have multifaceted personas, but\nprior work on bias in LLM-generated opinions has only explored multiple-choice\nsettings or one-dimensional personas. We define an incongruous persona as a\npersona with multiple traits where one trait makes its other traits less likely\nin human survey data, e.g. political liberals who support increased military\nspending. We find that LLMs are 9.7% less steerable towards incongruous\npersonas than congruous ones, sometimes generating the stereotypical stance\nassociated with its demographic rather than the target stance. Models that we\nevaluate that are fine-tuned with Reinforcement Learning from Human Feedback\n(RLHF) are more steerable, especially towards stances associated with political\nliberals and women, but present significantly less diverse views of personas.\nWe also find variance in LLM steerability that cannot be predicted from\nmultiple-choice opinion evaluation. Our results show the importance of\nevaluating models in open-ended text generation, as it can surface new LLM\nopinion biases. Moreover, such a setup can shed light on our ability to steer\nmodels toward a richer and more diverse range of viewpoints.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Andy Liu",
            "Mona Diab",
            "Daniel Fried"
        ],
        "published": "2024-05-30T17:06:03Z"
    },
    {
        "title": "Towards Hierarchical Multi-Agent Workflows for Zero-Shot Prompt\n  Optimization",
        "link": "http://arxiv.org/abs/2405.20252v1",
        "abstract": "Large language models (LLMs) have shown great progress in responding to user\nquestions, allowing for a multitude of diverse applications. Yet, the quality\nof LLM outputs heavily depends on the prompt design, where a good prompt might\nenable the LLM to answer a very challenging question correctly. Therefore,\nrecent works have developed many strategies for improving the prompt, including\nboth manual crafting and in-domain optimization. However, their efficacy in\nunrestricted scenarios remains questionable, as the former depends on human\ndesign for specific questions and the latter usually generalizes poorly to\nunseen scenarios. To address these problems, we give LLMs the freedom to design\nthe best prompts according to themselves. Specifically, we include a hierarchy\nof LLMs, first constructing a prompt with precise instructions and accurate\nwording in a hierarchical manner, and then using this prompt to generate the\nfinal answer to the user query. We term this pipeline Hierarchical Multi-Agent\nWorkflow, or HMAW. In contrast with prior works, HMAW imposes no human\nrestriction and requires no training, and is completely task-agnostic while\ncapable of adjusting to the nuances of the underlying task. Through both\nquantitative and qualitative experiments across multiple benchmarks, we verify\nthat despite its simplicity, the proposed approach can create detailed and\nsuitable prompts, further boosting the performance of current LLMs.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yuchi Liu",
            "Jaskirat Singh",
            "Gaowen Liu",
            "Ali Payani",
            "Liang Zheng"
        ],
        "published": "2024-05-30T17:05:45Z"
    },
    {
        "title": "Entropy annealing for policy mirror descent in continuous time and space",
        "link": "http://arxiv.org/abs/2405.20250v1",
        "abstract": "Entropy regularization has been extensively used in policy optimization\nalgorithms to regularize the optimization landscape and accelerate convergence;\nhowever, it comes at the cost of introducing an additional regularization bias.\nThis work quantifies the impact of entropy regularization on the convergence of\npolicy gradient methods for stochastic exit time control problems. We analyze a\ncontinuous-time policy mirror descent dynamics, which updates the policy based\non the gradient of an entropy-regularized value function and adjusts the\nstrength of entropy regularization as the algorithm progresses. We prove that\nwith a fixed entropy level, the dynamics converges exponentially to the optimal\nsolution of the regularized problem. We further show that when the entropy\nlevel decays at suitable polynomial rates, the annealed flow converges to the\nsolution of the unregularized problem at a rate of $\\mathcal O(1/S)$ for\ndiscrete action spaces and, under suitable conditions, at a rate of $\\mathcal\nO(1/\\sqrt{S})$ for general action spaces, with $S$ being the gradient flow\ntime. This paper explains how entropy regularization improves policy\noptimization, even with the true gradient, from the perspective of convergence\nrate.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "math.PR",
            "Primary 93E20, Secondary 49M29, 68Q25, 60H30, 35J61"
        ],
        "authors": [
            "Deven Sethi",
            "David Šiška",
            "Yufei Zhang"
        ],
        "published": "2024-05-30T17:02:18Z"
    },
    {
        "title": "Image-to-Joint Inverse Kinematic of a Supportive Continuum Arm Using\n  Deep Learning",
        "link": "http://arxiv.org/abs/2405.20248v1",
        "abstract": "In this work, a deep learning-based technique is used to study the\nimage-to-joint inverse kinematics of a tendon-driven supportive continuum arm.\nAn eye-off-hand configuration is considered by mounting a camera at a fixed\npose with respect to the inertial frame attached at the arm base. This camera\ncaptures an image for each distinct joint variable at each sampling time to\nconstruct the training dataset. This dataset is then employed to adapt a\nfeed-forward deep convolutional neural network, namely the modified VGG-16\nmodel, to estimate the joint variable. One thousand images are recorded to\ntrain the deep network, and transfer learning and fine-tuning techniques are\napplied to the modified VGG-16 to further improve the training. Finally,\ntraining is also completed with a larger dataset of images that are affected by\nvarious types of noises, changes in illumination, and partial occlusion. The\nmain contribution of this research is the development of an image-to-joint\nnetwork that can estimate the joint variable given an image of the arm, even if\nthe image is not captured in an ideal condition. The key benefits of this\nresearch are twofold: 1) image-to-joint mapping can offer a real-time\nalternative to computationally complex inverse kinematic mapping through\nanalytical models; and 2) the proposed technique can provide robustness against\nnoise, occlusion, and changes in illumination. The dataset is publicly\navailable on Kaggle.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Shayan Sepahvand",
            "Guanghui Wang",
            "Farrokh Janabi-Sharifi"
        ],
        "published": "2024-05-30T16:59:43Z"
    },
    {
        "title": "KerasCV and KerasNLP: Vision and Language Power-Ups",
        "link": "http://arxiv.org/abs/2405.20247v1",
        "abstract": "We present the Keras domain packages KerasCV and KerasNLP, extensions of the\nKeras API for Computer Vision and Natural Language Processing workflows,\ncapable of running on either JAX, TensorFlow, or PyTorch. These domain packages\nare designed to enable fast experimentation, with a focus on ease-of-use and\nperformance. We adopt a modular, layered design: at the library's lowest level\nof abstraction, we provide building blocks for creating models and data\npreprocessing pipelines, and at the library's highest level of abstraction, we\nprovide pretrained ``task\" models for popular architectures such as Stable\nDiffusion, YOLOv8, GPT2, BERT, Mistral, CLIP, Gemma, T5, etc. Task models have\nbuilt-in preprocessing, pretrained weights, and can be fine-tuned on raw\ninputs. To enable efficient training, we support XLA compilation for all\nmodels, and run all preprocessing via a compiled graph of TensorFlow operations\nusing the tf.data API. The libraries are fully open-source (Apache 2.0 license)\nand available on GitHub.",
        "subjects": [
            "cs.AI",
            "cs.CV",
            "cs.LG",
            "cs.SE",
            "I.2.5; I.2.7; I.2.10"
        ],
        "authors": [
            "Matthew Watson",
            "Divyashree Shivakumar Sreepathihalli",
            "Francois Chollet",
            "Martin Gorner",
            "Kiranbir Sodhia",
            "Ramesh Sampath",
            "Tirth Patel",
            "Haifeng Jin",
            "Neel Kovelamudi",
            "Gabriel Rasskin",
            "Samaneh Saadat",
            "Luke Wood",
            "Chen Qian",
            "Jonathan Bischof",
            "Ian Stenbit"
        ],
        "published": "2024-05-30T16:58:34Z"
    },
    {
        "title": "Retrieval Augmented Structured Generation: Business Document Information\n  Extraction As Tool Use",
        "link": "http://arxiv.org/abs/2405.20245v1",
        "abstract": "Business Document Information Extraction (BDIE) is the problem of\ntransforming a blob of unstructured information (raw text, scanned documents,\netc.) into a structured format that downstream systems can parse and use. It\nhas two main tasks: Key-Information Extraction (KIE) and Line Items Recognition\n(LIR). In this paper, we argue that BDIE is best modeled as a Tool Use problem,\nwhere the tools are these downstream systems. We then present Retrieval\nAugmented Structured Generation (RASG), a novel general framework for BDIE that\nachieves state of the art (SOTA) results on both KIE and LIR tasks on BDIE\nbenchmarks.\n  The contributions of this paper are threefold: (1) We show, with ablation\nbenchmarks, that Large Language Models (LLMs) with RASG are already competitive\nwith or surpasses current SOTA Large Multimodal Models (LMMs) without RASG on\nBDIE benchmarks. (2) We propose a new metric class for Line Items Recognition,\nGeneral Line Items Recognition Metric (GLIRM), that is more aligned with\npractical BDIE use cases compared to existing metrics, such as ANLS*, DocILE,\nand GriTS. (3) We provide a heuristic algorithm for backcalculating bounding\nboxes of predicted line items and tables without the need for vision encoders.\nFinally, we claim that, while LMMs might sometimes offer marginal performance\nbenefits, LLMs + RASG is oftentimes superior given real-world applications and\nconstraints of BDIE.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.IR",
            "cs.LG"
        ],
        "authors": [
            "Franz Louis Cesista",
            "Rui Aguiar",
            "Jason Kim",
            "Paolo Acilo"
        ],
        "published": "2024-05-30T16:54:42Z"
    },
    {
        "title": "Training-efficient density quantum machine learning",
        "link": "http://arxiv.org/abs/2405.20237v1",
        "abstract": "Quantum machine learning requires powerful, flexible and efficiently\ntrainable models to be successful in solving challenging problems. In this\nwork, we present density quantum neural networks, a learning model\nincorporating randomisation over a set of trainable unitaries. These models\ngeneralise quantum neural networks using parameterised quantum circuits, and\nallow a trade-off between expressibility and efficient trainability,\nparticularly on quantum hardware. We demonstrate the flexibility of the\nformalism by applying it to two recently proposed model families. The first are\ncommuting-block quantum neural networks (QNNs) which are efficiently trainable\nbut may be limited in expressibility. The second are orthogonal (Hamming-weight\npreserving) quantum neural networks which provide well-defined and\ninterpretable transformations on data but are challenging to train at scale on\nquantum devices. Density commuting QNNs improve capacity with minimal gradient\ncomplexity overhead, and density orthogonal neural networks admit a\nquadratic-to-constant gradient query advantage with minimal to no performance\nloss. We conduct numerical experiments on synthetic translationally invariant\ndata and MNIST image data with hyperparameter optimisation to support our\nfindings. Finally, we discuss the connection to post-variational quantum neural\nnetworks, measurement-based quantum machine learning and the dropout mechanism.",
        "subjects": [
            "quant-ph",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Brian Coyle",
            "El Amine Cherrat",
            "Nishant Jain",
            "Natansh Mathur",
            "Snehal Raj",
            "Skander Kazdaghli",
            "Iordanis Kerenidis"
        ],
        "published": "2024-05-30T16:40:28Z"
    },
    {
        "title": "Disentangling and Mitigating the Impact of Task Similarity for Continual\n  Learning",
        "link": "http://arxiv.org/abs/2405.20236v1",
        "abstract": "Continual learning of partially similar tasks poses a challenge for\nartificial neural networks, as task similarity presents both an opportunity for\nknowledge transfer and a risk of interference and catastrophic forgetting.\nHowever, it remains unclear how task similarity in input features and readout\npatterns influences knowledge transfer and forgetting, as well as how they\ninteract with common algorithms for continual learning. Here, we develop a\nlinear teacher-student model with latent structure and show analytically that\nhigh input feature similarity coupled with low readout similarity is\ncatastrophic for both knowledge transfer and retention. Conversely, the\nopposite scenario is relatively benign. Our analysis further reveals that\ntask-dependent activity gating improves knowledge retention at the expense of\ntransfer, while task-dependent plasticity gating does not affect either\nretention or transfer performance at the over-parameterized limit. In contrast,\nweight regularization based on the Fisher information metric significantly\nimproves retention, regardless of task similarity, without compromising\ntransfer performance. Nevertheless, its diagonal approximation and\nregularization in the Euclidean space are much less robust against task\nsimilarity. We demonstrate consistent results in a permuted MNIST task with\nlatent variables. Overall, this work provides insights into when continual\nlearning is difficult and how to mitigate it.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Naoki Hiratani"
        ],
        "published": "2024-05-30T16:40:07Z"
    },
    {
        "title": "Context Injection Attacks on Large Language Models",
        "link": "http://arxiv.org/abs/2405.20234v1",
        "abstract": "Large Language Models (LLMs) such as ChatGPT and Llama-2 have become\nprevalent in real-world applications, exhibiting impressive text generation\nperformance. LLMs are fundamentally developed from a scenario where the input\ndata remains static and lacks a clear structure. To behave interactively over\ntime, LLM-based chat systems must integrate additional contextual information\n(i.e., chat history) into their inputs, following a pre-defined structure. This\npaper identifies how such integration can expose LLMs to misleading context\nfrom untrusted sources and fail to differentiate between system and user\ninputs, allowing users to inject context. We present a systematic methodology\nfor conducting context injection attacks aimed at eliciting disallowed\nresponses by introducing fabricated context. This could lead to illegal\nactions, inappropriate content, or technology misuse. Our context fabrication\nstrategies, acceptance elicitation and word anonymization, effectively create\nmisleading contexts that can be structured with attacker-customized prompt\ntemplates, achieving injection through malicious user messages. Comprehensive\nevaluations on real-world LLMs such as ChatGPT and Llama-2 confirm the efficacy\nof the proposed attack with success rates reaching 97%. We also discuss\npotential countermeasures that can be adopted for attack detection and\ndeveloping more secure models. Our findings provide insights into the\nchallenges associated with the real-world deployment of LLMs for interactive\nand structured data scenarios.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Cheng'an Wei",
            "Kai Chen",
            "Yue Zhao",
            "Yujia Gong",
            "Lu Xiang",
            "Shenchen Zhu"
        ],
        "published": "2024-05-30T16:36:47Z"
    },
    {
        "title": "Grokfast: Accelerated Grokking by Amplifying Slow Gradients",
        "link": "http://arxiv.org/abs/2405.20233v1",
        "abstract": "One puzzling artifact in machine learning dubbed grokking is where delayed\ngeneralization is achieved tenfolds of iterations after near perfect\noverfitting to the training data. Focusing on the long delay itself on behalf\nof machine learning practitioners, our goal is to accelerate generalization of\na model under grokking phenomenon. By regarding a series of gradients of a\nparameter over training iterations as a random signal over time, we can\nspectrally decompose the parameter trajectories under gradient descent into two\ncomponents: the fast-varying, overfitting-yielding component and the\nslow-varying, generalization-inducing component. This analysis allows us to\naccelerate the grokking phenomenon more than $\\times 50$ with only a few lines\nof code that amplifies the slow-varying components of gradients. The\nexperiments show that our algorithm applies to diverse tasks involving images,\nlanguages, and graphs, enabling practical availability of this peculiar\nartifact of sudden generalization. Our code is available at\n\\url{https://github.com/ironjr/grokfast}.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Jaerin Lee",
            "Bong Gyun Kang",
            "Kihoon Kim",
            "Kyoung Mu Lee"
        ],
        "published": "2024-05-30T16:35:30Z"
    },
    {
        "title": "Distributed maze exploration using multiple agents and optimal goal\n  assignment",
        "link": "http://arxiv.org/abs/2405.20232v1",
        "abstract": "Robotic exploration has long captivated researchers aiming to map complex\nenvironments efficiently. Techniques such as potential fields and frontier\nexploration have traditionally been employed in this pursuit, primarily\nfocusing on solitary agents. Recent advancements have shifted towards\noptimizing exploration efficiency through multiagent systems. However, many\nexisting approaches overlook critical real-world factors, such as broadcast\nrange limitations, communication costs, and coverage overlap. This paper\naddresses these gaps by proposing a distributed maze exploration strategy\n(CU-LVP) that assumes constrained broadcast ranges and utilizes Voronoi\ndiagrams for better area partitioning. By adapting traditional multiagent\nmethods to distributed environments with limited broadcast ranges, this study\nevaluates their performance across diverse maze topologies, demonstrating the\nefficacy and practical applicability of the proposed method. The code and\nexperimental results supporting this study are available in the following\nrepository: https://github.com/manouslinard/multiagent-exploration/.",
        "subjects": [
            "cs.MA"
        ],
        "authors": [
            "Manousos Linardakis",
            "Iraklis Varlamis",
            "Georgios Th. Papadopoulos"
        ],
        "published": "2024-05-30T16:33:01Z"
    },
    {
        "title": "The Empirical Impact of Neural Parameter Symmetries, or Lack Thereof",
        "link": "http://arxiv.org/abs/2405.20231v1",
        "abstract": "Many algorithms and observed phenomena in deep learning appear to be affected\nby parameter symmetries -- transformations of neural network parameters that do\nnot change the underlying neural network function. These include linear mode\nconnectivity, model merging, Bayesian neural network inference, metanetworks,\nand several other characteristics of optimization or loss-landscapes. However,\ntheoretical analysis of the relationship between parameter space symmetries and\nthese phenomena is difficult. In this work, we empirically investigate the\nimpact of neural parameter symmetries by introducing new neural network\narchitectures that have reduced parameter space symmetries. We develop two\nmethods, with some provable guarantees, of modifying standard neural networks\nto reduce parameter space symmetries. With these new methods, we conduct a\ncomprehensive experimental study consisting of multiple tasks aimed at\nassessing the effect of removing parameter symmetries. Our experiments reveal\nseveral interesting observations on the empirical impact of parameter\nsymmetries; for instance, we observe linear mode connectivity between our\nnetworks without alignment of weight spaces, and we find that our networks\nallow for faster and more effective Bayesian neural network training.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Derek Lim",
            "Moe Putterman",
            "Robin Walters",
            "Haggai Maron",
            "Stefanie Jegelka"
        ],
        "published": "2024-05-30T16:32:31Z"
    },
    {
        "title": "MOFA-Video: Controllable Image Animation via Generative Motion Field\n  Adaptions in Frozen Image-to-Video Diffusion Model",
        "link": "http://arxiv.org/abs/2405.20222v1",
        "abstract": "We present MOFA-Video, an advanced controllable image animation method that\ngenerates video from the given image using various additional controllable\nsignals (such as human landmarks reference, manual trajectories, and another\neven provided video) or their combinations. This is different from previous\nmethods which only can work on a specific motion domain or show weak control\nabilities with diffusion prior. To achieve our goal, we design several\ndomain-aware motion field adapters (\\ie, MOFA-Adapters) to control the\ngenerated motions in the video generation pipeline. For MOFA-Adapters, we\nconsider the temporal motion consistency of the video and generate the dense\nmotion flow from the given sparse control conditions first, and then, the\nmulti-scale features of the given image are wrapped as a guided feature for\nstable video diffusion generation. We naively train two motion adapters for the\nmanual trajectories and the human landmarks individually since they both\ncontain sparse information about the control. After training, the MOFA-Adapters\nin different domains can also work together for more controllable video\ngeneration.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Muyao Niu",
            "Xiaodong Cun",
            "Xintao Wang",
            "Yong Zhang",
            "Ying Shan",
            "Yinqiang Zheng"
        ],
        "published": "2024-05-30T16:22:22Z"
    },
    {
        "title": "BeerReview: A Blockchain-enabled Peer Review Platform",
        "link": "http://arxiv.org/abs/2405.20220v1",
        "abstract": "In an era of increasing concerns over intellectual property rights,\ntraditional peer review systems face challenges including plagiarism, malicious\nattacks, and unauthorized data access. BeerReview, a blockchain-enabled peer\nreview platform, offers a robust solution, enabling experts and scholars to\nparticipate actively in the review process without concerns about plagiarism or\nsecurity threats. Following the completion of its alpha testing, BeerReview\ndemonstrates the potential for expanded deployment. This platform offers\nimproved convenience and more robust intellectual property protection within\nthe peer review process with open source initiative.",
        "subjects": [
            "cs.DC",
            "cs.CY"
        ],
        "authors": [
            "Guodong Jin",
            "Zihan Zhou",
            "Wenzheng Tang",
            "Kanglei Yu",
            "Hao Xu",
            "Erwu Liu"
        ],
        "published": "2024-05-30T16:19:13Z"
    },
    {
        "title": "System Identification for Lithium-Ion Batteries with Nonlinear Coupled\n  Electro-Thermal Dynamics via Bayesian Optimization",
        "link": "http://arxiv.org/abs/2405.20219v1",
        "abstract": "Essential to various practical applications of lithium-ion batteries is the\navailability of accurate equivalent circuit models. This paper presents a new\ncoupled electro-thermal model for batteries and studies how to extract it from\ndata. We consider the problem of maximum likelihood parameter estimation,\nwhich, however, is nontrivial to solve as the model is nonlinear in both its\ndynamics and measurement. We propose to leverage the Bayesian optimization\napproach, owing to its machine learning-driven capability in handling complex\noptimization problems and searching for global optima. To enhance the parameter\nsearch efficiency, we dynamically narrow and refine the search space in\nBayesian optimization. The proposed system identification approach can\nefficiently determine the parameters of the coupled electro-thermal model. It\nis amenable to practical implementation, with few requirements on the\nexperiment, data types, and optimization setups, and well applicable to many\nother battery models.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Hao Tu",
            "Xinfan Lin",
            "Yebin Wang",
            "Huazhen Fang"
        ],
        "published": "2024-05-30T16:19:05Z"
    },
    {
        "title": "ESG-FTSE: A corpus of news articles with ESG relevance labels and use\n  cases",
        "link": "http://arxiv.org/abs/2405.20218v1",
        "abstract": "We present ESG-FTSE, the first corpus comprised of news articles with\nEnvironmental, Social and Governance (ESG) relevance annotations. In recent\nyears, investors and regulators have pushed ESG investing to the mainstream due\nto the urgency of climate change. This has led to the rise of ESG scores to\nevaluate an investment's credentials as socially responsible. While demand for\nESG scores is high, their quality varies wildly. Quantitative techniques can be\napplied to improve ESG scores, thus, responsible investing. To contribute to\nresource building for ESG and financial text mining, we pioneer the ESG-FTSE\ncorpus. We further present the first of its kind ESG annotation schema. It has\nthree levels: a binary classification (relevant versus irrelevant news\narticles), ESG classification (ESG-related news articles), and target company.\nBoth supervised and unsupervised learning experiments for ESG relevance\ndetection were conducted to demonstrate that the corpus can be used in\ndifferent settings to derive accurate ESG predictions. Keywords: corpus\nannotation, ESG labels, annotation schema, news article, natural language\nprocessing",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Mariya Pavlova",
            "Bernard Casey",
            "Miaosen Wang"
        ],
        "published": "2024-05-30T16:19:02Z"
    },
    {
        "title": "Boost Your Own Human Image Generation Model via Direct Preference\n  Optimization with AI Feedback",
        "link": "http://arxiv.org/abs/2405.20216v1",
        "abstract": "The generation of high-quality human images through text-to-image (T2I)\nmethods is a significant yet challenging task. Distinct from general image\ngeneration, human image synthesis must satisfy stringent criteria related to\nhuman pose, anatomy, and alignment with textual prompts, making it particularly\ndifficult to achieve realistic results. Recent advancements in T2I generation\nbased on diffusion models have shown promise, yet challenges remain in meeting\nhuman-specific preferences. In this paper, we introduce a novel approach\ntailored specifically for human image generation utilizing Direct Preference\nOptimization (DPO). Specifically, we introduce an efficient method for\nconstructing a specialized DPO dataset for training human image generation\nmodels without the need for costly human feedback. We also propose a modified\nloss function that enhances the DPO training process by minimizing artifacts\nand improving image fidelity. Our method demonstrates its versatility and\neffectiveness in generating human images, including personalized text-to-image\ngeneration. Through comprehensive evaluations, we show that our approach\nsignificantly advances the state of human image generation, achieving superior\nresults in terms of natural anatomies, poses, and text-image alignment.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Sanghyeon Na",
            "Yonggyu Kim",
            "Hyunjoon Lee"
        ],
        "published": "2024-05-30T16:18:05Z"
    },
    {
        "title": "TS-Align: A Teacher-Student Collaborative Framework for Scalable\n  Iterative Finetuning of Large Language Models",
        "link": "http://arxiv.org/abs/2405.20215v1",
        "abstract": "Mainstream approaches to aligning large language models (LLMs) heavily rely\non human preference data, particularly when models require periodic updates.\nThe standard process for iterative alignment of LLMs involves collecting new\nhuman feedback for each update. However, the data collection process is costly\nand challenging to scale. To address this issue, we introduce the \"TS-Align\"\nframework, which fine-tunes a policy model using pairwise feedback data\nautomatically mined from its outputs. This automatic mining process is\nefficiently accomplished through the collaboration between a large-scale\nteacher model and a small-scale student model. The policy fine-tuning process\ncan be iteratively repeated using on-policy generations within our proposed\nteacher-student collaborative framework. Through extensive experiments, we\ndemonstrate that our final aligned policy outperforms the base policy model\nwith an average win rate of 69.7% across seven conversational or\ninstruction-following datasets. Furthermore, we show that the ranking\ncapability of the teacher is effectively distilled into the student through our\npipeline, resulting in a small-scale yet effective reward model for policy\nmodel alignment.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Chen Zhang",
            "Chengguang Tang",
            "Dading Chong",
            "Ke Shi",
            "Guohua Tang",
            "Feng Jiang",
            "Haizhou Li"
        ],
        "published": "2024-05-30T16:17:40Z"
    },
    {
        "title": "PostDoc: Generating Poster from a Long Multimodal Document Using Deep\n  Submodular Optimization",
        "link": "http://arxiv.org/abs/2405.20213v1",
        "abstract": "A poster from a long input document can be considered as a one-page\neasy-to-read multimodal (text and images) summary presented on a nice template\nwith good design elements. Automatic transformation of a long document into a\nposter is a very less studied but challenging task. It involves content\nsummarization of the input document followed by template generation and\nharmonization. In this work, we propose a novel deep submodular function which\ncan be trained on ground truth summaries to extract multimodal content from the\ndocument and explicitly ensures good coverage, diversity and alignment of text\nand images. Then, we use an LLM based paraphraser and propose to generate a\ntemplate with various design aspects conditioned on the input content. We show\nthe merits of our approach through extensive automated and human evaluations.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Vijay Jaisankar",
            "Sambaran Bandyopadhyay",
            "Kalp Vyas",
            "Varre Chaitanya",
            "Shwetha Somasundaram"
        ],
        "published": "2024-05-30T16:16:25Z"
    },
    {
        "title": "Low-rank and sparse approximations for contact mechanics",
        "link": "http://arxiv.org/abs/2405.20211v1",
        "abstract": "(Rephrased) Non-conformance decision-making processes in high-precision\nmanufacturing of engineering structures are often delayed due to numerical\nsimulations that are needed for analyzing the defective parts and assemblies.\nInterfaces between parts of assemblies can only be simulated using the modeling\nof contact. Thus, efficient parametric ROMs are necessary for performing\ncontact mechanics simulations in near real-time scenarios. Typical strategies\nfor reducing the cost of contact models use low-rank approximations.\nAssumptions include the existence of a low-dimensional subspace for\ndisplacement and a low-dimensional non-negative subcone for contact pressure.\nHowever, the contact pressure exhibits a local nature, as the position of\ncontact can vary with parameters like loading or geometry. The adequacy of\nlow-rank approximations for contact mechanics is investigated and alternative\nroutes based on sparse regression techniques are explored. It is shown that the\nlocal nature leads to loss of linear separability of contact pressure, thereby\nlimiting the accuracy of low-rank methods. The applicability of the low-rank\nassumption to contact pressure is analyzed using 3 different criteria:\ncompactness, generalization and specificity. Subsequently, over-complete\ndictionaries with a large number of snapshots to mitigate the inseparability\nissues is investigated. Two strategies are devised: a greedy active-set method\nwhere the dictionary elements are selected greedily and a convex hull\napproximation method that eliminates the necessity of explicitly enforcing\nnon-penetration constraints in convex problems. Lastly, Dynamic Time Warping is\nstudied as a possible non-linear interpolation method that permits the\nexploration of the non-linear manifoldm synthesising snapshots not computed in\nthe training set with low complexity; reducing the offline costs.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Kiran Sagar Kollepara"
        ],
        "published": "2024-05-30T16:15:41Z"
    },
    {
        "title": "Lasso-based state estimation for cyber-physical systems under sensor\n  attacks",
        "link": "http://arxiv.org/abs/2405.20209v1",
        "abstract": "The development of algorithms for secure state estimation in vulnerable\ncyber-physical systems has been gaining attention in the last years. A\nconsolidated assumption is that an adversary can tamper a relatively small\nnumber of sensors. In the literature, block-sparsity methods exploit this prior\ninformation to recover the attack locations and the state of the system.\n  In this paper, we propose an alternative, Lasso-based approach and we analyse\nits effectiveness. In particular, we theoretically derive conditions that\nguarantee successful attack/state recovery, independently of established time\nsparsity patterns. Furthermore, we develop a sparse state observer, by starting\nfrom the iterative soft thresholding algorithm for Lasso, to perform online\nestimation.\n  Through several numerical experiments, we compare the proposed methods to the\nstate-of-the-art algorithms.",
        "subjects": [
            "math.OC",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Vito Cerone",
            "Sophie M. Fosson",
            "Diego Regruto",
            "Francesco Ripa"
        ],
        "published": "2024-05-30T16:14:22Z"
    },
    {
        "title": "Jina CLIP: Your CLIP Model Is Also Your Text Retriever",
        "link": "http://arxiv.org/abs/2405.20204v1",
        "abstract": "Contrastive Language-Image Pretraining (CLIP) is widely used to train models\nto align images and texts in a common embedding space by mapping them to\nfixed-sized vectors. These models are key to multimodal information retrieval\nand related tasks. However, CLIP models generally underperform in text-only\ntasks compared to specialized text models. This creates inefficiencies for\ninformation retrieval systems that keep separate embeddings and models for\ntext-only and multimodal tasks. We propose a novel, multi-task contrastive\ntraining method to address this issue, which we use to train the jina-clip-v1\nmodel to achieve the state-of-the-art performance on both text-image and\ntext-text retrieval tasks.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CV",
            "cs.IR",
            "68T50",
            "I.2.7"
        ],
        "authors": [
            "Andreas Koukounas",
            "Georgios Mastrapas",
            "Michael Günther",
            "Bo Wang",
            "Scott Martens",
            "Isabelle Mohr",
            "Saba Sturua",
            "Mohammad Kalim Akram",
            "Joan Fontanals Martínez",
            "Saahil Ognawala",
            "Susana Guzman",
            "Maximilian Werk",
            "Nan Wang",
            "Han Xiao"
        ],
        "published": "2024-05-30T16:07:54Z"
    },
    {
        "title": "One QuantLLM for ALL: Fine-tuning Quantized LLMs Once for Efficient\n  Deployments",
        "link": "http://arxiv.org/abs/2405.20202v1",
        "abstract": "Large Language Models (LLMs) have advanced rapidly but face significant\nmemory demands. While quantization has shown promise for LLMs, current methods\ntypically require lengthy training to alleviate the performance degradation\nfrom quantization loss. However, deploying LLMs across diverse scenarios with\ndifferent resource constraints, e.g., servers and personal computers, requires\nrepeated training per application, which amplifies the lengthy training\nproblem. Given that, it is advantageous to train a once-for-all (OFA) supernet\ncapable of yielding diverse optimal subnets for downstream applications through\none-shot training. Nonetheless, the scale of current language models impedes\nefficiency and amplifies interference from weight sharing between subnets. We\nmake an initial attempt to extend the once-for-all framework to large language\nmodels. Specifically, we decouple shared weights to eliminate the interference\nand incorporate Low-Rank adapters for training efficiency. Furthermore, we\nobserve the imbalance allocation of training resources from the traditional\nuniform sampling. A non-parametric scheduler is introduced to adjust the\nsampling rate for each quantization configuration, achieving a more balanced\nallocation among subnets with varying demands. We validate the approach on\nLLaMA2 families, and downstream evaluation confirms our ability to maintain\nhigh performance while significantly reducing deployment time faced with\nmultiple scenarios.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Ke Yi",
            "Yuhui Xu",
            "Heng Chang",
            "Chen Tang",
            "Yuan Meng",
            "Tong Zhang",
            "Jia Li"
        ],
        "published": "2024-05-30T16:05:15Z"
    },
    {
        "title": "Unified Explanations in Machine Learning Models: A Perturbation Approach",
        "link": "http://arxiv.org/abs/2405.20200v1",
        "abstract": "A high-velocity paradigm shift towards Explainable Artificial Intelligence\n(XAI) has emerged in recent years. Highly complex Machine Learning (ML) models\nhave flourished in many tasks of intelligence, and the questions have started\nto shift away from traditional metrics of validity towards something deeper:\nWhat is this model telling me about my data, and how is it arriving at these\nconclusions? Inconsistencies between XAI and modeling techniques can have the\nundesirable effect of casting doubt upon the efficacy of these explainability\napproaches. To address these problems, we propose a systematic,\nperturbation-based analysis against a popular, model-agnostic method in XAI,\nSHapley Additive exPlanations (Shap). We devise algorithms to generate relative\nfeature importance in settings of dynamic inference amongst a suite of popular\nmachine learning and deep learning methods, and metrics that allow us to\nquantify how well explanations generated under the static case hold. We propose\na taxonomy for feature importance methodology, measure alignment, and observe\nquantifiable similarity amongst explanation models across several datasets.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Jacob Dineen",
            "Don Kridel",
            "Daniel Dolk",
            "David Castillo"
        ],
        "published": "2024-05-30T16:04:35Z"
    },
    {
        "title": "Generation planning and operation under power stability constraints: A\n  Hydro-Quebec use case",
        "link": "http://arxiv.org/abs/2405.20199v1",
        "abstract": "Hydro-Quebec (HQ) is a vertically integrated utility that produces,\ntransmits, and distributes most of the electricity in the province of Quebec.\nThe power grid it operates has a particular architecture created by large\nhydroelectric dams located far north and the extensive 735kV transmission grid\nthat allows the generated power to reach the majority of the load located\nthousands of kilometers away in the southern region of Quebec. The specificity\nof the grid has led HQ to develop monitoring tools responsible for generating\nso-called stability limits. Those stability limits take into account several\nnonlinear phenomena such as angular stability, frequency stability, or voltage\nstability. Since generation planning and operation tools rely mostly on mixed\ninteger linear programming formulation, HQ had to adapt its tools to integrate\nstability limits into them. This paper presents the challenges it faced,\nespecially considering its reserve monitoring tool and unit commitment tool.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Alexandre Besner",
            "Alexandre Blondin Massé",
            "Abderrahman Bani",
            "Mouad Morabit",
            "Luc Charest",
            "David Ialongo",
            "Simon Couture-Gagnon",
            "Julien Fournier"
        ],
        "published": "2024-05-30T16:01:56Z"
    },
    {
        "title": "Using Large Language Models for Humanitarian Frontline Negotiation:\n  Opportunities and Considerations",
        "link": "http://arxiv.org/abs/2405.20195v1",
        "abstract": "Humanitarian negotiations in conflict zones, called \\emph{frontline\nnegotiation}, are often highly adversarial, complex, and high-risk. Several\nbest-practices have emerged over the years that help negotiators extract\ninsights from large datasets to navigate nuanced and rapidly evolving\nscenarios. Recent advances in large language models (LLMs) have sparked\ninterest in the potential for AI to aid decision making in frontline\nnegotiation. Through in-depth interviews with 13 experienced frontline\nnegotiators, we identified their needs for AI-assisted case analysis and\ncreativity support, as well as concerns surrounding confidentiality and model\nbias. We further explored the potential for AI augmentation of three standard\ntools used in frontline negotiation planning. We evaluated the quality and\nstability of our ChatGPT-based negotiation tools in the context of two real\ncases. Our findings highlight the potential for LLMs to enhance humanitarian\nnegotiations and underscore the need for careful ethical and practical\nconsiderations.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Zilin Ma",
            "1 Susannah",
            " Su",
            "Nathan Zhao",
            "Linn Bieske",
            "Blake Bullwinkel",
            "Yanyi Zhang",
            " Sophia",
            " Yang",
            "Ziqing Luo",
            "Siyao Li",
            "Gekai Liao",
            "Boxiang Wang",
            "Jinglun Gao",
            "Zihan Wen",
            "Claude Bruderlein",
            "Weiwei Pan"
        ],
        "published": "2024-05-30T15:58:49Z"
    },
    {
        "title": "Occam Gradient Descent",
        "link": "http://arxiv.org/abs/2405.20194v1",
        "abstract": "Deep learning neural network models must be large enough to adapt to their\nproblem domain, while small enough to avoid overfitting training data during\ngradient descent. To balance these competing demands, overprovisioned deep\nlearning models such as transformers are trained for a single epoch on large\ndata sets, and hence inefficient with both computing resources and training\ndata. In response to these inefficiencies, we exploit learning theory to derive\nOccam Gradient Descent, an algorithm that interleaves adaptive reduction of\nmodel size to minimize generalization error, with gradient descent on model\nweights to minimize fitting error. In contrast, traditional gradient descent\ngreedily minimizes fitting error without regard to generalization error. Our\nalgorithm simultaneously descends the space of weights and topological size of\nany neural network without modification, and is effective in our experiments in\noutperforming traditional gradient descent with or without post-train pruning\nin accuracy, compute and model compression.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "B. N. Kausik"
        ],
        "published": "2024-05-30T15:58:22Z"
    },
    {
        "title": "TAIA: Large Language Models are Out-of-Distribution Data Learners",
        "link": "http://arxiv.org/abs/2405.20192v1",
        "abstract": "Fine-tuning on task-specific question-answer pairs is a predominant method\nfor enhancing the performance of instruction-tuned large language models (LLMs)\non downstream tasks. However, in certain specialized domains, such as\nhealthcare or harmless content generation, it is nearly impossible to obtain a\nlarge volume of high-quality data that matches the downstream distribution. To\nimprove the performance of LLMs in data-scarce domains with domain-mismatched\ndata, we re-evaluated the Transformer architecture and discovered that not all\nparameter updates during fine-tuning contribute positively to downstream\nperformance. Our analysis reveals that within the self-attention and\nfeed-forward networks, only the fine-tuned attention parameters are\nparticularly beneficial when the training set's distribution does not fully\nalign with the test set. Based on this insight, we propose an effective\ninference-time intervention method: \\uline{T}raining \\uline{A}ll parameters but\n\\uline{I}nferring with only \\uline{A}ttention (\\trainallInfAttn). We\nempirically validate \\trainallInfAttn using two general instruction-tuning\ndatasets and evaluate it on seven downstream tasks involving math, reasoning,\nand knowledge understanding across LLMs of different parameter sizes and\nfine-tuning techniques. Our comprehensive experiments demonstrate that\n\\trainallInfAttn achieves superior improvements compared to both the fully\nfine-tuned model and the base model in most scenarios, with significant\nperformance gains. The high tolerance of \\trainallInfAttn to data mismatches\nmakes it resistant to jailbreaking tuning and enhances specialized tasks using\ngeneral data.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Shuyang Jiang",
            "Yusheng Liao",
            "Ya Zhang",
            "Yu Wang",
            "Yanfeng Wang"
        ],
        "published": "2024-05-30T15:57:19Z"
    },
    {
        "title": "Nadine: An LLM-driven Intelligent Social Robot with Affective\n  Capabilities and Human-like Memory",
        "link": "http://arxiv.org/abs/2405.20189v1",
        "abstract": "In this work, we describe our approach to developing an intelligent and\nrobust social robotic system for the Nadine social robot platform. We achieve\nthis by integrating Large Language Models (LLMs) and skilfully leveraging the\npowerful reasoning and instruction-following capabilities of these types of\nmodels to achieve advanced human-like affective and cognitive capabilities.\nThis approach is novel compared to the current state-of-the-art LLM-based\nagents which do not implement human-like long-term memory or sophisticated\nemotional appraisal. The naturalness of social robots, consisting of multiple\nmodules, highly depends on the performance and capabilities of each component\nof the system and the seamless integration of the components. We built a social\nrobot system that enables generating appropriate behaviours through multimodal\ninput processing, bringing episodic memories accordingly to the recognised\nuser, and simulating the emotional states of the robot induced by the\ninteraction with the human partner. In particular, we introduce an LLM-agent\nframe for social robots, SoR-ReAct, serving as a core component for the\ninteraction module in our system. This design has brought forth the advancement\nof social robots and aims to increase the quality of human-robot interaction.",
        "subjects": [
            "cs.RO",
            "cs.AI"
        ],
        "authors": [
            "Hangyeol Kang",
            "Maher Ben Moussa",
            "Nadia Magnenat-Thalmann"
        ],
        "published": "2024-05-30T15:55:41Z"
    },
    {
        "title": "SPARE: Symmetrized Point-to-Plane Distance for Robust Non-Rigid\n  Registration",
        "link": "http://arxiv.org/abs/2405.20188v1",
        "abstract": "Existing optimization-based methods for non-rigid registration typically\nminimize an alignment error metric based on the point-to-point or\npoint-to-plane distance between corresponding point pairs on the source surface\nand target surface. However, these metrics can result in slow convergence or a\nloss of detail. In this paper, we propose SPARE, a novel formulation that\nutilizes a symmetrized point-to-plane distance for robust non-rigid\nregistration. The symmetrized point-to-plane distance relies on both the\npositions and normals of the corresponding points, resulting in a more accurate\napproximation of the underlying geometry and can achieve higher accuracy than\nexisting methods. To solve this optimization problem efficiently, we propose an\nalternating minimization solver using a majorization-minimization strategy.\nMoreover, for effective initialization of the solver, we incorporate a\ndeformation graph-based coarse alignment that improves registration quality and\nefficiency. Extensive experiments show that the proposed method greatly\nimproves the accuracy of non-rigid registration problems and maintains\nrelatively high solution efficiency. The code is publicly available at\nhttps://github.com/yaoyx689/spare.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "authors": [
            "Yuxin Yao",
            "Bailin Deng",
            "Junhui Hou",
            "Juyong Zhang"
        ],
        "published": "2024-05-30T15:55:04Z"
    },
    {
        "title": "A Survey Study on the State of the Art of Programming Exercise\n  Generation using Large Language Models",
        "link": "http://arxiv.org/abs/2405.20183v1",
        "abstract": "This paper analyzes Large Language Models (LLMs) with regard to their\nprogramming exercise generation capabilities. Through a survey study, we\ndefined the state of the art, extracted their strengths and weaknesses and\nfinally proposed an evaluation matrix, helping researchers and educators to\ndecide which LLM is the best fitting for the programming exercise generation\nuse case. We also found that multiple LLMs are capable of producing useful\nprogramming exercises. Nevertheless, there exist challenges like the ease with\nwhich LLMs might solve exercises generated by LLMs. This paper contributes to\nthe ongoing discourse on the integration of LLMs in education.",
        "subjects": [
            "cs.AI",
            "cs.SE"
        ],
        "authors": [
            "Eduard Frankford",
            "Ingo Höhn",
            "Clemens Sauerwein",
            "Ruth Breu"
        ],
        "published": "2024-05-30T15:49:34Z"
    },
    {
        "title": "Convergence Analysis for A Stochastic Maximum Principle Based Data\n  Driven Feedback Control Algorithm",
        "link": "http://arxiv.org/abs/2405.20182v1",
        "abstract": "This paper presents convergence analysis of a novel data-driven feedback\ncontrol algorithm designed for generating online controls based on partial\nnoisy observational data. The algorithm comprises a particle filter-enabled\nstate estimation component, estimating the controlled system's state via\nindirect observations, alongside an efficient stochastic maximum principle type\noptimal control solver. By integrating weak convergence techniques for the\nparticle filter with convergence analysis for the stochastic maximum principle\ncontrol solver, we derive a weak convergence result for the optimization\nprocedure in search of optimal data-driven feedback control. Numerical\nexperiments are performed to validate the theoretical findings.",
        "subjects": [
            "math.OC",
            "cs.NA",
            "math.NA"
        ],
        "authors": [
            "Siming Liang",
            "Hui Sun",
            "Richard Archibald",
            "Feng Bao"
        ],
        "published": "2024-05-30T15:49:26Z"
    },
    {
        "title": "Transformers and Slot Encoding for Sample Efficient Physical World\n  Modelling",
        "link": "http://arxiv.org/abs/2405.20180v1",
        "abstract": "World modelling, i.e. building a representation of the rules that govern the\nworld so as to predict its evolution, is an essential ability for any agent\ninteracting with the physical world. Recent applications of the Transformer\narchitecture to the problem of world modelling from video input show notable\nimprovements in sample efficiency. However, existing approaches tend to work\nonly at the image level thus disregarding that the environment is composed of\nobjects interacting with each other. In this paper, we propose an architecture\ncombining Transformers for world modelling with the slot-attention paradigm, an\napproach for learning representations of objects appearing in a scene. We\ndescribe the resulting neural architecture and report experimental results\nshowing an improvement over the existing solutions in terms of sample\nefficiency and a reduction of the variation of the performance over the\ntraining examples. The code for our architecture and experiments is available\nat https://github.com/torchipeppo/transformers-and-slot-encoding-for-wm",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CV"
        ],
        "authors": [
            "Francesco Petri",
            "Luigi Asprino",
            "Aldo Gangemi"
        ],
        "published": "2024-05-30T15:48:04Z"
    },
    {
        "title": "Robo-Instruct: Simulator-Augmented Instruction Alignment For Finetuning\n  CodeLLMs",
        "link": "http://arxiv.org/abs/2405.20179v1",
        "abstract": "Large language models (LLMs) have shown great promise at generating robot\nprograms from natural language given domain-specific robot application\nprogramming interfaces (APIs). However, the performance gap between proprietary\nLLMs and smaller open-weight LLMs remains wide. This raises a question: Can we\nfine-tune smaller open-weight LLMs for generating domain-specific robot\nprograms to close the performance gap with proprietary LLMs? While\nSelf-Instruct is a promising solution by generating a diverse set of training\ndata, it cannot verify the correctness of these programs. In contrast, a robot\nsimulator with a well-defined world can identify execution errors but limits\nthe diversity of programs that it can verify. In this work, we introduce\nRobo-Instruct, which brings the best of both worlds -- it promotes the\ndiversity of Self-Instruct while providing the correctness of simulator-based\nchecking. Robo-Instruct introduces RoboSim to synthesize a consistent world\nstate on the fly by inferring properties relevant to the program being checked,\nand simulating actions accordingly. Furthermore, the instructions and programs\ngenerated by Self-Instruct may be subtly inconsistent -- such as the program\nmissing a step implied by the instruction. Robo-Instruct further addresses this\nwith InstAlign, an instruction-program alignment procedure that revises the\ntask instruction to reflect the actual results of the generated program. Given\na few seed task descriptions and the robot APIs, Robo-Instruct is capable of\ngenerating a training dataset using only a small open-weight model. This\ndataset can then be used to fine-tune small open-weight language models,\nenabling them to match or even exceed the performance of several proprietary\nLLMs, such as GPT-3.5-Turbo and Gemini-Pro.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.RO"
        ],
        "authors": [
            "Zichao Hu",
            "Junyi Jessy Li",
            "Arjun Guha",
            "Joydeep Biswas"
        ],
        "published": "2024-05-30T15:47:54Z"
    },
    {
        "title": "Non-intrusive data-driven model order reduction for circuits based on\n  Hammerstein architectures",
        "link": "http://arxiv.org/abs/2405.20178v1",
        "abstract": "We demonstrate that data-driven system identification techniques can provide\na basis for effective, non-intrusive model order reduction (MOR) for common\ncircuits that are key building blocks in microelectronics. Our approach is\nmotivated by the practical operation of these circuits and utilizes a canonical\nHammerstein architecture. To demonstrate the approach we develop a parsimonious\nHammerstein model for a non-linear CMOS differential amplifier. We train this\nmodel on a combination of direct current (DC) and transient Spice (Xyce)\ncircuit simulation data using a novel sequential strategy to identify the\nstatic nonlinear and linear dynamical parts of the model. Simulation results\nshow that the Hammerstein model is an effective surrogate for the differential\namplifier circuit that accurately and efficiently reproduces its behavior over\na wide range of operating points and input frequencies.",
        "subjects": [
            "eess.SY",
            "cs.LG",
            "cs.SY"
        ],
        "authors": [
            "Joshua Hanson",
            "Biliana Paskaleva",
            "Pavel Bochev"
        ],
        "published": "2024-05-30T15:47:48Z"
    },
    {
        "title": "InstructionCP: A fast approach to transfer Large Language Models into\n  target language",
        "link": "http://arxiv.org/abs/2405.20175v1",
        "abstract": "The rapid development of large language models (LLMs) in recent years has\nlargely focused on English, resulting in models that respond exclusively in\nEnglish. To adapt these models to other languages, continual pre-training (CP)\nis often employed, followed by supervised fine-tuning (SFT) to maintain\nconversational abilities. However, CP and SFT can reduce a model's ability to\nfilter harmful content. We propose Instruction Continual Pre-training (InsCP),\nwhich integrates instruction tags into the CP process to prevent loss of\nconversational proficiency while acquiring new languages. Our experiments\ndemonstrate that InsCP retains conversational and Reinforcement Learning from\nHuman Feedback (RLHF) abilities. Empirical evaluations on language alignment,\nreliability, and knowledge benchmarks confirm the efficacy of InsCP. Notably,\nthis approach requires only 0.1 billion tokens of high-quality\ninstruction-following data, thereby reducing resource consumption.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Kuang-Ming Chen",
            "Hung-yi Lee"
        ],
        "published": "2024-05-30T15:45:13Z"
    },
    {
        "title": "Tropical Expressivity of Neural Networks",
        "link": "http://arxiv.org/abs/2405.20174v1",
        "abstract": "We propose an algebraic geometric framework to study the expressivity of\nlinear activation neural networks. A particular quantity that has been actively\nstudied in the field of deep learning is the number of linear regions, which\ngives an estimate of the information capacity of the architecture. To study and\nevaluate information capacity and expressivity, we work in the setting of\ntropical geometry -- a combinatorial and polyhedral variant of algebraic\ngeometry -- where there are known connections between tropical rational maps\nand feedforward neural networks. Our work builds on and expands this connection\nto capitalize on the rich theory of tropical geometry to characterize and study\nvarious architectural aspects of neural networks. Our contributions are\nthreefold: we provide a novel tropical geometric approach to selecting sampling\ndomains among linear regions; an algebraic result allowing for a guided\nrestriction of the sampling domain for network architectures with symmetries;\nand an open source library to analyze neural networks as tropical Puiseux\nrational maps. We provide a comprehensive set of proof-of-concept numerical\nexperiments demonstrating the breadth of neural network architectures to which\ntropical geometric theory can be applied to reveal insights on expressivity\ncharacteristics of a network. Our work provides the foundations for the\nadaptation of both theory and existing software from computational tropical\ngeometry and symbolic computation to deep learning.",
        "subjects": [
            "cs.LG",
            "math.AG"
        ],
        "authors": [
            "Shiv Bhatia",
            "Yueqi Cao",
            "Paul Lezeau",
            "Anthea Monod"
        ],
        "published": "2024-05-30T15:45:03Z"
    },
    {
        "title": "Eclipse Qrisp QAOA: description and preliminary comparison with Qiskit\n  counterparts",
        "link": "http://arxiv.org/abs/2405.20173v1",
        "abstract": "This paper focuses on the presentation and evaluation of the high-level\nquantum programming language Eclipse Qrisp. The presented framework, used for\ndeveloping and compiling quantum algorithms, is measured in terms of efficiency\nfor its implementation of the Quantum Approximation Optimization Algorithm\n(QAOA) Module. We measure this efficiency and compare it against two\nalternative QAOA algorithm implementations using IBM's Qiskit toolkit. The\nevaluation process has been carried out over a benchmark composed of 15\ninstances of the well-known Maximum Cut Problem. Through this preliminary\nexperimentation, Eclipse Qrisp demonstrated promising results, outperforming\nboth versions of its counterparts in terms of results quality and circuit\ncomplexity.",
        "subjects": [
            "quant-ph",
            "cs.ET"
        ],
        "authors": [
            "Eneko Osaba",
            "Matic Petrič",
            "Izaskun Oregi",
            "Raphael Seidel",
            "Alejandra Ruiz",
            "Michail-Alexandros Kourtis"
        ],
        "published": "2024-05-30T15:44:28Z"
    },
    {
        "title": "Iterative Feature Boosting for Explainable Speech Emotion Recognition",
        "link": "http://dx.doi.org/10.1109/ICMLA58977.2023.00081",
        "abstract": "In speech emotion recognition (SER), using predefined features without\nconsidering their practical importance may lead to high dimensional datasets,\nincluding redundant and irrelevant information. Consequently, high-dimensional\nlearning often results in decreasing model accuracy while increasing\ncomputational complexity. Our work underlines the importance of carefully\nconsidering and analyzing features in order to build efficient SER systems. We\npresent a new supervised SER method based on an efficient feature engineering\napproach. We pay particular attention to the explainability of results to\nevaluate feature relevance and refine feature sets. This is performed\niteratively through feature evaluation loop, using Shapley values to boost\nfeature selection and improve overall framework performance. Our approach\nallows thus to balance the benefits between model performance and transparency.\nThe proposed method outperforms human-level performance (HLP) and\nstate-of-the-art machine learning methods in emotion recognition on the TESS\ndataset.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "cs.CL",
            "cs.LG",
            "eess.AS",
            "I.2.7; I.2.6; I.2.1; I.2.8"
        ],
        "authors": [
            "Alaa Nfissi",
            "Wassim Bouachir",
            "Nizar Bouguila",
            "Brian Mishara"
        ],
        "published": "2024-05-30T15:44:27Z"
    },
    {
        "title": "Enhancing Battlefield Awareness: An Aerial RIS-assisted ISAC System with\n  Deep Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.20168v1",
        "abstract": "This paper considers a joint communication and sensing technique for\nenhancing situational awareness in practical battlefield scenarios. In\nparticular, we propose an aerial reconfigurable intelligent surface\n(ARIS)-assisted integrated sensing and communication (ISAC) system consisting\nof a single access point (AP), an ARIS, multiple users, and a sensing target.\nWith deep reinforcement learning (DRL), we jointly optimize the transmit\nbeamforming of the AP, the RIS phase shifts, and the trajectory of the ARIS\nunder signal-to-interference-noise ratio (SINR) constraints. Numerical results\ndemonstrate that the proposed technique outperforms the conventional benchmark\nschemes by suppressing the self-interference and clutter echo signals or\noptimizing the RIS phase shifts.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Hyunsang Cho",
            "Seonghoon Yoo",
            "Bang Chul Jung",
            "Joonhyuk Kang"
        ],
        "published": "2024-05-30T15:41:39Z"
    },
    {
        "title": "An approximation for return time distributions of random walks on sparse\n  networks",
        "link": "http://arxiv.org/abs/2405.20166v1",
        "abstract": "We propose an approximation for the first return time distribution of random\nwalks on undirected networks. We combine a message-passing solution with a\nmean-field approximation, to account for the short- and long-term behaviours\nrespectively. We test this approximation on several classes of large graphs and\nfind excellent agreement between our approximations and the true distributions.\nWhile the statistical properties of a random walk will depend on the structure\nof the network, the observed agreement between our approximations and numerical\ncalculations implies that while local structure is clearly very influential,\nglobal structure is only important in a relatively superficial way, namely\nthrough the total number of edges.",
        "subjects": [
            "cs.SI"
        ],
        "authors": [
            "Erik Hormann",
            "Renaud Lambiotte",
            "George T. Cantwell"
        ],
        "published": "2024-05-30T15:41:34Z"
    },
    {
        "title": "Randomized Exploration for Reinforcement Learning with Multinomial\n  Logistic Function Approximation",
        "link": "http://arxiv.org/abs/2405.20165v1",
        "abstract": "We study reinforcement learning with multinomial logistic (MNL) function\napproximation where the underlying transition probability kernel of the Markov\ndecision processes (MDPs) is parametrized by an unknown transition core with\nfeatures of state and action. For the finite horizon episodic setting with\ninhomogeneous state transitions, we propose provably efficient algorithms with\nrandomized exploration having frequentist regret guarantees. For our first\nalgorithm, $\\texttt{RRL-MNL}$, we adapt optimistic sampling to ensure the\noptimism of the estimated value function with sufficient frequency and\nestablish that $\\texttt{RRL-MNL}$ is both statistically and computationally\nefficient, achieving a $\\tilde{O}(\\kappa^{-1} d^{\\frac{3}{2}} H^{\\frac{3}{2}}\n\\sqrt{T})$ frequentist regret bound with constant-time computational cost per\nepisode. Here, $d$ is the dimension of the transition core, $H$ is the horizon\nlength, $T$ is the total number of steps, and $\\kappa$ is a problem-dependent\nconstant. Despite the simplicity and practicality of $\\texttt{RRL-MNL}$, its\nregret bound scales with $\\kappa^{-1}$, which is potentially large in the worst\ncase. To improve the dependence on $\\kappa^{-1}$, we propose\n$\\texttt{ORRL-MNL}$, which estimates the value function using local gradient\ninformation of the MNL transition model. We show that its frequentist regret\nbound is $\\tilde{O}(d^{\\frac{3}{2}} H^{\\frac{3}{2}} \\sqrt{T} + \\kappa^{-1} d^2\nH^2)$. To the best of our knowledge, these are the first randomized RL\nalgorithms for the MNL transition model that achieve both computational and\nstatistical efficiency. Numerical experiments demonstrate the superior\nperformance of the proposed algorithms.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Wooseong Cho",
            "Taehyun Hwang",
            "Joongkyu Lee",
            "Min-hwan Oh"
        ],
        "published": "2024-05-30T15:39:19Z"
    },
    {
        "title": "Reasoning about concepts with LLMs: Inconsistencies abound",
        "link": "http://arxiv.org/abs/2405.20163v1",
        "abstract": "The ability to summarize and organize knowledge into abstract concepts is key\nto learning and reasoning. Many industrial applications rely on the consistent\nand systematic use of concepts, especially when dealing with decision-critical\nknowledge. However, we demonstrate that, when methodically questioned, large\nlanguage models (LLMs) often display and demonstrate significant\ninconsistencies in their knowledge. Computationally, the basic aspects of the\nconceptualization of a given domain can be represented as Is-A hierarchies in a\nknowledge graph (KG) or ontology, together with a few properties or axioms that\nenable straightforward reasoning. We show that even simple ontologies can be\nused to reveal conceptual inconsistencies across several LLMs. We also propose\nstrategies that domain experts can use to evaluate and improve the coverage of\nkey domain concepts in LLMs of various sizes. In particular, we have been able\nto significantly enhance the performance of LLMs of various sizes with openly\navailable weights using simple knowledge-graph (KG) based prompting strategies.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Rosario Uceda-Sosa",
            "Karthikeyan Natesan Ramamurthy",
            "Maria Chang",
            "Moninder Singh"
        ],
        "published": "2024-05-30T15:38:54Z"
    },
    {
        "title": "Landslide mapping from Sentinel-2 imagery through change detection",
        "link": "http://arxiv.org/abs/2405.20161v1",
        "abstract": "Landslides are one of the most critical and destructive geohazards.\nWidespread development of human activities and settlements combined with the\neffects of climate change on weather are resulting in a high increase in the\nfrequency and destructive power of landslides, making them a major threat to\nhuman life and the economy. In this paper, we explore methodologies to map\nnewly-occurred landslides using Sentinel-2 imagery automatically. All\napproaches presented are framed as a bi-temporal change detection problem,\nrequiring only a pair of Sentinel-2 images, taken respectively before and after\na landslide-triggering event. Furthermore, we introduce a novel deep learning\narchitecture for fusing Sentinel-2 bi-temporal image pairs with Digital\nElevation Model (DEM) data, showcasing its promising performances w.r.t. other\nchange detection models in the literature. As a parallel task, we address\nlimitations in existing datasets by creating a novel geodatabase, which\nincludes manually validated open-access landslide inventories over\nheterogeneous ecoregions of the world. We release both code and dataset with an\nopen-source license.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Tommaso Monopoli",
            "Fabio Montello",
            "Claudio Rossi"
        ],
        "published": "2024-05-30T15:33:32Z"
    },
    {
        "title": "Scaling up archival text analysis with the blockmodeling of n-gram\n  networks -- A case study of Bulgaria's representation in the Osservatore\n  Romano (January-May 1877)",
        "link": "http://arxiv.org/abs/2405.20156v1",
        "abstract": "This paper seeks to bridge the gap between archival text analysis and network\nanalysis by applying network clustering methods to analyze the coverage of\nBulgaria in 123 issues of the newspaper Osservatore Romano published between\nJanuary and May 1877. Utilizing optical character recognition and generalized\nhomogeneity blockmodeling, the study constructs networks of relevant keywords.\nThose including the sets Bulgaria and Russia are rather isomorphic and they\nlargely overlap with those for Germany, Britain, and War. In structural terms,\nthe blockmodel of the two networks exhibits a clear\ncore-semiperiphery-periphery structure that reflects relations between concepts\nin the newpaper's coverage. The newspaper's lexical choices effectively\ndelegitimised the Bulgarian national revival, highlighting the influence of the\nHoly See on the newspaper's editorial line.",
        "subjects": [
            "cs.DL",
            "stat.AP",
            "stat.CO",
            "stat.OT",
            "05C15, 68U15, 90C35 05C90, 62P99",
            "I.7; H.5; J.5"
        ],
        "authors": [
            "Fabio Ashtar Telarico"
        ],
        "published": "2024-05-30T15:31:12Z"
    },
    {
        "title": "MotionDreamer: Zero-Shot 3D Mesh Animation from Video Diffusion Models",
        "link": "http://arxiv.org/abs/2405.20155v1",
        "abstract": "Animation techniques bring digital 3D worlds and characters to life. However,\nmanual animation is tedious and automated techniques are often specialized to\nnarrow shape classes. In our work, we propose a technique for automatic\nre-animation of arbitrary 3D shapes based on a motion prior extracted from a\nvideo diffusion model. Unlike existing 4D generation methods, we focus solely\non the motion, and we leverage an explicit mesh-based representation compatible\nwith existing computer-graphics pipelines. Furthermore, our utilization of\ndiffusion features enhances accuracy of our motion fitting. We analyze efficacy\nof these features for animation fitting and we experimentally validate our\napproach for two different diffusion models and four animation models. Finally,\nwe demonstrate that our time-efficient zero-shot method achieves a superior\nperformance re-animating a diverse set of 3D shapes when compared to existing\ntechniques in a user study. The project website is located at\nhttps://lukas.uzolas.com/MotionDreamer.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "authors": [
            "Lukas Uzolas",
            "Elmar Eisemann",
            "Petr Kellnhofer"
        ],
        "published": "2024-05-30T15:30:38Z"
    },
    {
        "title": "Uncovering Bias in Large Vision-Language Models at Scale with\n  Counterfactuals",
        "link": "http://arxiv.org/abs/2405.20152v1",
        "abstract": "With the advent of Large Language Models (LLMs) possessing increasingly\nimpressive capabilities, a number of Large Vision-Language Models (LVLMs) have\nbeen proposed to augment LLMs with visual inputs. Such models condition\ngenerated text on both an input image and a text prompt, enabling a variety of\nuse cases such as visual question answering and multimodal chat. While prior\nstudies have examined the social biases contained in text generated by LLMs,\nthis topic has been relatively unexplored in LVLMs. Examining social biases in\nLVLMs is particularly challenging due to the confounding contributions of bias\ninduced by information contained across the text and visual modalities. To\naddress this challenging problem, we conduct a large-scale study of text\ngenerated by different LVLMs under counterfactual changes to input images.\nSpecifically, we present LVLMs with identical open-ended text prompts while\nconditioning on images from different counterfactual sets, where each set\ncontains images which are largely identical in their depiction of a common\nsubject (e.g., a doctor), but vary only in terms of intersectional social\nattributes (e.g., race and gender). We comprehensively evaluate the text\nproduced by different models under this counterfactual generation setting at\nscale, producing over 57 million responses from popular LVLMs. Our\nmulti-dimensional analysis reveals that social attributes such as race, gender,\nand physical characteristics depicted in input images can significantly\ninfluence the generation of toxic content, competency-associated words, harmful\nstereotypes, and numerical ratings of depicted individuals. We additionally\nexplore the relationship between social bias in LVLMs and their corresponding\nLLMs, as well as inference-time strategies to mitigate bias.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Phillip Howard",
            "Kathleen C. Fraser",
            "Anahita Bhiwandiwalla",
            "Svetlana Kiritchenko"
        ],
        "published": "2024-05-30T15:27:56Z"
    },
    {
        "title": "Can the a.c.s. notion and the GLT theory handle approximated PDEs/FDEs\n  with either moving or unbounded domains?",
        "link": "http://arxiv.org/abs/2405.20150v1",
        "abstract": "In the current note we consider matrix-sequences $\\{B_{n,t}\\}_n$ of\nincreasing sizes depending on $n$ and equipped with a parameter $t>0$. For\nevery fixed $t>0$, we assume that each $\\{B_{n,t}\\}_n$ possesses a canonical\nspectral/singular values symbol $f_t$ defined on $D_t\\subset \\R^{d}$ of finite\nmeasure, $d\\ge 1$. Furthermore, we assume that $ \\{ \\{ B_{n,t}\\} : \\, t > 0 \\}\n$ is an approximating class of sequences (a.c.s.) for $ \\{ A_n \\} $ and that $\n\\bigcup_{t > 0} D_t = D $ with $ D_{t + 1} \\supset D_t $. Under such\nassumptions and via the notion of a.c.s, we prove results on the canonical\ndistributions of $ \\{ A_n \\} $, whose symbol, when it exists, can be defined on\nthe, possibly unbounded, domain $D$ of finite or even infinite measure.\n  We then extend the concept of a.c.s. to the case where the approximating\nsequence $ \\{ B_{n,t}\\}_n $ has possibly a different dimension than the one of\n$ \\{ A_n\\} $. This concept seems to be particularly natural when dealing, e.g.,\nwith the approximation both of a partial differential equation (PDE) and of its\n(possibly unbounded, or moving) domain $D$, using an exhausting sequence of\ndomains $\\{ D_t \\}$.\n  Examples coming from approximated PDEs/FDEs with either moving or unbounded\ndomains are presented in connection with the classical and the new notion of\na.c.s., while numerical tests and a list of open questions conclude the present\nwork.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Andrea Adriani",
            "Alec Jacopo Almo Schiavoni-Piazza",
            "Stefano Serra-Capizzano",
            "Cristina Tablino-Possio"
        ],
        "published": "2024-05-30T15:24:56Z"
    },
    {
        "title": "Heidelberg-Boston @ SIGTYP 2024 Shared Task: Enhancing Low-Resource\n  Language Analysis With Character-Aware Hierarchical Transformers",
        "link": "http://arxiv.org/abs/2405.20145v1",
        "abstract": "Historical languages present unique challenges to the NLP community, with one\nprominent hurdle being the limited resources available in their closed corpora.\nThis work describes our submission to the constrained subtask of the SIGTYP\n2024 shared task, focusing on PoS tagging, morphological tagging, and\nlemmatization for 13 historical languages. For PoS and morphological tagging we\nadapt a hierarchical tokenization method from Sun et al. (2023) and combine it\nwith the advantages of the DeBERTa-V3 architecture, enabling our models to\nefficiently learn from every character in the training data. We also\ndemonstrate the effectiveness of character-level T5 models on the lemmatization\ntask. Pre-trained from scratch with limited data, our models achieved first\nplace in the constrained subtask, nearly reaching the performance levels of the\nunconstrained task's winner. Our code is available at\nhttps://github.com/bowphs/SIGTYP-2024-hierarchical-transformers",
        "subjects": [
            "cs.CL",
            "I.2.7"
        ],
        "authors": [
            "Frederick Riemenschneider",
            "Kevin Krahn"
        ],
        "published": "2024-05-30T15:23:34Z"
    },
    {
        "title": "On the interpretation of quantum theory as games between physicists and\n  nature played in Minkowski spacetime",
        "link": "http://arxiv.org/abs/2405.20143v1",
        "abstract": "In 2019, we introduced games in Minkowski spacetime as a generalization of\ngame theory to special relativity that subsumes games in normal form (spacelike\nseparation) and games in extensive form (timelike separation). Many concepts\nincluding Nash equilibria naturally extend to spacetime games. We also\nemphasized the importance of these games to model quantum experiments such as\nBell experiments and more generally any adaptive measurements. Subsequent work\nsuggested to formalize a special case of such games in terms of strategy\npresheaves. In the case that measurements have a unique causal bridge and if a\nnatural cover is taken, we show that the two frameworks are isomorphic to each\nother and provide complementary perspectives. Spacetime games provide a visual\nand intuitive framework that also captures the distinction between joint\nexperiments and either-or experiments, so that they are rich enough in their\ncausal structure to imply a natural cover for the corresponding causal\ncontextuality scenario. Based on this observation, we suggest to define the\nstrategy presheaf directly based on the pure strategies (and restrictions\nthereof) of the spacetime game, and we show that the sheaf property obtains for\nthe games at hand. The argument is rather simple and similar to event sheaves\nfor the flat case. Finally, we explain how, in the other direction, the failure\nof the sheaf property on strategy distribution presheaves is consistent with\nour previous argument that Nash game theory is not compatible with quantum\nphysics. This shows that the insights of the two frameworks, taken together,\ncan contribute positively to the advancement of the field of quantum\nfoundations.",
        "subjects": [
            "quant-ph",
            "cs.GT",
            "91A35",
            "J.4"
        ],
        "authors": [
            "Ghislain Fourny"
        ],
        "published": "2024-05-30T15:19:27Z"
    },
    {
        "title": "MSSC-BiMamba: Multimodal Sleep Stage Classification and Early Diagnosis\n  of Sleep Disorders with Bidirectional Mamba",
        "link": "http://arxiv.org/abs/2405.20142v1",
        "abstract": "Background and Objectives: Monitoring sleep states is crucial for assessing\nsleep quality and diagnosing sleep disorders. Traditional manual staging\nmethods are not only time-consuming but also subject to subjective judgment,\nleading to inconsistent results. This study developed an automated sleep\nstaging and sleep disorder classification model through deep learning\ntechnology, aimed at improving diagnostic accuracy and efficiency.\n  Methods: Considering the characteristics of polysomnography (PSG) multi-lead\nsleep monitoring, we designed a sleep state classification model, MSSC-BiMamba,\nthat combines an Efficient Channel Attention (ECA) mechanism with a\nBidirectional State Space Model (BSSM). The ECA module allows for weighting\ndata from different sensor channels, thereby amplifying the influence of\ndiverse sensor inputs. Additionally, the implementation of mamba enables the\nmodel to effectively capture the multidimensional features and long-range\ndependencies of PSG data.\n  Results: The developed model demonstrated impressive performance on sleep\nstage classification tasks. Furthermore, the model exhibited an accuracy of\n0.952 for sleep health prediction when evaluated on a combined dataset\nconsisting of ISRUC and Sleep-EDF.\n  Conclusion: Our model is the first to apply the bidirectional Mamba to sleep\nstaging with complex PSG data, showing substantial gains in computational and\nmemory efficiency over traditional Transformer-style models. This method not\nonly makes health monitoring more accessible but also broadens the reach of\nadvanced healthcare, thereby enhancing sleep health management with innovative\ntechnology.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Chao Zhanga",
            "Weirong Cuia",
            "Jingjing Guo"
        ],
        "published": "2024-05-30T15:16:53Z"
    },
    {
        "title": "OpenDAS: Domain Adaptation for Open-Vocabulary Segmentation",
        "link": "http://arxiv.org/abs/2405.20141v1",
        "abstract": "The advent of Vision Language Models (VLMs) transformed image understanding\nfrom closed-set classifications to dynamic image-language interactions,\nenabling open-vocabulary segmentation. Despite this flexibility, VLMs often\nfall behind closed-set classifiers in accuracy due to their reliance on\nambiguous image captions and lack of domain-specific knowledge. We, therefore,\nintroduce a new task domain adaptation for open-vocabulary segmentation,\nenhancing VLMs with domain-specific priors while preserving their\nopen-vocabulary nature. Existing adaptation methods, when applied to\nsegmentation tasks, improve performance on training queries but can reduce VLM\nperformance on zero-shot text inputs. To address this shortcoming, we propose\nan approach that combines parameter-efficient prompt tuning with a\ntriplet-loss-based training strategy. This strategy is designed to enhance\nopen-vocabulary generalization while adapting to the visual domain. Our results\noutperform other parameter-efficient adaptation strategies in open-vocabulary\nsegment classification tasks across indoor and outdoor datasets. Notably, our\napproach is the only one that consistently surpasses the original VLM on\nzero-shot queries. Our adapted VLMs can be plug-and-play integrated into\nexisting open-vocabulary segmentation pipelines, improving OV-Seg by +6.0% mIoU\non ADE20K, and OpenMask3D by +4.1% AP on ScanNet++ Offices without any changes\nto the methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Gonca Yilmaz",
            "Songyou Peng",
            "Francis Engelmann",
            "Marc Pollefeys",
            "Hermann Blum"
        ],
        "published": "2024-05-30T15:16:06Z"
    },
    {
        "title": "GNN-RAG: Graph Neural Retrieval for Large Language Model Reasoning",
        "link": "http://arxiv.org/abs/2405.20139v1",
        "abstract": "Knowledge Graphs (KGs) represent human-crafted factual knowledge in the form\nof triplets (head, relation, tail), which collectively form a graph. Question\nAnswering over KGs (KGQA) is the task of answering natural questions grounding\nthe reasoning to the information provided by the KG. Large Language Models\n(LLMs) are the state-of-the-art models for QA tasks due to their remarkable\nability to understand natural language. On the other hand, Graph Neural\nNetworks (GNNs) have been widely used for KGQA as they can handle the complex\ngraph information stored in the KG. In this work, we introduce GNN-RAG, a novel\nmethod for combining language understanding abilities of LLMs with the\nreasoning abilities of GNNs in a retrieval-augmented generation (RAG) style.\nFirst, a GNN reasons over a dense KG subgraph to retrieve answer candidates for\na given question. Second, the shortest paths in the KG that connect question\nentities and answer candidates are extracted to represent KG reasoning paths.\nThe extracted paths are verbalized and given as input for LLM reasoning with\nRAG. In our GNN-RAG framework, the GNN acts as a dense subgraph reasoner to\nextract useful graph information, while the LLM leverages its natural language\nprocessing ability for ultimate KGQA. Furthermore, we develop a retrieval\naugmentation (RA) technique to further boost KGQA performance with GNN-RAG.\nExperimental results show that GNN-RAG achieves state-of-the-art performance in\ntwo widely used KGQA benchmarks (WebQSP and CWQ), outperforming or matching\nGPT-4 performance with a 7B tuned LLM. In addition, GNN-RAG excels on multi-hop\nand multi-entity questions outperforming competing approaches by 8.9--15.5%\npoints at answer F1.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Costas Mavromatis",
            "George Karypis"
        ],
        "published": "2024-05-30T15:14:24Z"
    },
    {
        "title": "Separation and Collapse of Equilibria Inequalities on AND-OR Trees\n  without Shape Constraints",
        "link": "http://arxiv.org/abs/2405.20138v1",
        "abstract": "Herein, we investigate the randomized complexity, which is the least cost\nagainst the worst input, of AND-OR tree computation by imposing various\nrestrictions on the algorithm to find the Boolean value of the root of that\ntree and no restrictions on the tree shape. When a tree satisfies a certain\ncondition regarding its symmetry, directional algorithms proposed by Saks and\nWigderson (1986), special randomized algorithms, are known to achieve the\nrandomized complexity. Furthermore, there is a known example of a tree that is\nso unbalanced that no directional algorithm achieves the randomized complexity\n(Vereshchagin 1998). In this study, we aim to identify where deviations arise\nbetween the general randomized Boolean decision tree and its special case,\ndirectional algorithms. In this paper, we show that for any AND-OR tree,\nrandomized depth-first algorithms, which form a broader class compared with\ndirectional algorithms, have the same equilibrium as that of the directional\nalgorithms. Thus, we get the collapse result on equilibria inequalities that\nholds for an arbitrary AND-OR tree. This implies that there exists a case where\neven depth-first algorithms cannot be the fastest, leading to the separation\nresult on equilibria inequality. Additionally, a new algorithm is introduced as\na key concept for proof of the separation result.",
        "subjects": [
            "cs.AI",
            "68T20, 68Q17, 03D15, 91A60",
            "I.2.8; F.2.2"
        ],
        "authors": [
            "Fuki Ito",
            "Toshio Suzuki"
        ],
        "published": "2024-05-30T15:13:46Z"
    },
    {
        "title": "A Multimodal Dangerous State Recognition and Early Warning System for\n  Elderly with Intermittent Dementia",
        "link": "http://arxiv.org/abs/2405.20136v1",
        "abstract": "In response to the social issue of the increasing number of elderly\nvulnerable groups going missing due to the aggravating aging population in\nChina, our team has developed a wearable anti-loss device and intelligent early\nwarning system for elderly individuals with intermittent dementia using\nartificial intelligence and IoT technology. This system comprises an anti-loss\nsmart helmet, a cloud computing module, and an intelligent early warning\napplication on the caregiver's mobile device. The smart helmet integrates a\nminiature camera module, a GPS module, and a 5G communication module to collect\nfirst-person images and location information of the elderly. Data is\ntransmitted remotely via 5G, FTP, and TCP protocols. In the cloud computing\nmodule, our team has proposed for the first time a multimodal dangerous state\nrecognition network based on scene and location information to accurately\nassess the risk of elderly individuals going missing. Finally, the application\nsoftware interface designed for the caregiver's mobile device implements\nmulti-level early warnings. The system developed by our team requires no\noperation or response from the elderly, achieving fully automatic environmental\nperception, risk assessment, and proactive alarming. This overcomes the\nlimitations of traditional monitoring devices, which require active operation\nand response, thus avoiding the issue of the digital divide for the elderly. It\neffectively prevents accidental loss and potential dangers for elderly\nindividuals with dementia.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Liyun Deng",
            "Lei Jin",
            "Guangcheng Wang",
            "Quan Shi",
            "Han Wang"
        ],
        "published": "2024-05-30T15:12:18Z"
    },
    {
        "title": "LLaMEA: A Large Language Model Evolutionary Algorithm for Automatically\n  Generating Metaheuristics",
        "link": "http://arxiv.org/abs/2405.20132v1",
        "abstract": "Large Language Models (LLMs) such as GPT-4 have demonstrated their ability to\nunderstand natural language and generate complex code snippets. This paper\nintroduces a novel Large Language Model Evolutionary Algorithm (LLaMEA)\nframework, leveraging GPT models for the automated generation and refinement of\nalgorithms. Given a set of criteria and a task definition (the search space),\nLLaMEA iteratively generates, mutates and selects algorithms based on\nperformance metrics and feedback from runtime evaluations. This framework\noffers a unique approach to generating optimized algorithms without requiring\nextensive prior expertise. We show how this framework can be used to generate\nnovel black-box metaheuristic optimization algorithms automatically. LLaMEA\ngenerates multiple algorithms that outperform state-of-the-art optimization\nalgorithms (Covariance Matrix Adaptation Evolution Strategy and Differential\nEvolution) on the five dimensional black box optimization benchmark (BBOB). The\nresults demonstrate the feasibility of the framework and identify future\ndirections for automated generation and optimization of algorithms via LLMs.",
        "subjects": [
            "cs.NE",
            "cs.AI"
        ],
        "authors": [
            "Niki van Stein",
            "Thomas Bäck"
        ],
        "published": "2024-05-30T15:10:59Z"
    },
    {
        "title": "Language Models Need Inductive Biases to Count Inductively",
        "link": "http://arxiv.org/abs/2405.20131v1",
        "abstract": "Counting is a fundamental example of generalization, whether viewed through\nthe mathematical lens of Peano's axioms defining the natural numbers or the\ncognitive science literature for children learning to count. The argument holds\nfor both cases that learning to count means learning to count infinitely. While\nfew papers have tried to distill transformer \"reasoning\" to the simplest case\nof counting, investigating length generalization does occur throughout the\nliterature. In the \"train short, test long\" paradigm of NLP, length refers to\nthe training sentence length. In formal language recognition, length refers to\nthe input sequence length, or the maximum stack size induced by a pushdown\nautomata. In general problem solving, length refers to the number of hops in a\ndeductive reasoning chain or the recursion depth. For all cases, counting is\ncentral to task success. And crucially, generalizing counting inductively is\ncentral to success on OOD instances. This work provides extensive empirical\nresults on training language models to count. We experiment with architectures\nranging from RNNs, Transformers, State-Space Models and RWKV. We present\ncarefully-designed task formats, auxiliary tasks and positional embeddings to\navoid limitations in generalization with OOD-position and OOD-vocabulary. We\nfind that while traditional RNNs trivially achieve inductive counting,\nTransformers have to rely on positional embeddings to count out-of-domain. As\ncounting is the basis for many arguments concerning the expressivity of\nTransformers, our finding calls for the community to reexamine the application\nscope of primitive functions defined in formal characterizations. Finally,\nmodern RNNs also largely underperform traditional RNNs in generalizing counting\ninductively. We discuss how design choices that enable parallelized training of\nmodern RNNs cause them to lose merits of a recurrent nature.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Yingshan Chang",
            "Yonatan Bisk"
        ],
        "published": "2024-05-30T15:10:37Z"
    },
    {
        "title": "LinApart: optimizing the univariate partial fraction decomposition",
        "link": "http://arxiv.org/abs/2405.20130v1",
        "abstract": "We present LinApart, a routine designed for efficiently performing the\nunivariate partial fraction decomposition of large symbolic expressions. Our\nmethod is based on an explicit closed formula for the decomposition of rational\nfunctions with fully factorized denominators. We provide implementations in\nboth the Wolfram Mathematica and C languages, made available at\nhttps://github.com/fekeshazy/LinApart . The routine can provide very\nsignificant performance gains over available tools such as the Apart command in\nMathematica.",
        "subjects": [
            "cs.SC",
            "hep-ph",
            "hep-th"
        ],
        "authors": [
            "Bakar Chargeishvili",
            "Levente Fekésházy",
            "Gábor Somogyi",
            "Sam Van Thurenhout"
        ],
        "published": "2024-05-30T15:10:30Z"
    },
    {
        "title": "Federated and Transfer Learning for Cancer Detection Based on Image\n  Analysis",
        "link": "http://arxiv.org/abs/2405.20126v1",
        "abstract": "This review article discusses the roles of federated learning (FL) and\ntransfer learning (TL) in cancer detection based on image analysis. These two\nstrategies powered by machine learning have drawn a lot of attention due to\ntheir potential to increase the precision and effectiveness of cancer diagnosis\nin light of the growing importance of machine learning techniques in cancer\ndetection. FL enables the training of machine learning models on data\ndistributed across multiple sites without the need for centralized data\nsharing, while TL allows for the transfer of knowledge from one task to\nanother. A comprehensive assessment of the two methods, including their\nstrengths, and weaknesses is presented. Moving on, their applications in cancer\ndetection are discussed, including potential directions for the future.\nFinally, this article offers a thorough description of the functions of TL and\nFL in image-based cancer detection. The authors also make insightful\nsuggestions for additional study in this rapidly developing area.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Amine Bechar",
            "Youssef Elmir",
            "Yassine Himeur",
            "Rafik Medjoudj",
            "Abbes Amira"
        ],
        "published": "2024-05-30T15:07:30Z"
    },
    {
        "title": "SPAM: Stochastic Proximal Point Method with Momentum Variance Reduction\n  for Non-convex Cross-Device Federated Learning",
        "link": "http://arxiv.org/abs/2405.20127v1",
        "abstract": "Cross-device training is a crucial subfield of federated learning, where the\nnumber of clients can reach into the billions. Standard approaches and local\nmethods are prone to issues such as client drift and insensitivity to data\nsimilarities. We propose a novel algorithm (SPAM) for cross-device federated\nlearning with non-convex losses, which solves both issues. We provide sharp\nanalysis under second-order (Hessian) similarity, a condition satisfied by a\nvariety of machine learning problems in practice. Additionally, we extend our\nresults to the partial participation setting, where a cohort of selected\nclients communicate with the server at each communication round. Our method is\nthe first in its kind, that does not require the smoothness of the objective\nand provably benefits from clients having similar data.",
        "subjects": [
            "math.OC",
            "cs.LG",
            "90C26"
        ],
        "authors": [
            "Avetik Karagulyan",
            "Egor Shulgin",
            "Abdurakhmon Sadiev",
            "Peter Richtárik"
        ],
        "published": "2024-05-30T15:07:30Z"
    },
    {
        "title": "A Geometric Unification of Distributionally Robust Covariance\n  Estimators: Shrinking the Spectrum by Inflating the Ambiguity Set",
        "link": "http://arxiv.org/abs/2405.20124v1",
        "abstract": "The state-of-the-art methods for estimating high-dimensional covariance\nmatrices all shrink the eigenvalues of the sample covariance matrix towards a\ndata-insensitive shrinkage target. The underlying shrinkage transformation is\neither chosen heuristically - without compelling theoretical justification - or\noptimally in view of restrictive distributional assumptions. In this paper, we\npropose a principled approach to construct covariance estimators without\nimposing restrictive assumptions. That is, we study distributionally robust\ncovariance estimation problems that minimize the worst-case Frobenius error\nwith respect to all data distributions close to a nominal distribution, where\nthe proximity of distributions is measured via a divergence on the space of\ncovariance matrices. We identify mild conditions on this divergence under which\nthe resulting minimizers represent shrinkage estimators. We show that the\ncorresponding shrinkage transformations are intimately related to the\ngeometrical properties of the underlying divergence. We also prove that our\nrobust estimators are efficiently computable and asymptotically consistent and\nthat they enjoy finite-sample performance guarantees. We exemplify our general\nmethodology by synthesizing explicit estimators induced by the\nKullback-Leibler, Fisher-Rao, and Wasserstein divergences. Numerical\nexperiments based on synthetic and real data show that our robust estimators\nare competitive with state-of-the-art estimators.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Man-Chung Yue",
            "Yves Rychener",
            "Daniel Kuhn",
            "Viet Anh Nguyen"
        ],
        "published": "2024-05-30T15:01:18Z"
    },
    {
        "title": "A Structure-Aware Lane Graph Transformer Model for Vehicle Trajectory\n  Prediction",
        "link": "http://arxiv.org/abs/2405.20121v1",
        "abstract": "Accurate prediction of future trajectories for surrounding vehicles is vital\nfor the safe operation of autonomous vehicles. This study proposes a Lane Graph\nTransformer (LGT) model with structure-aware capabilities. Its key contribution\nlies in encoding the map topology structure into the attention mechanism. To\naddress variations in lane information from different directions, four Relative\nPositional Encoding (RPE) matrices are introduced to capture the local details\nof the map topology structure. Additionally, two Shortest Path Distance (SPD)\nmatrices are employed to capture distance information between two accessible\nlanes. Numerical results indicate that the proposed LGT model achieves a\nsignificantly higher prediction performance on the Argoverse 2 dataset.\nSpecifically, the minFDE$_6$ metric was decreased by 60.73% compared to the\nArgoverse 2 baseline model (Nearest Neighbor) and the b-minFDE$_6$ metric was\nreduced by 2.65% compared to the baseline LaneGCN model. Furthermore, ablation\nexperiments demonstrated that the consideration of map topology structure led\nto a 4.24% drop in the b-minFDE$_6$ metric, validating the effectiveness of\nthis model.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Sun Zhanbo",
            "Dong Caiyin",
            "Ji Ang",
            "Zhao Ruibin",
            "Zhao Yu"
        ],
        "published": "2024-05-30T14:57:16Z"
    },
    {
        "title": "Assistance-Seeking in Human-Supervised Autonomy: Role of Trust and\n  Secondary Task Engagement (Extended Version)",
        "link": "http://arxiv.org/abs/2405.20118v1",
        "abstract": "Using a dual-task paradigm, we explore how robot actions, performance, and\nthe introduction of a secondary task influence human trust and engagement. In\nour study, a human supervisor simultaneously engages in a target-tracking task\nwhile supervising a mobile manipulator performing an object collection task.\nThe robot can either autonomously collect the object or ask for human\nassistance. The human supervisor also has the choice to rely upon or interrupt\nthe robot. Using data from initial experiments, we model the dynamics of human\ntrust and engagement using a linear dynamical system (LDS). Furthermore, we\ndevelop a human action model to define the probability of human reliance on the\nrobot. Our model suggests that participants are more likely to interrupt the\nrobot when their trust and engagement are low during high-complexity collection\ntasks. Using Model Predictive Control (MPC), we design an optimal\nassistance-seeking policy. Evaluation experiments demonstrate the superior\nperformance of the MPC policy over the baseline policy for most participants.",
        "subjects": [
            "cs.RO",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Dong Hae Mangalindan",
            "Vaibhav Srivastava"
        ],
        "published": "2024-05-30T14:55:08Z"
    },
    {
        "title": "Infinite 3D Landmarks: Improving Continuous 2D Facial Landmark Detection",
        "link": "http://dx.doi.org/10.1111/cgf.15126",
        "abstract": "In this paper, we examine 3 important issues in the practical use of\nstate-of-the-art facial landmark detectors and show how a combination of\nspecific architectural modifications can directly improve their accuracy and\ntemporal stability. First, many facial landmark detectors require face\nnormalization as a preprocessing step, which is accomplished by a\nseparately-trained neural network that crops and resizes the face in the input\nimage. There is no guarantee that this pre-trained network performs the optimal\nface normalization for landmark detection. We instead analyze the use of a\nspatial transformer network that is trained alongside the landmark detector in\nan unsupervised manner, and jointly learn optimal face normalization and\nlandmark detection. Second, we show that modifying the output head of the\nlandmark predictor to infer landmarks in a canonical 3D space can further\nimprove accuracy. To convert the predicted 3D landmarks into screen-space, we\nadditionally predict the camera intrinsics and head pose from the input image.\nAs a side benefit, this allows to predict the 3D face shape from a given image\nonly using 2D landmarks as supervision, which is useful in determining landmark\nvisibility among other things. Finally, when training a landmark detector on\nmultiple datasets at the same time, annotation inconsistencies across datasets\nforces the network to produce a suboptimal average. We propose to add a\nsemantic correction network to address this issue. This additional lightweight\nneural network is trained alongside the landmark detector, without requiring\nany additional supervision. While the insights of this paper can be applied to\nmost common landmark detectors, we specifically target a recently-proposed\ncontinuous 2D landmark detector to demonstrate how each of our additions leads\nto meaningful improvements over the state-of-the-art on standard benchmarks.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "authors": [
            "Prashanth Chandran",
            "Gaspard Zoss",
            "Paulo Gotardo",
            "Derek Bradley"
        ],
        "published": "2024-05-30T14:54:26Z"
    },
    {
        "title": "Complexity of Zeroth- and First-order Stochastic Trust-Region Algorithms",
        "link": "http://arxiv.org/abs/2405.20116v1",
        "abstract": "Model update (MU) and candidate evaluation (CE) are classical steps\nincorporated inside many stochastic trust-region (TR) algorithms. The sampling\neffort exerted within these steps, often decided with the aim of controlling\nmodel error, largely determines a stochastic TR algorithm's sample complexity.\nGiven that MU and CE are amenable to variance reduction, we investigate the\neffect of incorporating common random numbers (CRN) within MU and CE on\ncomplexity. Using ASTRO and ASTRO-DF as prototype first-order and zeroth-order\nfamilies of algorithms, we demonstrate that CRN's effectiveness leads to a\nrange of complexities depending on sample-path regularity and the oracle order.\nFor instance, we find that in first-order oracle settings with smooth sample\npaths, CRN's effect is pronounced -- ASTRO with CRN achieves\n$\\tilde{O}(\\epsilon^{-2})$ a.s. sample complexity compared to\n$\\tilde{O}(\\epsilon^{-6})$ a.s. in the generic no-CRN setting. By contrast,\nCRN's effect is muted when the sample paths are not Lipschitz, with the sample\ncomplexity improving from $\\tilde{O}(\\epsilon^{-6})$ a.s. to\n$\\tilde{O}(\\epsilon^{-5})$ and $\\tilde{O}(\\epsilon^{-4})$ a.s. in the zeroth-\nand first-order settings, respectively. Since our results imply that\nimprovements in complexity are largely inherited from generic aspects of\nvariance reduction, e.g., finite-differencing for zeroth-order settings and\nsample-path smoothness for first-order settings within MU, we anticipate\nsimilar trends in other contexts.",
        "subjects": [
            "math.OC",
            "cs.NA",
            "math.NA",
            "math.PR"
        ],
        "authors": [
            "Yunsoo Ha",
            "Sara Shashaani",
            "Raghu Pasupathy"
        ],
        "published": "2024-05-30T14:52:14Z"
    },
    {
        "title": "Monogamy of nonlocality from multipartite information causality",
        "link": "http://arxiv.org/abs/2405.20115v1",
        "abstract": "The monogamy of nonlocality is one the most intriguing and cryptographically\nsignificant predictions of quantum theory. The physical principle of\ninformation causality offers a promising means to understand and restrict the\nextent of nonlocality without invoking the abstract mathematical formalism of\nquantum theory. In this article, we demonstrate that the original bipartite\nformulation of information causality cannot imply non-trivial monogamy\nrelations, thereby refuting the previous claims. Nevertheless, we show that the\nrecently proposed multipartite formulation of information causality implies\nstronger-than-no-signaling monogamy relations. We use these monogamy relations\nto enhance the security of device-independent quantum key distribution against\na no-signaling eavesdropper constrained by information causality.",
        "subjects": [
            "quant-ph",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Lucas Pollyceno",
            "Anubhav Chaturvedi",
            "Chithra Raj",
            "Pedro R. Dieguez",
            "Marcin Pawłowski"
        ],
        "published": "2024-05-30T14:52:00Z"
    },
    {
        "title": "Near Optimal Decentralized Optimization with Compression and Momentum\n  Tracking",
        "link": "http://arxiv.org/abs/2405.20114v1",
        "abstract": "Communication efficiency has garnered significant attention as it is\nconsidered the main bottleneck for large-scale decentralized Machine Learning\napplications in distributed and federated settings. In this regime, clients are\nrestricted to transmitting small amounts of quantized information to their\nneighbors over a communication graph. Numerous endeavors have been made to\naddress this challenging problem by developing algorithms with compressed\ncommunication for decentralized non-convex optimization problems. Despite\nconsiderable efforts, the current results suffer from various issues such as\nnon-scalability with the number of clients, requirements for large batches, or\nbounded gradient assumption. In this paper, we introduce MoTEF, a novel\napproach that integrates communication compression with Momentum Tracking and\nError Feedback. Our analysis demonstrates that MoTEF achieves most of the\ndesired properties, and significantly outperforms existing methods under\narbitrary data heterogeneity. We provide numerical experiments to validate our\ntheoretical findings and confirm the practical superiority of MoTEF.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "math.OC",
            "stat.ML"
        ],
        "authors": [
            "Rustem Islamov",
            "Yuan Gao",
            "Sebastian U. Stich"
        ],
        "published": "2024-05-30T14:51:57Z"
    },
    {
        "title": "RIGID: A Training-free and Model-Agnostic Framework for Robust\n  AI-Generated Image Detection",
        "link": "http://arxiv.org/abs/2405.20112v1",
        "abstract": "The rapid advances in generative AI models have empowered the creation of\nhighly realistic images with arbitrary content, raising concerns about\npotential misuse and harm, such as Deepfakes. Current research focuses on\ntraining detectors using large datasets of generated images. However, these\ntraining-based solutions are often computationally expensive and show limited\ngeneralization to unseen generated images. In this paper, we propose a\ntraining-free method to distinguish between real and AI-generated images. We\nfirst observe that real images are more robust to tiny noise perturbations than\nAI-generated images in the representation space of vision foundation models.\nBased on this observation, we propose RIGID, a training-free and model-agnostic\nmethod for robust AI-generated image detection. RIGID is a simple yet effective\napproach that identifies whether an image is AI-generated by comparing the\nrepresentation similarity between the original and the noise-perturbed\ncounterpart. Our evaluation on a diverse set of AI-generated images and\nbenchmarks shows that RIGID significantly outperforms existing trainingbased\nand training-free detectors. In particular, the average performance of RIGID\nexceeds the current best training-free method by more than 25%. Importantly,\nRIGID exhibits strong generalization across different image generation methods\nand robustness to image corruptions.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhiyuan He",
            "Pin-Yu Chen",
            "Tsung-Yi Ho"
        ],
        "published": "2024-05-30T14:49:54Z"
    },
    {
        "title": "Autonomous programmable microscopic electronic lablets optimized with\n  digital control",
        "link": "http://arxiv.org/abs/2405.20110v1",
        "abstract": "Lablets are autonomous microscopic particles with programmable CMOS\nelectronics that can control electrokinetic phenomena and electrochemical\nreactions in solution via actuator and sensor microelectrodes. In this paper,\nwe describe the design and fabrication of optimized singulated lablets (CMOS3)\nwith dimensions 140x140x50 micrometers carrying an integrated coplanar\nencapsulated supercapacitor as a rechargeable power supply. The lablets are\ndesigned to allow docking to one another or to a smart surface for interchange\nof energy, electronic information, and chemicals. The paper focusses on the\ndigital and analog design of the lablets to allow significant programmable\nfunctionality in a microscopic footprint, including the control of autonomous\nactuation and sensing up to the level of being able to support a complete\nlablet self-reproduction life cycle, although experimentally this remains to be\nproven. The potential of lablets in autonomous sensing and control and for\nevolutionary experimentation are discussed.",
        "subjects": [
            "cs.RO",
            "cond-mat.mtrl-sci",
            "physics.ins-det",
            "I.2.9; B.7.0; J.2; J.3; J.7; H.0"
        ],
        "authors": [
            "Thomas Maeke",
            "John McCaskill",
            "Dominic Funke",
            "Pierre Mayr",
            "Abhishek Sharma",
            "Uwe Tangen",
            "Jürgen Oehm"
        ],
        "published": "2024-05-30T14:47:34Z"
    },
    {
        "title": "FMARS: Annotating Remote Sensing Images for Disaster Management using\n  Foundation Models",
        "link": "http://arxiv.org/abs/2405.20109v1",
        "abstract": "Very-High Resolution (VHR) remote sensing imagery is increasingly accessible,\nbut often lacks annotations for effective machine learning applications. Recent\nfoundation models like GroundingDINO and Segment Anything (SAM) provide\nopportunities to automatically generate annotations. This study introduces\nFMARS (Foundation Model Annotations in Remote Sensing), a methodology\nleveraging VHR imagery and foundation models for fast and robust annotation. We\nfocus on disaster management and provide a large-scale dataset with labels\nobtained from pre-event imagery over 19 disaster events, derived from the Maxar\nOpen Data initiative. We train segmentation models on the generated labels,\nusing Unsupervised Domain Adaptation (UDA) techniques to increase\ntransferability to real-world scenarios. Our results demonstrate the\neffectiveness of leveraging foundation models to automatically annotate remote\nsensing data at scale, enabling robust downstream models for critical\napplications. Code and dataset are available at\n\\url{https://github.com/links-ads/igarss-fmars}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Edoardo Arnaudo",
            "Jacopo Lungo Vaschetti",
            "Lorenzo Innocenti",
            "Luca Barco",
            "Davide Lisi",
            "Vanina Fissore",
            "Claudio Rossi"
        ],
        "published": "2024-05-30T14:45:02Z"
    },
    {
        "title": "Object-centric Reconstruction and Tracking of Dynamic Unknown Objects\n  using 3D Gaussian Splatting",
        "link": "http://arxiv.org/abs/2405.20104v1",
        "abstract": "Generalizable perception is one of the pillars of high-level autonomy in\nspace robotics. Estimating the structure and motion of unknown objects in\ndynamic environments is fundamental for such autonomous systems. Traditionally,\nthe solutions have relied on prior knowledge of target objects, multiple\ndisparate representations, or low-fidelity outputs unsuitable for robotic\noperations. This work proposes a novel approach to incrementally reconstruct\nand track a dynamic unknown object using a unified representation -- a set of\n3D Gaussian blobs that describe its geometry and appearance. The differentiable\n3D Gaussian Splatting framework is adapted to a dynamic object-centric setting.\nThe input to the pipeline is a sequential set of RGB-D images. 3D\nreconstruction and 6-DoF pose tracking tasks are tackled using first-order\ngradient-based optimization. The formulation is simple, requires no\npre-training, assumes no prior knowledge of the object or its motion, and is\nsuitable for online applications. The proposed approach is validated on a\ndataset of 10 unknown spacecraft of diverse geometry and texture under\narbitrary relative motion. The experiments demonstrate successful 3D\nreconstruction and accurate 6-DoF tracking of the target object in proximity\noperations over a short to medium duration. The causes of tracking drift are\ndiscussed and potential solutions are outlined.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Kuldeep R Barad",
            "Antoine Richard",
            "Jan Dentler",
            "Miguel Olivares-Mendez",
            "Carol Martinez"
        ],
        "published": "2024-05-30T14:42:13Z"
    },
    {
        "title": "Fill in the Gap! Combining Self-supervised Representation Learning with\n  Neural Audio Synthesis for Speech Inpainting",
        "link": "http://arxiv.org/abs/2405.20101v1",
        "abstract": "Most speech self-supervised learning (SSL) models are trained with a pretext\ntask which consists in predicting missing parts of the input signal, either\nfuture segments (causal prediction) or segments masked anywhere within the\ninput (non-causal prediction). Learned speech representations can then be\nefficiently transferred to downstream tasks (e.g., automatic speech or speaker\nrecognition). In the present study, we investigate the use of a speech SSL\nmodel for speech inpainting, that is reconstructing a missing portion of a\nspeech signal from its surrounding context, i.e., fulfilling a downstream task\nthat is very similar to the pretext task. To that purpose, we combine an SSL\nencoder, namely HuBERT, with a neural vocoder, namely HiFiGAN, playing the role\nof a decoder. In particular, we propose two solutions to match the HuBERT\noutput with the HiFiGAN input, by freezing one and fine-tuning the other, and\nvice versa. Performance of both approaches was assessed in single- and\nmulti-speaker settings, for both informed and blind inpainting configurations\n(i.e., the position of the mask is known or unknown, respectively), with\ndifferent objective metrics and a perceptual evaluation. Performances show that\nif both solutions allow to correctly reconstruct signal portions up to the size\nof 200ms (and even 400ms in some cases), fine-tuning the SSL encoder provides a\nmore accurate signal reconstruction in the single-speaker setting case, while\nfreezing it (and training the neural vocoder instead) is a better strategy when\ndealing with multi-speaker data.",
        "subjects": [
            "cs.SD",
            "cs.CL",
            "eess.AS"
        ],
        "authors": [
            "Ihab Asaad",
            "Maxime Jacquelin",
            "Olivier Perrotin",
            "Laurent Girin",
            "Thomas Hueber"
        ],
        "published": "2024-05-30T14:41:39Z"
    },
    {
        "title": "Dynamic Slack Bus",
        "link": "http://arxiv.org/abs/2405.20100v1",
        "abstract": "This letter proposes a general dynamic formulation of slack bus. With this\naim, the angle constraint imposed by the slack bus is redefined as a set of\ndifferential equations and an energy source. The existence and role of the\ntransient component of this source is also discussed in the letter. Based on\nthis framework, the letter shows that the swing equations of synchronous\nmachines can be interpreted as distributed, dynamic, multi-variable, local\nslack buses. Other relevant cases, including primary and secondary frequency\nregulation, passive loads as well as grid following and grid forming converters\nare discussed.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Federico Milano"
        ],
        "published": "2024-05-30T14:41:05Z"
    },
    {
        "title": "Defensive Prompt Patch: A Robust and Interpretable Defense of LLMs\n  against Jailbreak Attacks",
        "link": "http://arxiv.org/abs/2405.20099v1",
        "abstract": "Safety, security, and compliance are essential requirements when aligning\nlarge language models (LLMs). However, many seemingly aligned LLMs are soon\nshown to be susceptible to jailbreak attacks. These attacks aim to circumvent\nthe models' safety guardrails and security mechanisms by introducing jailbreak\nprompts into malicious queries. In response to these challenges, this paper\nintroduces Defensive Prompt Patch (DPP), a novel prompt-based defense mechanism\nspecifically designed to protect LLMs against such sophisticated jailbreak\nstrategies. Unlike previous approaches, which have often compromised the\nutility of the model for the sake of safety, DPP is designed to achieve a\nminimal Attack Success Rate (ASR) while preserving the high utility of LLMs.\nOur method uses strategically designed interpretable suffix prompts that\neffectively thwart a wide range of standard and adaptive jailbreak techniques.\nEmpirical results conducted on LLAMA-2-7B-Chat and Mistral-7B-Instruct-v0.2\nmodels demonstrate the robustness and adaptability of DPP, showing significant\nreductions in ASR with negligible impact on utility. Our approach not only\noutperforms existing defense strategies in balancing safety and functionality,\nbut also provides a scalable and interpretable solution applicable to various\nLLM platforms.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Chen Xiong",
            "Xiangyu Qi",
            "Pin-Yu Chen",
            "Tsung-Yi Ho"
        ],
        "published": "2024-05-30T14:40:35Z"
    },
    {
        "title": "Low-dimensional approximations of the conditional law of Volterra\n  processes: a non-positive curvature approach",
        "link": "http://arxiv.org/abs/2405.20094v1",
        "abstract": "Predicting the conditional evolution of Volterra processes with stochastic\nvolatility is a crucial challenge in mathematical finance. While deep neural\nnetwork models offer promise in approximating the conditional law of such\nprocesses, their effectiveness is hindered by the curse of dimensionality\ncaused by the infinite dimensionality and non-smooth nature of these problems.\nTo address this, we propose a two-step solution. Firstly, we develop a stable\ndimension reduction technique, projecting the law of a reasonably broad class\nof Volterra process onto a low-dimensional statistical manifold of non-positive\nsectional curvature. Next, we introduce a sequentially deep learning model\ntailored to the manifold's geometry, which we show can approximate the\nprojected conditional law of the Volterra process. Our model leverages an\nauxiliary hypernetwork to dynamically update its internal parameters, allowing\nit to encode non-stationary dynamics of the Volterra process, and it can be\ninterpreted as a gating mechanism in a mixture of expert models where each\nexpert is specialized at a specific point in time. Our hypernetwork further\nallows us to achieve approximation rates that would seemingly only be possible\nwith very large networks.",
        "subjects": [
            "math.NA",
            "cs.LG",
            "cs.NA",
            "cs.NE",
            "math.DG",
            "q-fin.CP"
        ],
        "authors": [
            "Reza Arabpour",
            "John Armstrong",
            "Luca Galimberti",
            "Anastasis Kratsios",
            "Giulia Livieri"
        ],
        "published": "2024-05-30T14:32:06Z"
    },
    {
        "title": "Rapid Wildfire Hotspot Detection Using Self-Supervised Learning on\n  Temporal Remote Sensing Data",
        "link": "http://arxiv.org/abs/2405.20093v1",
        "abstract": "Rapid detection and well-timed intervention are essential to mitigate the\nimpacts of wildfires. Leveraging remote sensed data from satellite networks and\nadvanced AI models to automatically detect hotspots (i.e., thermal anomalies\ncaused by active fires) is an effective way to build wildfire monitoring\nsystems. In this work, we propose a novel dataset containing time series of\nremotely sensed data related to European fire events and a Self-Supervised\nLearning (SSL)-based model able to analyse multi-temporal data and identify\nhotspots in potentially near real time. We train and evaluate the performance\nof our model using our dataset and Thraws, a dataset of thermal anomalies\nincluding several fire events, obtaining an F1 score of 63.58.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Luca Barco",
            "Angelica Urbanelli",
            "Claudio Rossi"
        ],
        "published": "2024-05-30T14:31:46Z"
    },
    {
        "title": "Divide-and-Conquer Meets Consensus: Unleashing the Power of Functions in\n  Code Generation",
        "link": "http://arxiv.org/abs/2405.20092v1",
        "abstract": "Despite recent progress made by large language models in code generation,\nthey still struggle with programs that meet complex requirements. Recent work\nutilizes plan-and-solve decomposition to decrease the complexity and leverage\nself-tests to refine the generated program. Yet, planning deep-inside\nrequirements in advance can be challenging, and the tests need to be accurate\nto accomplish self-improvement. To this end, we propose FunCoder, a code\ngeneration framework incorporating the divide-and-conquer strategy with\nfunctional consensus. Specifically, FunCoder recursively branches off\nsub-functions as smaller goals during code generation, represented by a tree\nhierarchy. These sub-functions are then composited to attain more complex\nobjectives. Additionally, we designate functions via a consensus formed by\nidentifying similarities in program behavior, mitigating error propagation.\nFunCoder outperforms state-of-the-art methods by +9.8% on average in HumanEval,\nMBPP, xCodeEval and MATH with GPT-3.5 and GPT-4. Moreover, our method\ndemonstrates superiority on smaller models: With FunCoder, StableCode-3b\nsurpasses GPT-3.5 by +18.6% and achieves 97.7% of GPT-4's performance on\nHumanEval. Further analysis reveals that our proposed dynamic function\ndecomposition is capable of handling complex requirements, and the functional\nconsensus prevails over self-testing in correctness evaluation.",
        "subjects": [
            "cs.CL",
            "cs.SE"
        ],
        "authors": [
            "Jingchang Chen",
            "Hongxuan Tang",
            "Zheng Chu",
            "Qianglong Chen",
            "Zekun Wang",
            "Ming Liu",
            "Bing Qin"
        ],
        "published": "2024-05-30T14:31:33Z"
    },
    {
        "title": "Visual Attention Analysis in Online Learning",
        "link": "http://arxiv.org/abs/2405.20091v1",
        "abstract": "In this paper, we present an approach in the Multimodal Learning Analytics\nfield. Within this approach, we have developed a tool to visualize and analyze\neye movement data collected during learning sessions in online courses. The\ntool is named VAAD (an acronym for Visual Attention Analysis Dashboard). These\neye movement data have been gathered using an eye-tracker and subsequently\nprocessed and visualized for interpretation. The purpose of the tool is to\nconduct a descriptive analysis of the data by facilitating its visualization,\nenabling the identification of differences and learning patterns among various\nlearner populations. Additionally, it integrates a predictive module capable of\nanticipating learner activities during a learning session. Consequently, VAAD\nholds the potential to offer valuable insights into online learning behaviors\nfrom both descriptive and predictive perspectives.",
        "subjects": [
            "cs.CV",
            "cs.HC",
            "cs.LG"
        ],
        "authors": [
            "Navarro Miriam",
            "Becerra Álvaro",
            "Daza Roberto",
            "Cobos Ruth",
            "Morales Aythami",
            "Fierrez Julian"
        ],
        "published": "2024-05-30T14:27:40Z"
    },
    {
        "title": "Typography Leads Semantic Diversifying: Amplifying Adversarial\n  Transferability across Multimodal Large Language Models",
        "link": "http://arxiv.org/abs/2405.20090v1",
        "abstract": "Following the advent of the Artificial Intelligence (AI) era of large models,\nMultimodal Large Language Models (MLLMs) with the ability to understand\ncross-modal interactions between vision and text have attracted wide attention.\nAdversarial examples with human-imperceptible perturbation are shown to possess\na characteristic known as transferability, which means that a perturbation\ngenerated by one model could also mislead another different model. Augmenting\nthe diversity in input data is one of the most significant methods for\nenhancing adversarial transferability. This method has been certified as a way\nto significantly enlarge the threat impact under black-box conditions. Research\nworks also demonstrate that MLLMs can be exploited to generate adversarial\nexamples in the white-box scenario. However, the adversarial transferability of\nsuch perturbations is quite limited, failing to achieve effective black-box\nattacks across different models. In this paper, we propose the\nTypographic-based Semantic Transfer Attack (TSTA), which is inspired by: (1)\nMLLMs tend to process semantic-level information; (2) Typographic Attack could\neffectively distract the visual information captured by MLLMs. In the scenarios\nof Harmful Word Insertion and Important Information Protection, our TSTA\ndemonstrates superior performance.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hao Cheng",
            "Erjia Xiao",
            "Jiahang Cao",
            "Le Yang",
            "Kaidi Xu",
            "Jindong Gu",
            "Renjing Xu"
        ],
        "published": "2024-05-30T14:27:20Z"
    },
    {
        "title": "The Fine-Tuning Paradox: Boosting Translation Quality Without\n  Sacrificing LLM Abilities",
        "link": "http://arxiv.org/abs/2405.20089v1",
        "abstract": "Fine-tuning large language models (LLMs) for machine translation has shown\nimprovements in overall translation quality. However, it is unclear what is the\nimpact of fine-tuning on desirable LLM behaviors that are not present in neural\nmachine translation models, such as steerability, inherent document-level\ntranslation abilities, and the ability to produce less literal translations. We\nperform an extensive translation evaluation on the LLaMA and Falcon family of\nmodels with model size ranging from 7 billion up to 65 billion parameters. Our\nresults show that while fine-tuning improves the general translation quality of\nLLMs, several abilities degrade. In particular, we observe a decline in the\nability to perform formality steering, to produce technical translations\nthrough few-shot examples, and to perform document-level translation. On the\nother hand, we observe that the model produces less literal translations after\nfine-tuning on parallel data. We show that by including monolingual data as\npart of the fine-tuning data we can maintain the abilities while simultaneously\nenhancing overall translation quality. Our findings emphasize the need for\nfine-tuning strategies that preserve the benefits of LLMs for machine\ntranslation.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "David Stap",
            "Eva Hasler",
            "Bill Byrne",
            "Christof Monz",
            "Ke Tran"
        ],
        "published": "2024-05-30T14:25:56Z"
    },
    {
        "title": "Analysis of a multi-target linear shrinkage covariance estimator",
        "link": "http://arxiv.org/abs/2405.20086v1",
        "abstract": "Multi-target linear shrinkage is an extension of the standard single-target\nlinear shrinkage for covariance estimation. We combine several constant\nmatrices - the targets - with the sample covariance matrix. We derive the\noracle and a \\textit{bona fide} multi-target linear shrinkage estimator with\nexact and empirical mean. In both settings, we proved its convergence towards\nthe oracle under Kolmogorov asymptotics. Finally, we show empirically that it\noutperforms other standard estimators in various situations.",
        "subjects": [
            "math.ST",
            "cs.LG",
            "math.PR",
            "stat.ML",
            "stat.TH"
        ],
        "authors": [
            "Benoit Oriol"
        ],
        "published": "2024-05-30T14:16:32Z"
    },
    {
        "title": "Soft Partitioning of Latent Space for Semantic Channel Equalization",
        "link": "http://arxiv.org/abs/2405.20085v1",
        "abstract": "Semantic channel equalization has emerged as a solution to address language\nmismatch in multi-user semantic communications. This approach aims to align the\nlatent spaces of an encoder and a decoder which were not jointly trained and it\nrelies on a partition of the semantic (latent) space into atoms based on the\nthe semantic meaning. In this work we explore the role of the semantic space\npartition in scenarios where the task structure involves a one-to-many mapping\nbetween the semantic space and the action space. In such scenarios,\npartitioning based on hard inference results results in loss of information\nwhich degrades the equalization performance. We propose a soft criterion to\nderive the atoms of the partition which leverages the soft decoder's output and\noffers a more comprehensive understanding of the semantic space's structure.\nThrough empirical validation, we demonstrate that soft partitioning yields a\nmore descriptive and regular partition of the space, consequently enhancing the\nperformance of the equalization algorithm.",
        "subjects": [
            "cs.LG",
            "cs.IT",
            "cs.MA",
            "math.IT"
        ],
        "authors": [
            "Tomás Huttebraucker",
            "Mohamed Sana",
            "Emilio Calvanese Strinati"
        ],
        "published": "2024-05-30T14:16:19Z"
    },
    {
        "title": "Estimating Human Poses Across Datasets: A Unified Skeleton and\n  Multi-Teacher Distillation Approach",
        "link": "http://arxiv.org/abs/2405.20084v1",
        "abstract": "Human pose estimation is a key task in computer vision with various\napplications such as activity recognition and interactive systems. However, the\nlack of consistency in the annotated skeletons across different datasets poses\nchallenges in developing universally applicable models. To address this\nchallenge, we propose a novel approach integrating multi-teacher knowledge\ndistillation with a unified skeleton representation. Our networks are jointly\ntrained on the COCO and MPII datasets, containing 17 and 16 keypoints,\nrespectively. We demonstrate enhanced adaptability by predicting an extended\nset of 21 keypoints, 4 (COCO) and 5 (MPII) more than original annotations,\nimproving cross-dataset generalization. Our joint models achieved an average\naccuracy of 70.89 and 76.40, compared to 53.79 and 55.78 when trained on a\nsingle dataset and evaluated on both. Moreover, we also evaluate all 21\npredicted points by our two models by reporting an AP of 66.84 and 72.75 on the\nHalpe dataset. This highlights the potential of our technique to address one of\nthe most pressing challenges in pose estimation research and application - the\ninconsistency in skeletal annotations.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Muhammad Saif Ullah Khan",
            "Dhavalkumar Limbachiya",
            "Didier Stricker",
            "Muhammad Zeshan Afzal"
        ],
        "published": "2024-05-30T14:14:39Z"
    },
    {
        "title": "Tachis: Higher-Order Separation Logic with Credits for Expected Costs",
        "link": "http://arxiv.org/abs/2405.20083v1",
        "abstract": "We present Tachis, a higher-order separation logic to reason about the\nexpected cost of probabilistic programs. Inspired by the uses of time credits\nfor reasoning about the running time of deterministic programs, we introduce a\nnovel notion of probabilistic cost credit. Probabilistic cost credits are a\nseparation logic resource that can be used to pay for the cost of operations in\nprograms, and that can be distributed across all possible branches of sampling\ninstructions according to their weight, thus enabling us to reason about\nexpected cost. The representation of cost credits as separation logic resources\ngives Tachis a great deal of flexibility and expressivity. In particular, it\npermits reasoning about amortized expected cost by storing excess credits as\npotential into data structures to pay for future operations. Tachis further\nsupports a range of cost models, including running time and entropy usage. We\nshowcase the versatility of this approach by applying our techniques to prove\nupper bounds on the expected cost of a variety of probabilistic algorithms and\ndata structures, including randomized quicksort, hash tables, and meldable\nheaps.\n  All of our results have been mechanized using Coq, Iris, and the Coquelicot\nreal analysis library.",
        "subjects": [
            "cs.LO",
            "cs.PL"
        ],
        "authors": [
            "Philipp G. Haselwarter",
            "Kwing Hei Li",
            "Markus de Medeiros",
            "Simon Oddershede Gregersen",
            "Alejandro Aguirre",
            "Joseph Tassarotti",
            "Lars Birkedal"
        ],
        "published": "2024-05-30T14:12:00Z"
    },
    {
        "title": "Segment, Shuffle, and Stitch: A Simple Mechanism for Improving\n  Time-Series Representations",
        "link": "http://arxiv.org/abs/2405.20082v1",
        "abstract": "Existing approaches for learning representations of time-series keep the\ntemporal arrangement of the time-steps intact with the presumption that the\noriginal order is the most optimal for learning. However, non-adjacent sections\nof real-world time-series may have strong dependencies. Accordingly we raise\nthe question: Is there an alternative arrangement for time-series which could\nenable more effective representation learning? To address this, we propose a\nsimple plug-and-play mechanism called Segment, Shuffle, and Stitch (S3)\ndesigned to improve time-series representation learning of existing models. S3\nworks by creating non-overlapping segments from the original sequence and\nshuffling them in a learned manner that is the most optimal for the task at\nhand. It then re-attaches the shuffled segments back together and performs a\nlearned weighted sum with the original input to capture both the newly shuffled\nsequence along with the original sequence. S3 is modular and can be stacked to\ncreate various degrees of granularity, and can be added to many forms of neural\narchitectures including CNNs or Transformers with negligible computation\noverhead. Through extensive experiments on several datasets and\nstate-of-the-art baselines, we show that incorporating S3 results in\nsignificant improvements for the tasks of time-series classification and\nforecasting, improving performance on certain datasets by up to 68\\%. We also\nshow that S3 makes the learning more stable with a smoother training loss curve\nand loss landscape compared to the original baseline. The code is available at\nhttps://github.com/shivam-grover/S3-TimeSeries .",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Shivam Grover",
            "Amin Jalali",
            "Ali Etemad"
        ],
        "published": "2024-05-30T14:11:29Z"
    },
    {
        "title": "NoiseBoost: Alleviating Hallucination with Noise Perturbation for\n  Multimodal Large Language Models",
        "link": "http://arxiv.org/abs/2405.20081v1",
        "abstract": "Multimodal large language models (MLLMs) contribute a powerful mechanism to\nunderstanding visual information building on large language models. However,\nMLLMs are notorious for suffering from hallucinations, especially when\ngenerating lengthy, detailed descriptions for images. Our analysis reveals that\nhallucinations stem from the inherent summarization mechanism of large language\nmodels, leading to excessive dependence on linguistic tokens while neglecting\nvision information. In this paper, we propose NoiseBoost, a broadly applicable\nand simple method for alleviating hallucinations for MLLMs through the\nintegration of noise feature perturbations. Noise perturbation acts as a\nregularizer, facilitating a balanced distribution of attention weights among\nvisual and linguistic tokens. Despite its simplicity, NoiseBoost consistently\nenhances the performance of MLLMs across common training strategies, including\nsupervised fine-tuning and reinforcement learning. Further, NoiseBoost\npioneerly enables semi-supervised learning for MLLMs, unleashing the power of\nunlabeled data. Comprehensive experiments demonstrate that NoiseBoost improves\ndense caption accuracy by 8.1% with human evaluation and achieves comparable\nresults with 50% of the data by mining unlabeled data. Code and models are\navailable at https://kaiwu5.github.io/noiseboost.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Kai Wu",
            "Boyuan Jiang",
            "Zhengkai Jiang",
            "Qingdong He",
            "Donghao Luo",
            "Shengzhi Wang",
            "Qingwen Liu",
            "Chengjie Wang"
        ],
        "published": "2024-05-30T14:11:27Z"
    },
    {
        "title": "Student Answer Forecasting: Transformer-Driven Answer Choice Prediction\n  for Language Learning",
        "link": "http://arxiv.org/abs/2405.20079v1",
        "abstract": "Intelligent Tutoring Systems (ITS) enhance personalized learning by\npredicting student answers to provide immediate and customized instruction.\nHowever, recent research has primarily focused on the correctness of the answer\nrather than the student's performance on specific answer choices, limiting\ninsights into students' thought processes and potential misconceptions. To\naddress this gap, we present MCQStudentBert, an answer forecasting model that\nleverages the capabilities of Large Language Models (LLMs) to integrate\ncontextual understanding of students' answering history along with the text of\nthe questions and answers. By predicting the specific answer choices students\nare likely to make, practitioners can easily extend the model to new answer\nchoices or remove answer choices for the same multiple-choice question (MCQ)\nwithout retraining the model. In particular, we compare MLP, LSTM, BERT, and\nMistral 7B architectures to generate embeddings from students' past\ninteractions, which are then incorporated into a finetuned BERT's\nanswer-forecasting mechanism. We apply our pipeline to a dataset of language\nlearning MCQ, gathered from an ITS with over 10,000 students to explore the\npredictive accuracy of MCQStudentBert, which incorporates student interaction\npatterns, in comparison to correct answer prediction and traditional\nmastery-learning feature-based approaches. This work opens the door to more\npersonalized content, modularization, and granular support.",
        "subjects": [
            "cs.CL",
            "cs.CY",
            "cs.LG"
        ],
        "authors": [
            "Elena Grazia Gado",
            "Tommaso Martorella",
            "Luca Zunino",
            "Paola Mejia-Domenzain",
            "Vinitra Swamy",
            "Jibril Frej",
            "Tanja Käser"
        ],
        "published": "2024-05-30T14:09:43Z"
    },
    {
        "title": "NeRF View Synthesis: Subjective Quality Assessment and Objective Metrics\n  Evaluation",
        "link": "http://arxiv.org/abs/2405.20078v1",
        "abstract": "Neural radiance fields (NeRF) are a groundbreaking computer vision technology\nthat enables the generation of high-quality, immersive visual content from\nmultiple viewpoints. This capability holds significant advantages for\napplications such as virtual/augmented reality, 3D modelling and content\ncreation for the film and entertainment industry. However, the evaluation of\nNeRF methods poses several challenges, including a lack of comprehensive\ndatasets, reliable assessment methodologies, and objective quality metrics.\nThis paper addresses the problem of NeRF quality assessment thoroughly, by\nconducting a rigorous subjective quality assessment test that considers several\nscene classes and recently proposed NeRF view synthesis methods. Additionally,\nthe performance of a wide range of state-of-the-art conventional and\nlearning-based full-reference 2D image and video quality assessment metrics is\nevaluated against the subjective scores of the subjective study. The\nexperimental results are analyzed in depth, providing a comparative evaluation\nof several NeRF methods and objective quality metrics, across different classes\nof visual scenes, including real and synthetic content for front-face and\n360-degree camera trajectories.",
        "subjects": [
            "cs.MM"
        ],
        "authors": [
            "Pedro Martin",
            "Antonio Rodrigues",
            "Joao Ascenso",
            "Maria Paula Queluz"
        ],
        "published": "2024-05-30T14:08:09Z"
    },
    {
        "title": "Power Allocation for Cell-Free Massive MIMO ISAC Systems with OTFS\n  Signal",
        "link": "http://arxiv.org/abs/2405.20073v1",
        "abstract": "Applying integrated sensing and communication (ISAC) to a cell-free massive\nmultiple-input multiple-output (CF mMIMO) architecture has attracted increasing\nattention. This approach equips CF mMIMO networks with sensing capabilities and\nresolves the problem of unreliable service at cell edges in conventional\ncellular networks. However, existing studies on CF-ISAC systems have focused on\nthe application of traditional integrated signals. To address this limitation,\nthis study explores the employment of the orthogonal time frequency space\n(OTFS) signal as a representative of innovative signals in the CF-ISAC system,\nand the system's overall performance is optimized and evaluated. A universal\ndownlink spectral efficiency (SE) expression is derived regarding multi-antenna\naccess points (APs) and optional sensing beams. To streamline the analysis and\noptimization of the CF-ISAC system with the OTFS signal, we introduce a lower\nbound on the achievable SE that is applicable to OTFS-signal-based systems.\nBased on this, a power allocation algorithm is proposed to maximize the minimum\ncommunication signal-to-interference-plus-noise ratio (SINR) of users while\nguaranteeing a specified sensing SINR value and meeting the per-AP power\nconstraints. The results demonstrate the tightness of the proposed lower bound\nand the efficiency of the proposed algorithm. Finally, the superiority of using\nthe OTFS signals is verified by a 13-fold expansion of the SE performance gap\nover the application of orthogonal frequency division multiplexing signals.\nThese findings could guide the future deployment of the CF-ISAC systems,\nparticularly in the field of millimeter waves with a large bandwidth.",
        "subjects": [
            "cs.IT",
            "eess.SP",
            "math.IT"
        ],
        "authors": [
            "Yifei Fan",
            "Shaochuan Wu",
            "Xixi Bi",
            "Guoyu Li"
        ],
        "published": "2024-05-30T14:03:07Z"
    },
    {
        "title": "Faces of the Mind: Unveiling Mental Health States Through Facial\n  Expressions in 11,427 Adolescents",
        "link": "http://arxiv.org/abs/2405.20072v1",
        "abstract": "Mood disorders, including depression and anxiety, often manifest through\nfacial expressions. While previous research has explored the connection between\nfacial features and emotions, machine learning algorithms for estimating mood\ndisorder severity have been hindered by small datasets and limited real-world\napplication. To address this gap, we analyzed facial videos of 11,427\nparticipants, a dataset two orders of magnitude larger than previous studies.\nThis comprehensive collection includes standardized facial expression videos\nfrom reading tasks, along with a detailed psychological scale that measures\ndepression, anxiety, and stress. By examining the relationships among these\nemotional states and employing clustering analysis, we identified distinct\nsubgroups embodying different emotional profiles. We then trained tree-based\nclassifiers and deep learning models to estimate emotional states from facial\nfeatures. Results indicate that models previously effective on small datasets\nexperienced decreased performance when applied to our large dataset,\nhighlighting the importance of data scale and mitigating overfitting in\npractical settings. Notably, our study identified subtle shifts in pupil\ndynamics and gaze orientation as potential markers of mood disorders, providing\nvaluable information on the interaction between facial expressions and mental\nhealth. This research marks the first large-scale and comprehensive\ninvestigation of facial expressions in the context of mental health, laying the\ngroundwork for future data-driven advancements in this field.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xiao Xu",
            "Keyin Zhou",
            "Yan Zhang",
            "Yang Wang",
            "Fei Wang",
            "Xizhe Zhang"
        ],
        "published": "2024-05-30T14:02:40Z"
    },
    {
        "title": "A Staged Approach using Machine Learning and Uncertainty Quantification\n  to Predict the Risk of Hip Fracture",
        "link": "http://arxiv.org/abs/2405.20071v1",
        "abstract": "Despite advancements in medical care, hip fractures impose a significant\nburden on individuals and healthcare systems. This paper focuses on the\nprediction of hip fracture risk in older and middle-aged adults, where falls\nand compromised bone quality are predominant factors. We propose a novel staged\nmodel that combines advanced imaging and clinical data to improve predictive\nperformance. By using CNNs to extract features from hip DXA images, along with\nclinical variables, shape measurements, and texture features, our method\nprovides a comprehensive framework for assessing fracture risk. A staged\nmachine learning-based model was developed using two ensemble models: Ensemble\n1 (clinical variables only) and Ensemble 2 (clinical variables and DXA imaging\nfeatures). This staged approach used uncertainty quantification from Ensemble 1\nto decide if DXA features are necessary for further prediction. Ensemble 2\nexhibited the highest performance, achieving an AUC of 0.9541, an accuracy of\n0.9195, a sensitivity of 0.8078, and a specificity of 0.9427. The staged model\nalso performed well, with an AUC of 0.8486, an accuracy of 0.8611, a\nsensitivity of 0.5578, and a specificity of 0.9249, outperforming Ensemble 1,\nwhich had an AUC of 0.5549, an accuracy of 0.7239, a sensitivity of 0.1956, and\na specificity of 0.8343. Furthermore, the staged model suggested that 54.49% of\npatients did not require DXA scanning. It effectively balanced accuracy and\nspecificity, offering a robust solution when DXA data acquisition is not always\nfeasible. Statistical tests confirmed significant differences between the\nmodels, highlighting the advantages of the advanced modeling strategies. Our\nstaged approach could identify individuals at risk with a high accuracy but\nreduce the unnecessary DXA scanning. It has great promise to guide\ninterventions to prevent hip fractures with reduced cost and radiation.",
        "subjects": [
            "physics.med-ph",
            "cs.LG"
        ],
        "authors": [
            "Anjum Shaik",
            "Kristoffer Larsen",
            "Nancy E. Lane",
            "Chen Zhao",
            "Kuan-Jui Su",
            "Joyce H. Keyak",
            "Qing Tian",
            "Qiuying Sha",
            "Hui Shen",
            "Hong-Wen Deng",
            "Weihua Zhou"
        ],
        "published": "2024-05-30T14:01:02Z"
    },
    {
        "title": "N-Dimensional Gaussians for Fitting of High Dimensional Functions",
        "link": "http://dx.doi.org/10.1145/3641519.3657502",
        "abstract": "In the wake of many new ML-inspired approaches for reconstructing and\nrepresenting high-quality 3D content, recent hybrid and explicitly learned\nrepresentations exhibit promising performance and quality characteristics.\nHowever, their scaling to higher dimensions is challenging, e.g. when\naccounting for dynamic content with respect to additional parameters such as\nmaterial properties, illumination, or time. In this paper, we tackle these\nchallenges for an explicit representations based on Gaussian mixture models.\nWith our solutions, we arrive at efficient fitting of compact N-dimensional\nGaussian mixtures and enable efficient evaluation at render time: For fast\nfitting and evaluation, we introduce a high-dimensional culling scheme that\nefficiently bounds N-D Gaussians, inspired by Locality Sensitive Hashing. For\nadaptive refinement yet compact representation, we introduce a loss-adaptive\ndensity control scheme that incrementally guides the use of additional capacity\ntowards missing details. With these tools we can for the first time represent\ncomplex appearance that depends on many input dimensions beyond position or\nviewing angle within a compact, explicit representation optimized in minutes\nand rendered in milliseconds.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "authors": [
            "Stavros Diolatzis",
            "Tobias Zirr",
            "Alexandr Kuznetsov",
            "Georgios Kopanas",
            "Anton Kaplanyan"
        ],
        "published": "2024-05-30T13:56:58Z"
    },
    {
        "title": "Variationally Correct Neural Residual Regression for Parametric PDEs: On\n  the Viability of Controlled Accuracy",
        "link": "http://arxiv.org/abs/2405.20065v1",
        "abstract": "This paper is about learning the parameter-to-solution map for systems of\npartial differential equations (PDEs) that depend on a potentially large number\nof parameters covering all PDE types for which a stable variational formulation\n(SVF) can be found. A central constituent is the notion of variationally\ncorrect residual loss function meaning that its value is always uniformly\nproportional to the squared solution error in the norm determined by the SVF,\nhence facilitating rigorous a posteriori accuracy control. It is based on a\nsingle variational problem, associated with the family of parameter dependent\nfiber problems, employing the notion of direct integrals of Hilbert spaces.\nSince in its original form the loss function is given as a dual test norm of\nthe residual a central objective is to develop equivalent computable\nexpressions. A first critical role is played by hybrid hypothesis classes,\nwhose elements are piecewise polynomial in (low-dimensional) spatio-temporal\nvariables with parameter-dependent coefficients that can be represented, e.g.\nby neural networks. Second, working with first order SVFs, we distinguish two\nscenarios: (i) the test space can be chosen as an $L_2$-space (e.g. for\nelliptic or parabolic problems) so that residuals live in $L_2$ and can be\nevaluated directly; (ii) when trial and test spaces for the fiber problems\n(e.g. for transport equations) depend on the parameters, we use ultraweak\nformulations. In combination with Discontinuous Petrov Galerkin concepts the\nhybrid format is then instrumental to arrive at variationally correct\ncomputable residual loss functions. Our findings are illustrated by numerical\nexperiments representing (i) and (ii), namely elliptic boundary value problems\nwith piecewise constant diffusion coefficients and pure transport equations\nwith parameter dependent convection field.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Markus Bachmayr",
            "Wolfgang Dahmen",
            "Mathias Oster"
        ],
        "published": "2024-05-30T13:56:38Z"
    },
    {
        "title": "1st Place Solution to Odyssey Emotion Recognition Challenge Task1:\n  Tackling Class Imbalance Problem",
        "link": "http://arxiv.org/abs/2405.20064v1",
        "abstract": "Speech emotion recognition is a challenging classification task with natural\nemotional speech, especially when the distribution of emotion types is\nimbalanced in the training and test data. In this case, it is more difficult\nfor a model to learn to separate minority classes, resulting in those sometimes\nbeing ignored or frequently misclassified. Previous work has utilised class\nweighted loss for training, but problems remain as it sometimes causes\nover-fitting for minor classes or under-fitting for major classes. This paper\npresents the system developed by a multi-site team for the participation in the\nOdyssey 2024 Emotion Recognition Challenge Track-1. The challenge data has the\naforementioned properties and therefore the presented systems aimed to tackle\nthese issues, by introducing focal loss in optimisation when applying class\nweighted loss. Specifically, the focal loss is further weighted by prior-based\nclass weights. Experimental results show that combining these two approaches\nbrings better overall performance, by sacrificing performance on major classes.\nThe system further employs a majority voting strategy to combine the outputs of\nan ensemble of 7 models. The models are trained independently, using different\nacoustic features and loss functions - with the aim to have different\nproperties for different data. Hence these models show different performance\npreferences on major classes and minor classes. The ensemble system output\nobtained the best performance in the challenge, ranking top-1 among 68\nsubmissions. It also outperformed all single models in our set. On the Odyssey\n2024 Emotion Recognition Challenge Task-1 data the system obtained a Macro-F1\nscore of 35.69% and an accuracy of 37.32%.",
        "subjects": [
            "eess.AS",
            "cs.SD"
        ],
        "authors": [
            "Mingjie Chen",
            "Hezhao Zhang",
            "Yuanchao Li",
            "Jiachen Luo",
            "Wen Wu",
            "Ziyang Ma",
            "Peter Bell",
            "Catherine Lai",
            "Joshua Reiss",
            "Lin Wang",
            "Philip C. Woodland",
            "Xie Chen",
            "Huy Phan",
            "Thomas Hain"
        ],
        "published": "2024-05-30T13:55:43Z"
    },
    {
        "title": "Can the accuracy bias by facial hairstyle be reduced through balancing\n  the training data?",
        "link": "http://arxiv.org/abs/2405.20062v1",
        "abstract": "Appearance of a face can be greatly altered by growing a beard and mustache.\nThe facial hairstyles in a pair of images can cause marked changes to the\nimpostor distribution and the genuine distribution. Also, different\ndistributions of facial hairstyle across demographics could cause a false\nimpression of relative accuracy across demographics. We first show that, even\nthough larger training sets boost the recognition accuracy on all facial\nhairstyles, accuracy variations caused by facial hairstyles persist regardless\nof the size of the training set. Then, we analyze the impact of having\ndifferent fractions of the training data represent facial hairstyles. We\ncreated balanced training sets using a set of identities available in\nWebface42M that both have clean-shaven and facial hair images. We find that,\neven when a face recognition model is trained with a balanced clean-shaven /\nfacial hair training set, accuracy variation on the test data does not\ndiminish. Next, data augmentation is employed to further investigate the effect\nof facial hair distribution in training data by manipulating facial hair pixels\nwith the help of facial landmark points and a facial hair segmentation model.\nOur results show facial hair causes an accuracy gap between clean-shaven and\nfacial hair images, and this impact can be significantly different between\nAfrican-Americans and Caucasians.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Kagan Ozturk",
            "Haiyu Wu",
            "Kevin W. Bowyer"
        ],
        "published": "2024-05-30T13:50:39Z"
    },
    {
        "title": "Spectral Mapping of Singing Voices: U-Net-Assisted Vocal Segmentation",
        "link": "http://arxiv.org/abs/2405.20059v1",
        "abstract": "Separating vocal elements from musical tracks is a longstanding challenge in\naudio signal processing. This study tackles the distinct separation of vocal\ncomponents from musical spectrograms. We employ the Short Time Fourier\nTransform (STFT) to extract audio waves into detailed frequency-time\nspectrograms, utilizing the benchmark MUSDB18 dataset for music separation.\nSubsequently, we implement a UNet neural network to segment the spectrogram\nimage, aiming to delineate and extract singing voice components accurately. We\nachieved noteworthy results in audio source separation using of our U-Net-based\nmodels. The combination of frequency-axis normalization with Min/Max scaling\nand the Mean Absolute Error (MAE) loss function achieved the highest\nSource-to-Distortion Ratio (SDR) of 7.1 dB, indicating a high level of accuracy\nin preserving the quality of the original signal during separation. This setup\nalso recorded impressive Source-to-Interference Ratio (SIR) and\nSource-to-Artifact Ratio (SAR) scores of 25.2 dB and 7.2 dB, respectively.\nThese values significantly outperformed other configurations, particularly\nthose using Quantile-based normalization or a Mean Squared Error (MSE) loss\nfunction. Our source code, model weights, and demo material can be found at the\nproject's GitHub repository: https://github.com/mbrotos/SoundSeg",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "authors": [
            "Adam Sorrenti"
        ],
        "published": "2024-05-30T13:47:53Z"
    },
    {
        "title": "Enhancing Plant Disease Detection: A Novel CNN-Based Approach with\n  Tensor Subspace Learning and HOWSVD-MD",
        "link": "http://arxiv.org/abs/2405.20058v1",
        "abstract": "Machine learning has revolutionized the field of agricultural science,\nparticularly in the early detection and management of plant diseases, which are\ncrucial for maintaining crop health and productivity. Leveraging advanced\nalgorithms and imaging technologies, researchers are now able to identify and\nclassify plant diseases with unprecedented accuracy and speed. Effective\nmanagement of tomato diseases is crucial for enhancing agricultural\nproductivity. The development and application of tomato disease classification\nmethods are central to this objective. This paper introduces a cutting-edge\ntechnique for the detection and classification of tomato leaf diseases,\nutilizing insights from the latest pre-trained Convolutional Neural Network\n(CNN) models. We propose a sophisticated approach within the domain of tensor\nsubspace learning, known as Higher-Order Whitened Singular Value Decomposition\n(HOWSVD), designed to boost the discriminatory power of the system. Our\napproach to Tensor Subspace Learning is methodically executed in two phases,\nbeginning with HOWSVD and culminating in Multilinear Discriminant Analysis\n(MDA). The efficacy of this innovative method was rigorously tested through\ncomprehensive experiments on two distinct datasets, namely PlantVillage and the\nTaiwan dataset. The findings reveal that HOWSVD-MDA outperforms existing\nmethods, underscoring its capability to markedly enhance the precision and\ndependability of diagnosing tomato leaf diseases. For instance, up to 98.36\\%\nand 89.39\\% accuracy scores have been achieved under PlantVillage and the\nTaiwan datasets, respectively.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Abdelmalik Ouamane",
            "Ammar Chouchane",
            "Yassine Himeur",
            "Abderrazak Debilou",
            "Abbes Amira",
            "Shadi Atalla",
            "Wathiq Mansoor",
            "Hussain Al Ahmad"
        ],
        "published": "2024-05-30T13:46:56Z"
    },
    {
        "title": "A General Automata Model for First-Order Temporal Logics (Extended\n  Version)",
        "link": "http://arxiv.org/abs/2405.20057v1",
        "abstract": "First-order linear temporal logic (FOLTL) is a flexible and expressive\nformalism capable of naturally describing complex behaviors and properties.\nAlthough the logic is in general highly undecidable, the idea of using it as a\nspecification language for the verification of complex infinite-state systems\nis appealing. However, a missing piece, which has proved to be an invaluable\ntool in dealing with other temporal logics, is an automaton model capable of\ncapturing the logic. In this paper we address this issue, by defining and\nstudying such a model, which we call first-order automaton. We define this very\ngeneral class of automata, and the corresponding notion of regular first-order\nlanguage, showing their closure under most common language-theoretic\noperations. We show how they can capture any FOLTL formula over any signature\nand theory, and provide sufficient conditions for the semi-decidability of\ntheir non-emptiness problem. Then, to show the usefulness of the formalism, we\nprove the decidability of monodic FOLTL, a classic result known in the\nliterature, with a simpler and direct proof.",
        "subjects": [
            "cs.LO"
        ],
        "authors": [
            "Luca Geatti",
            "Alessandro Gianola",
            "Nicola Gigante"
        ],
        "published": "2024-05-30T13:45:23Z"
    },
    {
        "title": "Hypergraph-Aided Task-Resource Matching for Maximizing Value of Task\n  Completion in Collaborative IoT Systems",
        "link": "http://arxiv.org/abs/2405.20055v1",
        "abstract": "With the growing scale and intrinsic heterogeneity of Internet of Things\n(IoT) systems, distributed device collaboration becomes essential for effective\ntask completion by dynamically utilizing limited communication and computing\nresources. However, the separated design and situation-agnostic operation of\ncomputing, communication and application layers create a fundamental challenge\nfor rapid task-resource matching, which further deteriorate the overall task\ncompletion effectiveness. To overcome this challenge, we utilize hypergraph as\na new tool to vertically unify computing, communication, and task aspects of\nIoT systems for an effective matching by accurately capturing the relationships\nbetween tasks and communication and computing resources. Specifically, a\nstate-of-the-art task-resource matching hypergraph (TRM-hypergraph) model is\nproposed in this paper, which is used to effectively transform the process of\nallocating complex heterogeneous resources to convoluted tasks into a\nhypergraph matching problem. Taking into account computational complexity and\nstorage, a game-theoretic hypergraph matching algorithm is proposed via\nconsidering the hypergraph matching problem as a non-cooperative multi-player\nclustering game. Numerical results demonstrate that the proposed TRM-hypergraph\nmodel achieves superior performance in matching of tasks and resources compared\nwith comparison algorithms.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Botao Zhu",
            "Xianbin Wang"
        ],
        "published": "2024-05-30T13:43:15Z"
    },
    {
        "title": "Would I Lie To You? Inference Time Alignment of Language Models using\n  Direct Preference Heads",
        "link": "http://arxiv.org/abs/2405.20053v1",
        "abstract": "Pre-trained Language Models (LMs) exhibit strong zero-shot and in-context\nlearning capabilities; however, their behaviors are often difficult to control.\nBy utilizing Reinforcement Learning from Human Feedback (RLHF), it is possible\nto fine-tune unsupervised LMs to follow instructions and produce outputs that\nreflect human preferences. Despite its benefits, RLHF has been shown to\npotentially harm a language model's reasoning capabilities and introduce\nartifacts such as hallucinations where the model may fabricate facts. To\naddress this issue we introduce Direct Preference Heads (DPH), a fine-tuning\nframework that enables LMs to learn human preference signals through an\nauxiliary reward head without directly affecting the output distribution of the\nlanguage modeling head. We perform a theoretical analysis of our objective\nfunction and find strong ties to Conservative Direct Preference Optimization\n(cDPO). Finally we evaluate our models on GLUE, RACE, and the GPT4All\nevaluation suite and demonstrate that our method produces models which achieve\nhigher scores than those fine-tuned with Supervised Fine-Tuning (SFT) or Direct\nPreference Optimization (DPO) alone.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Avelina Asada Hadji-Kyriacou",
            "Ognjen Arandjelovic"
        ],
        "published": "2024-05-30T13:38:52Z"
    },
    {
        "title": "A Hardware-Efficient EMG Decoder with an Attractor-based Neural Network\n  for Next-Generation Hand Prostheses",
        "link": "http://arxiv.org/abs/2405.20052v1",
        "abstract": "Advancements in neural engineering have enabled the development of Robotic\nProsthetic Hands (RPHs) aimed at restoring hand functionality. Current\ncommercial RPHs offer limited control through basic on/off commands. Recent\nprogresses in machine learning enable finger movement decoding with higher\ndegrees of freedom, yet the high computational complexity of such models limits\ntheir application in portable devices. Future RPH designs must balance\nportability, low power consumption, and high decoding accuracy to be practical\nfor individuals with disabilities. To this end, we introduce a novel\nattractor-based neural network to realize on-chip movement decoding for\nnext-generation portable RPHs. The proposed architecture comprises an encoder,\nan attention layer, an attractor network, and a refinement regressor. We tested\nour model on four healthy subjects and achieved a decoding accuracy of\n80.6\\pm3.3\\%. Our proposed model is over 120 and 50 times more compact compared\nto state-of-the-art LSTM and CNN models, respectively, with comparable (or\nsuperior) decoding accuracy. Therefore, it exhibits minimal hardware complexity\nand can be effectively integrated as a System-on-Chip.",
        "subjects": [
            "eess.SP",
            "cs.LG"
        ],
        "authors": [
            "Mohammad Kalbasi",
            "MohammadAli Shaeri",
            "Vincent Alexandre Mendez",
            "Solaiman Shokur",
            "Silvestro Micera",
            "Mahsa Shoaran"
        ],
        "published": "2024-05-30T13:38:28Z"
    },
    {
        "title": "Threshold-Independent Fair Matching through Score Calibration",
        "link": "http://dx.doi.org/10.1145/3665601.3669845",
        "abstract": "Entity Matching (EM) is a critical task in numerous fields, such as\nhealthcare, finance, and public administration, as it identifies records that\nrefer to the same entity within or across different databases. EM faces\nconsiderable challenges, particularly with false positives and negatives. These\nare typically addressed by generating matching scores and apply thresholds to\nbalance false positives and negatives in various contexts. However, adjusting\nthese thresholds can affect the fairness of the outcomes, a critical factor\nthat remains largely overlooked in current fair EM research. The existing body\nof research on fair EM tends to concentrate on static thresholds, neglecting\ntheir critical impact on fairness. To address this, we introduce a new approach\nin EM using recent metrics for evaluating biases in score based binary\nclassification, particularly through the lens of distributional parity. This\napproach enables the application of various bias metrics like equalized odds,\nequal opportunity, and demographic parity without depending on threshold\nsettings. Our experiments with leading matching methods reveal potential\nbiases, and by applying a calibration technique for EM scores using Wasserstein\nbarycenters, we not only mitigate these biases but also preserve accuracy\nacross real world datasets. This paper contributes to the field of fairness in\ndata cleaning, especially within EM, which is a central task in data cleaning,\nby promoting a method for generating matching scores that reduce biases across\ndifferent thresholds.",
        "subjects": [
            "cs.LG",
            "cs.DB"
        ],
        "authors": [
            "Mohammad Hossein Moslemi",
            "Mostafa Milani"
        ],
        "published": "2024-05-30T13:37:53Z"
    },
    {
        "title": "Schubert Subspace Codes",
        "link": "http://arxiv.org/abs/2405.20047v1",
        "abstract": "In this paper, we initiate the study of constant dimension subspace codes\nrestricted to Schubert varieties, which we call Schubert subspace codes. These\ncodes have a very natural geometric description, as objects that we call\nintersecting sets with respect to a fixed subspace. We provide a geometric\nconstruction of maximum size constant dimension subspace codes in some Schubert\nvarieties with the largest possible value for the minimum subspace distance.\nFinally, we generalize the problem to different values of the minimum distance.",
        "subjects": [
            "cs.IT",
            "math.CO",
            "math.IT"
        ],
        "authors": [
            "Gianira N. Alfarano",
            "Joachim Rosenthal",
            "Beatrice Toesca"
        ],
        "published": "2024-05-30T13:29:32Z"
    },
    {
        "title": "Cross-Training with Multi-View Knowledge Fusion for Heterogenous\n  Federated Learning",
        "link": "http://arxiv.org/abs/2405.20046v1",
        "abstract": "Federated learning benefits from cross-training strategies, which enables\nmodels to train on data from distinct sources to improve the generalization\ncapability. However, the data heterogeneity between sources may lead models to\ngradually forget previously acquired knowledge when undergoing cross-training\nto adapt to new tasks or data sources. We argue that integrating personalized\nand global knowledge to gather information from multiple perspectives could\npotentially improve performance. To achieve this goal, this paper presents a\nnovel approach that enhances federated learning through a cross-training scheme\nincorporating multi-view information. Specifically, the proposed method, termed\nFedCT, includes three main modules, where the consistency-aware knowledge\nbroadcasting module aims to optimize model assignment strategies, which\nenhances collaborative advantages between clients and achieves an efficient\nfederated learning process. The multi-view knowledge-guided representation\nlearning module leverages fused prototypical knowledge from both global and\nlocal views to enhance the preservation of local knowledge before and after\nmodel exchange, as well as to ensure consistency between local and global\nknowledge. The mixup-based feature augmentation module aggregates rich\ninformation to further increase the diversity of feature spaces, which enables\nthe model to better discriminate complex samples. Extensive experiments were\nconducted on four datasets in terms of performance comparison, ablation study,\nin-depth analysis and case study. The results demonstrated that FedCT\nalleviates knowledge forgetting from both local and global views, which enables\nit outperform state-of-the-art methods.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Zhuang Qi",
            "Lei Meng",
            "Weihao He",
            "Ruohan Zhang",
            "Yu Wang",
            "Xin Qi",
            "Xiangxu Meng"
        ],
        "published": "2024-05-30T13:27:30Z"
    },
    {
        "title": "Iterative Learning Control of Fast, Nonlinear, Oscillatory Dynamics\n  (Preprint)",
        "link": "http://arxiv.org/abs/2405.20045v1",
        "abstract": "The sudden onset of deleterious and oscillatory dynamics (often called\ninstabilities) is a known challenge in many fluid, plasma, and aerospace\nsystems. These dynamics are difficult to address because they are nonlinear,\nchaotic, and are often too fast for active control schemes. In this work, we\ndevelop an alternative active controls system using an iterative,\ntrajectory-optimization and parameter-tuning approach based on Iterative\nLearning Control (ILC), Time-Lagged Phase Portraits (TLPP) and Gaussian Process\nRegression (GPR). The novelty of this approach is that it can control a\nsystem's dynamics despite the controller being much slower than the dynamics.\nWe demonstrate this controller on the Lorenz system of equations where it\niteratively adjusts (tunes) the system's input parameters to successfully\nreproduce a desired oscillatory trajectory or state. Additionally, we\ninvestigate the system's dynamical sensitivity to its control parameters,\nidentify continuous and bounded regions of desired dynamical trajectories, and\ndemonstrate that the controller is robust to missing information and\nuncontrollable parameters as long as certain requirements are met. The\ncontroller presented in this work provides a framework for low-speed control\nfor a variety of fast, nonlinear systems that may aid in instability\nsuppression and mitigation.",
        "subjects": [
            "cs.LG",
            "cs.SY",
            "eess.SY",
            "math.DS"
        ],
        "authors": [
            "John W. Brooks",
            "Christine M. Greve"
        ],
        "published": "2024-05-30T13:27:17Z"
    },
    {
        "title": "A Point-Neighborhood Learning Framework for Nasal Endoscope Image\n  Segmentation",
        "link": "http://arxiv.org/abs/2405.20044v1",
        "abstract": "The lesion segmentation on endoscopic images is challenging due to its\ncomplex and ambiguous features. Fully-supervised deep learning segmentation\nmethods can receive good performance based on entirely pixel-level labeled\ndataset but greatly increase experts' labeling burden. Semi-supervised and\nweakly supervised methods can ease labeling burden, but heavily strengthen the\nlearning difficulty. To alleviate this difficulty, weakly semi-supervised\nsegmentation adopts a new annotation protocol of adding a large number of point\nannotation samples into a few pixel-level annotation samples. However, existing\nmethods only mine points' limited information while ignoring reliable prior\nsurrounding the point annotations. In this paper, we propose a weakly\nsemi-supervised method called Point-Neighborhood Learning (PNL) framework. To\nmine the prior of the pixels surrounding the annotated point, we transform a\nsingle-point annotation into a circular area named a point-neighborhood. We\npropose point-neighborhood supervision loss and pseudo-label scoring mechanism\nto enhance training supervision. Point-neighborhoods are also used to augment\nthe data diversity. Our method greatly improves performance without changing\nthe structure of segmentation network. Comprehensive experiments show the\nsuperiority of our method over the other existing methods, demonstrating its\neffectiveness in point-annotated medical images. The project code will be\navailable on: https://github.com/ParryJay/PNL.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Pengyu Jie",
            "Wanquan Liu",
            "Chenqiang Gao",
            "Yihui Wen",
            "Rui He",
            "Pengcheng Li",
            "Jintao Zhang",
            "Deyu Meng"
        ],
        "published": "2024-05-30T13:25:25Z"
    },
    {
        "title": "CycleFormer : TSP Solver Based on Language Modeling",
        "link": "http://arxiv.org/abs/2405.20042v1",
        "abstract": "We propose a new transformer model for the Traveling Salesman Problem (TSP)\ncalled CycleFormer. We identified distinctive characteristics that need to be\nconsidered when applying a conventional transformer model to TSP and aimed to\nfully incorporate these elements into the TSP-specific transformer. Unlike the\ntoken sets in typical language models, which are limited and static, the token\n(node) set in TSP is unlimited and dynamic. To exploit this fact to the\nfullest, we equated the encoder output with the decoder linear layer and\ndirectly connected the context vector of the encoder to the decoder encoding.\nAdditionally, we added a positional encoding to the encoder tokens that\nreflects the two-dimensional nature of TSP, and devised a circular positional\nencoding for the decoder tokens that considers the cyclic properties of a tour.\nBy incorporating these ideas, CycleFormer outperforms state-of-the-art (SOTA)\ntransformer models for TSP from TSP-50 to TSP-500. Notably, on TSP-500, the\noptimality gap was reduced by approximately 2.8 times, from 3.09% to 1.10%,\ncompared to the existing SOTA. The code will be made available at\nhttps://github.com/Giventicket/CycleFormer.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Jieun Yook",
            "Junpyo Seo",
            "Joon Huh",
            "Han Joon Byun",
            "Byung-ro Mooon"
        ],
        "published": "2024-05-30T13:23:02Z"
    },
    {
        "title": "Task-Agnostic Machine Learning-Assisted Inference",
        "link": "http://arxiv.org/abs/2405.20039v1",
        "abstract": "Machine learning (ML) is playing an increasingly important role in scientific\nresearch. In conjunction with classical statistical approaches, ML-assisted\nanalytical strategies have shown great promise in accelerating research\nfindings. This has also opened up a whole new field of methodological research\nfocusing on integrative approaches that leverage both ML and statistics to\ntackle data science challenges. One type of study that has quickly gained\npopularity employs ML to predict unobserved outcomes in massive samples and\nthen uses the predicted outcomes in downstream statistical inference. However,\nexisting methods designed to ensure the validity of this type of\npost-prediction inference are limited to very basic tasks such as linear\nregression analysis. This is because any extension of these approaches to new,\nmore sophisticated statistical tasks requires task-specific algebraic\nderivations and software implementations, which ignores the massive library of\nexisting software tools already developed for complex inference tasks and\nseverely constrains the scope of post-prediction inference in real\napplications. To address this challenge, we propose a novel statistical\nframework for task-agnostic ML-assisted inference. It provides a\npost-prediction inference solution that can be easily plugged into almost any\nestablished data analysis routine. It delivers valid and efficient inference\nthat is robust to arbitrary choices of ML models, while allowing nearly all\nexisting analytical frameworks to be incorporated into the analysis of\nML-predicted outcomes. Through extensive experiments, we showcase the validity,\nversatility, and superiority of our method compared to existing approaches.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "authors": [
            "Jiacheng Miao",
            "Qiongshi Lu"
        ],
        "published": "2024-05-30T13:19:49Z"
    },
    {
        "title": "Deep Reinforcement Learning for Intrusion Detection in IoT: A Survey",
        "link": "http://dx.doi.org/10.1109/IC2EM59347.2023.10419560",
        "abstract": "The rise of new complex attacks scenarios in Internet of things (IoT)\nenvironments necessitate more advanced and intelligent cyber defense techniques\nsuch as various Intrusion Detection Systems (IDSs) which are responsible for\ndetecting and mitigating malicious activities in IoT networks without human\nintervention. To address this issue, deep reinforcement learning (DRL) has been\nproposed in recent years, to automatically tackle intrusions/attacks. In this\npaper, a comprehensive survey of DRL-based IDS on IoT is presented.\nFurthermore, in this survey, the state-of-the-art DRL-based IDS methods have\nbeen classified into five categories including wireless sensor network (WSN),\ndeep Q-network (DQN), healthcare, hybrid, and other techniques. In addition,\nthe most crucial performance metrics, namely accuracy, recall, precision, false\nnegative rate (FNR), false positive rate (FPR), and F-measure, are detailed, in\norder to evaluate the performance of each proposed method. The paper provides a\nsummary of datasets utilized in the studies as well.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Afrah Gueriani",
            "Hamza Kheddar",
            "Ahmed Cherif Mazari"
        ],
        "published": "2024-05-30T13:19:23Z"
    },
    {
        "title": "Linguistic Landscape of Generative AI Perception: A Global Twitter\n  Analysis Across 14 Languages",
        "link": "http://arxiv.org/abs/2405.20037v1",
        "abstract": "The advent of generative AI tools has had a profound impact on societies\nglobally, transcending geographical boundaries. Understanding these tools'\nglobal reception and utilization is crucial for service providers and\npolicymakers in shaping future policies. Therefore, to unravel the perceptions\nand engagements of individuals within diverse linguistic communities with\nregard to generative AI tools, we extensively analyzed over 6.8 million tweets\nin 14 different languages. Our findings reveal a global trend in the perception\nof generative AI, accompanied by language-specific nuances. While sentiments\ntoward these tools vary significantly across languages, there is a prevalent\npositive inclination toward Image tools and a negative one toward Chat tools.\nNotably, the ban of ChatGPT in Italy led to a sentiment decline and initiated\ndiscussions across languages. Furthermore, we established a taxonomy for\ninteractions with chatbots, creating a framework for social analysis\nunderscoring variations in generative AI usage among linguistic communities. We\nfind that the Chinese community predominantly employs chatbots as substitutes\nfor search, while the Italian community tends to present more intricate\nprompts. Our research provides a robust foundation for further explorations of\nthe social dynamics surrounding generative AI tools and offers invaluable\ninsights for decision-makers in policy, technology, and education.",
        "subjects": [
            "cs.CY"
        ],
        "authors": [
            "Taichi Murayama",
            "Kunihiro Miyazaki",
            "Yasuko Matsubara",
            "Yasushi Sakurai"
        ],
        "published": "2024-05-30T13:19:16Z"
    },
    {
        "title": "Promptus: Can Prompts Streaming Replace Video Streaming with Stable\n  Diffusion",
        "link": "http://arxiv.org/abs/2405.20032v1",
        "abstract": "With the exponential growth of video traffic, traditional video streaming\nsystems are approaching their limits in compression efficiency and\ncommunication capacity. To further reduce bitrate while maintaining quality, we\npropose Promptus, a disruptive novel system that streaming prompts instead of\nvideo content with Stable Diffusion, which converts video frames into a series\nof \"prompts\" for delivery. To ensure pixel alignment, a gradient descent-based\nprompt fitting framework is proposed. To achieve adaptive bitrate for prompts,\na low-rank decomposition-based bitrate control algorithm is introduced. For\ninter-frame compression of prompts, a temporal smoothing-based prompt\ninterpolation algorithm is proposed. Evaluations across various video domains\nand real network traces demonstrate Promptus can enhance the perceptual quality\nby 0.111 and 0.092 (in LPIPS) compared to VAE and H.265, respectively, and\ndecreases the ratio of severely distorted frames by 89.3% and 91.7%. Moreover,\nPromptus achieves real-time video generation from prompts at over 150 FPS. To\nthe best of our knowledge, Promptus is the first attempt to replace video\ncodecs with prompt inversion and the first to use prompt streaming instead of\nvideo streaming. Our work opens up a new paradigm for efficient video\ncommunication beyond the Shannon limit.",
        "subjects": [
            "cs.NI",
            "cs.AI",
            "cs.MM"
        ],
        "authors": [
            "Jiangkai Wu",
            "Liming Liu",
            "Yunpeng Tan",
            "Junlin Hao",
            "Xinggong Zhang"
        ],
        "published": "2024-05-30T13:16:48Z"
    },
    {
        "title": "Structure Gaussian SLAM with Manhattan World Hypothesis",
        "link": "http://arxiv.org/abs/2405.20031v1",
        "abstract": "Gaussian SLAM systems have made significant advancements in improving the\nefficiency and fidelity of real-time reconstructions. However, these systems\noften encounter incomplete reconstructions in complex indoor environments,\ncharacterized by substantial holes due to unobserved geometry caused by\nobstacles or limited view angles. To address this challenge, we present\nManhattan Gaussian SLAM (MG-SLAM), an RGB-D system that leverages the Manhattan\nWorld hypothesis to enhance geometric accuracy and completeness. By seamlessly\nintegrating fused line segments derived from structured scenes, MG-SLAM ensures\nrobust tracking in textureless indoor areas. Moreover, The extracted lines and\nplanar surface assumption allow strategic interpolation of new Gaussians in\nregions of missing geometry, enabling efficient scene completion. Extensive\nexperiments conducted on both synthetic and real-world scenes demonstrate that\nthese advancements enable our method to achieve state-of-the-art performance,\nmarking a substantial improvement in the capabilities of Gaussian SLAM systems.",
        "subjects": [
            "cs.RO",
            "cs.CV"
        ],
        "authors": [
            "Shuhong Liu",
            "Heng Zhou",
            "Liuzhuozheng Li",
            "Yun Liu",
            "Tianchen Deng",
            "Yiming Zhou",
            "Mingrui Li"
        ],
        "published": "2024-05-30T13:16:17Z"
    },
    {
        "title": "EMAG: Ego-motion Aware and Generalizable 2D Hand Forecasting from\n  Egocentric Videos",
        "link": "http://arxiv.org/abs/2405.20030v1",
        "abstract": "Predicting future human behavior from egocentric videos is a challenging but\ncritical task for human intention understanding. Existing methods for\nforecasting 2D hand positions rely on visual representations and mainly focus\non hand-object interactions. In this paper, we investigate the hand forecasting\ntask and tackle two significant issues that persist in the existing methods:\n(1) 2D hand positions in future frames are severely affected by ego-motions in\negocentric videos; (2) prediction based on visual information tends to overfit\nto background or scene textures, posing a challenge for generalization on novel\nscenes or human behaviors. To solve the aforementioned problems, we propose\nEMAG, an ego-motion-aware and generalizable 2D hand forecasting method. In\nresponse to the first problem, we propose a method that considers ego-motion,\nrepresented by a sequence of homography matrices of two consecutive frames. We\nfurther leverage modalities such as optical flow, trajectories of hands and\ninteracting objects, and ego-motions, thereby alleviating the second issue.\nExtensive experiments on two large-scale egocentric video datasets, Ego4D and\nEPIC-Kitchens 55, verify the effectiveness of the proposed method. In\nparticular, our model outperforms prior methods by $7.0$\\% on cross-dataset\nevaluations. Project page: https://masashi-hatano.github.io/EMAG/",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Masashi Hatano",
            "Ryo Hachiuma",
            "Hideo Saito"
        ],
        "published": "2024-05-30T13:15:18Z"
    },
    {
        "title": "A Random Forest-based Prediction Model for Turning Points in\n  Antagonistic event-group Competitions",
        "link": "http://arxiv.org/abs/2405.20029v1",
        "abstract": "At present, most of the prediction studies related to antagonistic\nevent-group competitions focus on the prediction of competition results, and\nless on the prediction of the competition process, which can not provide\nreal-time feedback of the athletes' state information in the actual\ncompetition, and thus can not analyze the changes of the competition situation.\nIn order to solve this problem, this paper proposes a prediction model based on\nRandom Forest for the turning point of the antagonistic event-group. Firstly,\nthe quantitative equation of competitive potential energy is proposed;\nSecondly, the quantitative value of competitive potential energy is obtained by\nusing the dynamic combination of weights method, and the turning point of the\ncompetition situation of the antagonistic event-group is marked according to\nthe quantitative time series graph; Finally, the random forest prediction model\nbased on the optimisation of the KM-SMOTE algorithm and the grid search method\nis established. The experimental analysis shows that: the quantitative equation\nof competitive potential energy can effectively reflect the dynamic situation\nof the competition; The model can effectively predict the turning point of the\ncompetition situation of the antagonistic event-group, and the recall rate of\nthe model in the test set is 86.13%; the model has certain significance for the\nfuture study of the competition situation of the antagonistic event-group.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Zishuo Zhu"
        ],
        "published": "2024-05-30T13:13:48Z"
    },
    {
        "title": "A Simple and Adaptive Learning Rate for FTRL in Online Learning with\n  Minimax Regret of $Θ(T^{2/3})$ and its Application to\n  Best-of-Both-Worlds",
        "link": "http://arxiv.org/abs/2405.20028v1",
        "abstract": "Follow-the-Regularized-Leader (FTRL) is a powerful framework for various\nonline learning problems. By designing its regularizer and learning rate to be\nadaptive to past observations, FTRL is known to work adaptively to various\nproperties of an underlying environment. However, most existing adaptive\nlearning rates are for online learning problems with a minimax regret of\n$\\Theta(\\sqrt{T})$ for the number of rounds $T$, and there are only a few\nstudies on adaptive learning rates for problems with a minimax regret of\n$\\Theta(T^{2/3})$, which include several important problems dealing with\nindirect feedback. To address this limitation, we establish a new adaptive\nlearning rate framework for problems with a minimax regret of\n$\\Theta(T^{2/3})$. Our learning rate is designed by matching the stability,\npenalty, and bias terms that naturally appear in regret upper bounds for\nproblems with a minimax regret of $\\Theta(T^{2/3})$. As applications of this\nframework, we consider two major problems dealing with indirect feedback:\npartial monitoring and graph bandits. We show that FTRL with our learning rate\nand the Tsallis entropy regularizer improves existing Best-of-Both-Worlds\n(BOBW) regret upper bounds, which achieve simultaneous optimality in the\nstochastic and adversarial regimes. The resulting learning rate is surprisingly\nsimple compared to the existing learning rates for BOBW algorithms for problems\nwith a minimax regret of $\\Theta(T^{2/3})$.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Taira Tsuchiya",
            "Shinji Ito"
        ],
        "published": "2024-05-30T13:13:12Z"
    },
    {
        "title": "SEA Cache: A Performance-Efficient Countermeasure for Contention-based\n  Attacks",
        "link": "http://arxiv.org/abs/2405.20027v1",
        "abstract": "Many cache designs have been proposed to guard against contention-based\nside-channel attacks. One well-known type of cache is the randomized remapping\ncache. Many randomized remapping caches provide fixed or over protection, which\nleads to permanent performance degradation, or they provide flexible\nprotection, but sacrifice performance against strong contention-based attacks.\nTo improve the secure cache design, we extend an existing secure cache design,\nCEASER-SH cache, and propose the SEA cache. The novel cache configurations in\nboth caches are logical associativity, which allows the cache line to be placed\nnot only in its mapped cache set but also in the subsequent cache sets. SEA\ncache allows each user or each process to have a different local logical\nassociativity. Hence, only those users or processes that request extra\nprotection against contention-based attacks are protected with high logical\nassociativity. Other users or processes can access the cache with lower latency\nand higher performance. Compared to a CEASER-SH cache with logical\nassociativity of 8, an SEA cache with logical associativity of 1 for normal\nprotection users and 16 for high protection users has a Cycles Per Instruction\npenalty that is about 0.6% less for users under normal protections and provides\nbetter security against contention-based attacks. Based on a 45nm technology\nlibrary, and compared to a conventional cache, we estimate the power overhead\nis about 20% and the area overhead is 3.4%.",
        "subjects": [
            "cs.CR",
            "cs.AR"
        ],
        "authors": [
            "Xiao Liu",
            "Mark Zwolinski",
            "Basel Halak"
        ],
        "published": "2024-05-30T13:12:53Z"
    },
    {
        "title": "The CFG Complexity of Singleton Sets",
        "link": "http://arxiv.org/abs/2405.20026v1",
        "abstract": "Let G be a context-free grammar (CFG) in Chomsky normal form. We take the\nnumber of rules in G to be the size of G. We also assume all CFGs are in\nChomsky normal form.\n  We consider the question of, given a string w of length n, what is the\nsmallest CFG such that L(G)={w}? We show the following:\n  1) For all w, |w|=n, there is a CFG of size with O(n/log n) rules, such that\nL(G)={w}.\n  2) There exists a string w, |w|=n, such that every CFG G with L(G)={w} is of\nsize Omega(n/log n). We give two proofs of: one nonconstructive, the other\nconstructive.",
        "subjects": [
            "cs.FL",
            "F.4"
        ],
        "authors": [
            "Lance Fortnow",
            "William Gasarch"
        ],
        "published": "2024-05-30T13:11:43Z"
    },
    {
        "title": "From Forest to Zoo: Great Ape Behavior Recognition with ChimpBehave",
        "link": "http://arxiv.org/abs/2405.20025v1",
        "abstract": "This paper addresses the significant challenge of recognizing behaviors in\nnon-human primates, specifically focusing on chimpanzees. Automated behavior\nrecognition is crucial for both conservation efforts and the advancement of\nbehavioral research. However, it is significantly hindered by the\nlabor-intensive process of manual video annotation. Despite the availability of\nlarge-scale animal behavior datasets, the effective application of machine\nlearning models across varied environmental settings poses a critical\nchallenge, primarily due to the variability in data collection contexts and the\nspecificity of annotations.\n  In this paper, we introduce ChimpBehave, a novel dataset featuring over 2\nhours of video (approximately 193,000 video frames) of zoo-housed chimpanzees,\nmeticulously annotated with bounding boxes and behavior labels for action\nrecognition. ChimpBehave uniquely aligns its behavior classes with existing\ndatasets, allowing for the study of domain adaptation and cross-dataset\ngeneralization methods between different visual settings. Furthermore, we\nbenchmark our dataset using a state-of-the-art CNN-based action recognition\nmodel, providing the first baseline results for both within and cross-dataset\nsettings. The dataset, models, and code can be accessed at:\nhttps://github.com/MitchFuchs/ChimpBehave",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Michael Fuchs",
            "Emilie Genty",
            "Adrian Bangerter",
            "Klaus Zuberbühler",
            "Paul Cotofrei"
        ],
        "published": "2024-05-30T13:11:08Z"
    },
    {
        "title": "Applications of Generative AI (GAI) for Mobile and Wireless Networking:\n  A Survey",
        "link": "http://arxiv.org/abs/2405.20024v1",
        "abstract": "The success of Artificial Intelligence (AI) in multiple disciplines and\nvertical domains in recent years has promoted the evolution of mobile\nnetworking and the future Internet toward an AI-integrated Internet-of-Things\n(IoT) era. Nevertheless, most AI techniques rely on data generated by physical\ndevices (e.g., mobile devices and network nodes) or specific applications\n(e.g., fitness trackers and mobile gaming). To bypass this circumvent,\nGenerative AI (GAI), a.k.a. AI-generated content (AIGC), has emerged as a\npowerful AI paradigm; thanks to its ability to efficiently learn complex data\ndistributions and generate synthetic data to represent the original data in\nvarious forms. This impressive feature is projected to transform the management\nof mobile networking and diversify the current services and applications\nprovided. On this basis, this work presents a concise tutorial on the role of\nGAIs in mobile and wireless networking. In particular, this survey first\nprovides the fundamentals of GAI and representative GAI models, serving as an\nessential preliminary to the understanding of the applications of GAI in mobile\nand wireless networking. Then, this work provides a comprehensive review of\nstate-of-the-art studies and GAI applications in network management, wireless\nsecurity, semantic communication, and lessons learned from the open literature.\nFinally, this work summarizes the current research on GAI for mobile and\nwireless networking by outlining important challenges that need to be resolved\nto facilitate the development and applicability of GAI in this edge-cutting\narea.",
        "subjects": [
            "cs.NI",
            "cs.AI"
        ],
        "authors": [
            "Thai-Hoc Vu",
            "Senthil Kumar Jagatheesaperumal",
            "Minh-Duong Nguyen",
            "Nguyen Van Huynh",
            "Sunghwan Kim",
            "Quoc-Viet Pham"
        ],
        "published": "2024-05-30T13:06:40Z"
    },
    {
        "title": "About truncated Chebyshev spectral method for solving numerical\n  differentiation and summation",
        "link": "http://arxiv.org/abs/2405.20020v1",
        "abstract": "The problems of optimal recovering univariate functions and their derivatives\nare studied. To solve these problems, two variants of the truncation method are\nconstructed, which are order-optimal both in the sense of accuracy and in terms\nof the amount of involved Galerkin information. For numerical summation, it has\nbeen established how the parameters characterizing the problem being solved\naffect its stability.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "65D25"
        ],
        "authors": [
            "Y. V. Semenova",
            "S. G. Solodky"
        ],
        "published": "2024-05-30T12:59:12Z"
    },
    {
        "title": "Safe Multi-agent Reinforcement Learning with Natural Language\n  Constraints",
        "link": "http://arxiv.org/abs/2405.20018v1",
        "abstract": "The role of natural language constraints in Safe Multi-agent Reinforcement\nLearning (MARL) is crucial, yet often overlooked. While Safe MARL has vast\npotential, especially in fields like robotics and autonomous vehicles, its full\npotential is limited by the need to define constraints in pre-designed\nmathematical terms, which requires extensive domain expertise and reinforcement\nlearning knowledge, hindering its broader adoption. To address this limitation\nand make Safe MARL more accessible and adaptable, we propose a novel approach\nnamed Safe Multi-agent Reinforcement Learning with Natural Language constraints\n(SMALL). Our method leverages fine-tuned language models to interpret and\nprocess free-form textual constraints, converting them into semantic embeddings\nthat capture the essence of prohibited states and behaviours. These embeddings\nare then integrated into the multi-agent policy learning process, enabling\nagents to learn policies that minimize constraint violations while optimizing\nrewards. To evaluate the effectiveness of SMALL, we introduce the LaMaSafe, a\nmulti-task benchmark designed to assess the performance of multiple agents in\nadhering to natural language constraints. Empirical evaluations across various\nenvironments demonstrate that SMALL achieves comparable rewards and\nsignificantly fewer constraint violations, highlighting its effectiveness in\nunderstanding and enforcing natural language constraints.",
        "subjects": [
            "cs.MA",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Ziyan Wang",
            "Meng Fang",
            "Tristan Tomilin",
            "Fei Fang",
            "Yali Du"
        ],
        "published": "2024-05-30T12:57:35Z"
    },
    {
        "title": "Efficient LLM-Jailbreaking by Introducing Visual Modality",
        "link": "http://arxiv.org/abs/2405.20015v1",
        "abstract": "This paper focuses on jailbreaking attacks against large language models\n(LLMs), eliciting them to generate objectionable content in response to harmful\nuser queries. Unlike previous LLM-jailbreaks that directly orient to LLMs, our\napproach begins by constructing a multimodal large language model (MLLM)\nthrough the incorporation of a visual module into the target LLM. Subsequently,\nwe conduct an efficient MLLM-jailbreak to generate jailbreaking embeddings\nembJS. Finally, we convert the embJS into text space to facilitate the\njailbreaking of the target LLM. Compared to direct LLM-jailbreaking, our\napproach is more efficient, as MLLMs are more vulnerable to jailbreaking than\npure LLM. Additionally, to improve the attack success rate (ASR) of\njailbreaking, we propose an image-text semantic matching scheme to identify a\nsuitable initial input. Extensive experiments demonstrate that our approach\nsurpasses current state-of-the-art methods in terms of both efficiency and\neffectiveness. Moreover, our approach exhibits superior cross-class\njailbreaking capabilities.",
        "subjects": [
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Zhenxing Niu",
            "Yuyao Sun",
            "Haodong Ren",
            "Haoxuan Ji",
            "Quan Wang",
            "Xiaoke Ma",
            "Gang Hua",
            "Rong Jin"
        ],
        "published": "2024-05-30T12:50:32Z"
    },
    {
        "title": "subMFL: Compatiple subModel Generation for Federated Learning in Device\n  Heterogenous Environment",
        "link": "http://arxiv.org/abs/2405.20014v1",
        "abstract": "Federated Learning (FL) is commonly used in systems with distributed and\nheterogeneous devices with access to varying amounts of data and diverse\ncomputing and storage capacities. FL training process enables such devices to\nupdate the weights of a shared model locally using their local data and then a\ntrusted central server combines all of those models to generate a global model.\nIn this way, a global model is generated while the data remains local to\ndevices to preserve privacy. However, training large models such as Deep Neural\nNetworks (DNNs) on resource-constrained devices can take a prohibitively long\ntime and consume a large amount of energy. In the current process, the\nlow-capacity devices are excluded from the training process, although they\nmight have access to unseen data. To overcome this challenge, we propose a\nmodel compression approach that enables heterogeneous devices with varying\ncomputing capacities to participate in the FL process. In our approach, the\nserver shares a dense model with all devices to train it: Afterwards, the\ntrained model is gradually compressed to obtain submodels with varying levels\nof sparsity to be used as suitable initial global models for\nresource-constrained devices that were not capable of train the first dense\nmodel. This results in an increased participation rate of resource-constrained\ndevices while the transferred weights from the previous round of training are\npreserved. Our validation experiments show that despite reaching about 50 per\ncent global sparsity, generated submodels maintain their accuracy while can be\nshared to increase participation by around 50 per cent.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Zeyneddin Oz",
            "Ceylan Soygul Oz",
            "Abdollah Malekjafarian",
            "Nima Afraz",
            "Fatemeh Golpayegani"
        ],
        "published": "2024-05-30T12:49:34Z"
    },
    {
        "title": "Repeatable and Reliable Efforts of Accelerated Risk Assessment",
        "link": "http://arxiv.org/abs/2405.20013v1",
        "abstract": "Risk assessment of a robot in controlled environments, such as laboratories\nand proving grounds, is a common means to assess, certify, validate, verify,\nand characterize the robots' safety performance before, during, and even after\ntheir commercialization in the real-world. A standard testing program that\nacquires the risk estimate is expected to be (i) repeatable, such that it\nobtains similar risk assessments of the same testing subject among multiple\ntrials or attempts with the similar testing effort by different stakeholders,\nand (ii) reliable against a variety of testing subjects produced by different\nvendors and manufacturers. Both repeatability and reliability are fundamental\nand crucial for a testing algorithm's validity, fairness, and practical\nfeasibility, especially for standardization. However, these properties are\nrarely satisfied or ensured, especially as the subject robots become more\ncomplex, uncertain, and varied. This issue was present in traditional risk\nassessments through Monte-Carlo sampling, and remains a bottleneck for the\nrecent accelerated risk assessment methods, primarily those using importance\nsampling. This study aims to enhance existing accelerated testing frameworks by\nproposing a new algorithm that provably integrates repeatability and\nreliability with the already established formality and efficiency. It also\nfeatures demonstrations assessing the risk of instability from frontal impacts,\ninitiated by push-over disturbances on a controlled inverted pendulum and a\n7-DoF planar bipedal robot Rabbit managed by various control algorithms.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Linda Capito",
            "Guillermo A. Castillo",
            "Bowen Weng"
        ],
        "published": "2024-05-30T12:49:16Z"
    },
    {
        "title": "FlexiDrop: Theoretical Insights and Practical Advances in Random Dropout\n  Method on GNNs",
        "link": "http://arxiv.org/abs/2405.20012v1",
        "abstract": "Graph Neural Networks (GNNs) are powerful tools for handling graph-type data.\nRecently, GNNs have been widely applied in various domains, but they also face\nsome issues, such as overfitting, over-smoothing and non-robustness. The\nexisting research indicates that random dropout methods are an effective way to\naddress these issues. However, random dropout methods in GNNs still face\nunresolved problems. Currently, the choice of dropout rate, often determined by\nheuristic or grid search methods, can increase the generalization error,\ncontradicting the principal aims of dropout. In this paper, we propose a novel\nrandom dropout method for GNNs called FlexiDrop. First, we conduct a\ntheoretical analysis of dropout in GNNs using rademacher complexity and\ndemonstrate that the generalization error of traditional random dropout methods\nis constrained by a function related to the dropout rate. Subsequently, we use\nthis function as a regularizer to unify the dropout rate and empirical loss\nwithin a single loss function, optimizing them simultaneously. Therefore, our\nmethod enables adaptive adjustment of the dropout rate and theoretically\nbalances the trade-off between model complexity and generalization ability.\nFurthermore, extensive experimental results on benchmark datasets show that\nFlexiDrop outperforms traditional random dropout methods in GNNs.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Zhiheng Zhou",
            "Sihao Liu",
            "Weichen Zhao"
        ],
        "published": "2024-05-30T12:48:44Z"
    },
    {
        "title": "Sharing Key Semantics in Transformer Makes Efficient Image Restoration",
        "link": "http://arxiv.org/abs/2405.20008v1",
        "abstract": "Image Restoration (IR), a classic low-level vision task, has witnessed\nsignificant advancements through deep models that effectively model global\ninformation. Notably, the Vision Transformers (ViTs) emergence has further\npropelled these advancements. When computing, the self-attention mechanism, a\ncornerstone of ViTs, tends to encompass all global cues, even those from\nsemantically unrelated objects or regions. This inclusivity introduces\ncomputational inefficiencies, particularly noticeable with high input\nresolution, as it requires processing irrelevant information, thereby impeding\nefficiency. Additionally, for IR, it is commonly noted that small segments of a\ndegraded image, particularly those closely aligned semantically, provide\nparticularly relevant information to aid in the restoration process, as they\ncontribute essential contextual cues crucial for accurate reconstruction. To\naddress these challenges, we propose boosting IR's performance by sharing the\nkey semantics via Transformer for IR (i.e., SemanIR) in this paper.\nSpecifically, SemanIR initially constructs a sparse yet comprehensive\nkey-semantic dictionary within each transformer stage by establishing essential\nsemantic connections for every degraded patch. Subsequently, this dictionary is\nshared across all subsequent transformer blocks within the same stage. This\nstrategy optimizes attention calculation within each block by focusing\nexclusively on semantically related components stored in the key-semantic\ndictionary. As a result, attention calculation achieves linear computational\ncomplexity within each window. Extensive experiments across 6 IR tasks confirm\nthe proposed SemanIR's state-of-the-art performance, quantitatively and\nqualitatively showcasing advancements.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Bin Ren",
            "Yawei Li",
            "Jingyun Liang",
            "Rakesh Ranjan",
            "Mengyuan Liu",
            "Rita Cucchiara",
            "Luc Van Gool",
            "Ming-Hsuan Yang",
            "Nicu Sebe"
        ],
        "published": "2024-05-30T12:45:34Z"
    },
    {
        "title": "SWIFT: A Monotonic, Flux-Form Semi-Lagrangian Tracer Transport Scheme\n  for Flow with Large Courant Numbers",
        "link": "http://arxiv.org/abs/2405.20006v1",
        "abstract": "Local conservation of mass and entropy are becoming increasingly desirable\nproperties for modern numerical weather and climate models. This work presents\na Flux-Form Semi-Lagrangian (FFSL) transport scheme, called SWIFT, that\nfacilitates this conservation for tracer variables, whilst maintaining other\nvital properties such as preservation of a constant, monotonicity and\npositivity. Importantly, these properties all hold for large Courant numbers\nand multi-dimensional flow, making the scheme appropriate for use within a\ndynamical core which takes large time steps.\n  The SWIFT scheme presented here can be seen as an evolution of the FFSL\nmethods of Leonard et al and Lin and Rood. Two-dimensional and\nthree-dimensional schemes consist of a splitting into a sequence of\none-dimensional calculations. The new SWIFT splitting presented here allows\nmonotonic and positivity properties from the one-dimensional calculations to be\ninherited by the multi-dimensional scheme. These one-dimensional calculations\ninvolve separating the mass flux into terms that correspond to integer and\nfractional parts of the Courant number. Key to achieving conservation is\ncoupling the transport of tracers to the transport of the fluid density,\nthrough re-use of the discrete mass flux that was calculated from the fluid\ndensity in the transport of the tracers. This work also describes how these\nproperties can still be attained when the tracer is vertically-staggered from\nthe density in a Charney-Phillips grid.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "physics.ao-ph",
            "physics.flu-dyn"
        ],
        "authors": [
            "Thomas M. Bendall",
            "James Kent"
        ],
        "published": "2024-05-30T12:43:10Z"
    },
    {
        "title": "Kernel Language Entropy: Fine-grained Uncertainty Quantification for\n  LLMs from Semantic Similarities",
        "link": "http://arxiv.org/abs/2405.20003v1",
        "abstract": "Uncertainty quantification in Large Language Models (LLMs) is crucial for\napplications where safety and reliability are important. In particular,\nuncertainty can be used to improve the trustworthiness of LLMs by detecting\nfactually incorrect model responses, commonly called hallucinations.\nCritically, one should seek to capture the model's semantic uncertainty, i.e.,\nthe uncertainty over the meanings of LLM outputs, rather than uncertainty over\nlexical or syntactic variations that do not affect answer correctness. To\naddress this problem, we propose Kernel Language Entropy (KLE), a novel method\nfor uncertainty estimation in white- and black-box LLMs. KLE defines positive\nsemidefinite unit trace kernels to encode the semantic similarities of LLM\noutputs and quantifies uncertainty using the von Neumann entropy. It considers\npairwise semantic dependencies between answers (or semantic clusters),\nproviding more fine-grained uncertainty estimates than previous methods based\non hard clustering of answers. We theoretically prove that KLE generalizes the\nprevious state-of-the-art method called semantic entropy and empirically\ndemonstrate that it improves uncertainty quantification performance across\nmultiple natural language generation datasets and LLM architectures.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Alexander Nikitin",
            "Jannik Kossen",
            "Yarin Gal",
            "Pekka Marttinen"
        ],
        "published": "2024-05-30T12:42:05Z"
    },
    {
        "title": "Combining physics-informed graph neural network and finite difference\n  for solving forward and inverse spatiotemporal PDEs",
        "link": "http://arxiv.org/abs/2405.20000v1",
        "abstract": "The great success of Physics-Informed Neural Networks (PINN) in solving\npartial differential equations (PDEs) has significantly advanced our simulation\nand understanding of complex physical systems in science and engineering.\nHowever, many PINN-like methods are poorly scalable and are limited to\nin-sample scenarios. To address these challenges, this work proposes a novel\ndiscrete approach termed Physics-Informed Graph Neural Network (PIGNN) to solve\nforward and inverse nonlinear PDEs. In particular, our approach seamlessly\nintegrates the strength of graph neural networks (GNN), physical equations and\nfinite difference to approximate solutions of physical systems. Our approach is\ncompared with the PINN baseline on three well-known nonlinear PDEs (heat,\nBurgers and FitzHugh-Nagumo). We demonstrate the excellent performance of the\nproposed method to work with irregular meshes, longer time steps, arbitrary\nspatial resolutions, varying initial conditions (ICs) and boundary conditions\n(BCs) by conducting extensive numerical experiments. Numerical results also\nillustrate the superiority of our approach in terms of accuracy, time\nextrapolability, generalizability and scalability. The main advantage of our\napproach is that models trained in small domains with simple settings have\nexcellent fitting capabilities and can be directly applied to more complex\nsituations in large domains.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Hao Zhang",
            "Longxiang Jiang",
            "Xinkun Chu",
            "Yong Wen",
            "Luxiong Li",
            "Yonghao Xiao",
            "Liyuan Wang"
        ],
        "published": "2024-05-30T12:39:38Z"
    },
    {
        "title": "LAGMA: LAtent Goal-guided Multi-Agent Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.19998v1",
        "abstract": "In cooperative multi-agent reinforcement learning (MARL), agents collaborate\nto achieve common goals, such as defeating enemies and scoring a goal. However,\nlearning goal-reaching paths toward such a semantic goal takes a considerable\namount of time in complex tasks and the trained model often fails to find such\npaths. To address this, we present LAtent Goal-guided Multi-Agent reinforcement\nlearning (LAGMA), which generates a goal-reaching trajectory in latent space\nand provides a latent goal-guided incentive to transitions toward this\nreference trajectory. LAGMA consists of three major components: (a) quantized\nlatent space constructed via a modified VQ-VAE for efficient sample\nutilization, (b) goal-reaching trajectory generation via extended VQ codebook,\nand (c) latent goal-guided intrinsic reward generation to encourage transitions\ntowards the sampled goal-reaching path. The proposed method is evaluated by\nStarCraft II with both dense and sparse reward settings and Google Research\nFootball. Empirical results show further performance improvement over\nstate-of-the-art baselines.",
        "subjects": [
            "cs.MA"
        ],
        "authors": [
            "Hyungho Na",
            "Il-chul Moon"
        ],
        "published": "2024-05-30T12:34:58Z"
    },
    {
        "title": "DP-IQA: Utilizing Diffusion Prior for Blind Image Quality Assessment in\n  the Wild",
        "link": "http://arxiv.org/abs/2405.19996v1",
        "abstract": "Image quality assessment (IQA) plays a critical role in selecting\nhigh-quality images and guiding compression and enhancement methods in a series\nof applications. The blind IQA, which assesses the quality of in-the-wild\nimages containing complex authentic distortions without reference images, poses\ngreater challenges. Existing methods are limited to modeling a uniform\ndistribution with local patches and are bothered by the gap between low and\nhigh-level visions (caused by widely adopted pre-trained classification\nnetworks). In this paper, we propose a novel IQA method called diffusion\npriors-based IQA (DP-IQA), which leverages the prior knowledge from the\npre-trained diffusion model with its excellent powers to bridge semantic gaps\nin the perception of the visual quality of images. Specifically, we use\npre-trained stable diffusion as the backbone, extract multi-level features from\nthe denoising U-Net during the upsampling process at a specified timestep, and\ndecode them to estimate the image quality score. The text and image adapters\nare adopted to mitigate the domain gap for downstream tasks and correct the\ninformation loss caused by the variational autoencoder bottleneck. Finally, we\ndistill the knowledge in the above model into a CNN-based student model,\nsignificantly reducing the parameter to enhance applicability, with the student\nmodel performing similarly or even better than the teacher model surprisingly.\nExperimental results demonstrate that our DP-IQA achieves state-of-the-art\nresults on various in-the-wild datasets with better generalization capability,\nwhich shows the superiority of our method in global modeling and utilizing the\nhierarchical feature clues of diffusion for evaluating image quality.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Honghao Fu",
            "Yufei Wang",
            "Wenhan Yang",
            "Bihan Wen"
        ],
        "published": "2024-05-30T12:32:35Z"
    },
    {
        "title": "Symmetries in Overparametrized Neural Networks: A Mean-Field View",
        "link": "http://arxiv.org/abs/2405.19995v1",
        "abstract": "We develop a Mean-Field (MF) view of the learning dynamics of\noverparametrized Artificial Neural Networks (NN) under data symmetric in law\nwrt the action of a general compact group $G$. We consider for this a class of\ngeneralized shallow NNs given by an ensemble of $N$ multi-layer units, jointly\ntrained using stochastic gradient descent (SGD) and possibly\nsymmetry-leveraging (SL) techniques, such as Data Augmentation (DA), Feature\nAveraging (FA) or Equivariant Architectures (EA). We introduce the notions of\nweakly and strongly invariant laws (WI and SI) on the parameter space of each\nsingle unit, corresponding, respectively, to $G$-invariant distributions, and\nto distributions supported on parameters fixed by the group action (which\nencode EA). This allows us to define symmetric models compatible with taking\n$N\\to\\infty$ and give an interpretation of the asymptotic dynamics of DA, FA\nand EA in terms of Wasserstein Gradient Flows describing their MF limits. When\nactivations respect the group action, we show that, for symmetric data, DA, FA\nand freely-trained models obey the exact same MF dynamic, which stays in the\nspace of WI laws and minimizes therein the population risk. We also give a\ncounterexample to the general attainability of an optimum over SI laws. Despite\nthis, quite remarkably, we show that the set of SI laws is also preserved by\nthe MF dynamics even when freely trained. This sharply contrasts the finite-$N$\nsetting, in which EAs are generally not preserved by unconstrained SGD. We\nillustrate the validity of our findings as $N$ gets larger in a teacher-student\nexperimental setting, training a student NN to learn from a WI, SI or arbitrary\nteacher model through various SL schemes. We last deduce a data-driven\nheuristic to discover the largest subspace of parameters supporting SI\ndistributions for a problem, that could be used for designing EA with minimal\ngeneralization error.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "math.PR"
        ],
        "authors": [
            "Javier Maass Martínez",
            "Joaquin Fontbona"
        ],
        "published": "2024-05-30T12:32:18Z"
    },
    {
        "title": "High-order parallel-in-time method for the monodomain equation in\n  cardiac electrophysiology",
        "link": "http://arxiv.org/abs/2405.19994v1",
        "abstract": "Simulation of the monodomain equation, crucial for modeling the heart's\nelectrical activity, faces scalability limits when traditional numerical\nmethods only parallelize in space. To optimize the use of large multi-processor\ncomputers by distributing the computational load more effectively, time\nparallelization is essential. We introduce a high-order parallel-in-time method\naddressing the substantial computational challenges posed by the stiff,\nmultiscale, and nonlinear nature of cardiac dynamics. Our method combines the\nsemi-implicit and exponential spectral deferred correction methods, yielding a\nhybrid method that is extended to parallel-in-time employing the PFASST\nframework. We thoroughly evaluate the stability, accuracy, and robustness of\nthe proposed parallel-in-time method through extensive numerical experiments,\nusing practical ionic models such as the ten-Tusscher-Panfilov. The results\nunderscore the method's potential to significantly enhance real-time and\nhigh-fidelity simulations in biomedical research and clinical applications.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "65L04, 65L10, 65L20, 65Y05"
        ],
        "authors": [
            "Giacomo Rosilho de Souza",
            "Simone Pezzuto",
            "Rolf Krause"
        ],
        "published": "2024-05-30T12:27:31Z"
    },
    {
        "title": "OpenTM: An Open-source, Single-GPU, Large-scale Thermal Microstructure\n  Design Framework",
        "link": "http://arxiv.org/abs/2405.19991v1",
        "abstract": "Thermal microstructures are artificially engineered materials designed to\nmanipulate and control heat flow in unconventional ways. This paper presents an\neducational framework, called \\emph{OpenTM}, to use a single GPU for designing\nperiodic 3D high-resolution thermal microstructures to match the predefined\nthermal conductivity matrices with volume fraction constraints. Specifically,\nwe use adaptive volume fraction to make the Optimality Criteria (OC) method run\nstably to obtain the thermal microstructures without a large memory\noverhead.Practical examples with a high resolution $128 \\times 128 \\times 128$\nrun under 90 seconds per structure on an NVIDIA GeForce GTX 4070Ti GPU with a\npeak GPU memory of 355 MB. Our open-source, high-performance implementation is\npublicly accessible at \\url{https://github.com/quanyuchen2000/OPENTM}, and it\nis easy to install using Anaconda. Moreover, we provide a Python interface to\nmake OpenTM well-suited for novices in C/C++.",
        "subjects": [
            "cs.CE",
            "math.OC"
        ],
        "authors": [
            "Yuchen Quan",
            "Xiaoya Zhai",
            "Xiao-Ming Fu"
        ],
        "published": "2024-05-30T12:24:03Z"
    },
    {
        "title": "DiffPhysBA: Diffusion-based Physical Backdoor Attack against Person\n  Re-Identification in Real-World",
        "link": "http://arxiv.org/abs/2405.19990v1",
        "abstract": "Person Re-Identification (ReID) systems pose a significant security risk from\nbackdoor attacks, allowing adversaries to evade tracking or impersonate others.\nBeyond recognizing this issue, we investigate how backdoor attacks can be\ndeployed in real-world scenarios, where a ReID model is typically trained on\ndata collected in the digital domain and then deployed in a physical\nenvironment. This attack scenario requires an attack flow that embeds backdoor\ntriggers in the digital domain realistically enough to also activate the buried\nbackdoor in person ReID models in the physical domain. This paper realizes this\nattack flow by leveraging a diffusion model to generate realistic accessories\non pedestrian images (e.g., bags, hats, etc.) as backdoor triggers. However,\nthe noticeable domain gap between the triggers generated by the off-the-shelf\ndiffusion model and their physical counterparts results in a low attack success\nrate. Therefore, we introduce a novel diffusion-based physical backdoor attack\n(DiffPhysBA) method that adopts a training-free similarity-guided sampling\nprocess to enhance the resemblance between generated and physical triggers.\nConsequently, DiffPhysBA can generate realistic attributes as semantic-level\ntriggers in the digital domain and provides higher physical ASR compared to the\ndirect paste method by 25.6% on the real-world test set. Through evaluations on\nnewly proposed real-world and synthetic ReID test sets, DiffPhysBA demonstrates\nan impressive success rate exceeding 90% in both the digital and physical\ndomains. Notably, it excels in digital stealth metrics and can effectively\nevade state-of-the-art defense methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Wenli Sun",
            "Xinyang Jiang",
            "Dongsheng Li",
            "Cairong Zhao"
        ],
        "published": "2024-05-30T12:22:06Z"
    },
    {
        "title": "Video-Language Critic: Transferable Reward Functions for\n  Language-Conditioned Robotics",
        "link": "http://arxiv.org/abs/2405.19988v1",
        "abstract": "Natural language is often the easiest and most convenient modality for humans\nto specify tasks for robots. However, learning to ground language to behavior\ntypically requires impractical amounts of diverse, language-annotated\ndemonstrations collected on each target robot. In this work, we aim to separate\nthe problem of what to accomplish from how to accomplish it, as the former can\nbenefit from substantial amounts of external observation-only data, and only\nthe latter depends on a specific robot embodiment. To this end, we propose\nVideo-Language Critic, a reward model that can be trained on readily available\ncross-embodiment data using contrastive learning and a temporal ranking\nobjective, and use it to score behavior traces from a separate reinforcement\nlearning actor. When trained on Open X-Embodiment data, our reward model\nenables 2x more sample-efficient policy training on Meta-World tasks than a\nsparse reward only, despite a significant domain gap. Using in-domain data but\nin a challenging task generalization setting on Meta-World, we further\ndemonstrate more sample-efficient training than is possible with prior\nlanguage-conditioned reward models that are either trained with binary\nclassification, use static images, or do not leverage the temporal information\npresent in video data.",
        "subjects": [
            "cs.RO",
            "cs.AI",
            "cs.CL",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Minttu Alakuijala",
            "Reginald McLean",
            "Isaac Woungang",
            "Nariman Farsad",
            "Samuel Kaski",
            "Pekka Marttinen",
            "Kai Yuan"
        ],
        "published": "2024-05-30T12:18:06Z"
    },
    {
        "title": "Targeted Sequential Indirect Experiment Design",
        "link": "http://arxiv.org/abs/2405.19985v1",
        "abstract": "Scientific hypotheses typically concern specific aspects of complex,\nimperfectly understood or entirely unknown mechanisms, such as the effect of\ngene expression levels on phenotypes or how microbial communities influence\nenvironmental health. Such queries are inherently causal (rather than purely\nassociational), but in many settings, experiments can not be conducted directly\non the target variables of interest, but are indirect. Therefore, they perturb\nthe target variable, but do not remove potential confounding factors. If,\nadditionally, the resulting experimental measurements are multi-dimensional and\nthe studied mechanisms nonlinear, the query of interest is generally not\nidentified. We develop an adaptive strategy to design indirect experiments that\noptimally inform a targeted query about the ground truth mechanism in terms of\nsequentially narrowing the gap between an upper and lower bound on the query.\nWhile the general formulation consists of a bi-level optimization procedure, we\nderive an efficiently estimable analytical kernel-based estimator of the bounds\nfor the causal effect, a query of key interest, and demonstrate the efficacy of\nour approach in confounded, multivariate, nonlinear synthetic settings.",
        "subjects": [
            "stat.ME",
            "cs.LG"
        ],
        "authors": [
            "Elisabeth Ailer",
            "Niclas Dern",
            "Jason Hartford",
            "Niki Kilbertus"
        ],
        "published": "2024-05-30T12:14:25Z"
    },
    {
        "title": "A Deep Reinforcement Learning Approach for Trading Optimization in the\n  Forex Market with Multi-Agent Asynchronous Distribution",
        "link": "http://arxiv.org/abs/2405.19982v1",
        "abstract": "In today's forex market traders increasingly turn to algorithmic trading,\nleveraging computers to seek more profits. Deep learning techniques as\ncutting-edge advancements in machine learning, capable of identifying patterns\nin financial data. Traders utilize these patterns to execute more effective\ntrades, adhering to algorithmic trading rules. Deep reinforcement learning\nmethods (DRL), by directly executing trades based on identified patterns and\nassessing their profitability, offer advantages over traditional DL approaches.\nThis research pioneers the application of a multi-agent (MA) RL framework with\nthe state-of-the-art Asynchronous Advantage Actor-Critic (A3C) algorithm. The\nproposed method employs parallel learning across multiple asynchronous workers,\neach specialized in trading across multiple currency pairs to explore the\npotential for nuanced strategies tailored to different market conditions and\ncurrency pairs. Two different A3C with lock and without lock MA model was\nproposed and trained on single currency and multi-currency. The results\nindicate that both model outperform on Proximal Policy Optimization model. A3C\nwith lock outperforms other in single currency training scenario and A3C\nwithout Lock outperforms other in multi-currency scenario. The findings\ndemonstrate that this approach facilitates broader and faster exploration of\ndifferent currency pairs, significantly enhancing trading returns.\nAdditionally, the agent can learn a more profitable trading strategy in a\nshorter time.",
        "subjects": [
            "cs.CE",
            "cs.AI",
            "cs.CC"
        ],
        "authors": [
            "Davoud Sarani",
            "Dr. Parviz Rashidi-Khazaee"
        ],
        "published": "2024-05-30T12:07:08Z"
    },
    {
        "title": "Domain Adaptation with Cauchy-Schwarz Divergence",
        "link": "http://arxiv.org/abs/2405.19978v1",
        "abstract": "Domain adaptation aims to use training data from one or multiple source\ndomains to learn a hypothesis that can be generalized to a different, but\nrelated, target domain. As such, having a reliable measure for evaluating the\ndiscrepancy of both marginal and conditional distributions is crucial. We\nintroduce Cauchy-Schwarz (CS) divergence to the problem of unsupervised domain\nadaptation (UDA). The CS divergence offers a theoretically tighter\ngeneralization error bound than the popular Kullback-Leibler divergence. This\nholds for the general case of supervised learning, including multi-class\nclassification and regression. Furthermore, we illustrate that the CS\ndivergence enables a simple estimator on the discrepancy of both marginal and\nconditional distributions between source and target domains in the\nrepresentation space, without requiring any distributional assumptions. We\nprovide multiple examples to illustrate how the CS divergence can be\nconveniently used in both distance metric- or adversarial training-based UDA\nframeworks, resulting in compelling performance.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Wenzhe Yin",
            "Shujian Yu",
            "Yicong Lin",
            "Jie Liu",
            "Jan-Jakob Sonke",
            "Efstratios Gavves"
        ],
        "published": "2024-05-30T12:01:12Z"
    },
    {
        "title": "Consistent Submodular Maximization",
        "link": "http://arxiv.org/abs/2405.19977v1",
        "abstract": "Maximizing monotone submodular functions under cardinality constraints is a\nclassic optimization task with several applications in data mining and machine\nlearning. In this paper we study this problem in a dynamic environment with\nconsistency constraints: elements arrive in a streaming fashion and the goal is\nmaintaining a constant approximation to the optimal solution while having a\nstable solution (i.e., the number of changes between two consecutive solutions\nis bounded). We provide algorithms in this setting with different trade-offs\nbetween consistency and approximation quality. We also complement our\ntheoretical results with an experimental analysis showing the effectiveness of\nour algorithms in real-world instances.",
        "subjects": [
            "cs.DS",
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Paul Dütting",
            "Federico Fusco",
            "Silvio Lattanzi",
            "Ashkan Norouzi-Fard",
            "Morteza Zadimoghaddam"
        ],
        "published": "2024-05-30T11:59:58Z"
    },
    {
        "title": "Testing in the Evolving World of DL Systems:Insights from Python GitHub\n  Projects",
        "link": "http://arxiv.org/abs/2405.19976v1",
        "abstract": "In the ever-evolving field of Deep Learning (DL), ensuring project quality\nand reliability remains a crucial challenge. This research investigates testing\npractices within DL projects in GitHub. It quantifies the adoption of testing\nmethodologies, focusing on aspects like test automation, the types of tests\n(e.g., unit, integration, and system), test suite growth rate, and evolution of\ntesting practices across different project versions. We analyze a subset of 300\ncarefully selected repositories based on quantitative and qualitative criteria.\nThis study reports insights on the prevalence of testing practices in DL\nprojects within the open-source community.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Qurban Ali",
            "Oliviero Riganelli",
            "Leonardo Mariani"
        ],
        "published": "2024-05-30T11:58:05Z"
    },
    {
        "title": "A Triumvirate of AI Driven Theoretical Discovery",
        "link": "http://arxiv.org/abs/2405.19973v1",
        "abstract": "Recent years have seen the dramatic rise of the usage of AI algorithms in\npure mathematics and fundamental sciences such as theoretical physics. This is\nperhaps counter-intuitive since mathematical sciences require the rigorous\ndefinitions, derivations, and proofs, in contrast to the experimental sciences\nwhich rely on the modelling of data with error-bars. In this Perspective, we\ncategorize the approaches to mathematical discovery as \"top-down\", \"bottom-up\"\nand \"meta-mathematics\", as inspired by historical examples. We review some of\nthe progress over the last few years, comparing and contrasting both the\nadvances and the short-comings in each approach. We argue that while the\ntheorist is in no way in danger of being replaced by AI in the near future, the\nhybrid of human expertise and AI algorithms will become an integral part of\ntheoretical discovery.",
        "subjects": [
            "math.HO",
            "cs.AI",
            "hep-th",
            "physics.hist-ph"
        ],
        "authors": [
            "Yang-Hui He"
        ],
        "published": "2024-05-30T11:57:00Z"
    },
    {
        "title": "GasTrace: Detecting Sandwich Attack Malicious Accounts in Ethereum",
        "link": "http://arxiv.org/abs/2405.19971v1",
        "abstract": "The openness and transparency of Ethereum transaction data make it easy to be\nexploited by any entities, executing malicious attacks. The sandwich attack\nmanipulates the Automated Market Maker (AMM) mechanism, profiting from\nmanipulating the market price through front or after-running transactions. To\nidentify and prevent sandwich attacks, we propose a cascade classification\nframework GasTrace. GasTrace analyzes various transaction features to detect\nmalicious accounts, notably through the analysis and modeling of Gas features.\nIn the initial classification, we utilize the Support Vector Machine (SVM) with\nthe Radial Basis Function (RBF) kernel to generate the predicted probabilities\nof accounts, further constructing a detailed transaction network. Subsequently,\nthe behavior features are captured by the Graph Attention Network (GAT)\ntechnique in the second classification. Through cascade classification,\nGasTrace can analyze and classify the sandwich attacks. Our experimental\nresults demonstrate that GasTrace achieves a remarkable detection and\ngeneration capability, performing an accuracy of 96.73\\% and an F1 score of\n95.71\\% for identifying sandwich attack accounts.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "authors": [
            "Zekai Liu",
            "Xiaoqi Li",
            "Hongli Peng",
            "Wenkai Li"
        ],
        "published": "2024-05-30T11:55:21Z"
    },
    {
        "title": "Strategies to Counter Artificial Intelligence in Law Enforcement:\n  Cross-Country Comparison of Citizens in Greece, Italy and Spain",
        "link": "http://arxiv.org/abs/2405.19970v1",
        "abstract": "This paper investigates citizens' counter-strategies to the use of Artificial\nIntelligence (AI) by law enforcement agencies (LEAs). Based on information from\nthree countries (Greece, Italy and Spain) we demonstrate disparities in the\nlikelihood of ten specific counter-strategies. We further identified factors\nthat increase the propensity for counter-strategies. Our study provides an\nimportant new perspective to societal impacts of security-focused AI\napplications by illustrating the conscious, strategic choices by citizens when\nconfronted with AI capabilities for LEAs.",
        "subjects": [
            "cs.AI",
            "I.2.0; K.4.1"
        ],
        "authors": [
            "Petra Saskia Bayerl",
            "Babak Akhgar",
            "Ernesto La Mattina",
            "Barbara Pirillo",
            "Ioana Cotoi",
            "Davide Ariu",
            "Matteo Mauri",
            "Jorge Garcia",
            "Dimitris Kavallieros",
            "Antonia Kardara",
            "Konstantina Karagiorgou"
        ],
        "published": "2024-05-30T11:55:10Z"
    },
    {
        "title": "Stable semi-implicit SDC methods for conservation laws",
        "link": "http://arxiv.org/abs/2405.19969v1",
        "abstract": "Semi-implicit spectral deferred correction (SDC) methods provide a systematic\napproach to construct time integration methods of arbitrarily high order for\nnonlinear evolution equations including conservation laws. They converge\ntowards $A$- or even $L$-stable collocation methods, but are often not\nsufficiently robust themselves. In this paper, a family of SDC methods inspired\nby an implicit formulation of the Lax-Wendroff method is developed. Compared to\nfully implicit approaches, the methods have the advantage that they only\nrequire the solution of positive definite or semi-definite linear systems.\nNumerical evidence suggests that the proposed semi-implicit SDC methods with\nRadau points are $L$-stable up to order 11 and require very little diffusion\nfor orders 13 and 15. The excellent stability and accuracy of these methods is\nconfirmed by numerical experiments with 1D conservation problems, including the\nconvection-diffusion, Burgers, Euler and Navier-Stokes equations.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Joerg Stiller"
        ],
        "published": "2024-05-30T11:50:03Z"
    },
    {
        "title": "A Dynamic Logic for Information Evaluation in Intelligence",
        "link": "http://arxiv.org/abs/2405.19968v1",
        "abstract": "In the field of human intelligence, officers use an alphanumeric scale, known\nas the Admiralty System, to rate the credibility of messages and the\nreliability of their sources (NATO AJP-2.1, 2016). During this evaluation, they\nare expected to estimate the credibility and reliability dimensions\nindependently of each other (NATO STANAG, 2003). However, empirical results\nshow that officers perceive these dimensions as strongly correlated (Baker et\nal., 1968). More precisely, they consider credibility as playing the leading\nrole over reliability, the importance of which is only secondary (Samet, 1975).\nIn this paper, we present a formal evaluative procedure, called L(intel), in\nline with these findings. We adapt dynamic belief revision to make credibility\nthe main dimension of evaluation and introduce dynamic operators to update\ncredibility ratings with the source's reliability. In addition to being\nempirically sound, we show that L(intel) provides an effective procedure to\nclassify intelligence messages along the descriptive taxonomy presented in\nIcard (2023).",
        "subjects": [
            "cs.LO"
        ],
        "authors": [
            "Benjamin Icard"
        ],
        "published": "2024-05-30T11:48:32Z"
    },
    {
        "title": "Improved Out-of-Scope Intent Classification with Dual Encoding and\n  Threshold-based Re-Classification",
        "link": "http://arxiv.org/abs/2405.19967v1",
        "abstract": "Detecting out-of-scope user utterances is essential for task-oriented\ndialogues and intent classification. Current methodologies face difficulties\nwith the unpredictable distribution of outliers and often rely on assumptions\nabout data distributions. We present the Dual Encoder for Threshold-Based\nRe-Classification (DETER) to address these challenges. This end-to-end\nframework efficiently detects out-of-scope intents without requiring\nassumptions on data distributions or additional post-processing steps. The core\nof DETER utilizes dual text encoders, the Universal Sentence Encoder (USE) and\nthe Transformer-based Denoising AutoEncoder (TSDAE), to generate user utterance\nembeddings, which are classified through a branched neural architecture.\nFurther, DETER generates synthetic outliers using self-supervision and\nincorporates out-of-scope phrases from open-domain datasets. This approach\nensures a comprehensive training set for out-of-scope detection. Additionally,\na threshold-based re-classification mechanism refines the model's initial\npredictions. Evaluations on the CLINC-150, Stackoverflow, and Banking77\ndatasets demonstrate DETER's efficacy. Our model outperforms previous\nbenchmarks, increasing up to 13% and 5% in F1 score for known and unknown\nintents on CLINC-150 and Stackoverflow, and 16% for known and 24% % for unknown\nintents on Banking77. The source code has been released at\nhttps://github.com/Hossam-Mohammed-tech/Intent\\_Classification\\_OOS.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Hossam M. Zawbaa",
            "Wael Rashwan",
            "Sourav Dutta",
            "Haytham Assem"
        ],
        "published": "2024-05-30T11:46:42Z"
    },
    {
        "title": "Several classes of BCH codes of length $n=\\frac{q^{m}-1}{2}$",
        "link": "http://arxiv.org/abs/2405.19965v1",
        "abstract": "BCH codes are an important class of cyclic codes, and have wide applications\nin communication and storage systems. In this paper, we study the negacyclic\nBCH code and cyclic BCH code of length $n=\\frac{q^m-1}{2}$.For negacyclic BCH\ncode, we give the dimensions of $\\mathcal C_{(n,-1,\\delta,0)}$ for\n$\\widetilde{\\delta} =a\\frac{q^m-1}{q-1},aq^{m-1}-1$($1\\leq a <\\frac{q-1}{2}$)\nand $\\widetilde{\\delta}\n=a\\frac{q^m-1}{q-1}+b\\frac{q^m-1}{q^2-1},aq^{m-1}+(a+b)q^{m-2}-1$ $(2\\mid\nm,1\\leq a+b \\leq q-1$,$\\left\\lceil \\frac{q-a-2}{2}\\right\\rceil\\geq 1)$. The\ndimensions of negacyclic BCH codes $\\mathcal C_{(n,-1,\\delta,0)}$ with few\nnonzeros and $\\mathcal C_{(n,-1,\\delta,b)}$ with $b\\neq 1$ are settled.For\ncyclic BCH code, we give the weight distributions of extended codes\n$\\overline{\\mathcal C}_{(n,1,\\delta,1)}$ for $\\delta=\\delta_1,\\delta_2$ and the\nparameters of dual code $\\mathcal C^{\\perp}_{(n,1,\\delta,1)}$ for $\\delta_2\\leq\n\\delta \\leq \\delta_1$.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Mengchen Lian"
        ],
        "published": "2024-05-30T11:43:42Z"
    },
    {
        "title": "Collective Variable Free Transition Path Sampling with Generative Flow\n  Network",
        "link": "http://arxiv.org/abs/2405.19961v1",
        "abstract": "Understanding transition paths between meta-stable states in molecular\nsystems is fundamental for material design and drug discovery. However,\nsampling these paths via molecular dynamics simulations is computationally\nprohibitive due to the high-energy barriers between the meta-stable states.\nRecent machine learning approaches are often restricted to simple systems or\nrely on collective variables (CVs) extracted from expensive domain knowledge.\nIn this work, we propose to leverage generative flow networks (GFlowNets) to\nsample transition paths without relying on CVs. We reformulate the problem as\namortized energy-based sampling over molecular trajectories and train a bias\npotential by minimizing the squared log-ratio between the target distribution\nand the generator, derived from the flow matching objective of GFlowNets. Our\nevaluation on three proteins (Alanine Dipeptide, Polyproline, and Chignolin)\ndemonstrates that our approach, called TPS-GFN, generates more realistic and\ndiverse transition paths than the previous CV-free machine learning approach.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Kiyoung Seong",
            "Seonghyun Park",
            "Seonghwan Kim",
            "Woo Youn Kim",
            "Sungsoo Ahn"
        ],
        "published": "2024-05-30T11:32:42Z"
    },
    {
        "title": "Multi-Aspect Controllable Text Generation with Disentangled\n  Counterfactual Augmentation",
        "link": "http://arxiv.org/abs/2405.19958v1",
        "abstract": "Multi-aspect controllable text generation aims to control the generated texts\nin attributes from multiple aspects (e.g., \"positive\" from sentiment and\n\"sport\" from topic). For ease of obtaining training samples, existing works\nneglect attribute correlations formed by the intertwining of different\nattributes. Particularly, the stereotype formed by imbalanced attribute\ncorrelations significantly affects multi-aspect control. In this paper, we\npropose MAGIC, a new multi-aspect controllable text generation method with\ndisentangled counterfactual augmentation. We alleviate the issue of imbalanced\nattribute correlations during training using counterfactual feature vectors in\nthe attribute latent space by disentanglement. During inference, we enhance\nattribute correlations by target-guided counterfactual augmentation to further\nimprove multi-aspect control. Experiments show that MAGIC outperforms\nstate-of-the-art baselines in both imbalanced and balanced attribute\ncorrelation scenarios. Our source code and data are available at\nhttps://github.com/nju-websoft/MAGIC.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Yi Liu",
            "Xiangyu Liu",
            "Xiangrong Zhu",
            "Wei Hu"
        ],
        "published": "2024-05-30T11:25:42Z"
    },
    {
        "title": "PLA4D: Pixel-Level Alignments for Text-to-4D Gaussian Splatting",
        "link": "http://arxiv.org/abs/2405.19957v1",
        "abstract": "As text-conditioned diffusion models (DMs) achieve breakthroughs in image,\nvideo, and 3D generation, the research community's focus has shifted to the\nmore challenging task of text-to-4D synthesis, which introduces a temporal\ndimension to generate dynamic 3D objects. In this context, we identify Score\nDistillation Sampling (SDS), a widely used technique for text-to-3D synthesis,\nas a significant hindrance to text-to-4D performance due to its Janus-faced and\ntexture-unrealistic problems coupled with high computational costs. In this\npaper, we propose \\textbf{P}ixel-\\textbf{L}evel \\textbf{A}lignments for\nText-to-\\textbf{4D} Gaussian Splatting (\\textbf{PLA4D}), a novel method that\nutilizes text-to-video frames as explicit pixel alignment targets to generate\nstatic 3D objects and inject motion into them. Specifically, we introduce Focal\nAlignment to calibrate camera poses for rendering and GS-Mesh Contrastive\nLearning to distill geometry priors from rendered image contrasts at the pixel\nlevel. Additionally, we develop Motion Alignment using a deformation network to\ndrive changes in Gaussians and implement Reference Refinement for smooth 4D\nobject surfaces. These techniques enable 4D Gaussian Splatting to align\ngeometry, texture, and motion with generated videos at the pixel level.\nCompared to previous methods, PLA4D produces synthesized outputs with better\ntexture details in less time and effectively mitigates the Janus-faced problem.\nPLA4D is fully implemented using open-source models, offering an accessible,\nuser-friendly, and promising direction for 4D digital content creation. Our\nproject page:\n\\href{https://github.com/MiaoQiaowei/PLA4D.github.io}{https://github.com/MiaoQiaowei/PLA4D.github.io}.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Qiaowei Miao",
            "Yawei Luo",
            "Yi Yang"
        ],
        "published": "2024-05-30T11:23:01Z"
    },
    {
        "title": "HOLMES: to Detect Adversarial Examples with Multiple Detectors",
        "link": "http://arxiv.org/abs/2405.19956v1",
        "abstract": "Deep neural networks (DNNs) can easily be cheated by some imperceptible but\npurposeful noise added to images, and erroneously classify them. Previous\ndefensive work mostly focused on retraining the models or detecting the noise,\nbut has either shown limited success rates or been attacked by new adversarial\nexamples. Instead of focusing on adversarial images or the interior of DNN\nmodels, we observed that adversarial examples generated by different algorithms\ncan be identified based on the output of DNNs (logits). Logit can serve as an\nexterior feature to train detectors. Then, we propose HOLMES (Hierarchically\nOrganized Light-weight Multiple dEtector System) to reinforce DNNs by detecting\npotential adversarial examples to minimize the threats they may bring in\npractical. HOLMES is able to distinguish \\textit{unseen} adversarial examples\nfrom multiple attacks with high accuracy and low false positive rates than\nsingle detector systems even in an adaptive model. To ensure the diversity and\nrandomness of detectors in HOLMES, we use two methods: training dedicated\ndetectors for each label and training detectors with top-k logits. Our\neffective and inexpensive strategies neither modify original DNN models nor\nrequire its internal parameters. HOLMES is not only compatible with all kinds\nof learning models (even only with external APIs), but also complementary to\nother defenses to achieve higher detection rates (may also fully protect the\nsystem against various adversarial examples).",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Jing Wen"
        ],
        "published": "2024-05-30T11:22:55Z"
    },
    {
        "title": "GenKubeSec: LLM-Based Kubernetes Misconfiguration Detection,\n  Localization, Reasoning, and Remediation",
        "link": "http://arxiv.org/abs/2405.19954v1",
        "abstract": "A key challenge associated with Kubernetes configuration files (KCFs) is that\nthey are often highly complex and error-prone, leading to security\nvulnerabilities and operational setbacks. Rule-based (RB) tools for KCF\nmisconfiguration detection rely on static rule sets, making them inherently\nlimited and unable to detect newly-discovered misconfigurations. RB tools also\nsuffer from misdetection, since mistakes are likely when coding the detection\nrules. Recent methods for detecting and remediating KCF misconfigurations are\nlimited in terms of their scalability and detection coverage, or due to the\nfact that they have high expertise requirements and do not offer automated\nremediation along with misconfiguration detection. Novel approaches that employ\nLLMs in their pipeline rely on API-based, general-purpose, and mainly\ncommercial models. Thus, they pose security challenges, have inconsistent\nclassification performance, and can be costly. In this paper, we propose\nGenKubeSec, a comprehensive and adaptive, LLM-based method, which, in addition\nto detecting a wide variety of KCF misconfigurations, also identifies the exact\nlocation of the misconfigurations and provides detailed reasoning about them,\nalong with suggested remediation. When empirically compared with three\nindustry-standard RB tools, GenKubeSec achieved equivalent precision (0.990)\nand superior recall (0.999). When a random sample of KCFs was examined by a\nKubernetes security expert, GenKubeSec's explanations as to misconfiguration\nlocalization, reasoning and remediation were 100% correct, informative and\nuseful. To facilitate further advancements in this domain, we share the unique\ndataset we collected, a unified misconfiguration index we developed for label\nstandardization, our experimentation code, and GenKubeSec itself as an\nopen-source tool.",
        "subjects": [
            "cs.CR",
            "cs.CL",
            "cs.DC",
            "cs.LG"
        ],
        "authors": [
            "Ehud Malul",
            "Yair Meidan",
            "Dudu Mimran",
            "Yuval Elovici",
            "Asaf Shabtai"
        ],
        "published": "2024-05-30T11:18:52Z"
    },
    {
        "title": "MM-Lego: Modular Biomedical Multimodal Models with Minimal Fine-Tuning",
        "link": "http://arxiv.org/abs/2405.19950v1",
        "abstract": "Learning holistic computational representations in physical, chemical or\nbiological systems requires the ability to process information from different\ndistributions and modalities within the same model. Thus, the demand for\nmultimodal machine learning models has sharply risen for modalities that go\nbeyond vision and language, such as sequences, graphs, time series, or tabular\ndata. While there are many available multimodal fusion and alignment\napproaches, most of them require end-to-end training, scale quadratically with\nthe number of modalities, cannot handle cases of high modality imbalance in the\ntraining set, or are highly topology-specific, making them too restrictive for\nmany biomedical learning tasks. This paper presents Multimodal Lego (MM-Lego),\na modular and general-purpose fusion and model merging framework to turn any\nset of encoders into a competitive multimodal model with no or minimal\nfine-tuning. We achieve this by introducing a wrapper for unimodal encoders\nthat enforces lightweight dimensionality assumptions between modalities and\nharmonises their representations by learning features in the frequency domain\nto enable model merging with little signal interference. We show that MM-Lego\n1) can be used as a model merging method which achieves competitive performance\nwith end-to-end fusion models without any fine-tuning, 2) can operate on any\nunimodal encoder, and 3) is a model fusion method that, with minimal\nfine-tuning, achieves state-of-the-art results on six benchmarked multimodal\nbiomedical tasks.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Konstantin Hemker",
            "Nikola Simidjievski",
            "Mateja Jamnik"
        ],
        "published": "2024-05-30T11:14:01Z"
    },
    {
        "title": "Hyper-Transformer for Amodal Completion",
        "link": "http://arxiv.org/abs/2405.19949v1",
        "abstract": "Amodal object completion is a complex task that involves predicting the\ninvisible parts of an object based on visible segments and background\ninformation. Learning shape priors is crucial for effective amodal completion,\nbut traditional methods often rely on two-stage processes or additional\ninformation, leading to inefficiencies and potential error accumulation. To\naddress these shortcomings, we introduce a novel framework named the\nHyper-Transformer Amodal Network (H-TAN). This framework utilizes a hyper\ntransformer equipped with a dynamic convolution head to directly learn shape\npriors and accurately predict amodal masks. Specifically, H-TAN uses a\ndual-branch structure to extract multi-scale features from both images and\nmasks. The multi-scale features from the image branch guide the hyper\ntransformer in learning shape priors and in generating the weights for dynamic\nconvolution tailored to each instance. The dynamic convolution head then uses\nthe features from the mask branch to predict precise amodal masks. We\nextensively evaluate our model on three benchmark datasets: KINS, COCOA-cls,\nand D2SA, where H-TAN demonstrated superior performance compared to existing\nmethods. Additional experiments validate the effectiveness and stability of the\nnovel hyper transformer in our framework.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jianxiong Gao",
            "Xuelin Qian",
            "Longfei Liang",
            "Junwei Han",
            "Yanwei Fu"
        ],
        "published": "2024-05-30T11:11:54Z"
    },
    {
        "title": "Scalable Test Generation to Trigger Rare Targets in High-Level\n  Synthesizable IPs for Cloud FPGAs",
        "link": "http://arxiv.org/abs/2405.19948v1",
        "abstract": "High-Level Synthesis (HLS) has transformed the development of complex\nHardware IPs (HWIP) by offering abstraction and configurability through\nlanguages like SystemC/C++, particularly for Field Programmable Gate Array\n(FPGA) accelerators in high-performance and cloud computing contexts. These IPs\ncan be synthesized for different FPGA boards in cloud, offering compact area\nrequirements and enhanced flexibility. HLS enables designs to execute directly\non ARM processors within modern FPGAs without the need for Register Transfer\nLevel (RTL) synthesis, thereby conserving FPGA resources. While HLS offers\nflexibility and efficiency, it also introduces potential vulnerabilities such\nas the presence of hidden circuitry, including the possibility of hosting\nhardware trojans within designs. In cloud environments, these vulnerabilities\npose significant security concerns such as leakage of sensitive data, IP\nfunctionality disruption and hardware damage, necessitating the development of\nrobust testing frameworks. This research presents an advanced testing approach\nfor HLS-developed cloud IPs, specifically targeting hidden malicious\nfunctionalities that may exist in rare conditions within the design. The\nproposed method leverages selective instrumentation, combining greybox fuzzing\nand concolic execution techniques to enhance test generation capabilities.\nEvaluation conducted on various HLS benchmarks, possessing characteristics of\nFPGA-based cloud IPs with embedded cloud related threats, demonstrates the\neffectiveness of our framework in detecting trojans and rare scenarios,\nshowcasing improvements in coverage, time efficiency, memory usage, and testing\ncosts compared to existing methods.",
        "subjects": [
            "cs.CR",
            "cs.SE"
        ],
        "authors": [
            "Mukta Debnath",
            "Animesh Basak Chowdhury",
            "Debasri Saha",
            "Susmita Sur-Kolay"
        ],
        "published": "2024-05-30T11:10:11Z"
    },
    {
        "title": "Learning to Discuss Strategically: A Case Study on One Night Ultimate\n  Werewolf",
        "link": "http://arxiv.org/abs/2405.19946v1",
        "abstract": "Communication is a fundamental aspect of human society, facilitating the\nexchange of information and beliefs among people. Despite the advancements in\nlarge language models (LLMs), recent agents built with these often neglect the\ncontrol over discussion tactics, which are essential in communication scenarios\nand games. As a variant of the famous communication game Werewolf, One Night\nUltimate Werewolf (ONUW) requires players to develop strategic discussion\npolicies due to the potential role changes that increase the uncertainty and\ncomplexity of the game. In this work, we first present the existence of the\nPerfect Bayesian Equilibria (PBEs) in two scenarios of the ONUW game: one with\ndiscussion and one without. The results showcase that the discussion greatly\nchanges players' utilities by affecting their beliefs, emphasizing the\nsignificance of discussion tactics. Based on the insights obtained from the\nanalyses, we propose an RL-instructed language agent framework, where a\ndiscussion policy trained by reinforcement learning (RL) is employed to\ndetermine appropriate discussion tactics to adopt. Our experimental results on\nseveral ONUW game settings demonstrate the effectiveness and generalizability\nof our proposed framework.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Xuanfa Jin",
            "Ziyan Wang",
            "Yali Du",
            "Meng Fang",
            "Haifeng Zhang",
            "Jun Wang"
        ],
        "published": "2024-05-30T11:07:06Z"
    },
    {
        "title": "Discrete-Time I&I Adaptive Interconnection and Damping Passivity-Based\n  Control for Nonlinearly Parameterized Port-Controlled Hamiltonian Systems",
        "link": "http://arxiv.org/abs/2405.19944v1",
        "abstract": "In this paper, a discrete-time I&I-based adaptive IDA-PBC controller for\nuncertain nonlinearly parameterized port-controlled Hamiltonian systems (PCH),\nwhere the parameter uncertainties are assumed in the energy function, is\nconstructed. A proper formulation for the uncertain system dynamics is\nestablished where the uncertainties appear in nonlinearly parameterized form in\nthe gradient of the Hamiltonian function. The adaptive IDA-PBC controller is\nconstructed considering this formulation. For the adaptation mechanism of the\nIDA-PBC controller, a discrete-time parameter estimator is derived based on the\nimmersion and invariance (I&I) approach. A structure for a free design function\nin the I&I-based estimator is proposed including some other free design\nfunctions. If these free design functions are selected to satisfy some\nconditions, derived in this paper, the Lyapunov asymptotic stability of the\nestimator dynamics is guaranteed. Besides, assuming these conditions are\nsatisfied, local asymptotic stability of the closed-loop system, in a\nsufficiently large set is shown. The proposed method is applied to the two\nphysical system examples and the performance of the adaptive controller is\ntested by simulation. It is demonstrated that the performance of the certain\nIDA-PBC controller is maintained by the adaptive IDA-PBC controller\nsuccessfully.",
        "subjects": [
            "eess.SY",
            "cs.SY",
            "93"
        ],
        "authors": [
            "Mohammed Alkrunza",
            "Yaprak Yalcin"
        ],
        "published": "2024-05-30T11:04:30Z"
    },
    {
        "title": "Multi-View People Detection in Large Scenes via Supervised View-Wise\n  Contribution Weighting",
        "link": "http://arxiv.org/abs/2405.19943v1",
        "abstract": "Recent deep learning-based multi-view people detection (MVD) methods have\nshown promising results on existing datasets. However, current methods are\nmainly trained and evaluated on small, single scenes with a limited number of\nmulti-view frames and fixed camera views. As a result, these methods may not be\npractical for detecting people in larger, more complex scenes with severe\nocclusions and camera calibration errors. This paper focuses on improving\nmulti-view people detection by developing a supervised view-wise contribution\nweighting approach that better fuses multi-camera information under large\nscenes. Besides, a large synthetic dataset is adopted to enhance the model's\ngeneralization ability and enable more practical evaluation and comparison. The\nmodel's performance on new testing scenes is further improved with a simple\ndomain adaptation technique. Experimental results demonstrate the effectiveness\nof our approach in achieving promising cross-scene multi-view people detection\nperformance. See code here: https://vcc.tech/research/2024/MVD.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Qi Zhang",
            "Yunfei Gong",
            "Daijie Chen",
            "Antoni B. Chan",
            "Hui Huang"
        ],
        "published": "2024-05-30T11:03:27Z"
    },
    {
        "title": "Synthetic Patients: Simulating Difficult Conversations with Multimodal\n  Generative AI for Medical Education",
        "link": "http://arxiv.org/abs/2405.19941v1",
        "abstract": "Problem: Effective patient-centered communication is a core competency for\nphysicians. However, both seasoned providers and medical trainees report\ndecreased confidence in leading conversations on sensitive topics such as goals\nof care or end-of-life discussions. The significant administrative burden and\nthe resources required to provide dedicated training in leading difficult\nconversations has been a long-standing problem in medical education.\n  Approach: In this work, we present a novel educational tool designed to\nfacilitate interactive, real-time simulations of difficult conversations in a\nvideo-based format through the use of multimodal generative artificial\nintelligence (AI). Leveraging recent advances in language modeling, computer\nvision, and generative audio, this tool creates realistic, interactive\nscenarios with avatars, or \"synthetic patients.\" These synthetic patients\ninteract with users throughout various stages of medical care using a\ncustom-built video chat application, offering learners the chance to practice\nconversations with patients from diverse belief systems, personalities, and\nethnic backgrounds.\n  Outcomes: While the development of this platform demanded substantial upfront\ninvestment in labor, it offers a highly-realistic simulation experience with\nminimal financial investment. For medical trainees, this educational tool can\nbe implemented within programs to simulate patient-provider conversations and\ncan be incorporated into existing palliative care curriculum to provide a\nscalable, high-fidelity simulation environment for mastering difficult\nconversations.\n  Next Steps: Future developments will explore enhancing the authenticity of\nthese encounters by working with patients to incorporate their histories and\npersonalities, as well as employing the use of AI-generated evaluations to\noffer immediate, constructive feedback to learners post-simulation.",
        "subjects": [
            "cs.HC",
            "cs.CY"
        ],
        "authors": [
            "Simon N. Chu",
            "Alex J. Goodell"
        ],
        "published": "2024-05-30T11:02:08Z"
    },
    {
        "title": "Estimating Population Burden of Stroke with an Agent-Based Model",
        "link": "http://arxiv.org/abs/2405.19934v1",
        "abstract": "Stroke is one of the leading causes of death and disability worldwide but it\nis believed to be highly preventable. The majority of stroke prevention focuses\non targeting high-risk individuals but its is important to understand how the\ntargeting of high-risk individuals might impact the overall societal burden of\nstroke. We propose using an agent-based model that follows agents through their\npre-stroke and stroke journey to assess the impacts of different interventions\nat the population level. We present a case study looking at the impacts of\nagents being informed of their stroke risk at certain ages and those agents\ntaking measure to reduce their risk. The results of our study show that if\nagents are aware of their risk and act accordingly we see a significant\nreduction in strokes and population DALYs. The case study highlights the\nimportance of individuals understanding their own stroke risk for stroke\nprevention and the usefulness of agent-based models in assessing the impact of\nstroke interventions.",
        "subjects": [
            "cs.CY"
        ],
        "authors": [
            "Elizabeth Hunter",
            "John D. Kelleher"
        ],
        "published": "2024-05-30T10:49:37Z"
    },
    {
        "title": "Learning Latent Graph Structures and their Uncertainty",
        "link": "http://arxiv.org/abs/2405.19933v1",
        "abstract": "Within a prediction task, Graph Neural Networks (GNNs) use relational\ninformation as an inductive bias to enhance the model's accuracy. As\ntask-relevant relations might be unknown, graph structure learning approaches\nhave been proposed to learn them while solving the downstream prediction task.\nIn this paper, we demonstrate that minimization of a point-prediction loss\nfunction, e.g., the mean absolute error, does not guarantee proper learning of\nthe latent relational information and its associated uncertainty. Conversely,\nwe prove that a suitable loss function on the stochastic model outputs\nsimultaneously grants (i) the unknown adjacency matrix latent distribution and\n(ii) optimal performance on the prediction task. Finally, we propose a\nsampling-based method that solves this joint learning task. Empirical results\nvalidate our theoretical claims and demonstrate the effectiveness of the\nproposed approach.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Alessandro Manenti",
            "Daniele Zambon",
            "Cesare Alippi"
        ],
        "published": "2024-05-30T10:49:22Z"
    },
    {
        "title": "Exploring Diffusion Models' Corruption Stage in Few-Shot Fine-tuning and\n  Mitigating with Bayesian Neural Networks",
        "link": "http://arxiv.org/abs/2405.19931v1",
        "abstract": "Few-shot fine-tuning of Diffusion Models (DMs) is a key advancement,\nsignificantly reducing training costs and enabling personalized AI\napplications. However, we explore the training dynamics of DMs and observe an\nunanticipated phenomenon: during the training process, image fidelity initially\nimproves, then unexpectedly deteriorates with the emergence of noisy patterns,\nonly to recover later with severe overfitting. We term the stage with generated\nnoisy patterns as corruption stage. To understand this corruption stage, we\nbegin by theoretically modeling the one-shot fine-tuning scenario, and then\nextend this modeling to more general cases. Through this modeling, we identify\nthe primary cause of this corruption stage: a narrowed learning distribution\ninherent in the nature of few-shot fine-tuning. To tackle this, we apply\nBayesian Neural Networks (BNNs) on DMs with variational inference to implicitly\nbroaden the learned distribution, and present that the learning target of the\nBNNs can be naturally regarded as an expectation of the diffusion loss and a\nfurther regularization with the pretrained DMs. This approach is highly\ncompatible with current few-shot fine-tuning methods in DMs and does not\nintroduce any extra inference costs. Experimental results demonstrate that our\nmethod significantly mitigates corruption, and improves the fidelity, quality\nand diversity of the generated images in both object-driven and subject-driven\ngeneration tasks.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Xiaoyu Wu",
            "Jiaru Zhang",
            "Yang Hua",
            "Bohan Lyu",
            "Hao Wang",
            "Tao Song",
            "Haibing Guan"
        ],
        "published": "2024-05-30T10:47:48Z"
    },
    {
        "title": "BAN: Detecting Backdoors Activated by Adversarial Neuron Noise",
        "link": "http://arxiv.org/abs/2405.19928v1",
        "abstract": "Backdoor attacks on deep learning represent a recent threat that has gained\nsignificant attention in the research community. Backdoor defenses are mainly\nbased on backdoor inversion, which has been shown to be generic,\nmodel-agnostic, and applicable to practical threat scenarios. State-of-the-art\nbackdoor inversion recovers a mask in the feature space to locate prominent\nbackdoor features, where benign and backdoor features can be disentangled.\nHowever, it suffers from high computational overhead, and we also find that it\noverly relies on prominent backdoor features that are highly distinguishable\nfrom benign features. To tackle these shortcomings, this paper improves\nbackdoor feature inversion for backdoor detection by incorporating extra neuron\nactivation information. In particular, we adversarially increase the loss of\nbackdoored models with respect to weights to activate the backdoor effect,\nbased on which we can easily differentiate backdoored and clean models.\nExperimental results demonstrate our defense, BAN, is 1.37$\\times$ (on\nCIFAR-10) and 5.11$\\times$ (on ImageNet200) more efficient with 9.99% higher\ndetect success rate than the state-of-the-art defense BTI-DBF. Our code and\ntrained models are publicly\navailable.\\url{https://anonymous.4open.science/r/ban-4B32}",
        "subjects": [
            "cs.LG",
            "cs.CR"
        ],
        "authors": [
            "Xiaoyun Xu",
            "Zhuoran Liu",
            "Stefanos Koffas",
            "Shujian Yu",
            "Stjepan Picek"
        ],
        "published": "2024-05-30T10:44:45Z"
    },
    {
        "title": "MCDS-VSS: Moving Camera Dynamic Scene Video Semantic Segmentation by\n  Filtering with Self-Supervised Geometry and Motion",
        "link": "http://arxiv.org/abs/2405.19921v1",
        "abstract": "Autonomous systems, such as self-driving cars, rely on reliable semantic\nenvironment perception for decision making. Despite great advances in video\nsemantic segmentation, existing approaches ignore important inductive biases\nand lack structured and interpretable internal representations. In this work,\nwe propose MCDS-VSS, a structured filter model that learns in a self-supervised\nmanner to estimate scene geometry and ego-motion of the camera, while also\nestimating the motion of external objects. Our model leverages these\nrepresentations to improve the temporal consistency of semantic segmentation\nwithout sacrificing segmentation accuracy. MCDS-VSS follows a prediction-fusion\napproach in which scene geometry and camera motion are first used to compensate\nfor ego-motion, then residual flow is used to compensate motion of dynamic\nobjects, and finally the predicted scene features are fused with the current\nfeatures to obtain a temporally consistent scene segmentation. Our model parses\nautomotive scenes into multiple decoupled interpretable representations such as\nscene geometry, ego-motion, and object motion. Quantitative evaluation shows\nthat MCDS-VSS achieves superior temporal consistency on video sequences while\nretaining competitive segmentation performance.",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Angel Villar-Corrales",
            "Moritz Austermann",
            "Sven Behnke"
        ],
        "published": "2024-05-30T10:33:14Z"
    },
    {
        "title": "Unraveling the Impact of Heterophilic Structures on Graph\n  Positive-Unlabeled Learning",
        "link": "http://arxiv.org/abs/2405.19919v1",
        "abstract": "While Positive-Unlabeled (PU) learning is vital in many real-world scenarios,\nits application to graph data still remains under-explored. We unveil that a\ncritical challenge for PU learning on graph lies on the edge heterophily, which\ndirectly violates the irreducibility assumption for Class-Prior Estimation\n(class prior is essential for building PU learning algorithms) and degenerates\nthe latent label inference on unlabeled nodes during classifier training. In\nresponse to this challenge, we introduce a new method, named Graph PU Learning\nwith Label Propagation Loss (GPL). Specifically, GPL considers learning from PU\nnodes along with an intermediate heterophily reduction, which helps mitigate\nthe negative impact of the heterophilic structure. We formulate this procedure\nas a bilevel optimization that reduces heterophily in the inner loop and\nefficiently learns a classifier in the outer loop. Extensive experiments across\na variety of datasets have shown that GPL significantly outperforms baseline\nmethods, confirming its effectiveness and superiority.",
        "subjects": [
            "cs.LG",
            "cs.SI"
        ],
        "authors": [
            "Yuhao Wu",
            "Jiangchao Yao",
            "Bo Han",
            "Lina Yao",
            "Tongliang Liu"
        ],
        "published": "2024-05-30T10:30:44Z"
    },
    {
        "title": "Multimodal Cross-Domain Few-Shot Learning for Egocentric Action\n  Recognition",
        "link": "http://arxiv.org/abs/2405.19917v1",
        "abstract": "We address a novel cross-domain few-shot learning task (CD-FSL) with\nmultimodal input and unlabeled target data for egocentric action recognition.\nThis paper simultaneously tackles two critical challenges associated with\negocentric action recognition in CD-FSL settings: (1) the extreme domain gap in\negocentric videos (\\eg, daily life vs. industrial domain) and (2) the\ncomputational cost for real-world applications. We propose MM-CDFSL, a\ndomain-adaptive and computationally efficient approach designed to enhance\nadaptability to the target domain and improve inference speed. To address the\nfirst challenge, we propose the incorporation of multimodal distillation into\nthe student RGB model using teacher models. Each teacher model is trained\nindependently on source and target data for its respective modality. Leveraging\nonly unlabeled target data during multimodal distillation enhances the student\nmodel's adaptability to the target domain. We further introduce ensemble masked\ninference, a technique that reduces the number of input tokens through masking.\nIn this approach, ensemble prediction mitigates the performance degradation\ncaused by masking, effectively addressing the second issue. Our approach\noutperformed the state-of-the-art CD-FSL approaches with a substantial margin\non multiple egocentric datasets, improving by an average of 6.12/6.10 points\nfor 1-shot/5-shot settings while achieving $2.2$ times faster inference speed.\nProject page: https://masashi-hatano.github.io/MM-CDFSL/",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Masashi Hatano",
            "Ryo Hachiuma",
            "Ryo Fuji",
            "Hideo Saito"
        ],
        "published": "2024-05-30T10:30:07Z"
    },
    {
        "title": "P$^2$-ViT: Power-of-Two Post-Training Quantization and Acceleration for\n  Fully Quantized Vision Transformer",
        "link": "http://arxiv.org/abs/2405.19915v1",
        "abstract": "Vision Transformers (ViTs) have excelled in computer vision tasks but are\nmemory-consuming and computation-intensive, challenging their deployment on\nresource-constrained devices. To tackle this limitation, prior works have\nexplored ViT-tailored quantization algorithms but retained floating-point\nscaling factors, which yield non-negligible re-quantization overhead, limiting\nViTs' hardware efficiency and motivating more hardware-friendly solutions. To\nthis end, we propose \\emph{P$^2$-ViT}, the first \\underline{P}ower-of-Two (PoT)\n\\underline{p}ost-training quantization and acceleration framework to accelerate\nfully quantized ViTs. Specifically, {as for quantization,} we explore a\ndedicated quantization scheme to effectively quantize ViTs with PoT scaling\nfactors, thus minimizing the re-quantization overhead. Furthermore, we propose\ncoarse-to-fine automatic mixed-precision quantization to enable better\naccuracy-efficiency trade-offs. {In terms of hardware,} we develop {a dedicated\nchunk-based accelerator} featuring multiple tailored sub-processors to\nindividually handle ViTs' different types of operations, alleviating\nreconfigurable overhead. Additionally, we design {a tailored row-stationary\ndataflow} to seize the pipeline processing opportunity introduced by our PoT\nscaling factors, thereby enhancing throughput. Extensive experiments\nconsistently validate P$^2$-ViT's effectiveness. {Particularly, we offer\ncomparable or even superior quantization performance with PoT scaling factors\nwhen compared to the counterpart with floating-point scaling factors. Besides,\nwe achieve up to $\\mathbf{10.1\\times}$ speedup and $\\mathbf{36.8\\times}$ energy\nsaving over GPU's Turing Tensor Cores, and up to $\\mathbf{1.84\\times}$ higher\ncomputation utilization efficiency against SOTA quantization-based ViT\naccelerators. Codes are available at\n\\url{https://github.com/shihuihong214/P2-ViT}.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Huihong Shi",
            "Xin Cheng",
            "Wendong Mao",
            "Zhongfeng Wang"
        ],
        "published": "2024-05-30T10:26:36Z"
    },
    {
        "title": "Towards RGB-NIR Cross-modality Image Registration and Beyond",
        "link": "http://arxiv.org/abs/2405.19914v1",
        "abstract": "This paper focuses on the area of RGB(visible)-NIR(near-infrared)\ncross-modality image registration, which is crucial for many downstream vision\ntasks to fully leverage the complementary information present in visible and\ninfrared images. In this field, researchers face two primary challenges - the\nabsence of a correctly-annotated benchmark with viewpoint variations for\nevaluating RGB-NIR cross-modality registration methods and the problem of\ninconsistent local features caused by the appearance discrepancy between\nRGB-NIR cross-modality images. To address these challenges, we first present\nthe RGB-NIR Image Registration (RGB-NIR-IRegis) benchmark, which, for the first\ntime, enables fair and comprehensive evaluations for the task of RGB-NIR\ncross-modality image registration. Evaluations of previous methods highlight\nthe significant challenges posed by our RGB-NIR-IRegis benchmark, especially on\nRGB-NIR image pairs with viewpoint variations. To analyze the causes of the\nunsatisfying performance, we then design several metrics to reveal the toxic\nimpact of inconsistent local features between visible and infrared images on\nthe model performance. This further motivates us to develop a baseline method\nnamed Semantic Guidance Transformer (SGFormer), which utilizes high-level\nsemantic guidance to mitigate the negative impact of local inconsistent\nfeatures. Despite the simplicity of our motivation, extensive experimental\nresults show the effectiveness of our method.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Huadong Li",
            "Shichao Dong",
            "Jin Wang",
            "Rong Fu",
            "Minhao Jing",
            "Jiajun Liang",
            "Haoqiang Fan",
            "Renhe Ji"
        ],
        "published": "2024-05-30T10:25:50Z"
    },
    {
        "title": "Robust Kernel Hypothesis Testing under Data Corruption",
        "link": "http://arxiv.org/abs/2405.19912v1",
        "abstract": "We propose two general methods for constructing robust permutation tests\nunder data corruption. The proposed tests effectively control the\nnon-asymptotic type I error under data corruption, and we prove their\nconsistency in power under minimal conditions. This contributes to the\npractical deployment of hypothesis tests for real-world applications with\npotential adversarial attacks. One of our methods inherently ensures\ndifferential privacy, further broadening its applicability to private data\nanalysis. For the two-sample and independence settings, we show that our kernel\nrobust tests are minimax optimal, in the sense that they are guaranteed to be\nnon-asymptotically powerful against alternatives uniformly separated from the\nnull in the kernel MMD and HSIC metrics at some optimal rate (tight with\nmatching lower bound). Finally, we provide publicly available implementations\nand empirically illustrate the practicality of our proposed tests.",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Antonin Schrab",
            "Ilmun Kim"
        ],
        "published": "2024-05-30T10:23:16Z"
    },
    {
        "title": "Full weight spectrum one-orbit cyclic subspace codes",
        "link": "http://arxiv.org/abs/2405.19911v1",
        "abstract": "For a linear Hamming metric code of length n over a finite field, the number\nof distinct weights of its codewords is at most n. The codes achieving the\nequality in the above bound were called full weight spectrum codes. In this\npaper we will focus on the analogous class of codes within the framework of\ncyclic subspace codes. Cyclic subspace codes have garnered significant\nattention, particularly for their applications in random network coding to\ncorrect errors and erasures. We investigate one-orbit cyclic subspace codes\nthat are full weight spectrum in this context. Utilizing number theoretical\nresults and combinatorial arguments, we provide a complete classification of\nfull weight spectrum one-orbit cyclic subspace codes.",
        "subjects": [
            "cs.IT",
            "math.CO",
            "math.IT"
        ],
        "authors": [
            "Chiara Castello",
            "Olga Polverino",
            "Ferdinando Zullo"
        ],
        "published": "2024-05-30T10:22:11Z"
    },
    {
        "title": "Adaptive Advantage-Guided Policy Regularization for Offline\n  Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.19909v1",
        "abstract": "In offline reinforcement learning, the challenge of out-of-distribution (OOD)\nis pronounced. To address this, existing methods often constrain the learned\npolicy through policy regularization. However, these methods often suffer from\nthe issue of unnecessary conservativeness, hampering policy improvement. This\noccurs due to the indiscriminate use of all actions from the behavior policy\nthat generates the offline dataset as constraints. The problem becomes\nparticularly noticeable when the quality of the dataset is suboptimal. Thus, we\npropose Adaptive Advantage-guided Policy Regularization (A2PR), obtaining\nhigh-advantage actions from an augmented behavior policy combined with VAE to\nguide the learned policy. A2PR can select high-advantage actions that differ\nfrom those present in the dataset, while still effectively maintaining\nconservatism from OOD actions. This is achieved by harnessing the VAE capacity\nto generate samples matching the distribution of the data points. We\ntheoretically prove that the improvement of the behavior policy is guaranteed.\nBesides, it effectively mitigates value overestimation with a bounded\nperformance gap. Empirically, we conduct a series of experiments on the D4RL\nbenchmark, where A2PR demonstrates state-of-the-art performance. Furthermore,\nexperimental results on additional suboptimal mixed datasets reveal that A2PR\nexhibits superior performance. Code is available at\nhttps://github.com/ltlhuuu/A2PR.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.RO"
        ],
        "authors": [
            "Tenglong Liu",
            "Yang Li",
            "Yixing Lan",
            "Hao Gao",
            "Wei Pan",
            "Xin Xu"
        ],
        "published": "2024-05-30T10:20:55Z"
    },
    {
        "title": "Learning Discriminative Dynamics with Label Corruption for Noisy Label\n  Detection",
        "link": "http://arxiv.org/abs/2405.19902v1",
        "abstract": "Label noise, commonly found in real-world datasets, has a detrimental impact\non a model's generalization. To effectively detect incorrectly labeled\ninstances, previous works have mostly relied on distinguishable training\nsignals, such as training loss, as indicators to differentiate between clean\nand noisy labels. However, they have limitations in that the training signals\nincompletely reveal the model's behavior and are not effectively generalized to\nvarious noise types, resulting in limited detection accuracy. In this paper, we\npropose DynaCor framework that distinguishes incorrectly labeled instances from\ncorrectly labeled ones based on the dynamics of the training signals. To cope\nwith the absence of supervision for clean and noisy labels, DynaCor first\nintroduces a label corruption strategy that augments the original dataset with\nintentionally corrupted labels, enabling indirect simulation of the model's\nbehavior on noisy labels. Then, DynaCor learns to identify clean and noisy\ninstances by inducing two clearly distinguishable clusters from the latent\nrepresentations of training dynamics. Our comprehensive experiments show that\nDynaCor outperforms the state-of-the-art competitors and shows strong\nrobustness to various noise types and noise rates.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Suyeon Kim",
            "Dongha Lee",
            "SeongKu Kang",
            "Sukang Chae",
            "Sanghwan Jang",
            "Hwanjo Yu"
        ],
        "published": "2024-05-30T10:06:06Z"
    },
    {
        "title": "Urban Air Pollution Forecasting: a Machine Learning Approach leveraging\n  Satellite Observations and Meteorological Forecasts",
        "link": "http://arxiv.org/abs/2405.19901v1",
        "abstract": "Air pollution poses a significant threat to public health and well-being,\nparticularly in urban areas. This study introduces a series of machine-learning\nmodels that integrate data from the Sentinel-5P satellite, meteorological\nconditions, and topological characteristics to forecast future levels of five\nmajor pollutants. The investigation delineates the process of data collection,\ndetailing the combination of diverse data sources utilized in the study.\nThrough experiments conducted in the Milan metropolitan area, the models\ndemonstrate their efficacy in predicting pollutant levels for the forthcoming\nday, achieving a percentage error of around 30%. The proposed models are\nadvantageous as they are independent of monitoring stations, facilitating their\nuse in areas without existing infrastructure. Additionally, we have released\nthe collected dataset to the public, aiming to stimulate further research in\nthis field. This research contributes to advancing our understanding of urban\nair quality dynamics and emphasizes the importance of amalgamating satellite,\nmeteorological, and topographical data to develop robust pollution forecasting\nmodels.",
        "subjects": [
            "cs.LG",
            "physics.ao-ph",
            "I.2.m; G.3"
        ],
        "authors": [
            "Giacomo Blanco",
            "Luca Barco",
            "Lorenzo Innocenti",
            "Claudio Rossi"
        ],
        "published": "2024-05-30T10:02:53Z"
    },
    {
        "title": "Open-Set Domain Adaptation for Semantic Segmentation",
        "link": "http://arxiv.org/abs/2405.19899v1",
        "abstract": "Unsupervised domain adaptation (UDA) for semantic segmentation aims to\ntransfer the pixel-wise knowledge from the labeled source domain to the\nunlabeled target domain. However, current UDA methods typically assume a shared\nlabel space between source and target, limiting their applicability in\nreal-world scenarios where novel categories may emerge in the target domain. In\nthis paper, we introduce Open-Set Domain Adaptation for Semantic Segmentation\n(OSDA-SS) for the first time, where the target domain includes unknown classes.\nWe identify two major problems in the OSDA-SS scenario as follows: 1) the\nexisting UDA methods struggle to predict the exact boundary of the unknown\nclasses, and 2) they fail to accurately predict the shape of the unknown\nclasses. To address these issues, we propose Boundary and Unknown Shape-Aware\nopen-set domain adaptation, coined BUS. Our BUS can accurately discern the\nboundaries between known and unknown classes in a contrastive manner using a\nnovel dilation-erosion-based contrastive loss. In addition, we propose\nOpenReMix, a new domain mixing augmentation method that guides our model to\neffectively learn domain and size-invariant features for improving the shape\ndetection of the known and unknown classes. Through extensive experiments, we\ndemonstrate that our proposed BUS effectively detects unknown classes in the\nchallenging OSDA-SS scenario compared to the previous methods by a large\nmargin. The code is available at https://github.com/KHU-AGI/BUS.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Seun-An Choe",
            "Ah-Hyung Shin",
            "Keon-Hee Park",
            "Jinwoo Choi",
            "Gyeong-Moon Park"
        ],
        "published": "2024-05-30T09:55:19Z"
    },
    {
        "title": "Fast Numerical Approximation of Linear, Second-Order Hyperbolic Problems\n  Using Model Order Reduction and the Laplace Transform",
        "link": "http://arxiv.org/abs/2405.19896v1",
        "abstract": "We extend our previous work [F. Henr\\'iquez and J. S. Hesthaven,\narXiv:2403.02847 (2024)] to the linear, second-order wave equation in bounded\ndomains. This technique, referred to as the Laplace Transform Reduced Basis\n(LT-RB) method, uses two widely known mathematical tools to construct a fast\nand efficient method for the solution of linear, time-dependent problems: The\nLaplace transform and the Reduced Basis method, hence the name.\n  The application of the Laplace transform yields a time-independent problem\nparametrically depending on the Laplace variable. Following the two-phase\nparadigm of the RB method, firstly in an offline stage we sample the Laplace\nparameter, compute the full-order or high-fidelity solution, and then resort to\na Proper Orthogonal Decomposition (POD) to extract a basis of reduced\ndimension. Then, in an online phase, we project the time-dependent problem onto\nthis basis and proceed to solve the evolution problem using any suitable\ntime-stepping method. We prove exponential convergence of the reduced solution\ncomputed by the LT-RB method toward the high-fidelity one as the dimension of\nthe reduced space increases.\n  Finally, we present a set of numerical experiments portraying the performance\nof the method in terms of accuracy and, in particular, speed-up when compared\nto the full-order model.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Fernando Henriquez",
            "Jan S. Hesthaven"
        ],
        "published": "2024-05-30T09:53:10Z"
    },
    {
        "title": "Dispersion of personal spaces",
        "link": "http://arxiv.org/abs/2405.19895v1",
        "abstract": "There are many entities that disseminate in the physical space - information,\ngossip, mood, innovation etc. Personal spaces are also entities that disperse\nand interplay. In this work we study the emergence of configurations formed by\nparticipants when choosing a place to sit in a rectangular auditorium. Based on\nexperimental questionnaire data we design several models and assess their\nrelevancy to a real time-lapse footage of lecture hall being filled up. The\nmain focus is to compare the evolution of entropy of occupied seat\nconfigurations in time. Even though the process of choosing a seat is complex\nand could depend on various properties of participants or environment, some of\nthe developed models can capture at least basic essence of the real processes.\nAfter introducing the problem of seat selection and related results in close\nresearch areas, we introduce preliminary collected data and build models of\nseat selection based on them. We compare the resulting models to the real\nobservational data and discuss areas of future research directions.",
        "subjects": [
            "cs.MA"
        ],
        "authors": [
            "Jaroslav Horáček",
            "Miroslav Rada"
        ],
        "published": "2024-05-30T09:52:27Z"
    },
    {
        "title": "Similarity is Not All You Need: Endowing Retrieval Augmented Generation\n  with Multi Layered Thoughts",
        "link": "http://arxiv.org/abs/2405.19893v1",
        "abstract": "In recent years, large language models (LLMs) have made remarkable\nachievements in various domains. However, the untimeliness and cost of\nknowledge updates coupled with hallucination issues of LLMs have curtailed\ntheir applications in knowledge intensive tasks, where retrieval augmented\ngeneration (RAG) can be of help. Nevertheless, existing retrieval augmented\nmodels typically use similarity as a bridge between queries and documents and\nfollow a retrieve then read procedure. In this work, we argue that similarity\nis not always the panacea and totally relying on similarity would sometimes\ndegrade the performance of retrieval augmented generation. To this end, we\npropose MetRag, a Multi layEred Thoughts enhanced Retrieval Augmented\nGeneration framework. To begin with, beyond existing similarity oriented\nthought, we embrace a small scale utility model that draws supervision from an\nLLM for utility oriented thought and further come up with a smarter model by\ncomprehensively combining the similarity and utility oriented thoughts.\nFurthermore, given the fact that the retrieved document set tends to be huge\nand using them in isolation makes it difficult to capture the commonalities and\ncharacteristics among them, we propose to make an LLM as a task adaptive\nsummarizer to endow retrieval augmented generation with compactness-oriented\nthought. Finally, with multi layered thoughts from the precedent stages, an LLM\nis called for knowledge augmented generation. Extensive experiments on\nknowledge-intensive tasks have demonstrated the superiority of MetRag.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Chunjing Gan",
            "Dan Yang",
            "Binbin Hu",
            "Hanxiao Zhang",
            "Siyuan Li",
            "Ziqi Liu",
            "Yue Shen",
            "Lin Ju",
            "Zhiqiang Zhang",
            "Jinjie Gu",
            "Lei Liang",
            "Jun Zhou"
        ],
        "published": "2024-05-30T09:50:38Z"
    },
    {
        "title": "Improving the Fidelity of CNOT Circuits on NISQ Hardware",
        "link": "http://arxiv.org/abs/2405.19891v1",
        "abstract": "We introduce an improved CNOT synthesis algorithm that considers\nnearest-neighbour interactions and CNOT gate error rates in noisy\nintermediate-scale quantum (NISQ) hardware. Compared to IBM's Qiskit compiler,\nit improves the fidelity of a synthesized CNOT circuit by about 2 times on\naverage (up to 9 times). It lowers the synthesized CNOT count by a factor of 13\non average (up to a factor of 162).\n  Our contribution is twofold. First, we define a $\\textsf{Cost}$ function by\napproximating the average gate fidelity $F_{avg}$. According to the simulation\nresults, $\\textsf{Cost}$ fits the error probability of a noisy CNOT circuit,\n$\\textsf{Prob} = 1 - F_{avg}$, much tighter than the commonly used cost\nfunctions. On IBM's fake Nairobi backend, it matches $\\textsf{Prob}$ to within\n$10^{-3}$. On other backends, it fits $\\textsf{Prob}$ to within $10^{-1}$.\n$\\textsf{Cost}$ accurately quantifies the dynamic error characteristics and\nshows remarkable scalability. Second, we propose a noise-aware CNOT routing\nalgorithm, NAPermRowCol, by adapting the leading Steiner-tree-based\nconnectivity-aware CNOT synthesis algorithms. A weighted edge is used to encode\na CNOT gate error rate and $\\textsf{Cost}$-instructed heuristics are applied to\neach reduction step. NAPermRowCol does not use ancillary qubits and is not\nrestricted to certain initial qubit maps. Compared with algorithms that are\nnoise-agnostic, it improves the fidelity of a synthesized CNOT circuit across\nvaried NISQ hardware. Depending on the benchmark circuit and the IBM backend\nselected, it lowers the synthesized CNOT count up to $56.95\\%$ compared to\nROWCOL and up to $21.62\\%$ compared to PermRowCol. It reduces the synthesis\n$\\textsf{Cost}$ up to $25.71\\%$ compared to ROWCOL and up to $9.12\\%$ compared\nto PermRowCol. Our method can be extended to route a more general quantum\ncircuit, giving a powerful new tool for compiling on NISQ devices.",
        "subjects": [
            "quant-ph",
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Dohun Kim",
            "Minyoung Kim",
            "Sarah Meng Li",
            "Michele Mosca"
        ],
        "published": "2024-05-30T09:47:33Z"
    },
    {
        "title": "Deep Joint Semantic Coding and Beamforming for Near-Space Airship-Borne\n  Massive MIMO Network",
        "link": "http://arxiv.org/abs/2405.19889v1",
        "abstract": "Near-space airship-borne communication network is recognized to be an\nindispensable component of the future integrated ground-air-space network\nthanks to airships' advantage of long-term residency at stratospheric\naltitudes, but it urgently needs reliable and efficient Airship-to-X link. To\nimprove the transmission efficiency and capacity, this paper proposes to\nintegrate semantic communication with massive multiple-input multiple-output\n(MIMO) technology. Specifically, we propose a deep joint semantic coding and\nbeamforming (JSCBF) scheme for airship-based massive MIMO image transmission\nnetwork in space, in which semantics from both source and channel are fused to\njointly design the semantic coding and physical layer beamforming. First, we\ndesign two semantic extraction networks to extract semantics from image source\nand channel state information, respectively. Then, we propose a semantic fusion\nnetwork that can fuse these semantics into complex-valued semantic features for\nsubsequent physical-layer transmission. To efficiently transmit the fused\nsemantic features at the physical layer, we then propose the hybrid data and\nmodel-driven semantic-aware beamforming networks. At the receiver, a semantic\ndecoding network is designed to reconstruct the transmitted images. Finally, we\nperform end-to-end deep learning to jointly train all the modules, using the\nimage reconstruction quality at the receivers as a metric. The proposed deep\nJSCBF scheme fully combines the efficient source compressibility and robust\nerror correction capability of semantic communication with the high spectral\nefficiency of massive MIMO, achieving a significant performance improvement\nover existing approaches.",
        "subjects": [
            "eess.SP",
            "cs.IT",
            "cs.LG",
            "cs.MM",
            "math.IT"
        ],
        "authors": [
            "Minghui Wu",
            "Zhen Gao",
            "Zhaocheng Wang",
            "Dusit Niyato",
            "George K. Karagiannidis",
            "Sheng Chen"
        ],
        "published": "2024-05-30T09:46:59Z"
    },
    {
        "title": "Parrot: Efficient Serving of LLM-based Applications with Semantic\n  Variable",
        "link": "http://arxiv.org/abs/2405.19888v1",
        "abstract": "The rise of large language models (LLMs) has enabled LLM-based applications\n(a.k.a. AI agents or co-pilots), a new software paradigm that combines the\nstrength of LLM and conventional software. Diverse LLM applications from\ndifferent tenants could design complex workflows using multiple LLM requests to\naccomplish one task. However, they have to use the over-simplified\nrequest-level API provided by today's public LLM services, losing essential\napplication-level information. Public LLM services have to blindly optimize\nindividual LLM requests, leading to sub-optimal end-to-end performance of LLM\napplications.\n  This paper introduces Parrot, an LLM service system that focuses on the\nend-to-end experience of LLM-based applications. Parrot proposes Semantic\nVariable, a unified abstraction to expose application-level knowledge to public\nLLM services. A Semantic Variable annotates an input/output variable in the\nprompt of a request, and creates the data pipeline when connecting multiple LLM\nrequests, providing a natural way to program LLM applications. Exposing\nSemantic Variables to the public LLM service allows it to perform conventional\ndata flow analysis to uncover the correlation across multiple LLM requests.\nThis correlation opens a brand-new optimization space for the end-to-end\nperformance of LLM-based applications. Extensive evaluations demonstrate that\nParrot can achieve up to an order-of-magnitude improvement for popular and\npractical use cases of LLM applications.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Chaofan Lin",
            "Zhenhua Han",
            "Chengruidong Zhang",
            "Yuqing Yang",
            "Fan Yang",
            "Chen Chen",
            "Lili Qiu"
        ],
        "published": "2024-05-30T09:46:36Z"
    },
    {
        "title": "Federated Learning with Multi-resolution Model Broadcast",
        "link": "http://arxiv.org/abs/2405.19886v1",
        "abstract": "In federated learning, a server must periodically broadcast a model to the\nagents. We propose to use multi-resolution coding and modulation (also known as\nnon-uniform modulation) for this purpose. In the simplest instance, broadcast\ntransmission is used, whereby all agents are targeted with one and the same\ntransmission (typically without any particular favored beam direction), which\nis coded using multi-resolution coding/modulation. This enables high-SNR\nagents, with high path gains to the server, to receive a more accurate model\nthan the low-SNR agents do, without consuming more downlink resources. As one\nimplementation, we use transmission with a non-uniform 8-PSK constellation,\nwhere a high-SNR receiver (agent) can separate all 8 constellation points\n(hence receive 3 bits) whereas a low-SNR receiver can only separate 4 points\n(hence receive 2 bits). By encoding the least significant information in the\nthird bit, the high-SNR receivers can obtain the model with higher accuracy,\nwhile the low-SNR receiver can still obtain the model although with reduced\naccuracy, thereby facilitating at least some basic participation of the low-SNR\nreceiver. We show the effectiveness of our proposed scheme via experimentation\nusing federated learning with the MNIST data-set.",
        "subjects": [
            "cs.NI",
            "cs.LG"
        ],
        "authors": [
            "Henrik Rydén",
            "Reza Moosavi",
            "Erik G. Larsson"
        ],
        "published": "2024-05-30T09:45:18Z"
    },
    {
        "title": "Fourier Controller Networks for Real-Time Decision-Making in Embodied\n  Learning",
        "link": "http://arxiv.org/abs/2405.19885v1",
        "abstract": "Reinforcement learning is able to obtain generalized low-level robot policies\non diverse robotics datasets in embodied learning scenarios, and Transformer\nhas been widely used to model time-varying features. However, it still suffers\nfrom the issues of low data efficiency and high inference latency. In this\npaper, we propose to investigate the task from a new perspective of the\nfrequency domain. We first observe that the energy density in the frequency\ndomain of a robot's trajectory is mainly concentrated in the low-frequency\npart. Then, we present the Fourier Controller Network (FCNet), a new network\nthat utilizes the Short-Time Fourier Transform (STFT) to extract and encode\ntime-varying features through frequency domain interpolation. We further\nachieve parallel training and efficient recurrent inference by using FFT and\nSliding DFT methods in the model architecture for real-time decision-making.\nComprehensive analyses in both simulated (e.g., D4RL) and real-world\nenvironments (e.g., robot locomotion) demonstrate FCNet's substantial\nefficiency and effectiveness over existing methods such as Transformer, e.g.,\nFCNet outperforms Transformer on multi-environmental robotics datasets of all\ntypes of sizes (from 1.9M to 120M). The project page and code can be found\nhttps://thkkk.github.io/fcnet.",
        "subjects": [
            "cs.LG",
            "cs.RO"
        ],
        "authors": [
            "Hengkai Tan",
            "Songming Liu",
            "Kai Ma",
            "Chengyang Ying",
            "Xingxing Zhang",
            "Hang Su",
            "Jun Zhu"
        ],
        "published": "2024-05-30T09:43:59Z"
    },
    {
        "title": "From Words to Actions: Unveiling the Theoretical Underpinnings of\n  LLM-Driven Autonomous Systems",
        "link": "http://arxiv.org/abs/2405.19883v1",
        "abstract": "In this work, from a theoretical lens, we aim to understand why large\nlanguage model (LLM) empowered agents are able to solve decision-making\nproblems in the physical world. To this end, consider a hierarchical\nreinforcement learning (RL) model where the LLM Planner and the Actor perform\nhigh-level task planning and low-level execution, respectively. Under this\nmodel, the LLM Planner navigates a partially observable Markov decision process\n(POMDP) by iteratively generating language-based subgoals via prompting. Under\nproper assumptions on the pretraining data, we prove that the pretrained LLM\nPlanner effectively performs Bayesian aggregated imitation learning (BAIL)\nthrough in-context learning. Additionally, we highlight the necessity for\nexploration beyond the subgoals derived from BAIL by proving that naively\nexecuting the subgoals returned by LLM leads to a linear regret. As a remedy,\nwe introduce an $\\epsilon$-greedy exploration strategy to BAIL, which is proven\nto incur sublinear regret when the pretraining error is small. Finally, we\nextend our theoretical framework to include scenarios where the LLM Planner\nserves as a world model for inferring the transition model of the environment\nand to multi-agent settings, enabling coordination among multiple Actors.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Jianliang He",
            "Siyu Chen",
            "Fengzhuo Zhang",
            "Zhuoran Yang"
        ],
        "published": "2024-05-30T09:42:54Z"
    },
    {
        "title": "PixOOD: Pixel-Level Out-of-Distribution Detection",
        "link": "http://arxiv.org/abs/2405.19882v1",
        "abstract": "We propose a dense image prediction out-of-distribution detection algorithm,\ncalled PixOOD, which does not require training on samples of anomalous data and\nis not designed for a specific application which avoids traditional training\nbiases. In order to model the complex intra-class variability of the\nin-distribution data at the pixel level, we propose an online data condensation\nalgorithm which is more robust than standard K-means and is easily trainable\nthrough SGD. We evaluate PixOOD on a wide range of problems. It achieved\nstate-of-the-art results on four out of seven datasets, while being competitive\non the rest. The source code is available at https://github.com/vojirt/PixOOD.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Tomáš Vojíř",
            "Jan Šochman",
            "Jiří Matas"
        ],
        "published": "2024-05-30T09:41:10Z"
    },
    {
        "title": "Learning from Random Demonstrations: Offline Reinforcement Learning with\n  Importance-Sampled Diffusion Models",
        "link": "http://arxiv.org/abs/2405.19878v1",
        "abstract": "Generative models such as diffusion have been employed as world models in\noffline reinforcement learning to generate synthetic data for more effective\nlearning. Existing work either generates diffusion models one-time prior to\ntraining or requires additional interaction data to update it. In this paper,\nwe propose a novel approach for offline reinforcement learning with closed-loop\npolicy evaluation and world-model adaptation. It iteratively leverages a guided\ndiffusion world model to directly evaluate the offline target policy with\nactions drawn from it, and then performs an importance-sampled world model\nupdate to adaptively align the world model with the updated policy. We analyzed\nthe performance of the proposed method and provided an upper bound on the\nreturn gap between our method and the real environment under an optimal policy.\nThe result sheds light on various factors affecting learning performance.\nEvaluations in the D4RL environment show significant improvement over\nstate-of-the-art baselines, especially when only random or medium-expertise\ndemonstrations are available -- thus requiring improved alignment between the\nworld model and offline policy evaluation.",
        "subjects": [
            "cs.LG",
            "cs.GT"
        ],
        "authors": [
            "Zeyu Fang",
            "Tian Lan"
        ],
        "published": "2024-05-30T09:34:31Z"
    },
    {
        "title": "KNOW: A Real-World Ontology for Knowledge Capture with Large Language\n  Models",
        "link": "http://arxiv.org/abs/2405.19877v1",
        "abstract": "We present KNOW--the Knowledge Navigator Ontology for the World--the first\nontology designed to capture everyday knowledge to augment large language\nmodels (LLMs) in real-world generative AI use cases such as personal AI\nassistants. Our domain is human life, both its everyday concerns and its major\nmilestones. We have limited the initial scope of the modeled concepts to only\nestablished human universals: spacetime (places, events) plus social (people,\ngroups, organizations). The inclusion criteria for modeled concepts are\npragmatic, beginning with universality and utility. We compare and contrast\nprevious work such as Schema.org and Cyc--as well as attempts at a synthesis of\nknowledge graphs and language models--noting how LLMs already encode internally\nmuch of the commonsense tacit knowledge that took decades to capture in the Cyc\nproject. We also make available code-generated software libraries for the 12\nmost popular programming languages, enabling the direct use of ontology\nconcepts in software engineering. We emphasize simplicity and developer\nexperience in promoting AI interoperability.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "I.2.4; I.2.7"
        ],
        "authors": [
            "Arto Bendiken"
        ],
        "published": "2024-05-30T09:32:14Z"
    },
    {
        "title": "IReNe: Instant Recoloring in Neural Radiance Fields",
        "link": "http://arxiv.org/abs/2405.19876v1",
        "abstract": "Advances in NERFs have allowed for 3D scene reconstructions and novel view\nsynthesis. Yet, efficiently editing these representations while retaining\nphotorealism is an emerging challenge. Recent methods face three primary\nlimitations: they're slow for interactive use, lack precision at object\nboundaries, and struggle to ensure multi-view consistency. We introduce IReNe\nto address these limitations, enabling swift, near real-time color editing in\nNeRF. Leveraging a pre-trained NeRF model and a single training image with\nuser-applied color edits, IReNe swiftly adjusts network parameters in seconds.\nThis adjustment allows the model to generate new scene views, accurately\nrepresenting the color changes from the training image while also controlling\nobject boundaries and view-specific effects. Object boundary control is\nachieved by integrating a trainable segmentation module into the model. The\nprocess gains efficiency by retraining only the weights of the last network\nlayer. We observed that neurons in this layer can be classified into those\nresponsible for view-dependent appearance and those contributing to diffuse\nappearance. We introduce an automated classification approach to identify these\nneuron types and exclusively fine-tune the weights of the diffuse neurons. This\nfurther accelerates training and ensures consistent color edits across\ndifferent views. A thorough validation on a new dataset, with edited object\ncolors, shows significant quantitative and qualitative advancements over\ncompetitors, accelerating speeds by 5x to 500x.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Alessio Mazzucchelli",
            "Adrian Garcia-Garcia",
            "Elena Garces",
            "Fernando Rivas-Manzaneque",
            "Francesc Moreno-Noguer",
            "Adrian Penate-Sanchez"
        ],
        "published": "2024-05-30T09:30:28Z"
    },
    {
        "title": "Is In-Context Learning Sufficient for Instruction Following in LLMs?",
        "link": "http://arxiv.org/abs/2405.19874v1",
        "abstract": "In-context learning (ICL) allows LLMs to learn from examples without changing\ntheir weights, which is a particularly promising capability for long-context\nLLMs that can potentially learn from many examples. Recently, Lin et al. (2024)\nproposed URIAL, a method using only three in-context examples to align base\nLLMs, achieving non-trivial instruction following performance. In this work, we\nshow that, while effective, ICL alignment with URIAL still underperforms\ncompared to instruction fine-tuning on established benchmarks such as MT-Bench\nand AlpacaEval 2.0 (LC), especially with more capable base LMs. Unlike for\ntasks such as classification, translation, or summarization, adding more ICL\ndemonstrations for long-context LLMs does not systematically improve\ninstruction following performance. To address this limitation, we derive a\ngreedy selection approach for ICL examples that noticeably improves\nperformance, yet without bridging the gap to instruction fine-tuning. Finally,\nwe provide a series of ablation studies to better understand the reasons behind\nthe remaining gap, and we show how some aspects of ICL depart from the existing\nknowledge and are specific to the instruction tuning setting. Overall, our work\nadvances the understanding of ICL as an alignment technique. We provide our\ncode at https://github.com/tml-epfl/icl-alignment.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Hao Zhao",
            "Maksym Andriushchenko",
            "Francesco Croce",
            "Nicolas Flammarion"
        ],
        "published": "2024-05-30T09:28:56Z"
    },
    {
        "title": "Detection of the papermilling behavior",
        "link": "http://arxiv.org/abs/2405.19872v1",
        "abstract": "Based on the analysis of the data obtainable from the Web of Science\npublication and citation database, typical signs of possible papermilling\nbehavior are described, quantified, and illustrated by examples. A MATLAB\nfunction is provided for the analysis of the outputs from the Web of Science. A\nnew quantitative indicator -- integrity index, or I-index -- is proposed for\nusing it along with standard bibliographic and scientometric indicators.",
        "subjects": [
            "cs.DL",
            "01A90, 01A61"
        ],
        "authors": [
            "Igor Podlubny"
        ],
        "published": "2024-05-30T09:27:34Z"
    },
    {
        "title": "Don't Get Hijacked: Prevalence, Mitigation, and Impact of Non-Secure DNS\n  Dynamic Updates",
        "link": "http://arxiv.org/abs/2405.19871v1",
        "abstract": "DNS dynamic updates represent an inherently vulnerable mechanism deliberately\ngranting the potential for any host to dynamically modify DNS zone files.\nConsequently, this feature exposes domains to various security risks such as\ndomain hijacking, compromise of domain control validation, and\nman-in-the-middle attacks. Originally devised without the implementation of\nauthentication mechanisms, non-secure DNS updates were widely adopted in DNS\nsoftware, subsequently leaving domains susceptible to a novel form of attack\ntermed zone poisoning. In order to gauge the extent of this issue, our analysis\nencompassed over 353 million domain names, revealing the presence of 381,965\ndomains that openly accepted unsolicited DNS updates. We then undertook a\ncomprehensive three-phase campaign involving the notification of Computer\nSecurity Incident Response Teams (CSIRTs). Following extensive discussions\nspanning six months, we observed substantial remediation, with nearly 54\\% of\nnameservers and 98% of vulnerable domains addressing the issue. This outcome\nserves as evidence that engaging with CSIRTs can prove to be an effective\napproach for reporting security vulnerabilities. Moreover, our notifications\nhad a lasting impact, as evidenced by the sustained low prevalence of\nvulnerable domains.",
        "subjects": [
            "cs.CR",
            "cs.NI"
        ],
        "authors": [
            "Yevheniya Nosyk",
            "Maciej Korczyński",
            "Carlos H. Gañán",
            "Michał Król",
            "Qasim Lone",
            "Andrzej Duda"
        ],
        "published": "2024-05-30T09:23:53Z"
    },
    {
        "title": "On Vessel Location Forecasting and the Effect of Federated Learning",
        "link": "http://arxiv.org/abs/2405.19870v1",
        "abstract": "The wide spread of Automatic Identification System (AIS) has motivated\nseveral maritime analytics operations. Vessel Location Forecasting (VLF) is one\nof the most critical operations for maritime awareness. However, accurate VLF\nis a challenging problem due to the complexity and dynamic nature of maritime\ntraffic conditions. Furthermore, as privacy concerns and restrictions have\ngrown, training data has become increasingly fragmented, resulting in dispersed\ndatabases of several isolated data silos among different organizations, which\nin turn decreases the quality of learning models. In this paper, we propose an\nefficient VLF solution based on LSTM neural networks, in two variants, namely\nNautilus and FedNautilus for the centralized and the federated learning\napproach, respectively. We also demonstrate the superiority of the centralized\napproach with respect to current state of the art and discuss the advantages\nand disadvantages of the federated against the centralized approach.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Andreas Tritsarolis",
            "Nikos Pelekis",
            "Konstantina Bereta",
            "Dimitris Zissis",
            "Yannis Theodoridis"
        ],
        "published": "2024-05-30T09:23:48Z"
    },
    {
        "title": "Semantic Landmark Detection & Classification Using Neural Networks For\n  3D In-Air Sonar",
        "link": "http://arxiv.org/abs/2405.19869v1",
        "abstract": "In challenging environments where traditional sensing modalities struggle,\nin-air sonar offers resilience to optical interference. Placing a priori known\nlandmarks in these environments can eliminate accumulated errors in autonomous\nmobile systems such as Simultaneous Localization and Mapping (SLAM) and\nautonomous navigation. We present a novel approach using a convolutional neural\nnetwork to detect and classify ten different reflector landmarks with varying\nradii using in-air 3D sonar. Additionally, the network predicts the orientation\nangle of the detected landmarks. The neural network is trained on cochleograms,\nrepresenting echoes received by the sensor in a time-frequency domain.\nExperimental results in cluttered indoor settings show promising performance.\nThe CNN achieves a 97.3% classification accuracy on the test dataset,\naccurately detecting both the presence and absence of landmarks. Moreover, the\nnetwork predicts landmark orientation angles with an RMSE lower than 10\ndegrees, enhancing the utility in SLAM and autonomous navigation applications.\nThis advancement improves the robustness and accuracy of autonomous systems in\nchallenging environments.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Wouter Jansen",
            "Jan Steckel"
        ],
        "published": "2024-05-30T09:22:31Z"
    },
    {
        "title": "Out-of-distribution Reject Option Method for Dataset Shift Problem in\n  Early Disease Onset Prediction",
        "link": "http://arxiv.org/abs/2405.19864v1",
        "abstract": "Machine learning is increasingly used to predict lifestyle-related disease\nonset using health and medical data. However, the prediction effectiveness is\nhindered by dataset shift, which involves discrepancies in data distribution\nbetween the training and testing datasets, misclassifying out-of-distribution\n(OOD) data. To diminish dataset shift effects, this paper proposes the\nout-of-distribution reject option for prediction (ODROP), which integrates OOD\ndetection models to preclude OOD data from the prediction phase. We\ninvestigated the efficacy of five OOD detection methods (variational\nautoencoder, neural network ensemble std, neural network ensemble epistemic,\nneural network energy, and neural network gaussian mixture based energy\nmeasurement) across two datasets, the Hirosaki and Wakayama health checkup\ndata, in the context of three disease onset prediction tasks: diabetes,\ndyslipidemia, and hypertension. To evaluate the ODROP method, we trained\ndisease onset prediction models and OOD detection models on Hirosaki data and\nused AUROC-rejection curve plots from Wakayama data. The variational\nautoencoder method showed superior stability and magnitude of improvement in\nArea Under the Receiver Operating Curve (AUROC) in five cases: AUROC in the\nWakayama data was improved from 0.80 to 0.90 at a 31.1% rejection rate for\ndiabetes onset and from 0.70 to 0.76 at a 34% rejection rate for dyslipidemia.\nWe categorized dataset shifts into two types using SHAP clustering - those that\nconsiderably affect predictions and those that do not. We expect that this\nclassification will help standardize measuring instruments. This study is the\nfirst to apply OOD detection to actual health and medical data, demonstrating\nits potential to substantially improve the accuracy and reliability of disease\nprediction models amidst dataset shift.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.AP"
        ],
        "authors": [
            "Taisei Tosaki",
            "Eiichiro Uchino",
            "Ryosuke Kojima",
            "Yohei Mineharu",
            "Mikio Arita",
            "Nobuyuki Miyai",
            "Yoshinori Tamada",
            "Tatsuya Mikami",
            "Koichi Murashita",
            "Shigeyuki Nakaji",
            "Yasushi Okuno"
        ],
        "published": "2024-05-30T09:14:01Z"
    },
    {
        "title": "Hierarchical Object-Centric Learning with Capsule Networks",
        "link": "http://arxiv.org/abs/2405.19861v1",
        "abstract": "Capsule networks (CapsNets) were introduced to address convolutional neural\nnetworks limitations, learning object-centric representations that are more\nrobust, pose-aware, and interpretable. They organize neurons into groups called\ncapsules, where each capsule encodes the instantiation parameters of an object\nor one of its parts. Moreover, a routing algorithm connects capsules in\ndifferent layers, thereby capturing hierarchical part-whole relationships in\nthe data.\n  This thesis investigates the intriguing aspects of CapsNets and focuses on\nthree key questions to unlock their full potential. First, we explore the\neffectiveness of the routing algorithm, particularly in small-sized networks.\nWe propose a novel method that anneals the number of routing iterations during\ntraining, enhancing performance in architectures with fewer parameters.\n  Secondly, we investigate methods to extract more effective first-layer\ncapsules, also known as primary capsules. By exploiting pruned backbones, we\naim to improve computational efficiency by reducing the number of capsules\nwhile achieving high generalization. This approach reduces CapsNets memory\nrequirements and computational effort.\n  Third, we explore part-relationship learning in CapsNets. Through extensive\nresearch, we demonstrate that capsules with low entropy can extract more\nconcise and discriminative part-whole relationships compared to traditional\ncapsule networks, even with reasonable network sizes.\n  Lastly, we showcase how CapsNets can be utilized in real-world applications,\nincluding autonomous localization of unmanned aerial vehicles, quaternion-based\nrotations prediction in synthetic datasets, and lung nodule segmentation in\nbiomedical imaging.\n  The findings presented in this thesis contribute to a deeper understanding of\nCapsNets and highlight their potential to address complex computer vision\nchallenges.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Riccardo Renzulli"
        ],
        "published": "2024-05-30T09:10:33Z"
    },
    {
        "title": "DevEval: A Manually-Annotated Code Generation Benchmark Aligned with\n  Real-World Code Repositories",
        "link": "http://arxiv.org/abs/2405.19856v1",
        "abstract": "How to evaluate the coding abilities of Large Language Models (LLMs) remains\nan open question. We find that existing benchmarks are poorly aligned with\nreal-world code repositories and are insufficient to evaluate the coding\nabilities of LLMs.\n  To address the knowledge gap, we propose a new benchmark named DevEval, which\nhas three advances. (1) DevEval aligns with real-world repositories in multiple\ndimensions, e.g., code distributions and dependency distributions. (2) DevEval\nis annotated by 13 developers and contains comprehensive annotations (e.g.,\nrequirements, original repositories, reference code, and reference\ndependencies). (3) DevEval comprises 1,874 testing samples from 117\nrepositories, covering 10 popular domains (e.g., Internet, Database). Based on\nDevEval, we propose repository-level code generation and evaluate 8 popular\nLLMs on DevEval (e.g., gpt-4, gpt-3.5, StarCoder 2, DeepSeek Coder, CodeLLaMa).\nOur experiments reveal these LLMs' coding abilities in real-world code\nrepositories. For example, in our experiments, the highest Pass@1 of\ngpt-4-turbo is only 53.04%. We also analyze LLMs' failed cases and summarize\ntheir shortcomings. We hope DevEval can facilitate the development of LLMs in\nreal code repositories. DevEval, prompts, and LLMs' predictions have been\nreleased.",
        "subjects": [
            "cs.CL",
            "cs.SE"
        ],
        "authors": [
            "Jia Li",
            "Ge Li",
            "Yunfei Zhao",
            "Yongmin Li",
            "Huanyu Liu",
            "Hao Zhu",
            "Lecheng Wang",
            "Kaibo Liu",
            "Zheng Fang",
            "Lanshen Wang",
            "Jiazheng Ding",
            "Xuanming Zhang",
            "Yuqi Zhu",
            "Yihong Dong",
            "Zhi Jin",
            "Binhua Li",
            "Fei Huang",
            "Yongbin Li"
        ],
        "published": "2024-05-30T09:03:42Z"
    },
    {
        "title": "RTGen: Generating Region-Text Pairs for Open-Vocabulary Object Detection",
        "link": "http://arxiv.org/abs/2405.19854v1",
        "abstract": "Open-vocabulary object detection (OVD) requires solid modeling of the\nregion-semantic relationship, which could be learned from massive region-text\npairs. However, such data is limited in practice due to significant annotation\ncosts. In this work, we propose RTGen to generate scalable open-vocabulary\nregion-text pairs and demonstrate its capability to boost the performance of\nopen-vocabulary object detection. RTGen includes both text-to-region and\nregion-to-text generation processes on scalable image-caption data. The\ntext-to-region generation is powered by image inpainting, directed by our\nproposed scene-aware inpainting guider for overall layout harmony. For\nregion-to-text generation, we perform multiple region-level image captioning\nwith various prompts and select the best matching text according to CLIP\nsimilarity. To facilitate detection training on region-text pairs, we also\nintroduce a localization-aware region-text contrastive loss that learns object\nproposals tailored with different localization qualities. Extensive experiments\ndemonstrate that our RTGen can serve as a scalable, semantically rich, and\neffective source for open-vocabulary object detection and continue to improve\nthe model performance when more data is utilized, delivering superior\nperformance compared to the existing state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Fangyi Chen",
            "Han Zhang",
            "Zhantao Yang",
            "Hao Chen",
            "Kai Hu",
            "Marios Savvides"
        ],
        "published": "2024-05-30T09:03:23Z"
    },
    {
        "title": "Guardians of DNS Integrity: A Remote Method for Identifying DNSSEC\n  Validators Across the Internet",
        "link": "http://arxiv.org/abs/2405.19851v1",
        "abstract": "DNS Security Extensions (DNSSEC) provide the most effective way to fight DNS\ncache poisoning attacks. Yet, very few DNS resolvers perform DNSSEC validation.\nIdentifying such systems is non-trivial and the existing methods are not\nsuitable for Internet-scale measurements. In this paper, we propose a novel\nremote technique for identifying DNSSEC-validating resolvers. The proposed\nmethod consists of two steps. In the first step, we identify open resolvers by\nscanning 3.1 billion end hosts and request every non-forwarder to resolve one\ncorrect and seven deliberately misconfigured domains. We then build a\nclassifier that discriminates validators from non-validators based on query\npatterns and DNS response codes. We find that while most open resolvers are\nDNSSEC-enabled, less than 18% in IPv4 (38% in IPv6) validate received\nresponses. In the second step, we remotely identify closed non-forwarders in\nnetworks that do not have inbound Source Address Validation (SAV) in place.\nUsing the classifier built in step one, we identify 37.4% IPv4 (42.9% IPv6)\nclosed DNSSEC validators and cross-validate the results using RIPE Atlas\nprobes. Finally, we show that the discovered (non)-validators actively send\nrequests to DNS root servers, suggesting that we deal with operational\nrecursive resolvers rather than misconfigured machines.",
        "subjects": [
            "cs.CR",
            "cs.NI"
        ],
        "authors": [
            "Yevheniya Nosyk",
            "Maciej Korczyński",
            "Andrzej Duda"
        ],
        "published": "2024-05-30T08:58:18Z"
    },
    {
        "title": "Deciphering Human Mobility: Inferring Semantics of Trajectories with\n  Large Language Models",
        "link": "http://arxiv.org/abs/2405.19850v1",
        "abstract": "Understanding human mobility patterns is essential for various applications,\nfrom urban planning to public safety. The individual trajectory such as mobile\nphone location data, while rich in spatio-temporal information, often lacks\nsemantic detail, limiting its utility for in-depth mobility analysis. Existing\nmethods can infer basic routine activity sequences from this data, lacking\ndepth in understanding complex human behaviors and users' characteristics.\nAdditionally, they struggle with the dependency on hard-to-obtain auxiliary\ndatasets like travel surveys. To address these limitations, this paper defines\ntrajectory semantic inference through three key dimensions: user occupation\ncategory, activity sequence, and trajectory description, and proposes the\nTrajectory Semantic Inference with Large Language Models (TSI-LLM) framework to\nleverage LLMs infer trajectory semantics comprehensively and deeply. We adopt\nspatio-temporal attributes enhanced data formatting (STFormat) and design a\ncontext-inclusive prompt, enabling LLMs to more effectively interpret and infer\nthe semantics of trajectory data. Experimental validation on real-world\ntrajectory datasets demonstrates the efficacy of TSI-LLM in deciphering complex\nhuman mobility patterns. This study explores the potential of LLMs in enhancing\nthe semantic analysis of trajectory data, paving the way for more sophisticated\nand accessible human mobility research.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Yuxiao Luo",
            "Zhongcai Cao",
            "Xin Jin",
            "Kang Liu",
            "Ling Yin"
        ],
        "published": "2024-05-30T08:55:48Z"
    },
    {
        "title": "Quest: Query-centric Data Synthesis Approach for Long-context Scaling of\n  Large Language Model",
        "link": "http://arxiv.org/abs/2405.19846v1",
        "abstract": "Large language models, initially pre-trained with a limited context length,\ncan better handle longer texts by continuing training on a corpus with extended\ncontexts. However, obtaining effective long-context data is challenging due to\nthe scarcity and uneven distribution of long documents across different\ndomains. To address this issue, we propose a Query-centric data synthesis\nmethod, abbreviated as Quest. Quest is an interpretable method based on the\nobservation that documents retrieved by similar queries are relevant but\nlow-redundant, thus well-suited for synthesizing long-context data. The method\nis also scalable and capable of constructing large amounts of long-context\ndata. Using Quest, we synthesize a long-context dataset up to 128k context\nlength, significantly outperforming other data synthesis methods on multiple\nlong-context benchmark datasets. In addition, we further verify that the Quest\nmethod is predictable through scaling law experiments, making it a reliable\nsolution for advancing long-context models.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Chaochen Gao",
            "Xing Wu",
            "Qi Fu",
            "Songlin Hu"
        ],
        "published": "2024-05-30T08:50:55Z"
    },
    {
        "title": "Assessing the impact of weather-induced uncertainties in large-scale\n  electricity systems",
        "link": "http://arxiv.org/abs/2405.19845v1",
        "abstract": "The future energy system will largely depend on volatile renewable energy\nsources and temperature-dependent loads, which makes the weather a central\ninfluencing factor. This article presents a novel approach for simulating\nweather scenarios for robust large-scale power system analysis. By applying\ndifferent signal analysis methods, historical weather data is decomposed into\nits spectral components, processed appropriately, and then used to generate\nrandom, self-consistent weather data. In this process, any weather parameters\nof different locations can be considered, while their respective dependencies\nare mapped. The added value is demonstrated by coupling with a state-of-the-art\nlarge-scale energy system model for Europe. It is shown that the integrated\nconsideration of different weather influences allows a quantification of the\nrange of fluctuation of various parameters - such as the feed-in of wind and\nsolar power - and thus provides the basis for future resilient grid planning\napproaches.",
        "subjects": [
            "eess.SY",
            "cs.SY"
        ],
        "authors": [
            "Jan Peper",
            "David Kröger",
            "Jonathan Kipp",
            "Florian Ziel",
            "Christian Rehtanz"
        ],
        "published": "2024-05-30T08:50:53Z"
    },
    {
        "title": "The Neumann boundary condition for the two-dimensional Lax-Wendroff\n  scheme. II",
        "link": "http://arxiv.org/abs/2405.19844v1",
        "abstract": "We study the stability of a two-dimensional Lax-Wendroff scheme in a\nquarter-plane. Following our previous work, we aim here at adapting the energy\nmethod in order to study second order extrapolation boundary conditions. We\nfirst show on the one-dimensional problem why modifying the energy is a\nnecessity in order to obtain stability estimates. We then study the\ntwo-dimensional case and propose a modified energy as well as second order\nextrapolation boundary and corner conditions in order to maintain second order\naccuracy and stability of the whole scheme, including near the corner.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Antoine Benoit",
            "Jean-François Coulombel"
        ],
        "published": "2024-05-30T08:50:41Z"
    },
    {
        "title": "How Gold to Make the Golden Snitch: Designing the \"Game Changer\" in\n  Esports",
        "link": "http://arxiv.org/abs/2405.19843v1",
        "abstract": "Many battling games utilize a special item (e.g. Roshan in Defense of the\nAncients 2 (DOTA 2), Baron Nashor in League of Legends (LOL), Golden Snitch in\nQuidditch) as a potential ``Game Changer''. The reward of this item can enable\nthe underdog to make a comeback. However, if the reward is excessively high,\nthe whole game may devolve into a chase for the ``Game Changer''. Our research\ninitiates with a Quidditch case study, a fictional sport in Harry Potter\nseries, wherein we architect the Golden Snitch's reward to maximize the\naudience's surprise. Surprisingly, we discover that for equally competent\nteams, the optimal Snitch reward is zero. Moreover, we establish that under\nmost circumstances the optimal score aligns with the game's expected duration\nmultiplied by the teams' strength difference. Finally, we explore the\ncorrelation between the ``Game Changer's'' reward and audience surprise in\nMultiplayer Online Battle Arena (MOBA) games including DOTA 2 and LOL, finding\nthat the optimal reward escalates with increasing team strength inequality.",
        "subjects": [
            "cs.GT"
        ],
        "authors": [
            "Zhihuan Huang",
            "Yuxuan Lu",
            "Yongkang Guo",
            "Yuqing Kong"
        ],
        "published": "2024-05-30T08:50:37Z"
    },
    {
        "title": "Improve Student's Reasoning Generalizability through Cascading\n  Decomposed CoTs Distillation",
        "link": "http://arxiv.org/abs/2405.19842v1",
        "abstract": "Large language models (LLMs) exhibit enhanced reasoning at larger scales,\ndriving efforts to distill these capabilities into smaller models via\nteacher-student learning. Previous works simply fine-tune student models on\nteachers' generated Chain-of-Thoughts (CoTs) data. Although these methods\nenhance in-domain (IND) reasoning performance, they struggle to generalize to\nout-of-domain (OOD) tasks. We believe that the widespread spurious correlations\nbetween questions and answers may lead the model to preset a specific answer\nwhich restricts the diversity and generalizability of its reasoning process. In\nthis paper, we propose Cascading Decomposed CoTs Distillation (CasCoD) to\naddress these issues by decomposing the traditional single-step learning\nprocess into two cascaded learning steps. Specifically, by restructuring the\ntraining objectives -- removing the answer from outputs and concatenating the\nquestion with the rationale as input -- CasCoD's two-step learning process\nensures that students focus on learning rationales without interference from\nthe preset answers, thus improving reasoning generalizability. Extensive\nexperiments demonstrate the effectiveness of CasCoD on both IND and OOD\nbenchmark reasoning datasets. Code can be found at\nhttps://github.com/C-W-D/CasCoD.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Chengwei Dai",
            "Kun Li",
            "Wei Zhou",
            "Songlin Hu"
        ],
        "published": "2024-05-30T08:49:34Z"
    },
    {
        "title": "Lifelong learning challenges in the era of artificial intelligence: a\n  computational thinking perspective",
        "link": "http://arxiv.org/abs/2405.19837v1",
        "abstract": "The rapid advancement of artificial intelligence (AI) has brought significant\nchallenges to the education and workforce skills required to take advantage of\nAI for human-AI collaboration in the workplace. As AI continues to reshape\nindustries and job markets, the need to define how AI literacy can be\nconsidered in lifelong learning has become increasingly critical (Cetindamar et\nal., 2022; Laupichler et al., 2022; Romero et al., 2023). Like any new\ntechnology, AI is the subject of both hopes and fears, and what it entails\ntoday presents major challenges (Cugurullo \\& Acheampong, 2023; Villani et al.,\n2018). It also raises profound questions about our own humanity. Will the\nmachine surpass the intelligence of the humans who designed it? What will be\nthe relationship between so-called AI and our human intelligences? How could\nhuman-AI collaboration be regulated in a way that serves the Sustainable\nDevelopment Goals (SDGs)? This paper provides a review of the challenges of\nlifelong learning in the era of AI from a computational thinking, critical\nthinking, and creative competencies perspective, highlighting the implications\nfor management and leadership in organizations.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Margarida Romero"
        ],
        "published": "2024-05-30T08:46:11Z"
    },
    {
        "title": "The Merit of River Network Topology for Neural Flood Forecasting",
        "link": "http://arxiv.org/abs/2405.19836v1",
        "abstract": "Climate change exacerbates riverine floods, which occur with higher frequency\nand intensity than ever. The much-needed forecasting systems typically rely on\naccurate river discharge predictions. To this end, the SOTA data-driven\napproaches treat forecasting at spatially distributed gauge stations as\nisolated problems, even within the same river network. However, incorporating\nthe known topology of the river network into the prediction model has the\npotential to leverage the adjacency relationship between gauges. Thus, we model\nriver discharge for a network of gauging stations with GNNs and compare the\nforecasting performance achieved by different adjacency definitions. Our\nresults show that the model fails to benefit from the river network topology\ninformation, both on the entire network and small subgraphs. The learned edge\nweights correlate with neither of the static definitions and exhibit no regular\npattern. Furthermore, the GNNs struggle to predict sudden, narrow discharge\nspikes. Our work hints at a more general underlying phenomenon of neural\nprediction not always benefitting from graphical structure and may inspire a\nsystematic study of the conditions under which this happens.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Nikolas Kirschstein",
            "Yixuan Sun"
        ],
        "published": "2024-05-30T08:45:45Z"
    },
    {
        "title": "KITRO: Refining Human Mesh by 2D Clues and Kinematic-tree Rotation",
        "link": "http://arxiv.org/abs/2405.19833v1",
        "abstract": "2D keypoints are commonly used as an additional cue to refine estimated 3D\nhuman meshes. Current methods optimize the pose and shape parameters with a\nreprojection loss on the provided 2D keypoints. Such an approach, while simple\nand intuitive, has limited effectiveness because the optimal solution is hard\nto find in ambiguous parameter space and may sacrifice depth. Additionally,\ndivergent gradients from distal joints complicate and deviate the refinement of\nproximal joints in the kinematic chain. To address these, we introduce\nKinematic-Tree Rotation (KITRO), a novel mesh refinement strategy that\nexplicitly models depth and human kinematic-tree structure. KITRO treats\nrefinement from a bone-wise perspective. Unlike previous methods which perform\ngradient-based optimizations, our method calculates bone directions in closed\nform. By accounting for the 2D pose, bone length, and parent joint's depth, the\ncalculation results in two possible directions for each child joint. We then\nuse a decision tree to trace binary choices for all bones along the human\nskeleton's kinematic-tree to select the most probable hypothesis. Our\nexperiments across various datasets and baseline models demonstrate that KITRO\nsignificantly improves 3D joint estimation accuracy and achieves an ideal 2D\nfit simultaneously. Our code available at: https://github.com/MartaYang/KITRO.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Fengyuan Yang",
            "Kerui Gu",
            "Angela Yao"
        ],
        "published": "2024-05-30T08:44:12Z"
    },
    {
        "title": "AI Safety: A Climb To Armageddon?",
        "link": "http://arxiv.org/abs/2405.19832v1",
        "abstract": "This paper presents an argument that certain AI safety measures, rather than\nmitigating existential risk, may instead exacerbate it. Under certain key\nassumptions - the inevitability of AI failure, the expected correlation between\nan AI system's power at the point of failure and the severity of the resulting\nharm, and the tendency of safety measures to enable AI systems to become more\npowerful before failing - safety efforts have negative expected utility. The\npaper examines three response strategies: Optimism, Mitigation, and Holism.\nEach faces challenges stemming from intrinsic features of the AI safety\nlandscape that we term Bottlenecking, the Perfection Barrier, and Equilibrium\nFluctuation. The surprising robustness of the argument forces a re-examination\nof core assumptions around AI safety and points to several avenues for further\nresearch.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Herman Cappelen",
            "Josh Dever",
            "John Hawthorne"
        ],
        "published": "2024-05-30T08:41:54Z"
    },
    {
        "title": "Just Rewrite It Again: A Post-Processing Method for Enhanced Semantic\n  Similarity and Privacy Preservation of Differentially Private Rewritten Text",
        "link": "http://arxiv.org/abs/2405.19831v1",
        "abstract": "The study of Differential Privacy (DP) in Natural Language Processing often\nviews the task of text privatization as a $\\textit{rewriting}$ task, in which\nsensitive input texts are rewritten to hide explicit or implicit private\ninformation. In order to evaluate the privacy-preserving capabilities of a DP\ntext rewriting mechanism, $\\textit{empirical privacy}$ tests are frequently\nemployed. In these tests, an adversary is modeled, who aims to infer sensitive\ninformation (e.g., gender) about the author behind a (privatized) text. Looking\nto improve the empirical protections provided by DP rewriting methods, we\npropose a simple post-processing method based on the goal of aligning rewritten\ntexts with their original counterparts, where DP rewritten texts are rewritten\n$\\textit{again}$. Our results shown that such an approach not only produces\noutputs that are more semantically reminiscent of the original inputs, but also\ntexts which score on average better in empirical privacy evaluations.\nTherefore, our approach raises the bar for DP rewriting methods in their\nempirical privacy evaluations, providing an extra layer of protection against\nmalicious adversaries.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Stephen Meisenbacher",
            "Florian Matthes"
        ],
        "published": "2024-05-30T08:41:33Z"
    },
    {
        "title": "Joint Selective State Space Model and Detrending for Robust Time Series\n  Anomaly Detection",
        "link": "http://arxiv.org/abs/2405.19823v1",
        "abstract": "Deep learning-based sequence models are extensively employed in Time Series\nAnomaly Detection (TSAD) tasks due to their effective sequential modeling\ncapabilities. However, the ability of TSAD is limited by two key challenges:\n(i) the ability to model long-range dependency and (ii) the generalization\nissue in the presence of non-stationary data. To tackle these challenges, an\nanomaly detector that leverages the selective state space model known for its\nproficiency in capturing long-term dependencies across various domains is\nproposed. Additionally, a multi-stage detrending mechanism is introduced to\nmitigate the prominent trend component in non-stationary data to address the\ngeneralization issue. Extensive experiments conducted on realworld public\ndatasets demonstrate that the proposed methods surpass all 12 compared baseline\nmethods.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Junqi Chen",
            "Xu Tan",
            "Sylwan Rahardja",
            "Jiawei Yang",
            "Susanto Rahardja"
        ],
        "published": "2024-05-30T08:31:18Z"
    },
    {
        "title": "Improving Object Detector Training on Synthetic Data by Starting With a\n  Strong Baseline Methodology",
        "link": "http://arxiv.org/abs/2405.19822v1",
        "abstract": "Collecting and annotating real-world data for the development of object\ndetection models is a time-consuming and expensive process. In the military\ndomain in particular, data collection can also be dangerous or infeasible.\nTraining models on synthetic data may provide a solution for cases where access\nto real-world training data is restricted. However, bridging the reality gap\nbetween synthetic and real data remains a challenge. Existing methods usually\nbuild on top of baseline Convolutional Neural Network (CNN) models that have\nbeen shown to perform well when trained on real data, but have limited ability\nto perform well when trained on synthetic data. For example, some architectures\nallow for fine-tuning with the expectation of large quantities of training data\nand are prone to overfitting on synthetic data. Related work usually ignores\nvarious best practices from object detection on real data, e.g. by training on\nsynthetic data from a single environment with relatively little variation. In\nthis paper we propose a methodology for improving the performance of a\npre-trained object detector when training on synthetic data. Our approach\nfocuses on extracting the salient information from synthetic data without\nforgetting useful features learned from pre-training on real images. Based on\nthe state of the art, we incorporate data augmentation methods and a\nTransformer backbone. Besides reaching relatively strong performance without\nany specialized synthetic data transfer methods, we show that our methods\nimprove the state of the art on synthetic data trained object detection for the\nRarePlanes and DGTA-VisDrone datasets, and reach near-perfect performance on an\nin-house vehicle detection dataset.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.ET"
        ],
        "authors": [
            "Frank A. Ruis",
            "Alma M. Liezenga",
            "Friso G. Heslinga",
            "Luca Ballan",
            "Thijs A. Eker",
            "Richard J. M. den Hollander",
            "Martin C. van Leeuwen",
            "Judith Dijk",
            "Wyke Huizinga"
        ],
        "published": "2024-05-30T08:31:01Z"
    },
    {
        "title": "Gated Fields: Learning Scene Reconstruction from Gated Videos",
        "link": "http://arxiv.org/abs/2405.19819v1",
        "abstract": "Reconstructing outdoor 3D scenes from temporal observations is a challenge\nthat recent work on neural fields has offered a new avenue for. However,\nexisting methods that recover scene properties, such as geometry, appearance,\nor radiance, solely from RGB captures often fail when handling poorly-lit or\ntexture-deficient regions. Similarly, recovering scenes with scanning LiDAR\nsensors is also difficult due to their low angular sampling rate which makes\nrecovering expansive real-world scenes difficult. Tackling these gaps, we\nintroduce Gated Fields - a neural scene reconstruction method that utilizes\nactive gated video sequences. To this end, we propose a neural rendering\napproach that seamlessly incorporates time-gated capture and illumination. Our\nmethod exploits the intrinsic depth cues in the gated videos, achieving precise\nand dense geometry reconstruction irrespective of ambient illumination\nconditions. We validate the method across day and night scenarios and find that\nGated Fields compares favorably to RGB and LiDAR reconstruction methods. Our\ncode and datasets are available at https://light.princeton.edu/gatedfields/.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Andrea Ramazzina",
            "Stefanie Walz",
            "Pragyan Dahal",
            "Mario Bijelic",
            "Felix Heide"
        ],
        "published": "2024-05-30T08:26:47Z"
    },
    {
        "title": "WebUOT-1M: Advancing Deep Underwater Object Tracking with A\n  Million-Scale Benchmark",
        "link": "http://arxiv.org/abs/2405.19818v1",
        "abstract": "Underwater object tracking (UOT) is a foundational task for identifying and\ntracing submerged entities in underwater video sequences. However, current UOT\ndatasets suffer from limitations in scale, diversity of target categories and\nscenarios covered, hindering the training and evaluation of modern tracking\nalgorithms. To bridge this gap, we take the first step and introduce WebUOT-1M,\n\\ie, the largest public UOT benchmark to date, sourced from complex and\nrealistic underwater environments. It comprises 1.1 million frames across 1,500\nvideo clips filtered from 408 target categories, largely surpassing previous\nUOT datasets, \\eg, UVOT400. Through meticulous manual annotation and\nverification, we provide high-quality bounding boxes for underwater targets.\nAdditionally, WebUOT-1M includes language prompts for video sequences,\nexpanding its application areas, \\eg, underwater vision-language tracking. Most\nexisting trackers are tailored for open-air environments, leading to\nperformance degradation when applied to UOT due to domain gaps. Retraining and\nfine-tuning these trackers are challenging due to sample imbalances and limited\nreal-world underwater datasets. To tackle these challenges, we propose a novel\nomni-knowledge distillation framework based on WebUOT-1M, incorporating various\nstrategies to guide the learning of the student Transformer. To the best of our\nknowledge, this framework is the first to effectively transfer open-air domain\nknowledge to the UOT model through knowledge distillation, as demonstrated by\nresults on both existing UOT datasets and the newly proposed WebUOT-1M.\nFurthermore, we comprehensively evaluate WebUOT-1M using 30 deep trackers,\nshowcasing its value as a benchmark for UOT research by presenting new\nchallenges and opportunities for future studies. The complete dataset, codes\nand tracking results, will be made publicly available.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Chunhui Zhang",
            "Li Liu",
            "Guanjie Huang",
            "Hao Wen",
            "Xi Zhou",
            "Yanfeng Wang"
        ],
        "published": "2024-05-30T08:25:21Z"
    },
    {
        "title": "Performance Examination of Symbolic Aggregate Approximation in IoT\n  Applications",
        "link": "http://arxiv.org/abs/2405.19817v1",
        "abstract": "Symbolic Aggregate approXimation (SAX) is a common dimensionality reduction\napproach for time-series data which has been employed in a variety of domains,\nincluding classification and anomaly detection in time-series data. Domains\nalso include shape recognition where the shape outline is converted into\ntime-series data forinstance epoch classification of archived arrowheads. In\nthis paper we propose a dimensionality reduction and shape recognition approach\nbased on the SAX algorithm, an application which requires responses on cost\nefficient, IoT-like, platforms. The challenge is largely dealing with the\ncomputational expense of the SAX algorithm in IoT-like applications, from\nsimple time-series dimension reduction through shape recognition. The approach\nis based on lowering the dimensional space while capturing and preserving the\nmost representative features of the shape. We present three scenarios of\nincreasing computational complexity backing up our statements with measurement\nof performance characteristics",
        "subjects": [
            "cs.CV",
            "cs.RO"
        ],
        "authors": [
            "Suzana Veljanovska",
            "Hans Dermot Doran"
        ],
        "published": "2024-05-30T08:24:00Z"
    },
    {
        "title": "Growing Tiny Networks: Spotting Expressivity Bottlenecks and Fixing Them\n  Optimally",
        "link": "http://arxiv.org/abs/2405.19816v1",
        "abstract": "Machine learning tasks are generally formulated as optimization problems,\nwhere one searches for an optimal function within a certain functional space.\nIn practice, parameterized functional spaces are considered, in order to be\nable to perform gradient descent. Typically, a neural network architecture is\nchosen and fixed, and its parameters (connection weights) are optimized,\nyielding an architecture-dependent result. This way of proceeding however\nforces the evolution of the function during training to lie within the realm of\nwhat is expressible with the chosen architecture, and prevents any optimization\nacross architectures. Costly architectural hyper-parameter optimization is\noften performed to compensate for this. Instead, we propose to adapt the\narchitecture on the fly during training. We show that the information about\ndesirable architectural changes, due to expressivity bottlenecks when\nattempting to follow the functional gradient, can be extracted from %the\nbackpropagation. To do this, we propose a mathematical definition of\nexpressivity bottlenecks, which enables us to detect, quantify and solve them\nwhile training, by adding suitable neurons when and where needed. Thus, while\nthe standard approach requires large networks, in terms of number of neurons\nper layer, for expressivity and optimization reasons, we are able to start with\nvery small neural networks and let them grow appropriately. As a proof of\nconcept, we show results~on the CIFAR dataset, matching large neural network\naccuracy, with competitive training time, while removing the need for standard\narchitectural hyper-parameter search.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Manon Verbockhaven",
            "Sylvain Chevallier",
            "Guillaume Charpiat"
        ],
        "published": "2024-05-30T08:23:56Z"
    },
    {
        "title": "Efficient Stimuli Generation using Reinforcement Learning in Design\n  Verification",
        "link": "http://arxiv.org/abs/2405.19815v1",
        "abstract": "The increasing design complexity of System-on-Chips (SoCs) has led to\nsignificant verification challenges, particularly in meeting coverage targets\nwithin a timely manner. At present, coverage closure is heavily dependent on\nconstrained random and coverage driven verification methodologies where the\nrandomized stimuli are bounded to verify certain scenarios and to reach\ncoverage goals. This process is said to be exhaustive and to consume a lot of\nproject time. In this paper, a novel methodology is proposed to generate\nefficient stimuli with the help of Reinforcement Learning (RL) to reach the\nmaximum code coverage of the Design Under Verification (DUV). Additionally, an\nautomated framework is created using metamodeling to generate a SystemVerilog\ntestbench and an RL environment for any given design. The proposed approach is\napplied to various designs and the produced results proves that the RL agent\nprovides effective stimuli to achieve code coverage faster in comparison with\nbaseline random simulations. Furthermore, various RL agents and reward schemes\nare analyzed in our work.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Deepak Narayan Gadde",
            "Thomas Nalapat",
            "Aman Kumar",
            "Djones Lettnin",
            "Wolfgang Kunz",
            "Sebastian Simon"
        ],
        "published": "2024-05-30T08:23:04Z"
    },
    {
        "title": "SLAM-based Joint Calibration of Multiple Asynchronous Microphone Arrays\n  and Sound Source Localization",
        "link": "http://arxiv.org/abs/2405.19813v1",
        "abstract": "Robot audition systems with multiple microphone arrays have many applications\nin practice. However, accurate calibration of multiple microphone arrays\nremains challenging because there are many unknown parameters to be identified,\nincluding the relative transforms (i.e., orientation, translation) and\nasynchronous factors (i.e., initial time offset and sampling clock difference)\nbetween microphone arrays. To tackle these challenges, in this paper, we adopt\nbatch simultaneous localization and mapping (SLAM) for joint calibration of\nmultiple asynchronous microphone arrays and sound source localization. Using\nthe Fisher information matrix (FIM) approach, we first conduct the\nobservability analysis (i.e., parameter identifiability) of the above-mentioned\ncalibration problem and establish necessary/sufficient conditions under which\nthe FIM and the Jacobian matrix have full column rank, which implies the\nidentifiability of the unknown parameters. We also discover several scenarios\nwhere the unknown parameters are not uniquely identifiable. Subsequently, we\npropose an effective framework to initialize the unknown parameters, which is\nused as the initial guess in batch SLAM for multiple microphone arrays\ncalibration, aiming to further enhance optimization accuracy and convergence.\nExtensive numerical simulations and real experiments have been conducted to\nverify the performance of the proposed method. The experiment results show that\nthe proposed pipeline achieves higher accuracy with fast convergence in\ncomparison to methods that use the noise-corrupted ground truth of the unknown\nparameters as the initial guess in the optimization and other existing\nframeworks.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Jiang Wang",
            "Yuanzheng He",
            "Daobilige Su",
            "Katsutoshi Itoyama",
            "Kazuhiro Nakadai",
            "Junfeng Wu",
            "Shoudong Huang",
            "Youfu Li",
            "He Kong"
        ],
        "published": "2024-05-30T08:21:18Z"
    },
    {
        "title": "Approximate Global Convergence of Independent Learning in Multi-Agent\n  Systems",
        "link": "http://arxiv.org/abs/2405.19811v1",
        "abstract": "Independent learning (IL), despite being a popular approach in practice to\nachieve scalability in large-scale multi-agent systems, usually lacks global\nconvergence guarantees. In this paper, we study two representative algorithms,\nindependent $Q$-learning and independent natural actor-critic, within\nvalue-based and policy-based frameworks, and provide the first finite-sample\nanalysis for approximate global convergence. The results imply a sample\ncomplexity of $\\tilde{\\mathcal{O}}(\\epsilon^{-2})$ up to an error term that\ncaptures the dependence among agents and characterizes the fundamental limit of\nIL in achieving global convergence. To establish the result, we develop a novel\napproach for analyzing IL by constructing a separable Markov decision process\n(MDP) for convergence analysis and then bounding the gap due to model\ndifference between the separable MDP and the original one. Moreover, we conduct\nnumerical experiments using a synthetic MDP and an electric vehicle charging\nexample to verify our theoretical findings and to demonstrate the practical\napplicability of IL.",
        "subjects": [
            "cs.LG",
            "cs.MA"
        ],
        "authors": [
            "Ruiyang Jin",
            "Zaiwei Chen",
            "Yiheng Lin",
            "Jie Song",
            "Adam Wierman"
        ],
        "published": "2024-05-30T08:20:34Z"
    },
    {
        "title": "AI with Alien Content and Alien Metasemantics",
        "link": "http://dx.doi.org/10.1093/oxfordhb/9780192844118.013.47",
        "abstract": "AlphaGo plays chess and Go in a creative and novel way. It is natural for us\nto attribute contents to it, such as that it doesn't view being several pawns\nbehind, if it has more board space, as bad. The framework introduced in\nCappelen and Dever (2021) provides a way of thinking about the semantics and\nthe metasemantics of AI content: does AlphaGo entertain contents like this, and\nif so, in virtue of what does a given state of the program mean that particular\ncontent? One salient question Cappelen and Dever didn't consider was the\npossibility of alien content. Alien content is content that is not or cannot be\nexpressed by human beings. It's highly plausible that AlphaGo, or any other\nsophisticated AI system, expresses alien contents. That this is so, moreover,\nis plausibly a metasemantic fact: a fact that has to do with how AI comes to\nentertain content in the first place, one that will heed the vastly different\netiology of AI and human content. This chapter explores the question of alien\ncontent in AI from a semantic and metasemantic perspective. It lays out the\nlogical space of possible responses to the semantic and metasemantic questions\nalien content poses, considers whether and how we humans could communicate with\nentities who express alien content, and points out that getting clear about\nsuch questions might be important for more 'applied' issues in the philosophy\nof AI, such as existential risk and XAI.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Herman Cappelen",
            "Josh Dever"
        ],
        "published": "2024-05-30T08:17:15Z"
    },
    {
        "title": "MetaCURL: Non-stationary Concave Utility Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.19807v1",
        "abstract": "We explore online learning in episodic loop-free Markov decision processes on\nnon-stationary environments (changing losses and probability transitions). Our\nfocus is on the Concave Utility Reinforcement Learning problem (CURL), an\nextension of classical RL for handling convex performance criteria in\nstate-action distributions induced by agent policies. While various machine\nlearning problems can be written as CURL, its non-linearity invalidates\ntraditional Bellman equations. Despite recent solutions to classical CURL, none\naddress non-stationary MDPs. This paper introduces MetaCURL, the first CURL\nalgorithm for non-stationary MDPs. It employs a meta-algorithm running multiple\nblack-box algorithms instances over different intervals, aggregating outputs\nvia a sleeping expert framework. The key hurdle is partial information due to\nMDP uncertainty. Under partial information on the probability transitions\n(uncertainty and non-stationarity coming only from external noise, independent\nof agent state-action pairs), we achieve optimal dynamic regret without prior\nknowledge of MDP changes. Unlike approaches for RL, MetaCURL handles full\nadversarial losses, not just stochastic ones. We believe our approach for\nmanaging non-stationarity with experts can be of interest to the RL community.",
        "subjects": [
            "cs.LG",
            "math.PR",
            "math.ST",
            "stat.ML",
            "stat.TH"
        ],
        "authors": [
            "Bianca Marin Moreno",
            "Margaux Brégère",
            "Pierre Gaillard",
            "Nadia Oudjane"
        ],
        "published": "2024-05-30T08:17:00Z"
    },
    {
        "title": "Preference Alignment with Flow Matching",
        "link": "http://arxiv.org/abs/2405.19806v1",
        "abstract": "We present Preference Flow Matching (PFM), a new framework for\npreference-based reinforcement learning (PbRL) that streamlines the integration\nof preferences into an arbitrary class of pre-trained models. Existing PbRL\nmethods require fine-tuning pre-trained models, which presents challenges such\nas scalability, inefficiency, and the need for model modifications, especially\nwith black-box APIs like GPT-4. In contrast, PFM utilizes flow matching\ntechniques to directly learn from preference data, thereby reducing the\ndependency on extensive fine-tuning of pre-trained models. By leveraging\nflow-based models, PFM transforms less preferred data into preferred outcomes,\nand effectively aligns model outputs with human preferences without relying on\nexplicit or implicit reward function estimation, thus avoiding common issues\nlike overfitting in reward models. We provide theoretical insights that support\nour method's alignment with standard PbRL objectives. Experimental results\nindicate the practical effectiveness of our method, offering a new direction in\naligning a pre-trained model to preference.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Minu Kim",
            "Yongsik Lee",
            "Sehyeok Kang",
            "Jihwan Oh",
            "Song Chong",
            "Seyoung Yun"
        ],
        "published": "2024-05-30T08:16:22Z"
    },
    {
        "title": "Complexity of Deciding Injectivity and Surjectivity of ReLU Neural\n  Networks",
        "link": "http://arxiv.org/abs/2405.19805v1",
        "abstract": "Neural networks with ReLU activation play a key role in modern machine\nlearning. In view of safety-critical applications, the verification of trained\nnetworks is of great importance and necessitates a thorough understanding of\nessential properties of the function computed by a ReLU network, including\ncharacteristics like injectivity and surjectivity. Recently, Puthawala et al.\n[JMLR 2022] came up with a characterization for injectivity of a ReLU layer,\nwhich implies an exponential time algorithm. However, the exact computational\ncomplexity of deciding injectivity remained open. We answer this question by\nproving coNP-completeness of deciding injectivity of a ReLU layer. On the\npositive side, as our main result, we present a parameterized algorithm which\nyields fixed-parameter tractability of the problem with respect to the input\ndimension. In addition, we also characterize surjectivity for two-layer ReLU\nnetworks with one-dimensional output. Remarkably, the decision problem turns\nout to be the complement of a basic network verification task. We prove\nNP-hardness for surjectivity, implying a stronger hardness result than\npreviously known for the network verification problem. Finally, we reveal\ninteresting connections to computational convexity by formulating the\nsurjectivity problem as a zonotope containment problem",
        "subjects": [
            "cs.CC",
            "cs.DM",
            "cs.LG"
        ],
        "authors": [
            "Vincent Froese",
            "Moritz Grillo",
            "Martin Skutella"
        ],
        "published": "2024-05-30T08:14:34Z"
    },
    {
        "title": "Exploring Key Factors for Long-Term Vessel Incident Risk Prediction",
        "link": "http://arxiv.org/abs/2405.19804v1",
        "abstract": "Factor analysis acts a pivotal role in enhancing maritime safety. Most\nprevious studies conduct factor analysis within the framework of\nincident-related label prediction, where the developed models can be\ncategorized into short-term and long-term prediction models. The long-term\nmodels offer a more strategic approach, enabling more proactive risk\nmanagement, compared to the short-term ones. Nevertheless, few studies have\ndevoted to rigorously identifying the key factors for the long-term prediction\nand undertaking comprehensive factor analysis. Hence, this study aims to delve\ninto the key factors for predicting the incident risk levels in the subsequent\nyear given a specific datestamp. The majority of candidate factors potentially\ncontributing to the incident risk are collected from vessels' historical safety\nperformance data spanning up to five years. An improved embedded feature\nselection, which integrates Random Forest classifier with a feature filtering\nprocess is proposed to identify key risk-contributing factors from the\ncandidate pool. The results demonstrate superior performance of the proposed\nmethod in incident prediction and factor interpretability. Comprehensive\nanalysis is conducted upon the key factors, which could help maritime\nstakeholders formulate management strategies for incident prevenion.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Tianyi Chen",
            "Hua Wang",
            "Yutong Cai",
            "Maohan Liang",
            "Qiang Meng"
        ],
        "published": "2024-05-30T08:12:51Z"
    },
    {
        "title": "Exploring the Robustness of Decision-Level Through Adversarial Attacks\n  on LLM-Based Embodied Models",
        "link": "http://arxiv.org/abs/2405.19802v1",
        "abstract": "Embodied intelligence empowers agents with a profound sense of perception,\nenabling them to respond in a manner closely aligned with real-world\nsituations. Large Language Models (LLMs) delve into language instructions with\ndepth, serving a crucial role in generating plans for intricate tasks. Thus,\nLLM-based embodied models further enhance the agent's capacity to comprehend\nand process information. However, this amalgamation also ushers in new\nchallenges in the pursuit of heightened intelligence. Specifically, attackers\ncan manipulate LLMs to produce irrelevant or even malicious outputs by altering\ntheir prompts. Confronted with this challenge, we observe a notable absence of\nmulti-modal datasets essential for comprehensively evaluating the robustness of\nLLM-based embodied models. Consequently, we construct the Embodied Intelligent\nRobot Attack Dataset (EIRAD), tailored specifically for robustness evaluation.\nAdditionally, two attack strategies are devised, including untargeted attacks\nand targeted attacks, to effectively simulate a range of diverse attack\nscenarios. At the same time, during the attack process, to more accurately\nascertain whether our method is successful in attacking the LLM-based embodied\nmodel, we devise a new attack success evaluation method utilizing the BLIP2\nmodel. Recognizing the time and cost-intensive nature of the GCG algorithm in\nattacks, we devise a scheme for prompt suffix initialization based on various\ntarget tasks, thus expediting the convergence process. Experimental results\ndemonstrate that our method exhibits a superior attack success rate when\ntargeting LLM-based embodied models, indicating a lower level of decision-level\nrobustness in these models.",
        "subjects": [
            "cs.MM"
        ],
        "authors": [
            "Shuyuan Liu",
            "Jiawei Chen",
            "Shouwei Ruan",
            "Hang Su",
            "Zhaoxia Yin"
        ],
        "published": "2024-05-30T08:12:08Z"
    },
    {
        "title": "Unsupervised Mutual Learning of Dialogue Discourse Parsing and Topic\n  Segmentation",
        "link": "http://arxiv.org/abs/2405.19799v1",
        "abstract": "The advancement of large language models (LLMs) has propelled the development\nof dialogue systems. Unlike the popular ChatGPT-like assistant model, which\nonly satisfies the user's preferences, task-oriented dialogue systems have also\nfaced new requirements and challenges in the broader business field. They are\nexpected to provide correct responses at each dialogue turn, at the same time,\nachieve the overall goal defined by the task. By understanding rhetorical\nstructures and topic structures via topic segmentation and discourse parsing, a\ndialogue system may do a better planning to achieve both objectives. However,\nwhile both structures belong to discourse structure in linguistics, rhetorical\nstructure and topic structure are mostly modeled separately or with one\nassisting the other in the prior work. The interaction between these two\nstructures has not been considered for joint modeling and mutual learning.\nFurthermore, unsupervised learning techniques to achieve the above are not well\nexplored. To fill this gap, we propose an unsupervised mutual learning\nframework of two structures leveraging the global and local connections between\nthem. We extend the topic modeling between non-adjacent discourse units to\nensure global structural relevance with rhetorical structures. We also\nincorporate rhetorical structures into the topic structure through a graph\nneural network model to ensure local coherence consistency. Finally, we utilize\nthe similarity between the two fused structures for mutual learning. The\nexperimental results demonstrate that our methods outperform all strong\nbaselines on two dialogue rhetorical datasets (STAC and Molweni), as well as\ndialogue topic datasets (Doc2Dial and TIAGE).",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Jiahui Xu",
            "Feng Jiang",
            "Anningzhe Gao",
            "Haizhou Li"
        ],
        "published": "2024-05-30T08:10:50Z"
    },
    {
        "title": "Explainable Attribute-Based Speaker Verification",
        "link": "http://arxiv.org/abs/2405.19796v1",
        "abstract": "This paper proposes a fully explainable approach to speaker verification\n(SV), a task that fundamentally relies on individual speaker characteristics.\nThe opaque use of speaker attributes in current SV systems raises concerns of\ntrust. Addressing this, we propose an attribute-based explainable SV system\nthat identifies speakers by comparing personal attributes such as gender,\nnationality, and age extracted automatically from voice recordings. We believe\nthis approach better aligns with human reasoning, making it more understandable\nthan traditional methods. Evaluated on the Voxceleb1 test set, the best\nperformance of our system is comparable with the ground truth established when\nusing all correct attributes, proving its efficacy. Whilst our approach\nsacrifices some performance compared to non-explainable methods, we believe\nthat it moves us closer to the goal of transparent, interpretable AI and lays\nthe groundwork for future enhancements through attribute expansion.",
        "subjects": [
            "cs.SD",
            "cs.AI",
            "eess.AS"
        ],
        "authors": [
            "Xiaoliang Wu",
            "Chau Luu",
            "Peter Bell",
            "Ajitha Rajan"
        ],
        "published": "2024-05-30T08:04:28Z"
    },
    {
        "title": "SLM as Guardian: Pioneering AI Safety with Small Language Models",
        "link": "http://arxiv.org/abs/2405.19795v1",
        "abstract": "Most prior safety research of large language models (LLMs) has focused on\nenhancing the alignment of LLMs to better suit the safety requirements of\nhumans. However, internalizing such safeguard features into larger models\nbrought challenges of higher training cost and unintended degradation of\nhelpfulness. To overcome such challenges, a modular approach employing a\nsmaller LLM to detect harmful user queries is regarded as a convenient solution\nin designing LLM-based system with safety requirements.\n  In this paper, we leverage a smaller LLM for both harmful query detection and\nsafeguard response generation. We introduce our safety requirements and the\ntaxonomy of harmfulness categories, and then propose a multi-task learning\nmechanism fusing the two tasks into a single model. We demonstrate the\neffectiveness of our approach, providing on par or surpassing harmful query\ndetection and safeguard response performance compared to the publicly available\nLLMs.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Ohjoon Kwon",
            "Donghyeon Jeon",
            "Nayoung Choi",
            "Gyu-Hwung Cho",
            "Changbong Kim",
            "Hyunwoo Lee",
            "Inho Kang",
            "Sun Kim",
            "Taiwoo Park"
        ],
        "published": "2024-05-30T08:03:15Z"
    },
    {
        "title": "Video Question Answering for People with Visual Impairments Using an\n  Egocentric 360-Degree Camera",
        "link": "http://arxiv.org/abs/2405.19794v1",
        "abstract": "This paper addresses the daily challenges encountered by visually impaired\nindividuals, such as limited access to information, navigation difficulties,\nand barriers to social interaction. To alleviate these challenges, we introduce\na novel visual question answering dataset. Our dataset offers two significant\nadvancements over previous datasets: Firstly, it features videos captured using\na 360-degree egocentric wearable camera, enabling observation of the entire\nsurroundings, departing from the static image-centric nature of prior datasets.\nSecondly, unlike datasets centered on singular challenges, ours addresses\nmultiple real-life obstacles simultaneously through an innovative\nvisual-question answering framework. We validate our dataset using various\nstate-of-the-art VideoQA methods and diverse metrics. Results indicate that\nwhile progress has been made, satisfactory performance levels for AI-powered\nassistive services remain elusive for visually impaired individuals.\nAdditionally, our evaluation highlights the distinctive features of the\nproposed dataset, featuring ego-motion in videos captured via 360-degree\ncameras across varied scenarios.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Inpyo Song",
            "Minjun Joo",
            "Joonhyung Kwon",
            "Jangwon Lee"
        ],
        "published": "2024-05-30T08:02:05Z"
    },
    {
        "title": "PDDLEGO: Iterative Planning in Textual Environments",
        "link": "http://arxiv.org/abs/2405.19793v1",
        "abstract": "Planning in textual environments have been shown to be a long-standing\nchallenge even for current models. A recent, promising line of work uses LLMs\nto generate a formal representation of the environment that can be solved by a\nsymbolic planner. However, existing methods rely on a fully-observed\nenvironment where all entity states are initially known, so a one-off\nrepresentation can be constructed, leading to a complete plan. In contrast, we\ntackle partially-observed environments where there is initially no sufficient\ninformation to plan for the end-goal. We propose PDDLEGO that iteratively\nconstruct a planning representation that can lead to a partial plan for a given\nsub-goal. By accomplishing the sub-goal, more information is acquired to\naugment the representation, eventually achieving the end-goal. We show that\nplans produced by few-shot PDDLEGO are 43% more efficient than generating plans\nend-to-end on the Coin Collector simulation, with strong performance (98%) on\nthe more complex Cooking World simulation where end-to-end LLMs fail to\ngenerate coherent plans (4%).",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Li Zhang",
            "Peter Jansen",
            "Tianyi Zhang",
            "Peter Clark",
            "Chris Callison-Burch",
            "Niket Tandon"
        ],
        "published": "2024-05-30T08:01:20Z"
    },
    {
        "title": "Estimating before Debiasing: A Bayesian Approach to Detaching Prior Bias\n  in Federated Semi-Supervised Learning",
        "link": "http://arxiv.org/abs/2405.19789v1",
        "abstract": "Federated Semi-Supervised Learning (FSSL) leverages both labeled and\nunlabeled data on clients to collaboratively train a model.In FSSL, the\nheterogeneous data can introduce prediction bias into the model, causing the\nmodel's prediction to skew towards some certain classes. Existing FSSL methods\nprimarily tackle this issue by enhancing consistency in model parameters or\noutputs. However, as the models themselves are biased, merely constraining\ntheir consistency is not sufficient to alleviate prediction bias. In this\npaper, we explore this bias from a Bayesian perspective and demonstrate that it\nprincipally originates from label prior bias within the training data. Building\nupon this insight, we propose a debiasing method for FSSL named FedDB. FedDB\nutilizes the Average Prediction Probability of Unlabeled Data (APP-U) to\napproximate the biased prior.During local training, FedDB employs APP-U to\nrefine pseudo-labeling through Bayes' theorem, thereby significantly reducing\nthe label prior bias. Concurrently, during the model aggregation, FedDB uses\nAPP-U from participating clients to formulate unbiased aggregate weights,\nthereby effectively diminishing bias in the global model. Experimental results\nshow that FedDB can surpass existing FSSL methods. The code is available at\nhttps://github.com/GuogangZhu/FedDB.",
        "subjects": [
            "cs.LG",
            "cs.DC"
        ],
        "authors": [
            "Guogang Zhu",
            "Xuefeng Liu",
            "Xinghao Wu",
            "Shaojie Tang",
            "Chao Tang",
            "Jianwei Niu",
            "Hao Su"
        ],
        "published": "2024-05-30T07:58:01Z"
    },
    {
        "title": "From Symbolic Tasks to Code Generation: Diversification Yields Better\n  Task Performers",
        "link": "http://arxiv.org/abs/2405.19787v1",
        "abstract": "Instruction tuning -- tuning large language models on instruction-output\npairs -- is a promising technique for making models better adapted to the real\nworld. Yet, the key factors driving the model's capability to understand and\nfollow instructions not seen during training remain under-explored. Our\ninvestigation begins with a series of synthetic experiments within the\ntheoretical framework of a Turing-complete algorithm called Markov algorithm,\nwhich allows fine-grained control over the instruction-tuning data.\nGeneralization and robustness with respect to the training distribution emerge\nonce a diverse enough set of tasks is provided, even though very few examples\nare provided for each task. We extend these initial results to a real-world\napplication scenario of code generation and find that a more diverse\ninstruction set, extending beyond code-related tasks, improves the performance\nof code generation. Our observations suggest that a more diverse semantic space\nfor instruction-tuning sets greatly improves the model's ability to follow\ninstructions and perform tasks.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "cs.LO",
            "cs.PL"
        ],
        "authors": [
            "Dylan Zhang",
            "Justin Wang",
            "Francois Charton"
        ],
        "published": "2024-05-30T07:54:07Z"
    },
    {
        "title": "Recurrent Deep Kernel Learning of Dynamical Systems",
        "link": "http://arxiv.org/abs/2405.19785v1",
        "abstract": "Digital twins require computationally-efficient reduced-order models (ROMs)\nthat can accurately describe complex dynamics of physical assets. However,\nconstructing ROMs from noisy high-dimensional data is challenging. In this\nwork, we propose a data-driven, non-intrusive method that utilizes stochastic\nvariational deep kernel learning (SVDKL) to discover low-dimensional latent\nspaces from data and a recurrent version of SVDKL for representing and\npredicting the evolution of latent dynamics. The proposed method is\ndemonstrated with two challenging examples -- a double pendulum and a\nreaction-diffusion system. Results show that our framework is capable of (i)\ndenoising and reconstructing measurements, (ii) learning compact\nrepresentations of system states, (iii) predicting system evolution in\nlow-dimensional latent spaces, and (iv) quantifying modeling uncertainties.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Nicolò Botteghi",
            "Paolo Motta",
            "Andrea Manzoni",
            "Paolo Zunino",
            "Mengwu Guo"
        ],
        "published": "2024-05-30T07:49:02Z"
    },
    {
        "title": "PixelsDB: Serverless and Natural-Language-Aided Data Analytics with\n  Flexible Service Levels and Prices",
        "link": "http://arxiv.org/abs/2405.19784v1",
        "abstract": "Serverless query processing has become increasingly popular due to its\nadvantages, including automated hardware and software management, high\nelasticity, and pay-as-you-go pricing. For users who are not system experts,\nserverless query processing greatly reduces the cost of owning a data analytic\nsystem. However, it is still a significant challenge for non-expert users to\ntransform their complex and evolving data analytic needs into proper SQL\nqueries and select a serverless query engine that delivers satisfactory\nperformance and price for each type of query.\n  This paper presents PixelsDB, an open-source data analytic system that allows\nusers who lack system or SQL expertise to explore data efficiently. It allows\nusers to generate and debug SQL queries using a natural language interface\npowered by fine-tuned language models. The queries are then executed by a\nserverless query engine that offers varying prices for different service levels\non query urgency. The service levels are natively supported by dedicated\narchitecture design and heterogeneous resource scheduling that can apply\ncost-efficient resources to process non-urgent queries. We envision that the\ncombination of a serverless paradigm, a natural-language-aided interface, and\nflexible service levels and prices will substantially improve the user\nexperience in data analysis.",
        "subjects": [
            "cs.DB",
            "cs.AI",
            "cs.DC",
            "cs.HC",
            "cs.LG"
        ],
        "authors": [
            "Haoqiong Bian",
            "Dongyang Geng",
            "Haoyang Li",
            "Anastasia Ailamaki"
        ],
        "published": "2024-05-30T07:48:43Z"
    },
    {
        "title": "Instruction-Guided Visual Masking",
        "link": "http://arxiv.org/abs/2405.19783v1",
        "abstract": "Instruction following is crucial in contemporary LLM. However, when extended\nto multimodal setting, it often suffers from misalignment between specific\ntextual instruction and targeted local region of an image. To achieve more\naccurate and nuanced multimodal instruction following, we introduce\nInstruction-guided Visual Masking (IVM), a new versatile visual grounding model\nthat is compatible with diverse multimodal models, such as LMM and robot model.\nBy constructing visual masks for instruction-irrelevant regions, IVM-enhanced\nmultimodal models can effectively focus on task-relevant image regions to\nbetter align with complex instructions. Specifically, we design a visual\nmasking data generation pipeline and create an IVM-Mix-1M dataset with 1\nmillion image-instruction pairs. We further introduce a new learning technique,\nDiscriminator Weighted Supervised Learning (DWSL) for preferential IVM training\nthat prioritizes high-quality data samples. Experimental results on generic\nmultimodal tasks such as VQA and embodied robotic control demonstrate the\nversatility of IVM, which as a plug-and-play tool, significantly boosts the\nperformance of diverse multimodal models, yielding new state-of-the-art results\nacross challenging multimodal benchmarks. Code is available at\nhttps://github.com/2toinf/IVM.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG",
            "cs.RO"
        ],
        "authors": [
            "Jinliang Zheng",
            "Jianxiong Li",
            "Sijie Cheng",
            "Yinan Zheng",
            "Jiaming Li",
            "Jihao Liu",
            "Yu Liu",
            "Jingjing Liu",
            "Xianyuan Zhan"
        ],
        "published": "2024-05-30T07:48:32Z"
    },
    {
        "title": "Dataflow-Guided Retrieval Augmentation for Repository-Level Code\n  Completion",
        "link": "http://arxiv.org/abs/2405.19782v1",
        "abstract": "Recent years have witnessed the deployment of code language models (LMs) in\nvarious code intelligence tasks such as code completion. Yet, it is challenging\nfor pre-trained LMs to generate correct completions in private repositories.\nPrevious studies retrieve cross-file context based on import relations or text\nsimilarity, which is insufficiently relevant to completion targets. In this\npaper, we propose a dataflow-guided retrieval augmentation approach, called\nDraCo, for repository-level code completion. DraCo parses a private repository\ninto code entities and establishes their relations through an extended dataflow\nanalysis, forming a repo-specific context graph. Whenever triggering code\ncompletion, DraCo precisely retrieves relevant background knowledge from the\nrepo-specific context graph and generates well-formed prompts to query code\nLMs. Furthermore, we construct a large Python dataset, ReccEval, with more\ndiverse completion targets. Our experiments demonstrate the superior accuracy\nand applicable efficiency of DraCo, improving code exact match by 3.43% and\nidentifier F1-score by 3.27% on average compared to the state-of-the-art\napproach.",
        "subjects": [
            "cs.SE",
            "cs.CL"
        ],
        "authors": [
            "Wei Cheng",
            "Yuhan Wu",
            "Wei Hu"
        ],
        "published": "2024-05-30T07:48:00Z"
    },
    {
        "title": "Automatic Graph Topology-Aware Transformer",
        "link": "http://arxiv.org/abs/2405.19779v1",
        "abstract": "Existing efforts are dedicated to designing many topologies and graph-aware\nstrategies for the graph Transformer, which greatly improve the model's\nrepresentation capabilities. However, manually determining the suitable\nTransformer architecture for a specific graph dataset or task requires\nextensive expert knowledge and laborious trials. This paper proposes an\nevolutionary graph Transformer architecture search framework (EGTAS) to\nautomate the construction of strong graph Transformers. We build a\ncomprehensive graph Transformer search space with the micro-level and\nmacro-level designs. EGTAS evolves graph Transformer topologies at the macro\nlevel and graph-aware strategies at the micro level. Furthermore, a surrogate\nmodel based on generic architectural coding is proposed to directly predict the\nperformance of graph Transformers, substantially reducing the evaluation cost\nof evolutionary search. We demonstrate the efficacy of EGTAS across a range of\ngraph-level and node-level tasks, encompassing both small-scale and large-scale\ngraph datasets. Experimental results and ablation studies show that EGTAS can\nconstruct high-performance architectures that rival state-of-the-art manual and\nautomated baselines.",
        "subjects": [
            "cs.NE",
            "cs.GR",
            "cs.LG"
        ],
        "authors": [
            "Chao Wang",
            "Jiaxuan Zhao",
            "Lingling Li",
            "Licheng Jiao",
            "Fang Liu",
            "Shuyuan Yang"
        ],
        "published": "2024-05-30T07:44:31Z"
    },
    {
        "title": "Enhancing Consistency and Role-Specific Knowledge Capturing by\n  Rebuilding Fictional Character's Persona",
        "link": "http://arxiv.org/abs/2405.19778v1",
        "abstract": "With the recent introduction of Assistants API, it is expected that\ndocument-based language models will be actively used in various domains,\nespecially Role-playing. However, a key challenge lies in utilizing\nprotagonist's persona: Assistants API often fails to achieve with its search\nbecause the information extraction part is different each time and it often\nomits important information such as protagonist's backstory or relationships.\nIt is hard to maintain a consistent persona simply by using the persona\ndocument as input to the Assistants API. To address the challenge of achieving\nstable persona consistency, we propose CharacterGPT, a novel persona\nreconstruction framework to alleviate the shortcomings of the Assistants API.\nOur method involves Character Persona Training (CPT), an effective persona\nrebuilding process that updates the character persona by extracting the\ncharacter's traits from given summary of the novel for each character as if the\nstory in a novel progresses. In our experiments, we ask each character to take\nthe Big Five Inventory personality test in various settings and analyze the\nresults. To assess whether it can think outside the box, we let each character\ngenerate short novels. Extensive experiments and human evaluation demonstrate\nthat CharacterGPT presents new possibilities for role-playing agent research.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Jeiyoon Park",
            "Chanjun Park",
            "Heuiseok Lim"
        ],
        "published": "2024-05-30T07:44:16Z"
    },
    {
        "title": "Puff-Net: Efficient Style Transfer with Pure Content and Style Feature\n  Fusion Network",
        "link": "http://arxiv.org/abs/2405.19775v1",
        "abstract": "Style transfer aims to render an image with the artistic features of a style\nimage, while maintaining the original structure. Various methods have been put\nforward for this task, but some challenges still exist. For instance, it is\ndifficult for CNN-based methods to handle global information and long-range\ndependencies between input images, for which transformer-based methods have\nbeen proposed. Although transformers can better model the relationship between\ncontent and style images, they require high-cost hardware and time-consuming\ninference. To address these issues, we design a novel transformer model that\nincludes only the encoder, thus significantly reducing the computational cost.\nIn addition, we also find that existing style transfer methods may lead to\nimages under-stylied or missing content. In order to achieve better\nstylization, we design a content feature extractor and a style feature\nextractor, based on which pure content and style images can be fed to the\ntransformer. Finally, we propose a novel network termed Puff-Net, i.e., pure\ncontent and style feature fusion network. Through qualitative and quantitative\nexperiments, we demonstrate the advantages of our model compared to\nstate-of-the-art ones in the literature.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Sizhe Zheng",
            "Pan Gao",
            "Peng Zhou",
            "Jie Qin"
        ],
        "published": "2024-05-30T07:41:07Z"
    },
    {
        "title": "VQA Training Sets are Self-play Environments for Generating Few-shot\n  Pools",
        "link": "http://arxiv.org/abs/2405.19773v1",
        "abstract": "Large-language models and large-vision models are increasingly capable of\nsolving compositional reasoning tasks, as measured by breakthroughs in\nvisual-question answering benchmarks. However, state-of-the-art solutions often\ninvolve careful construction of large pre-training and fine-tuning datasets,\nwhich can be expensive. The use of external tools, whether other ML models,\nsearch engines, or APIs, can significantly improve performance by breaking down\nhigh-level reasoning questions into sub-questions that are answerable by\nindividual tools, but this approach has similar dataset construction costs to\nteach fine-tuned models how to use the available tools. We propose a technique\nin which existing training sets can be directly used for constructing\ncomputational environments with task metrics as rewards. This enables a model\nto autonomously teach itself to use itself or another model as a tool. By doing\nso, we augment training sets by integrating external signals. The proposed\nmethod starts with zero-shot prompts and iteratively refines them by selecting\nfew-shot examples that maximize the task metric on the training set. Our\nexperiments showcase how Gemini learns how to use itself, or another smaller\nand specialized model such as ScreenAI, to iteratively improve performance on\ntraining sets. Our approach successfully generalizes and improves upon zeroshot\nperformance on charts, infographics, and document visual question-answering\ndatasets",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Tautvydas Misiunas",
            "Hassan Mansoor",
            "Jasper Uijlings",
            "Oriana Riva",
            "Victor Carbune"
        ],
        "published": "2024-05-30T07:38:58Z"
    },
    {
        "title": "Data Service Maximization in Integrated Terrestrial-Non-Terrestrial 6G\n  Networks: A Deep Reinforcement Learning Approach",
        "link": "http://arxiv.org/abs/2405.19771v1",
        "abstract": "Integrating terrestrial and non-terrestrial networks has emerged as a\npromising paradigm to fulfill the constantly growing demand for connectivity,\nlow transmission delay, and quality of services (QoS). This integration brings\ntogether the strengths of terrestrial and non-terrestrial networks, such as the\nreliability of terrestrial networks, broad coverage, and service continuity of\nnon-terrestrial networks like low earth orbit (LEO) satellites. In this work,\nwe study a data service maximization problem in an integrated\nterrestrial-non-terrestrial network (I-TNT) where the ground base stations\n(GBSs) and LEO satellites cooperatively serve the coexisting aerial users (AUs)\nand ground users (GUs). Then, by considering the spectrum scarcity,\ninterference, and QoS requirements of the users, we jointly optimize the user\nassociation, AUE's trajectory, and power allocation. To tackle the formulated\nmixed-integer non-convex problem, we disintegrate it into two subproblems: 1)\nuser association problem and 2) trajectory and power allocation problem. Since\nthe user association problem is a binary integer programming problem, we use\nthe standard convex optimization method to solve it. Meanwhile, the trajectory\nand power allocation problem is solved by the deep deterministic policy\ngradient (DDPG) method to cope with the problem's non-convexity and dynamic\nnetwork environments. Then, the two subproblems are alternately solved by the\nproposed iterative algorithm. By comparing with the baselines in the existing\nliterature, extensive simulations are conducted to evaluate the performance of\nthe proposed framework.",
        "subjects": [
            "cs.NI",
            "eess.SP"
        ],
        "authors": [
            "Nway Nway Ei",
            "Kitae Kim",
            "Yan Kyaw Tun",
            "Choong Seon Hong"
        ],
        "published": "2024-05-30T07:36:03Z"
    },
    {
        "title": "All-In-One Medical Image Restoration via Task-Adaptive Routing",
        "link": "http://arxiv.org/abs/2405.19769v1",
        "abstract": "Although single-task medical image restoration (MedIR) has witnessed\nremarkable success, the limited generalizability of these methods poses a\nsubstantial obstacle to wider application. In this paper, we focus on the task\nof all-in-one medical image restoration, aiming to address multiple distinct\nMedIR tasks with a single universal model. Nonetheless, due to significant\ndifferences between different MedIR tasks, training a universal model often\nencounters task interference issues, where different tasks with shared\nparameters may conflict with each other in the gradient update direction. This\ntask interference leads to deviation of the model update direction from the\noptimal path, thereby affecting the model's performance. To tackle this issue,\nwe propose a task-adaptive routing strategy, allowing conflicting tasks to\nselect different network paths in spatial and channel dimensions, thereby\nmitigating task interference. Experimental results demonstrate that our\nproposed \\textbf{A}ll-in-one \\textbf{M}edical \\textbf{I}mage\n\\textbf{R}estoration (\\textbf{AMIR}) network achieves state-of-the-art\nperformance in three MedIR tasks: MRI super-resolution, CT denoising, and PET\nsynthesis, both in single-task and all-in-one settings. The code and data will\nbe available at\n\\href{https://github.com/Yaziwel/All-In-One-Medical-Image-Restoration-via-Task-Adaptive-Routing.git}{https://github.com/Yaziwel/AMIR}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Zhiwen Yang",
            "Haowei Chen",
            "Ziniu Qian",
            "Yang Yi",
            "Hui Zhang",
            "Dan Zhao",
            "Bingzheng Wei",
            "Yan Xu"
        ],
        "published": "2024-05-30T07:34:05Z"
    },
    {
        "title": "Towards Unified Multi-granularity Text Detection with Interactive\n  Attention",
        "link": "http://arxiv.org/abs/2405.19765v1",
        "abstract": "Existing OCR engines or document image analysis systems typically rely on\ntraining separate models for text detection in varying scenarios and\ngranularities, leading to significant computational complexity and resource\ndemands. In this paper, we introduce \"Detect Any Text\" (DAT), an advanced\nparadigm that seamlessly unifies scene text detection, layout analysis, and\ndocument page detection into a cohesive, end-to-end model. This design enables\nDAT to efficiently manage text instances at different granularities, including\n*word*, *line*, *paragraph* and *page*. A pivotal innovation in DAT is the\nacross-granularity interactive attention module, which significantly enhances\nthe representation learning of text instances at varying granularities by\ncorrelating structural information across different text queries. As a result,\nit enables the model to achieve mutually beneficial detection performances\nacross multiple text granularities. Additionally, a prompt-based segmentation\nmodule refines detection outcomes for texts of arbitrary curvature and complex\nlayouts, thereby improving DAT's accuracy and expanding its real-world\napplicability. Experimental results demonstrate that DAT achieves\nstate-of-the-art performances across a variety of text-related benchmarks,\nincluding multi-oriented/arbitrarily-shaped scene text detection, document\nlayout analysis and page detection tasks.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Xingyu Wan",
            "Chengquan Zhang",
            "Pengyuan Lyu",
            "Sen Fan",
            "Zihan Ni",
            "Kun Yao",
            "Errui Ding",
            "Jingdong Wang"
        ],
        "published": "2024-05-30T07:25:23Z"
    },
    {
        "title": "Enhancing Reinforcement Learning with Label-Sensitive Reward for Natural\n  Language Understanding",
        "link": "http://arxiv.org/abs/2405.19763v1",
        "abstract": "Recent strides in large language models (LLMs) have yielded remarkable\nperformance, leveraging reinforcement learning from human feedback (RLHF) to\nsignificantly enhance generation and alignment capabilities. However, RLHF\nencounters numerous challenges, including the objective mismatch issue, leading\nto suboptimal performance in Natural Language Understanding (NLU) tasks. To\naddress this limitation, we propose a novel Reinforcement Learning framework\nenhanced with Label-sensitive Reward (RLLR) to amplify the performance of LLMs\nin NLU tasks. By incorporating label-sensitive pairs into reinforcement\nlearning, our method aims to adeptly capture nuanced label-sensitive semantic\nfeatures during RL, thereby enhancing natural language understanding.\nExperiments conducted on five diverse foundation models across eight tasks\nshowcase promising results. In comparison to Supervised Fine-tuning models\n(SFT), RLLR demonstrates an average performance improvement of 1.54%. Compared\nwith RLHF models, the improvement averages at 0.69%. These results reveal the\neffectiveness of our method for LLMs in NLU tasks. Code and data available at:\nhttps://github.com/MagiaSN/ACL2024_RLLR.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Kuo Liao",
            "Shuang Li",
            "Meng Zhao",
            "Liqun Liu",
            "Mengge Xue",
            "Zhenyu Hu",
            "Honglin Han",
            "Chengguo Yin"
        ],
        "published": "2024-05-30T07:19:31Z"
    },
    {
        "title": "The Kosmosis Use-Case of Crypto Rug Pull Detection and Prevention",
        "link": "http://arxiv.org/abs/2405.19762v1",
        "abstract": "Current methods to prevent crypto asset fraud are based on the analysis of\ntransaction graphs within blockchain networks. While effective for identifying\ntransaction patterns indicative of fraud, it does not capture the semantics of\ntransactions and is constrained to blockchain data. Consequently, preventive\nmethods based on transaction graphs are inherently limited. In response to\nthese limitations, we propose the Kosmosis approach, which aims to\nincrementally construct a knowledge graph as new blockchain and social media\ndata become available. During construction, it aims to extract the semantics of\ntransactions and connect blockchain addresses to their real-world entities by\nfusing blockchain and social media data in a knowledge graph. This enables\nnovel preventive methods against rug pulls as a form of crypto asset fraud. To\ndemonstrate the effectiveness and practical applicability of the Kosmosis\napproach, we examine a series of real-world rug pulls from 2021. Through this\ncase, we illustrate how Kosmosis can aid in identifying and preventing such\nfraudulent activities by leveraging the insights from the constructed knowledge\ngraph.",
        "subjects": [
            "cs.CR",
            "cs.DC"
        ],
        "authors": [
            "Philipp Stangl",
            "Christoph P. Neumann"
        ],
        "published": "2024-05-30T07:17:57Z"
    },
    {
        "title": "Revisiting CNNs for Trajectory Similarity Learning",
        "link": "http://arxiv.org/abs/2405.19761v1",
        "abstract": "Similarity search is a fundamental but expensive operator in querying\ntrajectory data, due to its quadratic complexity of distance computation. To\nmitigate the computational burden for long trajectories, neural networks have\nbeen widely employed for similarity learning and each trajectory is encoded as\na high-dimensional vector for similarity search with linear complexity. Given\nthe sequential nature of trajectory data, previous efforts have been primarily\ndevoted to the utilization of RNNs or Transformers.\n  In this paper, we argue that the common practice of treating trajectory as\nsequential data results in excessive attention to capturing long-term global\ndependency between two sequences. Instead, our investigation reveals the\npivotal role of local similarity, prompting a revisit of simple CNNs for\ntrajectory similarity learning. We introduce ConvTraj, incorporating both 1D\nand 2D convolutions to capture sequential and geo-distribution features of\ntrajectories, respectively. In addition, we conduct a series of theoretical\nanalyses to justify the effectiveness of ConvTraj. Experimental results on\nthree real-world large-scale datasets demonstrate that ConvTraj achieves\nstate-of-the-art accuracy in trajectory similarity search. Owing to the simple\nnetwork structure of ConvTraj, the training and inference speed on the Porto\ndataset with 1.6 million trajectories are increased by at least $240$x and\n$2.16$x, respectively. The source code and dataset can be found at\n\\textit{\\url{https://github.com/Proudc/ConvTraj}}.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Zhihao Chang",
            "Linzhu Yu",
            "Huan Li",
            "Sai Wu",
            "Gang Chen",
            "Dongxiang Zhang"
        ],
        "published": "2024-05-30T07:16:03Z"
    },
    {
        "title": "Identifiability of a statistical model with two latent vectors:\n  Importance of the dimensionality relation and application to graph embedding",
        "link": "http://arxiv.org/abs/2405.19760v1",
        "abstract": "Identifiability of statistical models is a key notion in unsupervised\nrepresentation learning. Recent work of nonlinear independent component\nanalysis (ICA) employs auxiliary data and has established identifiable\nconditions. This paper proposes a statistical model of two latent vectors with\nsingle auxiliary data generalizing nonlinear ICA, and establishes various\nidentifiability conditions. Unlike previous work, the two latent vectors in the\nproposed model can have arbitrary dimensions, and this property enables us to\nreveal an insightful dimensionality relation among two latent vectors and\nauxiliary data in identifiability conditions. Furthermore, surprisingly, we\nprove that the indeterminacies of the proposed model has the same as\n\\emph{linear} ICA under certain conditions: The elements in the latent vector\ncan be recovered up to their permutation and scales. Next, we apply the\nidentifiability theory to a statistical model for graph data. As a result, one\nof the identifiability conditions includes an appealing implication:\nIdentifiability of the statistical model could depend on the maximum value of\nlink weights in graph data. Then, we propose a practical method for\nidentifiable graph embedding. Finally, we numerically demonstrate that the\nproposed method well-recovers the latent vectors and model identifiability\nclearly depends on the maximum value of link weights, which supports the\nimplication of our theoretical results",
        "subjects": [
            "stat.ML",
            "cs.LG"
        ],
        "authors": [
            "Hiroaki Sasaki"
        ],
        "published": "2024-05-30T07:11:20Z"
    },
    {
        "title": "InterPreT: Interactive Predicate Learning from Language Feedback for\n  Generalizable Task Planning",
        "link": "http://arxiv.org/abs/2405.19758v1",
        "abstract": "Learning abstract state representations and knowledge is crucial for\nlong-horizon robot planning. We present InterPreT, an LLM-powered framework for\nrobots to learn symbolic predicates from language feedback of human non-experts\nduring embodied interaction. The learned predicates provide relational\nabstractions of the environment state, facilitating the learning of symbolic\noperators that capture action preconditions and effects. By compiling the\nlearned predicates and operators into a PDDL domain on-the-fly, InterPreT\nallows effective planning toward arbitrary in-domain goals using a PDDL\nplanner. In both simulated and real-world robot manipulation domains, we\ndemonstrate that InterPreT reliably uncovers the key predicates and operators\ngoverning the environment dynamics. Although learned from simple training\ntasks, these predicates and operators exhibit strong generalization to novel\ntasks with significantly higher complexity. In the most challenging\ngeneralization setting, InterPreT attains success rates of 73% in simulation\nand 40% in the real world, substantially outperforming baseline methods.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Muzhi Han",
            "Yifeng Zhu",
            "Song-Chun Zhu",
            "Ying Nian Wu",
            "Yuke Zhu"
        ],
        "published": "2024-05-30T07:08:40Z"
    },
    {
        "title": "Improving SMOTE via Fusing Conditional VAE for Data-adaptive Noise\n  Filtering",
        "link": "http://arxiv.org/abs/2405.19757v1",
        "abstract": "Recent advances in a generative neural network model extend the development\nof data augmentation methods. However, the augmentation methods based on the\nmodern generative models fail to achieve notable performance for class\nimbalance data compared to the conventional model, the SMOTE. We investigate\nthe problem of the generative model for imbalanced classification and introduce\na framework to enhance the SMOTE algorithm using Variational Autoencoders\n(VAE). Our approach systematically quantifies the density of data points in a\nlow-dimensional latent space using the VAE, simultaneously incorporating\ninformation on class labels and classification difficulty. Then, the data\npoints potentially degrading the augmentation are systematically excluded, and\nthe neighboring observations are directly augmented on the data space.\nEmpirical studies on several imbalanced datasets represent that this simple\nprocess innovatively improves the conventional SMOTE algorithm over the deep\nlearning models. Consequently, we conclude that the selection of minority data\nand the interpolation in the data space are beneficial for imbalanced\nclassification problems with a relatively small number of data points.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Sungchul Hong",
            "Seunghwan An",
            "Jong-June Jeon"
        ],
        "published": "2024-05-30T07:06:02Z"
    },
    {
        "title": "Developing a Comprehensive Measurement Tool for Assessing the Rate of\n  BIM Adoption in the Construction Industry",
        "link": "http://arxiv.org/abs/2405.19755v1",
        "abstract": "Building Information Modeling (BIM) is a crucial technology in the\nconstruction industry, offering benefits such as enhanced collaboration,\nreal-time decision-making, and significant cost and time savings. Despite its\nadvantages, BIM adoption faces numerous barriers. This study aims to create a\nreliable tool to assess the Rate of BIM Adoption (RBA), drawing on Attributes\nof Innovation theory and empirical data from the literature. This research\nintegrates theoretical insights with empirical data, providing quantitative\nitems to measure BAR in the construction industry. The quantitative approach\nhelps decision-makers and policymakers to mandate BIM and establish appropriate\nimplementation standards. Its implications are significant for the construction\nindustry, policymakers, and the academic community, offering a systematic\napproach to assess BIM adoption, identify barriers, and implement targeted\nstrategies. The reliability of this approach is ensured through a solid\ntheoretical foundation, item development, pilot testing, and statistical\nanalysis, making it a valuable resource for improving BIM implementation and\nfostering innovation in the construction industry.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Mohammed Abdulsalam Alsofiani"
        ],
        "published": "2024-05-30T07:03:26Z"
    },
    {
        "title": "Mitigating annotation shift in cancer classification using single image\n  generative models",
        "link": "http://arxiv.org/abs/2405.19754v1",
        "abstract": "Artificial Intelligence (AI) has emerged as a valuable tool for assisting\nradiologists in breast cancer detection and diagnosis. However, the success of\nAI applications in this domain is restricted by the quantity and quality of\navailable data, posing challenges due to limited and costly data annotation\nprocedures that often lead to annotation shifts. This study simulates, analyses\nand mitigates annotation shifts in cancer classification in the breast\nmammography domain. First, a high-accuracy cancer risk prediction model is\ndeveloped, which effectively distinguishes benign from malignant lesions. Next,\nmodel performance is used to quantify the impact of annotation shift. We\nuncover a substantial impact of annotation shift on multiclass classification\nperformance particularly for malignant lesions. We thus propose a training data\naugmentation approach based on single-image generative models for the affected\nclass, requiring as few as four in-domain annotations to considerably mitigate\nannotation shift, while also addressing dataset imbalance. Lastly, we further\nincrease performance by proposing and validating an ensemble architecture based\non multiple models trained under different data augmentation regimes. Our study\noffers key insights into annotation shift in deep learning breast cancer\nclassification and explores the potential of single-image generative models to\novercome domain shift challenges.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Marta Buetas Arcas",
            "Richard Osuala",
            "Karim Lekadir",
            "Oliver Díaz"
        ],
        "published": "2024-05-30T07:02:50Z"
    },
    {
        "title": "Understanding Memory-Regret Trade-Off for Streaming Stochastic\n  Multi-Armed Bandits",
        "link": "http://arxiv.org/abs/2405.19752v1",
        "abstract": "We study the stochastic multi-armed bandit problem in the $P$-pass streaming\nmodel. In this problem, the $n$ arms are present in a stream and at most $m<n$\narms and their statistics can be stored in the memory. We give a complete\ncharacterization of the optimal regret in terms of $m, n$ and $P$.\nSpecifically, we design an algorithm with $\\tilde\nO\\left((n-m)^{1+\\frac{2^{P}-2}{2^{P+1}-1}} n^{\\frac{2-2^{P+1}}{2^{P+1}-1}}\nT^{\\frac{2^P}{2^{P+1}-1}}\\right)$ regret and complement it with an $\\tilde\n\\Omega\\left((n-m)^{1+\\frac{2^{P}-2}{2^{P+1}-1}} n^{\\frac{2-2^{P+1}}{2^{P+1}-1}}\nT^{\\frac{2^P}{2^{P+1}-1}}\\right)$ lower bound when the number of rounds $T$ is\nsufficiently large. Our results are tight up to a logarithmic factor in $n$ and\n$P$.",
        "subjects": [
            "cs.LG",
            "cs.DS",
            "stat.ML"
        ],
        "authors": [
            "Yuchen He",
            "Zichun Ye",
            "Chihao Zhang"
        ],
        "published": "2024-05-30T06:56:48Z"
    },
    {
        "title": "HQ-DiT: Efficient Diffusion Transformer with FP4 Hybrid Quantization",
        "link": "http://arxiv.org/abs/2405.19751v1",
        "abstract": "Diffusion Transformers (DiTs) have recently gained substantial attention in\nboth industrial and academic fields for their superior visual generation\ncapabilities, outperforming traditional diffusion models that use U-Net.\nHowever,the enhanced performance of DiTs also comes with high parameter counts\nand implementation costs, seriously restricting their use on resource-limited\ndevices such as mobile phones. To address these challenges, we introduce the\nHybrid Floating-point Quantization for DiT(HQ-DiT), an efficient post-training\nquantization method that utilizes 4-bit floating-point (FP) precision on both\nweights and activations for DiT inference. Compared to fixed-point quantization\n(e.g., INT8), FP quantization, complemented by our proposed clipping range\nselection mechanism, naturally aligns with the data distribution within DiT,\nresulting in a minimal quantization error. Furthermore, HQ-DiT also implements\na universal identity mathematical transform to mitigate the serious\nquantization error caused by the outliers. The experimental results demonstrate\nthat DiT can achieve extremely low-precision quantization (i.e., 4 bits) with\nnegligible impact on performance. Our approach marks the first instance where\nboth weights and activations in DiTs are quantized to just 4 bits, with only a\n0.12 increase in sFID on ImageNet.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Wenxuan Liu",
            "Saiqian Zhang"
        ],
        "published": "2024-05-30T06:56:11Z"
    },
    {
        "title": "Generating Query Recommendations via LLMs",
        "link": "http://arxiv.org/abs/2405.19749v1",
        "abstract": "Query recommendation systems are ubiquitous in modern search engines,\nassisting users in producing effective queries to meet their information needs.\nHowever, these systems require a large amount of data to produce good\nrecommendations, such as a large collection of documents to index and query\nlogs. In particular, query logs and user data are not available in cold start\nscenarios. Query logs are expensive to collect and maintain and require complex\nand time-consuming cascading pipelines for creating, combining, and ranking\nrecommendations. To address these issues, we frame the query recommendation\nproblem as a generative task, proposing a novel approach called Generative\nQuery Recommendation (GQR). GQR uses an LLM as its foundation and does not\nrequire to be trained or fine-tuned to tackle the query recommendation problem.\nWe design a prompt that enables the LLM to understand the specific\nrecommendation task, even using a single example. We then improved our system\nby proposing a version that exploits query logs called Retriever-Augmented GQR\n(RA-GQR). RA-GQr dynamically composes its prompt by retrieving similar queries\nfrom query logs. GQR approaches reuses a pre-existing neural architecture\nresulting in a simpler and more ready-to-market approach, even in a cold start\nscenario. Our proposed GQR obtains state-of-the-art performance in terms of\nNDCG@10 and clarity score against two commercial search engines and the\nprevious state-of-the-art approach on the Robust04 and ClueWeb09B collections,\nimproving on average the NDCG@10 performance up to ~4% on Robust04 and\nClueWeb09B w.r.t the previous best competitor. RA-GQR further improve the\nNDCG@10 obtaining an increase of ~11%, ~6\\% on Robust04 and ClueWeb09B w.r.t\nthe best competitor. Furthermore, our system obtained ~59% of user preferences\nin a blind user study, proving that our method produces the most engaging\nqueries.",
        "subjects": [
            "cs.IR",
            "H.3.3"
        ],
        "authors": [
            "Andrea Bacciu",
            "Enrico Palumbo",
            "Andreas Damianou",
            "Nicola Tonellotto",
            "Fabrizio Silvestri"
        ],
        "published": "2024-05-30T06:52:01Z"
    },
    {
        "title": "Understanding and mitigating difficulties in posterior predictive\n  evaluation",
        "link": "http://arxiv.org/abs/2405.19747v1",
        "abstract": "Predictive posterior densities (PPDs) are of interest in approximate Bayesian\ninference. Typically, these are estimated by simple Monte Carlo (MC) averages\nusing samples from the approximate posterior. We observe that the\nsignal-to-noise ratio (SNR) of such estimators can be extremely low. An\nanalysis for exact inference reveals SNR decays exponentially as there is an\nincrease in (a) the mismatch between training and test data, (b) the\ndimensionality of the latent space, or (c) the size of the test data relative\nto the training data. Further analysis extends these results to approximate\ninference. To remedy the low SNR problem, we propose replacing simple MC\nsampling with importance sampling using a proposal distribution optimized at\ntest time on a variational proxy for the SNR and demonstrate that this yields\ngreatly improved estimates.",
        "subjects": [
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Abhinav Agrawal",
            "Justin Domke"
        ],
        "published": "2024-05-30T06:50:28Z"
    },
    {
        "title": "DenseSeg: Joint Learning for Semantic Segmentation and Landmark\n  Detection Using Dense Image-to-Shape Representation",
        "link": "http://arxiv.org/abs/2405.19746v1",
        "abstract": "Purpose: Semantic segmentation and landmark detection are fundamental tasks\nof medical image processing, facilitating further analysis of anatomical\nobjects. Although deep learning-based pixel-wise classification has set a\nnew-state-of-the-art for segmentation, it falls short in landmark detection, a\nstrength of shape-based approaches.\n  Methods: In this work, we propose a dense image-to-shape representation that\nenables the joint learning of landmarks and semantic segmentation by employing\na fully convolutional architecture. Our method intuitively allows the\nextraction of arbitrary landmarks due to its representation of anatomical\ncorrespondences. We benchmark our method against the state-of-the-art for\nsemantic segmentation (nnUNet), a shape-based approach employing geometric deep\nlearning and a CNN-based method for landmark detection.\n  Results: We evaluate our method on two medical dataset: one common benchmark\nfeaturing the lungs, heart, and clavicle from thorax X-rays, and another with\n17 different bones in the paediatric wrist. While our method is on pair with\nthe landmark detection baseline in the thorax setting (error in mm of\n$2.6\\pm0.9$ vs $2.7\\pm0.9$), it substantially surpassed it in the more complex\nwrist setting ($1.1\\pm0.6$ vs $1.9\\pm0.5$).\n  Conclusion: We demonstrate that dense geometric shape representation is\nbeneficial for challenging landmark detection tasks and outperforms previous\nstate-of-the-art using heatmap regression. While it does not require explicit\ntraining on the landmarks themselves, allowing for the addition of new\nlandmarks without necessitating retraining.}",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Ron Keuth",
            "Lasse Hansen",
            "Maren Balks",
            "Ronja Jäger",
            "Anne-Nele Schröder",
            "Ludger Tüshaus",
            "Mattias Heinrich"
        ],
        "published": "2024-05-30T06:49:59Z"
    },
    {
        "title": "GaussianPrediction: Dynamic 3D Gaussian Prediction for Motion\n  Extrapolation and Free View Synthesis",
        "link": "http://dx.doi.org/10.1145/3641519.3657417",
        "abstract": "Forecasting future scenarios in dynamic environments is essential for\nintelligent decision-making and navigation, a challenge yet to be fully\nrealized in computer vision and robotics. Traditional approaches like video\nprediction and novel-view synthesis either lack the ability to forecast from\narbitrary viewpoints or to predict temporal dynamics. In this paper, we\nintroduce GaussianPrediction, a novel framework that empowers 3D Gaussian\nrepresentations with dynamic scene modeling and future scenario synthesis in\ndynamic environments. GaussianPrediction can forecast future states from any\nviewpoint, using video observations of dynamic scenes. To this end, we first\npropose a 3D Gaussian canonical space with deformation modeling to capture the\nappearance and geometry of dynamic scenes, and integrate the lifecycle property\ninto Gaussians for irreversible deformations. To make the prediction feasible\nand efficient, a concentric motion distillation approach is developed by\ndistilling the scene motion with key points. Finally, a Graph Convolutional\nNetwork is employed to predict the motions of key points, enabling the\nrendering of photorealistic images of future scenarios. Our framework shows\noutstanding performance on both synthetic and real-world datasets,\ndemonstrating its efficacy in predicting and rendering future environments.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "authors": [
            "Boming Zhao",
            "Yuan Li",
            "Ziyu Sun",
            "Lin Zeng",
            "Yujun Shen",
            "Rui Ma",
            "Yinda Zhang",
            "Hujun Bao",
            "Zhaopeng Cui"
        ],
        "published": "2024-05-30T06:47:55Z"
    },
    {
        "title": "X-Instruction: Aligning Language Model in Low-resource Languages with\n  Self-curated Cross-lingual Instructions",
        "link": "http://arxiv.org/abs/2405.19744v1",
        "abstract": "Large language models respond well in high-resource languages like English\nbut struggle in low-resource languages. It may arise from the lack of\nhigh-quality instruction following data in these languages. Directly\ntranslating English samples into these languages can be a solution but\nunreliable, leading to responses with translation errors and lacking\nlanguage-specific or cultural knowledge. To address this issue, we propose a\nnovel method to construct cross-lingual instruction following samples with\ninstruction in English and response in low-resource languages. Specifically,\nthe language model first learns to generate appropriate English instructions\naccording to the natural web texts in other languages as responses. The\ncandidate cross-lingual instruction tuning samples are further refined and\ndiversified. We have employed this method to build a large-scale cross-lingual\ninstruction tuning dataset on 10 languages, namely X-Instruction. The\ninstruction data built using our method incorporate more language-specific\nknowledge compared with the naive translation method. Experimental results have\nshown that the response quality of the model tuned on X-Instruction greatly\nexceeds the model distilled from a powerful teacher model, reaching or even\nsurpassing the ones of ChatGPT. In addition, we find that models tuned on\ncross-lingual instruction following samples can follow the instruction in the\noutput language without further tuning.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Chong Li",
            "Wen Yang",
            "Jiajun Zhang",
            "Jinliang Lu",
            "Shaonan Wang",
            "Chengqing Zong"
        ],
        "published": "2024-05-30T06:45:23Z"
    },
    {
        "title": "May the Dance be with You: Dance Generation Framework for Non-Humanoids",
        "link": "http://arxiv.org/abs/2405.19743v1",
        "abstract": "We hypothesize dance as a motion that forms a visual rhythm from music, where\nthe visual rhythm can be perceived from an optical flow. If an agent can\nrecognize the relationship between visual rhythm and music, it will be able to\ndance by generating a motion to create a visual rhythm that matches the music.\nBased on this, we propose a framework for any kind of non-humanoid agents to\nlearn how to dance from human videos. Our framework works in two processes: (1)\ntraining a reward model which perceives the relationship between optical flow\n(visual rhythm) and music from human dance videos, (2) training the\nnon-humanoid dancer based on that reward model, and reinforcement learning. Our\nreward model consists of two feature encoders for optical flow and music. They\nare trained based on contrastive learning which makes the higher similarity\nbetween concurrent optical flow and music features. With this reward model, the\nagent learns dancing by getting a higher reward when its action creates an\noptical flow whose feature has a higher similarity with the given music\nfeature. Experiment results show that generated dance motion can align with the\nmusic beat properly, and user study result indicates that our framework is more\npreferred by humans compared to the baselines. To the best of our knowledge,\nour work of non-humanoid agents which learn dance from human videos is\nunprecedented. An example video can be found at https://youtu.be/dOUPvo-O3QY.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.RO"
        ],
        "authors": [
            "Hyemin Ahn"
        ],
        "published": "2024-05-30T06:43:55Z"
    },
    {
        "title": "PertEval: Unveiling Real Knowledge Capacity of LLMs with\n  Knowledge-Invariant Perturbations",
        "link": "http://arxiv.org/abs/2405.19740v1",
        "abstract": "Expert-designed close-ended benchmarks serve as vital tools in assessing the\nknowledge capacity of large language models (LLMs). Despite their widespread\nuse, concerns have mounted regarding their reliability due to limited test\nscenarios and an unavoidable risk of data contamination. To rectify this, we\npresent PertEval, a toolkit devised for in-depth probing of LLMs' knowledge\ncapacity through knowledge-invariant perturbations. These perturbations employ\nhuman-like restatement techniques to generate on-the-fly test samples from\nstatic benchmarks, meticulously retaining knowledge-critical content while\naltering irrelevant details. Our toolkit further includes a suite of transition\nanalyses that compare performance on raw vs. perturbed test sets to precisely\nassess LLMs' genuine knowledge capacity. Six state-of-the-art LLMs are\nre-evaluated using PertEval. Results reveal significantly inflated performance\nof the LLMs on raw benchmarks, including an absolute 21% overestimation for\nGPT-4. Additionally, through a nuanced response pattern analysis, we discover\nthat PertEval retains LLMs' uncertainty to specious knowledge, potentially\nbeing resolved through rote memorization and leading to inflated performance.\nWe also find that the detailed transition analyses by PertEval could illuminate\nweaknesses in existing LLMs' knowledge mastery and guide the development of\nrefinement. Given these insights, we posit that PertEval can act as an\nessential tool that, when applied alongside any close-ended benchmark, unveils\nthe true knowledge capacity of LLMs, marking a significant step toward more\ntrustworthy LLM evaluation.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.CY"
        ],
        "authors": [
            "Jiatong Li",
            "Renjun Hu",
            "Kunzhe Huang",
            "Yan Zhuang",
            "Qi Liu",
            "Mengxiao Zhu",
            "Xing Shi",
            "Wei Lin"
        ],
        "published": "2024-05-30T06:38:32Z"
    },
    {
        "title": "Beyond Imitation: Learning Key Reasoning Steps from Dual\n  Chain-of-Thoughts in Reasoning Distillation",
        "link": "http://arxiv.org/abs/2405.19737v1",
        "abstract": "As Large Language Models (LLMs) scale up and gain powerful Chain-of-Thoughts\n(CoTs) reasoning abilities, practical resource constraints drive efforts to\ndistill these capabilities into more compact Smaller Language Models (SLMs). We\nfind that CoTs consist mainly of simple reasoning forms, with a small\nproportion ($\\approx 4.7\\%$) of key reasoning steps that truly impact\nconclusions. However, previous distillation methods typically involve\nsupervised fine-tuning student SLMs only on correct CoTs data produced by\nteacher LLMs, resulting in students struggling to learn the key reasoning\nsteps, instead imitating the teacher's reasoning forms and making errors or\nomissions on these steps. To address these issues, drawing an analogy to human\nlearning, where analyzing mistakes according to correct solutions often reveals\nthe crucial steps leading to successes or failures, we propose\nmistak\\textbf{E}-\\textbf{D}riven key reason\\textbf{I}ng step\ndistilla\\textbf{T}ion (\\textbf{EDIT}), a novel method that further aids SLMs\nlearning key reasoning steps rather than mere simple fine-tuning. Firstly, to\nexpose these crucial steps in CoTs, we design specific prompts to generate dual\nCoTs data with similar reasoning paths but divergent conclusions. Then, we\napply the minimum edit distance algorithm on the dual CoTs data to locate these\nkey steps and optimize the likelihood of these steps. Extensive experiments\nvalidate the effectiveness of EDIT across both in-domain and out-of-domain\nbenchmark reasoning datasets. Further analysis shows that EDIT can generate\nhigh-quality CoTs with more correct key reasoning steps. Notably, we also\nexplore how different mistake patterns affect performance and find that EDIT\nbenefits more from logical errors than from knowledge or mathematical\ncalculation errors in dual CoTs\\footnote{Code can be found at\n\\url{https://github.com/C-W-D/EDIT}}.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Chengwei Dai",
            "Kun Li",
            "Wei Zhou",
            "Songlin Hu"
        ],
        "published": "2024-05-30T06:32:11Z"
    },
    {
        "title": "Twin Deformable Point Convolutions for Point Cloud Semantic Segmentation\n  in Remote Sensing Scenes",
        "link": "http://arxiv.org/abs/2405.19735v1",
        "abstract": "Thanks to the application of deep learning technology in point cloud\nprocessing of the remote sensing field, point cloud segmentation has become a\nresearch hotspot in recent years, which can be applied to real-world 3D, smart\ncities, and other fields. Although existing solutions have made unprecedented\nprogress, they ignore the inherent characteristics of point clouds in remote\nsensing fields that are strictly arranged according to latitude, longitude, and\naltitude, which brings great convenience to the segmentation of point clouds in\nremote sensing fields. To consider this property cleverly, we propose novel\nconvolution operators, termed Twin Deformable point Convolutions (TDConvs),\nwhich aim to achieve adaptive feature learning by learning deformable sampling\npoints in the latitude-longitude plane and altitude direction, respectively.\nFirst, to model the characteristics of the latitude-longitude plane, we propose\na Cylinder-wise Deformable point Convolution (CyDConv) operator, which\ngenerates a two-dimensional cylinder map by constructing a cylinder-like grid\nin the latitude-longitude direction. Furthermore, to better integrate the\nfeatures of the latitude-longitude plane and the spatial geometric features, we\nperform a multi-scale fusion of the extracted latitude-longitude features and\nspatial geometric features, and realize it through the aggregation of adjacent\npoint features of different scales. In addition, a Sphere-wise Deformable point\nConvolution (SpDConv) operator is introduced to adaptively offset the sampling\npoints in three-dimensional space by constructing a sphere grid structure,\naiming at modeling the characteristics in the altitude direction. Experiments\non existing popular benchmarks conclude that our TDConvs achieve the best\nsegmentation performance, surpassing the existing state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yong-Qiang Mao",
            "Hanbo Bi",
            "Xuexue Li",
            "Kaiqiang Chen",
            "Zhirui Wang",
            "Xian Sun",
            "Kun Fu"
        ],
        "published": "2024-05-30T06:31:03Z"
    },
    {
        "title": "Learning Task-relevant Sequence Representations via Intrinsic Dynamics\n  Characteristics in Reinforcement Learning",
        "link": "http://arxiv.org/abs/2405.19736v1",
        "abstract": "Learning task-relevant state representations is crucial to solving the\nproblem of scene generalization in visual deep reinforcement learning. Prior\nwork typically establishes a self-supervised auxiliary learner, introducing\nelements (e.g., rewards and actions) to extract task-relevant state information\nfrom observations through behavioral similarity metrics. However, the methods\noften ignore the inherent relationships between the elements (e.g., dynamics\nrelationships) that are essential for learning accurate representations, and\nthey are also limited to single-step metrics, which impedes the discrimination\nof short-term similar task/behavior information in long-term dynamics\ntransitions. To solve the issues, we propose an intrinsic dynamic\ncharacteristics-driven sequence representation learning method (DSR) over a\ncommon DRL frame. Concretely, inspired by the fact of state transition in the\nunderlying system, it constrains the optimization of the encoder via modeling\nthe dynamics equations related to the state transition, which prompts the\nlatent encoding information to satisfy the state transition process and thereby\ndistinguishes state space and noise space. Further, to refine the ability of\nencoding similar tasks based on dynamics constraints, DSR also sequentially\nmodels inherent dynamics equation relationships from the perspective of\nsequence elements' frequency domain and multi-step prediction. Finally,\nexperimental results show that DSR has achieved a significant performance boost\nin the Distracting DMControl Benchmark, with an average of 78.9% over the\nbackbone baseline. Further results indicate that it also achieves the best\nperformance in real-world autonomous driving tasks in the CARLA simulator.\nMoreover, the qualitative analysis results of t-SNE visualization validate that\nour method possesses superior representation ability on visual tasks.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Dayang Liang",
            "Jinyang Lai",
            "Yunlong Liu"
        ],
        "published": "2024-05-30T06:31:03Z"
    },
    {
        "title": "Two Optimizers Are Better Than One: LLM Catalyst for Enhancing\n  Gradient-Based Optimization",
        "link": "http://arxiv.org/abs/2405.19732v1",
        "abstract": "Learning a skill generally relies on both practical experience by doer and\ninsightful high-level guidance by instructor. Will this strategy also work well\nfor solving complex non-convex optimization problems? Here, a common\ngradient-based optimizer acts like a disciplined doer, making locally optimal\nupdate at each step. Recent methods utilize large language models (LLMs) to\noptimize solutions for concrete problems by inferring from natural language\ninstructions, akin to a high-level instructor. In this paper, we show that\nthese two optimizers are complementary to each other, suggesting a\ncollaborative optimization approach. The gradient-based optimizer and LLM-based\noptimizer are combined in an interleaved manner. We instruct LLMs using task\ndescriptions and timely optimization trajectories recorded during\ngradient-based optimization. Inferred results from LLMs are used as restarting\npoints for the next stage of gradient optimization. By leveraging both the\nlocally rigorous gradient-based optimizer and the high-level deductive\nLLM-based optimizer, our combined optimization method consistently yields\nimprovements over competitive baseline prompt tuning methods. Our results\ndemonstrate the synergistic effect of conventional gradient-based optimization\nand the inference ability of LLMs. The code is released at\nhttps://github.com/guozix/LLM-catalyst.",
        "subjects": [
            "cs.CV",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Zixian Guo",
            "Ming Liu",
            "Zhilong Ji",
            "Jinfeng Bai",
            "Yiwen Guo",
            "Wangmeng Zuo"
        ],
        "published": "2024-05-30T06:24:14Z"
    },
    {
        "title": "Some New Approaches to MPI Implementations",
        "link": "http://arxiv.org/abs/2405.19731v1",
        "abstract": "This paper provides some new approaches to MPI implementations to improve MPI\nperformance. These approaches include dynamically composable libraries,\nreducing average layer numbers of MPI libraries, and a single entity of\nMPI-network, MPI-protocol, and MPI.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Yuqing Xiong"
        ],
        "published": "2024-05-30T06:23:00Z"
    },
    {
        "title": "Research on Foundation Model for Spatial Data Intelligence: China's 2024\n  White Paper on Strategic Development of Spatial Data Intelligence",
        "link": "http://arxiv.org/abs/2405.19730v1",
        "abstract": "This report focuses on spatial data intelligent large models, delving into\nthe principles, methods, and cutting-edge applications of these models. It\nprovides an in-depth discussion on the definition, development history, current\nstatus, and trends of spatial data intelligent large models, as well as the\nchallenges they face. The report systematically elucidates the key technologies\nof spatial data intelligent large models and their applications in urban\nenvironments, aerospace remote sensing, geography, transportation, and other\nscenarios. Additionally, it summarizes the latest application cases of spatial\ndata intelligent large models in themes such as urban development, multimodal\nsystems, remote sensing, smart transportation, and resource environments.\nFinally, the report concludes with an overview and outlook on the development\nprospects of spatial data intelligent large models.",
        "subjects": [
            "cs.AI",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Shaohua Wang",
            "Xing Xie",
            "Yong Li",
            "Danhuai Guo",
            "Zhi Cai",
            "Yu Liu",
            "Yang Yue",
            "Xiao Pan",
            "Feng Lu",
            "Huayi Wu",
            "Zhipeng Gui",
            "Zhiming Ding",
            "Bolong Zheng",
            "Fuzheng Zhang",
            "Tao Qin",
            "Jingyuan Wang",
            "Chuang Tao",
            "Zhengchao Chen",
            "Hao Lu",
            "Jiayi Li",
            "Hongyang Chen",
            "Peng Yue",
            "Wenhao Yu",
            "Yao Yao",
            "Leilei Sun",
            "Yong Zhang",
            "Longbiao Chen",
            "Xiaoping Du",
            "Xiang Li",
            "Xueying Zhang",
            "Kun Qin",
            "Zhaoya Gong",
            "Weihua Dong",
            "Xiaofeng Meng"
        ],
        "published": "2024-05-30T06:21:34Z"
    },
    {
        "title": "Dynamic feature selection in medical predictive monitoring by\n  reinforcement learning",
        "link": "http://arxiv.org/abs/2405.19729v1",
        "abstract": "In this paper, we investigate dynamic feature selection within multivariate\ntime-series scenario, a common occurrence in clinical prediction monitoring\nwhere each feature corresponds to a bio-test result. Many existing feature\nselection methods fall short in effectively leveraging time-series information,\nprimarily because they are designed for static data. Our approach addresses\nthis limitation by enabling the selection of time-varying feature subsets for\neach patient. Specifically, we employ reinforcement learning to optimize a\npolicy under maximum cost restrictions. The prediction model is subsequently\nupdated using synthetic data generated by trained policy. Our method can\nseamlessly integrate with non-differentiable prediction models. We conducted\nexperiments on a sizable clinical dataset encompassing regression and\nclassification tasks. The results demonstrate that our approach outperforms\nstrong feature selection baselines, particularly when subjected to stringent\ncost limitations. Code will be released once paper is accepted.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Yutong Chen",
            "Jiandong Gao",
            "Ji Wu"
        ],
        "published": "2024-05-30T06:21:11Z"
    },
    {
        "title": "Automatic Dance Video Segmentation for Understanding Choreography",
        "link": "http://dx.doi.org/10.1145/3658852.3659076",
        "abstract": "Segmenting dance video into short movements is a popular way to easily\nunderstand dance choreography. However, it is currently done manually and\nrequires a significant amount of effort by experts. That is, even if many dance\nvideos are available on social media (e.g., TikTok and YouTube), it remains\ndifficult for people, especially novices, to casually watch short video\nsegments to practice dance choreography. In this paper, we propose a method to\nautomatically segment a dance video into each movement. Given a dance video as\ninput, we first extract visual and audio features: the former is computed from\nthe keypoints of the dancer in the video, and the latter is computed from the\nMel spectrogram of the music in the video. Next, these features are passed to a\nTemporal Convolutional Network (TCN), and segmentation points are estimated by\npicking peaks of the network output. To build our training dataset, we annotate\nsegmentation points to dance videos in the AIST Dance Video Database, which is\na shared database containing original street dance videos with\ncopyright-cleared dance music. The evaluation study shows that the proposed\nmethod (i.e., combining the visual and audio features) can estimate\nsegmentation points with high accuracy. In addition, we developed an\napplication to help dancers practice choreography using the proposed method.",
        "subjects": [
            "cs.CV",
            "cs.HC",
            "H.5.2; I.2.6"
        ],
        "authors": [
            "Koki Endo",
            "Shuhei Tsuchida",
            "Tsukasa Fukusato",
            "Takeo Igarashi"
        ],
        "published": "2024-05-30T06:19:01Z"
    },
    {
        "title": "Streaming Video Diffusion: Online Video Editing with Diffusion Models",
        "link": "http://arxiv.org/abs/2405.19726v1",
        "abstract": "We present a novel task called online video editing, which is designed to\nedit \\textbf{streaming} frames while maintaining temporal consistency. Unlike\nexisting offline video editing assuming all frames are pre-established and\naccessible, online video editing is tailored to real-life applications such as\nlive streaming and online chat, requiring (1) fast continual step inference,\n(2) long-term temporal modeling, and (3) zero-shot video editing capability. To\nsolve these issues, we propose Streaming Video Diffusion (SVDiff), which\nincorporates the compact spatial-aware temporal recurrence into off-the-shelf\nStable Diffusion and is trained with the segment-level scheme on large-scale\nlong videos. This simple yet effective setup allows us to obtain a single model\nthat is capable of executing a broad range of videos and editing each streaming\nframe with temporal coherence. Our experiments indicate that our model can edit\nlong, high-quality videos with remarkable results, achieving a real-time\ninference speed of 15.2 FPS at a resolution of 512x512.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Feng Chen",
            "Zhen Yang",
            "Bohan Zhuang",
            "Qi Wu"
        ],
        "published": "2024-05-30T06:16:33Z"
    },
    {
        "title": "Quantum Visual Feature Encoding Revisited",
        "link": "http://arxiv.org/abs/2405.19725v1",
        "abstract": "Although quantum machine learning has been introduced for a while, its\napplications in computer vision are still limited. This paper, therefore,\nrevisits the quantum visual encoding strategies, the initial step in quantum\nmachine learning. Investigating the root cause, we uncover that the existing\nquantum encoding design fails to ensure information preservation of the visual\nfeatures after the encoding process, thus complicating the learning process of\nthe quantum machine learning models. In particular, the problem, termed\n\"Quantum Information Gap\" (QIG), leads to a gap of information between\nclassical and corresponding quantum features. We provide theoretical proof and\npractical demonstrations of that found and underscore the significance of QIG,\nas it directly impacts the performance of quantum machine learning algorithms.\nTo tackle this challenge, we introduce a simple but efficient new loss function\nnamed Quantum Information Preserving (QIP) to minimize this gap, resulting in\nenhanced performance of quantum machine learning algorithms. Extensive\nexperiments validate the effectiveness of our approach, showcasing superior\nperformance compared to current methodologies and consistently achieving\nstate-of-the-art results in quantum modeling.",
        "subjects": [
            "quant-ph",
            "cs.CV"
        ],
        "authors": [
            "Xuan-Bac Nguyen",
            "Hoang-Quan Nguyen",
            "Hugh Churchill",
            "Samee U. Khan",
            "Khoa Luu"
        ],
        "published": "2024-05-30T06:15:08Z"
    },
    {
        "title": "Encoding and Controlling Global Semantics for Long-form Video Question\n  Answering",
        "link": "http://arxiv.org/abs/2405.19723v1",
        "abstract": "Seeking answers effectively for long videos is essential to build video\nquestion answering (videoQA) systems. Previous methods adaptively select frames\nand regions from long videos to save computations. However, this fails to\nreason over the whole sequence of video, leading to sub-optimal performance. To\naddress this problem, we introduce a state space layer (SSL) into multi-modal\nTransformer to efficiently integrate global semantics of the video, which\nmitigates the video information loss caused by frame and region selection\nmodules. Our SSL includes a gating unit to enable controllability over the flow\nof global semantics into visual representations. To further enhance the\ncontrollability, we introduce a cross-modal compositional congruence (C^3)\nobjective to encourage global semantics aligned with the question. To\nrigorously evaluate long-form videoQA capacity, we construct two new benchmarks\nEgo-QA and MAD-QA featuring videos of considerably long length, i.e. 17.5\nminutes and 1.9 hours, respectively. Extensive experiments demonstrate the\nsuperiority of our framework on these new as well as existing datasets.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Thong Thanh Nguyen",
            "Zhiyuan Hu",
            "Xiaobao Wu",
            "Cong-Duy T Nguyen",
            "See-Kiong Ng",
            "Anh Tuan Luu"
        ],
        "published": "2024-05-30T06:10:10Z"
    },
    {
        "title": "QClusformer: A Quantum Transformer-based Framework for Unsupervised\n  Visual Clustering",
        "link": "http://arxiv.org/abs/2405.19722v1",
        "abstract": "Unsupervised vision clustering, a cornerstone in computer vision, has been\nstudied for decades, yielding significant outcomes across numerous vision\ntasks. However, these algorithms involve substantial computational demands when\nconfronted with vast amounts of unlabeled data. Conversely, Quantum computing\nholds promise in expediting unsupervised algorithms when handling large-scale\ndatabases. In this study, we introduce QClusformer, a pioneering\nTransformer-based framework leveraging Quantum machines to tackle unsupervised\nvision clustering challenges. Specifically, we design the Transformer\narchitecture, including the self-attention module and transformer blocks, from\na Quantum perspective to enable execution on Quantum hardware. In addition, we\npresent QClusformer, a variant based on the Transformer architecture, tailored\nfor unsupervised vision clustering tasks. By integrating these elements into an\nend-to-end framework, QClusformer consistently outperforms previous methods\nrunning on classical computers. Empirical evaluations across diverse\nbenchmarks, including MS-Celeb-1M and DeepFashion, underscore the superior\nperformance of QClusformer compared to state-of-the-art methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xuan-Bac Nguyen",
            "Hoang-Quan Nguyen",
            "Samuel Yen-Chi Chen",
            "Samee U. Khan",
            "Hugh Churchill",
            "Khoa Luu"
        ],
        "published": "2024-05-30T06:07:57Z"
    },
    {
        "title": "LED: A Large-scale Real-world Paired Dataset for Event Camera Denoising",
        "link": "http://arxiv.org/abs/2405.19718v1",
        "abstract": "Event camera has significant advantages in capturing dynamic scene\ninformation while being prone to noise interference, particularly in\nchallenging conditions like low threshold and low illumination. However, most\nexisting research focuses on gentle situations, hindering event camera\napplications in realistic complex scenarios. To tackle this limitation and\nadvance the field, we construct a new paired real-world event denoising dataset\n(LED), including 3K sequences with 18K seconds of high-resolution (1200*680)\nevent streams and showing three notable distinctions compared to others:\ndiverse noise levels and scenes, larger-scale with high-resolution, and\nhigh-quality GT. Specifically, it contains stepped parameters and varying\nillumination with diverse scenarios. Moreover, based on the property of noise\nevents inconsistency and signal events consistency, we propose a novel\neffective denoising framework(DED) using homogeneous dual events to generate\nthe GT with better separating noise from the raw. Furthermore, we design a\nbio-inspired baseline leveraging Leaky-Integrate-and-Fire (LIF) neurons with\ndynamic thresholds to realize accurate denoising. The experimental results\ndemonstrate that the remarkable performance of the proposed approach on\ndifferent datasets.The dataset and code are at https://github.com/Yee-Sing/led.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Yuxing Duan",
            "Shihan Peng",
            "Lin Zhu",
            "Wei Zhang",
            "Yi Chang",
            "Sheng Zhong",
            "Luxin Yan"
        ],
        "published": "2024-05-30T06:02:35Z"
    },
    {
        "title": "Enhancing Large Vision Language Models with Self-Training on Image\n  Comprehension",
        "link": "http://arxiv.org/abs/2405.19716v1",
        "abstract": "Large vision language models (LVLMs) integrate large language models (LLMs)\nwith pre-trained vision encoders, thereby activating the perception capability\nof the model to understand image inputs for different queries and conduct\nsubsequent reasoning. Improving this capability requires high-quality\nvision-language data, which is costly and labor-intensive to acquire.\nSelf-training approaches have been effective in single-modal settings to\nalleviate the need for labeled data by leveraging model's own generation.\nHowever, effective self-training remains a challenge regarding the unique\nvisual perception and reasoning capability of LVLMs. To address this, we\nintroduce Self-Training on Image Comprehension (STIC), which emphasizes a\nself-training approach specifically for image comprehension. First, the model\nself-constructs a preference dataset for image descriptions using unlabeled\nimages. Preferred responses are generated through a step-by-step prompt, while\ndis-preferred responses are generated from either corrupted images or\nmisleading prompts. To further self-improve reasoning on the extracted visual\ninformation, we let the model reuse a small portion of existing\ninstruction-tuning data and append its self-generated image descriptions to the\nprompts. We validate the effectiveness of STIC across seven different\nbenchmarks, demonstrating substantial performance gains of 4.0% on average\nwhile using 70% less supervised fine-tuning data than the current method.\nFurther studies investigate various components of STIC and highlight its\npotential to leverage vast quantities of unlabeled images for self-training.\nCode and data are made publicly available.",
        "subjects": [
            "cs.CV",
            "cs.CL"
        ],
        "authors": [
            "Yihe Deng",
            "Pan Lu",
            "Fan Yin",
            "Ziniu Hu",
            "Sheng Shen",
            "James Zou",
            "Kai-Wei Chang",
            "Wei Wang"
        ],
        "published": "2024-05-30T05:53:49Z"
    },
    {
        "title": "SpecDec++: Boosting Speculative Decoding via Adaptive Candidate Lengths",
        "link": "http://arxiv.org/abs/2405.19715v1",
        "abstract": "Speculative decoding reduces the inference latency of a target large language\nmodel via utilizing a smaller and faster draft model. Its performance depends\non a hyperparameter K -- the candidate length, i.e., the number of candidate\ntokens for the target model to verify in each round. However, previous methods\noften use simple heuristics to choose K, which may result in sub-optimal\nperformance. We study the choice of the candidate length K and formulate it as\na Markov Decision Process. We theoretically show that the optimal policy of\nthis Markov decision process takes the form of a threshold policy, i.e., the\ncurrent speculation should stop and be verified when the probability of getting\na rejection exceeds a threshold value. Motivated by this theory, we propose\nSpecDec++, an enhanced version of speculative decoding that adaptively\ndetermines the candidate length on the fly. We augment the draft model with a\ntrained acceptance prediction head to predict the conditional acceptance\nprobability of the candidate tokens. SpecDec++ will stop the current\nspeculation when the predicted probability that at least one token gets\nrejected exceeds a threshold. We implement SpecDec++ and apply it to the\nllama-2-chat 7B & 70B model pair. Our adaptive method achieves a 2.04x speedup\non the Alpaca dataset (an additional 7.2% improvement over the baseline\nspeculative decoding). On the GSM8K and HumanEval datasets, our method achieves\na 2.26x speedup (9.4% improvement) and 2.23x speedup (11.1% improvement),\nrespectively.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Kaixuan Huang",
            "Xudong Guo",
            "Mengdi Wang"
        ],
        "published": "2024-05-30T05:49:38Z"
    },
    {
        "title": "Summing divergent matrix series",
        "link": "http://arxiv.org/abs/2405.19713v1",
        "abstract": "We extend several celebrated methods in classical analysis for summing series\nof complex numbers to series of complex matrices. These include the summation\nmethods of Abel, Borel, Ces\\'aro, Euler, Lambert, N\\\"orlund, and\nMittag-Leffler, which are frequently used to sum scalar series that are\ndivergent in the conventional sense. One feature of our matrix extensions is\nthat they are fully noncommutative generalizations of their scalar counterparts\n-- not only is the scalar series replaced by a matrix series, positive weights\nare replaced by positive definite matrix weights, order on $\\mathbb{R}$\nreplaced by Loewner order, exponential function replaced by matrix exponential\nfunction, etc. We will establish the regularity of our matrix summation\nmethods, i.e., when applied to a matrix series convergent in the conventional\nsense, we obtain the same value for the sum. Our second goal is to provide\nnumerical algorithms that work in conjunction with these summation methods. We\ndiscuss how the block and mixed-block summation algorithms, the Kahan\ncompensated summation algorithm, may be applied to matrix sums with similar\nroundoff error bounds. These summation methods and algorithms apply not only to\npower or Taylor series of matrices but to any general matrix series including\nmatrix Fourier and Dirichlet series. We will demonstrate the utility of these\nsummation methods: establishing a Fej\\'{e}r's theorem and alleviating the Gibbs\nphenomenon for matrix Fourier series; extending the domains of matrix functions\nand accurately evaluating them; enhancing the matrix Pad\\'e approximation and\nSchur--Parlett algorithms; and more.",
        "subjects": [
            "math.NA",
            "cs.NA",
            "math.CA",
            "15A16, 40D05, 40G10, 47A56, 65B10, 65F60"
        ],
        "authors": [
            "Rongbiao Wang",
            "JungHo Lee",
            "Lek-Heng Lim"
        ],
        "published": "2024-05-30T05:43:36Z"
    },
    {
        "title": "HINT: Learning Complete Human Neural Representations from Limited\n  Viewpoints",
        "link": "http://arxiv.org/abs/2405.19712v1",
        "abstract": "No augmented application is possible without animated humanoid avatars. At\nthe same time, generating human replicas from real-world monocular hand-held or\nrobotic sensor setups is challenging due to the limited availability of views.\nPrevious work showed the feasibility of virtual avatars but required the\npresence of 360 degree views of the targeted subject. To address this issue, we\npropose HINT, a NeRF-based algorithm able to learn a detailed and complete\nhuman model from limited viewing angles. We achieve this by introducing a\nsymmetry prior, regularization constraints, and training cues from large human\ndatasets. In particular, we introduce a sagittal plane symmetry prior to the\nappearance of the human, directly supervise the density function of the human\nmodel using explicit 3D body modeling, and leverage a co-learned human\ndigitization network as additional supervision for the unseen angles. As a\nresult, our method can reconstruct complete humans even from a few viewing\nangles, increasing performance by more than 15% PSNR compared to previous\nstate-of-the-art algorithms.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Alessandro Sanvito",
            "Andrea Ramazzina",
            "Stefanie Walz",
            "Mario Bijelic",
            "Felix Heide"
        ],
        "published": "2024-05-30T05:43:09Z"
    },
    {
        "title": "SimiSketch: Efficiently Estimating Similarity of streaming Multisets",
        "link": "http://arxiv.org/abs/2405.19711v1",
        "abstract": "The challenge of estimating similarity between sets has been a significant\nconcern in data science, finding diverse applications across various domains.\nHowever, previous approaches, such as MinHash, have predominantly centered\naround hashing techniques, which are well-suited for sets but less naturally\nadaptable to multisets, a common occurrence in scenarios like network streams\nand text data. Moreover, with the increasing prevalence of data arriving in\nstreaming patterns, many existing methods struggle to handle cases where set\nitems are presented in a continuous stream. Consequently, our focus in this\npaper is on the challenging scenario of multisets with item streams. To address\nthis, we propose SimiSketch, a sketching algorithm designed to tackle this\nspecific problem. The paper begins by presenting two simpler versions that\nemploy intuitive sketches for similarity estimation. Subsequently, we formally\nintroduce SimiSketch and leverage SALSA to enhance accuracy. To validate our\nalgorithms, we conduct extensive testing on synthetic datasets, real-world\nnetwork traffic, and text articles. Our experiment shows that compared with the\nstate-of-the-art, SimiSketch can improve the accuracy by up to 42 times, and\nincrease the throughput by up to 360 times. The complete source code is\nopen-sourced and available on GitHub for reference.",
        "subjects": [
            "cs.DS"
        ],
        "authors": [
            "Fenghao Dong",
            "Yang He",
            "Yutong Liang",
            "Zirui Liu",
            "Yuhan Wu",
            "Peiqing Chen",
            "Tong Yang"
        ],
        "published": "2024-05-30T05:43:01Z"
    },
    {
        "title": "Text Guided Image Editing with Automatic Concept Locating and Forgetting",
        "link": "http://arxiv.org/abs/2405.19708v1",
        "abstract": "With the advancement of image-to-image diffusion models guided by text,\nsignificant progress has been made in image editing. However, a persistent\nchallenge remains in seamlessly incorporating objects into images based on\ntextual instructions, without relying on extra user-provided guidance. Text and\nimages are inherently distinct modalities, bringing out difficulties in fully\ncapturing the semantic intent conveyed through language and accurately\ntranslating that into the desired visual modifications. Therefore, text-guided\nimage editing models often produce generations with residual object attributes\nthat do not fully align with human expectations. To address this challenge, the\nmodels should comprehend the image content effectively away from a disconnect\nbetween the provided textual editing prompts and the actual modifications made\nto the image. In our paper, we propose a novel method called Locate and Forget\n(LaF), which effectively locates potential target concepts in the image for\nmodification by comparing the syntactic trees of the target prompt and scene\ndescriptions in the input image, intending to forget their existence clues in\nthe generated image. Compared to the baselines, our method demonstrates its\nsuperiority in text-guided image editing tasks both qualitatively and\nquantitatively.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Jia Li",
            "Lijie Hu",
            "Zhixian He",
            "Jingfeng Zhang",
            "Tianhang Zheng",
            "Di Wang"
        ],
        "published": "2024-05-30T05:36:32Z"
    },
    {
        "title": "DeMamba: AI-Generated Video Detection on Million-Scale GenVideo\n  Benchmark",
        "link": "http://arxiv.org/abs/2405.19707v1",
        "abstract": "Recently, video generation techniques have advanced rapidly. Given the\npopularity of video content on social media platforms, these models intensify\nconcerns about the spread of fake information. Therefore, there is a growing\ndemand for detectors capable of distinguishing between fake AI-generated videos\nand mitigating the potential harm caused by fake information. However, the lack\nof large-scale datasets from the most advanced video generators poses a barrier\nto the development of such detectors. To address this gap, we introduce the\nfirst AI-generated video detection dataset, GenVideo. It features the following\ncharacteristics: (1) a large volume of videos, including over one million\nAI-generated and real videos collected; (2) a rich diversity of generated\ncontent and methodologies, covering a broad spectrum of video categories and\ngeneration techniques. We conducted extensive studies of the dataset and\nproposed two evaluation methods tailored for real-world-like scenarios to\nassess the detectors' performance: the cross-generator video classification\ntask assesses the generalizability of trained detectors on generators; the\ndegraded video classification task evaluates the robustness of detectors to\nhandle videos that have degraded in quality during dissemination. Moreover, we\nintroduced a plug-and-play module, named Detail Mamba (DeMamba), designed to\nenhance the detectors by identifying AI-generated videos through the analysis\nof inconsistencies in temporal and spatial dimensions. Our extensive\nexperiments demonstrate DeMamba's superior generalizability and robustness on\nGenVideo compared to existing detectors. We believe that the GenVideo dataset\nand the DeMamba module will significantly advance the field of AI-generated\nvideo detection. Our code and dataset will be aviliable at\n\\url{https://github.com/chenhaoxing/DeMamba}.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Haoxing Chen",
            "Yan Hong",
            "Zizheng Huang",
            "Zhuoer Xu",
            "Zhangxuan Gu",
            "Yaohui Li",
            "Jun Lan",
            "Huijia Zhu",
            "Jianfu Zhang",
            "Weiqiang Wang",
            "Huaxiong Li"
        ],
        "published": "2024-05-30T05:36:12Z"
    },
    {
        "title": "Bridging eResearch Infrastructure and Experimental Materials Science\n  Process in the Quantum Data Hub",
        "link": "http://arxiv.org/abs/2405.19706v1",
        "abstract": "Experimental materials science is experiencing significant growth due to\nautomated experimentation and AI techniques. Integrated autonomous platforms\nare emerging, combining generative models, robotics, simulations, and automated\nsystems for material synthesis. However, two major challenges remain:\ndemocratizing access to these technologies and creating accessible\ninfrastructure for under-resourced scientists. This paper introduces the\nQuantum Data Hub (QDH), a community-accessible research infrastructure aimed at\nresearchers working with quantum materials. QDH integrates with the National\nData Platform, adhering to FAIR principles while proposing additional UNIT\nprinciples for usability, navigability, interpretability, and timeliness. The\nQDH facilitates collaboration and extensibility, allowing seamless integration\nof new researchers, instruments, and data into the system.",
        "subjects": [
            "cs.SE",
            "cs.CE",
            "cs.ET"
        ],
        "authors": [
            "Amarnath Gupta",
            "Shweta Purawat",
            "Subhasis Dasgupta",
            "Pratyush Karmakar",
            "Elaine Chi",
            "Ilkay Altintas"
        ],
        "published": "2024-05-30T05:35:57Z"
    },
    {
        "title": "Universal Online Convex Optimization with $1$ Projection per Round",
        "link": "http://arxiv.org/abs/2405.19705v1",
        "abstract": "To address the uncertainty in function types, recent progress in online\nconvex optimization (OCO) has spurred the development of universal algorithms\nthat simultaneously attain minimax rates for multiple types of convex\nfunctions. However, for a $T$-round online problem, state-of-the-art methods\ntypically conduct $O(\\log T)$ projections onto the domain in each round, a\nprocess potentially time-consuming with complicated feasible sets. In this\npaper, inspired by the black-box reduction of Cutkosky and Orabona (2018), we\nemploy a surrogate loss defined over simpler domains to develop universal OCO\nalgorithms that only require $1$ projection. Embracing the framework of\nprediction with expert advice, we maintain a set of experts for each type of\nfunctions and aggregate their predictions via a meta-algorithm. The crux of our\napproach lies in a uniquely designed expert-loss for strongly convex functions,\nstemming from an innovative decomposition of the regret into the meta-regret\nand the expert-regret. Our analysis sheds new light on the surrogate loss,\nfacilitating a rigorous examination of the discrepancy between the regret of\nthe original loss and that of the surrogate loss, and carefully controlling\nmeta-regret under the strong convexity condition. In this way, with only $1$\nprojection per round, we establish optimal regret bounds for general convex,\nexponentially concave, and strongly convex functions simultaneously.\nFurthermore, we enhance the expert-loss to exploit the smoothness property, and\ndemonstrate that our algorithm can attain small-loss regret for multiple types\nof convex and smooth functions.",
        "subjects": [
            "cs.LG",
            "math.OC"
        ],
        "authors": [
            "Wenhao Yang",
            "Yibo Wang",
            "Peng Zhao",
            "Lijun Zhang"
        ],
        "published": "2024-05-30T05:29:40Z"
    },
    {
        "title": "Enhancing Sufficient Dimension Reduction via Hellinger Correlation",
        "link": "http://arxiv.org/abs/2405.19704v1",
        "abstract": "In this work, we develop a new theory and method for sufficient dimension\nreduction (SDR) in single-index models, where SDR is a sub-field of supervised\ndimension reduction based on conditional independence. Our work is primarily\nmotivated by the recent introduction of the Hellinger correlation as a\ndependency measure. Utilizing this measure, we develop a method capable of\neffectively detecting the dimension reduction subspace, complete with\ntheoretical justification. Through extensive numerical experiments, we\ndemonstrate that our proposed method significantly enhances and outperforms\nexisting SDR methods. This improvement is largely attributed to our proposed\nmethod's deeper understanding of data dependencies and the refinement of\nexisting SDR techniques.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "authors": [
            "Seungbeom Hong",
            "Ilmun Kim",
            "Jun Song"
        ],
        "published": "2024-05-30T05:29:12Z"
    },
    {
        "title": "Towards a Better Evaluation of Out-of-Domain Generalization",
        "link": "http://arxiv.org/abs/2405.19703v1",
        "abstract": "The objective of Domain Generalization (DG) is to devise algorithms and\nmodels capable of achieving high performance on previously unseen test\ndistributions. In the pursuit of this objective, average measure has been\nemployed as the prevalent measure for evaluating models and comparing\nalgorithms in the existing DG studies. Despite its significance, a\ncomprehensive exploration of the average measure has been lacking and its\nsuitability in approximating the true domain generalization performance has\nbeen questionable. In this study, we carefully investigate the limitations\ninherent in the average measure and propose worst+gap measure as a robust\nalternative. We establish theoretical grounds of the proposed measure by\nderiving two theorems starting from two different assumptions. We conduct\nextensive experimental investigations to compare the proposed worst+gap measure\nwith the conventional average measure. Given the indispensable need to access\nthe true DG performance for studying measures, we modify five existing datasets\nto come up with SR-CMNIST, C-Cats&Dogs, L-CIFAR10, PACS-corrupted, and\nVLCS-corrupted datasets. The experiment results unveil an inferior performance\nof the average measure in approximating the true DG performance and confirm the\nrobustness of the theoretically supported worst+gap measure.",
        "subjects": [
            "cs.LG",
            "cs.CV",
            "stat.ML"
        ],
        "authors": [
            "Duhun Hwang",
            "Suhyun Kang",
            "Moonjung Eo",
            "Jimyeong Kim",
            "Wonjong Rhee"
        ],
        "published": "2024-05-30T05:27:46Z"
    },
    {
        "title": "Significance of Chain of Thought in Gender Bias Mitigation for\n  English-Dravidian Machine Translation",
        "link": "http://arxiv.org/abs/2405.19701v1",
        "abstract": "Gender bias in machine translation (MT) systems poses a significant challenge\nto achieving accurate and inclusive translations. This paper examines gender\nbias in machine translation systems for languages such as Telugu and Kannada\nfrom the Dravidian family, analyzing how gender inflections affect translation\naccuracy and neutrality using Google Translate and ChatGPT. It finds that while\nplural forms can reduce bias, individual-centric sentences often maintain the\nbias due to historical stereotypes. The study evaluates the Chain of Thought\nprocessing, noting significant bias mitigation from 80% to 4% in Telugu and\nfrom 40% to 0% in Kannada. It also compares Telugu and Kannada translations,\nemphasizing the need for language specific strategies to address these\nchallenges and suggesting directions for future research to enhance fairness in\nboth data preparation and prompts during inference.",
        "subjects": [
            "cs.CL",
            "cs.AI"
        ],
        "authors": [
            "Lavanya Prahallad",
            "Radhika Mamidi"
        ],
        "published": "2024-05-30T05:26:57Z"
    },
    {
        "title": "Fairness in AI-Driven Recruitment: Challenges, Metrics, Methods, and\n  Future Directions",
        "link": "http://arxiv.org/abs/2405.19699v1",
        "abstract": "The recruitment process is crucial to an organization's ability to position\nitself for success, from finding qualified and well-fitting job candidates to\nimpacting its output and culture. Therefore, over the past century, human\nresources experts and industrial-organizational psychologists have established\nhiring practices such as attracting candidates with job ads, gauging a\ncandidate's skills with assessments, and using interview questions to assess\norganizational fit. However, the advent of big data and machine learning has\nled to a rapid transformation in the traditional recruitment process as many\norganizations have moved to using artificial intelligence (AI). Given the\nprevalence of AI-based recruitment, there is growing concern that human biases\nmay carry over to decisions made by these systems, which can amplify the effect\nthrough systematic application. Empirical studies have identified prevalent\nbiases in candidate ranking software and chatbot interactions, catalyzing a\ngrowing body of research dedicated to AI fairness over the last decade. This\npaper provides a comprehensive overview of this emerging field by discussing\nthe types of biases encountered in AI-driven recruitment, exploring various\nfairness metrics and mitigation methods, and examining tools for auditing these\nsystems. We highlight current challenges and outline future directions for\ndeveloping fair AI recruitment applications, ensuring equitable candidate\ntreatment and enhancing organizational outcomes.",
        "subjects": [
            "cs.CY",
            "K.4.3; I.2.0; J.4"
        ],
        "authors": [
            "Dena F. Mujtaba",
            "Nihar R. Mahapatra"
        ],
        "published": "2024-05-30T05:25:14Z"
    },
    {
        "title": "Bilevel reinforcement learning via the development of hyper-gradient\n  without lower-level convexity",
        "link": "http://arxiv.org/abs/2405.19697v1",
        "abstract": "Bilevel reinforcement learning (RL), which features intertwined two-level\nproblems, has attracted growing interest recently. The inherent non-convexity\nof the lower-level RL problem is, however, to be an impediment to developing\nbilevel optimization methods. By employing the fixed point equation associated\nwith the regularized RL, we characterize the hyper-gradient via fully\nfirst-order information, thus circumventing the assumption of lower-level\nconvexity. This, remarkably, distinguishes our development of hyper-gradient\nfrom the general AID-based bilevel frameworks since we take advantage of the\nspecific structure of RL problems. Moreover, we propose both model-based and\nmodel-free bilevel reinforcement learning algorithms, facilitated by access to\nthe fully first-order hyper-gradient. Both algorithms are provable to enjoy the\nconvergence rate $\\mathcal{O}(\\epsilon^{-1})$. To the best of our knowledge,\nthis is the first time that AID-based bilevel RL gets rid of additional\nassumptions on the lower-level problem. In addition, numerical experiments\ndemonstrate that the hyper-gradient indeed serves as an integration of\nexploitation and exploration.",
        "subjects": [
            "math.OC",
            "cs.AI",
            "cs.LG",
            "stat.ML"
        ],
        "authors": [
            "Yan Yang",
            "Bin Gao",
            "Ya-xiang Yuan"
        ],
        "published": "2024-05-30T05:24:20Z"
    },
    {
        "title": "Distribution Aligned Semantics Adaption for Lifelong Person\n  Re-Identification",
        "link": "http://arxiv.org/abs/2405.19695v1",
        "abstract": "In real-world scenarios, person Re-IDentification (Re-ID) systems need to be\nadaptable to changes in space and time. Therefore, the adaptation of Re-ID\nmodels to new domains while preserving previously acquired knowledge is\ncrucial, known as Lifelong person Re-IDentification (LReID). Advanced LReID\nmethods rely on replaying exemplars from old domains and applying knowledge\ndistillation in logits with old models. However, due to privacy concerns,\nretaining previous data is inappropriate. Additionally, the fine-grained and\nopen-set characteristics of Re-ID limit the effectiveness of the distillation\nparadigm for accumulating knowledge. We argue that a Re-ID model trained on\ndiverse and challenging pedestrian images at a large scale can acquire robust\nand general human semantic knowledge. These semantics can be readily utilized\nas shared knowledge for lifelong applications. In this paper, we identify the\nchallenges and discrepancies associated with adapting a pre-trained model to\neach application domain, and introduce the Distribution Aligned Semantics\nAdaption (DASA) framework. It efficiently adjusts Batch Normalization (BN) to\nmitigate interference from data distribution discrepancy and freezes the\npre-trained convolutional layers to preserve shared knowledge. Additionally, we\npropose the lightweight Semantics Adaption (SA) module, which effectively\nadapts learned semantics to enhance pedestrian representations. Extensive\nexperiments demonstrate the remarkable superiority of our proposed framework\nover advanced LReID methods, and it exhibits significantly reduced storage\nconsumption. DASA presents a novel and cost-effective perspective on\neffectively adapting pre-trained models for LReID.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Qizao Wang",
            "Xuelin Qian",
            "Bin Li",
            "Xiangyang Xue"
        ],
        "published": "2024-05-30T05:15:38Z"
    },
    {
        "title": "Grade Like a Human: Rethinking Automated Assessment with Large Language\n  Models",
        "link": "http://arxiv.org/abs/2405.19694v1",
        "abstract": "While large language models (LLMs) have been used for automated grading, they\nhave not yet achieved the same level of performance as humans, especially when\nit comes to grading complex questions. Existing research on this topic focuses\non a particular step in the grading procedure: grading using predefined\nrubrics. However, grading is a multifaceted procedure that encompasses other\ncrucial steps, such as grading rubrics design and post-grading review. There\nhas been a lack of systematic research exploring the potential of LLMs to\nenhance the entire grading~process.\n  In this paper, we propose an LLM-based grading system that addresses the\nentire grading procedure, including the following key components: 1) Developing\ngrading rubrics that not only consider the questions but also the student\nanswers, which can more accurately reflect students' performance. 2) Under the\nguidance of grading rubrics, providing accurate and consistent scores for each\nstudent, along with customized feedback. 3) Conducting post-grading review to\nbetter ensure accuracy and fairness. Additionally, we collected a new dataset\nnamed OS from a university operating system course and conducted extensive\nexperiments on both our new dataset and the widely used Mohler dataset.\nExperiments demonstrate the effectiveness of our proposed approach, providing\nsome new insights for developing automated grading systems based on LLMs.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Wenjing Xie",
            "Juxin Niu",
            "Chun Jason Xue",
            "Nan Guan"
        ],
        "published": "2024-05-30T05:08:15Z"
    },
    {
        "title": "Designing Prompt Analytics Dashboards to Analyze Student-ChatGPT\n  Interactions in EFL Writing",
        "link": "http://arxiv.org/abs/2405.19691v1",
        "abstract": "While ChatGPT has significantly impacted education by offering personalized\nresources for students, its integration into educational settings poses\nunprecedented risks, such as inaccuracies and biases in AI-generated content,\nplagiarism and over-reliance on AI, and privacy and security issues. To help\nteachers address such risks, we conducted a two-phase iterative design process\nthat comprises surveys, interviews, and prototype demonstration involving six\nEFL (English as a Foreign Language) teachers, who integrated ChatGPT into\nsemester-long English essay writing classes. Based on the needs identified\nduring the initial survey and interviews, we developed a prototype of Prompt\nAnalytics Dashboard (PAD) that integrates the essay editing history and chat\nlogs between students and ChatGPT. Teacher's feedback on the prototype informs\nadditional features and unmet needs for designing future PAD, which helps them\n(1) analyze contextual analysis of student behaviors, (2) design an overall\nlearning loop, and (3) develop their teaching skills.",
        "subjects": [
            "cs.HC"
        ],
        "authors": [
            "Minsun Kim",
            "SeonGyeom Kim",
            "Suyoun Lee",
            "Yoosang Yoon",
            "Junho Myung",
            "Haneul Yoo",
            "Hyungseung Lim",
            "Jieun Han",
            "Yoonsu Kim",
            "So-Yeon Ahn",
            "Juho Kim",
            "Alice Oh",
            "Hwajung Hong",
            "Tak Yeon Lee"
        ],
        "published": "2024-05-30T05:04:46Z"
    },
    {
        "title": "Diffusion Policies creating a Trust Region for Offline Reinforcement\n  Learning",
        "link": "http://arxiv.org/abs/2405.19690v1",
        "abstract": "Offline reinforcement learning (RL) leverages pre-collected datasets to train\noptimal policies. Diffusion Q-Learning (DQL), introducing diffusion models as a\npowerful and expressive policy class, significantly boosts the performance of\noffline RL. However, its reliance on iterative denoising sampling to generate\nactions slows down both training and inference. While several recent attempts\nhave tried to accelerate diffusion-QL, the improvement in training and/or\ninference speed often results in degraded performance. In this paper, we\nintroduce a dual policy approach, Diffusion Trusted Q-Learning (DTQL), which\ncomprises a diffusion policy for pure behavior cloning and a practical one-step\npolicy. We bridge the two polices by a newly introduced diffusion trust region\nloss. The diffusion policy maintains expressiveness, while the trust region\nloss directs the one-step policy to explore freely and seek modes within the\nregion defined by the diffusion policy. DTQL eliminates the need for iterative\ndenoising sampling during both training and inference, making it remarkably\ncomputationally efficient. We evaluate its effectiveness and algorithmic\ncharacteristics against popular Kullback-Leibler (KL) based distillation\nmethods in 2D bandit scenarios and gym tasks. We then show that DTQL could not\nonly outperform other methods on the majority of the D4RL benchmark tasks but\nalso demonstrate efficiency in training and inference speeds. The PyTorch\nimplementation will be made available.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Tianyu Chen",
            "Zhendong Wang",
            "Mingyuan Zhou"
        ],
        "published": "2024-05-30T05:04:33Z"
    },
    {
        "title": "Uncertainty-aware sign language video retrieval with probability\n  distribution modeling",
        "link": "http://arxiv.org/abs/2405.19689v1",
        "abstract": "Sign language video retrieval plays a key role in facilitating information\naccess for the deaf community. Despite significant advances in video-text\nretrieval, the complexity and inherent uncertainty of sign language preclude\nthe direct application of these techniques. Previous methods achieve the\nmapping between sign language video and text through fine-grained modal\nalignment. However, due to the scarcity of fine-grained annotation, the\nuncertainty inherent in sign language video is underestimated, limiting the\nfurther development of sign language retrieval tasks. To address this\nchallenge, we propose a novel Uncertainty-aware Probability Distribution\nRetrieval (UPRet), that conceptualizes the mapping process of sign language\nvideo and text in terms of probability distributions, explores their potential\ninterrelationships, and enables flexible mappings. Experiments on three\nbenchmarks demonstrate the effectiveness of our method, which achieves\nstate-of-the-art results on How2Sign (59.1%), PHOENIX-2014T (72.0%), and\nCSL-Daily (78.4%).",
        "subjects": [
            "cs.CV",
            "cs.IR"
        ],
        "authors": [
            "Xuan Wu",
            "Hongxiang Li",
            "Yuanjiang Luo",
            "Xuxin Cheng",
            "Xianwei Zhuang",
            "Meng Cao",
            "Keren Fu"
        ],
        "published": "2024-05-30T05:04:01Z"
    },
    {
        "title": "DNPM: A Neural Parametric Model for the Synthesis of Facial Geometric\n  Details",
        "link": "http://arxiv.org/abs/2405.19688v1",
        "abstract": "Parametric 3D models have enabled a wide variety of computer vision and\ngraphics tasks, such as modeling human faces, bodies and hands. In 3D face\nmodeling, 3DMM is the most widely used parametric model, but can't generate\nfine geometric details solely from identity and expression inputs. To tackle\nthis limitation, we propose a neural parametric model named DNPM for the facial\ngeometric details, which utilizes deep neural network to extract latent codes\nfrom facial displacement maps encoding details and wrinkles. Built upon DNPM, a\nnovel 3DMM named Detailed3DMM is proposed, which augments traditional 3DMMs by\nincluding the synthesis of facial details only from the identity and expression\ninputs. Moreover, we show that DNPM and Detailed3DMM can facilitate two\ndownstream applications: speech-driven detailed 3D facial animation and 3D face\nreconstruction from a degraded image. Extensive experiments have shown the\nusefulness of DNPM and Detailed3DMM, and the progressiveness of two proposed\napplications.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Haitao Cao",
            "Baoping Cheng",
            "Qiran Pu",
            "Haocheng Zhang",
            "Bin Luo",
            "Yixiang Zhuang",
            "Juncong Lin",
            "Liyan Chen",
            "Xuan Cheng"
        ],
        "published": "2024-05-30T04:57:55Z"
    },
    {
        "title": "Autonomous Driving with Spiking Neural Networks",
        "link": "http://arxiv.org/abs/2405.19687v1",
        "abstract": "Autonomous driving demands an integrated approach that encompasses\nperception, prediction, and planning, all while operating under strict energy\nconstraints to enhance scalability and environmental sustainability. We present\nSpiking Autonomous Driving (\\name{}), the first unified Spiking Neural Network\n(SNN) to address the energy challenges faced by autonomous driving systems\nthrough its event-driven and energy-efficient nature. SAD is trained end-to-end\nand consists of three main modules: perception, which processes inputs from\nmulti-view cameras to construct a spatiotemporal bird's eye view; prediction,\nwhich utilizes a novel dual-pathway with spiking neurons to forecast future\nstates; and planning, which generates safe trajectories considering predicted\noccupancy, traffic rules, and ride comfort. Evaluated on the nuScenes dataset,\nSAD achieves competitive performance in perception, prediction, and planning\ntasks, while drawing upon the energy efficiency of SNNs. This work highlights\nthe potential of neuromorphic computing to be applied to energy-efficient\nautonomous driving, a critical step toward sustainable and safety-critical\nautomotive technology. Our code is available at\n\\url{https://github.com/ridgerchu/SAD}.",
        "subjects": [
            "cs.NE",
            "cs.CV"
        ],
        "authors": [
            "Rui-Jie Zhu",
            "Ziqing Wang",
            "Leilani Gilpin",
            "Jason K. Eshraghian"
        ],
        "published": "2024-05-30T04:57:54Z"
    },
    {
        "title": "Knowledge Graph Tuning: Real-time Large Language Model Personalization\n  based on Human Feedback",
        "link": "http://arxiv.org/abs/2405.19686v1",
        "abstract": "Large language models (LLMs) have demonstrated remarkable proficiency in a\nrange of natural language processing tasks. Once deployed, LLMs encounter users\nwith personalized factual knowledge, and such personalized knowledge is\nconsistently reflected through users' interactions with the LLMs. To enhance\nuser experience, real-time model personalization is essential, allowing LLMs to\nadapt user-specific knowledge based on user feedback during human-LLM\ninteractions. Existing methods mostly require back-propagation to finetune the\nmodel parameters, which incurs high computational and memory costs. In\naddition, these methods suffer from low interpretability, which will cause\nunforeseen impacts on model performance during long-term use, where the user's\npersonalized knowledge is accumulated extensively.To address these challenges,\nwe propose Knowledge Graph Tuning (KGT), a novel approach that leverages\nknowledge graphs (KGs) to personalize LLMs. KGT extracts personalized factual\nknowledge triples from users' queries and feedback and optimizes KGs without\nmodifying the LLM parameters. Our method improves computational and memory\nefficiency by avoiding back-propagation and ensures interpretability by making\nthe KG adjustments comprehensible to humans.Experiments with state-of-the-art\nLLMs, including GPT-2, Llama2, and Llama3, show that KGT significantly improves\npersonalization performance while reducing latency and GPU memory costs.\nUltimately, KGT offers a promising solution of effective, efficient, and\ninterpretable real-time LLM personalization during user interactions with the\nLLMs.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Jingwei Sun",
            "Zhixu Du",
            "Yiran Chen"
        ],
        "published": "2024-05-30T04:57:03Z"
    },
    {
        "title": "A Comprehensive Survey on Underwater Image Enhancement Based on Deep\n  Learning",
        "link": "http://arxiv.org/abs/2405.19684v1",
        "abstract": "Underwater image enhancement (UIE) is a challenging research task in the\nfield of computer vision. Although hundreds of UIE algorithms have been\nproposed, a comprehensive and systematic review is still lacking. To promote\nfuture research, we summarize the UIE task from multiple perspectives. First,\nthe physical models, data construction processes, evaluation metrics, and loss\nfunctions are introduced. Second, according to the contributions brought by\ndifferent literatures, recent proposed algorithms are discussed and classified\nfrom six perspectives, namely network architecture, learning strategy, learning\nstage, assistance task, domain perspective and disentanglement fusion,\nrespectively. Third, considering the inconsistencies in experimental settings\nin different literatures, a comprehensive and fair comparison does not yet\nexist. To this end, we quantitatively and qualitatively evaluate\nstate-of-the-art algorithms on multiple benchmark datasets. Finally, issues\nworthy of further research in the UIE task are raised. A collection of useful\nmaterials is available at https://github.com/YuZhao1999/UIE.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xiaofeng Cong",
            "Yu Zhao",
            "Jie Gui",
            "Junming Hou",
            "Dacheng Tao"
        ],
        "published": "2024-05-30T04:46:40Z"
    },
    {
        "title": "Breaking Indistinguishability with Transfer Learning: A First Look at\n  SPECK32/64 Lightweight Block Ciphers",
        "link": "http://arxiv.org/abs/2405.19683v1",
        "abstract": "In this research, we introduce MIND-Crypt, a novel attack framework that uses\ndeep learning (DL) and transfer learning (TL) to challenge the\nindistinguishability of block ciphers, specifically SPECK32/64 encryption\nalgorithm in CBC mode (Cipher Block Chaining) against Known Plaintext Attacks\n(KPA). Our methodology includes training a DL model with ciphertexts of two\nmessages encrypted using the same key. The selected messages have the same\nbyte-length and differ by only one bit at the binary level. This DL model\nemploys a residual network architecture. For the TL, we use the trained DL\nmodel as a feature extractor, and these features are then used to train a\nshallow machine learning, such as XGBoost. This dual strategy aims to\ndistinguish ciphertexts of two encrypted messages, addressing traditional\ncryptanalysis challenges.\n  Our findings demonstrate that the DL model achieves an accuracy of\napproximately 99% under consistent cryptographic conditions (Same Key or\nRounds) with the SPECK32/64 cipher. However, performance degrades to random\nguessing levels (50%) when tested with ciphertext generated from different keys\nor different encryption rounds of SPECK32/64. To enhance the results, the DL\nmodel requires retraining with different keys or encryption rounds using larger\ndatasets (10^7 samples). To overcome this limitation, we implement TL,\nachieving an accuracy of about 53% with just 10,000 samples, which is better\nthan random guessing. Further training with 580,000 samples increases accuracy\nto nearly 99%, showing a substantial reduction in data requirements by over\n94%. This shows that an attacker can utilize machine learning models to break\nindistinguishability by accessing pairs of plaintexts and their corresponding\nciphertexts encrypted with the same key, without directly interacting with the\ncommunicating parties.",
        "subjects": [
            "cs.CR",
            "cs.LG"
        ],
        "authors": [
            "Jimmy Dani",
            "Kalyan Nakka",
            "Nitesh Saxena"
        ],
        "published": "2024-05-30T04:40:13Z"
    },
    {
        "title": "Fully Test-Time Adaptation for Monocular 3D Object Detection",
        "link": "http://arxiv.org/abs/2405.19682v1",
        "abstract": "Monocular 3D object detection (Mono 3Det) aims to identify 3D objects from a\nsingle RGB image. However, existing methods often assume training and test data\nfollow the same distribution, which may not hold in real-world test scenarios.\nTo address the out-of-distribution (OOD) problems, we explore a new adaptation\nparadigm for Mono 3Det, termed Fully Test-time Adaptation. It aims to adapt a\nwell-trained model to unlabeled test data by handling potential data\ndistribution shifts at test time without access to training data and test\nlabels. However, applying this paradigm in Mono 3Det poses significant\nchallenges due to OOD test data causing a remarkable decline in object\ndetection scores. This decline conflicts with the pre-defined score thresholds\nof existing detection methods, leading to severe object omissions (i.e., rare\npositive detections and many false negatives). Consequently, the limited\npositive detection and plenty of noisy predictions cause test-time adaptation\nto fail in Mono 3Det. To handle this problem, we propose a novel Monocular\nTest-Time Adaptation (MonoTTA) method, based on two new strategies. 1)\nReliability-driven adaptation: we empirically find that high-score objects are\nstill reliable and the optimization of high-score objects can enhance\nconfidence across all detections. Thus, we devise a self-adaptive strategy to\nidentify reliable objects for model adaptation, which discovers potential\nobjects and alleviates omissions. 2) Noise-guard adaptation: since high-score\nobjects may be scarce, we develop a negative regularization term to exploit the\nnumerous low-score objects via negative learning, preventing overfitting to\nnoise and trivial solutions. Experimental results show that MonoTTA brings\nsignificant performance gains for Mono 3Det models in OOD test scenarios,\napproximately 190% gains by average on KITTI and 198% gains on nuScenes.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Hongbin Lin",
            "Yifan Zhang",
            "Shuaicheng Niu",
            "Shuguang Cui",
            "Zhen Li"
        ],
        "published": "2024-05-30T04:37:57Z"
    },
    {
        "title": "Bayesian Online Natural Gradient (BONG)",
        "link": "http://arxiv.org/abs/2405.19681v1",
        "abstract": "We propose a novel approach to sequential Bayesian inference based on\nvariational Bayes. The key insight is that, in the online setting, we do not\nneed to add the KL term to regularize to the prior (which comes from the\nposterior at the previous timestep); instead we can optimize just the expected\nlog-likelihood, performing a single step of natural gradient descent starting\nat the prior predictive. We prove this method recovers exact Bayesian inference\nif the model is conjugate, and empirically outperforms other online VB methods\nin the non-conjugate setting, such as online learning for neural networks,\nespecially when controlling for computational costs.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.CO"
        ],
        "authors": [
            "Matt Jones",
            "Peter Chang",
            "Kevin Murphy"
        ],
        "published": "2024-05-30T04:27:36Z"
    },
    {
        "title": "Efficient Trajectory Inference in Wasserstein Space Using Consecutive\n  Averaging",
        "link": "http://arxiv.org/abs/2405.19679v1",
        "abstract": "Capturing data from dynamic processes through cross-sectional measurements is\nseen in many fields such as computational biology. Trajectory inference deals\nwith the challenge of reconstructing continuous processes from such\nobservations. In this work, we propose methods for B-spline approximation and\ninterpolation of point clouds through consecutive averaging that is instrinsic\nto the Wasserstein space. Combining subdivision schemes with optimal\ntransport-based geodesic, our methods carry out trajectory inference at a\nchosen level of precision and smoothness, and can automatically handle\nscenarios where particles undergo division over time. We rigorously evaluate\nour method by providing convergence guarantees and testing it on simulated cell\ndata characterized by bifurcations and merges, comparing its performance\nagainst state-of-the-art trajectory inference and interpolation methods. The\nresults not only underscore the effectiveness of our method in inferring\ntrajectories, but also highlight the benefit of performing interpolation and\napproximation that respect the inherent geometric properties of the data.",
        "subjects": [
            "cs.LG",
            "cs.NA",
            "math.NA",
            "math.OC"
        ],
        "authors": [
            "Amartya Banerjee",
            "Harlin Lee",
            "Nir Sharon",
            "Caroline Moosmüller"
        ],
        "published": "2024-05-30T04:19:20Z"
    },
    {
        "title": "View-Consistent Hierarchical 3D SegmentationUsing Ultrametric Feature\n  Fields",
        "link": "http://arxiv.org/abs/2405.19678v1",
        "abstract": "Large-scale vision foundation models such as Segment Anything (SAM)\ndemonstrate impressive performance in zero-shot image segmentation at multiple\nlevels of granularity. However, these zero-shot predictions are rarely\n3D-consistent. As the camera viewpoint changes in a scene, so do the\nsegmentation predictions, as well as the characterizations of ``coarse\" or\n``fine\" granularity. In this work, we address the challenging task of lifting\nmulti-granular and view-inconsistent image segmentations into a hierarchical\nand 3D-consistent representation. We learn a novel feature field within a\nNeural Radiance Field (NeRF) representing a 3D scene, whose segmentation\nstructure can be revealed at different scales by simply using different\nthresholds on feature distance. Our key idea is to learn an ultrametric feature\nspace, which unlike a Euclidean space, exhibits transitivity in distance-based\ngrouping, naturally leading to a hierarchical clustering. Put together, our\nmethod takes view-inconsistent multi-granularity 2D segmentations as input and\nproduces a hierarchy of 3D-consistent segmentations as output. We evaluate our\nmethod and several baselines on synthetic datasets with multi-view images and\nmulti-granular segmentation, showcasing improved accuracy and\nviewpoint-consistency. We additionally provide qualitative examples of our\nmodel's 3D hierarchical segmentations in real world scenes.\\footnote{The code\nand dataset are available at:",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Haodi He",
            "Colton Stearns",
            "Adam W. Harley",
            "Leonidas J. Guibas"
        ],
        "published": "2024-05-30T04:14:58Z"
    },
    {
        "title": "Large Language Model Watermark Stealing With Mixed Integer Programming",
        "link": "http://arxiv.org/abs/2405.19677v1",
        "abstract": "The Large Language Model (LLM) watermark is a newly emerging technique that\nshows promise in addressing concerns surrounding LLM copyright, monitoring\nAI-generated text, and preventing its misuse. The LLM watermark scheme commonly\nincludes generating secret keys to partition the vocabulary into green and red\nlists, applying a perturbation to the logits of tokens in the green list to\nincrease their sampling likelihood, thus facilitating watermark detection to\nidentify AI-generated text if the proportion of green tokens exceeds a\nthreshold. However, recent research indicates that watermarking methods using\nnumerous keys are susceptible to removal attacks, such as token editing,\nsynonym substitution, and paraphrasing, with robustness declining as the number\nof keys increases. Therefore, the state-of-the-art watermark schemes that\nemploy fewer or single keys have been demonstrated to be more robust against\ntext editing and paraphrasing. In this paper, we propose a novel green list\nstealing attack against the state-of-the-art LLM watermark scheme and\nsystematically examine its vulnerability to this attack. We formalize the\nattack as a mixed integer programming problem with constraints. We evaluate our\nattack under a comprehensive threat model, including an extreme scenario where\nthe attacker has no prior knowledge, lacks access to the watermark detector\nAPI, and possesses no information about the LLM's parameter settings or\nwatermark injection/detection scheme. Extensive experiments on LLMs, such as\nOPT and LLaMA, demonstrate that our attack can successfully steal the green\nlist and remove the watermark across all settings.",
        "subjects": [
            "cs.CR",
            "cs.AI"
        ],
        "authors": [
            "Zhaoxi Zhang",
            "Xiaomei Zhang",
            "Yanjun Zhang",
            "Leo Yu Zhang",
            "Chao Chen",
            "Shengshan Hu",
            "Asif Gill",
            "Shirui Pan"
        ],
        "published": "2024-05-30T04:11:17Z"
    },
    {
        "title": "Knowledge-grounded Adaptation Strategy for Vision-language Models:\n  Building Unique Case-set for Screening Mammograms for Residents Training",
        "link": "http://arxiv.org/abs/2405.19675v1",
        "abstract": "A visual-language model (VLM) pre-trained on natural images and text pairs\nposes a significant barrier when applied to medical contexts due to domain\nshift. Yet, adapting or fine-tuning these VLMs for medical use presents\nconsiderable hurdles, including domain misalignment, limited access to\nextensive datasets, and high-class imbalances. Hence, there is a pressing need\nfor strategies to effectively adapt these VLMs to the medical domain, as such\nadaptations would prove immensely valuable in healthcare applications. In this\nstudy, we propose a framework designed to adeptly tailor VLMs to the medical\ndomain, employing selective sampling and hard-negative mining techniques for\nenhanced performance in retrieval tasks. We validate the efficacy of our\nproposed approach by implementing it across two distinct VLMs: the in-domain\nVLM (MedCLIP) and out-of-domain VLMs (ALBEF). We assess the performance of\nthese models both in their original off-the-shelf state and after undergoing\nour proposed training strategies, using two extensive datasets containing\nmammograms and their corresponding reports. Our evaluation spans zero-shot,\nfew-shot, and supervised scenarios. Through our approach, we observe a notable\nenhancement in Recall@K performance for the image-text retrieval task.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Aisha Urooj Khan",
            "John Garrett",
            "Tyler Bradshaw",
            "Lonie Salkowski",
            "Jiwoong Jason Jeong",
            "Amara Tariq",
            "Imon Banerjee"
        ],
        "published": "2024-05-30T04:04:36Z"
    },
    {
        "title": "Bridging Model-Based Optimization and Generative Modeling via\n  Conservative Fine-Tuning of Diffusion Models",
        "link": "http://arxiv.org/abs/2405.19673v1",
        "abstract": "AI-driven design problems, such as DNA/protein sequence design, are commonly\ntackled from two angles: generative modeling, which efficiently captures the\nfeasible design space (e.g., natural images or biological sequences), and\nmodel-based optimization, which utilizes reward models for extrapolation. To\ncombine the strengths of both approaches, we adopt a hybrid method that\nfine-tunes cutting-edge diffusion models by optimizing reward models through\nRL. Although prior work has explored similar avenues, they primarily focus on\nscenarios where accurate reward models are accessible. In contrast, we\nconcentrate on an offline setting where a reward model is unknown, and we must\nlearn from static offline datasets, a common scenario in scientific domains. In\noffline scenarios, existing approaches tend to suffer from overoptimization, as\nthey may be misled by the reward model in out-of-distribution regions. To\naddress this, we introduce a conservative fine-tuning approach, BRAID, by\noptimizing a conservative reward model, which includes additional penalization\noutside of offline data distributions. Through empirical and theoretical\nanalysis, we demonstrate the capability of our approach to outperform the best\ndesigns in offline data, leveraging the extrapolation capabilities of reward\nmodels while avoiding the generation of invalid designs through pre-trained\ndiffusion models.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "stat.ML"
        ],
        "authors": [
            "Masatoshi Uehara",
            "Yulai Zhao",
            "Ehsan Hajiramezanali",
            "Gabriele Scalia",
            "Gökcen Eraslan",
            "Avantika Lal",
            "Sergey Levine",
            "Tommaso Biancalani"
        ],
        "published": "2024-05-30T03:57:29Z"
    },
    {
        "title": "CRIS: Collaborative Refinement Integrated with Segmentation for Polyp\n  Segmentation",
        "link": "http://arxiv.org/abs/2405.19672v1",
        "abstract": "Accurate detection of colorectal cancer and early prevention heavily rely on\nprecise polyp identification during gastrointestinal colonoscopy. Due to\nlimited data, many current state-of-the-art deep learning methods for polyp\nsegmentation often rely on post-processing of masks to reduce noise and enhance\nresults. In this study, we propose an approach that integrates mask refinement\nand binary semantic segmentation, leveraging a novel collaborative training\nstrategy that surpasses current widely-used refinement strategies. We\ndemonstrate the superiority of our approach through comprehensive evaluation on\nestablished benchmark datasets and its successful application across various\nmedical image segmentation architectures.",
        "subjects": [
            "eess.IV",
            "cs.CV",
            "cs.LG"
        ],
        "authors": [
            "Ankush Gajanan Arudkar",
            "Bernard J. E. Evans"
        ],
        "published": "2024-05-30T03:56:01Z"
    },
    {
        "title": "GaussianRoom: Improving 3D Gaussian Splatting with SDF Guidance and\n  Monocular Cues for Indoor Scene Reconstruction",
        "link": "http://arxiv.org/abs/2405.19671v1",
        "abstract": "Recently, 3D Gaussian Splatting(3DGS) has revolutionized neural rendering\nwith its high-quality rendering and real-time speed. However, when it comes to\nindoor scenes with a significant number of textureless areas, 3DGS yields\nincomplete and noisy reconstruction results due to the poor initialization of\nthe point cloud and under-constrained optimization. Inspired by the continuity\nof signed distance field (SDF), which naturally has advantages in modeling\nsurfaces, we present a unified optimizing framework integrating neural SDF with\n3DGS. This framework incorporates a learnable neural SDF field to guide the\ndensification and pruning of Gaussians, enabling Gaussians to accurately model\nscenes even with poor initialized point clouds. At the same time, the geometry\nrepresented by Gaussians improves the efficiency of the SDF field by piloting\nits point sampling. Additionally, we regularize the optimization with normal\nand edge priors to eliminate geometry ambiguity in textureless areas and\nimprove the details. Extensive experiments in ScanNet and ScanNet++ show that\nour method achieves state-of-the-art performance in both surface reconstruction\nand novel view synthesis.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Haodong Xiang",
            "Xinghui Li",
            "Xiansong Lai",
            "Wanting Zhang",
            "Zhichao Liao",
            "Kai Cheng",
            "Xueping Liu"
        ],
        "published": "2024-05-30T03:46:59Z"
    },
    {
        "title": "One Token Can Help! Learning Scalable and Pluggable Virtual Tokens for\n  Retrieval-Augmented Large Language Models",
        "link": "http://arxiv.org/abs/2405.19670v1",
        "abstract": "Retrieval-augmented generation (RAG) is a promising way to improve large\nlanguage models (LLMs) for generating more factual, accurate, and up-to-date\ncontent. Existing methods either optimize prompts to guide LLMs in leveraging\nretrieved information or directly fine-tune the LLMs to adapt to RAG scenarios.\nAlthough fine-tuning can yield better performance, it often compromises the\nLLMs' general generation capabilities by modifying their parameters. This\nlimitation poses challenges in practical applications, especially when LLMs are\nalready deployed, as parameter adjustments may affect their original\nfunctionality. To address this, we propose a novel method that involves\nlearning scalable and pluggable virtual tokens for RAG. By maintaining the\nLLMs' original parameters and fine-tuning only the embeddings of these\npluggable tokens, our approach not only enhances LLMs' performance but also\npreserves their general generation capacities. Furthermore, we design several\ntraining strategies to improve the scalability, flexibility, and\ngeneralizability of our method. Comprehensive experiments across nine\nquestion-answering tasks demonstrate the superiority of our approach.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yutao Zhu",
            "Zhaoheng Huang",
            "Zhicheng Dou",
            "Ji-Rong Wen"
        ],
        "published": "2024-05-30T03:44:54Z"
    },
    {
        "title": "Texture-guided Coding for Deep Features",
        "link": "http://arxiv.org/abs/2405.19669v1",
        "abstract": "With the rapid development of machine vision technology in recent years, many\nresearchers have begun to focus on feature compression that is better suited\nfor machine vision tasks. The target of feature compression is deep features,\nwhich arise from convolution in the middle layer of a pre-trained convolutional\nneural network. However, due to the large volume of data and high level of\nabstraction of deep features, their application is primarily limited to\nmachine-centric scenarios, which poses significant constraints in situations\nrequiring human-computer interaction. This paper investigates features and\ntextures and proposes a texture-guided feature compression strategy based on\ntheir characteristics. Specifically, the strategy comprises feature layers and\ntexture layers. The feature layers serve the machine, including a feature\nselection module and a feature reconstruction network. With the assistance of\ntexture images, they selectively compress and transmit channels relevant to\nvisual tasks, reducing feature data while providing high-quality features for\nthe machine. The texture layers primarily serve humans and consist of an image\nreconstruction network. This image reconstruction network leverages features\nand texture images to reconstruct preview images for humans. Our method fully\nexploits the characteristics of texture and features. It eliminates feature\nredundancy, reconstructs high-quality preview images for humans, and supports\ndecision-making. The experimental results demonstrate excellent performance\nwhen employing our proposed method to compress the deep features.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Lei Xiong",
            "Xin Luo",
            "Zihao Wang",
            "Chaofan He",
            "Shuyuan Zhu",
            "Bing Zeng"
        ],
        "published": "2024-05-30T03:38:44Z"
    },
    {
        "title": "AutoBreach: Universal and Adaptive Jailbreaking with Efficient\n  Wordplay-Guided Optimization",
        "link": "http://arxiv.org/abs/2405.19668v1",
        "abstract": "Despite the widespread application of large language models (LLMs) across\nvarious tasks, recent studies indicate that they are susceptible to jailbreak\nattacks, which can render their defense mechanisms ineffective. However,\nprevious jailbreak research has frequently been constrained by limited\nuniversality, suboptimal efficiency, and a reliance on manual crafting. In\nresponse, we rethink the approach to jailbreaking LLMs and formally define\nthree essential properties from the attacker' s perspective, which contributes\nto guiding the design of jailbreak methods. We further introduce AutoBreach, a\nnovel method for jailbreaking LLMs that requires only black-box access.\nInspired by the versatility of wordplay, AutoBreach employs a wordplay-guided\nmapping rule sampling strategy to generate a variety of universal mapping rules\nfor creating adversarial prompts. This generation process leverages LLMs'\nautomatic summarization and reasoning capabilities, thus alleviating the manual\nburden. To boost jailbreak success rates, we further suggest sentence\ncompression and chain-of-thought-based mapping rules to correct errors and\nwordplay misinterpretations in target LLMs. Additionally, we propose a\ntwo-stage mapping rule optimization strategy that initially optimizes mapping\nrules before querying target LLMs to enhance the efficiency of AutoBreach.\nAutoBreach can efficiently identify security vulnerabilities across various\nLLMs, including three proprietary models: Claude-3, GPT-3.5, GPT-4 Turbo, and\ntwo LLMs' web platforms: Bingchat, GPT-4 Web, achieving an average success rate\nof over 80% with fewer than 10 queries",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jiawei Chen",
            "Xiao Yang",
            "Zhengwei Fang",
            "Yu Tian",
            "Yinpeng Dong",
            "Zhaoxia Yin",
            "Hang Su"
        ],
        "published": "2024-05-30T03:38:31Z"
    },
    {
        "title": "Reconciling Model Multiplicity for Downstream Decision Making",
        "link": "http://arxiv.org/abs/2405.19667v1",
        "abstract": "We consider the problem of model multiplicity in downstream decision-making,\na setting where two predictive models of equivalent accuracy cannot agree on\nthe best-response action for a downstream loss function. We show that even when\nthe two predictive models approximately agree on their individual predictions\nalmost everywhere, it is still possible for their induced best-response actions\nto differ on a substantial portion of the population. We address this issue by\nproposing a framework that calibrates the predictive models with regard to both\nthe downstream decision-making problem and the individual probability\nprediction. Specifically, leveraging tools from multi-calibration, we provide\nan algorithm that, at each time-step, first reconciles the differences in\nindividual probability prediction, then calibrates the updated models such that\nthey are indistinguishable from the true probability distribution to the\ndecision-maker. We extend our results to the setting where one does not have\ndirect access to the true probability distribution and instead relies on a set\nof i.i.d data to be the empirical distribution. Finally, we provide a set of\nexperiments to empirically evaluate our methods: compared to existing work, our\nproposed algorithm creates a pair of predictive models with both improved\ndownstream decision-making losses and agrees on their best-response actions\nalmost everywhere.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Ally Yalei Du",
            "Dung Daniel Ngo",
            "Zhiwei Steven Wu"
        ],
        "published": "2024-05-30T03:36:46Z"
    },
    {
        "title": "A novel fault localization with data refinement for hydroelectric units",
        "link": "http://arxiv.org/abs/2405.19665v1",
        "abstract": "Due to the scarcity of fault samples and the complexity of non-linear and\nnon-smooth characteristics data in hydroelectric units, most of the traditional\nhydroelectric unit fault localization methods are difficult to carry out\naccurate localization. To address these problems, a sparse autoencoder\n(SAE)-generative adversarial network (GAN)-wavelet noise reduction (WNR)-\nmanifold-boosted deep learning (SG-WMBDL) based fault localization method for\nhydroelectric units is proposed. To overcome the data scarcity, a SAE is\nembedded into the GAN to generate more high-quality samples in the data\ngeneration module. Considering the signals involving non-linear and non-smooth\ncharacteristics, the improved WNR which combining both soft and hard\nthresholding and local linear embedding (LLE) are utilized to the data\npreprocessing module in order to reduce the noise and effectively capture the\nlocal features. In addition, to seek higher performance, the novel Adaptive\nBoost (AdaBoost) combined with multi deep learning is proposed to achieve\naccurate fault localization. The experimental results show that the SG-WMBDL\ncan locate faults for hydroelectric units under a small number of fault samples\nwith non-linear and non-smooth characteristics on higher precision and accuracy\ncompared to other frontier methods, which verifies the effectiveness and\npracticality of the proposed method.",
        "subjects": [
            "eess.SY",
            "cs.AI",
            "cs.LG",
            "cs.SY"
        ],
        "authors": [
            "Jialong Huang",
            "Junlin Song",
            "Penglong Lian",
            "Mengjie Gan",
            "Zhiheng Su",
            "Benhao Wang",
            "Wenji Zhu",
            "Xiaomin Pu",
            "Jianxiao Zou",
            "Shicai Fan"
        ],
        "published": "2024-05-30T03:33:49Z"
    },
    {
        "title": "MGCP: A Multi-Grained Correlation based Prediction Network for\n  Multivariate Time Series",
        "link": "http://arxiv.org/abs/2405.19661v1",
        "abstract": "Multivariate time series prediction is widely used in daily life, which poses\nsignificant challenges due to the complex correlations that exist at\nmulti-grained levels. Unfortunately, the majority of current time series\nprediction models fail to simultaneously learn the correlations of multivariate\ntime series at multi-grained levels, resulting in suboptimal performance. To\naddress this, we propose a Multi-Grained Correlations-based Prediction (MGCP)\nNetwork, which simultaneously considers the correlations at three granularity\nlevels to enhance prediction performance. Specifically, MGCP utilizes Adaptive\nFourier Neural Operators and Graph Convolutional Networks to learn the global\nspatiotemporal correlations and inter-series correlations, enabling the\nextraction of potential features from multivariate time series at fine-grained\nand medium-grained levels. Additionally, MGCP employs adversarial training with\nan attention mechanism-based predictor and conditional discriminator to\noptimize prediction results at coarse-grained level, ensuring high fidelity\nbetween the generated forecast results and the actual data distribution.\nFinally, we compare MGCP with several state-of-the-art time series prediction\nalgorithms on real-world benchmark datasets, and our results demonstrate the\ngenerality and effectiveness of the proposed model.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Zhicheng Chen",
            "Xi Xiao",
            "Ke Xu",
            "Zhong Zhang",
            "Yu Rong",
            "Qing Li",
            "Guojun Gan",
            "Zhiqiang Xu",
            "Peilin Zhao"
        ],
        "published": "2024-05-30T03:32:44Z"
    },
    {
        "title": "PATIENT-Ψ: Using Large Language Models to Simulate Patients for\n  Training Mental Health Professionals",
        "link": "http://arxiv.org/abs/2405.19660v1",
        "abstract": "Mental illness remains one of the most critical public health issues, with a\nsignificant gap between the available mental health support and patient needs.\nMany mental health professionals highlight a disconnect between their training\nand real-world patient interactions, leaving some trainees feeling unprepared\nand potentially affecting their early career success. In this paper, we propose\nPATIENT-{\\Psi}, a novel patient simulation framework for cognitive behavior\ntherapy (CBT) training. To build PATIENT-{\\Psi}, we constructed diverse patient\nprofiles and their corresponding cognitive models based on CBT principles, and\nthen used large language models (LLMs) programmed with the patient cognitive\nmodels to act as a simulated therapy patient. We propose an interactive\ntraining scheme, PATIENT-{\\Psi}-TRAINER, for mental health trainees to practice\na key skill in CBT -- formulating the cognitive model of the patient -- through\nrole-playing a therapy session with PATIENT-{\\Psi}. To evaluate PATIENT-{\\Psi},\nwe conducted a user study of 4 mental health trainees and 10 experts. The\nresults demonstrate that practice using PATIENT-{\\Psi}-TRAINER greatly enhances\nthe perceived skill acquisition and confidence of the trainees beyond existing\nforms of training such as textbooks, videos, and role-play with non-patients.\nBased on the experts' perceptions, PATIENT-{\\Psi} is perceived to be closer to\nreal patient interactions than GPT-4, and PATIENT-{\\Psi}-TRAINER holds strong\npromise to improve trainee competencies. Our pioneering patient simulation\ntraining framework, using LLMs, holds great potential to enhance and advance\nmental health training, ultimately leading to improved patient care and\noutcomes. We will release all our data, code, and the training platform.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Ruiyi Wang",
            "Stephanie Milani",
            "Jamie C. Chiu",
            "Shaun M. Eack",
            "Travis Labrum",
            "Samuel M. Murphy",
            "Nev Jones",
            "Kate Hardy",
            "Hong Shen",
            "Fei Fang",
            "Zhiyu Zoey Chen"
        ],
        "published": "2024-05-30T03:20:56Z"
    },
    {
        "title": "CSANet: Channel Spatial Attention Network for Robust 3D Face Alignment\n  and Reconstruction",
        "link": "http://arxiv.org/abs/2405.19659v1",
        "abstract": "Our project proposes an end-to-end 3D face alignment and reconstruction\nnetwork. The backbone of our model is built by Bottle-Neck structure via\nDepth-wise Separable Convolution. We integrate Coordinate Attention mechanism\nand Spatial Group-wise Enhancement to extract more representative features. For\nmore stable training process and better convergence, we jointly use Wing loss\nand the Weighted Parameter Distance Cost to learn parameters for 3D Morphable\nmodel and 3D vertices. Our proposed model outperforms all baseline models both\nquantitatively and qualitatively.",
        "subjects": [
            "cs.CV",
            "eess.IV"
        ],
        "authors": [
            "Yilin Liu",
            "Xuezhou Guo",
            "Xinqi Wang",
            "Fangzhou Du"
        ],
        "published": "2024-05-30T03:20:37Z"
    },
    {
        "title": "Uncertainty-guided Optimal Transport in Depth Supervised Sparse-View 3D\n  Gaussian",
        "link": "http://arxiv.org/abs/2405.19657v1",
        "abstract": "3D Gaussian splatting has demonstrated impressive performance in real-time\nnovel view synthesis. However, achieving successful reconstruction from RGB\nimages generally requires multiple input views captured under static\nconditions. To address the challenge of sparse input views, previous approaches\nhave incorporated depth supervision into the training of 3D Gaussians to\nmitigate overfitting, using dense predictions from pretrained depth networks as\npseudo-ground truth. Nevertheless, depth predictions from monocular depth\nestimation models inherently exhibit significant uncertainty in specific areas.\nRelying solely on pixel-wise L2 loss may inadvertently incorporate detrimental\nnoise from these uncertain areas. In this work, we introduce a novel method to\nsupervise the depth distribution of 3D Gaussians, utilizing depth priors with\nintegrated uncertainty estimates. To address these localized errors in depth\npredictions, we integrate a patch-wise optimal transport strategy to complement\ntraditional L2 loss in depth supervision. Extensive experiments conducted on\nthe LLFF, DTU, and Blender datasets demonstrate that our approach, UGOT,\nachieves superior novel view synthesis and consistently outperforms\nstate-of-the-art methods.",
        "subjects": [
            "cs.CV",
            "cs.AI"
        ],
        "authors": [
            "Wei Sun",
            "Qi Zhang",
            "Yanzhao Zhou",
            "Qixiang Ye",
            "Jianbin Jiao",
            "Yuan Li"
        ],
        "published": "2024-05-30T03:18:30Z"
    },
    {
        "title": "Accurate and Reliable Predictions with Mutual-Transport Ensemble",
        "link": "http://arxiv.org/abs/2405.19656v1",
        "abstract": "Deep Neural Networks (DNNs) have achieved remarkable success in a variety of\ntasks, especially when it comes to prediction accuracy. However, in complex\nreal-world scenarios, particularly in safety-critical applications, high\naccuracy alone is not enough. Reliable uncertainty estimates are crucial.\nModern DNNs, often trained with cross-entropy loss, tend to be overconfident,\nespecially with ambiguous samples. To improve uncertainty calibration, many\ntechniques have been developed, but they often compromise prediction accuracy.\nTo tackle this challenge, we propose the ``mutual-transport ensemble'' (MTE).\nThis approach introduces a co-trained auxiliary model and adaptively\nregularizes the cross-entropy loss using Kullback-Leibler (KL) divergence\nbetween the prediction distributions of the primary and auxiliary models. We\nconducted extensive studies on various benchmarks to validate the effectiveness\nof our method. The results show that MTE can simultaneously enhance both\naccuracy and uncertainty calibration. For example, on the CIFAR-100 dataset,\nour MTE method on ResNet34/50 achieved significant improvements compared to\nprevious state-of-the-art method, with absolute accuracy increases of\n2.4%/3.7%, relative reductions in ECE of $42.3%/29.4%, and relative reductions\nin classwise-ECE of 11.6%/15.3%.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Han Liu",
            "Peng Cui",
            "Bingning Wang",
            "Jun Zhu",
            "Xiaolin Hu"
        ],
        "published": "2024-05-30T03:15:59Z"
    },
    {
        "title": "Unlocking the Power of Spatial and Temporal Information in Medical\n  Multimodal Pre-training",
        "link": "http://arxiv.org/abs/2405.19654v1",
        "abstract": "Medical vision-language pre-training methods mainly leverage the\ncorrespondence between paired medical images and radiological reports. Although\nmulti-view spatial images and temporal sequences of image-report pairs are\navailable in off-the-shelf multi-modal medical datasets, most existing methods\nhave not thoroughly tapped into such extensive supervision signals. In this\npaper, we introduce the Med-ST framework for fine-grained spatial and temporal\nmodeling to exploit information from multiple spatial views of chest\nradiographs and temporal historical records. For spatial modeling, Med-ST\nemploys the Mixture of View Expert (MoVE) architecture to integrate different\nvisual features from both frontal and lateral views. To achieve a more\ncomprehensive alignment, Med-ST not only establishes the global alignment\nbetween whole images and texts but also introduces modality-weighted local\nalignment between text tokens and spatial regions of images. For temporal\nmodeling, we propose a novel cross-modal bidirectional cycle consistency\nobjective by forward mapping classification (FMC) and reverse mapping\nregression (RMR). By perceiving temporal information from simple to complex,\nMed-ST can learn temporal semantics. Experimental results across four distinct\ntasks demonstrate the effectiveness of Med-ST, especially in temporal\nclassification tasks. Our code and model are available at\nhttps://github.com/SVT-Yang/MedST.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Jinxia Yang",
            "Bing Su",
            "Wayne Xin Zhao",
            "Ji-Rong Wen"
        ],
        "published": "2024-05-30T03:15:09Z"
    },
    {
        "title": "SysCaps: Language Interfaces for Simulation Surrogates of Complex\n  Systems",
        "link": "http://arxiv.org/abs/2405.19653v1",
        "abstract": "Data-driven simulation surrogates help computational scientists study complex\nsystems. They can also help inform impactful policy decisions. We introduce a\nlearning framework for surrogate modeling where language is used to interface\nwith the underlying system being simulated. We call a language description of a\nsystem a \"system caption\", or SysCap. To address the lack of datasets of paired\nnatural language SysCaps and simulation runs, we use large language models\n(LLMs) to synthesize high-quality captions. Using our framework, we train\nmultimodal text and timeseries regression models for two real-world simulators\nof complex energy systems. Our experiments demonstrate the feasibility of\ndesigning language interfaces for real-world surrogate models at comparable\naccuracy to standard baselines. We qualitatively and quantitatively show that\nSysCaps unlock text-prompt-style surrogate modeling and new generalization\nabilities beyond what was previously possible. We will release the generated\nSysCaps datasets and our code to support follow-on studies.",
        "subjects": [
            "cs.LG",
            "cs.CL",
            "cs.SY",
            "eess.SY"
        ],
        "authors": [
            "Patrick Emami",
            "Zhaonan Li",
            "Saumya Sinha",
            "Truc Nguyen"
        ],
        "published": "2024-05-30T03:12:04Z"
    },
    {
        "title": "Dual sparse training framework: inducing activation map sparsity via\n  Transformed $\\ell1$ regularization",
        "link": "http://arxiv.org/abs/2405.19652v1",
        "abstract": "Although deep convolutional neural networks have achieved rapid development,\nit is challenging to widely promote and apply these models on low-power\ndevices, due to computational and storage limitations. To address this issue,\nresearchers have proposed techniques such as model compression, activation\nsparsity induction, and hardware accelerators. This paper presents a method to\ninduce the sparsity of activation maps based on Transformed $\\ell1$\nregularization, so as to improve the research in the field of activation\nsparsity induction. Further, the method is innovatively combined with\ntraditional pruning, constituting a dual sparse training framework. Compared to\nprevious methods, Transformed $\\ell1$ can achieve higher sparsity and better\nadapt to different network structures. Experimental results show that the\nmethod achieves improvements by more than 20\\% in activation map sparsity on\nmost models and corresponding datasets without compromising the accuracy.\nSpecifically, it achieves a 27.52\\% improvement for ResNet18 on the ImageNet\ndataset, and a 44.04\\% improvement for LeNet5 on the MNIST dataset. In\naddition, the dual sparse training framework can greatly reduce the\ncomputational load and provide potential for reducing the required storage\nduring runtime. Specifically, the ResNet18 and ResNet50 models obtained by the\ndual sparse training framework respectively reduce 81.7\\% and 84.13\\% of\nmultiplicative floating-point operations, while maintaining accuracy and a low\npruning rate.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xiaolong Yu",
            "Cong Tian"
        ],
        "published": "2024-05-30T03:11:21Z"
    },
    {
        "title": "Few for Many: Tchebycheff Set Scalarization for Many-Objective\n  Optimization",
        "link": "http://arxiv.org/abs/2405.19650v1",
        "abstract": "Multi-objective optimization can be found in many real-world applications\nwhere some conflicting objectives can not be optimized by a single solution.\nExisting optimization methods often focus on finding a set of Pareto solutions\nwith different optimal trade-offs among the objectives. However, the required\nnumber of solutions to well approximate the whole Pareto optimal set could be\nexponentially large with respect to the number of objectives, which makes these\nmethods unsuitable for handling many optimization objectives. In this work,\ninstead of finding a dense set of Pareto solutions, we propose a novel\nTchebycheff set scalarization method to find a few representative solutions\n(e.g., 5) to cover a large number of objectives (e.g., $>100$) in a\ncollaborative and complementary manner. In this way, each objective can be well\naddressed by at least one solution in the small solution set. In addition, we\nfurther develop a smooth Tchebycheff set scalarization approach for efficient\noptimization with good theoretical guarantees. Experimental studies on\ndifferent problems with many optimization objectives demonstrate the\neffectiveness of our proposed method.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.NE",
            "math.OC"
        ],
        "authors": [
            "Xi Lin",
            "Yilu Liu",
            "Xiaoyuan Zhang",
            "Fei Liu",
            "Zhenkun Wang",
            "Qingfu Zhang"
        ],
        "published": "2024-05-30T03:04:57Z"
    },
    {
        "title": "Towards Deeper Understanding of PPR-based Embedding Approaches: A\n  Topological Perspective",
        "link": "http://dx.doi.org/10.1145/3589334.3645663",
        "abstract": "Node embedding learns low-dimensional vectors for nodes in the graph. Recent\nstate-of-the-art embedding approaches take Personalized PageRank (PPR) as the\nproximity measure and factorize the PPR matrix or its adaptation to generate\nembeddings. However, little previous work analyzes what information is encoded\nby these approaches, and how the information correlates with their superb\nperformance in downstream tasks. In this work, we first show that\nstate-of-the-art embedding approaches that factorize a PPR-related matrix can\nbe unified into a closed-form framework. Then, we study whether the embeddings\ngenerated by this strategy can be inverted to better recover the graph topology\ninformation than random-walk based embeddings. To achieve this, we propose two\nmethods for recovering graph topology via PPR-based embeddings, including the\nanalytical method and the optimization method. Extensive experimental results\ndemonstrate that the embeddings generated by factorizing a PPR-related matrix\nmaintain more topological information, such as common edges and community\nstructures, than that generated by random walks, paving a new way to\nsystematically comprehend why PPR-based node embedding approaches outperform\nrandom walk-based alternatives in various downstream tasks. To the best of our\nknowledge, this is the first work that focuses on the interpretability of\nPPR-based node embedding approaches.",
        "subjects": [
            "cs.LG",
            "cs.SI",
            "stat.ML"
        ],
        "authors": [
            "Xingyi Zhang",
            "Zixuan Weng",
            "Sibo Wang"
        ],
        "published": "2024-05-30T03:02:23Z"
    },
    {
        "title": "Detecting Hallucinations in Large Language Model Generation: A Token\n  Probability Approach",
        "link": "http://arxiv.org/abs/2405.19648v1",
        "abstract": "Concerns regarding the propensity of Large Language Models (LLMs) to produce\ninaccurate outputs, also known as hallucinations, have escalated. Detecting\nthem is vital for ensuring the reliability of applications relying on\nLLM-generated content. Current methods often demand substantial resources and\nrely on extensive LLMs or employ supervised learning with multidimensional\nfeatures or intricate linguistic and semantic analyses difficult to reproduce\nand largely depend on using the same LLM that hallucinated. This paper\nintroduces a supervised learning approach employing two simple classifiers\nutilizing only four numerical features derived from tokens and vocabulary\nprobabilities obtained from other LLM evaluators, which are not necessarily the\nsame. The method yields promising results, surpassing state-of-the-art outcomes\nin multiple tasks across three different benchmarks. Additionally, we provide a\ncomprehensive examination of the strengths and weaknesses of our approach,\nhighlighting the significance of the features utilized and the LLM employed as\nan evaluator. We have released our code publicly at\nhttps://github.com/Baylor-AI/HalluDetect.",
        "subjects": [
            "cs.CL",
            "cs.AI",
            "cs.LG",
            "I.2.7"
        ],
        "authors": [
            "Ernesto Quevedo",
            "Jorge Yero",
            "Rachel Koerner",
            "Pablo Rivas",
            "Tomas Cerny"
        ],
        "published": "2024-05-30T03:00:47Z"
    },
    {
        "title": "FTS: A Framework to Find a Faithful TimeSieve",
        "link": "http://arxiv.org/abs/2405.19647v1",
        "abstract": "The field of time series forecasting has garnered significant attention in\nrecent years, prompting the development of advanced models like TimeSieve,\nwhich demonstrates impressive performance. However, an analysis reveals certain\nunfaithfulness issues, including high sensitivity to random seeds and minute\ninput noise perturbations. Recognizing these challenges, we embark on a quest\nto define the concept of \\textbf{\\underline{F}aithful\n\\underline{T}ime\\underline{S}ieve \\underline{(FTS)}}, a model that consistently\ndelivers reliable and robust predictions. To address these issues, we propose a\nnovel framework aimed at identifying and rectifying unfaithfulness in\nTimeSieve. Our framework is designed to enhance the model's stability and\nresilience, ensuring that its outputs are less susceptible to the\naforementioned factors. Experimentation validates the effectiveness of our\nproposed framework, demonstrating improved faithfulness in the model's\nbehavior. Looking forward, we plan to expand our experimental scope to further\nvalidate and optimize our algorithm, ensuring comprehensive faithfulness across\na wide range of scenarios. Ultimately, we aspire to make this framework can be\napplied to enhance the faithfulness of not just TimeSieve but also other\nstate-of-the-art temporal methods, thereby contributing to the reliability and\nrobustness of temporal modeling as a whole.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Songning Lai",
            "Ninghui Feng",
            "Haochen Sui",
            "Ze Ma",
            "Hao Wang",
            "Zichen Song",
            "Hang Zhao",
            "Yutao Yue"
        ],
        "published": "2024-05-30T02:59:49Z"
    },
    {
        "title": "FaceLift: Semi-supervised 3D Facial Landmark Localization",
        "link": "http://arxiv.org/abs/2405.19646v1",
        "abstract": "3D facial landmark localization has proven to be of particular use for\napplications, such as face tracking, 3D face modeling, and image-based 3D face\nreconstruction. In the supervised learning case, such methods usually rely on\n3D landmark datasets derived from 3DMM-based registration that often lack\nspatial definition alignment, as compared with that chosen by hand-labeled\nhuman consensus, e.g., how are eyebrow landmarks defined? This creates a gap\nbetween landmark datasets generated via high-quality 2D human labels and 3DMMs,\nand it ultimately limits their effectiveness. To address this issue, we\nintroduce a novel semi-supervised learning approach that learns 3D landmarks by\ndirectly lifting (visible) hand-labeled 2D landmarks and ensures better\ndefinition alignment, without the need for 3D landmark datasets. To lift 2D\nlandmarks to 3D, we leverage 3D-aware GANs for better multi-view consistency\nlearning and in-the-wild multi-frame videos for robust cross-generalization.\nEmpirical experiments demonstrate that our method not only achieves better\ndefinition alignment between 2D-3D landmarks but also outperforms other\nsupervised learning 3D landmark localization methods on both 3DMM labeled and\nphotogrammetric ground truth evaluation datasets. Project Page:\nhttps://davidcferman.github.io/FaceLift",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "David Ferman",
            "Pablo Garrido",
            "Gaurav Bharaj"
        ],
        "published": "2024-05-30T02:58:15Z"
    },
    {
        "title": "EgoSurgery-Phase: A Dataset of Surgical Phase Recognition from\n  Egocentric Open Surgery Videos",
        "link": "http://arxiv.org/abs/2405.19644v1",
        "abstract": "Surgical phase recognition has gained significant attention due to its\npotential to offer solutions to numerous demands of the modern operating room.\nHowever, most existing methods concentrate on minimally invasive surgery (MIS),\nleaving surgical phase recognition for open surgery understudied. This\ndiscrepancy is primarily attributed to the scarcity of publicly available open\nsurgery video datasets for surgical phase recognition. To address this issue,\nwe introduce a new egocentric open surgery video dataset for phase recognition,\nnamed EgoSurgery-Phase. This dataset comprises 15 hours of real open surgery\nvideos spanning 9 distinct surgical phases all captured using an egocentric\ncamera attached to the surgeon's head. In addition to video, the\nEgoSurgery-Phase offers eye gaze. As far as we know, it is the first real open\nsurgery video dataset for surgical phase recognition publicly available.\nFurthermore, inspired by the notable success of masked autoencoders (MAEs) in\nvideo understanding tasks (e.g., action recognition), we propose a gaze-guided\nmasked autoencoder (GGMAE). Considering the regions where surgeons' gaze\nfocuses are often critical for surgical phase recognition (e.g., surgical\nfield), in our GGMAE, the gaze information acts as an empirical semantic\nrichness prior to guiding the masking process, promoting better attention to\nsemantically rich spatial regions. GGMAE significantly improves the previous\nstate-of-the-art recognition method (6.4% in Jaccard) and the masked\nautoencoder-based method (3.1% in Jaccard) on EgoSurgery-Phase. The dataset\nwill be released at https://github.com/Fujiry0/EgoSurgery.",
        "subjects": [
            "cs.CV",
            "cs.AI",
            "cs.LG"
        ],
        "authors": [
            "Ryo Fujii",
            "Masashi Hatano",
            "Hideo Saito",
            "Hiroki Kajita"
        ],
        "published": "2024-05-30T02:53:19Z"
    },
    {
        "title": "Few-shot fault diagnosis based on multi-scale graph convolution\n  filtering for industry",
        "link": "http://arxiv.org/abs/2405.19642v1",
        "abstract": "Industrial equipment fault diagnosis often encounter challenges such as the\nscarcity of fault data, complex operating conditions, and varied types of\nfailures. Signal analysis, data statistical learning, and conventional deep\nlearning techniques face constraints under these conditions due to their\nsubstantial data requirements and the necessity for transfer learning to\naccommodate new failure modes. To effectively leverage information and extract\nthe intrinsic characteristics of faults across different domains under limited\nsample conditions, this paper introduces a fault diagnosis approach employing\nMulti-Scale Graph Convolution Filtering (MSGCF). MSGCF enhances the traditional\nGraph Neural Network (GNN) framework by integrating both local and global\ninformation fusion modules within the graph convolution filter block. This\nadvancement effectively mitigates the over-smoothing issue associated with\nexcessive layering of graph convolutional layers while preserving a broad\nreceptive field. It also reduces the risk of overfitting in few-shot diagnosis,\nthereby augmenting the model's representational capacity. Experiments on the\nUniversity of Paderborn bearing dataset (PU) demonstrate that the MSGCF method\nproposed herein surpasses alternative approaches in accuracy, thereby offering\nvaluable insights for industrial fault diagnosis in few-shot learning\nscenarios.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Mengjie Gan",
            "Penglong Lian",
            "Zhiheng Su",
            "Jiyang Zhang",
            "Jialong Huang",
            "Benhao Wang",
            "Jianxiao Zou",
            "Shicai Fan"
        ],
        "published": "2024-05-30T02:51:29Z"
    },
    {
        "title": "Reconciling Safety Measurement and Dynamic Assurance",
        "link": "http://arxiv.org/abs/2405.19641v1",
        "abstract": "We propose a new framework to facilitate dynamic assurance within a safety\ncase approach by associating safety performance measurement with the core\nassurance artifacts of a safety case. The focus is mainly on the safety\narchitecture, whose underlying risk assessment model gives the concrete link\nfrom safety measurement to operational risk. Using an aviation domain example\nof autonomous taxiing, we describe our approach to derive safety indicators and\nrevise the risk assessment based on safety measurement. We then outline a\nnotion of consistency between a collection of safety indicators and the safety\ncase, as a formal basis for implementing the proposed framework in our tool,\nAdvoCATE.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Ewen Denney",
            "Ganesh Pai"
        ],
        "published": "2024-05-30T02:48:00Z"
    },
    {
        "title": "Learning Robust Correlation with Foundation Model for Weakly-Supervised\n  Few-Shot Segmentation",
        "link": "http://dx.doi.org/10.1016/j.knosys.2024.112004",
        "abstract": "Existing few-shot segmentation (FSS) only considers learning support-query\ncorrelation and segmenting unseen categories under the precise pixel masks.\nHowever, the cost of a large number of pixel masks during training is\nexpensive. This paper considers a more challenging scenario, weakly-supervised\nfew-shot segmentation (WS-FSS), which only provides category ($i.e.$\nimage-level) labels. It requires the model to learn robust support-query\ninformation when the generated mask is inaccurate. In this work, we design a\nCorrelation Enhancement Network (CORENet) with foundation model, which utilizes\nmulti-information guidance to learn robust correlation. Specifically,\ncorrelation-guided transformer (CGT) utilizes self-supervised ViT tokens to\nlearn robust correlation from both local and global perspectives. From the\nperspective of semantic categories, the class-guided module (CGM) guides the\nmodel to locate valuable correlations through the pre-trained CLIP. Finally,\nthe embedding-guided module (EGM) implicitly guides the model to supplement the\ninevitable information loss during the correlation learning by the original\nappearance embedding and finally generates the query mask. Extensive\nexperiments on PASCAL-5$^i$ and COCO-20$^i$ have shown that CORENet exhibits\nexcellent performance compared to existing methods.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Xinyang Huang",
            "Chuang Zhu",
            "Kebin Liu",
            "Ruiying Ren",
            "Shengjie Liu"
        ],
        "published": "2024-05-30T02:42:58Z"
    },
    {
        "title": "Creating Language-driven Spatial Variations of Icon Images",
        "link": "http://arxiv.org/abs/2405.19636v1",
        "abstract": "Editing 2D icon images can require significant manual effort from designers.\nIt involves manipulating multiple geometries while maintaining the logical or\nphysical coherence of the objects depicted in the image. Previous language\ndriven image editing methods can change the texture and geometry of objects in\nthe image but fail at producing spatial variations, i.e. modifying spatial\nrelations between objects while maintaining their identities. We present a\nlanguage driven editing method that can produce spatial variations of icon\nimages. Our method takes in an icon image along with a user's editing request\ntext prompt and outputs an edited icon image reflecting the user's editing\nrequest. Our method is designed based on two key observations: (1) A user's\nediting requests can be translated by a large language model (LLM), with help\nfrom a domain specific language (DSL) library, into to a set of geometrical\nconstraints defining the relationships between segments in an icon image. (2)\nOptimizing the affine transformations of the segments with respect to these\ngeometrical constraints can produce icon images that fulfill the editing\nrequest and preserve overall physical and logical coherence. Quantitative and\nqualitative results show that our system outperforms multiple baselines,\nenabling natural editing of icon images.",
        "subjects": [
            "cs.GR"
        ],
        "authors": [
            "Xianghao Xu",
            "Aditya Ganeshan",
            "Karl D. D. Willis",
            "Yewen Pu",
            "Daniel Ritchie"
        ],
        "published": "2024-05-30T02:39:56Z"
    },
    {
        "title": "GKT: A Novel Guidance-Based Knowledge Transfer Framework For Efficient\n  Cloud-edge Collaboration LLM Deployment",
        "link": "http://arxiv.org/abs/2405.19635v1",
        "abstract": "The burgeoning size of Large Language Models (LLMs) has led to enhanced\ncapabilities in generating responses, albeit at the expense of increased\ninference times and elevated resource demands. Existing methods of\nacceleration, predominantly hinged on knowledge distillation, generally\nnecessitate fine-tuning of considerably large models, such as Llama-7B, posing\na challenge for average users. Furthermore, present techniques for expediting\ninference and reducing costs operate independently. To address these issues, we\nintroduce a novel and intuitive Guidance-based Knowledge Transfer (GKT)\nframework. This approach leverages a larger LLM as a ''teacher'' to create\nguidance prompts, paired with a smaller ''student'' model to finalize\nresponses. Remarkably, GKT requires no fine-tuning and doesn't necessitate the\nteacher and student models to have the same vocabulary, allowing for extensive\nbatch generation to accelerate the process while ensuring user customization.\nGKT can be seamlessly integrated into cloud-edge collaboration architectures,\nand is versatile enough for plug-and-play application across various models. It\nexcels in both efficiency and affordability, epitomizing a ''cheap and\ncheerful'' solution. GKT achieves a maximum accuracy improvement of 14.18%,\nalong with a 10.72 times speed-up on GSM8K and an accuracy improvement of 14.00\n% along with a 7.73 times speed-up in CSQA. When utilizing ChatGPT as teacher\nmodel and Llama2-70B as the student model, we can achieve 95.00% of ChatGPT's\nperformance at 52% of the cost. The results highlight substantial enhancements\nin accuracy and processing speed on the GSM8K and CSQA datasets, surpassing the\nperformance of using either the student or teacher models in isolation.",
        "subjects": [
            "cs.CL"
        ],
        "authors": [
            "Yao Yao",
            "Zuchao Li",
            "Hai Zhao"
        ],
        "published": "2024-05-30T02:37:35Z"
    },
    {
        "title": "Leveraging Open-Source Large Language Models for encoding Social\n  Determinants of Health using an Intelligent Router",
        "link": "http://arxiv.org/abs/2405.19631v1",
        "abstract": "Social Determinants of Health (SDOH) play a significant role in patient\nhealth outcomes. The Center of Disease Control (CDC) introduced a subset of\nICD-10 codes called Z-codes in an attempt to officially recognize and measure\nSDOH in the health care system. However, these codes are rarely annotated in a\npatient's Electronic Health Record (EHR), and instead, in many cases, need to\nbe inferred from clinical notes. Previous research has shown that large\nlanguage models (LLMs) show promise on extracting unstructured data from EHRs.\nHowever, with thousands of models to choose from with unique architectures and\ntraining sets, it's difficult to choose one model that performs the best on\ncoding tasks. Further, clinical notes contain trusted health information making\nthe use of closed-source language models from commercial vendors difficult, so\nthe identification of open source LLMs that can be run within health\norganizations and exhibits high performance on SDOH tasks is an urgent problem.\nHere, we introduce an intelligent routing system for SDOH coding that uses a\nlanguage model router to direct medical record data to open source LLMs that\ndemonstrate optimal performance on specific SDOH codes. The intelligent routing\nsystem exhibits state of the art performance of 97.4% accuracy averaged across\n5 codes, including homelessness and food insecurity, on par with closed models\nsuch as GPT-4o. In order to train the routing system and validate models, we\nalso introduce a synthetic data generation and validation paradigm to increase\nthe scale of training data without needing privacy protected medical records.\nTogether, we demonstrate an architecture for intelligent routing of inputs to\ntask-optimal language models to achieve high performance across a set of\nmedical coding sub-tasks.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Akul Goel",
            "Surya Narayanan Hari",
            "Belinda Waltman",
            "Matt Thomson"
        ],
        "published": "2024-05-30T02:33:28Z"
    },
    {
        "title": "The use of a humanoid robot for older people with dementia in aged care\n  facilities",
        "link": "http://arxiv.org/abs/2405.19630v1",
        "abstract": "This paper presents an interdisciplinary PhD project using a humanoid robot\nto encourage interactive activities for people with dementia living in two aged\ncare facilities. The aim of the project was to develop software and use\ntechnologies to achieve successful robot-led engagement with older people with\ndementia. This paper outlines the qualitative findings from the project's\nfeasibility stage. The researcher's observations, the participants' attitudes\nand the feedback from carers are presented and discussed.",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Dongjun Wu",
            "Lihui Pu",
            "Jun Jo",
            "Rene Hexel",
            "Wendy Moyle"
        ],
        "published": "2024-05-30T02:33:09Z"
    },
    {
        "title": "YotoR-You Only Transform One Representation",
        "link": "http://arxiv.org/abs/2405.19629v1",
        "abstract": "This paper introduces YotoR (You Only Transform One Representation), a novel\ndeep learning model for object detection that combines Swin Transformers and\nYoloR architectures. Transformers, a revolutionary technology in natural\nlanguage processing, have also significantly impacted computer vision, offering\nthe potential to enhance accuracy and computational efficiency. YotoR combines\nthe robust Swin Transformer backbone with the YoloR neck and head. In our\nexperiments, YotoR models TP5 and BP4 consistently outperform YoloR P6 and Swin\nTransformers in various evaluations, delivering improved object detection\nperformance and faster inference speeds than Swin Transformer models. These\nresults highlight the potential for further model combinations and improvements\nin real-time object detection with Transformers. The paper concludes by\nemphasizing the broader implications of YotoR, including its potential to\nenhance transformer-based models for image-related tasks.",
        "subjects": [
            "cs.CV",
            "I.2.10"
        ],
        "authors": [
            "José Ignacio Díaz Villa",
            "Patricio Loncomilla",
            "Javier Ruiz-del-Solar"
        ],
        "published": "2024-05-30T02:27:56Z"
    },
    {
        "title": "Deep Learning Model for Detecting Abnormal Corn Kernels",
        "link": "http://arxiv.org/abs/2405.19628v1",
        "abstract": "This research aims to detect the physical characteristics of corn kernels and\nanalyze images using a deep learning model. The data analysis based on the\nCRISP-DM framework which consists of six steps, business understanding, data\nunderstanding, data preparation, modelling, evaluation, and deployment. The\nbusiness goal reduces the cost of the separation of abnormal corn kernels. The\ndataset comprises 1,800 images of corn kernels and divided equally between\nnormal and abnormal corn kernels. The dataset was divided into three subsets:\n1,000 images for training the deep learning model, 600 images for validation\nand 200 images for testing. The tools for analysis in this research are Jupyter\nLab, Python, TensorFlow Keras, and Convolutional Neural Networks. The results\nrevealed that the deep learning model achieved the accuracy rate of 99% in\ndifferentiating between normal and abnormal corn kernel images that is a highly\neffective model in this context.",
        "subjects": [
            "cs.CE"
        ],
        "authors": [
            "Suwannee Adsavakulchai",
            "Mawin Prommasaeng"
        ],
        "published": "2024-05-30T02:27:19Z"
    },
    {
        "title": "Position: CXL Shared Memory Programming: Barely Distributed and Almost\n  Persistent",
        "link": "http://arxiv.org/abs/2405.19626v1",
        "abstract": "While Compute Express Link (CXL) enables support for cache-coherent shared\nmemory among multiple nodes, it also introduces new types of\nfailures--processes can fail before data does, or data might fail before a\nprocess does. The lack of a failure model for CXL-based shared memory makes it\nchallenging to understand and mitigate these failures.\n  To solve these challenges, in this paper, we describe a model categorizing\nand handling the CXL-based shared memory's failures: data and process failures.\nData failures in CXL-based shared memory render data inaccessible or\ninconsistent for a currently running application. We argue that such failures\nare unlike data failures in distributed storage systems and require\nCXL-specific handling. To address this, we look into traditional data failure\nmitigation techniques like erasure coding and replication and propose new\nsolutions to better handle data failures in CXL-based shared memory systems.\nNext, we look into process failures and compare the failures and potential\nsolutions with PMEM's failure model and programming solutions. We argue that\nalthough PMEM shares some of CXL's characteristics, it does not fully address\nCXL's volatile nature and low access latencies. Finally, taking inspiration\nfrom PMEM programming solutions, we propose techniques to handle these new\nfailures.\n  Thus, this paper is the first work to define the CXL-based shared memory\nfailure model and propose tailored solutions that address challenges specific\nto CXL-based systems.",
        "subjects": [
            "cs.DC"
        ],
        "authors": [
            "Yi Xu",
            "Suyash Mahar",
            "Ziheng Liu",
            "Mingyao Shen",
            "Steven Swanson"
        ],
        "published": "2024-05-30T02:23:50Z"
    },
    {
        "title": "A Novel Approach for Automated Design Information Mining from Issue Logs",
        "link": "http://arxiv.org/abs/2405.19623v1",
        "abstract": "Software architectures are usually meticulously designed to address multiple\nquality concerns and support long-term maintenance. However, due to the\nimbalance between the cost and value for developers to document design\nrationales (i.e., the design alternatives and the underlying arguments for\nmaking or rejecting decisions), these rationales are often obsolete or even\nmissing. The lack of design knowledge has motivated a number of studies to\nextract design information from various platforms in recent years.\nUnfortunately, despite the wealth of discussion records related to design\ninformation provided by platforms like open-source communities, existing\nresearch often overlooks the underlying arguments behind alternatives due to\nchallenges such as the intricate semantics of discussions and the lack of\nbenchmarks for design rationale extraction. In this paper, we propose a novel\nmethod, named by DRMiner, to automatically mine latent design rationales from\ndevelopers' live discussion in open-source community (i.e., issue logs in\nJira). To better identify solutions and the arguments supporting them, DRMiner\nskillfully decomposes the problem into multiple text classification tasks and\ntackles them using prompt tuning of language models and customized text-related\nfeatures. To evaluate DRMiner, we acquire issue logs from Cassandra, Flink, and\nSolr repositories in Jira, and then annotate and process them under a rigorous\nscheme, ultimately forming a dataset for design rationale mining. Experimental\nresults show that DRMiner achieves an F1 score of 65% for mining design\nrationales, outperforming all baselines with a 7% improvement over GPT-4.0.\nFurthermore, we investigate the usefulness of the design rationales mined by\nDRMiner for automated program repair (APR) and find that the design rationales\nsignificantly enhance APR, achieving 14 times higher full-match repairs on\naverage.",
        "subjects": [
            "cs.SE"
        ],
        "authors": [
            "Jiuang Zhao",
            "Zitian Yang",
            "Li Zhang",
            "Xiaoli Lian",
            "Donghao Yang"
        ],
        "published": "2024-05-30T02:20:04Z"
    },
    {
        "title": "On shortest products for nonnegative matrix mortality",
        "link": "http://arxiv.org/abs/2405.19622v1",
        "abstract": "Given a finite set of matrices with integer entries, the matrix mortality\nproblem asks if there exists a product of these matrices equal to the zero\nmatrix. We consider a special case of this problem where all entries of the\nmatrices are nonnegative. This case is equivalent to the NFA mortality problem,\nwhich, given an NFA, asks for a word $w$ such that the image of every state\nunder $w$ is the empty set. The size of the alphabet of the NFA is then equal\nto the number of matrices in the set. We study the length of shortest such\nwords depending on the size of the alphabet. We show that this length for an\nNFA with $n$ states can be at least $2^n - 1$, $2^{(n - 4)/2}$ and $2^{(n -\n2)/3}$ if the size of the alphabet is, respectively, equal to $n$, three and\ntwo.",
        "subjects": [
            "cs.DM",
            "cs.FL",
            "math.CO"
        ],
        "authors": [
            "Andrew Ryzhikov"
        ],
        "published": "2024-05-30T02:19:24Z"
    },
    {
        "title": "SparseDrive: End-to-End Autonomous Driving via Sparse Scene\n  Representation",
        "link": "http://arxiv.org/abs/2405.19620v1",
        "abstract": "The well-established modular autonomous driving system is decoupled into\ndifferent standalone tasks, e.g. perception, prediction and planning, suffering\nfrom information loss and error accumulation across modules. In contrast,\nend-to-end paradigms unify multi-tasks into a fully differentiable framework,\nallowing for optimization in a planning-oriented spirit. Despite the great\npotential of end-to-end paradigms, both the performance and efficiency of\nexisting methods are not satisfactory, particularly in terms of planning\nsafety. We attribute this to the computationally expensive BEV (bird's eye\nview) features and the straightforward design for prediction and planning. To\nthis end, we explore the sparse representation and review the task design for\nend-to-end autonomous driving, proposing a new paradigm named SparseDrive.\nConcretely, SparseDrive consists of a symmetric sparse perception module and a\nparallel motion planner. The sparse perception module unifies detection,\ntracking and online mapping with a symmetric model architecture, learning a\nfully sparse representation of the driving scene. For motion prediction and\nplanning, we review the great similarity between these two tasks, leading to a\nparallel design for motion planner. Based on this parallel design, which models\nplanning as a multi-modal problem, we propose a hierarchical planning selection\nstrategy , which incorporates a collision-aware rescore module, to select a\nrational and safe trajectory as the final planning output. With such effective\ndesigns, SparseDrive surpasses previous state-of-the-arts by a large margin in\nperformance of all tasks, while achieving much higher training and inference\nefficiency. Code will be avaliable at https://github.com/swc-17/SparseDrive for\nfacilitating future research.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Wenchao Sun",
            "Xuewu Lin",
            "Yining Shi",
            "Chuang Zhang",
            "Haoran Wu",
            "Sifa Zheng"
        ],
        "published": "2024-05-30T02:13:56Z"
    },
    {
        "title": "Easy Problems That LLMs Get Wrong",
        "link": "http://arxiv.org/abs/2405.19616v1",
        "abstract": "We introduce a comprehensive Linguistic Benchmark designed to evaluate the\nlimitations of Large Language Models (LLMs) in domains such as logical\nreasoning, spatial intelligence, and linguistic understanding, among others.\nThrough a series of straightforward questions, it uncovers the significant\nlimitations of well-regarded models to perform tasks that humans manage with\nease. It also highlights the potential of prompt engineering to mitigate some\nerrors and underscores the necessity for better training methodologies. Our\nfindings stress the importance of grounding LLMs with human reasoning and\ncommon sense, emphasising the need for human-in-the-loop for enterprise\napplications. We hope this work paves the way for future research to enhance\nthe usefulness and reliability of new models.",
        "subjects": [
            "cs.AI",
            "cs.CL",
            "cs.LG"
        ],
        "authors": [
            "Sean Williams",
            "James Huckle"
        ],
        "published": "2024-05-30T02:09:51Z"
    },
    {
        "title": "TAMBRIDGE: Bridging Frame-Centered Tracking and 3D Gaussian Splatting\n  for Enhanced SLAM",
        "link": "http://arxiv.org/abs/2405.19614v1",
        "abstract": "The limited robustness of 3D Gaussian Splatting (3DGS) to motion blur and\ncamera noise, along with its poor real-time performance, restricts its\napplication in robotic SLAM tasks. Upon analysis, the primary causes of these\nissues are the density of views with motion blur and the cumulative errors in\ndense pose estimation from calculating losses based on noisy original images\nand rendering results, which increase the difficulty of 3DGS rendering\nconvergence. Thus, a cutting-edge 3DGS-based SLAM system is introduced,\nleveraging the efficiency and flexibility of 3DGS to achieve real-time\nperformance while remaining robust against sensor noise, motion blur, and the\nchallenges posed by long-session SLAM. Central to this approach is the Fusion\nBridge module, which seamlessly integrates tracking-centered ORB Visual\nOdometry with mapping-centered online 3DGS. Precise pose initialization is\nenabled by this module through joint optimization of re-projection and\nrendering loss, as well as strategic view selection, enhancing rendering\nconvergence in large-scale scenes. Extensive experiments demonstrate\nstate-of-the-art rendering quality and localization accuracy, positioning this\nsystem as a promising solution for real-world robotics applications that\nrequire stable, near-real-time performance. Our project is available at\nhttps://ZeldaFromHeaven.github.io/TAMBRIDGE/",
        "subjects": [
            "cs.RO"
        ],
        "authors": [
            "Peifeng Jiang",
            "Hong Liu",
            "Xia Li",
            "Ti Wang",
            "Fabian Zhang",
            "Joachim M. Buhmann"
        ],
        "published": "2024-05-30T02:08:45Z"
    },
    {
        "title": "Keyword-driven Retrieval-Augmented Large Language Models for Cold-start\n  User Recommendations",
        "link": "http://arxiv.org/abs/2405.19612v1",
        "abstract": "Recent advancements in Large Language Models (LLMs) have shown significant\npotential in enhancing recommender systems. However, addressing the cold-start\nrecommendation problem, where users lack historical data, remains a\nconsiderable challenge. In this paper, we introduce KALM4Rec (Keyword-driven\nRetrieval-Augmented Large Language Models for Cold-start User Recommendations),\na novel framework specifically designed to tackle this problem by requiring\nonly a few input keywords from users in a practical scenario of cold-start user\nrestaurant recommendations. KALM4Rec operates in two main stages: candidates\nretrieval and LLM-based candidates re-ranking. In the first stage,\nkeyword-driven retrieval models are used to identify potential candidates,\naddressing LLMs' limitations in processing extensive tokens and reducing the\nrisk of generating misleading information. In the second stage, we employ LLMs\nwith various prompting strategies, including zero-shot and few-shot techniques,\nto re-rank these candidates by integrating multiple examples directly into the\nLLM prompts. Our evaluation, using a Yelp restaurant dataset with user reviews\nfrom three English-speaking cities, shows that our proposed framework\nsignificantly improves recommendation quality. Specifically, the integration of\nin-context instructions with LLMs for re-ranking markedly enhances the\nperformance of the cold-start user recommender system.",
        "subjects": [
            "cs.IR"
        ],
        "authors": [
            "Hai-Dang Kieu",
            "Minh Duc Nguyen",
            "Thanh-Son Nguyen",
            "Dung D. Le"
        ],
        "published": "2024-05-30T02:00:03Z"
    },
    {
        "title": "Factor Augmented Tensor-on-Tensor Neural Networks",
        "link": "http://arxiv.org/abs/2405.19610v1",
        "abstract": "This paper studies the prediction task of tensor-on-tensor regression in\nwhich both covariates and responses are multi-dimensional arrays (a.k.a.,\ntensors) across time with arbitrary tensor order and data dimension. Existing\nmethods either focused on linear models without accounting for possibly\nnonlinear relationships between covariates and responses, or directly employed\nblack-box deep learning algorithms that failed to utilize the inherent tensor\nstructure. In this work, we propose a Factor Augmented Tensor-on-Tensor Neural\nNetwork (FATTNN) that integrates tensor factor models into deep neural\nnetworks. We begin with summarizing and extracting useful predictive\ninformation (represented by the ``factor tensor'') from the complex structured\ntensor covariates, and then proceed with the prediction task using the\nestimated factor tensor as input of a temporal convolutional neural network.\nThe proposed methods effectively handle nonlinearity between complex data\nstructures, and improve over traditional statistical models and conventional\ndeep learning approaches in both prediction accuracy and computational cost. By\nleveraging tensor factor models, our proposed methods exploit the underlying\nlatent factor structure to enhance the prediction, and in the meantime,\ndrastically reduce the data dimensionality that speeds up the computation. The\nempirical performances of our proposed methods are demonstrated via simulation\nstudies and real-world applications to three public datasets. Numerical results\nshow that our proposed algorithms achieve substantial increases in prediction\naccuracy and significant reductions in computational time compared to benchmark\nmethods.",
        "subjects": [
            "stat.ML",
            "cs.LG",
            "stat.ME"
        ],
        "authors": [
            "Guanhao Zhou",
            "Yuefeng Han",
            "Xiufan Yu"
        ],
        "published": "2024-05-30T01:56:49Z"
    },
    {
        "title": "SMPLX-Lite: A Realistic and Drivable Avatar Benchmark with Rich Geometry\n  and Texture Annotations",
        "link": "http://arxiv.org/abs/2405.19609v1",
        "abstract": "Recovering photorealistic and drivable full-body avatars is crucial for\nnumerous applications, including virtual reality, 3D games, and tele-presence.\nMost methods, whether reconstruction or generation, require large numbers of\nhuman motion sequences and corresponding textured meshes. To easily learn a\ndrivable avatar, a reasonable parametric body model with unified topology is\nparamount. However, existing human body datasets either have images or textured\nmodels and lack parametric models which fit clothes well. We propose a new\nparametric model SMPLX-Lite-D, which can fit detailed geometry of the scanned\nmesh while maintaining stable geometry in the face, hand and foot regions. We\npresent SMPLX-Lite dataset, the most comprehensive clothing avatar dataset with\nmulti-view RGB sequences, keypoints annotations, textured scanned meshes, and\ntextured SMPLX-Lite-D models. With the SMPLX-Lite dataset, we train a\nconditional variational autoencoder model that takes human pose and facial\nkeypoints as input, and generates a photorealistic drivable human avatar.",
        "subjects": [
            "cs.CV",
            "cs.GR"
        ],
        "authors": [
            "Yujiao Jiang",
            "Qingmin Liao",
            "Zhaolong Wang",
            "Xiangru Lin",
            "Zongqing Lu",
            "Yuxi Zhao",
            "Hanqing Wei",
            "Jingrui Ye",
            "Yu Zhang",
            "Zhijing Shao"
        ],
        "published": "2024-05-30T01:53:39Z"
    },
    {
        "title": "Relation Modeling and Distillation for Learning with Noisy Labels",
        "link": "http://arxiv.org/abs/2405.19606v1",
        "abstract": "Learning with noisy labels has become an effective strategy for enhancing the\nrobustness of models, which enables models to better tolerate inaccurate data.\nExisting methods either focus on optimizing the loss function to mitigate the\ninterference from noise, or design procedures to detect potential noise and\ncorrect errors. However, their effectiveness is often compromised in\nrepresentation learning due to the dilemma where models overfit to noisy\nlabels. To address this issue, this paper proposes a relation modeling and\ndistillation framework that models inter-sample relationships via\nself-supervised learning and employs knowledge distillation to enhance\nunderstanding of latent associations, which mitigate the impact of noisy\nlabels. Specifically, the proposed method, termed RMDNet, includes two main\nmodules, where the relation modeling (RM) module implements the contrastive\nlearning technique to learn representations of all data, an unsupervised\napproach that effectively eliminates the interference of noisy tags on feature\nextraction. The relation-guided representation learning (RGRL) module utilizes\ninter-sample relation learned from the RM module to calibrate the\nrepresentation distribution for noisy samples, which is capable of improving\nthe generalization of the model in the inference phase. Notably, the proposed\nRMDNet is a plug-and-play framework that can integrate multiple methods to its\nadvantage. Extensive experiments were conducted on two datasets, including\nperformance comparison, ablation study, in-depth analysis and case study. The\nresults show that RMDNet can learn discriminative representations for noisy\ndata, which results in superior performance than the existing methods.",
        "subjects": [
            "cs.AI"
        ],
        "authors": [
            "Xiaming Che",
            "Junlin Zhang",
            "Zhuang Qi",
            "Xin Qi"
        ],
        "published": "2024-05-30T01:47:27Z"
    },
    {
        "title": "Morse and Lusternik-Schnirelmann for graphs",
        "link": "http://arxiv.org/abs/2405.19603v1",
        "abstract": "Both Morse theory and Lusternik-Schnirelmann theory link algebra, topology\nand analysis in a geometric setting. The two theories can be formulated in\nfinite geometries like graph theory or within finite abstract simplicial\ncomplexes. We work here mostly in graph theory and review the Morse\ninequalities b(k)-b(k-1) + ... + b(0) less of equal than c(k)-c(k-1) + ... +\nc(0) for the Betti numbers b(k) and the minimal number c(k) of Morse critical\npoints of index k and the Lusternik-Schnirelmann inequalities cup+1 less or\nequal than cat less or equal than cri, between the algebraic cup length cup,\nthe topological category cat and the analytic number cri counting the minimal\nnumber of critical points of a function.",
        "subjects": [
            "math.CO",
            "cs.DM",
            "57M15, 68R10, 55U10, 05Exx 57M15, 68R10, 55U10, 05Exx 57M15, 68R10,\n  55U10, 05Exx"
        ],
        "authors": [
            "Oliver Knill"
        ],
        "published": "2024-05-30T01:40:14Z"
    },
    {
        "title": "Do spectral cues matter in contrast-based graph self-supervised\n  learning?",
        "link": "http://arxiv.org/abs/2405.19600v1",
        "abstract": "The recent surge in contrast-based graph self-supervised learning has\nprominently featured an intensified exploration of spectral cues. However, an\nintriguing paradox emerges, as methods grounded in seemingly conflicting\nassumptions or heuristic approaches regarding the spectral domain demonstrate\nnotable enhancements in learning performance. This paradox prompts a critical\ninquiry into the genuine contribution of spectral information to contrast-based\ngraph self-supervised learning. This study undertakes an extensive\ninvestigation into this inquiry, conducting a thorough study of the\nrelationship between spectral characteristics and the learning outcomes of\ncontemporary methodologies. Based on this analysis, we claim that the\neffectiveness and significance of spectral information need to be questioned.\nInstead, we revisit simple edge perturbation: random edge dropping designed for\nnode-level self-supervised learning and random edge adding intended for\ngraph-level self-supervised learning. Compelling evidence is presented that\nthese simple yet effective strategies consistently yield superior performance\nwhile demanding significantly fewer computational resources compared to all\nprior spectral augmentation methods. The proposed insights represent a\nsignificant leap forward in the field, potentially reshaping the understanding\nand implementation of graph self-supervised learning.",
        "subjects": [
            "cs.LG",
            "cs.AI"
        ],
        "authors": [
            "Xiangru Jian",
            "Xinjian Zhao",
            "Wei Pang",
            "Chaolong Ying",
            "Yimu Wang",
            "Yaoyao Xu",
            "Tianshu Yu"
        ],
        "published": "2024-05-30T01:30:34Z"
    },
    {
        "title": "Evaluating the Effectiveness and Robustness of Visual Similarity-based\n  Phishing Detection Models",
        "link": "http://arxiv.org/abs/2405.19598v1",
        "abstract": "Phishing attacks pose a significant threat to Internet users, with\ncybercriminals elaborately replicating the visual appearance of legitimate\nwebsites to deceive victims. Visual similarity-based detection systems have\nemerged as an effective countermeasure, but their effectiveness and robustness\nin real-world scenarios have been unexplored. In this paper, we comprehensively\nscrutinize and evaluate state-of-the-art visual similarity-based anti-phishing\nmodels using a large-scale dataset of 450K real-world phishing websites. Our\nanalysis reveals that while certain models maintain high accuracy, others\nexhibit notably lower performance than results on curated datasets,\nhighlighting the importance of real-world evaluation. In addition, we observe\nthe real-world tactic of manipulating visual components that phishing attackers\nemploy to circumvent the detection systems. To assess the resilience of\nexisting models against adversarial attacks and robustness, we apply visible\nand perturbation-based manipulations to website logos, which adversaries\ntypically target. We then evaluate the models' robustness in handling these\nadversarial samples. Our findings reveal vulnerabilities in several models,\nemphasizing the need for more robust visual similarity techniques capable of\nwithstanding sophisticated evasion attempts. We provide actionable insights for\nenhancing the security of phishing defense systems, encouraging proactive\nactions. To the best of our knowledge, this work represents the first\nlarge-scale, systematic evaluation of visual similarity-based models for\nphishing detection in real-world settings, necessitating the development of\nmore effective and robust defenses.",
        "subjects": [
            "cs.CR"
        ],
        "authors": [
            "Fujiao Ji",
            "Kiho Lee",
            "Hyungjoon Koo",
            "Wenhao You",
            "Euijin Choo",
            "Hyoungshick Kim",
            "Doowon Kim"
        ],
        "published": "2024-05-30T01:28:36Z"
    },
    {
        "title": "SVFT: Parameter-Efficient Fine-Tuning with Singular Vectors",
        "link": "http://arxiv.org/abs/2405.19597v1",
        "abstract": "Popular parameter-efficient fine-tuning (PEFT) methods, such as LoRA and its\nvariants, freeze pre-trained model weights \\(W\\) and inject learnable matrices\n\\(\\Delta W\\). These \\(\\Delta W\\) matrices are structured for efficient\nparameterization, often using techniques like low-rank approximations or\nscaling vectors. However, these methods typically show a performance gap\ncompared to full fine-tuning. Although recent PEFT methods have narrowed this\ngap, they do so at the cost of additional learnable parameters. We propose\nSVFT, a simple approach that fundamentally differs from existing methods: the\nstructure imposed on \\(\\Delta W\\) depends on the specific weight matrix \\(W\\).\nSpecifically, SVFT updates \\(W\\) as a sparse combination of outer products of\nits singular vectors, training only the coefficients (scales) of these sparse\ncombinations. This approach allows fine-grained control over expressivity\nthrough the number of coefficients. Extensive experiments on language and\nvision benchmarks show that SVFT recovers up to 96% of full fine-tuning\nperformance while training only 0.006 to 0.25% of parameters, outperforming\nexisting methods that only recover up to 85% performance using 0.03 to 0.8% of\nthe trainable parameter budget.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Vijay Lingam",
            "Atula Tejaswi",
            "Aditya Vavre",
            "Aneesh Shetty",
            "Gautham Krishna Gudur",
            "Joydeep Ghosh",
            "Alex Dimakis",
            "Eunsol Choi",
            "Aleksandar Bojchevski",
            "Sujay Sanghavi"
        ],
        "published": "2024-05-30T01:27:43Z"
    },
    {
        "title": "The weight hierarchies of three classes of linear codes",
        "link": "http://arxiv.org/abs/2405.19596v1",
        "abstract": "Studying the generalized Hamming weights of linear codes is a significant\nresearch area within coding theory, as it provides valuable structural\ninformation about the codes and plays a crucial role in determining their\nperformance in various applications. However, determining the generalized\nHamming weights of linear codes, particularly their weight hierarchy, is\ngenerally a challenging task. In this paper, we focus on investigating the\ngeneralized Hamming weights of three classes of linear codes over finite\nfields. These codes are constructed by different defining sets. By analysing\nthe intersections between the definition sets and the duals of all\n$r$-dimensional subspaces, we get the inequalities on the sizes of these\nintersections. Then constructing subspaces that reach the upper bounds of these\ninequalities, we successfully determine the complete weight hierarchies of\nthese codes.",
        "subjects": [
            "cs.IT",
            "math.IT"
        ],
        "authors": [
            "Wei Lu",
            "Qingyao Wang",
            "Xiaoqiang Wang",
            "Dabin Zheng"
        ],
        "published": "2024-05-30T01:27:07Z"
    },
    {
        "title": "The RSNA Abdominal Traumatic Injury CT (RATIC) Dataset",
        "link": "http://arxiv.org/abs/2405.19595v1",
        "abstract": "The RSNA Abdominal Traumatic Injury CT (RATIC) dataset is the largest\npublicly available collection of adult abdominal CT studies annotated for\ntraumatic injuries. This dataset includes 4,274 studies from 23 institutions\nacross 14 countries. The dataset is freely available for non-commercial use via\nKaggle at\nhttps://www.kaggle.com/competitions/rsna-2023-abdominal-trauma-detection.\nCreated for the RSNA 2023 Abdominal Trauma Detection competition, the dataset\nencourages the development of advanced machine learning models for detecting\nabdominal injuries on CT scans. The dataset encompasses detection and\nclassification of traumatic injuries across multiple organs, including the\nliver, spleen, kidneys, bowel, and mesentery. Annotations were created by\nexpert radiologists from the American Society of Emergency Radiology (ASER) and\nSociety of Abdominal Radiology (SAR). The dataset is annotated at multiple\nlevels, including the presence of injuries in three solid organs with injury\ngrading, image-level annotations for active extravasations and bowel injury,\nand voxelwise segmentations of each of the potentially injured organs. With the\nrelease of this dataset, we hope to facilitate research and development in\nmachine learning and abdominal trauma that can lead to improved patient care\nand outcomes.",
        "subjects": [
            "cs.CV"
        ],
        "authors": [
            "Jeffrey D. Rudie",
            "Hui-Ming Lin",
            "Robyn L. Ball",
            "Sabeena Jalal",
            "Luciano M. Prevedello",
            "Savvas Nicolaou",
            "Brett S. Marinelli",
            "Adam E. Flanders",
            "Kirti Magudia",
            "George Shih",
            "Melissa A. Davis",
            "John Mongan",
            "Peter D. Chang",
            "Ferco H. Berger",
            "Sebastiaan Hermans",
            "Meng Law",
            "Tyler Richards",
            "Jan-Peter Grunz",
            "Andreas Steven Kunz",
            "Shobhit Mathur",
            "Sandro Galea-Soler",
            "Andrew D. Chung",
            "Saif Afat",
            "Chin-Chi Kuo",
            "Layal Aweidah",
            "Ana Villanueva Campos",
            "Arjuna Somasundaram",
            "Felipe Antonio Sanchez Tijmes",
            "Attaporn Jantarangkoon",
            "Leonardo Kayat Bittencourt",
            "Michael Brassil",
            "Ayoub El Hajjami",
            "Hakan Dogan",
            "Muris Becircic",
            "Agrahara G. Bharatkumar",
            "Eduardo Moreno Júdice de Mattos Farina",
            "Dataset Curator Group",
            "Dataset Contributor Group",
            "Dataset Annotator Group",
            "Errol Colak"
        ],
        "published": "2024-05-30T01:18:50Z"
    },
    {
        "title": "Why Larger Language Models Do In-context Learning Differently?",
        "link": "http://arxiv.org/abs/2405.19592v1",
        "abstract": "Large language models (LLM) have emerged as a powerful tool for AI, with the\nkey ability of in-context learning (ICL), where they can perform well on unseen\ntasks based on a brief series of task examples without necessitating any\nadjustments to the model parameters. One recent interesting mysterious\nobservation is that models of different scales may have different ICL\nbehaviors: larger models tend to be more sensitive to noise in the test\ncontext. This work studies this observation theoretically aiming to improve the\nunderstanding of LLM and ICL. We analyze two stylized settings: (1) linear\nregression with one-layer single-head linear transformers and (2) parity\nclassification with two-layer multiple attention heads transformers (non-linear\ndata and non-linear model). In both settings, we give closed-form optimal\nsolutions and find that smaller models emphasize important hidden features\nwhile larger ones cover more hidden features; thus, smaller models are more\nrobust to noise while larger ones are more easily distracted, leading to\ndifferent ICL behaviors. This sheds light on where transformers pay attention\nto and how that affects ICL. Preliminary experimental results on large base and\nchat models provide positive support for our analysis.",
        "subjects": [
            "cs.LG",
            "cs.AI",
            "cs.CL"
        ],
        "authors": [
            "Zhenmei Shi",
            "Junyi Wei",
            "Zhuoyan Xu",
            "Yingyu Liang"
        ],
        "published": "2024-05-30T01:11:35Z"
    },
    {
        "title": "Weights Augmentation: it has never ever ever ever let her model down",
        "link": "http://arxiv.org/abs/2405.19590v1",
        "abstract": "Weight play an essential role in deep learning network models. Unlike network\nstructure design, this article proposes the concept of weight augmentation,\nfocusing on weight exploration. The core of Weight Augmentation Strategy (WAS)\nis to adopt random transformed weight coefficients training and transformed\ncoefficients, named Shadow Weight(SW), for networks that can be used to\ncalculate loss function to affect parameter updates. However, stochastic\ngradient descent is applied to Plain Weight(PW), which is referred to as the\noriginal weight of the network before the random transformation. During\ntraining, numerous SW collectively form high-dimensional space, while PW is\ndirectly learned from the distribution of SW instead of the data. The weight of\nthe accuracy-oriented mode(AOM) relies on PW, which guarantees the network is\nhighly robust and accurate. The desire-oriented mode(DOM) weight uses SW, which\nis determined by the network model's unique functions based on WAT's\nperformance desires, such as lower computational complexity, lower sensitivity\nto particular data, etc. The dual mode be switched at anytime if needed. WAT\nextends the augmentation technique from data augmentation to weight, and it is\neasy to understand and implement, but it can improve almost all networks\namazingly. Our experimental results show that convolutional neural networks,\nsuch as VGG-16, ResNet-18, ResNet-34, GoogleNet, MobilementV2, and\nEfficientment-Lite, can benefit much at little or no cost. The accuracy of\nmodels is on the CIFAR100 and CIFAR10 datasets, which can be evaluated to\nincrease by 7.32\\% and 9.28\\%, respectively, with the highest values being\n13.42\\% and 18.93\\%, respectively. In addition, DOM can reduce floating point\noperations (FLOPs) by up to 36.33\\%. The code is available at\nhttps://github.com/zlearh/Weight-Augmentation-Technology.",
        "subjects": [
            "cs.LG"
        ],
        "authors": [
            "Junbin Zhuang",
            "Guiguang Din",
            "Yunyi Yan"
        ],
        "published": "2024-05-30T00:57:06Z"
    },
    {
        "title": "SAM-E: Leveraging Visual Foundation Model with Sequence Imitation for\n  Embodied Manipulation",
        "link": "http://arxiv.org/abs/2405.19586v1",
        "abstract": "Acquiring a multi-task imitation policy in 3D manipulation poses challenges\nin terms of scene understanding and action prediction. Current methods employ\nboth 3D representation and multi-view 2D representation to predict the poses of\nthe robot's end-effector. However, they still require a considerable amount of\nhigh-quality robot trajectories, and suffer from limited generalization in\nunseen tasks and inefficient execution in long-horizon reasoning. In this\npaper, we propose SAM-E, a novel architecture for robot manipulation by\nleveraging a vision-foundation model for generalizable scene understanding and\nsequence imitation for long-term action reasoning. Specifically, we adopt\nSegment Anything (SAM) pre-trained on a huge number of images and promptable\nmasks as the foundation model for extracting task-relevant features, and employ\nparameter-efficient fine-tuning on robot data for a better understanding of\nembodied scenarios. To address long-horizon reasoning, we develop a novel\nmulti-channel heatmap that enables the prediction of the action sequence in a\nsingle pass, notably enhancing execution efficiency. Experimental results from\nvarious instruction-following tasks demonstrate that SAM-E achieves superior\nperformance with higher execution efficiency compared to the baselines, and\nalso significantly improves generalization in few-shot adaptation to new tasks.",
        "subjects": [
            "cs.CV",
            "cs.LG",
            "cs.RO"
        ],
        "authors": [
            "Junjie Zhang",
            "Chenjia Bai",
            "Haoran He",
            "Wenke Xia",
            "Zhigang Wang",
            "Bin Zhao",
            "Xiu Li",
            "Xuelong Li"
        ],
        "published": "2024-05-30T00:32:51Z"
    },
    {
        "title": "Evaluation of Resonances via AAA Rational Approximation of Randomly\n  Scalarized Boundary Integral Resolvents",
        "link": "http://arxiv.org/abs/2405.19582v1",
        "abstract": "This paper presents a novel algorithm, based on use of rational approximants\nof randomly scalarized boundary integral resolvents, for the evaluation of\nacoustic and electromagnetic resonances in open and closed cavities; for\nsimplicity we restrict treatment to cavities in two-dimensional space. The\ndesired open cavity resonances (also known as ``eigenvalues'' for interior\nproblems, and ``scattering poles'' for exterior and open problems) are obtained\nas the poles of associated rational approximants; both the approximants and\ntheir poles are obtained by means of the recently introduced AAA\nrational-approximation algorithm. In fact, the proposed resonance-search method\napplies to any nonlinear eigenvalue problem (NEP) associated with a given\nfunction $F: U \\to \\mathbb{C}^{n\\times n}$, wherein a complex value $k$ is\nsought for which $F_kw = 0$ for some nonzero $w\\in \\mathbb{C}^n$. For the\ncavity problems considered in this paper, $F_k$ is taken as a spectrally\ndiscretized version of a Green function-based boundary integral operator at\nspatial frequency $k$. In all cases, the scalarized resolvent is given by an\nexpression of the form $u^* F_k^{-1} v$, where $u,v \\in \\mathbb{C}^n$ are fixed\nrandom vectors. A variety of numerical results are presented for both\nscattering resonances and other NEPs, demonstrating the accuracy of the method\neven for high frequency states.",
        "subjects": [
            "math.NA",
            "cs.NA"
        ],
        "authors": [
            "Oscar P. Bruno",
            "Manuel A. Santana",
            "Lloyd N. Trefethen"
        ],
        "published": "2024-05-30T00:22:09Z"
    },
    {
        "title": "Source Code Foundation Models are Transferable Binary Analysis Knowledge\n  Bases",
        "link": "http://arxiv.org/abs/2405.19581v1",
        "abstract": "Human-Oriented Binary Reverse Engineering (HOBRE) lies at the intersection of\nbinary and source code, aiming to lift binary code to human-readable content\nrelevant to source code, thereby bridging the binary-source semantic gap.\nRecent advancements in uni-modal code model pre-training, particularly in\ngenerative Source Code Foundation Models (SCFMs) and binary understanding\nmodels, have laid the groundwork for transfer learning applicable to HOBRE.\nHowever, existing approaches for HOBRE rely heavily on uni-modal models like\nSCFMs for supervised fine-tuning or general LLMs for prompting, resulting in\nsub-optimal performance. Inspired by recent progress in large multi-modal\nmodels, we propose that it is possible to harness the strengths of uni-modal\ncode models from both sides to bridge the semantic gap effectively. In this\npaper, we introduce a novel probe-and-recover framework that incorporates a\nbinary-source encoder-decoder model and black-box LLMs for binary analysis. Our\napproach leverages the pre-trained knowledge within SCFMs to synthesize\nrelevant, symbol-rich code fragments as context. This additional context\nenables black-box LLMs to enhance recovery accuracy. We demonstrate significant\nimprovements in zero-shot binary summarization and binary function name\nrecovery, with a 10.3% relative gain in CHRF and a 16.7% relative gain in a\nGPT4-based metric for summarization, as well as a 6.7% and 7.4% absolute\nincrease in token-level precision and recall for name recovery, respectively.\nThese results highlight the effectiveness of our approach in automating and\nimproving binary code analysis.",
        "subjects": [
            "cs.SE",
            "cs.AI"
        ],
        "authors": [
            "Zian Su",
            "Xiangzhe Xu",
            "Ziyang Huang",
            "Kaiyuan Zhang",
            "Xiangyu Zhang"
        ],
        "published": "2024-05-30T00:17:44Z"
    },
    {
        "title": "Facilitating Mixed-Methods Analysis with Computational Notebooks",
        "link": "http://arxiv.org/abs/2405.19580v1",
        "abstract": "Data exploration is an important aspect of the workflow of mixed-methods\nresearchers, who conduct both qualitative and quantitative analysis. However,\nthere currently exists few tools that adequately support both types of analysis\nsimultaneously, forcing researchers to context-switch between different tools\nand increasing their mental burden when integrating the results. To address\nthis gap, we propose a unified environment that facilitates mixed-methods\nanalysis in a computational notebook-based settings. We conduct a scenario\nstudy with three HCI mixed-methods researchers to gather feedback on our design\nconcept and to understand our users' needs and requirements.",
        "subjects": [
            "cs.HC",
            "H.5; H.5.2"
        ],
        "authors": [
            "Jiawen Stefanie Zhu",
            "Zibo Zhang",
            "Jian Zhao"
        ],
        "published": "2024-05-30T00:11:00Z"
    },
    {
        "title": "The Accuracy of Domain Specific and Descriptive Analysis Generated by\n  Large Language Models",
        "link": "http://arxiv.org/abs/2405.19578v1",
        "abstract": "Large language models (LLMs) have attracted considerable attention as they\nare capable of showcasing impressive capabilities generating comparable\nhigh-quality responses to human inputs. LLMs, can not only compose textual\nscripts such as emails and essays but also executable programming code.\nContrary, the automated reasoning capability of these LLMs in performing\nstatistically-driven descriptive analysis, particularly on user-specific data\nand as personal assistants to users with limited background knowledge in an\napplication domain who would like to carry out basic, as well as advanced\nstatistical and domain-specific analysis is not yet fully explored. More\nimportantly, the performance of these LLMs has not been compared and discussed\nin detail when domain-specific data analysis tasks are needed. This study,\nconsequently, explores whether LLMs can be used as generative AI-based personal\nassistants to users with minimal background knowledge in an application domain\ninfer key data insights. To demonstrate the performance of the LLMs, the study\nreports a case study through which descriptive statistical analysis, as well as\nNatural Language Processing (NLP) based investigations, are performed on a\nnumber of phishing emails with the objective of comparing the accuracy of the\nresults generated by LLMs to the ones produced by analysts. The experimental\nresults show that LangChain and the Generative Pre-trained Transformer (GPT-4)\nexcel in numerical reasoning tasks i.e., temporal statistical analysis, achieve\ncompetitive correlation with human judgments on feature engineering tasks while\nstruggle to some extent on domain specific knowledge reasoning, where\ndomain-specific knowledge is required.",
        "subjects": [
            "cs.CE",
            "econ.GN",
            "q-fin.EC"
        ],
        "authors": [
            "Denish Omondi Otieno",
            "Faranak Abri",
            "Sima Siami-Namini",
            "Akbar Siami Namin"
        ],
        "published": "2024-05-30T00:05:04Z"
    }
]